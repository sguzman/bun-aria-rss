<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/"><channel><title>IEEE Spectrum</title><link>https://spectrum.ieee.org/</link><description>IEEE Spectrum</description><atom:link href="https://spectrum.ieee.org/feeds/topic/biomedical.rss" rel="self"></atom:link><language>en-us</language><lastBuildDate>Wed, 02 Nov 2022 20:41:17 -0000</lastBuildDate><image><url>https://spectrum.ieee.org/media-library/eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy8yNjg4NDUyMC9vcmlnaW4ucG5nIiwiZXhwaXJlc19hdCI6MTY5OTk5OTQzOX0.aimbeagNFKGtififsLPFvztNYGr1_NMvLOOT1mPOjEU/image.png?width=210</url><link>https://spectrum.ieee.org/</link><title>IEEE Spectrum</title></image><item><title>NYU Biomedical Engineering Speeds Research from Lab Bench to Bedside</title><link>https://spectrum.ieee.org/nyu-biomedical-engineering</link><description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/medical-equipment-with-two-rings-each-with-concentric-sensors-and-wires-connected-to-a-computer-nearby.jpg?id=31997012&width=1245&height=700&coordinates=0%2C0%2C0%2C2"/><br/><br/><p><em>This is a sponsored article brought to you by <a href="https://engineering.nyu.edu/?utm_source=ieee&utm_medium=email&utm_campaign=reputation-2022&utm_content=hielscher-bme" rel="noopener noreferrer" target="_blank">NYU’s Tandon School of Engineering</a>.</em></p><p>When <a href="https://engineering.nyu.edu/academics/departments/biomedical-engineering/faculty?utm_source=ieee&utm_medium=email&utm_campaign=reputation-2022&utm_content=hielscher-bme" rel="noopener noreferrer" target="_blank">Andreas H. Hielscher</a>, the chair of the <a href="https://engineering.nyu.edu/academics/departments/biomedical-engineering?utm_source=ieee&utm_medium=email&utm_campaign=reputation-2022&utm_content=hielscher-bme" rel="noopener noreferrer" target="_blank">biomedical engineering (BME) department at NYU’s Tandon School of Engineering</a>, arrived at his new position, <a href="https://engineering.nyu.edu/news/introducing-new-chair-tandons-department-biomedical-engineering?utm_source=ieee&utm_medium=email&utm_campaign=reputation-2022&utm_content=hielscher-bme" rel="noopener noreferrer" target="_blank">he</a><a href="https://engineering.nyu.edu/news/introducing-new-chair-tandons-department-biomedical-engineering?utm_source=ieee&utm_medium=email&utm_campaign=reputation-2022&utm_content=hielscher-bme" rel="noopener noreferrer" target="_blank"> saw raw </a><a href="https://engineering.nyu.edu/news/introducing-new-chair-tandons-department-biomedical-engineering?utm_source=ieee&utm_medium=email&utm_campaign=reputation-2022&utm_content=hielscher-bme" rel="noopener noreferrer" target="_blank">potential</a>. NYU Tandon had undergone a meteoric rise in its <em>U.S. News & World Report </em>graduate ranking in recent years, skyrocketing 47 spots since 2009. At the same time, the <a href="https://med.nyu.edu/our-community/about-us" rel="noopener noreferrer" target="_blank">NYU Grossman School of Medicine</a> had shot from the thirties to the #2 spot in the country for research. The two scientific powerhouses, sitting on opposite banks of the East River, offered Hielscher a unique opportunity: to work at the intersection of engineering and healthcare research, with the unmet clinical needs and clinician feedback from NYU’s world-renowned medical program directly informing new areas of development, exploration, and testing.</p><hr/><h3></h3><br/><p>“There is now an understanding that technology coming from a biomedical engineering department can play a big role for a top-tier medical school,” said Hielscher. “At some point, everybody needs to have a BME department.”</p><p>In the early days of biomedical engineering departments nationwide, there was some resistance even to the notion of biomedical engineering: either you were an electrical engineer or a mechanical engineer. “That’s no longer the case,” said Hielscher. “The combining of the biology and medical aspects with the engineering aspects has been proven to be the best approach.”</p><h3></h3><br/><span class="rm-shortcode" data-rm-shortcode-id="9b55948ce0289b58bf59d0e2b87681eb" style="display:block;position:relative;padding-top:56.25%;"><iframe frameborder="0" height="auto" lazy-loadable="true" scrolling="no" src="https://www.youtube.com/embed/IukEi7aHndI?rel=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" width="100%"></iframe></span><p class="caption">Dr. Andreas Hielscher, NYU Tandon Biomedical Engineering Department Chair and head of the Clinical Biophotonics Laboratory, speaks with IEEE Spectrum about his work leveraging optical tomography for early detection and treatment monitoring for breast cancer.</p><h3></h3><br/><p>The proof of this can be seen by the trend that an undergraduate biomedical degree has become one of the most desired engineering degrees, according to Hielscher. He also noted that the current Dean of NYU’s Tandon School of Engineering, <a href="https://engineering.nyu.edu/faculty/jelena-kovacevic?utm_source=ieee&utm_medium=email&utm_campaign=reputation-2022&utm_content=hielscher-bme" rel="noopener noreferrer" target="_blank">Jelena Kovačević</a>, has a biomedical engineering background, having just received the 2022 IEEE Engineering in Medicine and Biology Society <a href="https://youtu.be/v_b-ElMEUc8" rel="noopener noreferrer" target="_blank">career achievement award</a> for her pioneering research related to signal processing applications for biomedical imaging.</p><p>Mary Cowman, a pioneer in joint and cartilage regeneration, began laying the foundations for NYU Tandon’s biomedical engineering department in the 2010s. Since her retirement in 2020, Hielscher has continued to grow the department through innovative collaborations with the medical school and medical center, including the recently-announced <a href="https://engineering.nyu.edu/research-innovation/entrepreneurship/nyu-translational-healthcare-initiative?utm_source=ieee&utm_medium=email&utm_campaign=reputation-2022&utm_content=hielscher-bme" rel="noopener noreferrer" target="_blank">Translational Healthcare Initiative</a>, on which Hielscher worked closely with <a href="https://engineering.nyu.edu/faculty/daniel-sodickson?utm_source=ieee&utm_medium=email&utm_campaign=reputation-2022&utm_content=hielscher-bme" rel="noopener noreferrer" target="_blank">Daniel Sodickson</a>, the co-director of the medical school’s <a href="https://med.nyu.edu/departments-institutes/health-technology-engineering/" rel="noopener noreferrer" target="_blank">Tech4Health</a>.</p><h3></h3><br/><img alt="Man with beard and eyeglasses in a suit against a background showing bookshelves." class="rm-shortcode" data-rm-shortcode-id="d3fcdd5a36712e5fe07365db6d2f0582" data-rm-shortcode-name="rebelmouse-image" id="647ca" loading="lazy" src="https://spectrum.ieee.org/media-library/man-with-beard-and-eyeglasses-in-a-suit-against-a-background-showing-bookshelves.jpg?id=31996999&width=980"/><h3></h3><br/><p>“The fundamental idea of the Initiative is to have one physician from Langone Medical School, and one engineer at least—you could have multiple—and have them address some unmet clinical needs, some particular problem,” explained Hielscher. “In many cases they have already worked together, or researched this issue. What this initiative is about is to give these groups funding to do some experimentation to either prove that it won’t work, or demonstrate that it can and prioritize it.”<br/></p><p>With this funding of further experimentation, it becomes possible to develop the technology to a point where you could begin to bring investors in, according Hielscher. “This mitigates the risk of the technology and helps attract potential investors,” added Hielscher. “At that point, perhaps a medical device company comes in, or some angel investor, and then you can get to the next level of investment for moving the technology forward.”</p><h2>Biophotonics for Cancer Diagnosis</h2><p>Hielscher himself has been leading research on developing new technologies within the <a href="https://wp.nyu.edu/tandonschoolofengineering-cbl/" target="_blank">Clinical Biophotonics Laboratory</a>. One of the latest areas of research has been investigating the application of optical technologies to breast cancer diagnosis.</p><h3></h3><br><img alt="Six images showing tomographic cross sections of a breast with tumor" class="rm-shortcode" data-rm-shortcode-id="3c81468928b06738c7989f37ff4f9b7e" data-rm-shortcode-name="rebelmouse-image" id="95ede" loading="lazy" src="https://spectrum.ieee.org/media-library/six-images-showing-tomographic-cross-sections-of-a-breast-with-tumor.jpg?id=31996967&width=980"/><h3></h3><br/><p>Hielscher and his colleagues have built a system that shines light through both breasts at the same time. By measuring how much light is reflected back it’s possible to generate maps of locations with high levels of oxygen and total hemoglobin, which may indicate tumors.</p><p>“We look at where there’s blood in the breast,” explained Hielscher. “Because breast tumors recruit new blood vessels, or, once they grow, they generate their own vascular network requiring more oxygen, wherever there is a tumor you will see an increase in total blood volume, and you will see more oxygenated blood.”</p><p>Initially, this diagnostic tool was targeted for early detection, since mammograms can only detect calcification in lower density breast tissue of women over a certain age. But it soon became clear in collaboration with clinical partners that it was also highly effective in monitoring treatment.</p><h3></h3><br/><p>“Technology coming from a biomedical engineering department can play a big role for a top-tier medical school”<br/>—Andreas H. Hielscher, Biomedical Engineering Department Chair, NYU Tandon</p><h3></h3><br><p>This realization came in part because of a recent change in cancer treatment that has moved towards what is known as neoadjuvant chemotherapy, in which chemotherapy drugs are administered before surgical extraction of the tumor. One of the drawbacks of this approach is that only around 60 percent of patients respond favorably to the chemotherapy, resulting in a large percentage of patients suffering through a grueling six-month-long chemotherapy treatment with minimal-to-no impact on the tumor.</p><p>With the optical technique, Hielscher and his colleagues have found that if they can detect a noticeable decrease of blood in targeted areas after two weeks, it’s very likely that the patient will respond to the chemotherapy. On the other hand, if they see that the amount of blood in that area stays the same, then there’s a very high likelihood that the patient will not respond to the therapy.</p><p>This same fundamental technique can also be applied to what is known as peripheral artery disease (PAD), which affects many patients with diabetes and involves the narrowing or blockage of the vessels that carry blood from the heart to the legs. An Israel-based company called <a href="https://www.votis.net/" target="_blank">VOTIS</a> has licensed the technology for diagnosing and treating PAD.</p><h3></h3><br/><img alt="Medical equipment image with blue background showing in bright yellow a finger joint affected by lupus arthritis" class="rm-shortcode" data-rm-shortcode-id="d1930edb3000e4edfd4b2acf58f513c1" data-rm-shortcode-name="rebelmouse-image" id="586bc" loading="lazy" src="https://spectrum.ieee.org/media-library/medical-equipment-image-with-blue-background-showing-in-bright-yellow-a-finger-joint-affected-by-lupus-arthritis.jpg?id=31996972&width=980"/><h3></h3><br/><p>
	While Hielscher’s work is in biophotonics, he recognized that the department has also quickly been developing a reputation in other emerging areas, including wearables, synthetic biology, and neurorehabilitation and stroke prediction.
</p><p>
	Hielscher highlighted the recent work of <a href="https://engineering.nyu.edu/faculty/rose-faghih?utm_source=ieee&utm_medium=email&utm_campaign=reputation-2022&utm_content=hielscher-bme" target="_blank">Rose Faghih</a>, working in smart wearables and data for mental health, <a href="https://engineering.nyu.edu/faculty/jef-d-boeke?utm_source=ieee&utm_medium=email&utm_campaign=reputation-2022&utm_content=hielscher-bme" rel="noopener noreferrer" target="_blank">Jef Boeke</a>, a synthetic biology pioneer, and <a href="https://engineering.nyu.edu/faculty/s-farokh-atashzar?utm_source=ieee&utm_medium=email&utm_campaign=reputation-2022&utm_content=hielscher-bme" rel="noopener noreferrer" target="_blank">S. Farokh Atashzar</a>, doing work in neurorehabilitation and stroke prediction. Atashzar’s work was highlighted last year in the pages of <a href="https://spectrum.ieee.org/nyu-tandon-robotics" target="_self"><em>IEEE Spectrum</em></a>.
</p><p>
	“Rose Faghih is leveraging all kinds of sensors to make inferences about the mental state of patients, to determine if someone is depressed or schizophrenic, and then possibly have a feedback loop where you actually also treat them,” said Hielscher. “Jef Boeke is involved in what I term ‘wet engineering,’ and is currently involved in efforts to take cancer cells outside of the body to find a way to attack them, or reprogram them.”
</p><h2>Future Collaborations</h2><p>
	As NYU Tandon’s BME department goes forward, Hielscher’s aim is that the department becomes a trusted source for the medical school, and that partnership enables key technologies to go from an unmet clinical need or an idea in a lab to a patient’s bedside in a 3-5 year timeframe.
</p><p>
	“What I really would like, “Hielscher concluded, “is that if somebody in the medical school has a problem, the first thing they would say is, ‘Oh, I’ll call the engineering school. I bet there’s somebody there that can help me.’ We can work together to benefit patients, and we’re starting this already.”<span class="ieee-end-mark"></span>
</p></br></br>]]></description><pubDate>Mon, 31 Oct 2022 14:46:16 +0000</pubDate><guid>https://spectrum.ieee.org/nyu-biomedical-engineering</guid><category>Biomedical engineering</category><category>Nyu tandon</category><category>Cancer</category><category>Optics</category><category>Medical diagnostics</category><category>Medical imaging</category><dc:creator>Dexter Johnson</dc:creator><media:content medium="image" type="image/jpeg" url="https://spectrum.ieee.org/media-library/medical-equipment-with-two-rings-each-with-concentric-sensors-and-wires-connected-to-a-computer-nearby.jpg?id=31997012&amp;width=980"></media:content></item><item><title>Nanoparticles in Medicine—Microbots to Blood Clots</title><link>https://spectrum.ieee.org/medical-nanoparticles</link><description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/microscopic-image-of-neutrophils-and-blood-cells.jpg?id=31945869&width=1245&height=700&coordinates=0%2C234%2C0%2C235"/><br/><br/><p>As nanotechology burrows into an increasing number of medical technologies, new developments in nanoparticles point to the ways that treatments can today be nanotechnologically targeted. In one case, would-be end effectors on microrobots are aimed at clearing up cases of bacterial pneumonia. In another, a smart-targeting system may decrease clotting risks in dangerous cases of thrombosis. </p><p>Scientists from the University of California, San Diego, demonstrated antibiotic-filled nanoparticles that hitch a ride on microbots made of algae to deliver targeted therapeutics. Their <a href="https://www.nature.com/articles/s41563-022-01360-9" target="_blank">paper</a> was recently published in <em>Nature Materials</em>. As a proof of concept, the researchers administered antibiotic-laden microbots to mice infected with a potentially fatal variety of pneumonia (a strain that is common in human patients who are receiving mechanical ventilation in  intensive-care settings). All infections in the treated mice cleared up within a week, while untreated mice died within three days.<br/></p><p>The algae–nanoparticle hybrid microbots were effectively distributed to infected tissue through lung fluid and showed negligible toxicity. “Our goal is to do targeted drug delivery into more challenging parts of
 the body, like the lungs,” said bioengineering professor <a href="https://iem.ucsd.edu/researchers/people/profiles/liangfang-zhang.html" target="_blank">Liangfang Zhang</a> in a press statement. “And we want to do it in a way that is safe, 
easy, biocompatible, and long lasting.” </p><p>The nanoparticle treatment was also shown to be more effective than an IV injection because of its targeted delivery. “With an IV injection, sometimes only a very small fraction of 
antibiotics will get into the lungs,” said coresearcher <a href="https://profiles.ucsd.edu/victor.nizet" target="_blank">Victor Nizet</a> in the press release. This results in high mortality for patients with current antibiotic treatments for pneumonia. “Based on 
these mouse data, we see that the microrobots could potentially improve 
antibiotic penetration to kill bacterial pathogens and save more 
patients’ lives.”</p><h2>Nano targets neutro</h2><p>Thrombosis, or the obstruction of blood flow in the body because of clot (thrombus) formation, is one of the <a href="https://www.who.int/news-room/fact-sheets/detail/the-top-10-causes-of-death" target="_blank"><u>leading killers</u></a> of humans globally. Even so, the molecular drivers of thrombosis are poorly understood. A recent <a href="https://www.science.org/doi/10.1126/scitranslmed.abj7465" target="_blank"><u>paper</u></a> published in <em>Science Translational Medicine</em> identifies neutrophils as playing a key role in thrombosis. Targeting neutrophils using nanoparticle therapy, the researchers report, decreases clotting risk without increasing the risk of bleeding.<br/></p><p><u><a href="https://case.edu/cancer/members/member-directory/lalitha-nayak" target="_blank">Lalitha Nayak</a></u>, associate professor at the <a href="https://case.edu/medicine/" target="_blank">Case Western Reserve School of Medicine</a>, in Cleveland, first author of the study, says this is the first time overactive neutrophils have been identified as a key driver of both venous and arterial thrombosis.</p><p>Diseases associated with arterial clots are not the same as those with venous clots. Arteries are thicker, as are their walls, while veins are collapsible with thinner walls; the endothelial lining of these vessels are different, as are the pressures of the blood running through them. Myocardial infarction, or heart attack, for instance, is an arterial clot event, while deep-vein thrombosis is due to venous clots. Therefore, treatments for these two types of thromboses have also been different. </p><p>However, there are some diseases where you see both arterial and venous clots, Nayak says, one of those being antiphospholipid antibody syndrome (APS). This is what the researchers used as a model in their study. They identified key molecular events that serve as potential targets for treatment of thrombosis in APS.</p><p><u><a href="https://www.healthline.com/health/neutrophils" rel="noopener noreferrer" target="_blank">Neutrophils</a></u> are a type of white blood cells that are first responders in the body’s immune system. Ordinarily, they rush to a site of injury or infection, and capture and destroy (by ingesting) infection-causing microorganisms.</p><p>In the present paper, a culmination of 10 years of research, Nayak and colleagues used mice models to show how overactive neutrophils participate in thrombosis because of their tendency to migrate and adhere to sites of injury, increasing the production of key factors used as building blocks of clots. </p><p>Theoretically, blocking neutrophils should make the thrombosis go away, but as these cells play an important immune role, that wouldn’t be practical. “That’s why we developed nanoparticles that specifically [identify and] target one receptor on an activated neutrophil,” Nayak says.<br/></p><p>The nanoparticles are synthetically engineered particles and are coated with different proteins of interest, she adds. For this study, they were coated with an antibody that would target specific receptors on neutrophils. “We did a lot of ex vivo studies to show that this is very specific and targets only activated neutrophils,” she says. “And we showed that if the animals were injected with this nanoparticle, thrombosis was significantly mitigated.”</p><p>At this point, as Nayak points out, their study is a proof of principle to show that if they could develop something like this for human patients, then they could mitigate thrombosis for them as well, irrespective of whether it was caused by, cancer, APS, or any other disease. </p><p>“For us now, the [next] challenge would be to try and develop something that would be translational, to take it to the bench [and then] from the bench to the bedside,” she says. “My next study would include patients’ samples, patients with antiphospholipid antibodies. We want to show that what we did in the mouse can be done in humans.”</p><p>Nayak’s study could be significant not just in treating thrombosis in general, but also could play a crucial role in the treatment regimes of other diseases that have blood clots as a common complication, such as cancer. Testing their nanoparticle therapy on cancer-associated thrombosis in mice is also among Nayak’s future plans.</p>]]></description><pubDate>Sun, 30 Oct 2022 14:00:01 +0000</pubDate><guid>https://spectrum.ieee.org/medical-nanoparticles</guid><category>Biomedical</category><category>Biomedical engineering</category><category>Biomedicine</category><category>Nanoparticles</category><category>Nanobots</category><dc:creator>Payal Dhar</dc:creator><media:content medium="image" type="image/jpeg" url="https://spectrum.ieee.org/media-library/microscopic-image-of-neutrophils-and-blood-cells.jpg?id=31945869&amp;width=980"></media:content></item><item><title>This Implant Turns Brain Waves Into Words</title><link>https://spectrum.ieee.org/brain-computer-interface-speech</link><description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/a-man-using-an-interface-looking-at-a-screen-with-words-on-it.png?id=32005613&width=1245&height=700&coordinates=156%2C0%2C157%2C0"/><br/><br/><p>
<strong>A computer screen </strong>shows the question “Would you like some water?” Underneath, three dots blink, followed by words that appear, one at a time: “No I am not thirsty.”
</p><p>
	It was brain activity that made those words materialize—the brain of a man who has not spoken for more than 15 years, ever since a stroke damaged the connection between his brain and the rest of his body, leaving him mostly paralyzed. He has used many other technologies to communicate; most recently, he used a pointer attached to his baseball cap to tap out words on a touchscreen, a method that was effective but slow. He volunteered for 
	<a href="https://changlab.ucsf.edu/" target="_blank">my research group</a>’s clinical trial at the <a href="https://www.ucsf.edu/" target="_blank">University of California, San Francisco</a> in hopes of pioneering a faster method. So far, he has used the brain-to-text system only during research sessions, but he wants to help develop the technology into something that people like himself could use in their everyday lives.
</p><hr/><p>
	In 
	<a href="https://www.nejm.org/doi/full/10.1056/NEJMoa2027540" target="_blank">our pilot study</a>, we draped a thin, flexible electrode array over the surface of the volunteer’s brain. The electrodes recorded neural signals and sent them to a speech decoder, which translated the signals into the words the man intended to say. It was the first time a paralyzed person who couldn’t speak had used neurotechnology to broadcast whole words—not just letters—from the brain.
</p><p>
	That trial was the culmination of more than a decade of research on the underlying brain mechanisms that govern speech, and we’re enormously proud of what we’ve accomplished so far. But we’re just getting started. 
	<a href="http://changlab.ucsf.edu/" target="_blank">My lab at UCSF</a> is working with colleagues around the world to make this technology safe, stable, and reliable enough for everyday use at home. We’re also working to improve the system’s performance so it will be worth the effort.
</p><h2>How neuroprosthetics work</h2><p class="shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left" data-rm-resized-container="25%" style="float: left;">
<img alt="A series of three photographs shows the back of a man\u2019s head that has a device and a wire attached to the skull. A screen in front of the man shows three questions and responses, including \u201cWould you like some water?\u201d and \u201cNo I am not thirsty.\u201d" class="rm-shortcode rm-resized-image" data-rm-shortcode-id="9c244396817e338bf94872811b9ab530" data-rm-shortcode-name="rebelmouse-image" id="dfde7" loading="lazy" src="https://spectrum.ieee.org/media-library/a-series-of-three-photographs-shows-the-back-of-a-man-u2019s-head-that-has-a-device-and-a-wire-attached-to-the-skull-a-screen-i.png?id=32001054&width=980" style="max-width: 100%"/>
<small class="image-media media-caption" placeholder="Add Photo Caption..." style="max-width: 100%;">The first version of the brain-computer interface gave the volunteer a vocabulary of 50 practical words. </small>
<small class="image-media media-photo-credit" placeholder="Add Photo Credit..." style="max-width: 100%;">University of California, San Francisco</small></p><p>
	Neuroprosthetics have come a long way in the past two decades. Prosthetic implants for hearing have advanced the furthest, with designs that interface with the 
	<a href="https://en.wikipedia.org/wiki/Cochlear_implant" target="_blank">cochlear nerve</a> of the inner ear or directly into the <a href="https://www.mayoclinic.org/tests-procedures/auditory-brainstem-implant/about/pac-20384649" target="_blank">auditory brain stem</a>. There’s also considerable research on <a href="https://spectrum.ieee.org/french-regulators-approve-human-trial-of-a-bionic-eye" target="_self">retinal</a> and <a href="https://spectrum.ieee.org/progress-toward-a-brain-implant-for-the-blind" target="_self">brain implants</a> for vision, as well as efforts to give people with prosthetic hands <a href="https://spectrum.ieee.org/bionic-hands-let-amputees-feel-and-grip" target="_self">a sense of touch</a>. All of these sensory prosthetics take information from the outside world and convert it into electrical signals that feed into the brain’s processing centers.
</p><p>
	The opposite kind of neuroprosthetic records the electrical activity of the brain and converts it into signals that control something in the outside world, such as a 
	<a href="https://spectrum.ieee.org/a-better-way-for-brains-to-control-robotic-arms" target="_self">robotic arm</a>, a <a href="https://spectrum.ieee.org/quadriplegic-pilots-race-for-gold-in-cybathlon-brain-race" target="_self">video-game controller</a>, or a <a href="https://spectrum.ieee.org/new-record-for-typing-by-brain-paralyzed-man-uses-brain-implant-to-type-8-words-per-minute" target="_self">cursor</a> on a computer screen. That last control modality has been used by groups such as the <a href="https://www.braingate.org/" target="_blank">BrainGate consortium</a> to enable paralyzed people to <a href="https://spectrum.ieee.org/people-paralysis-command-computers-wirelessly" target="_self">type words</a>—sometimes one letter at a time, sometimes using an autocomplete function to speed up the process.
</p><p>
	For that typing-by-brain function, an implant is typically placed in the motor cortex, the part of the brain that controls movement. Then the user imagines certain physical actions to control a cursor that moves over a virtual keyboard. Another approach, pioneered by some of my collaborators in a 
	<a href="https://www.nature.com/articles/s41586-021-03506-2.epdf?sharing_token=DsRZtRuFdieF5Yaw89p1GdRgN0jAjWel9jnR3ZoTv0No0Kktd9EUuDWeYWONAJ_7c9Vh-4dwWbu73lNBtR0SQIf6IATlhZ46V90CDPbxsChH4nCQRro7BGVvoyq7J1WjdI7xyn5OqpUdtG17JjQqmnEw1vWhwTgHs15FL3T_UOt48eOhTNkpTZ2H2CIz3RxMjlpXcdtJjKbGa1Ecdmbxh24IPyhEhFKcZ3e6zl5sF2YI4i7R7KRSp2iyVjkqgbvGAaTaWTrtF-jHWV5gqTXgF8vPfRjc-_gqpuUB58vK_mTr00cZmL7718XZrMGfw2ow&tracking_referrer=spectrum.ieee.org" target="_self">2021 paper</a>, had one user imagine that he was holding a pen to paper and was writing letters, creating signals in the motor cortex that were translated into text. That approach <a href="https://spectrum.ieee.org/braincomputer-interface-smashes-previous-record-for-typing-speed" target="_self">set a new record for speed</a>, enabling the volunteer to write about 18 words per minute.
</p><p>
	In my lab’s research, we’ve taken a more ambitious approach. Instead of decoding a user’s intent to move a cursor or a pen, we decode the intent to control the vocal tract, comprising dozens of muscles governing the larynx (commonly called the voice box), the tongue, and the lips.
</p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="A photo taken from above shows a room full of computers and other equipment with a man in a wheelchair in the center, facing a screen. " class="rm-shortcode" data-rm-shortcode-id="a99c14fa3abed1263e636f1a3c75356d" data-rm-shortcode-name="rebelmouse-image" id="76dc9" loading="lazy" src="https://spectrum.ieee.org/media-library/a-photo-taken-from-above-shows-a-room-full-of-computers-and-other-equipment-with-a-man-in-a-wheelchair-in-the-center-facing-a-s.png?id=32001098&width=980"/>
<small class="image-media media-caption" placeholder="Add Photo Caption...">The seemingly simple conversational setup for the paralyzed man [in pink shirt] is enabled by both sophisticated neurotech hardware and machine-learning systems that decode his brain signals. </small>
<small class="image-media media-photo-credit" placeholder="Add Photo Credit...">University of California, San Francisco</small></p><p>
	I began working in this area more than 10 years ago. As a neurosurgeon, I would often see patients with severe injuries that left them unable to speak. To my surprise, in many cases the locations of brain injuries didn’t match up with the syndromes I learned about in medical school, and I realized that we still have a lot to learn about how language is processed in the brain. I decided to study the underlying neurobiology of language and, if possible, to develop a brain-machine interface (BMI) to restore communication for people who have lost it. In addition to my neurosurgical background, my team has expertise in linguistics, electrical engineering, computer science, bioengineering, and medicine. Our ongoing clinical trial is testing both hardware and software to explore the limits of our BMI and determine what kind of speech we can restore to people.
</p><h2>The muscles involved in speech</h2><p>
	Speech is one of the behaviors that 
	<a href="https://bmcbiol.biomedcentral.com/articles/10.1186/s12915-017-0405-3" target="_blank">sets humans apart</a>. Plenty of other species vocalize, but only humans combine a set of sounds in myriad different ways to represent the world around them. It’s also an extraordinarily complicated motor act—some experts believe it’s the most complex motor action that people perform. Speaking is a product of modulated air flow through the vocal tract; with every utterance we shape the breath by creating audible vibrations in our laryngeal vocal folds and changing the shape of the lips, jaw, and tongue.
</p><p>
	Many of the muscles of the vocal tract are quite unlike the joint-based muscles such as those in the arms and legs, which can move in only a few prescribed ways. For example, the muscle that controls the lips is a sphincter, while the muscles that make up the tongue are governed more by hydraulics—the tongue is largely composed of a fixed volume of muscular tissue, so moving one part of the tongue changes its shape elsewhere. The physics governing the movements of such muscles is totally different from that of the biceps or hamstrings.
</p><p>
	Because there are so many muscles involved and they each have so many degrees of freedom, there’s essentially an infinite number of possible configurations. But when people speak, it turns out they use a relatively small set of core movements (which differ somewhat in different languages). For example, when English speakers make the “d” sound, they put their tongues behind their teeth; when they make the “k” sound, the backs of their tongues go up to touch the ceiling of the back of the mouth. Few people are conscious of the precise, complex, and coordinated muscle actions required to say the simplest word.
</p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="A man looks at two large display screens; one is covered in squiggly lines, the other shows text.\u00a0" class="rm-shortcode" data-rm-shortcode-id="cff1723a7666c03132d4cc94943f4e92" data-rm-shortcode-name="rebelmouse-image" id="ef273" loading="lazy" src="https://spectrum.ieee.org/media-library/a-man-looks-at-two-large-display-screens-one-is-covered-in-squiggly-lines-the-other-shows-text-u00a0.png?id=32001182&width=980"/>
<small class="image-media media-caption" placeholder="Add Photo Caption...">Team member David Moses looks at a readout of the patient’s brain waves [left screen] and a display of the decoding system’s activity [right screen].</small>
<small class="image-media media-photo-credit" placeholder="Add Photo Credit...">University of California, San Francisco</small></p><p>
	My research group focuses on the parts of the brain’s motor cortex that send movement commands to the muscles of the face, throat, mouth, and tongue. Those brain regions are multitaskers: They manage muscle movements that produce speech and also the movements of those same muscles for swallowing, smiling, and kissing.
</p><p>
	Studying the neural activity of those regions in a useful way requires both spatial resolution on the scale of millimeters and temporal resolution on the scale of milliseconds. Historically, noninvasive imaging systems have been able to provide one or the other, but not both. When we started this research, we found remarkably little data on how brain activity patterns were associated with even the simplest components of speech: phonemes and syllables.
</p><p>
	Here we owe a debt of gratitude to our volunteers. At the UCSF epilepsy center, patients preparing for surgery typically have electrodes surgically placed over the surfaces of their brains for several days so we can map the regions involved when they have seizures. During those few days of wired-up downtime, many patients volunteer for neurological research experiments that make use of the electrode recordings from their brains. My group asked patients to let us study their patterns of neural activity while they spoke words.
</p><p>
	The hardware involved is called 
	<a href="https://en.wikipedia.org/wiki/Electrocorticography" target="_blank">electrocorticography</a> (ECoG). The electrodes in an ECoG system don’t penetrate the brain but lie on the surface of it. Our arrays can contain several hundred electrode sensors, each of which records from thousands of neurons. So far, we’ve used an array with 256 channels. Our goal in those early studies was to discover the patterns of cortical activity when people speak simple syllables. We asked volunteers to say specific sounds and words while we recorded their neural patterns and tracked the movements of their tongues and mouths. Sometimes we did so by having them wear colored face paint and using a computer-vision system to extract the kinematic gestures; other times we used an ultrasound machine positioned under the patients’ jaws to image their moving tongues.
</p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="A diagram shows a man in a wheelchair facing a screen that displays two lines of dialogue: \u201cHow are you today?\u201d and \u201cI am very good.\u201d Wires connect a piece of hardware on top of the man\u2019s head to a computer system, and also connect the computer system to the display screen. A close-up of the man\u2019s head shows a strip of electrodes on his brain." class="rm-shortcode" data-rm-shortcode-id="d278d132f84073773405b4318e67f3ed" data-rm-shortcode-name="rebelmouse-image" id="3689a" loading="lazy" src="https://spectrum.ieee.org/media-library/a-diagram-shows-a-man-in-a-wheelchair-facing-a-screen-that-displays-two-lines-of-dialogue-u201chow-are-you-today-u201d-and-u.png?id=32001118&width=980"/>
<small class="image-media media-caption" placeholder="Add Photo Caption...">The system starts with a flexible electrode array that’s draped over the patient’s brain to pick up signals from the motor cortex. The array specifically captures movement commands intended for the patient’s vocal tract. A port affixed to the skull guides the wires that go to the computer system, which decodes the brain signals and translates them into the words that the patient wants to say. His answers then appear on the display screen.</small>
<small class="image-media media-photo-credit" placeholder="Add Photo Credit...">Chris Philpot</small></p><p>
	We used these systems to match neural patterns to movements of the vocal tract. At first we had a lot of questions about the neural code. One possibility was that neural activity encoded directions for particular muscles, and the brain essentially turned these muscles on and off as if pressing keys on a keyboard. Another idea was that the code determined the velocity of the muscle contractions. Yet another was that neural activity corresponded with coordinated patterns of muscle contractions used to produce a certain sound. (For example, to make the “aaah” sound, both the tongue and the jaw need to drop.) What we discovered was that there is a map of representations that controls different parts of the vocal tract, and that together the different brain areas combine in a coordinated manner to give rise to fluent speech.
</p><h2>The role of AI in today’s neurotech</h2><p>
	Our work depends on the advances in artificial intelligence over the past decade. We can feed the data we collected about both neural activity and the kinematics of speech into a neural network, then let the machine-learning algorithm find patterns in the associations between the two data sets. It was possible to make connections between neural activity and produced speech, and to use this model to produce computer-generated speech or text. But this technique couldn’t train an algorithm for paralyzed people because we’d lack half of the data: We’d have the neural patterns, but nothing about the corresponding muscle movements.
</p><p>
	The smarter way to use machine learning, we realized, was to break the problem into two steps. First, the decoder translates signals from the brain into intended movements of muscles in the vocal tract, then it translates those intended movements into synthesized speech or text.
</p><p>
	We call this a biomimetic approach because it copies biology; in the human body, neural activity is directly responsible for the vocal tract’s movements and is only indirectly responsible for the sounds produced. A big advantage of this approach comes in the training of the decoder for that second step of translating muscle movements into sounds. Because those relationships between vocal tract movements and sound are fairly universal, we were able to train the decoder on large data sets derived from people who weren’t paralyzed.
</p><h2>A clinical trial to test our speech neuroprosthetic</h2><p>
	The next big challenge was to bring the technology to the people who could really benefit from it.
</p><p>
	The National Institutes of Health (NIH) is funding 
	<a href="https://reporter.nih.gov/search/kfhqyDGlEk-BF89Lei3E3w/project-details/10113331" target="_blank">our pilot trial</a>, which began in 2021. We already have two paralyzed volunteers with implanted ECoG arrays, and we hope to enroll more in the coming years. The primary goal is to improve their communication, and we’re measuring performance in terms of words per minute. An average adult typing on a full keyboard can type 40 words per minute, with the fastest typists reaching speeds of more than 80 words per minute.
</p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="A man in surgical scrubs and wearing a magnifying lens on his glasses looks at a screen showing images of a brain.\u00a0" class="rm-shortcode" data-rm-shortcode-id="84af6259f58fc96ea52ef1660e994a3c" data-rm-shortcode-name="rebelmouse-image" id="37775" loading="lazy" src="https://spectrum.ieee.org/media-library/a-man-in-surgical-scrubs-and-wearing-a-magnifying-lens-on-his-glasses-looks-at-a-screen-showing-images-of-a-brain-u00a0.png?id=32001077&width=980"/>
<small class="image-media media-caption" placeholder="Add Photo Caption...">Edward Chang was inspired to develop a brain-to-speech system by the patients he encountered in his neurosurgery practice. </small>
<small class="image-media media-photo-credit" placeholder="Add Photo Credit...">Barbara Ries</small></p><p>
	We think that tapping into the speech system can provide even better results. Human speech is much faster than typing: An English speaker can easily say 150 words in a minute. We’d like to enable paralyzed people to communicate at a rate of 100 words per minute. We have a lot of work to do to reach that goal, but we think our approach makes it a feasible target.
</p><p>
	The implant procedure is routine. First the surgeon removes a small portion of the skull; next, the flexible ECoG array is gently placed across the surface of the cortex. Then a small port is fixed to the skull bone and exits through a separate opening in the scalp. We currently need that port, which attaches to external wires to transmit data from the electrodes, but we hope to make the system wireless in the future.
</p><p>
	We’ve considered using penetrating microelectrodes, because they can record from smaller neural populations and may therefore provide more detail about neural activity. But the current hardware isn’t as robust and safe as ECoG for clinical applications, especially over many years.
</p><p>
	Another consideration is that penetrating electrodes typically require daily recalibration to turn the neural signals into clear commands, and research on neural devices has shown that speed of setup and performance reliability are key to getting people to use the technology. That’s why we’ve prioritized stability in 
	<a href="https://www.nature.com/articles/s41587-020-0662-5" rel="noopener noreferrer" target="_blank">creating a “plug and play” system</a> for long-term use. We conducted a study looking at the variability of a volunteer’s neural signals over time and found that the decoder performed better if it used data patterns across multiple sessions and multiple days. In machine-learning terms, we say that the decoder’s “weights” carried over, creating consolidated neural signals.
</p><p class="shortcode-media shortcode-media-youtube">
<span class="rm-shortcode" data-rm-shortcode-id="d4c17701550c87cb08654854e1344975" style="display:block;position:relative;padding-top:56.25%;"><iframe frameborder="0" height="auto" lazy-loadable="true" scrolling="no" src="https://www.youtube.com/embed/AfX-fH3A6Bs?rel=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" width="100%"></iframe></span>
<small class="image-media media-photo-credit" placeholder="Add Photo Credit...">University of California, San Francisco</small></p><p>
	Because our paralyzed volunteers can’t speak while we watch their brain patterns, we asked our first volunteer to try two different approaches. He started with a list of 50 words that are handy for daily life, such as “hungry,” “thirsty,” “please,” “help,” and “computer.” During 48 sessions over several months, we sometimes asked him to just imagine saying each of the words on the list, and sometimes asked him to overtly 
	<em>try</em> to say them. We found that attempts to speak generated clearer brain signals and were sufficient to train the decoding algorithm. Then the volunteer could use those words from the list to generate sentences of his own choosing, such as “No I am not thirsty.”
</p><p>
	We’re now pushing to expand to a broader vocabulary. To make that work, we need to continue to improve the current algorithms and interfaces, but I am confident those improvements will happen in the coming months and years. Now that the proof of principle has been established, the goal is optimization. We can focus on making our system faster, more accurate, and—most important— safer and more reliable. Things should move quickly now.
</p><p>
	Probably the biggest breakthroughs will come if we can get a better understanding of the brain systems we’re trying to decode, and how paralysis alters their activity. We’ve come to realize that the neural patterns of a paralyzed person who can’t send commands to the muscles of their vocal tract are very different from those of an epilepsy patient who can. We’re attempting an ambitious feat of BMI engineering while there is still lots to learn about the underlying neuroscience. We believe it will all come together to give our patients their voices back. <span class="ieee-end-mark"></span>
</p>]]></description><pubDate>Sat, 29 Oct 2022 15:00:03 +0000</pubDate><guid>https://spectrum.ieee.org/brain-computer-interface-speech</guid><category>Neuroprosthetics</category><category>Brain-machine interface</category><category>Neurotechnology</category><category>Brain implants</category><category>Speech</category><dc:creator>Edward Chang</dc:creator><media:content medium="image" type="image/png" url="https://spectrum.ieee.org/media-library/a-man-using-an-interface-looking-at-a-screen-with-words-on-it.png?id=32005613&amp;width=980"></media:content></item><item><title>This AI Watches You Walk to Diagnose Parkinson’s, MS</title><link>https://spectrum.ieee.org/ai-diagnostics</link><description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/illustration-of-someone-walking-on-a-treadmill-like-object-with-a-front-camera-that-maps-to-different-parts-of-their-legs.jpg?id=32008886&width=1245&height=700&coordinates=0%2C351%2C0%2C351"/><br/><br/><p><em>This article is part of our exclusive <a href="https://spectrum.ieee.org/collections/journal-watch/" rel="noopener noreferrer" target="_self">IEEE Journal Watch series</a> in partnership with IEEE Xplore.</em></p><p><em></em>When it’s suspected that a person may have a certain neurological disorder, such as multiple sclerosis or Parkinson’s disease, doctors will often assess the person’s ability to walk. Simply by looking at someone’s gait, clues may emerge about an underlying neurological disorder.</p><p>In a recent study, a team of researchers at the University of Illinois explored a technique using standard video cameras combined with AI that can assess a person’s gait and identify those who may have Parkinson’s disease or MS. The results, which show the approach can reach accuracies as high as 79 percent, were <a href="https://ieeexplore.ieee.org/document/9896159" target="_blank">published</a> on 20 September in the <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6221020" rel="noopener noreferrer" target="_blank"><em>IEEE Journal of Biomedical and Health Informatics</em></a><u><em>.</em></u> </p><p>Neurological disorders can often cause subtle changes in a person’s gait, even during the early-to-mid stages of disease. Often health care professionals will use specialized equipment such as a lab-based motion-capture system, force plates, or electromyography sensors to assess a person’s gait for neurological abnormalities, which can be expensive and require skilled personnel to analyze the results. </p><p>“The integration of video of people walking and AI may allow for a wider range of health care providers in rural or underserved communities to identify early gait changes from neurological conditions and more efficiently provide a potential diagnosis,” explains Manuel Enrique Hernandez, an assistant professor in the <a href="https://ahs.illinois.edu/kch-home" target="_blank">Department of Kinesiology and Community Health at the University of Illinois at Urbana-Champaign</a>. </p><p class="pull-quote">“Properly developed, this could be a game changer.”  <em>—</em>Richard Sowers</p><p>In their study, Hernandez and his colleagues recruited a total of 33 volunteers—10 with MS, 9 with Parkinson’s disease, and 14 who did not have any neurological disease. All of the volunteers were asked to walk on a treadmill while two standard RGB cameras recorded their movements from side and front angles. </p><p>“We looked at the body coordinates for hips, knees, ankles, the big and small toes and the heels,” explains Rachneet Kaur, a Ph.D. student at the University of Illinois who was involved in the research. “We analyzed how these coordinates moved over time to look for differences between adults with and without MS or Parkinson’s disease.”</p><p>In total, the researchers developed and validated 16 different AI algorithms to assess these gait movements. Several of the algorithms were more than 75 percent accurate in predicting a person’s neurological status, with the top-performing algorithm—a convolutional deep-learning model—achieving 79 percent of accuracy. </p><p>“We were pleasantly surprised with the validation results of using somewhat inexpensive video equipment and open-source image processing software to get the performance we saw,” says Richard Sowers, a professor in the departments of Mathematics and of Industrial and Enterprise Systems Engineering at Urbana-Champaign who was also involved in the study. “Properly developed, this could be a game changer.”</p><p>Although commercialization of such an approach is still a few years away, the team says they have made their work <a href="https://github.com/kaurrachneet6/VGA4MS.git" rel="noopener noreferrer" target="_blank">available for free online</a> for other researchers to use. In future work, they hope to explore how the inclusion of people with other neurological disorders could improve the accuracy of this approach. They also hope to experiment with the number and positioning of the cameras.<strong></strong></p>]]></description><pubDate>Thu, 27 Oct 2022 18:10:12 +0000</pubDate><guid>https://spectrum.ieee.org/ai-diagnostics</guid><category>Artificial intelligence</category><category>Neurology</category><category>Journal watch</category><category>Diagnostics</category><dc:creator>Michelle Hampson</dc:creator><media:content medium="image" type="image/jpeg" url="https://spectrum.ieee.org/media-library/illustration-of-someone-walking-on-a-treadmill-like-object-with-a-front-camera-that-maps-to-different-parts-of-their-legs.jpg?id=32008886&amp;width=980"></media:content></item><item><title>Pong-in-a-Dish</title><link>https://spectrum.ieee.org/pong-in-a-dish</link><description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/a-grid-with-colorful-blocks-that-look-like-lights-and-columns-a-box-shows-control-panels-and-another-shows-a-visualizer-of-the.jpg?id=31994756&width=1245&height=700&coordinates=0%2C61%2C0%2C62"/><br/><br/><p>Ever hear of the <a href="https://spectrum.ieee.org/untold-history-of-ai-charles-babbage-and-the-turk" target="_self">Turk</a>—the 19th<sup></sup>-century mechanism topped by a turbaned head that played chess against all comers? In fact, hidden inside was a diminutive chessmaster, one you might imagine deadpanning, “<a href="https://www.youtube.com/watch?v=pyxJ7GKGFG0" rel="noopener noreferrer" target="_blank">Eh, It’s a living.</a>”</p><p>Then there’s its namesake, the <a href="https://spectrum.ieee.org/untold-history-of-ai-mechanical-turk-revisited-tktkt" target="_self">Mechanical Turk</a>—a 21st<sup></sup>-century service offered by Amazon to mark up images on the Web with the help of crowdsourced freelancers. They, too, might intone, glassy-eyed, “It’s a living.”</p><p>Now we have a kind of Biological Turk. A mass of neurons act as a computer that mimics a human being playing the classic computer game Pong. The neurons, some taken from mouse embryos, others grown from human precursor cells, spread out into a one-layer, 800,000-cell mesh called a biological neural network, which lives in a giant petri dish called the DishBrain. There it interfaces with arrays of electrodes that form an interface to silicon hardware. Software mounted on that hardware provides stimulation and feedback, and the minibrain learns how to control a paddle on a simulated ping-pong table.</p><p>The work was described recently in the journal <a href="https://www.cell.com/neuron/fulltext/S0896-6273(22)00806-6#%20" rel="noopener noreferrer" target="_blank"><em>Neuron</em></a> by Brett Kagan, the chief scientific officer of <a href="https://corticallabs.com/" rel="noopener noreferrer" target="_blank">Cortical Labs</a>, a startup in Melbourne, Australia, and nine colleagues at that company.</p><p>The authors talk hopefully about the emergence of sentience, a notion that other brain-in-a-dish researchers have also <a href="https://www.nature.com/articles/d41586-020-02986-y" rel="noopener noreferrer" target="_blank">recently floated</a>. But they seem to stand on solid ground when they say their method will help to advance brain science, on the one hand, and computer science, on the other. A bio-neuro-network might model the effects of drugs on the brain in ways that single-cell neurons can’t. Also, neurons may show themselves to be more than just protoplasmic logic switches but more like entire computers.</p><p>The question before us, though, is how does the thing play Pong?</p><p class="shortcode-media shortcode-media-youtube">
<span class="rm-shortcode" data-rm-shortcode-id="0d57b1d55d16d51cf831540a01c2f883" style="display:block;position:relative;padding-top:56.25%;"><iframe frameborder="0" height="auto" lazy-loadable="true" scrolling="no" src="https://www.youtube.com/embed/GJaXiR_uvVI?rel=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" width="100%"></iframe></span>
<small class="image-media media-caption" placeholder="Add Photo Caption...">Pong-in-a-Dish</small>
<small class="image-media media-photo-credit" placeholder="Add Photo Credit...">
<a href="https://youtu.be/GJaXiR_uvVI" target="_blank">youtu.be</a>
</small>
</p><p>First, the electronic scaffolding hits the minibrain with electrical signals that represent the position and movement of the virtual ball. It’s rather like the action potential that a firing neuron would use to convey, say, a sensory signal from the eye to the brain. Because the electrodes are placed at different points in the cell network, the system physically represents the different possible locations. Further information comes from the frequency of the signals, which varies with the distance of the ball to the virtual paddle.<br/></p><p>The network responds to these stimuli like a motor neuron, sending out a signal that moves the virtual paddle. If the resulting movement causes the ball to bounce, the neural network gets a “reward.” Failure results in a signal that has the opposite effect.<span></span></p><p>“Reward” is put in sneer quotes because these cells don’t have feelings. They can’t experience the joy of victory, the agony of defeat. There’s no dopamine, no salted popcorn. Instead, the researchers say, the network is working to minimize unpredictability. In this view, the so-called reward is a predictable signal, the anti-reward is an unpredictable one.</p><p>Kagan tells <em>IEEE Spectrum</em> that the system as a whole then reorganizes to become better at playing the game. The most marked improvement came in the first five minutes of play.</p><p>It seems amazing that a mere 800,000 neurons can model the world, even a simplified world. But, Kagan says, such feats are seen in nature. "Flies have even fewer neurons but must be able to do some modeling—although perhaps not in a way a human may—to navigate a complex and changing 3D world," he says.</p><p>As he and his colleagues point out in their report the ability of neurons to adapt to external stimuli is well established <em>in vivo</em>; it forms the basis for all animal learning. But theirs, they say, is the first <em>in vitro </em>demonstration involving a goal-directed behavior. </p><p>The current version of Pong is forgiving. The paddle is broad, the volley slow, the ball unspinning. Even a neophyte would crush DishBrain. Then again, the same was true of all of AI’s early assays in game playing.</p><p>The early chess machines would sometimes senselessly give up first a pawn, then a piece, then the queen—all because they were attempting to put off a disagreeable action to a point beyond the built-in <a href="https://spectrum.ieee.org/cars-may-think-but-will-they-achieve-artificial-stupidity" target="_self">planning horizon</a>. Poker-playing programs <a href="https://spectrum.ieee.org/poker-pros-battle-artificial-intelligence-to-statistical-draw" target="_self">got good</a> pretty fast, but the early ones sometimes played too well—that is, too cautiously—against weak human opponents, which reduced their winnings. Car navigation programs would send you into a vacant lot.</p><p>You might think that just getting a machine to play a decent game is the hard part, and that further improving it to perfection ought to be a snap. Edgar Allan Poe made that judgement when he called the Turk a fraud because it occasionally erred. His conclusion was correct but his reasoning was faulty.</p><p>It’s not easy turning a barely there machine into a world champion at chess or <a href="https://spectrum.ieee.org/alphago-wins-match-against-top-go-player" target="_self">Go</a>. And yet it has been done.</p>]]></description><pubDate>Sat, 22 Oct 2022 14:09:13 +0000</pubDate><guid>https://spectrum.ieee.org/pong-in-a-dish</guid><category>Neuroscience</category><category>Brain computer interface</category><category>Video games</category><category>Pong</category><category>Neurons</category><category>Biological neural networks</category><dc:creator>Philip E. Ross</dc:creator><media:content medium="image" type="image/jpeg" url="https://spectrum.ieee.org/media-library/a-grid-with-colorful-blocks-that-look-like-lights-and-columns-a-box-shows-control-panels-and-another-shows-a-visualizer-of-the.jpg?id=31994756&amp;width=980"></media:content></item><item><title>Deep-Brain Stimulator Draws Power From Breath</title><link>https://spectrum.ieee.org/deep-brain-stimulation-no-battery</link><description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/neon-colored-outline-of-person-and-lungs-against-a-dark-checked-background.jpg?id=31988426&width=1245&height=700&coordinates=0%2C234%2C0%2C235"/><br/><br/><p>A new experimental, batteryless, surgically implanted brain device for chronic conditions and neurodegenerative disorders is bolstering hopes in the eternal quest for maximally effective but minimally invasive treatments. </p><p><a href="https://spectrum.ieee.org/what-is-neural-implant-neuromodulation-brain-implants-electroceuticals-neuralink-definition-examples" target="_self">Neural implants</a> that electrically stimulate tissue deep in the brain are used today to treat Parkinson’s disease and epilepsy. Researchers have also shown recently that <a href="https://spectrum.ieee.org/how-to-treat-psychiatric-disorders-with-brain-stimulation" target="_self">deep-brain simulation can be used to treat mental disorders</a> such as addiction, depression, obsessive-compulsive disorder, and post-traumatic stress disorder.<br/></p><p>The batteries that power these deep-brain stimulation (DBS) implants last for about three years. However, surgery to replace the bulky batteries can add cost and increase the risk of infection. To get around that problem, researchers have made a DBS system that powers itself by harvesting and storing energy from the motion of breathing lungs. </p><p>“Deep-brain stimulators are energy monsters so the battery runs out very quickly,” says <a href="https://soeprofed.uconn.edu/meet-islam-mosa/" target="_blank">Islam Mosa</a>, a chemist and chief technology officer of University of Connecticut spinoff <a href="https://www.linkedin.com/company/voltxon" target="_blank">VoltXon</a>, which is commercializing the system reported in the journal <em><a href="https://www.sciencedirect.com/science/article/pii/S2666386422004015" rel="noopener noreferrer" target="_blank">Cell Reports Physical Science</a></em>. “We have created the first self-sustainable and battery-free deep-brain stimulating device.”</p><p>Deep-brain stimulation uses electrodes surgically implanted in the deep interior part of the brain to send electrical impulses at varying frequencies via electrodes. A pulse generator placed under the skin just below the collarbone fires the electrodes through a wire under the skin that runs up the neck to the skull.</p><p>Those electrical pulses have to be delivered to the brain in a controlled manner. <a href="https://scholar.google.com/scholar?hl=en&as_sdt=0%2C22&q=make+battery-free+DBS+systems+&btnG=" target="_blank">Past efforts to make battery-free DBS systems</a> that rely on harvesting the body’s mechanical energy have either not been able to deliver pulses with controlled frequency or haven’t generated enough power to trigger the electrodes. </p><p>Mosa, UConn chemistry professor James Rusling, and their colleagues developed a new type of <a href="https://spectrum.ieee.org/tag/triboelectric-nanogenerators" target="_blank">triboelectric nanogenerator (TENG)</a> to harvest energy from lung movements, and a <a href="https://spectrum.ieee.org/tag/supercapacitors" target="_blank">supercapacitor</a> to store that energy. Both devices are superthin and flexible. </p><p><a href="https://spectrum.ieee.org/yarnlike-rechargeable-zinc-battery-could-power-smart-clothes-and-wearables" target="_self">TENGs</a> rely on the buildup of electrical charge when repeated movements cause their two electrodes, made of <a href="https://spectrum.ieee.org/nanogenerators-could-charge-your-smartphone" target="_self">dissimilar materials</a>, to separate and come together. They have been demonstrated to generate power from <a href="https://spectrum.ieee.org/flexible-nanogenerators-offer-dependable-energy-source-for-flexible-electronics" target="_self">footsteps</a>, <a href="https://spectrum.ieee.org/skinbased-generators-scavenge-muscle-motion-to-power-wearables" target="_self">muscle motion</a>, and <a href="https://spectrum.ieee.org/solar-and-wind-energy-from-the-same-device" target="_self">wind</a>, among other things, but have yet to be commercialized on a large scale.</p><p>The new TENG relies on the contact and separation of films made of two different plastics. But the researchers also added an extra “biographene” layer—which they make by coating a carbon microfiber fabric with graphene flakes and a protein. This biographene serves as an additional TENG, Mosa says, because of the relative movement between the carbon materials and protein, boosting the energy produced by the TENG. The entire device is the thickness of paper, and a 4- by 5-centimeter device generates 6.9 microwatts for each contact-separation cycle.</p><p>That energy is stored in the supercapacitor, which the researchers make by sandwiching a gel electrolyte between two biographene electrodes. Once the supercapacitor is charged up, it powers the pulse generator to fire the implanted electrode. </p><p>For practical use, the TENG wouldn’t be placed on delicate lung tissue, but attached to the inside of the rib cage, he says. The lungs would then press and release the device every time a person breathes in and out.</p><p>The researchers tested their system <em>ex vivo</em> for now, with the TENG placed on a model rib cage with actual pig lungs that were inflated and deflated using a pump, and the biosupercapacitor connected to electrodes that stimulated mouse brain tissue in a petri dish. </p><p>While commercial DBS systems electrically stimulate the brain continually, delivering 60 to 180 pulses per second, the new system is meant for intermittent DBS. Research has recently shown that intermittent stimulation might be more effective in conditions such as Alzheimer’s disease, memory, depression, and PTSD, Mosa says. </p><p>“Next we plan to do a long-term in vivo study,” he says.</p>]]></description><pubDate>Fri, 21 Oct 2022 17:29:55 +0000</pubDate><guid>https://spectrum.ieee.org/deep-brain-stimulation-no-battery</guid><category>Triboelectric nanogenerators</category><category>Supercapacitors</category><category>Parkinson's disease</category><category>Addiction</category><category>Depression</category><category>Electrical stimulation</category><category>Deep brain stimulation</category><category>Triboelectricity</category><dc:creator>Prachi Patel</dc:creator><media:content medium="image" type="image/jpeg" url="https://spectrum.ieee.org/media-library/neon-colored-outline-of-person-and-lungs-against-a-dark-checked-background.jpg?id=31988426&amp;width=980"></media:content></item><item><title>Robopill Drills Through Mucus to Deliver Drugs</title><link>https://spectrum.ieee.org/swallowable-robotic-pills</link><description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/image.jpg?id=31957157&width=1245&height=700&coordinates=0%2C174%2C0%2C174"/><br/><br/><p>Mucus plays a key role in protecting the body from harm, preventing potentially dangerous substances from reaching the gastrointestinal system. But it also makes it virtually impossible to give certain medications orally, including insulin. That means people with diabetes must regularly inject insulin, which is unpleasant and can cause people with diabetes to be inconsistent in taking their medication. </p><p>Researchers at MIT wanted to come up with a way around this problem, so they invented a robotic pill, called RoboCap, which can tunnel like a drill through the mucus protecting the GI tract. In a study published in <a href="https://www.science.org/doi/10.1126/scirobotics.abp9066" target="_blank"><em>Science Robotics</em></a>, they tested the invention in pigs, finding that it was effective at getting the pigs’ bodies to absorb medications, including insulin and an IV antibiotic. Though the research is preliminary, it could one day make treatment of many medical conditions easier and more convenient.<br/></p><hr/><p>“The results that we’re seeing are able to be applied to any drug,” said <a href="https://www.media.mit.edu/people/shriyas/overview/" target="_blank">Shriya Srinivasan</a>, a postdoctoral researcher at MIT’s Koch Institute for Integrative Cancer Research and junior fellow at the Society of Fellows at Harvard University. Srinivasan is the lead author of the <em>Science Robotics</em> paper. </p><h2>How RoboCap Works</h2><p>RoboCap has several parts that allow it to get to the right place and to penetrate mucus. The entire pill is coated with a gelatinous substance that responds to pH, allowing easy swallowing and activation only upon reaching the small intestine. Once there, the coating dissolves, closing the pill’s circuit and triggering its mechanical components. On one side of the pill is a weight  attached to an internal motor, which makes the pill start to vibrate and spin as the motor is activated. RoboCap begins drilling through the mucus that lines the small intestine, eventually depositing its drug load, which is on the other side of the pill.</p><p>To effectively drill through the mucus, the pill uses surface features like spiral turbine fins, inspired by torpedo fins, and helical grooves. It’s also coated with small studs to help “brush” mucus aside, similar to how a toothbrush works. Srinivasan said she was also inspired by online videos of tunnel-boring machines called moles, which push through rock and dirt to drill narrow channels. </p><p>The researchers tested their invention with two different drugs: insulin and vancomycin, an IV antibiotic. They tested the method on a resected portion of a pig’s small intestine.  This allowed them to measure how much of the drug they injected above the mucous layer got through to the other side. They also tested RoboCap on live pigs, in both instances comparing the RoboCap to sham, or control pills, which didn’t have a drilling mechanism.</p><p>“When we look at it, it’s anywhere between a 20-to-40-fold increase in the amount of drug that actually is reaching the bloodstream, when you compare [the control] to RoboCap,” said Srinivasan. </p><h2>Potential Applications</h2><p>After making its drug delivery, RoboCap moves through the digestive system and out of the body on its own. The researchers found no evidence that the pill caused any damage to the pigs’ GI system, and frequent mucus production meant that the drilling action had no lasting impact on infection risk or the body’s ability to protect itself. </p><p>Both the study and the technology have limitations, said Srinivasan. It’s unclear how to dispose of RoboCap once it’s out of the body. The study also did not examine medication dosing, or how the drug would be loaded into the pill. The study also only compared the release of drugs administered orally; it did not compare, for instance, how much insulin gets into the bloodstream when delivered with RoboCap versus insulin injection, as it normally would be. The invention is also a long way from being used in people; it would have to undergo extensive development so that it could be mass-produced and would need to go through the clinical trial process. </p><p>Using mechanical methods like this has many advantages over approaches that use chemical methods to accomplish oral drug delivery for the drugs where that ingestion path is indicated. But just because the approach could be used with a variety of drugs doesn’t mean it would necessarily be practical. </p><p>“I think some of the political and societal pressures right now on insulin pricing maybe make it such that this particular mode of delivery would always kind of make it too expensive,” said <a href="https://engineering.nd.edu/faculty/matthew-webber/" rel="noopener noreferrer" target="_blank">Matthew Webber</a>, a professor of chemical and biomolecular engineering department at the University of Notre Dame. </p><p>Webber does see the approach being potentially useful for other drugs, such as antibody therapies for cancer, which usually have to be given through an IV in the hospital. Regardless of the drug’s possibilities for oral drug delivery, Webber says the idea is an innovative one.</p><p>“The science on it is supercool,” he said. “I think there’s a lot of…really intricate and detailed engineering that goes into making something like this.” </p>]]></description><pubDate>Tue, 18 Oct 2022 14:00:00 +0000</pubDate><guid>https://spectrum.ieee.org/swallowable-robotic-pills</guid><category>Robopill</category><category>Biomedical electronics</category><category>Biomedical engineering</category><category>Mit</category><dc:creator>Rebecca Sohn</dc:creator><media:content medium="image" type="image/jpeg" url="https://spectrum.ieee.org/media-library/image.jpg?id=31957157&amp;width=980"></media:content></item><item><title>With This Bionic Nose, COVID Survivors May Smell the Roses Again</title><link>https://spectrum.ieee.org/covid-smell-prosthetic</link><description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/two-scientists-in-white-lab-coats-look-at-a-mannequin-head-thats-wearing-a-pair-of-black-glasses-with-wires-sticking-out-from-s.png?id=31947210&width=1245&height=700&coordinates=0%2C42%2C0%2C172"/><br/><br/><p>
<strong>Richard Costanzo stands</strong> beside a mannequin head sporting spectacles decked with electronics and holds a vial of blue liquid up to a tiny sensor. An LED glows blue, and Costanzo’s phone displays the word “Windex.” Then he waves a vial of purple liquid and gets a purple light along with the message “Listerine.”
</p><p>
	“There won’t be Scotch tape on the final model,” says 
	<a href="https://medschool.vcu.edu/about/portfolio/detail.html?id=rcostanz" rel="noopener noreferrer" target="_blank">Costanzo</a>, as he rearranges the gear in his lab at <a href="https://www.vcu.edu/" rel="noopener noreferrer" target="_blank">Virginia Commonwealth University</a> (VCU), in Richmond. The prototype is a partial demonstration of a concept that he’s been working on for decades: a neuroprosthetic for smell. The mannequin represents someone who has lost their sense of smell to <a href="https://spectrum.ieee.org/tag/covid-19" target="_blank">COVID-19</a>, brain injury, or some other medical condition. It is also intended to show off the sensor, which is the same type used for commercial electronic noses, or 
	<a href="https://en.wikipedia.org/wiki/Electronic_nose" target="_blank">e-noses</a>. In the final product, the sensor won’t light up an LED but will instead send a signal to the user’s brain.
</p><p>
	In the lab’s back room, another model shows the second half of the concept: There, the e-nose sensor transmits its signal to a small array of electrodes taken from a 
	<a href="https://en.wikipedia.org/wiki/Cochlear_implant" rel="noopener noreferrer" target="_blank">cochlear implant</a>. For people with hearing loss, such implants feed information about sound to the inner ear and then to the brain. The implant is also about the right size for the olfactory bulb on the edge of the brain. Why not use it to convey information about odor?
</p><div class="rm-embed embed-media"><div class="flourish-embed flourish-interactive diagram" data-src="visualisation/11477812?602891">
<script src="https://public.flourish.studio/resources/embed.js"> </script>
</div></div><p>
	This project could be a career-capping achievement for 
	Costanzo, a professor emeritus of physiology and biophysics who in the 1980s cofounded VCU’s 
	<a href="https://ent.vcu.edu/specialties/smell-and-taste-disorders-center/" target="_blank">Smell and Taste Disorders Center,</a> one of the first such clinics in the country. After years of research on olfactory loss and investigations into the possibility of biological regeneration, he began working on a hardware solution in the 1990s.<br/>
</p><p>
	A self-described electronics buff, Costanzo enjoyed his experiments with sensors and electrodes. But the project really took off in 2011 when he began talking with his colleague 
	<a href="https://www.vcuhealth.org/find-a-provider/daniel-coelho" target="_blank">Daniel Coelho</a>, a professor of otolaryngology at VCU and an expert in cochlear implants. They recognized at once that a smell prosthetic could be similar to a cochlear implant: “It’s taking something from the physical world and translating it into electrical signals that strategically target the brain,” Coelho says. In 2016 the two researchers were awarded a U.S. patent for their <a href="https://patents.google.com/patent/US9517342B2/fr" target="_blank">olfactory-implant system</a>.
</p><div class="rm-embed embed-media"><div class="flourish-embed flourish-interactive diagram" data-src="visualisation/11478179?602891">
<script src="https://public.flourish.studio/resources/embed.js"> </script>
</div></div><p>
	Costanzo’s quest became abruptly more relevant in early 2020, when many patients with a new illness called COVID-19 realized they had lost their senses of smell and taste. Three years into the pandemic, some of those patients have still not recovered those faculties. When you also consider people who have lost their sense of smell due to other diseases, brain injury, and aging, this niche technology starts to look like a viable product. Add in Costanzo and Coelho’s other collaborators—including an electronic nose expert in England, several clinicians in Boston, and a businessman in Indiana—and you have a dream team who just might make it happen.
</p><p>
	Costanzo says he’s wary of hype and doesn’t want to give people the impression that a commercial device will be available any day now. But he does want to offer hope. Right now, the team is focused on getting the sensors to detect more than a few odors and figuring out how best to interface with the brain. “I think we’re several years away from cracking those nuts,” Costanzo says, “but I think it’s doable.”
</p><h2>How people can lose their sense of smell</h2><p class="shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left" data-rm-resized-container="25%" style="float: left;">
<img alt="Headshot of a smiling man with a shaved head and blue checkered shirt." class="rm-shortcode rm-resized-image" data-rm-shortcode-id="f8b8779b7d571d9aae42016642fdd348" data-rm-shortcode-name="rebelmouse-image" id="d9892" loading="lazy" src="https://spectrum.ieee.org/media-library/headshot-of-a-smiling-man-with-a-shaved-head-and-blue-checkered-shirt.jpg?id=31947103&width=980" style="max-width: 100%"/>
<small class="image-media media-caption" placeholder="Add Photo Caption...">After Scott Moorehead lost his sense of smell after a head injury, he began supporting research on smell prosthetic technology.</small><small class="image-media media-photo-credit" placeholder="Add Photo Credit...">Round Room</small>
</p><p>
<strong><a href="https://www.linkedin.com/in/scott-moorehead-bb547b37/" rel="noopener noreferrer" target="_blank">Scott Moorehead</a> just</strong> <strong>wanted</strong> to teach his 6-year-old son how to skateboard. On a Sunday in 2012 he was demonstrating some moves in the driveway of his Indiana home when the skateboard hit a crack and flipped him off. “The back of my skull bore the brunt of the fall,” he says. He spent three days in the intensive care unit, where doctors treated him for multiple skull fractures, massive internal bleeding, and damage to his brain’s frontal lobe.
</p><p>
	Over weeks and months his hearing came back, his headaches went away, and his irritability and confusion faded. But he never regained his sense of smell.
</p><p>
	Moorehead’s accident permanently disconnected the nerves that run from the nose to the olfactory bulb at the base of the brain. Along with his sense of smell, he lost all but a rudimentary sense of taste. “Flavor comes mostly from smell,” he explains. “My tongue on its own can only do sweet, salty, spicy, and bitter. You can blindfold me and put 10 flavors of ice cream in front of me, and I won’t know the difference: They’ll all taste slightly sweet, except chocolate that’s a bit bitter.”
</p><p>
	Moorehead grew depressed: Even more than the flavors of food, he missed the unique smells of the people he loved. And on one occasion he was oblivious to a gas leak, only realizing the danger when his wife came home and raised the alarm.
</p><p>
<a href="https://en.wikipedia.org/wiki/Anosmia" target="_blank">Anosmia</a>, or the inability to smell, can be caused not only by head injuries but also by exposure to certain toxins and by a variety of medical problems—including tumors, Alzheimer’s, and viral diseases, such as COVID. The sense of smell also commonly atrophies with age; in <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5033684/" target="_blank">a 2012 study</a> in which more than 1,200 adults were given olfactory exams, 39 percent of participants age 80 and above had olfactory dysfunction.
</p><p>
	The loss of smell and taste have been dominant symptoms of COVID since the beginning of the pandemic. People with COVID-induced anosmia currently have only three options: Wait and see if the sense comes back on its own, ask for a steroid medication that reduces inflammation and may speed recovery, or begin 
	<a href="https://www.enthealth.org/be_ent_smart/smell-retraining-therapy/" target="_blank">smell rehab</a>, in which they expose themselves to a few familiar scents each day to encourage the restoration of the nose-brain nerves. Patients typically do best if they seek out medication and rehab within a few weeks of experiencing symptoms, before scar tissue builds up. But even then, these interventions don’t work for everyone.
</p><p>
	In April 2020, researchers at VCU’s smell and taste clinic launched a nationwide survey of adults who had been diagnosed with COVID to determine the prevalence and duration of smell-related symptoms. They’ve followed up with those people at regular intervals, and this past August they published results from people who were two years past their initial diagnosis. The 
	<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9375644/" target="_blank">findings</a> were striking: Thirty-eight percent reported a full recovery of smell and taste, 54 percent reported a partial recovery, and 7.5 percent reported no recovery at all. “It’s a serious quality of life issue,” says <a href="https://ent.vcu.edu/about/faculty/evan-reiter-md-facs.html" target="_blank">Evan Reiter</a>, director of the VCU clinic.
</p><p>
	While other researchers are investigating biological approaches, such as using stem cells to regenerate odor receptors and nerves, Costanzo believes the hardware approach is the only solution for people with total loss of smell. “When the pathways are really out of commission, you have to replace them with technology,” he says.
</p><p>
	Unlike most anosmics, Scott Moorehead didn’t give up when his doctors told him there was nothing he could do to recover his sense of smell. As the CEO of a 
	<a href="https://www.roundroom.com/" target="_blank">cellphone retail company</a> with stores in 43 states, he had the resources to invest in long-shot research. And when a colleague told him about the work at VCU, he got in touch and offered to help. Since 2015, Moorehead has put almost US $1 million into the research. He also licensed the technology from VCU and launched a startup called Sensory Restoration Technologies.
</p><p>
	When COVID struck, Moorehead saw an opportunity. Although they were far from having a product to advertise, he scrambled to put up a 
	<a href="https://www.sensoryrestorationtechnologies.com/" target="_blank">website</a> for the startup. He remembers saying: “People are losing their sense of smell. People need to know we exist!”
</p><h2>How the sense of smell works</h2><p>
<strong>Equivalent neuroprosthetics exist</strong> for other senses. Cochlear implants are the most successful neurotechnology to date, with 
	<a href="https://www.nidcd.nih.gov/health/cochlear-implants" target="_blank">more than 700,000 devices</a> implanted in ears around the world. Retina implants have been developed for blind people (though some bionic-vision systems <a href="https://spectrum.ieee.org/bionic-eye-obsolete" target="_self">have had commercial trouble</a>), and researchers are even working on restoring the sense of touch to people with <a href="https://spectrum.ieee.org/creating-a-prosthetic-hand-that-can-feel" target="_self">prosthetic limbs</a> and <a href="https://spectrum.ieee.org/brain-implants-and-wearables-let-paralyzed-people-move-again" target="_self">paralysis</a>. But smell and taste have long been considered too hard a challenge.
</p><p>
	To understand why, you need to understand the marvelous complexity of the human olfactory system. When the smell of a rose wafts up into your nasal cavity, the odor molecules bind to receptor neurons that send electrical signals up the olfactory nerves. Those nerves pass through a bony plate to reach the olfactory bulb, a small neural structure in the forebrain. From there, information goes to the amygdala, a part of the brain that governs emotional responses; the hippocampus, a structure involved in memory; and the frontal cortex, which handles cognitive processing.
</p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="An anatomical diagram shows a three-layered structure with olfactory receptors at the bottom, where they\u2019re binding with odorant molecules, a layer of bone in the middle, and a yellow shape representing the olfactory bulb at top. The olfactory receptor cells have long protrusions that go up through the bone to the olfactory bulb. " class="rm-shortcode" data-rm-shortcode-id="83b0f019d176fe2816b32842afdf775a" data-rm-shortcode-name="rebelmouse-image" id="9c310" loading="lazy" src="https://spectrum.ieee.org/media-library/an-anatomical-diagram-shows-a-three-layered-structure-with-olfactory-receptors-at-the-bottom-where-they-u2019re-binding-with-od.png?id=31947120&width=980"/>
<small class="image-media media-caption" placeholder="Add Photo Caption...">Odor molecules that enter the nose bind to olfactory receptor cells, which send signals through the bone of the cribriform plate to reach the olfactory bulb. From there, the signals are sent to the brain.</small><small class="image-media media-photo-credit" placeholder="Add Photo Credit...">James Archer/Anatomy Blue</small>
</p><p>
	Those branching neural connections are the reason that smells can sometimes hit with such force, conjuring up a happy memory or a traumatizing event. “The olfactory system has access to parts of the brain that other senses don’t,” Costanzo says. The diversity of brain connections, Coelho says, also suggests that stimulating the olfactory system could have other applications, going well beyond appreciating food or noticing a gas leak: “It could affect mood, memory, and cognition.”
</p><p>
	The biological system is difficult to replicate for a few reasons. A human nose has around 400 different types of receptors that detect odor molecules. Working together, those receptors enable humans to distinguish between a staggering number of smells: A 2014 study estimated the number at 
	<a href="https://www.science.org/doi/10.1126/science.1249168" target="_blank">1 trillion</a>. Until now, it hasn’t been practical to put 400 sensors on a chip that would be attached to a user’s eyeglasses. What’s more, researchers don’t yet fully understand the olfactory code by which stimulating certain combinations of receptors leads to perceptions of odor in the brain. Luckily, Costanzo and Coelho know people working on both of those problems.
</p><h2>Progress on e-noses and brain stimulation</h2><p>
<strong>E-noses are already</strong> <strong>used</strong> today in a variety of industrial, office, and residential settings—if you have a typical carbon-monoxide detector in your home, you have a very simple e-nose.
</p><p class="shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left" data-rm-resized-container="25%" style="float: left;">
<img alt="Headshot of a smiling man with glasses." class="rm-shortcode rm-resized-image" data-rm-shortcode-id="99c643d40df38e64646fd50aee0cca8a" data-rm-shortcode-name="rebelmouse-image" id="1ac78" loading="lazy" src="https://spectrum.ieee.org/media-library/headshot-of-a-smiling-man-with-glasses.jpg?id=31941916&width=980" style="max-width: 100%"/>
<small class="image-media media-caption" placeholder="Add Photo Caption...">Krishna Persaud is advising the Virginia Commonwealth University team on e-nose sensors.</small><small class="image-media media-photo-credit" placeholder="Add Photo Credit...">The University of Manchester</small>
</p><p>
	“Traditional gas sensors are based on semiconductors like metal oxides,” explains 
	<a href="https://www.research.manchester.ac.uk/portal/en/researchers/krishna-persaud(e1566e46-12eb-41ed-af14-937f42255f4e).html" target="_blank">Krishna Persaud</a>, a leading e-nose researcher and a professor of chemoreception at the University of Manchester, in England. He’s also an advisor to Costanzo and Coelho. In the most typical e-nose setup, he says, “when a molecule interacts with the semiconductor material, a change in resistance occurs that you can measure.” Such sensors have been shrinking over the last two decades, Persaud says, and they’re now the size of a microchip. “That makes them very convenient to put in a small package,” he says. In the VCU team’s early experiments, they used an off-the-shelf sensor from a Japanese company called <a href="https://www.figarosensor.com/product/" target="_blank">Figaro</a>.
</p><p>
	The problem with such commercially available sensors, Persaud says, is that they can’t distinguish between very many different odors. That’s why he’s been working with new materials, such as conductive polymers that are cheap to manufacture, low power, and can be grouped together in an array to provide sensitivity to dozens of odors. For the neuroprosthetic, “in principle, several hundred [sensors] could be feasible,” Persaud says.
</p><p>
	A first-generation product wouldn’t allow users to smell hundreds of different odors. Instead, the VCU team imagines initially including receptors for a few safety-related smells, such as smoke and natural gas, as well as a few pleasurable ones. They could even customize the prosthetic to give users smells that are meaningful to them: the smell of bread for a home baker, for example, or the smell of a pine forest for an avid hiker.
</p><p>
	Pairing this e-nose technology with the latest neurotechnology is Costanzo and Coelho’s current challenge. While working with Persaud to test new sensors, they’re also partnering with clinicians in Boston to investigate the best method of sending signals to the brain.
</p><p>
	The VCU team laid the groundwork with animal experiments. In experiments with rats in 
	<a href="https://pubmed.ncbi.nlm.nih.gov/27165674/" target="_blank">2016</a> and <a href="https://pubmed.ncbi.nlm.nih.gov/29719130/" target="_blank">2018</a>, the team showed that using electrodes to directly stimulate spots on the surface of the olfactory bulb generated patterns of neural activity deep in the bulb, in the neurons that passed messages on to other parts of the brain. The researchers called these patterns odor maps. But while the neural activity indicated that the rats were perceiving <em>something</em>, the rats couldn’t tell the researchers what they smelled.
</p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="A doctor stands over a patient seated in a chair and holds an endoscopy probe inside her nostril. On the wall, a screen shows the images that the probe is capturing." class="rm-shortcode" data-rm-shortcode-id="e27a14e2cab1a74dce003585a1ae29ce" data-rm-shortcode-name="rebelmouse-image" id="6683c" loading="lazy" src="https://spectrum.ieee.org/media-library/a-doctor-stands-over-a-patient-seated-in-a-chair-and-holds-an-endoscopy-probe-inside-her-nostril-on-the-wall-a-screen-shows-th.jpg?id=31941924&width=980"/>
<small class="image-media media-caption" placeholder="Add Photo Caption...">Eric Holbrook, an otolaryngologist, often works with patients who need surgeries in their sinus cavities. He has helped the VCU team with preliminary clinical experiments.</small><small class="image-media media-photo-credit" placeholder="Add Photo Credit...">Massachusetts Eye and Ear</small>
</p><p>
	Their next step was to recruit collaborators who could perform similar trials with human volunteers. They started with one of Costanzo’s former students, 
	<a href="https://doctors.masseyeandear.org/details/214/eric-holbrook-otolaryngology-boston" target="_blank">Eric Holbrook</a>, an associate professor of otolaryngology at Harvard Medical School and director of rhinology at <a href="https://www.masseyeandear.org/" target="_blank">Massachusetts Eye and Ear</a>. Holbrook spends much of his time operating on people’s <a href="https://en.wikipedia.org/wiki/Paranasal_sinuses" target="_blank">sinus cavities</a>, including the <a href="https://en.wikipedia.org/wiki/Ethmoid_sinus" target="_blank">ethmoid sinus cavities</a>, which are positioned just below the cribriform plate, a bony structure that separates the olfactory receptors from the olfactory bulb.
</p><p>
	Holbrook discovered, in 2018, that placing electrodes on the bone transmitted an electrical pulse to the olfactory bulb. In a trial with awake patients, three of the five volunteers 
	<a href="https://onlinelibrary.wiley.com/doi/full/10.1002/alr.22237" target="_blank">reported smell perception</a> during this stimulation, with the reported odors including “an onionlike smell,” “antiseptic-like and sour,” and “fruity but bad.” While Holbrook sees the trial as a good proof of concept for an olfactory-implant system, he says that poor conductance through the bone was an important limiting factor. “If we are to provide discrete, separate areas of stimulation,” he says, “it can’t be through bone and will need to be on the olfactory bulb itself.”
</p><p>
	Placing electrodes on the olfactory bulb would be new territory. “Theoretically,” says Coelho, “there are many different ways to get there.” Surgeons could go down through the brain, sideways through the eye socket, or up through the nasal cavity, breaking through the cribriform plate to reach the bulb. Coelho explains that rhinology surgeons often perform low-risk surgeries that involve breaking through the cribriform plate. “What’s new isn’t how to get there or clean up afterward,” he says, “it’s how do you keep an indwelling foreign body in there without causing problems.”
</p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="A surgeon wearing scrubs and a facemask holds the end of a robotic surgical tool." class="rm-shortcode" data-rm-shortcode-id="c06dd9e1c2c5649ad622eee6c3a4d21b" data-rm-shortcode-name="rebelmouse-image" id="d3a7b" loading="lazy" src="https://spectrum.ieee.org/media-library/a-surgeon-wearing-scrubs-and-a-facemask-holds-the-end-of-a-robotic-surgical-tool.jpg?id=31941926&width=980"/>
<small class="image-media media-caption" placeholder="Add Photo Caption...">Mark Richardson, a neurosurgeon, has epilepsy patients who volunteer for neuroscience studies while they’re in the hospital for brain monitoring with implanted electrodes.</small><small class="image-media media-photo-credit" placeholder="Add Photo Credit...">Pat Piasecki</small>
</p><p>
	Another tactic entirely would be to skip over the olfactory bulb and instead stimulate “downstream” parts of the brain that receive signals from the olfactory bulb. Championing that approach is another of Costanzo’s former students, 
	<a href="https://www.brainmodulationlab.org/mark-richardson" target="_blank">Mark Richardson</a>, director of functional neurosurgery at Massachusetts General Hospital. Richardson often has epilepsy patients spend several days in the hospital with electrodes in their brains, so that doctors can determine which brain regions are involved in their seizures and plan surgical treatments. While such patients are waiting around, however, they’re often recruited for neuroscience studies.
</p><p>
	To contribute to Costanzo and Coelho’s research, Richardson’s team asked epilepsy patients in the monitoring unit to take a sniff of a wand imbued with a smell such as peppermint, fish, or banana. The electrodes in their brains showed the pattern of resulting neural activity “in areas where we expected, but also in areas where we didn’t expect,” Richardson says. To better understand the brain responses, his team has just begun another round of experiments with a tool called an olfactometer that will release more precisely timed bursts of smell.
</p><p>
	Once the researchers know where the brain lights up with activity in response to, say, the smell of peppermint, they can try stimulating those areas with electricity alone in hopes of creating the same sensation. “With the existing technology, I think we’re closer to inducing the [smell perceptions] with brain stimulation than with olfactory-bulb stimulation,” Richardson says. He notes that there are already approved implants for brain stimulation and says using such a device would make the regulatory path easier. However, the distributed nature of smell perception within the brain poses a new complication: A user would likely need multiple implants to stimulate different areas. “We might need to hit different sites in quick succession or all at once,” he says.
</p><h2>The path to a commercial device</h2><p>
<strong>Across the Atlantic,</strong> the European Union is funding its own olfactory-implant project, called 
	<a href="https://cordis.europa.eu/project/id/964529" target="_blank">ROSE</a> (Restoring Odorant detection and recognition in Smell dEficits). It launched in 2021 and involves seven institutions across Europe.
</p><p>
<a href="https://www.linkedin.com/in/thomas-hummel-b1486817/" target="_blank">Thomas Hummel</a>, head of the <a href="https://www.uniklinikum-dresden.de/en/the-hospital/departments-and-institutes/otorhinolaryngology/interdisciplinary-center-smell-taste" target="_blank">Smell & Taste Clinic</a> at the Technical University of Dresden and a member of the consortium, says the ROSE researchers are partnering with <a href="https://aryballe.com/" target="_blank">Aryballe</a>, a French company that makes a tiny sensor for odor analytics. The partners are currently experimenting with stimulating both the olfactory bulb and the prefrontal cortex. “All the parts that are needed for the device, they already exist,” he says. “The difficulty is to bring them together.” Hummel estimates that the consortium’s research could lead to a commercial product in 5 to 10 years. “It’s a question of effort and a question of funding,” he says.
</p><p>
	Persaud, the e-nose expert, says the jury is out on whether a neuroprosthetic could be commercially viable. “Some people with anosmia would do anything to have that sense back to them,” he says. “It’s a question of whether there are enough of those people out there to make a market for this device,” he says, given that surgery and implants always carry some amount of risk.
</p><p>
	The VCU researchers have already had an informal meeting with regulators from the U.S. Food and Drug Administration, and they’ve started the early steps of the process for approving an implanted medical device. But Moorehead, the investor who tends to focus on practical matters, says this dream team might not take the technology all the way to the finish line of an FDA-approved commercial system. He notes that there are plenty of existing medical-implant companies that have that expertise, such as the Australian company 
	<a href="https://www.cochlear.com/us/en/about-us" target="_blank">Cochlear</a>, which dominates the cochlear-implant market. “If I can get [the project] to the stage where it’s attractive to one of those companies, if I can take some of the risk out of it for them, that will be my best effort,” Moorehead says.
</p><p>
	Restoring people’s ability to smell and taste is the ultimate goal, Costanzo says. But until then, there’s something else he can give them. He often gets calls from desperate people with anosmia who have found out about his work. “They’re so appreciative that someone is working on a solution,” Costanzo says. “My goal is to provide hope for these people.” 
	<span class="ieee-end-mark"></span>
</p><p>
<em>This article appears in the November 2022 print issue as “A Bionic Nose to Smell the Roses Again.”</em>
</p>]]></description><pubDate>Mon, 17 Oct 2022 15:00:00 +0000</pubDate><guid>https://spectrum.ieee.org/covid-smell-prosthetic</guid><category>Covid-19</category><category>E-nose</category><category>Neuroprosthetic</category><category>Neurotech</category><category>Neurotechnology</category><category>Type:cover</category><dc:creator>Eliza Strickland</dc:creator><media:content medium="image" type="image/png" url="https://spectrum.ieee.org/media-library/two-scientists-in-white-lab-coats-look-at-a-mannequin-head-thats-wearing-a-pair-of-black-glasses-with-wires-sticking-out-from-s.png?id=31947210&amp;width=980"></media:content></item><item><title>AI Can Offer Insight Into Who Responds to Antidepressants</title><link>https://spectrum.ieee.org/at-last-insight-into-who-responds-to-anti-depressants</link><description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/monitor-with-brain-scan-in-foreground-woman-with-electrodes-on-head-in-background.jpg?id=31886616&width=1245&height=700&coordinates=0%2C426%2C0%2C43"/><br/><br/><p><em>This article is part of our exclusive <a href="https://spectrum.ieee.org/collections/journal-watch/" rel="noopener noreferrer" target="_self">IEEE Journal Watch series</a> in partnership with IEEE Xplore.</em></p><p>Depression is an all-too-common psychiatric condition that can profoundly affect a person’s well-being. While there is a huge range of medications available to treat depression, many people don’t respond to the first or even second medications they are prescribed. As a result, doctors must often take a trial-and-error approach, meaning it could take months or even years to find an effective medication. </p><p>In the search for better approach, some researchers are exploring the use of machine learning to predict which patients will respond to a specific antidepressant medication. In a <a href="https://ieeexplore.ieee.org/document/9887881" rel="noopener noreferrer" target="_blank">study</a> published 12 September in <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=10" rel="noopener noreferrer" target="_blank"><em>IEEE Transactions on Biomedical Engineering</em></a>, one team describes a machine-learning algorithm that analyzes the electrical activity of people’s brains and could predict response to the antidepressant Sertraline with 83.7 percent accuracy. </p><hr/><p><a href="https://www.nyit.edu/bio/mravan" target="_blank">Maryam Ravan</a>, an assistant professor at the New York Institute of Technology’s <a href="https://www.nyit.edu/departments/electrical_and_computer_engineering" target="_blank">department of electrical and computer engineering</a>, was involved in the study. She notes that the current method for prescribing medication to people with depression is highly inefficient. </p><p>“The absence of biomarkers renders this branch of medicine completely dependent on personal interviews and patient reports,” says Ravan, citing one study showing that 33 to 37 percent of patients will remit after the first antidepressant chosen using the current trial-and-error method. </p><p>“Frustration with these inefficiencies led our group to determine if quantitative methods based on machine-learning analysis of brain electrical-activity patterns could offer more accurate clinical guidance,” she says. “Our data and that of others suggest that this is indeed the case.”</p><p>In their study, Ravan and her colleagues analyzed electroencephalogram (EEG) data from patients with depression before they received treatment. EEG is a relatively simple test in which electrodes placed on the scalp can record the electrical patterns of the brain. In total, the researchers analyzed pretreatment EEG data from 228 participants with <a href="https://www.mayoclinic.org/diseases-conditions/depression/symptoms-causes/syc-20356007" target="_blank">major depressive disorder</a>, who were randomly assigned to a placebo or treatment with Sertraline, a common <a href="https://www.mayoclinic.org/diseases-conditions/depression/in-depth/ssris/art-20044825" target="_blank">serotonin reuptake inhibitor</a> used to treat depression. </p><p>The researchers then applied machine-learning algorithms to determine who responded to treatment with Sertraline—and also the placebo. It has been widely documented across many studies that some patients’ health conditions can improve when they are given a fake treatment. </p><p>“[The placebo effect] may be based on patient belief, trust in the treatment team, simple passage of time, or may in fact have biological underpinnings reflective in brain-activity patterns which might be measurable,” explains Ravan. </p><p>She notes that a better understanding of the placebo effect could potentially lead to clinical treatments for those who would benefit from it. Indeed, the study results show that the machine-learning algorithms—along with predicting response to Sertraline with 83.7 percent accuracy—could similarly detect response to the placebo with 83 percent accuracy. </p><p>Ravan cautions that machine-learning approaches require massive data sets to ensure that results translate to the real world, and this study was based on a relatively small sample size. “[But], if our algorithms are truly as accurate as we think they are, application in the real world would lead to a great improvement in the efficiency and effectiveness of psychiatric treatment,” she says, noting that portable EEG devices are currently widely available and could be deployed in underserviced areas. </p><p><a href="https://www.eng.mcmaster.ca/msbe/people/faculty/gary-hasey" target="_blank">Gary Hasey</a>, an associate professor at <a href="https://www.mcmaster.ca/" target="_blank">McMaster University</a>’s department of psychiatry and behavioural neurosciences, who was also involved in the study, says the team is now working toward commercialization and broader implementation of their approach, through a startup company called Digital Medical Experts (DME). </p><p>“DME has patented psychiatric machine-learning technologies in the United States, Canada, and Australia,” he says. “We have created the infrastructure necessary for the remote collection of EEG data and are actively pursuing further investment.”</p><p>The team has also been exploring the use of machine learning to identify individuals with suicidal ideation. Notably, many people who die by suicide deny having suicidal ideation when asked.</p><p>“Our group has conducted a study in 68 subjects diagnosed with major depressive disorder, where we were able to identify the presence of suicidal ideation with accuracy of 70 percent using machine-learning analysis of the EEG signal,” says Ravan. “We are currently further testing and training these algorithms using a much larger data set.”</p>]]></description><pubDate>Mon, 10 Oct 2022 13:42:52 +0000</pubDate><guid>https://spectrum.ieee.org/at-last-insight-into-who-responds-to-anti-depressants</guid><category>Journal watch</category><category>Depression</category><category>Machine learning</category><category>Medications</category><dc:creator>Michelle Hampson</dc:creator><media:content medium="image" type="image/jpeg" url="https://spectrum.ieee.org/media-library/monitor-with-brain-scan-in-foreground-woman-with-electrodes-on-head-in-background.jpg?id=31886616&amp;width=980"></media:content></item><item><title>Bring Physics-Based AI Into Your Research With NVIDIA Modulus</title><link>https://info.nvidia.com/developer-physics-informed-machine-learning-with-modulus-webinar.html?&amp;ncid=pa-srch-othe-987968-vt16#cid=ix01_pa-srch-othe_en-us</link><description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/image.png?id=31869919&width=980"/><br/><br/><p>High-fidelity simulations in science and engineering are widely used in industrial, seismic, weather/climate, and life sciences applications. However, traditional simulations remain computationally expensive and impractical for real time applications. They are discretization dependent, meaning they do not easily assimilate either measured or synthetic data from various sources. Due to rapid developments in AI for science and engineering problems, machine learning has assumed an important complementary role in addressing the critical gaps in the traditional methods.</p><p>NVIDIA Modulus is a physics-based machine learning platform that has several state-of-the-art network architectures and data, as well as PDE driven AI techniques to solve real world science and engineering problems. Various performance features for both single and multi-GPU/node systems, plus connectivity with several NVIDIA toolkits and technologies are available in Modulus. Examples and documentation are provided to ensure seamless learning for students while the researchers can customize the framework through various APIs.</p><h2>Introduction to NVIDIA Modulus: A Physics-ML Framework for Research</h2><p>This webinar will introduce you to applications of machine learning, various domains of science and engineering, as well as a deep dive into the code implementation, training, solution, and visualization aspects of physics-ML workflow.</p><p><a href="https://info.nvidia.com/developer-physics-informed-machine-learning-with-modulus-webinar.html?&ncid=pa-srch-othe-987968-vt16#cid=ix01_pa-srch-othe_en-us" rel="noopener noreferrer nofollow" target="_blank">Register now for this free webinar!</a></p><hr/><p><strong>By attending this webinar, you will learn about:</strong></p><ul><li>The machine learning applications in science & engineering with physics-ML framework, NVIDIA Modulus.</li></ul><ul><li>How you can extend/modify Modulus to implement your own work.</li></ul><ul><li>The architecture and functionality of Modulus, and performance enhancements for data & physics driven systems.</li></ul><ul><li>How the Modulus framework integrates with other Nvidia toolkits and technologies: PySDF (for geometry), DALI™ (for data loading), Triton™ (for inference), Omniverse™ platform (for visualization).</li></ul>Join us after the presentation for a live Q&A session with Jianjun Xu, Ph.D., Sr. Solutions Architect, Amazon Web Services.]]></description><pubDate>Wed, 05 Oct 2022 18:45:41 +0000</pubDate><guid>https://info.nvidia.com/developer-physics-informed-machine-learning-with-modulus-webinar.html?&amp;ncid=pa-srch-othe-987968-vt16#cid=ix01_pa-srch-othe_en-us</guid><category>Nvidia</category><category>Ai</category><category>Artificial intelligence</category><category>Machine learning</category><category>Research</category><category>Simulations</category><category>Type:webinar</category><dc:creator>NVIDIA</dc:creator><media:content medium="image" type="image/png" url="https://assets.rbl.ms/31869919/origin.png"></media:content></item><item><title>"Nothing About Us Without Us"</title><link>https://spectrum.ieee.org/bionic-hand-editorial</link><description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/a-photo-of-two-people-holding-signs-outside-one-is-in-a-wheelchair.png?id=31822925&width=1245&height=700&coordinates=0%2C373%2C0%2C373"/><br/><br/><p><strong>Before we redesigned</strong> our website a couple of years ago, we took pains to have some users show us how they navigate our content or complete specific tasks like leaving a comment or listening to a podcast. We queried them about what they liked or didn’t like about how our content is presented. And we took onboard their experiences and designed a site and a magazine based on that feedback.</p><p>So when I read this month’s cover story by Britt Young about using a variety of high- and low-tech prosthetic hands, I was surprised to learn that much bionic-hand development is conducted without taking the lived experience of people who use artificial hands into account.</p><hr/><p>I shouldn’t have been. While user-centered design is a long-standing practice in Web development, it doesn’t seem to have expanded deep into other product-development practices. A quick search on the IEEE Xplore Digital Library tallied less than 2,000 papers (out of 5.7 million) on “user-centered design.” Five papers bubbled up when searching “user-centered design” and “prosthesis.” </p><p>Young, who is working on a book about the prosthetics industry, was in the first cohort of toddlers fitted with a myoelectric prosthetic hand, which users control by tensing and relaxing their muscles against sensors inside the device’s socket. Designed by people Young characterizes as “well-intentioned engineers,” these technologically dazzling hands try to recreate in all its complex glory what Aristotle called “the instrument of instruments.” </p><p class="pull-quote">“It’s more important that we get to live the lives we want, with access to the tools we need, than it is to make us look like everyone else.”</p><p>While high-tech solutions appeal to engineers, Young makes the case that low-tech solutions like the split hook are often more effective for users. “Bionic hands seek to make disabled people ‘whole,’ to have us participate in a world that is culturally two-handed. But it’s more important that we get to live the lives we want, with access to the tools we need, than it is to make us look like everyone else.”</p><p>As Senior Editor Stephen Cass pointed out to me, one of the rallying cries of the disabled community is “nothing about us, without us.” It is a response to a long and often cruel history of able-bodied people making decisions for people with disabilities. Even the best intentions don’t make up for doing things <em>for</em> disabled people instead of <em>with</em> them, as we see in Young’s article.</p><p>Assistive and other technologies can indeed have huge positive impacts on the lives of people with disabilities. <em>IEEE Spectrum</em> has covered many of these developments over the decades, but generally speaking it has involved able-bodied journalists writing <em>about</em> assistive technology, often with the perspective of disabled people relegated to a quote or two, if it was included at all. </p><p>We are fortunate now to have the chance to break that pattern, thanks to a grant from the IEEE Foundation and the Jon C. Taenzer Memorial Fund. With the grant, <em>Spectrum</em> is launching a multiyear fellowship program for disabled writers. The goal is to develop writers with disabilities as technology journalists and provide practical support for their reporting. These writers will investigate not just assistive technologies, but also look at other technologies with ambitions for mass adoption through a disability lens. Will these technologies be built with inclusion in mind, or will disabled people be a literal afterthought? Our first step will be to involve people with disabilities in the design of the program, and we hope to begin publishing articles by fellows early next year. </p><p><em>This article appears in the October 2022 print issue.</em></p>]]></description><pubDate>Sat, 01 Oct 2022 15:00:00 +0000</pubDate><guid>https://spectrum.ieee.org/bionic-hand-editorial</guid><category>Prosthetics</category><category>Bionic hand</category><category>Prosthetic hand</category><category>Product design</category><category>User-centered design</category><dc:creator>Harry Goldstein</dc:creator><media:content medium="image" type="image/png" url="https://spectrum.ieee.org/media-library/a-photo-of-two-people-holding-signs-outside-one-is-in-a-wheelchair.png?id=31822925&amp;width=980"></media:content></item><item><title>The Electric Purple Snake-Oil Machine</title><link>https://spectrum.ieee.org/violet-ray</link><description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/an-antique-medical-apparatus-consisting-of-a-black-wand-various-glass-tools-to-plug-into-the-wand-and-a-power-cord.jpg?id=31822581&width=1245&height=700&coordinates=0%2C337%2C0%2C338"/><br/><br/><p>
<strong>The violet ray machine </strong>has an awesome name that conjures up images of cartoon supervillains taking out Gotham, but its <em>actual</em> history is even odder—and it includes a superhero, not a villain.
</p><p>
	The technology underpinning the machine begins with none other than 
	<a href="https://ethw.org/Nikola_Tesla" rel="noopener noreferrer" target="_blank">Nikola Tesla</a> and his <a href="https://handwiki.org/wiki/Engineering:History_of_the_Tesla_coil" rel="noopener noreferrer" target="_blank">eponymous coil</a>. After Tesla and others made some refinements to the device, an influential clairvoyant named Edgar Cayce popularized violet ray machines for treating just about every kind of ailment—rheumatism and nervous conditions, acne and baldness, gonorrhea and prostate troubles, brain fog and writer’s cramp. Even Wonder Woman had her own health-restoring Purple Ray device. During the first half of the 20th century, a number of companies manufactured and sold the machines, which became ubiquitous for a time. And yet the scientific basis for the healing effects of violet rays was scant. So what accounted for their popularity?
</p><hr/><h2>The cutting-edge tech of the violet ray machine</h2><p>
	Violet ray machines employ a Tesla coil, also known as a resonance transformer, to produce a high-frequency, low-current beam, which is then applied to the skin. Nikola Tesla kicked off this line of invention after traveling to Paris during the summer of 1889 to attend the 
	<a href="https://en.wikipedia.org/wiki/Exposition_Universelle_(1889)" rel="noopener noreferrer" target="_blank">Exposition Universelle</a>. There he learned of Heinrich Hertz’s electromagnetic discoveries. Intrigued, Tesla returned to New York City to run some experiments of his own. The result was the Tesla coil, which he envisioned being used for wireless lighting and power. In April 1891, he applied for a <a href="https://patents.google.com/patent/US454622A/en?oq=454622" rel="noopener noreferrer" target="_blank">U.S. patent</a> for a “System of Electric Lighting,” which he received two months later. It would be the first in a series of related patents that spanned more than a decade.
</p><p>
	In May of that year, Tesla unveiled his wondrous invention to members of the American Institute of Electrical Engineers, during a 
	<a href="https://books.google.com/books?id=7YPbAAAAMAAJ&pg=PA145#v=onepage&q&f=false" rel="noopener noreferrer" target="_blank">lecture</a> on his “Experiments with Alternate Currents of Very High Frequency and Their Application to Methods of Artificial Illumination.” He continued to test different circuit configurations and patented some (but not all) of his improvements, such as a “Means for Generating Electric Currents,” <a href="https://patents.google.com/patent/US514168A/en" rel="noopener noreferrer" target="_blank">U.S. Patent No. 514,168</a>. After more years of tinkering, Tesla perfected his resonance transformer and was granted <a href="https://patents.google.com/patent/US1119732A/en?oq=1119732" rel="noopener noreferrer" target="_blank">U.S. Patent No. 1,119,732</a> for an “Apparatus for Transmitting Electrical Energy” on 1 December 1914.
</p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="An old black and white photo showing a man sitting next to a large electrical apparatus that is emitting sparks." class="rm-shortcode" data-rm-shortcode-id="a3cb2a38509dbe855371a23276cb8951" data-rm-shortcode-name="rebelmouse-image" id="09a11" loading="lazy" src="https://spectrum.ieee.org/media-library/an-old-black-and-white-photo-showing-a-man-sitting-next-to-a-large-electrical-apparatus-that-is-emitting-sparks.jpg?id=31822607&width=980"/>
<small class="image-media media-caption" placeholder="Add Photo Caption...">Nikola Tesla envisioned his eponymous coil being used for wireless lighting and power. It was also at the heart of the violet ray machine. </small><small class="image-media media-photo-credit" placeholder="Add Photo Credit...">Stocktrek Images/Getty Images</small>
</p><p>
	Tesla promoted the 
	<a href="https://ieeexplore.ieee.org/document/771079" target="_blank">medical use</a> of the electromagnetic spectrum, suggesting to physicians that different voltages and currents could be used to treat a variety of conditions. His endorsement came at a time when trained doctors as well as shrewd hucksters were already experimenting with <a href="https://spectrum.ieee.org/this-1850s-medical-device-was-said-to-cure-toothache-gangrene-and-ennui" target="_self">electrotherapy</a> and <a href="https://spectrum.ieee.org/weve-been-killing-deadly-germs-with-uv-light-for-more-than-a-century" target="_self">ultraviolet light</a> to help patients or to make a buck, depending on your perspective.<br/>
</p><p>
	The market was perfectly primed for the violet ray machine, in other words. Tesla himself never commercialized a medical device based around his coil, but others did. The French physician and electrophysiologist 
	<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7828069" target="_blank">Jacques-Arsène d’Arsonval</a> modified Tesla’s design to make the device safer for human use. It was further improved by another French doctor and electrotherapy researcher, <a href="https://en.wikipedia.org/wiki/Paul_Oudin" rel="noopener noreferrer" target="_blank">Paul Marie Oudin</a>. In 1893, Oudin crafted the first working prototype of what eventually became the violet ray machine. Four years later, Frederick Strong developed an American version.
</p><p class="pull-quote">
	An influential clairvoyant named Edgar Cayce popularized violet ray machines for treating just about every kind of ailment—rheumatism and nervous conditions, acne and baldness, gonorrhea and prostate troubles, brain fog and writer’s cramp.
</p><p>
	Another charismatic individual gets credit for popularizing the device: the psychic 
	<a href="https://psi-encyclopedia.spr.ac.uk/articles/edgar-cayce" target="_blank">Edgar Cayce</a>. As a young adult, Cayce reportedly lost his voice for over a year. No doctor could cure him, and in desperation he underwent hypnosis. He not only regained the ability to speak, he also began suggesting medical advice and homeopathic remedies. Cayce, who claimed to have had visions from childhood, became a professional clairvoyant, and for the next 40 years he dispensed his wisdom through <a href="https://www.edgarcayce.org/edgar-cayce/his-life/" target="_blank">psychic readings</a>. Out of more than 14,000 recorded readings, Cayce mentioned the violet ray machine almost 900 times. In case you doubt his status as an influencer, Cayce counted Thomas Edison, composer George Gershwin, and U.S. president Woodrow Wilson among his clients.<br/>
</p><h2>Was there nothing the violet ray machine couldn’t cure?</h2><h3></h3><br/><p>The popularity of violet ray machines exploded after 1915, once all of the components for a portable device could be easily manufactured. They could be plugged into a lamp or wall socket or wired to a battery—remember that most homes and businesses in the early 20th century were not yet electrified, and so most manufacturers offered both alternating and direct current options. The machine’s handheld wand consisted of a Tesla coil wrapped in an insulating material, such as Bakelite. The coil produced 1 to 2 kilovolts, which charged a condenser, and then discharged at a rate between 4 to 10 kilohertz when passed over the skin. A voltage selector controlled the intensity of the spark, creating anything from a mild sensation to something quite intense. This video shows the sparks coming from an antique machine:</p><h3></h3><br/><span class="rm-shortcode" data-rm-shortcode-id="9218b56f53f61d6c0c01b85cd8d96085" style="display:block;position:relative;padding-top:56.25%;"><iframe frameborder="0" height="auto" lazy-loadable="true" scrolling="no" src="https://www.youtube.com/embed/5c8mrnW2evI?rel=0&start=535" style="position:absolute;top:0;left:0;width:100%;height:100%;" width="100%"></iframe></span><h3></h3><br/><div class="rblad-ieee_in_content"></div><p>Glass electrodes—partially evacuated glass tubes known as Geissler tubes—could be inserted into the wand. These came in different shapes depending on their intended use. For example, a rake-shaped attachment worked to massage the scalp, while a narrow tube could be inserted into the mouth, nose, or another orifice. The high voltage ionized the gas within the glass tube, creating the purple glow that gave the device its name.<br/></p><p>
	Numerous manufacturers sprang up to produce the portable machines, including Detroit’s 
	<a href="https://americanhistory.si.edu/collections/search/object/nmah_736741" rel="noopener noreferrer" target="_blank">Renulife Electric Co</a>. Founded by inventor James Henry Eastman in 1917, Renulife sold different models for different uses. According to <a href="https://www.sindecusemuseum.org/blog/violet-ray" rel="noopener noreferrer" target="_blank">company literature</a>, Model M was its most popular general-purpose product, while Model D was for dentistry, and the tricked-out Model R [pictured at top] had finer regulation of current and a built-in ozone generator to help with head and lung congestion.
</p><p class="pull-quote">
	In 1917, editors at the 
	<i>Journal of the American Medical Association</i> reported that a violet ray generator certainly couldn’t treat “practically every ailment known to mankind,” as one manufacturer had claimed.
</p><p>
<a href="https://medicalhistory.uwo.ca/teaching_modules/eletrotherapy/Branston_Violet_Ray_Directions.pdf" rel="noopener noreferrer" target="_blank">Instructions</a> for the violet ray machines manufactured by Charles A. Branston Ltd. contain an alphabetical list of disorders that could be treated, from abscess to writer’s cramp, with dozens of other ailments in between. Like the Renulife products, the Branston machines also came in <a href="https://www.cppdigitallibrary.org/items/show/4433" rel="noopener noreferrer" target="_blank">different flavors</a>. The Branston machine’s high-frequency mode had germicidal effects and purportedly could be used to cure infections as well as relieve pain. Sinusoidal mode was used to gently massage away nervousness and paralysis. Ozone mode was for inhaling, to treat lung disorders. The Branston devices ranged in price from US $30 for the Model 5B (high-frequency mode only) to $100 for the Model 29 (which had all three modes).
</p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="A page from a pamphlet showing the potential uses of an electrotherapeutic machine. " class="rm-shortcode" data-rm-shortcode-id="ef56a9a7f67c1f587c7f8591eaa6db2b" data-rm-shortcode-name="rebelmouse-image" id="9c209" loading="lazy" src="https://spectrum.ieee.org/media-library/a-page-from-a-pamphlet-showing-the-potential-uses-of-an-electrotherapeutic-machine.jpg?id=31822651&width=980"/>
<small class="image-media media-caption" placeholder="Add Photo Caption...">The violet ray machines made by Charles A. Branston Ltd. had different modes for treating a wide variety of ailments.</small><small class="image-media media-photo-credit" placeholder="Add Photo Credit...">Historical Medical Library/College of Physicians of Philadelphia</small>
</p><p>
	During the first half of the 20th century, manufacturers marketed the machines to doctors and consumers alike. By the time Wonder Woman debuted in her own comic book in June 1942, the violet ray machine was a well-known household technology. So it wasn’t too surprising that the superhero had a machine of her own.
</p><p>
	In the very first issue, Wonder Woman’s future love interest, Steve Trevor, is grievously injured in a plane crash. Seeking to cure his wounds, Diana works tirelessly for five days to complete her Purple Ray machine—but she’s too late. Trevor has died. Undeterred, Diana bathes her patient in the glowing light of the machine. The result might have embarrassed even the admen who wrote the promotional copy for Branston’s products: Wonder Woman’s Purple Ray 
	<a href="https://wonder-woman.fandom.com/wiki/Purple_Ray?file=Purple_Ray_WWv1-01.png" rel="noopener noreferrer" target="_blank">brings Trevor back to life</a>.
</p><h2>Science frowns on the violet ray machine </h2><p>
	Despite their popularity, the machines didn’t fare quite as well within the medical establishment. In 1917, editors at the 
	<em>Journal of the American Medical Association</em> reported that a violet ray generator certainly couldn’t treat “practically every ailment known to mankind,” as one manufacturer had claimed. Although the devices emitted a violet color, they were not in fact emitting ultraviolet light, or at least not in amounts that would be beneficial. In 1951, a Maryland district court ruled against a company named Master Appliances in a libel suit. The charge was misbranding, and the court found that the device was not an effective treatment nor capable of producing the claimed results. At the time, Master Appliances was one of the last manufacturers of violet ray machines in the United States, and the ruling effectively ended production in this country.
</p><p>
	And yet you can still buy violet ray machines today—both the antique variety and its 
	<a href="https://laserskinsolutions.com.au/skin-problems/what-is-high-frequency-and-why-do-we-use-it/" rel="noopener noreferrer" target="_blank">modern equivalent</a>. Today’s units are mainly marketed to aestheticians or sold for home use, and some dermatologists are not ready to categorically dismiss their benefits. Although they probably won’t cure indigestion or gray hair, the high frequency can dry out the skin and ozone does kill bacteria, so the machines may help treat acne and other skin conditions. Plus, there’s the placebo effect. As with all consumer electronics for which outrageous claims are made, let the buyer beware.
</p><p>
<em>Part of a </em><a href="https://spectrum.ieee.org/collections/past-forward/" target="_self"><em>continuing series</em></a> <em>looking at photographs of historical artifacts that embrace the boundless potential of technology.</em>
</p><p>
<em>An abridged version of this article appears in the October 2022 print issue.</em>
</p>]]></description><pubDate>Fri, 30 Sep 2022 15:00:00 +0000</pubDate><guid>https://spectrum.ieee.org/violet-ray</guid><category>Past forward</category><category>History of medical devices</category><category>Type:departments</category><category>Violet ray machine</category><category>Tesla coils</category><dc:creator>Allison Marsh</dc:creator><media:content medium="image" type="image/jpeg" url="https://spectrum.ieee.org/media-library/an-antique-medical-apparatus-consisting-of-a-black-wand-various-glass-tools-to-plug-into-the-wand-and-a-power-cord.jpg?id=31822581&amp;width=980"></media:content></item><item><title>Monitoring Parkinson’s Patients at Home Could Improve Disease Management</title><link>https://spectrum.ieee.org/radar-device-could-monitor-parkinson-s-at-home</link><description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/illustration-showing-a-device-with-an-antenna-on-a-wall-radiating-a-signal-a-figure-walks-through-a-door-and-is-seen-in-severa.jpg?id=31842546&width=1245&height=700&coordinates=0%2C0%2C0%2C513"/><br/><br/><p>A radar device the size of a Wi-Fi router could help continuously monitor Parkinson’s disease in patients from afar as they go about their lives at home. By using radio waves to track the gait of Parkinson’s patients, the device should help doctors assess the effectiveness of medications, see how the disease is progressing, and create better treatment plans.</p><p><a href="https://www.michaeljfox.org/parkinsons-101" target="_blank">Parkinson’s disease</a> is a chronic, progressive brain disorder that affects motor function, causing tremors, impaired balance, and the <a href="https://spectrum.ieee.org/smart-footwear-helps-assess-the-fall-risk-of-people-with-parkinsons-disease" target="_self">risk of falls</a> and injuries. There is no cure for it and patients rely on medications to control symptoms. </p><p>Patients then have to visit clinics regularly so specialists can assess their motor and nonmotor symptoms to determine how they are responding to the drugs. The gold-standard test used to assess Parkinson’s disease is the <a href="https://www.movementdisorders.org/MDS/MDS-Rating-Scales/MDS-Unified-Parkinsons-Disease-Rating-Scale-MDS-UPDRS.htm" target="_blank">Unified Parkinson’s Disease Rating Scale </a>(UPDRS) in which a patient’s motor skills are evaluated and scored based on a number of physical exercises. But this type of assessment isn’t ideal and can be affected by things like the patient being tired or the subjectivity of the evaluator. </p><p>That’s if patients even make it to the clinics in the first place. About 40 percent of patients with Parkinson’s are not seen by neurologists or Parkinson’s specialists, because these care providers are concentrated in medical centers in urban areas. Those suffering from advanced Parkinson’s often have problems traveling to these medical centers due to old age, limited mobility, impaired cognition, and decreased driving ability.</p><p>An objective and accurate way to continuously assess Parkinson’s at home could lead to better medical care and also help researchers develop new drugs to control the disorder, says <a href="http://yingchengliu.com/" rel="noopener noreferrer" target="_blank">Yingcheng Liu</a>, a Ph.D. candidate in the electrical engineering and computer science department at MIT. One way to do that is to ask patients to wear sensors or measure themselves. But Liu and Guo Zhang of MIT, along with neurologists at the University of Rochester Medical Center wanted to develop a touchless, passive system. So they decided to use radio waves. </p><p>Their device, reported in the journal <em>Science Translational Medicine</em>, is the size of a Wi-Fi router, but it transmits radio signals at a thousandth of the power. “Our device works like a low-power home human radar,” Liu says. </p><p class="pull-quote">An objective and accurate way to continuously assess Parkinson’s at home could lead to better medical care and also help researchers develop new drugs to control the disorder.</p><p>The low-power signals can travel through walls and objects, but they reflect off the human body because of its water content. The device collects the signals and sends them to Amazon Cloud where they are analyzed by the advanced signal-processing and machine-learning algorithms that the researchers developed. </p><p>Based on the signals, the algorithms extract a patient’s walking movements and trajectories through the home. From these trajectories, Liu says the researchers can calculate the person’s walking speed and evaluate its correlation with Parkinson’s severity, disease progression, and medication response.</p><p>The team tested the device by using it to monitor 34 participants with Parkinson’s disease and 16 healthy control subjects continuously in their homes for months. They found that the calculated walking speed correlated with scores on the standard test used today to measure disease severity. </p><p>But the at-home gait speed was more sensitive at tracking disease progression over time. “We found that those with Parkinson’s disease had a faster rate of decline in gait speed over time than those without,” Liu says.</p><p>What’s more, the device was able to detect the fluctuations in patients’ walking speed in response to medication over the course of the day. Typically, patients have to record these fluctuations in diaries so that doctors can adjust their treatment plans. Being able to detect them remotely using the radar device takes the burden off the patients, the researchers say.<br/></p><p>They now need to make the algorithms more robust and efficient, and they plan to test the device and methods on a larger population. Liu says he also wants to analyze more gait parameters such as stride length and swing length. “I will try to combine both gait and sleep to study Parkinson’s in a more holistic aspect,” he says. “Also, there are many other diseases that result in gait dysfunction, such as cancer. I will also study these diseases.” </p>]]></description><pubDate>Thu, 29 Sep 2022 17:43:48 +0000</pubDate><guid>https://spectrum.ieee.org/radar-device-could-monitor-parkinson-s-at-home</guid><category>Radar</category><category>Remote monitoring</category><category>Parkinson's disease</category><category>Gait control</category><dc:creator>Prachi Patel</dc:creator><media:content medium="image" type="image/jpeg" url="https://spectrum.ieee.org/media-library/illustration-showing-a-device-with-an-antenna-on-a-wall-radiating-a-signal-a-figure-walks-through-a-door-and-is-seen-in-severa.jpg?id=31842546&amp;width=980"></media:content></item><item><title>AI Matches Doctors in Screening  for Tuberculosis</title><link>https://spectrum.ieee.org/tuberculosis-screening-ai</link><description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/image-of-chest-x-ray.jpg?id=31804370&width=1245&height=700&coordinates=0%2C187%2C0%2C188"/><br/><br/><p>A killer could be stopped cold—or at least be limited in its deadly toll—thanks to AI. </p><p>Apart from COVID-19, tuberculosis (TB) is the leading cause of death by an infectious disease worldwide, despite being largely preventable and treatable. While the World Health Organization (WHO) <a href="https://www.who.int/publications/digital/global-tuberculosis-report-2021/featured-topics/tb-guidelines" target="_blank">recommends</a> using chest X-rays to help identify likely cases of TB, many health-care centers lack adequate radiologists to interpret these X-rays. In a study published on 6 September in the journal <a href="https://pubs.rsna.org/doi/10.1148/radiol.212213" target="_blank"><em>Radiology</em></a>, researchers at Google along with colleagues from India, South Africa, and Zambia showed that their deep-learning algorithm could identify cases of TB from chest X-rays as well as radiologists could. <br/></p><p>“From a global health standpoint, understanding how to efficiently and effectively identify people living with TB” is extremely valuable, said <a href="https://www.hopkinsmedicine.org/profiles/details/christopher-hoffmann" target="_blank">Dr. Christopher Hoffmann</a>—an associate professor of medicine in the division of infectious disease at the Johns Hopkins University School of Medicine—who was not involved in the study. </p><p>To train their algorithm, the researchers used more than 165,000 chest X-ray images from 22,000 patients in several European countries, China, India, South Africa, and Zambia. The AI itself had three components—a cropping system, which helped the algorithm analyze the correct part of the image, a smart image-analysis routine, and a final part that combined the two to make the final decision. The algorithm sorts the images into three categories: normal, TB, or abnormal but not TB. As a result it could potentially help even patients who might not have TB but still require medical care. Moreover, the researchers said the abnormal-but-not-TB category also improved the accuracy of their TB-screening algorithm, allowing the model to home in on abnormalities specific to TB. </p><p>The “distinction between abnormal but not TB and abnormal and TB was one of the creative solutions that we had” that helped make the model better, said <a href="https://research.google/people/ShruthiPrabhakara/" target="_blank">Shruthi Prabhakara</a>, a Google researcher and an author of the study.</p><p>To be clear, the authors noted that Google’s system would not be the first AI ever devised to accurately screen for TB. Indeed, the WHO already <a href="https://apps.who.int/iris/bitstream/handle/10665/340255/9789240022676-eng.pdf" target="_blank">recommends</a> that such AI systems be used for TB screening. Nevertheless, researchers say adapting systems like this one can help combat that devastating impact of TB all over the world, especially in underserved health-care systems</p><p>To test the algorithm, researchers studied some 1,200 patients from four different countries as well as a separate data set of some 1,000 people from a gold-mining community in South Africa. The study was retrospective, meaning that the data in question was collected from medical records, not current patients. Researchers compared the AI’s accuracy with that of nine radiologists from India, where TB is endemic, and five from the United States, where it is not. </p><p>In most cases, the AI produced very similar results in terms of both sensitivity and specificity to radiologists. Sensitivity, or true positive rate, is how well a system can correctly identify a person with TB, while specificity, or true negative rate, is how well it can isolate the people who don’t have TB. </p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="images of various chest x-rays" class="rm-shortcode" data-rm-shortcode-id="1daf3524fa73aeb75df9327a022a9101" data-rm-shortcode-name="rebelmouse-image" id="19472" loading="lazy" src="https://spectrum.ieee.org/media-library/images-of-various-chest-x-rays.jpg?id=31804372&width=980"/>
<small class="image-media media-caption" placeholder="Add Photo Caption...">Examples of chest radiographs for which the deep-learning system (DLS) provided the correct interpretation, corresponding to (A) tuberculosis (TB)–positive subjects and (B) TB-negative subjects. </small><small class="image-media media-photo-credit" placeholder="Add Photo Credit...">Radiological Society of America</small></p><p>For most of the data sets, the AI was able to meet WHO requirements for TB screening tests of at least 90 percent sensitivity and 70 percent specificity. Though the AI did not meet these requirements for the South Africa and Zambia data, radiologists also couldn’t meet these standards. An analysis of some of the subgroups involved in the study helps highlight why. For both the AI and radiologists, patients with HIV, who made up most of the patients in the Zambia data set, were more difficult to correctly screen. Many of the false results, the researchers reported, occurred in patients with other lung conditions, which are more prevalent in populations like the South African miners data set. </p><p>“There are mimics of TB, which means that there may be things that may look almost like TB on a chest X-ray, which then is not TB,” said Dr. <a href="https://www.hopkinsmedicine.org/profiles/details/sanjay-jain" target="_blank">Sanjay K. Jain</a>, a professor at the Johns Hopkins University School of Medicine who studies TB imaging and who was not involved in the study. </p><p>Google’s algorithm is not the first AI to use chest X-rays to screen TB patients. As part of a <a href="https://www.who.int/news/item/22-03-2021-who-announces-updated-guidance-on-the-systematic-screening-for-tuberculosis" target="_blank">2021 update to WHO recommendations on screening for TB</a>, the agency looked at three similar technologies—concluding that because the technologies were about as accurate as human radiologists, who are scarce in many areas, health-care systems can use these AIs for TB screening and triage in place of human experts and specialists. Though only a laboratory test can truly diagnose TB, AI systems can screen patients so that only those who are likely to have TB receive lab tests, which are typically more expensive than chest X-rays on their own. However, the researchers also found that while this method can save money, it saves the most when disease prevalence is low, becoming closer to the cost of simply giving everyone a laboratory test as prevalence increases. </p><p>The study incorporated diverse data sets but did not incorporate study participants who were current patients. </p><p>“I think a study where the system is actually used by the people in the field is a logical next step,” said <a href="https://irp.nih.gov/pi/ronald-summers" target="_blank">Dr. Ronald Summers</a>, a radiologist who directs the Imaging Biomarkers and Computer-Aided Diagnosis Laboratory at the National Institutes of Health Clinical Center. In fact, the study’s researchers have already started doing that work, they said. </p><p>Although technology similar to the one used in the study already exists,  Google researchers said they just want to provide another effective option for this technology. “Our goal is not to go out and try and prove superiority over other products,” said Daniel Tse, a Google researcher and one of the study’s authors. </p><p>Jain said that even if the system is not perfect, developing these sort of AI systems is still important. </p><p>“This is moving in the right direction,” he said. “I think we should encourage this kind of system.”</p>]]></description><pubDate>Sat, 24 Sep 2022 14:00:01 +0000</pubDate><guid>https://spectrum.ieee.org/tuberculosis-screening-ai</guid><category>Smart medical devices</category><category>Tuberculosis</category><category>Artificial intelligence</category><category>Screening</category><dc:creator>Rebecca Sohn</dc:creator><media:content medium="image" type="image/jpeg" url="https://spectrum.ieee.org/media-library/image-of-chest-x-ray.jpg?id=31804370&amp;width=980"></media:content></item><item><title>Monitoring a Pregnancy at Home With a Smartphone</title><link>https://spectrum.ieee.org/pregnancy-heartbeat-monitor-smartphone</link><description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/a-smiling-pregnant-woman-sitting-on-a-couch-and-looking-at-her-phone.jpg?id=31802228&width=1245&height=700&coordinates=0%2C0%2C0%2C939"/><br/><br/><p><em>This article is part of our exclusive <a href="https://spectrum.ieee.org/collections/journal-watch/" rel="noopener noreferrer" target="_self">IEEE Journal Watch series</a> in partnership with IEEE Xplore.</em></p><p>Although a pregnancy is an exciting time for expecting parents, it can involve many trips to a doctor’s office to monitor the health of the fetus. Currently, the most common method for monitoring the heartbeat of a fetus is through an ultrasound test—which requires not only a visit to a doctor’s office but also the expertise of a trained technician. </p><p>In the search for a simpler approach, researchers have developed a novel system that includes a wearable device, a smartphone, and an algorithm that could offer at-home monitoring of a fetus’s cardiac health. The new algorithm, dubbed Lullaby, is described in a <a href="https://ieeexplore.ieee.org/document/9863638" rel="noopener noreferrer" target="_blank">study</a> published on 19 August in <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=7782634" rel="noopener noreferrer" target="_blank"><em>IEEE Sensors Letters</em></a>.</p><p>The wearable device involves a patch that’s placed on the abdomen of a pregnant user in addition to electrodes that monitor the electrocardiogram (ECG) signals from the fetus. The device also includes a microcontroller that processes the signals and sends them via Bluetooth to a smartphone or watch. Users can then view the data on an app.</p><p>However, a major challenge with this type of tech is that continuous ECG monitoring involves a lot of data to process, which has made real-time monitoring with wearable devices challenging. The new Lullaby algorithm addresses this issue. </p><p>“Lullaby was made to push the boundaries of the field by creating an algorithm that could process high-resolution ECG in real time and on a wearable device,” explains Daniel Jilani, an undergraduate researcher at University of California, Irvine, who co-led the development of this technology.</p><p>The system works by exploiting the fact that a heartbeat has a steady rhythm. The device uses this temporal pattern to better distinguish between true and false heartbeats, thereby focusing its computational power more on the heartbeats themselves, rather than the cardiac activity between heartbeats. This approach reduces the amount of computation required to process the data and extract the fetal heartbeats.</p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="" class="rm-shortcode" data-rm-shortcode-id="e687fd62b1ec16a2de1d55a21a68ade9" data-rm-shortcode-name="rebelmouse-image" id="2ff6a" loading="lazy" src="https://spectrum.ieee.org/media-library/this-fetal-cardiac-monitoring-system-uses-a-patch-with-electrodes-which-record-the-abdominal-ecg-signals-of-a-pregnant-user-th.png?id=31786813&width=980"/>
<small class="image-media media-caption" placeholder="Add Photo Caption...">This fetal cardiac-monitoring system uses a patch with electrodes, which record the abdominal ECG signals of a pregnant user. The novel system is currently being developed jointly by Sensoriis and HERO Laboratory.</small><small class="image-media media-photo-credit" placeholder="Add Photo Credit...">Tai Le</small></p><p>In their study, the researchers used a data set of abdominal ECG recordings to test the Lullaby approach against other existing ECG-processing algorithms, finding it to be nearly seven to 1,000 times as fast as these existing options.<br/></p><p>“In terms of power, we believe that the algorithm is efficient enough to run continuously [on a smartphone] for days or weeks,” says Jilani. “In terms of RAM memory, the Lullaby algorithm uses memory on the scale of kilobytes, meaning it can run on memory-limited devices such as microcontrollers and smartwatches.”</p><p>The researchers do not yet know how accurate the Lullaby approach is compared to a traditional ultrasound test, but they note that ultrasound devices are less accessible, more expensive, and more difficult to operate than an ECG. What’s more, ultrasound tests are done during a visit to the doctor’s office, whereas a wearable ECG device can provide more continuous monitoring as a pregnant user goes about their normal day. Significantly, this technology could be especially impactful by making fetal heart monitoring more accessible to low-income and disadvantaged communities, Jilani notes. </p><p>Since this initial study, Jilani says the team has already greatly improved the algorithm to be more accurate and faster than the original version, and they are working toward implementing it in a full system. This includes work on a mobile app that can be used on smart phones to support fetal heart monitoring. </p><p>They have a provisional joint patent on the Lullaby algorithm with the University of California, Irvine, and have teamed up with a sponsoring company, <a href="https://sensoriis.com/" target="_blank">Sensoriis</a>, to produce a novel fetal cardiac-monitoring system that uses it. </p>]]></description><pubDate>Thu, 22 Sep 2022 18:43:44 +0000</pubDate><guid>https://spectrum.ieee.org/pregnancy-heartbeat-monitor-smartphone</guid><category>Pregnancy</category><category>Ecg</category><category>Fetus</category><category>Journal watch</category><dc:creator>Michelle Hampson</dc:creator><media:content medium="image" type="image/jpeg" url="https://spectrum.ieee.org/media-library/a-smiling-pregnant-woman-sitting-on-a-couch-and-looking-at-her-phone.jpg?id=31802228&amp;width=980"></media:content></item><item><title>Dissolvable Optical Switches Control Neurons With Light</title><link>https://spectrum.ieee.org/brain-machine-interface-optogenetics</link><description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/brain-with-light-pulsating-into-it.jpg?id=31636751&width=1245&height=700&coordinates=0%2C235%2C0%2C235"/><br/><br/><p>Roughly two decades ago, a strategy called <a href="https://spectrum.ieee.org/deep-brain-stimulation" target="_self">optogenetics</a> emerged to control brain activity with lasers. It uses viruses to insert genes into cells that make them sensitive to light. Optogenetics has revolutionized neuroscience by giving researchers a precise way to excite or suppress brain circuits and shed light on what role they play in the brain. However, a key drawback of this work is that it usually only targets cells that are genetically modified to respond to light. Now scientists in China have developed a new way to control brain cells using light without this limitation, potentially greatly expanding the applications of this optical approach.<br/></p><p>Optogenetics has a number of advantages over previous methods of controlling neurons. Electrical techniques often prove bulky and invasive, triggering inflammation, while drugs often act slowly and imprecisely, with unwanted side effects. However, the fact that optogenetics works only on genetically modified cells has largely limited it to lab research.</p><p>In the new study, researchers experimented with thin-film single-crystal silicon diodes. When illuminated with lasers, the flexible photovoltaic devices could generate either positive or negative electric fields, depending on the polarity of the light.</p><p>In tests on lab-grown neurons, the silicon diodes could excite or inhibit neural activity, depending on their positive or negative voltage. In experiments on mice, the devices could also stimulate or silence neural activity in the hind leg and in the part of the brain that handles the sense of touch.</p><p>The researchers suggest these silicon films can be used in wireless, battery-free neuron stimulation by means of near-infrared light that can penetrate tissue. Potential applications include manipulating peripheral nerves for control of limb movements, the spinal cord for pain relief, the vagus nerve for treating epilepsy, and the retina for visual prosthetics, says study co-senior author Xing Sheng, a materials scientist and electrical engineer at <a href="https://www.ee.tsinghua.edu.cn/en/info/1076/1159.htm" target="_blank">Tsinghua University in Beijing</a>.</p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="multiple images spanning over days of film dissolving in mice bodies" class="rm-shortcode" data-rm-shortcode-id="41cbe6f08a5ba9e9654b6a3a8d72873d" data-rm-shortcode-name="rebelmouse-image" id="658ef" loading="lazy" src="https://spectrum.ieee.org/media-library/multiple-images-spanning-over-days-of-film-dissolving-in-mice-bodies.jpg?id=31636921&width=980"/>
<small class="image-media media-caption" placeholder="Add Photo Caption...">The top series of images shows the natural dissolution of a silicon film on PLLA–PTMC wrapped around the sciatic nerve of mice. The bottom series shows the natural dissolution of a silicon film on the brain cortex of mice. </small><small class="image-media media-photo-credit" placeholder="Add Photo Credit...">Xing Sheng</small></p><p>In addition, these devices are bioresorbable, meaning they naturally dissolve in the body. Therefore, brain surgery is not needed to extract them after they have accomplished any planned therapeutic goal.</p><p>“These days, brain-machine interfaces are very hot topics,” Sheng says. “However, most people focus on either the brain part—neuroscientists; or the machine part—electrical engineers. We really need more people to address the interface, which is the essential key.”</p><p>The scientists note they have not yet seen how their devices might help in models of disease. Currently, “We need to identify the most applicable scenario to use our devices and design the systems accordingly to satisfy the in vivo applications, and meet the standards for clinical grade implants,” Sheng says.</p><p>The researchers detailed <a href="https://www.nature.com/articles/s41551-022-00931-0" rel="noopener noreferrer" target="_blank">their findings</a> <a href="https://www.biorxiv.org/content/10.1101/2022.06.10.495723v1" rel="noopener noreferrer" target="_blank">online</a> 5 September in the journal <em>Nature Biomedical Engineering</em>.</p>]]></description><pubDate>Fri, 09 Sep 2022 15:16:16 +0000</pubDate><guid>https://spectrum.ieee.org/brain-machine-interface-optogenetics</guid><category>Optogenetics</category><category>Neurons</category><category>Brain-machine interface</category><category>Optical switch</category><category>Optoelectronics</category><dc:creator>Charles Q. Choi</dc:creator><media:content medium="image" type="image/jpeg" url="https://spectrum.ieee.org/media-library/brain-with-light-pulsating-into-it.jpg?id=31636751&amp;width=980"></media:content></item><item><title>E-Skin Sensors Go Chipless and Batteryless</title><link>https://spectrum.ieee.org/electronic-skin-chipless-batteryless</link><description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/illustration-of-a-golden-patch-on-a-forearm-a-red-ring-attached-to-gold-piping-hovers-above-it-with-colored-rings-radiating-be.jpg?id=31371138&width=1245&height=700&coordinates=0%2C530%2C0%2C530"/><br/><br/><p>Wearable sensors now often help keep track of vital signs, but these devices usually rely on bulky microchips and batteries. Now scientists have invented a new microscopically thin “electronic skin” that can wirelessly transmit data about the body’s heart rate and chemistry, all without chips or batteries.<br/></p><p>Recent advances in <a href="https://spectrum.ieee.org/laserprinted-polysilicon-transistors-on-paper" target="_self">flexible</a> and <a href="https://spectrum.ieee.org/stretchy-touchpad-could-find-use-in-gaming" target="_self">stretchable</a> circuits and sensors have enabled the emergence of <a href="https://spectrum.ieee.org/skin-circuits" target="_self">electronic skin</a>, or e-skin, which sticks onto the body like an electronic version of tape. These devices often find use as health-monitoring platforms to keep track of wellness and fitness.</p><p>In order for e-skin devices to find broader use in daily life, they need to communicate data wirelessly. However, this means e-skins typically rely on rigid microchips that limit flexibility and consume a lot of power.</p><p>Now scientists have devised new chipless, wireless electronic skins that “are very thin and imperceptible, because our e-skins do not use thick and rigid integrated-circuit chips,” says study cosenior author <a href="http://jeehwanlab.mit.edu/" target="_blank">Jeehwan Kim</a>, a materials scientist at MIT. “Also, whereas integrated-circuit chips generate a lot of heat because of high power consumption, our e-skins do not. Thus, our e-skins can be worn over long periods—for example, weeks—without causing discomfort or skin injury.”</p><p>The new electronic skin employs sensors that examine acoustic waves rippling across the surfaces of materials. Modern cellphones now each possess dozens of acoustic devices to manipulate these kinds of <a href="https://spectrum.ieee.org/acoustic-integrated-circuit" target="_self">surface acoustic waves</a>.</p><p>These sensors are made of pure single-crystalline gallium nitride membranes only 200 nanometers thick. These <a href="https://www.nature.com/articles/nature22053" target="_blank">extraordinarily thin</a> piezoelectric films can convert electric signals to sound waves and vice versa.</p><p>The scientists reasoned that each gallium nitride membrane would possess its own inherent vibration frequency that its piezoelectric nature would convert into an electrical signal, the frequency of which a smartphone wireless receiver could detect. Any change in the electronic skin’s physical condition would affect its mechanical vibrations, resulting in detectable changes to its electrical signals, all without the need for a chip or battery in the sensor.</p><p>In the new study, the researchers combined these gallium nitride membranes with gold, titanium, and other materials to help serve as the e-skin's antenna. They incorporated the device onto a silicone rubber patch just 20 micrometers thick, or about one-fifth the diameter of the average human hair.</p><p>In experiments, the scientists placed the e-skin on volunteers’ wrists and necks. They were able to monitor changes in the surface acoustic waves of the device related to pulse and heart rate, “which can be useful when tracking exercise and trying to detect heart abnormalities,” Kim says.</p><p>The researchers found e-skin can continuously monitor heart rate and pulse for about 17 hours per day for a week, demonstrating its wearable and reusable nature. Such wireless mechanical sensors could also find use in virtual reality and other entertainment applications that wirelessly detect motions of users, Kim says.</p><p>When the researchers paired the sensors with thin-membrane detectors, changing sodium levels on the skin could be sensed—for instance, when a volunteer held onto a heat pad and began to sweat. The electronic skin could be paired with other sensors to help analyze other chemicals, such as glucose to help monitor diabetes, or the stress hormone cortisol to keep track of depression and panic disorders, Kim says.</p><p>In addition, the scientists found that the sensors were sensitive to ultraviolet light. “Ultraviolet light information can be used to track the exact amount of sun exposure and prevent sunburns, or too little exposure to sunlight that might lead to vitamin D deficiency,” Kim says.</p><p>The scientists detailed <a href="http://www.science.org/doi/10.1126/science.abn7325" rel="noopener noreferrer" target="_blank">their findings</a> in the 19 August issue of the journal <em>Science</em>.</p>]]></description><pubDate>Thu, 01 Sep 2022 14:52:12 +0000</pubDate><guid>https://spectrum.ieee.org/electronic-skin-chipless-batteryless</guid><category>E-skin</category><category>Wearable sensors</category><category>Flexible electronics</category><category>Stretchable electronics</category><category>Surface acoustic waves</category><category>Gallium nitride</category><category>Piezoelectric</category><category>Electronic skin</category><dc:creator>Charles Q. Choi</dc:creator><media:content medium="image" type="image/jpeg" url="https://spectrum.ieee.org/media-library/illustration-of-a-golden-patch-on-a-forearm-a-red-ring-attached-to-gold-piping-hovers-above-it-with-colored-rings-radiating-be.jpg?id=31371138&amp;width=980"></media:content></item><item><title>Brain Stimulation Improves Memory in Older Adults</title><link>https://spectrum.ieee.org/brain-stimulation-memory-improvement</link><description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/cartoon-drawing-of-a-human-head-with-electrodes-plugged-into-brain.jpg?id=31358441&width=1245&height=700&coordinates=0%2C39%2C0%2C39"/><br/><br/><p>Forgetfulness is natural, but as we get older, we tend to struggle more to remember things. Researchers from Boston University report that daily electrical brain stimulation for 20 minutes on four consecutive days shows memory improvements in seniors for at least one month. This noninvasive procedure was found to have benefits for both working memory and long-term memory.</p><p>For their study, the scientists used a technique called <a href="https://www.frontiersin.org/articles/10.3389/fnhum.2013.00279/full" target="_blank">transcranial alternating current stimulation</a> to target specific parts of the brain with electric pulses. They invited 150 people aged 65 to 88 to their laboratory, who were asked to memorize and recall lists of English words. As they did so, electric current was delivered through electrodes in a cap worn by the participants. This current, says neuroscientist <a href="https://www.bu.edu/psych/profile/robert-m-g-reinhart-phd/" rel="noopener noreferrer" target="_blank"><u>Robert Reinhart</u></a>, who led the study, strengthens the natural biological processes of the brain during memorizing and recall.</p><p>“People performed this process for 20 minutes each day on four days, and we then tested their ability to memorize and recall words one month after, without the electrical energy,” Reinhart reports. The participants showed memory improvements by the second or third day. “[They] could remember and recall more words than usual, and this improvement could be seen even after one month.” </p><p>They also noted that participants who started out with the lowest cognitive performance were the ones who benefited the most from brain stimulation. The results of their study was published in <a href="https://www.nature.com/articles/s41593-022-01132-3" rel="noopener noreferrer" target="_blank"><u><em>Nature Neuroscience</em></u></a>.</p><p>Reinhart and colleagues targeted specific regions of the brain for <a href="https://www.psychologytoday.com/us/basics/memory/working-memory" rel="noopener noreferrer" target="_blank"><u>working memory</u></a> (temporarily holding a limited amount of information at the ready) and <a href="https://www.verywellmind.com/what-is-long-term-memory-2795347" rel="noopener noreferrer" target="_blank"><u>long-term memory</u></a> (information held over a long period of time), based on available research. They found that low-frequency (4 hertz) pulses in the parietal cortex improved recall of words from the end of the lists, that is, for working memory. This type of memory showed particular improvements on days 3 and 4, and also one month later. For long-term memory, they targeted the <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8165195/#:~:text=Traditionally%2C%20the%20dorsolateral%20prefrontal%20cortex,Hart%20et%20al.%2C%202013%3B" target="_blank">dorsolateral prefrontal cortex</a> at a higher frequency, 60 Hz. In this case, the participants showed better recall of words at the beginning of the lists on days 2, 3, and 4, and after one month.</p><p>These results suggest that storing information for short versus long periods of time require distinct rhythmic activity patterns in different brain regions, Reinhart says. “Critically, we need to take both anatomical location in the brain and the frequency of rhythmic activity in that location into account when studying memory function for a specific time scale.” </p><p>There will be over 2.1 billion people over the age of 60 by 2050, according to <a href="https://www.who.int/news-room/fact-sheets/detail/ageing-and-health" rel="noopener noreferrer" target="_blank"><u>World Health Organization estimates</u></a>, more than doubling from 2020 figures. In this same period, the global population of 80-pluses will triple to 426 million. <a href="https://www.betteraging.com/cognitive-aging/when-does-cognitive-decline-begin/" rel="noopener noreferrer" target="_blank"><u>Cognitive decline</u></a> is an inevitability of age, but as life expectancies increase worldwide—from 47 years in 1950 to 73 in 2020—scientists have been looking at technologies to sustainably enhance or protect memory function in older adults.</p><p>Emerging research also suggests that COVID-19, particularly long COVID, may lead to memory impairments in some people, Reinhart points out. “Given that the world already faces heavy burdens due to memory decline in a rapidly aging population," he says, “Our study contributes…by using noninvasive brain stimulation technology to improve memory function.”</p><p>The study also contributes to the debate about theoretical models of <a href="https://www.sciencedirect.com/topics/neuroscience/free-recall" rel="noopener noreferrer" target="_blank"><u>free recall</u></a>. “One family of theories suggests two distinct memory stores dedicated to short-term and long-term storage of information,” he explains. “A more recent family of theories…[instead] considers other cognitive abilities, such as attention, to explain memory phenomena.” His team’s findings suggest that the first family of theories cannot yet be conclusively rejected, and suggests further avenues for study to test ideas from the two categories of theories against each other.</p><p>Though their results were promising, Reinhart admits there are still gaps to be addressed. “We need to identify whether these memory improvements generalize to different kinds of memories, such as, visual or spatial memories, and whether these can be observed in tasks other than free recall. We also need to examine whether these improvements sustain for longer periods of time and whether they produce meaningful improvements in people’s real-world functioning.” Further research will also be needed to ascertain if this can help individuals with brain disorders and at risk for dementia.</p>]]></description><pubDate>Wed, 31 Aug 2022 13:30:53 +0000</pubDate><guid>https://spectrum.ieee.org/brain-stimulation-memory-improvement</guid><category>Biomedical</category><category>Biomedical electronics</category><category>Brain stimulation</category><dc:creator>Payal Dhar</dc:creator><media:content medium="image" type="image/jpeg" url="https://spectrum.ieee.org/media-library/cartoon-drawing-of-a-human-head-with-electrodes-plugged-into-brain.jpg?id=31358441&amp;width=980"></media:content></item><item><title>The Superconducting Shields Behind MRIs’ Triumph</title><link>https://spectrum.ieee.org/the-superconducting-shields-behind-mris</link><description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/looking-through-the-opening-of-an-mri-machine.jpg?id=31214851&width=1245&height=700&coordinates=77%2C0%2C78%2C0"/><br/><br/><p>Magnetic resonance imaging (MRI) is a common strategy physicians use to diagnose diseases such as cancer. The patient is placed on a table that slides into the bore of a scanner, which contains a strong magnet and various coils. The machine uses the resulting magnetic field and radio waves to create images of the patient’s insides.</p><p>Full-body MRI scanners were first used clinically in hospitals in the early 1980s, but they were bulky and expensive. Because the magnetic field produced by the machines sometimes strayed outside the room where the MRI scanner was located, safety measures had to be implemented. The stray field was dangerous as it could affect pacemakers and other metal medical devices. </p><hr/><p>To confine the magnetic field to the room, <a href="https://prizmedimaging.com/pages/mri-shielding-and-rf-shield-enclosure-design-considerations" rel="noopener noreferrer" target="_blank">iron sheets</a> were placed on the walls, ceiling, and floors. The strategy, known as <em>passive shielding</em>, increased construction costs and the time it took to install a scanner, however. The method also restricted where the machines could be built and used.</p><p>The addition of secondary actively shielded superconducting magnets in MRI systems in 1986 eliminated the need for iron sheets. The enhancement, unveiled by a team of scientists at Oxford Instruments (now part of <a href="https://www.siemens-healthineers.com/en-uk/magnetic-resonance-imaging/siemens-magnet-technology" rel="noopener noreferrer" target="_blank">Siemens</a>), in Oxfordshire, England, lowered installation costs and shortened construction times.</p><p>The IEEE commemorated the magnets as an IEEE Milestone during a ceremony on 17 June at the Siemens Oxfordshire facility.</p><p>“The magnets made MRI widely available,” says <a href="https://www.westminster.ac.uk/about-us/our-people/directory/kale-izzet" rel="noopener noreferrer" target="_blank">Izzet Kale</a>. The IEEE member is chair of the <a href="https://www.ieee-ukandireland.org/" rel="noopener noreferrer" target="_blank">IEEE U.K. and Ireland Section</a>, which sponsored the Milestone nomination.</p><h2>Magnetic fields and radio waves</h2><p>Images produced by MRI scanners aren’t really images in the usual sense. They are constructed by a computer using magnetic fields and radio waves.</p><p>Nearly 70 percent of the human body consists of water, and each water molecule has two hydrogen protons. The protons’ magnetic moments (the measure of its tendency to align with a magnetic field) are usually oriented in various directions, but when they are subjected to a strong magnetic field, the protons become polarized and <a href="https://global.canon/en/technology/support28.html" rel="noopener noreferrer" target="_blank">point in the same direction</a>, according to an <a href="https://global.canon/en/technology/support28.html" rel="noopener noreferrer" target="_blank">article about MRI</a> on <a href="https://us.medical.canon/about/" rel="noopener noreferrer" target="_blank">Canon Medical</a>. The application of radio waves at the right frequency makes the protons’ orientation oscillate. When the radio waves are turned off, the protons revert to their prior state and emit a signal (also a radio wave). The interaction is magnetic resonance.</p><p>The strength of the magnetic field produced by an MRI machine can be altered using three sets of gradient electric coils that are made of copper or aluminum, as explained in an <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1121941/" rel="noopener noreferrer" target="_blank">article</a> published by the U.S. <a href="https://www.ncbi.nlm.nih.gov/" rel="noopener noreferrer" target="_blank">National Library of Medicine</a>. <a href="https://mriquestions.com/how-to-reduce-fringe.html" rel="noopener noreferrer" target="_blank">Gradient electric coils</a> are loops of wire or thin conductive sheets that are located on the innermost part of the scanner’s tube. When current passes through the coils, a secondary magnetic field, or gradient field, is created. The gradient field slightly distorts the main magnetic field and modifies its strength.</p><p>Protons in different areas of the patient’s body will resonate at different frequencies depending on how strong the magnetic field is. Receiver coils in the scanner tube improve the detection of the emitted signal.</p><p>MRI scanners use those signals to produce images, showing differences in the way protons react.</p><h2>Making MRI a staple of medical diagnostics</h2><p>When MRI scanners were introduced in hospitals, up to 40 tonnes of iron were required to prevent the external magnetic field from straying beyond the room, according to the <a href="https://ieeemilestones.ethw.org/w/images/2/21/US4587504.pdf" rel="noopener noreferrer" target="_blank">actively shielded superconducting magnets’ patent</a>. But the extra safety measures made installing a scanner more expensive and difficult because the machine often had to be built in a freestanding building or in the hospital’s basement.</p><p>To help lower the cost and make it easier to install scanners, four Oxford Instruments scientists—John Bird, Frank Davis, IEEE Member <a href="https://indico.cern.ch/event/445667/contributions/2654717/attachments/1516432/2366717/Or20-01_DGH_MT25_Memorial_final_.pdf" rel="noopener noreferrer" target="_blank">David Hawksworth</a>, and John Woodgate—in 1986 enhanced the scanner with a second set of actively shielded superconducting magnets. Bird was the project’s lead engineer, Davis was the company’s technical director, Hawksworth was its engineering director, and Woodgate was the managing director.</p><p class="pull-quote">“Actively shielded superconducting magnets made MRI widely available.”</p><p>They created secondary electromagnets that, like the primary ones, operate in a superconducting state: they have no resistance to the flow of an electrical current and can carry large currents without overheating. The electromagnets were forced into a superconducting state by being continually bathed in liquid helium at minus 269.1 °C, according to an <a href="https://ieeemilestones.ethw.org/Milestone-Proposal:Active_shielding_of_superconducting_magnets" rel="noopener noreferrer" target="_blank">entry about the Milestone</a> on the <a href="https://ethw.org/Main_Page" rel="noopener noreferrer" target="_blank">Engineering and Technology History Wiki</a>.</p><p>The magnets are made of two coils of wire, either of niobium and titanium or niobium and tin. The coils are embedded in copper.</p><p>An electrical current is passed through the coils, each producing its own magnetic field. The coils are oriented so that the magnetic fields they produce oppose each other, according to the technology’s patent.</p><p>If, for example, the first coil produces a magnetic field of 2 Teslas and the second coil generates a field that’s 0.5 T, it reduces the strength of the overall magnetic field to 1.5 T. The Tesla is the unit of measurement of a magnetic field’s magnitude.</p><p>Although the strength of the scanner’s magnetic field is reduced by the active shielding, it keeps the stray magnetic field inside the room, the developers noted in their patent application.</p><p>Thanks to actively shielded superconducting magnets, MRI is now a fundamental diagnostic tool “on which modern medicine depends,” Kale says. “Active shielding was a key enabler to MRI becoming so widespread and important.”</p><p>Administered by the <a href="http://www.ieee.org/about/history_center/index.html" rel="noopener noreferrer" target="_blank">IEEE History Center</a> and <a href="https://www.ieeefoundation.org/donate_history" rel="noopener noreferrer" target="_blank">supported by donors</a>, the Milestone program recognizes outstanding technical developments around the world. The magnets’ Milestone plaque, which is to be displayed inside the Siemens Magnet Technology building in the Eynsham section of Oxfordshire reads:</p><p><em>“At this site, the first actively shielded superconducting magnets for diagnostic magnetic resonance imaging (MRI) use were conceived, designed, and produced. Active shielding reduced the size, weight, and installed cost of MRI systems, allowing them to be more easily transported and advantageously located, thereby benefiting advanced medical diagnosis worldwide.”</em></p>]]></description><pubDate>Thu, 25 Aug 2022 18:00:00 +0000</pubDate><guid>https://spectrum.ieee.org/the-superconducting-shields-behind-mris</guid><category>Ieee history</category><category>Ieee news</category><category>Ieee milestone</category><category>Biomedical engineering</category><category>Mri</category><category>Type:ti</category><dc:creator>Joanna Goodrich</dc:creator><media:content medium="image" type="image/jpeg" url="https://spectrum.ieee.org/media-library/looking-through-the-opening-of-an-mri-machine.jpg?id=31214851&amp;width=980"></media:content></item><item><title>Dead Pig’s Restored Organs Give Hope for Transplants</title><link>https://spectrum.ieee.org/expired-pigs-restored-organs-give-hope-for-transplants</link><description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/rendering-of-a-heart-liver-and-kidneys-with-tubes-of-red-liquid-moving-through-them.jpg?id=31203626&width=1245&height=700&coordinates=0%2C384%2C0%2C385"/><br/><br/><p>After animals die, rapid biological and chemical processes begin to destroy cells and organs. Previous research on pig brains showed that a treatment the researchers called<a href="https://www.nature.com/articles/s41586-019-1099-1" rel="noopener noreferrer" target="_blank"> BrainEx</a> could slow or reverse some of these processes. Now, the team has shown that a modified version of the previous technology, called OrganEx, can create some of the same effects when applied to the entire body of a pig, reversing the deterioration of cells in the liver, heart, kidneys, and other organs after death. Though the preliminary research is far from being used with humans, the researchers say that it could eventually help keep organs viable for donations for longer after an organ donor dies. The research also raises a number of ethical questions, from the welfare of animals to the future allocation of medical resources.</p><p>“We have shown that certain cellular functions can be restored in the brain following several hours after cessation of blood flow,” said authors<a href="https://medicine.yale.edu/profile/david_andrijevic/" rel="noopener noreferrer" target="_blank"> Dr. David Andrijevic</a>,<a href="https://medicine.yale.edu/profile/zvonimir_vrselja/" rel="noopener noreferrer" target="_blank"> Zvonimir Vrselja</a>, and<a href="https://medicine.yale.edu/profile/nenad_sestan/" rel="noopener noreferrer" target="_blank"> Dr. Nenad Sestan</a>, of Yale University’s department of neuroscience via email. “We wanted to see whether the same observations could also be seen across multiple vital organs in the whole body.”</p><p>Researchers first induced cardiac arrest in anesthetized pigs. Then, they waited one hour before applying their system to the pigs’ bodies. OrganEx is a two-part system, including a device similar to a<a href="https://www.mayoclinic.org/tests-procedures/ecmo/about/pac-20484615#:~:text=Overview,to%20tissues%20in%20the%20body." rel="noopener noreferrer" target="_blank"> heart-lung machine</a> that's used to keep patients alive during major heart surgery. The device helps to restore blood circulation and distribute the second part of the technology, a special solution containing ingredients designed to protect cells and restore some cell and organ function. These ingredients include an artificial-oxygen-carrier similar to hemoglobin, amino acids, vitamins, and over 13 drugs meant to reduce inflammation and cell death.</p><p>Researchers found that the OrganEx process helped preserve the structure of organs and cells. In addition, they found, many revived organ cells worked similarly to cells in living pigs. These cells—including cells in the heart, liver, and kidneys—also had genetic signatures showing that they were repairing themselves.</p><p>According to <a href="https://www.ucladdrcc.med.ucla.edu/members/members/jerzy-kupiec-weglinski-phd" target="_blank">Jerzy Kupiec-Weglinski</a>, a professor of surgery, pathology, and laboratory medicine at the David Geffen School of Medicine at the University of California, Los Angeles, “the ‘resurrection’ of the brain” under OrganEx’s 6-hour-long treatment is “most striking.” The accomplishment is all the more remarkable, he says, for the hour postmortem that the tissue had been deprived of oxygen. <br/></p><p>The OrganEx treatment preserved the cellular structure of brain cells, and even some electrical activity in the brain, though nowhere near the amount of activity that would mean the pigs were conscious. The pigs also had some sporadic movements that the researchers said they do not completely understand.<br/></p><p>OrganEx is still in the early stages of testing and development and would need to go through more stages of animal research as well as the clinical trial process before it might be used in humans. But, the study’s authors write, the technology ultimately promises to extend the time after death that organs are viable for transplantation.</p><p>“The lack of donor organs is the major problem in our field, and people are dying while waiting for the life-saving organ transplant,” said Kupiec-Weglinski via email. (He is also director of the Dumont-UCLA Transplantation Research Center.) </p><p>The OrganEx research also raises a number of ethical questions, including redefining what death is, says<a href="https://ethics.emory.edu/who-we-are/our-people/director.html" target="_blank"> Paul Root Wolpe</a>, a bioethicist and director of the Center for Ethics at Emory University.</p><p>“Death is the cessation of organized metabolic activity,” he says. “If this process begins to reanimate metabolic activity, then you really are talking about the very, very early first rudimentary possible steps of reversing death.” If researchers were able to restore more activity in the brain, he notes, it could also become difficult to determine if the animals are conscious. <a href="https://www.scientificamerican.com/article/how-can-we-tell-if-a-comatose-patient-is-conscious/" target="_blank">Research on coma patients</a> has shown that we don’t always know if humans are conscious based on brain activity alone.</p><p>Future use of the new technology could also raise questions about the use of medical resources, says<a href="https://devcell.bio.uci.edu/faculty/maksim-plikus/" rel="noopener noreferrer" target="_blank"> Maksim Plikus</a>, a professor of developmental biology at the University of California, Irvine, who was not involved with the study. Right now, people who are brain-dead are sometimes left on life support, even if there is minimal chance of recovery, draining valuable medical resources. If such technologies could one day restore organ function—though not necessarily brain function—in someone who is clinically dead, this dilemma could become more common, he says.</p><p>For their part, the Yale team doesn’t view their research, published this month in the journal<a href="https://www.nature.com/articles/s41586-022-05016-1" rel="noopener noreferrer" target="_blank"> <em>Nature</em></a>, as redefining death.</p><p>“In our work, we are more focused [on] cellular and organ recovery,” the authors said. “That is what we would like to continue focusing on in the future.”</p>]]></description><pubDate>Thu, 25 Aug 2022 13:00:00 +0000</pubDate><guid>https://spectrum.ieee.org/expired-pigs-restored-organs-give-hope-for-transplants</guid><category>Transplants</category><category>Life extension</category><dc:creator>Rebecca Sohn</dc:creator><media:content medium="image" type="image/jpeg" url="https://spectrum.ieee.org/media-library/rendering-of-a-heart-liver-and-kidneys-with-tubes-of-red-liquid-moving-through-them.jpg?id=31203626&amp;width=980"></media:content></item><item><title>A Self-Powered HMI That’s Also Waterproof</title><link>https://spectrum.ieee.org/a-self-powered-waterproof-hmi</link><description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/a-hand-covered-in-water-droplets-shows-a-square-sheet-with-4-circular-sensors-affixed-to-the-top-of-the-hand.jpg?id=31169800&width=1245&height=700&coordinates=0%2C196%2C0%2C197"/><br/><br/><p>Over the past few decades, human-machine interface (HMI) technologies, especially driven by the demands of <a href="https://spectrum.ieee.org/tag/wearables" target="_self"><u>wearables</u></a>, have progressed rapidly—into smaller, lighter, more efficient, more robust forms. Today, we also have various self-powered HMIs, using <a href="https://spectrum.ieee.org/concussion-diagnosis-neck-patch" target="_self"><u>piezoelectricity</u></a> and triboelectricity, for example, for power generation. Despite these advances, most wearable HMIs still remain relatively defenseless to moisture, such as sweating and weather conditions.</p><p>To address this issue, a research team at the Samueli School of Engineering at the University of California, Los Angeles, have come up with a prototype of a waterproof, flexible, and low-cost skin-integrated HMI. The device comprises a magnetoelastic sensor array that converts ambient biomechanical motion into electrical signals. Their <a href="https://aip.scitation.org/doi/10.1063/5.0094289" rel="noopener noreferrer" target="_blank"><u>study</u></a> has been published in <em>Applied Physics Reviews</em>.</p><p>The device is intrinsically waterproof, biocompatible, and able to convert the force induced by pressing a finger on it into a continuous electrical signal. The team demonstrated this by controlling a music player and turning an electric lamp on and off. They tested it in a variety of real-world conditions as well, including in a water spray, in heavy rain, and during vigorous physical activity.</p><p>The researchers, lead by <a href="https://samueli.ucla.edu/people/jun-chen/" rel="noopener noreferrer" target="_blank"><u>Jun Chen</u></a> of UCLA’s <a href="https://www.junchenlab.com/" rel="noopener noreferrer" target="_blank"><u>Wearable Bioelectronics Research Group</u></a>, used what is known as the magnetoelastic effect (also known as inverse magnetorestriction), discovered in the 1860s, describing the variation in magnetization of a material under mechanical stress. In fact, the current study expands upon the group’s earlier work demonstrating the magnetoelastic effect in a soft polymer system.</p><p>The effect is traditionally observed in rigid metals and metal alloys, Chen says, but in 2021, the researchers observed the effect in his lab, in a <a href="https://www.ept.ca/2021/10/bioengineers-develop-new-class-of-human-powered-bioelectronics/" rel="noopener noreferrer" target="_blank">soft system</a> composed of magnets ranging in size from micro to nano and a polymer matrix. “[It showed] a measured magnetoelastic effect with a five times enhancement compared to that in metals and metal alloys.” As a result, they dubbed it the “<a href="https://www.bioeng.ucla.edu/giant-magnetoelastic-effect-in-soft-systems-for-bioelectronics/" rel="noopener noreferrer" target="_blank"><u>giant magnetoelastic effect</u></a>.” Speaking of their current work, he adds, “we harnessed this discovery to develop a fundamentally new and wearable HMI.”</p><p>The prototype was a 4-by-4-centimeter array comprising two components: a layer of nanomagnets in a porous silicone rubber matrix that converts biomechanical pressure (touch of a finger) into a magnetic response; and a magnetic induction layer of patterned liquid metal coils. The latter responds to the magnetic variations and generates electricity (electromagnetic induction).</p><p>“In this way, [our] device works in a self-powered manner,” Chen says. “Compared with conventional HMI devices, which are non-self-powered, our device will [result in] much less power consumption.”</p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="Two fingers strecth the magnetoelastic HMI out." class="rm-shortcode" data-rm-shortcode-id="8d47d3443fb1c221b7f0a3f6dd009b5b" data-rm-shortcode-name="rebelmouse-image" id="b5589" loading="lazy" src="https://spectrum.ieee.org/media-library/two-fingers-strecth-the-magnetoelastic-hmi-out.jpg?id=31169808&width=980"/>
<small class="image-media media-photo-credit" placeholder="Add Photo Credit...">Jun Chen Research Group/UCLA</small></p><p>The fabrication processes involved in making magnetoelastic HMI devices are straightforward, Chen says. The research team used methods like 3D printing, the reverse-mold process, and laser patterning, but, he adds, costs can be further reduced by exploring more economical range of micromagnets to nanomagnets and polymer-matrix materials, or replacing the liquid metal coils layer with a fine-design solid conductive wire layer that is suitable for large-scale fabrication.</p><p>The material was flexible, elastic, and durable, generating stable power even when rolled, folded, and stretched.  Additionally, the magnetic field was not particularly affected by the device being wet. It was unperturbed by a strain of up to 150 percent, and exhibited wide pressure sensitivity as well as a response time of 0.2 seconds at a 1-hertz frequency. These characteristics  make it conducive to controlling electronic devices in real time. In their demonstration, the researchers integrated a circuit with buttons to operate a desk lamp and a music player.</p><p>Chen is interested in commercializing the technology. “Since the devices are soft, wearable, and biocompatible, [they] could be widely adopted for HMI applications,” he says. Among the possible uses are mechanosensitive electronics for electronic skins and soft actuators. He also foresees applications in virtual platforms. “Another appealing potential application is for body motion sensing, in which it can operate as a self-powered stretchable strain sensor, capturing the motion of limbs, muscles, and vital-sign signals for lifestyle, fitness, and health-related applications,” he adds.</p><p>Meanwhile, Chen notes, the fundamental science behind the technology needs more basic research so that scientists and engineers can develop a deeper understanding of its attributes and physical limits. He would also like to work on the voltage output: “Faraday’s law [says] the output voltage is linearly proportional to the number of the coils and the variation of total magnetic flux through the coil. Therefore, one possible direction [of research is] more advanced fabrication techniques to increase the magnetomechanical coupling factor and the number of coils.”</p>]]></description><pubDate>Tue, 23 Aug 2022 14:27:13 +0000</pubDate><guid>https://spectrum.ieee.org/a-self-powered-waterproof-hmi</guid><category>Wearables</category><category>Biomedical</category><category>Wearable devices</category><dc:creator>Payal Dhar</dc:creator><media:content medium="image" type="image/jpeg" url="https://spectrum.ieee.org/media-library/a-hand-covered-in-water-droplets-shows-a-square-sheet-with-4-circular-sensors-affixed-to-the-top-of-the-hand.jpg?id=31169800&amp;width=980"></media:content></item><item><title>Stretchable Artificial Nerves Help Restore Motion in Mice</title><link>https://spectrum.ieee.org/artificial-nerves</link><description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/illustration-of-a-paralyzed-mouse-and-a-moving-mouse.jpg?id=30836078&width=1245&height=700&coordinates=104%2C0%2C105%2C0"/><br/><br/><p>Conventional neuroprosthetic devices that aim to help patients bypass nerve damage are often rigid and power hungry. Now scientists have developed stretchable artificial nerves that helped paralyzed mice run on a treadmill and kick a ball while consuming less than one-hundredth of the power of a typical microprocessor. The scientists suggest these artificial nerves may one day be used in the human body.<br/></p><p>To help restore movement to patients who have suffered nerve damage from injuries or diseases, scientists are researching neuroprosthetic devices that can help relay signals from the brain to muscles or nerves. However, these systems often face a number of critical limitations, says study co–senior author <a href="https://www.pnel.snu.ac.kr/professor-intro" target="_blank">Tae-Woo Lee</a>, a materials scientist at Seoul National University.</p><hr/><p>For example, <a data-linked-post="2650231620" href="https://spectrum.ieee.org/progress-toward-a-brain-implant-for-the-blind" target="_blank">conventional neuroprosthetic systems</a> often depend on power-hungry external computing systems. They also typically stimulate the body with electric pulses of constant strength that abruptly increase and decrease in magnitude, “which cause drastic contraction of muscles that make patients uncomfortable,” Lee says.</p><p>To help generate more natural, comfortable movements, conventional neuroprosthetic systems may add voltage ramping during the start and end of electrical stimulation. However, this involves additional devices known as function generators that are typically rigid and bulky, Lee says, making them a poor fit for the human body.</p><p>In the new study, the researchers developed highly stretchable electronic nerves that mimic real nerves. Like real nerves, these artificial nerves can deliver electric signals that gradually ramp up and down in strength. These artificial neuroprosthetics also consume only about 1/150 of the power of a typical microprocessor.</p><p>The new device consists of a stretchable organic semiconducting nanowire transistor that electrically stimulates muscles using soft, elastic hydrogel electrodes. This bioinspired or “biomimetic” device acts like an artificial synapse, a junction that links neurons together in the human body.</p><p>The device is coupled via an ion gel to a carbon nanotube sensor that detects strain. This serves as an artificial version of a proprioceptor, a sensor that receives signals from within the body to help it keep track of its position and movements. The researchers used this artificial proprioceptor to give real-time feedback to the electronic nerve. This helped keep the artificial nerve from overstimulating and overstraining mouse leg muscles, all without the need of external computers to control the movements.</p><p>In the new study, the researchers experimented with mice they anesthetized to paralyze their muscles in order to mimic injuries or diseases targeting nerves. They found they could use their artificial nerves and proprioceptors to generate coordinated smooth leg movements, including walking and running on a treadmill or kicking a ball. They also showed they could use the neuroprosthetics to move the legs of the mice with electrical signals recorded from the rodents’ brains.</p><p>“Our work is the first example of delivering biological neural signals through biomimetic electronic nerves to biological organs,” Lee says. “Through this, it seems possible to present new solutions and strategies for nerve damage in humans such as spinal-cord injury, peripheral nerve damage, and neurological damage such as Lou Gehrig’s, Parkinson’s, and Huntington’s disease.”</p><p>In addition to potential medical applications, “the source technology of the stretchable artificial nerve may be applied to various medical wearable technologies,” says study co–senior author <a href="https://baogroup.stanford.edu/people/zhenan-bao" target="_blank">Zhenan Bao</a>, a materials chemist at Stanford University, in California.</p><p>The scientists detailed <a href="https://www.nature.com/articles/s41551-022-00918-x" target="_blank">their findings</a> online 15 August in the journal <em>Nature Biomedical Engineering</em>.</p>]]></description><pubDate>Mon, 15 Aug 2022 15:30:00 +0000</pubDate><guid>https://spectrum.ieee.org/artificial-nerves</guid><category>Nerve</category><category>Nanowire</category><category>Biomimetics</category><category>Carbon nanotubes</category><category>Neuroprosthetics</category><dc:creator>Charles Q. Choi</dc:creator><media:content medium="image" type="image/jpeg" url="https://spectrum.ieee.org/media-library/illustration-of-a-paralyzed-mouse-and-a-moving-mouse.jpg?id=30836078&amp;width=980"></media:content></item><item><title>GPT Language Model Spells Out New Proteins</title><link>https://spectrum.ieee.org/gpt-2-language-model-proteins</link><description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/3d-model-of-a-protein.jpg?id=30828183&width=1245&height=700&coordinates=0%2C187%2C0%2C188"/><br/><br/><p>Human languages have much in common with proteins, at least in terms of computational <a href="https://spectrum.ieee.org/alphafold-proves-that-ai-can-crack-fundamental-scientific-problems" target="_blank">modeling</a>. This has led research teams to apply novel methods from natural-language processing (NLP) to <a href="https://spectrum.ieee.org/ai-hallucinates-novel-proteins" target="_blank">protein design</a>. One of these—Birte Höcker’s <a href="https://www.proteindesign.uni-bayreuth.de/en/index.html" target="_blank">protein design lab</a> at Bayreuth University, in Germany—<a href="https://www.nature.com/articles/s41467-022-32007-7" rel="noopener noreferrer" target="_blank"><u>describes ProtGPT2</u></a>, a language model based on OpenAI’s <a href="https://openai.com/blog/tags/gpt-2/" target="_blank">GPT-2</a>, to generate novel protein sequences based on the principles of natural ones.</p><p>Just as letters from the alphabet form words and sentences, naturally occurring amino acids combine in different ways to form proteins. And protein sequences, just like natural languages, store structure and function in their amino-acid sequence with extreme efficiency.</p><p>ProtGPT2 is a deep, <a href="https://en.wikipedia.org/wiki/Unsupervised_learning" target="_blank">unsupervised model</a> that takes advantage of advances in <a href="https://towardsdatascience.com/a-deep-dive-into-the-transformer-architecture-the-development-of-transformer-models-acbdf7ca34e0" rel="noopener noreferrer" target="_blank"><u>transformer architecture</u></a> that have also caused rapid progress in NLP technologies. The architecture has two modules, explains <a href="https://de.linkedin.com/in/noeliaferruz" rel="noopener noreferrer" target="_blank"><u>Noelia Ferruz</u></a>, a coauthor of the paper and the person who trained ProtGPT2: one module to understand input text, and another that processes or generates new text. It was the second one, the decoder module that generates new text, that went into the development of ProtGPT2.</p><p class="pull-quote">Researchers have used GPT-2 to train a model to learn the protein “language,” generate stable proteins, and explore “dark” regions of protein space.</p><p>“At the time we created this model, there were many others that were using the first module,” she says, such as <a href="https://www.infoq.com/news/2022/08/meta-genomic-ai-esmfold/" rel="noopener noreferrer" target="_blank"><u>ESM</u></a>, <a href="https://pubmed.ncbi.nlm.nih.gov/34232869/" rel="noopener noreferrer" target="_blank"><u>ProtTrans</u></a>, and <a href="https://pubmed.ncbi.nlm.nih.gov/35020807/" rel="noopener noreferrer" target="_blank"><u>ProteinBERT</u></a>. “Ours was the first one publicly released at a time that was a decoder.” It was also the first time someone had directly applied GPT-2, she adds. </p><p>Ferruz herself is a big fan of <a href="https://huggingface.co/gpt2" rel="noopener noreferrer" target="_blank"><u>GPT-2</u></a>. “I find it very impressive that there was a model capable of writing English,” she says. This is a well-known transformer model that was pretrained on 40 gigabytes of Internet text in English in an unsupervised manner—that is, it used raw text with no human labeling—to generate the next word in sentences. The GPT-<em>x</em> series has been shown to efficiently produce long, coherent text, often indistinguishable from something written by a human—to the extent that <a href="https://www.analyticssteps.com/blogs/openais-gpt-2-generative-pre-trained-transformer-2-ai-that-is-too-dangerous-to-handle" rel="noopener noreferrer" target="_blank"><u>potential misuse</u></a> is a concern. </p><p>Given the capabilities of GPT-2, the Bayreuth researchers were optimistic about using it to train a model to learn the protein language, generate stable proteins, and also explore “dark” regions of the protein space. Ferruz trained ProtGPT2 on a data set of about 50 million nonannotated sequences across the whole protein space. To evaluate the model, the researchers compared a data set of 10,000 sequences generated by ProtGPT2 with a random set of 10,000 sequences from the training data set. </p><p class="pull-quote">“We could add labels, and potentially in the future start generating sequences with a specific function.”<br/>—Noelia Ferruz, University of Bayreuth, Germany</p><p>They found the sequences predicted by the model to be similar in secondary structure to naturally occurring proteins. ProtGPT2 can predict proteins that are stable and functional, although, Ferruz says, this will be verified by laboratory experiments on a set of 30 or so proteins in the coming months. ProtGPT2 also models proteins that do not occur in nature, opening up possibilities in the protein design space.</p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img class="rm-shortcode" data-rm-shortcode-id="f2c20f4b18acc7a2bd9c568a303b08a4" data-rm-shortcode-name="rebelmouse-image" id="69846" loading="lazy" src="https://spectrum.ieee.org/media-library/each-node-represents-a-sequence-two-nodes-are-linked-when-they-have-an-alignment-of-at-least-20-amino-acids-and-70-percent-u00a.jpg?id=30828240&width=980"/>
<small class="image-media media-caption" placeholder="Add Photo Caption...">Each node represents a sequence. Two nodes are linked when they have an alignment of at least 20 amino acids and 70 percent HHsearch probability. Colors depict the different SCOPe classes, and ProtGPT2 sequences are shown in white.</small><small class="image-media media-photo-credit" placeholder="Add Photo Credit...">University of Bayreuth/Nature Communications</small></p><p>The model can generate millions of proteins in minutes, says Ferruz. “Without further improvements, people could take the model, which is freely available, and fine-tune a set of sequences to produce more sequences in this region,” such as for antibiotics or vaccines. But also, she adds, with small modifications in the training process “we could add labels, and potentially in the future start generating sequences with a specific function.” This in turn has potential for uses in not just medical and biomedical fields but also in environmental sciences and more.</p><p>Ferruz acknowledges the rapid developments in the NLP space for the success of ProtGPT2, but also points out that this is an ever-changing space—“It’s crazy, all the things that have happened in the last 12 months.” At the moment, she and her colleagues are already writing a review of their work. “I trained this model over Christmas [2021],” she says, “and at the time, there was another model that had been described...but it wasn’t available.” Yet by this spring, she says, other models had been released.</p><p>ProtGPT2’s predicted sequences spanned new, rarely explored regions of protein structure and function. However, a few weeks ago, DeepMind released structures of over <a href="https://www.theguardian.com/technology/2022/jul/28/deepmind-uncovers-structure-of-200m-proteins-in-scientific-leap-forward" rel="noopener noreferrer" target="_blank"><u>200 million proteins</u></a>. “So I guess we don’t have that much of a dark proteome anymore,” Ferruz says. “But still, there are regions…that haven’t been explored.”</p><p>There is plenty of work ahead, though. “I would like to have control over the design process,” Ferruz adds. “We will need to take the sequence, predict the structure, and maybe predict the function if it has any….That will be very challenging.”</p>]]></description><pubDate>Fri, 12 Aug 2022 15:30:46 +0000</pubDate><guid>https://spectrum.ieee.org/gpt-2-language-model-proteins</guid><category>Artificial intelligence</category><category>Biomedical</category><category>Large language models</category><dc:creator>Payal Dhar</dc:creator><media:content medium="image" type="image/jpeg" url="https://spectrum.ieee.org/media-library/3d-model-of-a-protein.jpg?id=30828183&amp;width=980"></media:content></item><item><title>Detecting Earthquake Victims Through Walls</title><link>https://spectrum.ieee.org/dopppler-radar-detects-breath</link><description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/rescue-workers-looking-at-a-demolished-building.jpg?id=30827908&width=1245&height=700&coordinates=0%2C207%2C0%2C0"/><br/><br/><p><em>This article is part of our exclusive <a href="https://spectrum.ieee.org/collections/journal-watch/" rel="noopener noreferrer" target="_self">IEEE Journal Watch series</a> in partnership with IEEE Xplore.</em></p><p><em></em>When a disaster strikes and buildings collapse, it’s important to locate survivors as quickly as possible. A wide range of tech solutions are being explored to help make the search-and-rescue process quicker and more efficient—one example being mobile robots that can squeeze through small spaces. However, these robots aren’t helpful in situations where there’s a solid wall of concrete between the search-and-rescue team and the victim.</p><p>To address this issue, researchers from Taiwan and Indonesia have developed a novel technique that uses radar to detect a person’s breathing through a concrete wall. Experiments show that when a human is half a meter behind a concrete wall, their location can be detected with significant specificity: Any error is generally no more than about 3.375 centimeters wide of the actual position of the person’s chest cavity. The results the researchers obtained with their sensor system are described in a <a href="https://ieeexplore.ieee.org/document/9826342" target="_blank">paper</a> published 11 July  in <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=7361" rel="noopener noreferrer" target="_blank"><em>IEEE Sensors Journal</em></a>. </p><p>Aloysius Adya Pramudita is an associate professor at the Intelligent Sensing-IoT Centre, Telkom University, in Indonesia, who was involved in the research. He notes that Indonesia is located at the meeting point of several tectonic plates, making the country prone to disasters such as earthquakes. “Our research deals with postdisaster problems and activity,” he explains. “The objective is to reduce the loss [of life] and speed [up] recovery.”</p><p>Radar is often considered in search-and-rescue technology because of its ability to penetrate thick, dense objects like concrete. It’s also sensitive enough, via the Doppler effect, to detect the minute movements of a person’s chest as they breathe. However, when standard radar of the type clinicians use in medical offices hits the barriers and rubble between a rescue team and a disaster victim, this can alter the phase and amplitude of the signal, distorting it.</p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="person laying underneath table of bricks" class="rm-shortcode" data-rm-shortcode-id="41a2a6ba967c2361f109e72d938576ee" data-rm-shortcode-name="rebelmouse-image" id="969b9" loading="lazy" src="https://spectrum.ieee.org/media-library/person-laying-underneath-table-of-bricks.jpg?id=30842741&width=980"/>
<small class="image-media media-caption" placeholder="Add Photo Caption...">In this experimental setup by Aloysius Adya Pramudita and his colleagues, radar is used to detect a person's breathing through a concrete barrier.</small><small class="image-media media-photo-credit" placeholder="Add Photo Credit...">Aloysius Adya Pramudita/Telkom University</small></p><p>Pramudita’s team overcame this issue by developing a technique using frequency-modulated continuous-wave (FMCW) radar, which takes two measurements. The first measurement is used to estimate the signal distortion caused by a large object, while an algorithm adjusts for this distortion. The second radar measurement is then used to detect a person's breathing and estimate their position behind the object, taking into account the distortion endemic to the first measurement. In terms of hardware, the approach just needs a FMCW system, a mini-PC for computation, and a 12-volt lithium battery for power.</p><p>The researchers tested their approach with four volunteers, who lay behind a concrete wall with a thickness of either 20 or 40 cm. The results show that the thicker walls do attenuate the radar signal more; however, the system is still able to detect a person and determine their position to within a few centimeters. The data suggest that the maximum depth at which the proposed FMCW system can detect a victim behind a concrete wall is 3.28 meters. </p><p>“Our proposed method successfully overcomes the obstacle problem, and the breathing vital sign [indicating the presence] of the live victim can be detected,” says Pramudita, noting that his team is currently collaborating with industry partners to commercialize the technology. He says the team is also interested in integrating their radar approach with autonomous technology, such as robots and drones.</p><p>Adding this functionality to drones and robots “will support victim search efforts using the proposed radar system to reach the areas or locations that are difficult to reach by humans, and therefore will speed up the search process,” explains Pramudita. </p>]]></description><pubDate>Thu, 11 Aug 2022 17:49:32 +0000</pubDate><guid>https://spectrum.ieee.org/dopppler-radar-detects-breath</guid><category>Disaster response</category><category>Radar</category><category>Earthquake</category><category>Search and rescue</category><dc:creator>Michelle Hampson</dc:creator><media:content medium="image" type="image/jpeg" url="https://spectrum.ieee.org/media-library/rescue-workers-looking-at-a-demolished-building.jpg?id=30827908&amp;width=980"></media:content></item><item><title>No More Invasive Surgery—This Pacemaker Dissolves Instead</title><link>https://spectrum.ieee.org/dissolvable-pacemaker</link><description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/animated-gif-of-a-device-with-a-coil-on-one-end-dissolving-between-days-1-and-60.gif?id=30813679&width=1245&height=700&coordinates=0%2C70%2C0%2C71"/><br/><br/><p>After having cardiovascular surgery, many patients require a temporary pacemaker to help stabilize their heart rate. The device consists of a pulse generator, one or more insulated wires, and an electrode at the end of each wire.</p><p>The pulse generator—a metal case that contains electronic circuitry with a small computer and a battery—regulates the impulses sent to the heart. The wire is connected to the pulse generator on one end while the electrode is placed inside one of the heart’s chambers.</p><p>But there are several issues with temporary pacemakers: The generator limits the patient’s mobility, and the wires must be surgically removed, which can cause complications such as infection, dislodgment, torn or damaged tissues, bleeding, and blood clots.</p><hr/><p>Researchers have found that a dissolving pacemaker can make a real difference for patients. Last year a team of scientists at <a href="https://www.northwestern.edu/" rel="noopener noreferrer" target="_blank">Northwestern University</a>, in Evanston, Ill., developed such a device, which will allow patients to live without being tethered to external hardware. The dissolving pacemaker is 250 micrometers thick, weighs less than half a gram, and dissolves in the patient’s body, eliminating the need for surgical removal.</p><p>In May, the researchers introduced an upgraded, smart version of the pacemaker. It connects to a network of soft, flexible wearable sensors developed by the team. These sensors monitor various physiological functions to help determine when to pace the heart and at what rate. The pacing system is completely autonomous.</p><p>The device also releases an anti-inflammatory drug while it dissolves.</p><p>“When you implant any kind of foreign hardware into the human body, cells attack that object,” explains <a href="https://www.feinberg.northwestern.edu/faculty-profiles/az/profile.html?xid=54955" rel="noopener noreferrer" target="_blank">Igor Efimov</a>, a member of the development team and a professor of biomedical engineering at the university. He says that releasing the anti-inflammatory drug will stop the body from rejecting the pacemaker.</p><p>The device isn’t available for human use yet, but Efimov expects it to be available to patients in less than five years.</p><p>The pacemaker’s outer layer is made of a bioresorbable polyurethane. The material is thin, soft, and flexible, which were important factors to consider during development because the device is placed on the surface of a patient’s heart, says <a href="http://rogersgroup.northwestern.edu/" rel="noopener noreferrer" target="_blank">John Rogers</a>, who led the project. Rogers, an IEEE Fellow, is a professor of materials science and engineering, biomedical engineering, and neurological surgery at Northwestern.<br/></p><p>Encased in the bioresorbable polyurethane are the electronics. On one side there is a receiver antenna and on the other side there is a transmission coil. They are connected via a serpentine radio-frequency diode.</p><p>A small wireless patch is attached to the patient’s chest, directly above the pacemaker. Electrodes are located on the side of the patch that is in direct contact with the person’s skin. Inside the device there is a small battery and a transmission coil. The electrodes record an electrocardiogram (ECG) on the patient and help regulate impulses sent to the heart.</p><p>The transmission coils in the patch and the pacemaker couple wirelessly. An oscillating magnetic field produced by the battery induces current in the patch’s coil. The current is then passed into the coil in the pacemaker to power the device and control the heart’s pacing rate.</p><p>If the pacemaker detects that the patient’s heart rate drops below a certain rate, the device activates the transmission coil in the patch. This powers the pacemaker, allowing it to bring the patient’s heart rate back up to a healthy level.</p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="Close up of a tablet screen next to a person with two white devices affixed to their chest." class="rm-shortcode" data-rm-shortcode-id="c2199e13fb9080a3eb48971e2c278bf0" data-rm-shortcode-name="rebelmouse-image" id="61f1e" loading="lazy" src="https://spectrum.ieee.org/media-library/close-up-of-a-tablet-screen-next-to-a-person-with-two-white-devices-affixed-to-their-chest.jpg?id=30813688&width=980"/>
<small class="image-media media-caption" placeholder="Add Photo Caption...">A small wireless patch attached to the patient’s chest records an ECG, which is then sent to a mobile app and available for the patient’s doctor to monitor.</small><small class="image-media media-photo-credit" placeholder="Add Photo Credit...">Northwestern University</small></p><p>The receiver antenna inside the pacemaker collects data on the patient’s heart rate and sends it to a mobile app using <a data-linked-post="2650277409" href="https://spectrum.ieee.org/smart-tags-add-touch-controls-to-ordinary-objects" target="_blank">Near Field Communication protocols</a>—the same technology used in smartphones and RFID tags. The data is monitored by the patient’s doctor.</p><p>The process of dissolution starts immediately after the device is implanted. The bioresorbable polyurethane is the first material to dissolve.</p><p>Each device will be designed and made for individual patients. If a surgeon needs a patient’s pacemaker to last for two weeks, the team will design the device so it maintains its integrity for the required time period, Rogers says.</p><p>While it is possible to measure how fast a patient’s heart is beating solely based on ECG results, Rogers says, outside factors such as physical activity, the patient’s blood type, and their resting heart rate can affect the heart. So Rogers and his team developed a network of sensors that monitor the patient’s body temperature, oxygen levels, respiration, physical activity, muscle tone, and the heart’s electrical activity.</p><p>There are currently three units: one for the chest, the forehead, and the neck. The pacemaker’s system automatically analyzes the data collected by these sensors. If it detects abnormal cardiac rhythms, the pacemaker will change the impulse of the heart rate.</p><p>“If normal activity is regained, then it stops pacing,” Efimov explains. “This is important because if you stimulate the heart when it’s unnecessary, then you risk inducing arrhythmia.”</p>]]></description><pubDate>Wed, 10 Aug 2022 14:47:35 +0000</pubDate><guid>https://spectrum.ieee.org/dissolvable-pacemaker</guid><category>Biomedical electronics</category><category>Northwestern university</category><category>Pacemaker</category><category>Medical devices</category><dc:creator>Joanna Goodrich</dc:creator><media:content medium="image" type="image/gif" url="https://spectrum.ieee.org/media-library/animated-gif-of-a-device-with-a-coil-on-one-end-dissolving-between-days-1-and-60.gif?id=30813679&amp;width=980"></media:content></item><item><title>Ultrasound Stickers Look Inside the Body</title><link>https://spectrum.ieee.org/ultrasound-imaging</link><description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/close-up-of-a-square-rectangular-clear-device-affixed-to-an-arm.jpg?id=30454684&width=1245&height=700&coordinates=0%2C155%2C0%2C156"/><br/><br/><p>A wearable ultrasound sticker roughly the size of a postage stamp could help enable continuous medical imaging of internal organs for patients on the move, a new study finds.<br/></p><p><a href="https://spectrum.ieee.org/piezo-samarium" target="_blank">Ultrasound imaging</a> is one of the most common medical tools for scanning inside the body in <a href="https://spectrum.ieee.org/ultrasound-microscopy-helps-image-tiny-blood-vessels" target="_blank">a safe, noninvasive manner</a>. Currently, to image with ultrasound, first a liquid gel is applied to a patient’s skin that helps transmit ultrasound waves. Then an ultrasound probe, or transducer, is pressed against the gel.</p><p>Continuous long-term ultrasound imaging could help shed light on potentially vital changes in a patient’s health over days or even months. However, ultrasound imaging currently requires bulky, rigid equipment, making long-term monitoring difficult.</p><p>In addition, capturing ultrasound images demands highly trained sonographers to properly apply and orient the ultrasound probes onto a patient’s body. Practically speaking, and even just to avoid repetitive motion injuries, these practical restrictions often limit the length of ultrasound sessions. For patients who need long periods of imaging, some hospitals offer probes on robotic arms that can hold a transducer in place without tiring. However, the liquid ultrasound gel flows away and dries out over time, interrupting the sessions and producing less-than-ideal results.</p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="Animated gif shows gel being pressed against an arm by a device on the left, and on the right, a gloved finger pressing down on a contained gel device on the skin." class="rm-shortcode" data-rm-shortcode-id="0a0d51979abdc7d6abf86987fd19f4d8" data-rm-shortcode-name="rebelmouse-image" id="326f4" loading="lazy" src="https://spectrum.ieee.org/media-library/animated-gif-shows-gel-being-pressed-against-an-arm-by-a-device-on-the-left-and-on-the-right-a-gloved-finger-pressing-down-on.gif?id=30454695&width=980"/>
<small class="image-media media-caption" placeholder="Add Photo Caption...">In this animated image, the bioadhesive ultrasound (BAUS) device is compared with a conventional ultrasound probe with liquid hydrogel couplant.</small><small class="image-media media-photo-credit" placeholder="Add Photo Credit...">MIT</small></p><p>Recently scientists have explored stretchable ultrasound probes that can better conform  to a patient’s body for potential wearable applications. However, such designs have suffered from low resolution and poor image quality during body movements, among other problems.</p><p>Now scientists have developed an ultrasound sticker they say can overcome many of these challenges. They detailed <a href="http://www.science.org/doi/10.1126/science.abo2542" target="_blank">their findings</a> in the 29 July issue of the journal <em>Science</em>.</p><p>The new device consists of a thin, rigid scanner array possessing 400 ultrasound transducers per square centimeter. This array is coupled to a soft, durable, sticky layer that can bond onto skin. The entire sticker measures 3 millimeters thick and 2 square centimeters in size.</p><p>The device’s adhesive layer contains a soft <a href="https://spectrum.ieee.org/stretchy-touchpad-could-find-use-in-gaming" target="_blank">hydrogel</a>, a material similar to the absorbent stuffing inside disposable diapers. This hydrogel easily transmits sound waves, and unlike traditional ultrasound gels, is stretchy and elastic. The hydrogel is encapsulated between two thin rubbery layers that help keep the hydrogel wet so acoustic waves can pass through it.</p><p>In tests, the researchers had healthy volunteers wear the devices on various parts of their body, including the neck, chest, abdomen and arms. They also had the participants perform a variety of activities in the lab, such as sitting, standing, jogging, biking, weightlifting and drinking juice.</p><p>The devices stuck onto the skin of the volunteers and produced clear images of underlying structures for up to 48 hours. They could watch how the jugular vein widened after volunteers went from sitting or standing to a supine position; how the heart swelled after a half hour of exercise; how the lungs behaved during jogging and cycling; how the stomach distended and shrank as the volunteers drank juice that later flowed out; and how biceps became flooded with blood after lifting weights.</p><p>The image resolution of the bioadhesive ultrasound (BAUS) device “is on a similar level to point-of-care ultrasound,” says study senior author Xuanhe Zhao, a mechanical engineer at MIT. More work is needed to reach the performance of mature conventional ultrasound machines, he adds.</p><p>Although the stickers do continuously image the body with ultrasound waves, “the imaging frequency is low, such as one image per 30 minutes or 1 hour,” Zhao says. “Therefore, BAUS is safe for the body.”</p><p>Currently, the devices need to be connected with instruments that can translate their ultrasound data into images. Even with this tethered design, the researchers suggest the stickers could have a variety of applications. For instance, they can be applied to patients in the hospital, similar to heart-monitoring <a href="https://spectrum.ieee.org/skin-circuits" target="_self">EKG</a> stickers, and help continuously scan internal organs without requiring a technician to hold a probe in place for long stretches of time.</p><p>The scientists now seek to make wireless versions of their device. In addition, they are working on integrating data-processing circuitry and other components onto the stickers. Moreover, they are developing software algorithms based on artificial intelligence that can better interpret and diagnose the stickers’ images.</p><p>The ultimate goal are wearable ultrasound stickers, each designed for a different location on the body, that patients could take home from a doctor’s office or even buy at a pharmacy or get shipped to them. The patches could communicate with your cellphone, where AI algorithms could then automatically analyze the images on demand. Such a setup could, for example, help doctors continuously monitor the symptoms of possibly infected <a href="https://spectrum.ieee.org/covid-breathalyzers-could-transform-rapid-testing" target="_blank">COVID-19</a> patients at home with minimal exposure risk to medical staff, Zhao says. They might also help monitor the development of fetuses in the womb or the progression of tumors.</p><p>“Continuous monitoring and diagnosis of chronic conditions is a grand challenge in health care,” Zhao says. “We want to use wearable imaging with BAUS to address this challenge.”</p>]]></description><pubDate>Wed, 03 Aug 2022 18:22:56 +0000</pubDate><guid>https://spectrum.ieee.org/ultrasound-imaging</guid><category>Ultrasound transducer</category><category>Adhesive</category><category>Wearables</category><category>Wearable sensors</category><category>Wearable devices</category><category>Ultrasound</category><category>Covid-19</category><category>Ultrasound imaging</category><dc:creator>Charles Q. Choi</dc:creator><media:content medium="image" type="image/jpeg" url="https://spectrum.ieee.org/media-library/close-up-of-a-square-rectangular-clear-device-affixed-to-an-arm.jpg?id=30454684&amp;width=980"></media:content></item><item><title>Why Studying Bats Might Yield Insights into Human Life Extension</title><link>https://spectrum.ieee.org/a-bat-youve-never-heard-of-might-help-radically-extend-human-lifespans</link><description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/a-bat-in-flight-approaches-its-prey-a-katydid-on-a-rock.jpg?id=30453479&width=1245&height=700&coordinates=0%2C157%2C0%2C157"/><br/><br/><p>
	Few fields of endeavor have advanced as swiftly as bioinformatics over the past couple of decades. Just 25 years ago, the human genome was still largely a mystery. Then, in 2003, 
	<a href="https://www.rockefeller.edu/news/32087-the-human-genome-is-at-long-last-complete/" rel="noopener noreferrer" target="_blank">the first sequence</a> was announced, of about 92 percent of a human genome. That sequence cost some US $300 million dollars. Over the years, as the technology became more advanced and pervasive, the cost of sequencing declined. Nowadays, it’s possible to get a sequence <a href="https://sequencing.com/education-center/whole-genome-sequencing/whole-genome-sequencing-cost" rel="noopener noreferrer" target="_blank">for well under $1,000</a>. This price drop has triggered a revolution in the ability of doctors to identify a patient’s susceptibility to disease and also to prescribe effective treatments.
</p><p>
	Once the genome was sequenced, the enormous task of identifying the function of the many genes began. Most estimates of the number of protein-coding genes in the human genome are now in the range of 
	<a href="https://sandwalk.blogspot.com/2019/09/how-many-protein-coding-genes-in-human.html" rel="noopener noreferrer" target="_blank">19,000 to 21,000</a>, although some are considerably higher. And as many as a quarter of these genes remain of largely uncertain function. The most powerful software-based tool for researchers trying to understand the function of these many genes is a system called BLAST, which stands for Basic Local Alignment Search Tool.
</p><hr/><p>
	Here’s how it works. Let’s say a team of research biologists has come across a rhesus monkey gene that they can’t identify. They can enter into BLAST the nucleotides of the DNA or the amino-acid sequences of the protein associated with the gene. BLAST then searches enormous databases to find similar genes within the genomes of countless creatures, including humans. A match to a known gene often enables the researchers to infer the function of the unknown gene. It also lets them infer functional and evolutionary relationships that might exist between the sequences, and locate the unknown gene within one or more families of related genes.
</p><p>
	First released in 1990, 
	<a href="https://www.nature.com/scitable/topicpage/basic-local-alignment-search-tool-blast-29096/" rel="noopener noreferrer" target="_blank">BLAST</a> was created by a group at the <a href="https://www.nih.gov/" target="_blank">U.S. National Institutes of Health</a> that included Eugene Myers, Webb Miller, Stephen Altschul, Warren Gish, and David Lipman. <a href="https://pubmed.ncbi.nlm.nih.gov/2231712/" rel="noopener noreferrer" target="_blank">Their 1990 paper</a> describing BLAST has more than <a href="https://www.researchgate.net/publication/20923774_Basic_Local_Aligment_Search_Tool" rel="noopener noreferrer" target="_blank">75,000 citations</a>, making it one of the most highly cited research papers of all time.
</p><p>
	Earlier this year, Myers and Miller received the 
	<a href="https://corporate-awards.ieee.org/award/ieee-frances-e-allen-medal/" rel="noopener noreferrer" target="_blank">IEEE Francis E. Allen Medal</a>, which honors “innovative work in computing leading to lasting impact on other aspects of engineering, science, technology, or society.” Shortly before the ceremony, <em>IEEE Spectrum</em> spoke with Myers, who had just retired as a director of the <a href="https://www.mpi-cbg.de/" rel="noopener noreferrer" target="_blank">Max Planck Institute of Molecular Cell Biology and Genetics</a>. <a name="top"></a>
</p><p>
	Eugene Myers on…
</p><ul>
<li><a href="#blast">The origins of the BLAST system</a></li>
<li><a href="#lifestyle">Will it ever be possible for humans to live hundreds of years?</a></li>
<li><a href="#extinct"></a><a href="#extinct">Why we should resurrect extinct creatures</a></li>
<li><a href="#challenge">The next big challenge for bioinformatics</a></li>
</ul><p>
<strong> <a name="blast"></a>It’s the mid-to-late 1980s at the U.S. National Institutes of Health. What was in the air? What were some of the </strong><strong><a href="http://myerslab.mpi-cbg.de/wp-content/uploads/2014/06/behind.blast_.pdf" rel="noopener noreferrer" target="_blank">motivating factors</a> that led you and your colleagues there to work on and, ultimately, complete, BLAST?</strong>
</p><p class="shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left" data-rm-resized-container="25%" style="float: left;">
<img alt="A smiling man with grey hair and glasses" class="rm-shortcode rm-resized-image" data-rm-shortcode-id="b37d671abf1f182936f549145293b3ed" data-rm-shortcode-name="rebelmouse-image" id="3b04e" loading="lazy" src="https://spectrum.ieee.org/media-library/a-smiling-man-with-grey-hair-and-glasses.jpg?id=30449783&width=980" style="max-width: 100%"/>
<small class="image-media media-caption" placeholder="Add Photo Caption..." style="max-width: 100%;">Eugene Myers</small>
</p><p>
<strong>Eugene Myers:</strong> Well, there was already a tool like BLAST for searching the database, but it wasn’t very efficient and it took much too long. And <a href="https://en.wikipedia.org/wiki/David_J._Lipman" target="_blank">David Lipman</a>, who was running the <a href="https://www.ncbi.nlm.nih.gov/" target="_blank">National Center for Biotechnology Information</a> (NCBI), that growing database, was looking for something faster. And I happened to be on sabbatical. And I was a smoker at the time, and I was downstairs and he brought me this article about this new hot chip that was being promoted by <a href="https://en.wikipedia.org/wiki/TRW_Inc." target="_blank">TRW</a>. And I’m sitting there smoking my cigarettes saying, “Oh, David, I don’t believe in ASICs. I think if we just write the right code, we can do something.” And I had actually been working on a technique, a theoretical technique, for sublinear search. And I mean, basically, David and I and Webb got together and we had a very quick series of exchanges where we basically took the theoretical idea and distilled it down to its essence. And it was really fun, actually. I mean, Webb and I were passing back and forth versions of code, trying different implementations. And that was it. And I need to say, we got something that was fast as greased lightning at the time.
</p><p>
<a href="#top">Back to top</a>
</p><p>
<strong>Do you remember what the chip was?</strong>
</p><p>
<strong>Myers:</strong> I think it was called the FDF, and it was a systolic-array chip. It was designed for pattern matching primarily for the intelligence agencies. [<em>Editor’s note: the </em><a href="https://patents.google.com/patent/US4760523A/en?oq=United+States+4760523" rel="noopener noreferrer" target="_blank"><em>Fast Data Finder (FDF)</em></a><em> was an ASIC for recognizing strings of text. It was created at TRW in the mid-1980s</em>.]
</p><p>
<strong>Ah, intrigue. So that leads us to the next question, which is, for those who aren’t biologists, what exactly does BLAST do? It’s been called a sort of a search engine for genes. So a biologist who is doing a sequence, say, of a genome has a piece of genetic material that’s presumably a gene and doesn’t know what this gene does.</strong>
</p><p>
<strong>Myers:</strong> Well, I mean, basically, BLAST takes a DNA sequence or protein sequence, which is just a code over some alphabet, and it goes off and it searches the database looking for something that looks like that sequence. In biology, sequences aren’t preserved exactly. So you’re not looking for exactly the same sequence. You’re looking for something that’s like it. A few of the symbols can be different, maybe one can be missing, there could be an extra one. So it’s called approximate match.
</p><p>
<strong>And when you say it goes off and finds them, it finds them from a catalog of the genomes and genetic material of all living creatures that have been recorded.</strong>
</p><p>
<strong>Myers</strong><strong>:</strong> Yes. The database is oftentimes preprocessed to accelerate the search, although the initial BLAST, basically, just streamed the entire database.
</p><p>
<strong>So it will find a close-as-possible match for whatever the sequences you have, which may be a gene, and it will find it and it might be a totally different creature…</strong>
</p><p>
<strong>Myers:</strong> It could potentially find many of them. And one of the important things about BLAST, actually, which Altschul contributed, was it actually gave you the probability that you would see that match by chance. Because one of the big problems prior to that is that people were taking things that they thought kind of looked the same and saying, “Well, here’s an interesting match,” when in fact, according to probability theory, that was not an interesting match at all. So one of the very nice things about BLAST is it gave you a P-value that told you whether or not your match was actually interesting or not. But it would actually give you a whole list of matches and rank them according to their probability.
</p><p>
<strong>So one of the things that this illustrates is that all of us creatures on Earth, all of us, we’re made up of genes, and not only are we made up of genes, but you see throughout all of the living creatures very similar genes. So the blueprint, if you will, the elements of the blueprint that make up a human are different, but remarkably similar to the ones that, say, make up a parakeet or a lizard.</strong>
</p><p>
<strong>Myers:</strong> Now, there was a huge diaspora of life about 500 million years ago from bacteria into multicellular creatures where we basically ended up with fish and insects and all of the more complex orders of life. And they, basically, all used the same genes or proteins, but they used them in different ways. And mostly what was going on was the way that those genes were being turned on and the way those cassettes were being run. I mean, for example, a fruit fly has 14,000 genes and a human being has, I don’t know, maybe 28,000. And basically, every gene that’s in the fruit fly, there’s an analog that’s in a human being. Human beings have more copies of particular genes. They have one or two of something instead of just one of them. And human beings have a lot more genes that turn things on and off selectively. In other words, that regulate how the genes are being used. But the actual repertoire of genes is very similar. When we sequenced the human genome back at the turn of the century, 2000, we looked at the fruit fly and we looked at a human, and we said, “Hey, the fruit fly is like a little human.” I mean, potentially it gets cancer, metabolic disorders. It’s really quite fascinating.
</p><p>
<strong>There are some very large-scale projects around the world now aimed at sequencing the genomes of enormous classes of creatures, such as, vertebrates or plants or all living things native to the British Isles. These initiatives are sometimes collectively referred to as “sequencing the world.” Why are these efforts important?</strong>
</p><p>
<strong>Myers:</strong> Well, that’s a complex question. The basic answer is that we’re starting to do it now because we can finally do it at a quality where we feel like these libraries of sequences that we produce are going to, basically, stand the test of time—that they’re sufficiently correct and accurate. And the fascinating thing is, we’re going to learn more about how the various genes function. See, there’s still a lot of questions about what these genes are doing. And we’re going to learn more about how they function by looking at how they’re working across all of life than by looking at a particular species. I mean, right now, most medicine is just focused on human beings.
</p><p>
	For example, we’re interested in how long a human being lives. We’d like to live longer. But absent disease, the variation and the longevity of human beings is about 10 percent. I mean, some of us expire at 85, some of us at 95, and some of us at 75. It’s not a very big range. But for example, 
	<a href="https://arstechnica.com/science/2019/06/why-do-bats-have-such-bizarrely-long-lifespans/" target="_blank">there are bats</a> that as a function of their body weight live 50 times <a href="https://www.sciencedaily.com/releases/2019/04/190410105649.htm" rel="noopener noreferrer" target="_blank">longer than they’re supposed to</a>. <em>Fifty times</em>. That’s like living to 5,000 for a human being. And there are other bats that are very closely related to that bat—only 5 million years of evolution between them—where the bat lives a normal life. So if you go out into nature, you’re going to see these extremes in physical characteristics of what we call phenotype. So what we are interested in is what’s the relationship between the genotype, which is the gene sequence, and all the genes that are in it, and the phenotype, which is the physical characterization or manifestation of the creature.
</p><p>
<strong>So in other words, one of the things you want to do is you want to know what the cluster of genes is that enables certain bats to live 50 times longer than other bats?</strong>
</p><p>
<strong>Myers:</strong> Yes. So we think that by sequencing lots of pairs of bats that are short- and long-lived and comparing their genomes, we’re going to get real clues about what it takes to have a creature live a long time. And presumably, because the genes in a human being are so similar to those in the bat, it will translate to human medicine.
</p><p>
<a name="lifestyle"></a><strong>There is a study of so-called supercentenarians among human beings, if I’m not mistaken. So this would presumably provide additional depth and information beyond just studying supercentenarians. Supercentenarians are people who live to be about 100 without substantial decline, either mentally or physically.</strong>
</p><p>
<strong>Myers:</strong> A lot of that is about lifestyle. I mean, they’ve done studies, the <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6125071/" rel="noopener noreferrer" target="_blank">Blue Zones</a>. And it’s about having good friends, it’s about eating a healthy diet, not eating too much, getting a little exercise, not too much stress. A lot of these things, I mean, turn out to be very significant factors. But again, there’s basically a kind of an expire-by date for every species of creature, and <a href="https://www.sciencedirect.com/science/article/pii/S0169534715001044" rel="noopener noreferrer" target="_blank">they have a longevity</a>. Because the original purpose, really, of a creature is to create children. And once you’ve created the children, your job’s done. I mean, once you’ve created offspring, you’ve propagated the genome and you’re superfluous.
</p><p class="pull-quote">
	We’ve got this natural built-in expiry date. And the question is, how can we fundamentally change that?
</p><p>
	So we’ve got this natural kind of built-in expiry date. And the question is, how can we fundamentally change that? Because I don’t want to live to be 100. I want to live to be 1,000, okay? I mean, it’s too late for me. But think about it. If I could live to be 1,000, I could have 10 careers. I mean, I’d love to do 100 years as an architect, 100 years as a physician. Right?
</p><p>
<a href="#top">Back to top</a>
</p><p>
<strong>So the idea is if you could identify the genes and the sequences that these long-lived creatures have in common, not only humans, but other creatures, you could, in theory, use a gene-editing technique, something that follows from CRISPR in the far future, to actually edit genes? This is probably decades from now.</strong>
</p><p>
<strong>Myers:</strong> Well, it could be just as simple as stopping certain reactions from happening. So it may not even be as much as a [genome] edit. I mean, it may just be like a drug where basically we just inhibit certain pathways. We build a small molecule that inhibits something to stop it from doing its thing, and that turns off the expiry clock. But we don’t know exactly how to do that yet. I mean, we know that reducing inflammation certainly leads to longer life. We know that not eating as much. So maybe there’s a drug that we can take that helps us metabolize better so that we don’t—so there are a lot of options like that. It doesn’t necessarily have to be gene editing. This is a kind of a futuristic thing. I can’t tell you when, but I can tell you that as long as we don’t blow ourselves up to kingdom come or ruin our planet and we have enough time, we will do it. We will do it.
</p><p>
<strong>One of the main motivations, perhaps the greatest motivation for all of this work, is to better understand how specific genetic variations lead to disease. It’s a lot of what keeps the money flowing and the whole enterprise going. And a very powerful tool for this purpose is the <a href="https://medlineplus.gov/genetics/understanding/genomicresearch/gwastudies/" rel="noopener noreferrer" target="_blank">genome-wide association study</a>. And this predates a lot of this technology. It’s an older tool, but it is one that is as dependent as ever on bioinformatics. And I would think because of the growing complexity, only getting more dependent.</strong>
</p><p>
<strong>Myers:</strong> A lot of what we’ve been trying to do for the last couple of decades is basically correlative. In other words, we’re not looking actually for causation. We’re just simply looking for correlation. This gene seems to have something to do with this disease and vice versa. And it doesn’t give us a mechanism, but it does tell us that this is associated with that. So we want to understand. A lot of what we’ve been doing is sequencing lots and lots of people. In other words, getting their genotype, their genome, and correlating that with their phenotype, with their physical characteristics. Do they get heart disease early? Do they get diabetes?
</p><p>
<a name="challenge"></a><strong>A classic one is breast cancer with the <a href="https://www.nationalbreastcancer.org/what-is-brca" rel="noopener noreferrer" target="_blank">BRCA</a>.</strong>
</p><p>
<strong>Myers:</strong> Right. And that was an example where we found basically the genes that are absolutely correlated with breast cancer. I mean, we know there’s a fairly small repertoire. But on the other hand, something like coronary health, heart health, is very, very complicated because really it’s a function of hundreds of genes. And so which combination and which battery? So basically, it’s not a single locus. I mean, early on, in the very early days, there were a lot of diseases that were caused by single mutation, but those are kind of the exception rather than the rule. I mean, those single mutations, they were incredibly serious diseases. And it’s nice that—well, I think we’re in a position to affect some of those.
</p><p>
	It’s very interesting to have these single-locus diseases in hand to really improve the health of humanity as a whole. We’re going to need to have a kind of more refined understanding of the relationship between the genotype and the phenotype. And so these studies have been going on and people have been collecting data. In fact, the biggest problem, actually, isn’t getting everybody’s genome. The biggest problem is getting accurate phenotypic data. In other words, actually getting accurate measurements of people’s blood sugar. Like, when do you take the test, etc. I won’t go into all the complexities. But it’s actually building a database of all of the characteristics of people and basically digitizing all of the information we have about people. But this is going forward, and I think it will be very useful.
</p><p>
<a href="#top">Back to top</a>
</p><p>
<a name="extinct"></a><strong>One of the more sensational applications of bioinformatics is the challenge of reviving extinct species. So we read about the woolly mammoth, and there’s recent talk about the dodo and others. There’s the quagga, I think. There’s just a whole host of creatures that have, sadly, departed from the earth, but that in theory, we could revive in some form with the techniques and tools now available.</strong>
</p><p>
<strong>Myers:</strong> I think probably what’s more interesting is not actually bringing them back, but understanding what they were. For example, <a href="https://en.wikipedia.org/wiki/Svante_P%C3%A4%C3%A4bo" target="_blank">Svante Pääbo’s</a> work reconstructing the Neanderthal sequence. Okay. I mean, it turns out that we’re all about, I think, <a href="https://humanorigins.si.edu/evidence/genetics/ancient-dna-and-neanderthals/interbreeding" rel="noopener noreferrer" target="_blank">4 percent Neanderthal DNA</a>. And it turns out, for example with COVID, it turns out that your propensity for outcomes in COVID actually is <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7859372/" rel="noopener noreferrer" target="_blank">correlated with whether or not you had some of this Neanderthal DNA</a>.
</p><p>
	I think it’s quite fascinating that we’re kind of an admixture of these things. So knowing this ancient genome is quite interesting. I mean, also, the woolly mammoth versus the modern-day elephant basically gives us another clue. And I think what’s fascinating is the fact that we can do it at all. If we can get sufficient DNA material, then we can extract these things. Understanding that the evolutionary history of mankind is certainly of interest because we’re interested in ourselves, yes? For other creatures, well, it is the case that if we have a sequence, I do believe that we will eventually be able to kind of realize 
	<em>Jurassic Park</em> and actually literally create the genomic sequence, transplant it into a nonfertilized embryo of a nearby species, and create the creature, an instance of the creature. And I think that will be pretty cool if we really want to <a href="https://www.natureworldnews.com/articles/49999/20220319/dodo-resurrected-when-scientists-examine-extinct-birds-dna-first-time.htm" rel="noopener noreferrer" target="_blank">understand dodo birds</a>. But I think in general, we don’t want to lose all of that diversity. That connects back to what we were talking about before, which are these projects to go out and sequence the world. For example, I’ve sequenced some nearly extinct turtles. Now, that I have the sequence of those turtles, even if they go extinct, we can still do a <em>Jurassic Park</em> sometime in the future, but at least the genetic inheritance of those species is still present and we will still have it. So it’s, basically, a matter of conservation and a matter of understanding evolution and it’s pretty damn cool.
</p><p>
<a href="#top">Back to top</a>
</p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="Black and white photo of a striped doglike animal at a zoo" class="rm-shortcode" data-rm-shortcode-id="7d9f645303113894dea18b63306b4752" data-rm-shortcode-name="rebelmouse-image" id="33066" loading="lazy" src="https://spectrum.ieee.org/media-library/black-and-white-photo-of-a-striped-doglike-animal-at-a-zoo.jpg?id=30453631&width=980"/>
<small class="image-media media-caption" placeholder="Add Photo Caption...">The last thylacine died at the Beaumaris Zoo in Hobart, Australia, on 7 September 1936. Recently, biologists at the University of Melbourne launched a project aimed at bringing the creature back from extinction.</small><small class="image-media media-photo-credit" placeholder="Add Photo Credit...">Hum Historical/Alamy</small>
</p><p>
<strong>And for full disclosure, we should point out that nobody could actually do <em>Jurassic Park</em> because dinosaur DNA is tens of millions of years old, so it no longer exists.</strong>
</p><p>
<strong>Myers:</strong> Yeah. I don’t mean <em>Jurassic Park</em> in the sense of bringing back dinosaurs. <em>Jurassic Park</em> in the sense of creating creatures that are no longer extant. Okay? I mean, that’s always the case with the best science fiction, is that it’s plausible. <em>Jurassic Park</em> is plausible, so is <em><a href="https://www.rogerebert.com/reviews/gattaca-1997" rel="noopener noreferrer" target="_blank">Gattaca</a></em>. You know that one with Ethan Hawke where they, basically, sequenced everybody and they took the best? I mean, that is completely plausible.
</p><p>
<strong>What do you think are some of the most exciting challenges for young people, that they’ll be working on, say, in two years or four years? The big, difficult problems in bioinformatics.</strong>
</p><p>
<strong>Myers:</strong> Well, there are a lot of problems that still haven’t been solved. For example, how do you get a given shape and form from a genome? The genome actually encodes everything. It gives you five fingers. It gives you a nose, eyes. It encodes for everything. But we don’t understand the biophysical process for that. I mean, we have some idea that this gene controls that and this gene controls that, but that doesn’t tell us mechanistically what’s happening, and it doesn’t tell us how to intervene or what would happen if we intervene. So I still think that the fundamental question is to try to understand kind of what’s encoded in a genome and what mechanistically does it unfold. And I mean, computational biology is going to be at the core of it because, I mean, you’re talking about, okay, for a human being, 30,000 genes. Does 30,000 genes probably get transcribed into 150,000 different protein variants?
</p><p>
	There are probably 10 billion of those proteins floating around an individual cell. And then your body—I mean, your brain alone has 10 billion neurons. So think about the scale of that thing. Okay? I mean, we’re not even close. So I think that high-performance computing. I think that advanced simulations.
</p><p>
	A lot of what moves biology is technology, the ways to manipulate things. We’ve been able to manipulate creatures for a long time genetically. But now that we have this new mechanism, CRISPR-Cas, for which the Nobel was awarded a couple of years ago, I mean, we can now do that with precision and fidelity, which is a huge advance.
</p><p><iframe class="rm-shortcode" data-rm-shortcode-id="cb292ac2a9ea78362abcf386840690a3" expand="1" frameborder="0" height="480" id="d796c" site_id="20265424" src="https://www.rebelmouse.com/res/scraper/embed?type=mp4&adapt_to_iframe=1&url=https%3A//ieeetv.ieee.org/ns/ieeetvdl/2022/IEEE-VICS-Honors/IEEE-VICS-Honors-2022-Gene-Myers-Glenn-Zorpette.mp4&thumb=https%3A//ieeetv.ieee.org/assets/video-images/large/2022-IEEE-VICS-Honors-Poster-Frame-02-Gene-Myers.png" width="100%"></iframe></p>]]></description><pubDate>Wed, 03 Aug 2022 13:12:49 +0000</pubDate><guid>https://spectrum.ieee.org/a-bat-youve-never-heard-of-might-help-radically-extend-human-lifespans</guid><category>Bioinformatics</category><category>Dna</category><category>Health</category><category>Genome sequencing</category><category>Genetics</category><dc:creator>Glenn Zorpette</dc:creator><media:content medium="image" type="image/jpeg" url="https://spectrum.ieee.org/media-library/a-bat-in-flight-approaches-its-prey-a-katydid-on-a-rock.jpg?id=30453479&amp;width=980"></media:content></item><item><title>Robot Outperforms a Surgeon in a Precision Training Task</title><link>https://spectrum.ieee.org/robot-outperforms-a-surgeon-in-a-precision-training-task</link><description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/robotic-arms-with-surgical-tools-approach-a-red-board-with-pegs.jpg?id=30154200&width=1245&height=700&coordinates=0%2C84%2C0%2C84"/><br/><br/><p>
<p>
<em>This article is part of our exclusive <a href="https://spectrum.ieee.org/collections/journal-watch/" rel="noopener noreferrer" target="_self">IEEE Journal Watch series</a> in partnership with IEEE Xplore.</em>
</p>
</p>
<p>
	Who is better at performing surgery: an experienced surgeon or a robot?
</p>
<p>
	Typically, surgeons have to make incisions that are relatively big during surgery, whereas the small instruments of a robot can fit through smaller incisions. Given this advantage of robotic systems, it’s now quite common for surgeons to use remote-controlled robotic arms to perform surgery—combining the precision of an experienced human with the minimal invasiveness of a small robotic arm. Nevertheless, the surgeon is controlling the robot in these cases, and a fully automated robotic system that can outperform surgeons in terms of precision is yet to be realized.
</p>
<p>
	A recent advance shows that robots could surpass human performance in the near future, however. In a 
	<a href="https://ieeexplore.ieee.org/abstract/document/9772013" rel="noopener noreferrer" target="_blank">paper</a> published 10 May in <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=8856" rel="noopener noreferrer" target="_blank"><em>IEEE Transactions on Automation Science and Engineering</em></a>, a multinational team of researchers reported the results of a study where a robot was able to complete a common surgery training task with the same accuracy as an experienced surgeon, while completing the task more quickly and consistently.
</p>
<p>
	Minho Hwang, an assistant professor at the Daegu Gyeongbuk Institute of Science and Technology, in South Korea, was involved in the study. He notes that many robotic systems currently rely on automated control of cables, which are subjected to friction, cable coupling, and stretch—all of which can make precision positioning difficult.
</p>
<p>
	“When humans control the robots, they can compensate through human visual feedback,” explains Hwang. “But automation of robot-assisted surgery is very difficult due to [these] position errors.”
</p>
<p>
	In their study, Hwang and colleagues took a standard da Vinci robotic system, which is a common model usedd for robot-assisted surgery, and strategically placed 3-D printed markers on its robotic arm. This allowed the team to track its movements using a color and depth sensor. They then analyzed the arm’s movements using a machine-learning algorithm. Results suggest that the trained model can reduce the mean tracking error by 78 percent, from 2.96 millimeters to 0.65 mm.
</p>
<p>
	Next, the researchers put their system to the test against an experienced surgeon who had performed more than 900 surgeries, as well as against nine volunteers with no surgical experience. The study participants were asked to complete a peg transfer task, which is a standardized test for training surgeons that involves transferring six triangular blocks from one side of a pegboard to the other and then back again. While the task sounds simple enough, it requires millimeter precision.
</p>
<p>
	The study participants completed three different variations of the peg task using the da Vinci system: unilateral (using one arm to move a peg), bilateral (using two arms to simultaneously move two pegs) and bilateral with a crossover (using one arm to pick up the peg, transfer it to the other arm, and place the peg on the board). Their robot-assisted performance was compared to that of the fully automated robotic system designed by Hwang’s team.
</p>
<p class="shortcode-media shortcode-media-youtube">
<span class="rm-shortcode" data-rm-shortcode-id="4e971addae5aa180bbbb81c9dce5c925" style="display:block;position:relative;padding-top:56.25%;"><iframe frameborder="0" height="auto" lazy-loadable="true" scrolling="no" src="https://www.youtube.com/embed/xXMvtPlBzlc?rel=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" width="100%"></iframe></span>
<small class="image-media media-caption" placeholder="Add Photo Caption...">Hwang et al show how their robot system can outperform a surgeon in a precision training task. In the most difficult variation of the task, called a bilateral handover, the robot must pick up a peg, transfer it to the other robotic arm, and then place the peg back on the peg board, all with millimeter precision. The robot outperforms the surgeon by 31.7 % in mean transfer time.</small>
</p>
<p>
	Using one arm, the surgeon outperformed the automated robot in terms of speed. But in the more complex tasks involving two arms, the robot outperformed the surgeon.
</p>
<p>
	For example, for the most difficult task (bilateral handovers), the surgeon achieved a success rate of 100 percent with a mean transfer time of 7.9 seconds. The robot had the same success rate, but with a mean transfer time of just 6.0 seconds.
</p>
<p>
	“We were very surprised by the robot’s speed and accuracy, as it is very hard to surpass the skill of a trained human surgeon,” says Ken Goldberg, a
	 professor in the Department of Electrical Engineering and Computer Sciences at the University of California, Berkeley, who was also involved in the study. “We were also surprised by how consistent the robot was; it transferred 120 blocks flawlessly without a single failure.”
</p>
<p>
	Goldberg and Hwang note that this is a preliminary study in a controlled environment, and more studies are still needed to achieve fully automated robotic surgery. But as far as they are aware, this is the first instance of a robot outperforming a human in a surgery-related training task.
</p>
<p>
	“We have demonstrated that fast and accurate automation is feasible for one surgical task involving rigid objects of known shape. The next step is to demonstrate this for other tasks and in the much more complex environment of a human body,” says Hwang.
</p>
<p>
	He says that, in future work, the team plans to extend their approach to automating surgical subtasks such as tissue suturing, and that they would like to build upon their methods for calibration, motion planning, visual servoing, and error recovery.
</p>
<p>
<em>This article appears in the October 2022 print issue as “Robot Bests Surgeon in Precision Task.”</em>
</p>]]></description><pubDate>Tue, 19 Jul 2022 15:03:02 +0000</pubDate><guid>https://spectrum.ieee.org/robot-outperforms-a-surgeon-in-a-precision-training-task</guid><category>Surgical robots</category><category>Machine learning</category><category>Journal watch</category><dc:creator>Michelle Hampson</dc:creator><media:content medium="image" type="image/jpeg" url="https://spectrum.ieee.org/media-library/robotic-arms-with-surgical-tools-approach-a-red-board-with-pegs.jpg?id=30154200&amp;width=980"></media:content></item><item><title>Restoring Hearing With Beams of Light</title><link>https://spectrum.ieee.org/cochlear-implant</link><description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/a-computer-graphic-shows-a-gray-structure-thats-curled-like-a-snails-shell-a-big-purple-line-runs-through-it-many-clusters-o.jpg?id=30131021&width=1245&height=700&coordinates=0%2C249%2C0%2C250"/><br/><br/><p>
<strong>There’s a popular</strong> misconception that <a href="https://www.nidcd.nih.gov/health/cochlear-implants" target="_blank">cochlear implants</a> restore natural hearing. In fact, these marvels of engineering give people a new kind of “electric hearing” that they must learn how to use.
</p><p>
	Natural hearing results from vibrations hitting tiny structures called hair cells within the cochlea in the inner ear. A cochlear implant bypasses the damaged or dysfunctional parts of the ear and uses electrodes to directly stimulate the cochlear nerve, which sends signals to the brain. When my hearing-impaired patients have their cochlear implants turned on for the first time, they often report that voices sound flat and robotic and that background noises blur together and drown out voices. Although users can have many sessions with technicians to “tune” and adjust their implants’ settings to make sounds more pleasant and helpful, there’s a limit to what can be achieved with today’s technology.
</p><p>
	I have been an otolaryngologist for more than two decades. My patients tell me they want more natural sound, more enjoyment of music, and most of all, better comprehension of speech, particularly in settings with background noise—the so-called 
	<a href="https://en.wikipedia.org/wiki/Cocktail_party_effect" target="_blank">cocktail party problem</a>. For 15 years, <a href="http://www.auditory-neuroscience.uni-goettingen.de/" target="_blank">my team</a> at the University of Göttingen, in Germany, has been collaborating with colleagues at the University of Freiburg and beyond to reinvent the cochlear implant in a strikingly counterintuitive way: using light.
</p><p>
	We recognize that today’s cochlear implants run up against hard limits of engineering and human physiology. So we’re developing a new kind of cochlear implant that uses light emitters and genetically altered cells that respond to light. By using precise beams of light instead of electrical current to stimulate the cochlear nerve, we expect our optical cochlear implants to better replicate the full spectral nature of sounds and better mimic natural hearing. We aim to start clinical trials in 2026 and, if all goes well, we could get regulatory approval for our device at the beginning of the next decade. Then, people all over the world could begin to hear the light.
</p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="Three 3D microscopic images show bony structures in gray, cells in glowing blue spirals, and an implant as a thin and twisting dotted line." class="rm-shortcode" data-rm-shortcode-id="b885b3c619eb4f4a83f17de56a1244cf" data-rm-shortcode-name="rebelmouse-image" id="a5d92" loading="lazy" src="https://spectrum.ieee.org/media-library/three-3d-microscopic-images-show-bony-structures-in-gray-cells-in-glowing-blue-spirals-and-an-implant-as-a-thin-and-twisting-d.jpg?id=30131368&width=980"/>
<small class="image-media media-caption" placeholder="Add Photo Caption...">These 3D microscopic images of mouse ear anatomy show optical implants [dotted lines] twisting through the intricate structure of a normal cochlea, which contains hair cells; in deafness, these cells are lost or damaged. At left, the hair cells [light blue spiral] connect to the cochlear nerve cells [blue filaments and dots]. In the middle and right images, the bony housing of the mouse cochlea surrounds this delicate arrangement.</small>
<small class="image-media media-photo-credit" placeholder="Add Photo Credit...">Daniel Keppeler</small>
</p><h2><strong>How cochlear implants work</strong></h2><p>
	Some 
	<a href="https://www.who.int/news-room/fact-sheets/detail/deafness-and-hearing-loss" target="_blank">466 million people</a> worldwide suffer from disabling hearing loss that requires intervention, according to the World Health Organization. Hearing loss mainly results from damage to the cochlea caused by disease, noise, or age and, so far, there is no cure. Hearing can be partially restored by hearing aids, which essentially provide an amplified version of the sound to the remaining sensory hair cells of the cochlea. Profoundly hearing-impaired people benefit more from cochlear implants, which, as mentioned above, skip over dysfunctional or lost hair cells and directly stimulate the cochlear, or auditory, nerve.
</p><p class="pull-quote">
	 In the 2030s, people all over the world could begin to hear the light.
</p><p>
	Today’s cochlear implants are the most successful neuroprosthetic to date. The first device was approved by the U.S. Food and Drug Administration in the 1980s, and 
	<a href="https://www.nidcd.nih.gov/health/cochlear-implants" target="_blank">nearly 737,000 devices</a> had been implanted globally by 2019. Yet they make limited use of the neurons available for sound encoding in the cochlea. To understand why, you first need to understand how natural hearing works.
</p><p>
	In a functioning human ear, sound waves are channeled down the ear canal and set the ear drum in motion, which in turn vibrates tiny bones in the middle ear. Those bones transfer the vibrations to the inner ear’s cochlea, a snail-shaped structure about the size of a pea. Inside the fluid-filled cochlea, a membrane ripples in response to sound vibrations, and those ripples move bundles of sensory hair cells that project from the surface of that membrane. These movements trigger the hair cells to release neurotransmitters that cause an electrical signal in the neurons of the cochlear nerve. All these electrical signals encode the sound, and the signal travels up the nerve to the brain. Regardless of which sound frequency they encode, the cochlear neurons represent sound intensity by the rate and timing of their electrical signals: The firing rate can reach a few hundred hertz, and the timing can achieve submillisecond precision.
</p><p>
	Hair cells in different parts of the cochlea respond to different frequencies of sound, with those at the base of the spiral-shaped cochlea detecting high-pitched sounds of up to about 20 kilohertz, and those at the top of the spiral detecting low-pitched sounds down to about 20 Hz. This frequency map of the cochlea is also available at the level of the neurons, which can be thought of as a spiraling array of receivers. Cochlear implants capitalize on this structure, stimulating neurons in the base of the cochlea to create the perception of a high pitch, and so on.
</p><p>
	A commercial cochlear implant today has a microphone, processor, and transmitter that are worn on the head, as well as a receiver and electrodes that are implanted. It typically has between 12 and 24 electrodes that are inserted into the cochlea to directly stimulate the nerve at different points. But the saline fluid within the cochlea is conductive, so the current from each electrode spreads out and causes broad activation of neurons across the frequency map of the cochlea. Because the frequency selectivity of electrical stimulation is limited, the quality of artificial hearing is limited, too. The natural process of hearing, in which hair cells trigger precise points on the cochlear nerve, can be thought of as playing the piano with your fingers; cochlear implants are more equivalent to playing with your fists. Even worse, this large stimulation overlap limits the way we can stimulate the auditory nerve, as it forces us to activate only one electrode at a time.
</p><div class="ieee-sidebar-large">
<h3>Three Ways to Hear</h3>
<p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="A diagram with three parts shows the differences between normal hearing, electrical cochlear implant, and optical cochlear implant. Each shows the anatomy of the middle and inner ear, including the spiral shaped cochlea." class="rm-shortcode" data-rm-shortcode-id="bd38ce25764d6cdf193e102b6242b536" data-rm-shortcode-name="rebelmouse-image" id="53b9a" loading="lazy" src="https://spectrum.ieee.org/media-library/a-diagram-with-three-parts-shows-the-differences-between-normal-hearing-electrical-cochlear-implant-and-optical-cochlear-impla.jpg?id=30131050&width=980"/>
<small class="image-media media-photo-credit" placeholder="Add Photo Credit...">Chris Philpot</small>
</p>
<p>
		In normal hearing, sound waves travel down the ear canal and vibrate the ear drum and tiny bones in the middle ear. Those vibrations then reach the spiral-shaped cochlea and move bundles of sensory hair cells. When the hair cells respond, it triggers a neural signal that travels up the cochlear nerve to the brain. Hair cells at the base of the spiral respond to high-pitched sounds; those at the tip respond to low-pitched sounds.
	</p>
<p>
		With an electrical cochlear implant, a microphone, processor, and transmitter are worn behind the ear. The processor translates a sound’s pattern of frequencies into a crude stimulation pattern, which is transmitted to an implanted receiver and then to an electrode array that spirals through the cochlea. A limited number of electrodes (12 are shown here) directly stimulate the cells of the cochlear nerve. But each electrical pulse spreads out and stimulates off-target nerve cells, which results in muddier sound.
	</p>
<p>
		In a future optical cochlear implant, the external hardware could remain the same, though the processor could break up the sound into narrower frequency bands and transmit a more sophisticated stimulation pattern. The light source, either a flexible micro-LED array or optical fibers, would spiral through the cochlea, and the implant could have many more stimulation sites, because light is more easily confined in space than electrical current is. The user would have a gene-therapy treatment to make the cells of the cochlear nerve responsive to light, which would trigger precise signals that travel up the nerve to the brain.
	</p>
</div><h2><strong>How optogenetics works</strong></h2><p>
	The idea for a better way began back in 2005, when I started hearing about a new technique being pioneered in neuroscience called 
	<a href="https://www.youtube.com/watch?v=I64X7vHSHOE" target="_blank">optogenetics</a>. German researchers were among the first to discover <a href="https://www.science.org/doi/abs/10.1126/science.1072068" target="_blank">light-sensitive proteins</a> in algae that regulated the flow of ions across a cellular membrane. Then, other research groups began experimenting with taking the genes that coded for such proteins and using a harmless viral vector to <a href="https://www.nature.com/articles/nn1525" target="_blank">insert them into neurons</a>. The upshot was that shining a light on these genetically altered neurons could trigger them to open their voltage-gated ion channels and thus fire, or activate, allowing researchers to directly control living animals’ <a href="https://spectrum.ieee.org/neuroscientists-wirelessly-control-the-brain-of-a-scampering-lab-mouse" target="_self">brains and behaviors</a>. Since then, optogenetics has become a significant tool in neuroscience research, and clinicians are experimenting with medical applications including <a href="https://www.nature.com/articles/s41591-021-01351-4" target="_blank">vision restoration</a> and <a href="https://www.frontiersin.org/articles/10.3389/fphys.2021.720190/full" target="_blank">cardiac pacing</a>.
</p><p>
	I’ve long been interested in how sound is encoded and how this coding goes wrong in hearing impairment. It occurred to me that stimulating the cochlear nerve with light instead of electricity could provide much more precise control, because light can be tightly focused even in the cochlea’s saline environment.
</p><p class="pull-quote">
	We are proposing a new type of implanted medical device that will be paired with a new type of gene therapy.
</p><p>
	If we used optogenetics to make cochlear nerve cells light sensitive, we could then precisely hit these targets with beams of low-energy light to produce much finer auditory sensations than with the electrical implant. We could theoretically have more than five times as many targets spaced throughout the cochlea, perhaps as many as 64 or 128. Sound stimuli could be electronically split up into many more discrete frequency bands, giving users a much richer experience of sound. This general idea had been taken up earlier by 
	<a href="https://www.feinberg.northwestern.edu/faculty-profiles/az/profile.html?xid=12460" target="_blank">Claus-Peter Richter</a> from Northwestern University, who proposed directly stimulating the auditory nerve with high-energy infrared light, though that concept wasn’t confirmed by other laboratories.
</p><p>
	Our idea was exciting, but my collaborators and I saw a host of challenges. We were proposing a new type of implanted medical device that would be paired with a new type of gene therapy, both of which must meet the highest safety standards. We’d need to determine the best light source to use in the optogenetic system and how to transmit it to the proper spots in the cochlea. We had to find the right light-sensitive protein to use in the cochlear nerve cells, and we had to figure out how best to deliver the genes that code for those proteins to the right parts of the cochlea.
</p><p>
	But we’ve made great progress over the years. In 2015, the European Research Council gave us a vote of confidence when it 
	<a href="http://www.auditory-neuroscience.uni-goettingen.de/OptoHear.html" target="_blank">funded our “OptoHear” project</a>, and in 2019, we spun off a company called <a href="https://www.optogentech.com/" target="_blank">OptoGenTech</a> to work toward commercializing our device.<br/>
</p><h2><strong>Channelrhodopsins, micro-LEDs, and fiber optics</strong></h2><p>
	Our early proof-of-concept experiments in mice explored both the biology and technology at play in our mission. Finding the right light-sensitive protein, or channelrhodopsin, turned out to be a long process. Many early efforts in optogenetics used 
	<a href="https://www.pnas.org/doi/10.1073/pnas.1936192100" target="_blank">channelrhodopsin-2</a> (ChR2) that opens an ion channel in response to blue light. We used it in a <a href="https://dm5migu4zj3pb.cloudfront.net/manuscripts/69000/69050/cache/69050.2-20150223083122-covered-e0fd13ba177f913fd3156f593ead4cfd.pdf" target="_blank">proof-of-concept experiment</a> in mice that demonstrated that optogenetic stimulation of the auditory pathway provided better frequency selectivity than electrical stimulation did.
</p><p>
	In our continued search for the best channelrhodopsin for our purpose, we tried a ChR2 variant called 
	<a href="https://www.nature.com/articles/nn.2776" target="_blank">calcium translocating channelrhodopsin</a> (CatCh) from the <a href="https://www.biophys.mpg.de/en/bamberg" target="_blank">Max Planck Institute of Biophysics</a> lab of <a href="https://www.biophys.mpg.de/en/bamberg" target="_blank">Ernst Bamberg</a>, one of the world pioneers of optogenetics. We delivered CatCh to the cochlear neurons of Mongolian gerbils using a <a href="https://en.wikipedia.org/wiki/Adeno-associated_virus" target="_blank">harmless virus</a> as a vector. We next trained the gerbils to respond to an auditory stimulus, teaching them to avoid a certain area when they heard a tone. Then we deafened the gerbils by applying a drug that kills hair cells and inserted a tiny optical cochlear implant to stimulate the light-sensitized cochlear neurons. The deaf animals <a href="https://pubmed.ncbi.nlm.nih.gov/29997248/" target="_blank">responded to this light stimulation</a> just as they had to the auditory stimulus.
</p><p class="pull-quote">The optical cochlear implant will enable people to pick out voices in a busy meeting and appreciate the subtleties of their favorite songs.</p><p>
	However, the use of CatCh has two problems: First, it requires blue light, which is associated with 
	<a href="https://www.nature.com/articles/s41598-017-00829-x" target="_blank">phototoxicity</a>. When light, particularly high-energy blue light, shines directly on cells that are typically in the dark of the body’s interior, these cells can be damaged and eventually die off. The other problem with CatCh is that it’s slow to reset. At body temperature, once CatCh is activated by light, it takes about a dozen milliseconds to close the channel and be ready for the next activation. Such slow kinetics do not support the precise timing of neuron activation necessary to encode sound, which can require more than a hundred spikes per second. Many people said the kinetics of channelrhodopsins made our quest impossible—that even if we gained spectral resolution, we’d lose temporal resolution. But we took those doubts as a strong motivation to look for faster channelrhodopsins, and ones that respond to red light.
</p><p>
	We were excited when a leader in optogenetics, 
	<a href="https://be.mit.edu/directory/ed-boyden" target="_blank">Edward Boyden</a> at MIT, discovered a faster-acting channelrhodopsin that his team called <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3943671/" target="_blank">Chronos.</a> Although it still required blue light for activation, Chronos was the fastest channelrhodopsin to date, taking about 3.6 milliseconds to close at room temperature. Even better, we found that it closed within about 1 ms at the warmer temperature of the body. However, it took some extra tricks to get Chronos working in the cochlea: We had to use powerful viral vectors and certain genetic sequences to improve the delivery of Chronos protein to the cell membrane of the cochlear neurons. With those tricks, both single neurons and the neural population responded robustly and with good temporal precision to optical stimulation at higher rates of up to about 250 Hz. So Chronos enabled us to elicit near-natural rates of neural firing, suggesting that we could have both frequency and time resolution. But we still needed to find an ultrafast channelrhodopsin that operated with longer wavelength light.
</p><p>
	We teamed up with Bamberg to take on the challenge. The collaboration targeted Chrimson, a channelrhodopsin first described by Boyden that’s best stimulated by orange light. The 
	<a href="https://www.nature.com/articles/s41467-018-04146-3.pdf" target="_blank">first results</a> of our engineering experiments with Chrimson were fast Chrimson (f-Chrimson) and very fast Chrimson (vf-Chrimson). We were pleased to discover that f-Chrimson enables cochlear neurons to <a href="https://www.nature.com/articles/s41467-018-04146-3" target="_blank">respond to red light reliably</a> up to stimulation rates of approximately 200 Hz. Vf-Chrimson is even faster but is less well expressed in the cells than f-Chrimson is; so far, vf-Chrimson <a href="https://www.embopress.org/doi/full/10.15252/emmm.202013391" target="_blank">has not shown a measurable advantage</a> over f-Chrimson when it comes to high-frequency stimulation of cochlear neurons.
</p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="Two micrograph images each show a glass rod with a thin, flexible tape wrapped around it in a spiral. In the image at left, the tape is clear with tiny black squares all along its length. In the image at right, the squares are glowing with light blue light.   " class="rm-shortcode" data-rm-shortcode-id="45aa61c4f58464484501b665b8594e8f" data-rm-shortcode-name="rebelmouse-image" id="abc35" loading="lazy" src="https://spectrum.ieee.org/media-library/two-micrograph-images-each-show-a-glass-rod-with-a-thin-flexible-tape-wrapped-around-it-in-a-spiral-in-the-image-at-left-the.jpg?id=30131496&width=980"/>
<small class="image-media media-caption" placeholder="Add Photo Caption...">This flexible micro-LED array, fabricated at the University of Freiburg, is wrapped around a glass rod that’s 1 millimeter in diameter. The array is shown with its 144 diodes turned off [left] and operating at 1 milliamp [right]. </small><small class="image-media media-photo-credit" placeholder="Add Photo Credit...">University of Freiburg/Frontiers</small>
</p><p>
	We’ve also been exploring our options for the implanted light source that will trigger the optogenetic cells. The implant must be small enough to fit into the limited space of the cochlea, stiff enough for surgical insertion, yet flexible enough to gently follow the cochlea’s curvature. Its housing must be biocompatible, transparent, and robust enough to last for decades. My collaborators 
	<a href="https://www.tu-chemnitz.de/physik/EXSE/" target="_blank">Ulrich Schwarz</a> and <a href="https://www.imtek.de/professuren/materialien/mitarbeiter/persoenlich/Ruther.Patrick.jpg/" target="_blank">Patrick Ruther</a>, then at the University of Freiburg, started things off by developing the first <a href="https://iopscience.iop.org/article/10.1088/0022-3727/47/20/205401" target="_blank">micro-light-emitting diodes (micro-LEDs) for optical cochlear implants</a>.
</p><p>
	We found micro-LEDs useful because they’re a very mature commercial technology with good power efficiency. We conducted 
	<a href="https://www.science.org/doi/10.1126/scitranslmed.abb8086" target="_blank">several</a> <a href="https://www.embopress.org/doi/full/10.15252/emmm.202012387" target="_blank">experiments</a> with microfabricated thin-film micro-LEDs and demonstrated that we could optogenetically stimulate the cochlear nerve in our targeted frequency ranges. But micro-LEDs have drawbacks. For one thing, it’s difficult to establish a flexible, transparent, and durable hermetic seal around the implanted micro-LEDs. Also, micro-LEDs with the highest efficiency emit blue light, which brings us back to the phototoxicity problem. That's why we’re also looking at another way forward.
</p><p>
	Instead of getting the semiconductor emitter itself into the cochlea, the alternative approach puts the light source, such as a laser diode, farther away in a hermetically sealed titanium housing. Optical fibers then bring the light into the cochlea and to the light-sensitive neurons. The optical fibers must be biocompatible, durable, and flexible enough to wind through the cochlea, which may be challenging with typical glass fibers. There’s interesting ongoing research in flexible polymer fibers, which might have better mechanical characteristics, but so far, they haven’t matched glass in efficiency of light propagation. The fiber-optic approach could have efficiency drawbacks, because we’d lose some light when it goes from the laser diode to the fiber, when it travels down the fiber, and when it goes from the fiber to the cochlea. But the approach seems promising, as it ensures that the optoelectronic components could be safely sealed up and would likely make for an easy insertion of the flexible waveguide array.
</p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="Two micrograph images show thin black tubes of varying lengths with tips that glow with a reddish light. " class="rm-shortcode" data-rm-shortcode-id="1c7e34e5335c50277d459596b2d2d6fc" data-rm-shortcode-name="rebelmouse-image" id="c6738" loading="lazy" src="https://spectrum.ieee.org/media-library/two-micrograph-images-show-thin-black-tubes-of-varying-lengths-with-tips-that-glow-with-a-reddish-light.jpg?id=30131576&width=980"/>
<small class="image-media media-caption" placeholder="Add Photo Caption...">Another design possibility for optical cochlear implants is to use laser diodes as a light source and pair them with optical fibers made of a flexible polymer. The laser diode could be safely encapsulated outside the cochlea, which would reduce concerns about heat, while polymer waveguide arrays [left and right images] would curl into the cochlea to deliver the light to the cells.</small>
<small class="image-media media-photo-credit" placeholder="Add Photo Credit...">OptoGenTech</small>
</p><h2><strong>The road to clinical trials</strong></h2><p>
	As we consider assembling these components into a commercial medical device, we first look for parts of existing cochlear implants that we can adopt. The audio processors that work with today’s cochlear implants can be adapted to our purpose; we’ll just need to split up the signal into more channels with smaller frequency ranges. The external transmitter and implanted receiver also could be similar to existing technologies, which will make our regulatory pathway that much easier. But the truly novel parts of our system—the optical stimulator and the gene therapy to deliver the channelrhodopsins to the cochlea—will require a good amount of scrutiny.
</p><p>
	Cochlear implant surgery is quite mature and typically takes only a couple of hours at most. To keep things simple, we want to keep our procedure as close as possible to existing surgeries. But the key part of the surgery will be quite different: Instead of inserting electrodes into the cochlea, surgeons will first administer viral vectors to deliver the genes for the channelrhodopsin to the cochlear nerve cells, and then implant the light emitter into the cochlea.
</p><h3>Hearing Upgrade</h3><br/>Today’s electrical cochlear implants divide rich sounds up into a small number of frequency bands and send the signals to a limited number of electrodes. Optical cochlear implants could have many more stimulation sites, meaning that sound could be divided into many more frequency bands.<p>
<br/>
</p><div class="horizontal-rule">
</div><h3><br/></h3><h3>Original</h3><div class="rm-embed embed-media">
<script src="https://cdn.jwplayer.com/players/Vsz7pOmK-bxGY83BN.js"> </script>
</div><p>
<br/>
</p><h3>8 channels</h3><div class="rm-embed embed-media">
<script src="https://cdn.jwplayer.com/players/7XtQzJjY-bxGY83BN.js"> </script>
</div><p>
<br/>
</p><h3>64 channels</h3><div class="rm-embed embed-media">
<script src="https://cdn.jwplayer.com/players/rQjmJbph-bxGY83BN.js"> </script>
</div><p>
	Since optogenetic therapies are just beginning to be tested in clinical trials, there’s still some uncertainty about how best to make the technique work in humans. We’re still thinking about how to get the viral vector to deliver the necessary genes to the correct neurons in the cochlea. The viral vector we’ve used in experiments thus far, an 
	<a href="https://en.wikipedia.org/wiki/Adeno-associated_virus" target="_blank">adeno-associated virus</a>, is a harmless virus that has already been approved for use in <a href="https://www.nature.com/articles/s41573-019-0012-9" target="_blank">several gene therapies</a>, and we’re using some genetic tricks and local administration to target cochlear neurons specifically. We’ve already begun gathering data about the <a href="https://www.life-science-alliance.org/content/5/8/e202101338" target="_blank">stability of the optogenetically altered cells</a> and whether they’ll need repeated injections of the channelrhodopsin genes to stay responsive to light.
</p><p>
	Our roadmap to clinical trials is very ambitious. We’re working now to finalize and freeze the design of the device, and we have ongoing preclinical studies in animals to check for phototoxicity and prove the efficacy of the basic idea. We aim to begin our first-in-human study in 2026, in which we’ll find the safest dose for the gene therapy. We hope to launch a large phase 3 clinical trial in 2028 to collect data that we’ll use in submitting the device for regulatory approval, which we could win in the early 2030s.
</p><p>
	We foresee a future in which beams of light can bring rich soundscapes to people with profound hearing loss or deafness. We hope that the optical cochlear implant will enable them to pick out voices in a busy meeting, appreciate the subtleties of their favorite songs, and take in the full spectrum of sound—from trilling birdsongs to booming bass notes. We think this technology has the potential to illuminate their auditory worlds. 
	<span class="ieee-end-mark"></span>
</p>]]></description><pubDate>Mon, 18 Jul 2022 15:00:00 +0000</pubDate><guid>https://spectrum.ieee.org/cochlear-implant</guid><category>Cochlear implant</category><category>Hearing</category><category>Hearing loss</category><category>Optogenetics</category><dc:creator>Tobias Moser</dc:creator><media:content medium="image" type="image/jpeg" url="https://spectrum.ieee.org/media-library/a-computer-graphic-shows-a-gray-structure-thats-curled-like-a-snails-shell-a-big-purple-line-runs-through-it-many-clusters-o.jpg?id=30131021&amp;width=980"></media:content></item><item><title>A Breath Test for Monitoring Glucose Levels</title><link>https://spectrum.ieee.org/glucose-test-e-nose</link><description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/illustration-of-open-mouth.jpg?id=30132237&width=1245&height=700&coordinates=0%2C187%2C0%2C187"/><br/><br/><p>
<p>
<em>This article is part of our exclusive <a href="https://spectrum.ieee.org/collections/journal-watch/" rel="noopener noreferrer" target="_self">IEEE Journal Watch series</a> in partnership with IEEE Xplore.</em>
</p>
</p><p>
	Diabetes is a very common condition affecting roughly <a href="https://www.cdc.gov/diabetes/pdfs/data/statistics/national-diabetes-statistics-report.pdf" rel="noopener noreferrer" target="_blank">10 percent</a> of the U.S. population—and, <a href="https://www.who.int/health-topics/diabetes#tab=tab_1" target="_blank">according to the World Health Organization</a>, there are 422 million people living with diabetes around the world. To manage the disease, people must test their blood glucose levels several times a day, which often involves finger pricks and can be burdensome and painful.
</p><p>
	In recent years, some <a href="https://www.healthline.com/diabetesmine/non-invasive-diabetes-technology" target="_blank">noninvasive, wearable devices for measuring glucose</a> have hit the market, but these devices are typically expensive and still depend on direct sampling and interaction with blood. However, a newly designed e-nose that can measure glucose levels based on a person’s breath could offer people with diabetes a different noninvasive and low-cost solution. The e-nose is described in a <a href="https://ieeexplore.ieee.org/document/9789967" rel="noopener noreferrer" target="_blank">study</a> published 7 June in <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=7361" rel="noopener noreferrer" target="_blank"><em>IEEE Sensors Journal</em></a>.
</p><p>
	E-noses are devices that detect and analyze chemicals in the air in real time, determining the nature of the substance at hand. They are being designed for a wide range of tasks, including  <a href="https://spectrum.ieee.org/electronic-nose-whiskey" target="_self">sniffing out good whiskey</a>, monitoring crops, and detecting lung cancer.
</p><p>
	Qiliang Li is a Professor in the <a href="https://ece.gmu.edu/" target="_blank">Department of Electrical and Computer Engineering</a> at George Mason University who’s been interested in developing similar technology for measuring glucose levels on a person’s breath. Although glucose isn’t exhaled in breath, the concentration of <a href="https://pubs.rsc.org/en/content/articlelanding/2021/an/d1an00402f#:~:text=The%20levels%20of%20acetone%20and,dietary%20fat%20loss%20and%20diabetes." target="_blank">acetone and other ketones</a> in the exhaled breath is associated with human metabolic conditions, including diabetes.
</p><p>
	“To alleviate the pain and danger for the patients, we created an e-nose for noninvasive, painless, low-cost, and frequent diabetes testing,” says Li. “The e-nose is designed to identify the ‘smell’ of exhaled breath which contains certain level of acetone and other ketones. Therefore, the smell is an indicator of glucose level in the blood.”
</p><p>
	The e-nose designed by Li’s team contains an array of 12 different chemical sensors and a microprocessor. When the e-nose sniffs the exhaled breath, the chemical sensors will send electrical response to the microprocessor, which processes the signals into digital information. “The e-nose will then analyze the digital information with our database and give a correct number of glucose levels,” explains Dr. Xiangdong Zhou, a professor at the Respiratory Department of Nanjing Medical University, in Nanjing, China, who was also involved in the study.
</p><p>
	In their study, the researchers collected breath samples from 41 study participants with a range of glucose levels and used the data to train the e-nose with a range of machine-learning algorithms until they found a combination of models that could detect glucose levels on a person’s breath with 90.4 percent accuracy and an average error of 0.69 <a href="https://www.qeios.com/read/64WT29" target="_blank">millimoles per liter</a> (mmol/L) in blood glucose concentration.
</p><p>
	Li notes that, although the system doesn’t directly measure glucose levels by blood, which is the current gold standard form of measurement, it offers several advantages. “The new e-nose enables noninvasive, painless, and low-cost measurement of glucose levels. It is designed for close monitoring of glucose levels for diabetes patients, especially for the patients with high blood sugar and Type 1 patients who need insulin medication frequently,” he says.
</p><p>
	Next, Li says the team is interested in designing a new chip for the chemical sensor arrays to create a more precise e-nose. As well, he says, “We plan to recruit more patients with different body mass index (BMI), living styles, and diet for testing and build a comprehensive database of exhaled breath and glucose levels.”
</p><p>
<em>This article appears in the September 2022 print issue as “A Blood-Sugar Breathalyzer for Diabetics.”</em>
</p>]]></description><pubDate>Fri, 15 Jul 2022 17:17:43 +0000</pubDate><guid>https://spectrum.ieee.org/glucose-test-e-nose</guid><category>E-nose</category><category>Machine learning</category><category>Diabetes</category><category>Journal watch</category><dc:creator>Michelle Hampson</dc:creator><media:content medium="image" type="image/jpeg" url="https://spectrum.ieee.org/media-library/illustration-of-open-mouth.jpg?id=30132237&amp;width=980"></media:content></item></channel></rss>