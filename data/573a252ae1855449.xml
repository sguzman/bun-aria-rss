<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	
	xmlns:georss="http://www.georss.org/georss"
	xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#"
	>

<channel>
	<title>AnalytiXon</title>
	<atom:link href="https://analytixon.com/feed/" rel="self" type="application/rss+xml" />
	<link>https://analytixon.com</link>
	<description>Broaden your Horizon</description>
	<lastBuildDate>Fri, 04 Nov 2022 18:19:32 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	

<image>
	<url>https://s0.wp.com/i/webclip.png</url>
	<title>AnalytiXon</title>
	<link>https://analytixon.com</link>
	<width>32</width>
	<height>32</height>
</image> 
<site xmlns="com-wordpress:feed-additions:1">82209298</site>	<item>
		<title>If you did not already know</title>
		<link>https://analytixon.com/2022/11/04/if-you-did-not-already-know-1877/</link>
					<comments>https://analytixon.com/2022/11/04/if-you-did-not-already-know-1877/#respond</comments>
		
		<dc:creator><![CDATA[Michael Laux]]></dc:creator>
		<pubDate>Fri, 04 Nov 2022 18:19:32 +0000</pubDate>
				<category><![CDATA[What is ...]]></category>
		<guid isPermaLink="false">https://analytixon.com/?p=37455</guid>

					<description><![CDATA[MAESTRO We present MAESTRO, a framework to describe and analyze CNN dataflows, and predict performance and energy-efficiency when running neural &#8230;<p><a href="https://analytixon.com/2022/11/04/if-you-did-not-already-know-1877/">Continue reading <span class="meta-nav">&#8594;</span></a></p>]]></description>
										<content:encoded><![CDATA[<p><a href="http://arxiv.org/abs/1805.02566v1" target="top" rel="noopener"><strong>MAESTRO</strong></a>  <a href="https://www.google.de/search?q=MAESTRO" target="_blank" rel="noopener"><img decoding="async" class="alignright" src="https://analytixon.files.wordpress.com/2015/01/google.png?w=529" alt="google" data-recalc-dims="1"/></a><BR/><span style="font-size:12px;font-style:normal;text-align:justify;">We present MAESTRO, a framework to describe and analyze CNN dataflows, and predict performance and energy-efficiency when running neural network layers across various hardware configurations. This includes two components: (i) a concise language to describe arbitrary dataflows and (ii) and analysis framework that accepts the dataflow description, hardware resource description, and DNN layer description as inputs and generates buffer requirements, buffer access counts, network-on-chip (NoC) bandwidth requirements, and roofline performance information. We demonstrate both components across several dataflows as case studies. &#8230; </span><BR/><BR/><a href="http://arxiv.org/abs/1809.09262v1" target="top" rel="noopener"><strong>RBFI Unit</strong></a>  <a href="https://www.google.de/search?q=RBFI Unit" target="_blank" rel="noopener"><img decoding="async" class="alignright" src="https://analytixon.files.wordpress.com/2015/01/google.png?w=529" alt="google" data-recalc-dims="1"/></a><BR/><span style="font-size:12px;font-style:normal;text-align:justify;">In adversarial attacks to machine-learning classifiers, small perturbations are added to input that is correctly classified. The perturbations yield adversarial examples, which are virtually indistinguishable from the unperturbed input, and yet are misclassified. In standard neural networks used for deep learning, attackers can craft adversarial examples from most input to cause a misclassification of their choice. We introduce a new type of network units, called RBFI units, whose non-linear structure makes them inherently resistant to adversarial attacks. On permutation-invariant MNIST, in absence of adversarial attacks, networks using RBFI units match the performance of networks using sigmoid units, and are slightly below the accuracy of networks with ReLU units. When subjected to adversarial attacks, networks with RBFI units retain accuracies above 90% for attacks that degrade the accuracy of networks with ReLU or sigmoid units to below 2%. RBFI networks trained with regular input are superior in their resistance to adversarial attacks even to ReLU and sigmoid networks trained with the help of adversarial examples. The non-linear structure of RBFI units makes them difficult to train using standard gradient descent. We show that networks of RBFI units can be efficiently trained to high accuracies using pseudogradients, computed using functions especially crafted to facilitate learning instead of their true derivatives. We show that the use of pseudogradients makes training deep RBFI networks practical, and we compare several structural alternatives of RBFI networks for their accuracy. &#8230; </span><BR/><BR/><a href="http://arxiv.org/abs/1902.04149v1" target="top" rel="noopener"><strong>Multimodal Deep Hashing Neural Decoder (MDHND)</strong></a>  <a href="https://www.google.de/search?q=Multimodal Deep Hashing Neural Decoder" target="_blank" rel="noopener"><img decoding="async" class="alignright" src="https://analytixon.files.wordpress.com/2015/01/google.png?w=529" alt="google" data-recalc-dims="1"/></a><BR/><span style="font-size:12px;font-style:normal;text-align:justify;">In this paper, we propose a novel three-stage multimodal deep hashing neural decoder (MDHND) architecture, which integrates a deep hashing framework with a neural network decoder (NND) to create an effective multibiometric authentication system. The MDHND consists of two separate modules: a multimodal deep hashing (MDH) module, which is used for feature-level fusion and binarization of multiple biometrics, and a neural network decoder (NND) module, which is used to refine the intermediate binary codes generated by the MDH and compensate for the difference between enrollment and probe biometrics (variations in pose, illumination, etc.). Use of NND helps to improve the performance of the overall multimodal authentication system. The MDHND framework is trained in 3 stages using joint optimization of the two modules. In Stage 1, the MDH parameters are trained and learned to generate a shared multimodal latent code; in Stage 2, the latent codes from Stage 1 are passed through a conventional error-correcting code (ECC) decoder to generate the ground truth to train a neural network decoder (NND); in Stage 3, the NND decoder is trained using the ground truth from Stage 2 and the MDH and NND are jointly optimized. Experimental results on a standard multimodal dataset demonstrate the superiority of our method relative to other current multimodal authentication systems. Furthermore, the proposed system can work in both identification and authentication modes. &#8230; </span><BR/><BR/><a href="http://arxiv.org/abs/1809.06147v1" target="top" rel="noopener"><strong>Feature2Mass</strong></a>  <a href="https://www.google.de/search?q=Feature2Mass" target="_blank" rel="noopener"><img decoding="async" class="alignright" src="https://analytixon.files.wordpress.com/2015/01/google.png?w=529" alt="google" data-recalc-dims="1"/></a><BR/><span style="font-size:12px;font-style:normal;text-align:justify;">This paper deals with a method for generating realistic labeled masses. Recently, there have been many attempts to apply deep learning to various bio-image computing fields including computer-aided detection and diagnosis. In order to learn deep network model to be well-behaved in bio-image computing fields, a lot of labeled data is required. However, in many bioimaging fields, the large-size of labeled dataset is scarcely available. Although a few researches have been dedicated to solving this problem through generative model, there are some problems as follows: 1) The generated bio-image does not seem realistic; 2) the variation of generated bio-image is limited; and 3) additional label annotation task is needed. In this study, we propose a realistic labeled bio-image generation method through visual feature processing in latent space. Experimental results have shown that mass images generated by the proposed method were realistic and had wide expression range of targeted mass characteristics. &#8230; </span><BR/></p>
]]></content:encoded>
					
					<wfw:commentRss>https://analytixon.com/2022/11/04/if-you-did-not-already-know-1877/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">37455</post-id>	</item>
		<item>
		<title>If you did not already know</title>
		<link>https://analytixon.com/2022/11/03/if-you-did-not-already-know-1876/</link>
					<comments>https://analytixon.com/2022/11/03/if-you-did-not-already-know-1876/#respond</comments>
		
		<dc:creator><![CDATA[Michael Laux]]></dc:creator>
		<pubDate>Thu, 03 Nov 2022 02:03:17 +0000</pubDate>
				<category><![CDATA[What is ...]]></category>
		<guid isPermaLink="false">https://analytixon.com/?p=37445</guid>

					<description><![CDATA[Extended Fourier Amplitude Sensitivity Test Excluding irrelevant features in a pattern recognition task plays an important role in maintaining a &#8230;<p><a href="https://analytixon.com/2022/11/03/if-you-did-not-already-know-1876/">Continue reading <span class="meta-nav">&#8594;</span></a></p>]]></description>
										<content:encoded><![CDATA[<p><a href="http://arxiv.org/abs/1804.05092v1" target="top" rel="noopener"><strong>Extended Fourier Amplitude Sensitivity Test</strong></a>  <a href="https://www.google.de/search?q=Extended Fourier Amplitude Sensitivity Test" target="_blank" rel="noopener"><img decoding="async" class="alignright" src="https://analytixon.files.wordpress.com/2015/01/google.png?w=529" alt="google" data-recalc-dims="1"/></a><BR/><span style="font-size:12px;font-style:normal;text-align:justify;">Excluding irrelevant features in a pattern recognition task plays an important role in maintaining a simpler machine learning model and optimizing the computational efficiency. Nowadays with the rise of large scale datasets, feature selection is in great demand as it becomes a central issue when facing high-dimensional datasets. The present study provides a new measure of saliency for features by employing a Sensitivity Analysis (SA) technique called the extended Fourier amplitude sensitivity test, and a well-trained Feedforward Neural Network (FNN) model, which ultimately leads to the selection of a promising optimal feature subset. Ideas of the paper are mainly demonstrated based on adopting FNN model for feature selection in classification problems. But in the end, a generalization framework is discussed in order to give insights into the usage in regression problems as well as expressing how other function approximate models can be deployed. Effectiveness of the proposed method is verified by result analysis and data visualization for a series of experiments over several well-known datasets drawn from UCI machine learning repository. &#8230; </span><BR/><BR/><a href="http://arxiv.org/abs/1905.02266v1" target="top" rel="noopener"><strong>Maximally Filtered Clique Forest (MFCF)</strong></a>  <a href="https://www.google.de/search?q=Maximally Filtered Clique Forest" target="_blank" rel="noopener"><img decoding="async" class="alignright" src="https://analytixon.files.wordpress.com/2015/01/google.png?w=529" alt="google" data-recalc-dims="1"/></a><BR/><span style="font-size:12px;font-style:normal;text-align:justify;">We propose a topological learning algorithm for the estimation of the conditional dependency structure of large sets of random variables from sparse and noisy data. The algorithm, named Maximally Filtered Clique Forest (MFCF), produces a clique forest and an associated Markov Random Field (MRF) by generalising Prim&#8217;s minimum spanning tree algorithm. To the best of our knowledge, the MFCF presents three elements of novelty with respect to existing structure learning approaches. The first is the repeated application of a local topological move, the clique expansion, that preserves the decomposability of the underlying graph. Through this move the decomposability and calculation of scores is performed incrementally at the variable (rather than edge) level, and this provides better computational performance and an intuitive application of multivariate statistical tests. The second is the capability to accommodate a variety of score functions and, while this paper is focused on multivariate normal distributions, it can be directly generalised to different types of statistics. Finally, the third is the variable range of allowed clique sizes which is an adjustable topological constraint that acts as a topological penalizer providing a way to tackle sparsity at $l_0$ semi-norm level; this allows a clean decoupling of structure learning and parameter estimation. The MFCF produces a representation of the clique forest, together with a perfect ordering of the cliques and a perfect elimination ordering for the vertices. As an example we propose an application to covariance selection models and we show that the MCFC outperforms the Graphical Lasso for a number of classes of matrices. &#8230; </span><BR/><BR/><a href="http://arxiv.org/abs/1806.08198v1" target="top" rel="noopener"><strong>DPP-Net</strong></a>  <a href="https://www.google.de/search?q=DPP-Net" target="_blank" rel="noopener"><img decoding="async" class="alignright" src="https://analytixon.files.wordpress.com/2015/01/google.png?w=529" alt="google" data-recalc-dims="1"/></a><BR/><span style="font-size:12px;font-style:normal;text-align:justify;">Recent breakthroughs in Neural Architectural Search (NAS) have achieved state-of-the-art performances in applications such as image classification and language modeling. However, these techniques typically ignore device-related objectives such as inference time, memory usage, and power consumption. Optimizing neural architecture for device-related objectives is immensely crucial for deploying deep networks on portable devices with limited computing resources. We propose DPP-Net: Device-aware Progressive Search for Pareto-optimal Neural Architectures, optimizing for both device-related (e.g., inference time and memory usage) and device-agnostic (e.g., accuracy and model size) objectives. DPP-Net employs a compact search space inspired by current state-of-the-art mobile CNNs, and further improves search efficiency by adopting progressive search (Liu et al. 2017). Experimental results on CIFAR-10 are poised to demonstrate the effectiveness of Pareto-optimal networks found by DPP-Net, for three different devices: (1) a workstation with Titan X GPU, (2) NVIDIA Jetson TX1 embedded system, and (3) mobile phone with ARM Cortex-A53. Compared to CondenseNet and NASNet-A (Mobile), DPP-Net achieves better performances: higher accuracy and shorter inference time on various devices. Additional experimental results show that models found by DPP-Net also achieve considerably-good performance on ImageNet as well. &#8230; </span><BR/><BR/><a href="http://arxiv.org/abs/1905.11452v1" target="top" rel="noopener"><strong>Differentiable Quantization</strong></a>  <a href="https://www.google.de/search?q=Differentiable Quantization" target="_blank" rel="noopener"><img decoding="async" class="alignright" src="https://analytixon.files.wordpress.com/2015/01/google.png?w=529" alt="google" data-recalc-dims="1"/></a><BR/><span style="font-size:12px;font-style:normal;text-align:justify;">We propose differentiable quantization (DQ) for efficient deep neural network (DNN) inference where gradient descent is used to learn the quantizer&#8217;s step size, dynamic range and bitwidth. Training with differentiable quantizers brings two main benefits: first, DQ does not introduce hyperparameters; second, we can learn for each layer a different step size, dynamic range and bitwidth. Our experiments show that DNNs with heterogeneous and learned bitwidth yield better performance than DNNs with a homogeneous one. Further, we show that there is one natural DQ parametrization especially well suited for training. We confirm our findings with experiments on CIFAR-10 and ImageNet and we obtain quantized DNNs with learned quantization parameters achieving state-of-the-art performance. &#8230; </span><BR/></p>
]]></content:encoded>
					
					<wfw:commentRss>https://analytixon.com/2022/11/03/if-you-did-not-already-know-1876/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">37445</post-id>	</item>
		<item>
		<title>If you did not already know</title>
		<link>https://analytixon.com/2022/11/02/if-you-did-not-already-know-1875/</link>
					<comments>https://analytixon.com/2022/11/02/if-you-did-not-already-know-1875/#respond</comments>
		
		<dc:creator><![CDATA[Michael Laux]]></dc:creator>
		<pubDate>Wed, 02 Nov 2022 22:23:36 +0000</pubDate>
				<category><![CDATA[What is ...]]></category>
		<guid isPermaLink="false">https://analytixon.com/?p=37443</guid>

					<description><![CDATA[Self-Attention Capsule Network (SACN) We propose a novel architecture for image classification, called Self-Attention Capsule Networks (SACN). SACN is the &#8230;<p><a href="https://analytixon.com/2022/11/02/if-you-did-not-already-know-1875/">Continue reading <span class="meta-nav">&#8594;</span></a></p>]]></description>
										<content:encoded><![CDATA[<p><a href="http://arxiv.org/abs/1904.12483v1" target="top" rel="noopener"><strong>Self-Attention Capsule Network (SACN)</strong></a>  <a href="https://www.google.de/search?q=Self-Attention Capsule Network" target="_blank" rel="noopener"><img decoding="async" class="alignright" src="https://analytixon.files.wordpress.com/2015/01/google.png?w=529" alt="google" data-recalc-dims="1"/></a><BR/><span style="font-size:12px;font-style:normal;text-align:justify;">We propose a novel architecture for image classification, called Self-Attention Capsule Networks (SACN). SACN is the first model that incorporates the Self-Attention mechanism as an integral layer within the Capsule Network (CapsNet). While the Self-Attention mechanism selects the more dominant image regions to focus on, the CapsNet analyzes the relevant features and their spatial correlations inside these regions only. The features are extracted in the convolutional layer. Then, the Self-Attention layer learns to suppress irrelevant regions based on features analysis, and highlights salient features useful for a specific task. The attention map is then fed into the CapsNet primary layer that is followed by a classification layer. The SACN proposed model was designed to use a relatively shallow CapsNet architecture to reduce computational load, and compensates for the absence of a deeper network by using the Self-Attention module to significantly improve the results. The proposed Self-Attention CapsNet architecture was extensively evaluated on five different datasets, mainly on three different medical sets, in addition to the natural MNIST and SVHN. The model was able to classify images and their patches with diverse and complex backgrounds better than the baseline CapsNet. As a result, the proposed Self-Attention CapsNet significantly improved classification performance within and across different datasets and outperformed the baseline CapsNet not only in classification accuracy but also in robustness. &#8230; </span><BR/><BR/><a href="http://arxiv.org/abs/1905.08965v1" target="top" rel="noopener"><strong>U-SAID</strong></a>  <a href="https://www.google.de/search?q=U-SAID" target="_blank" rel="noopener"><img decoding="async" class="alignright" src="https://analytixon.files.wordpress.com/2015/01/google.png?w=529" alt="google" data-recalc-dims="1"/></a><BR/><span style="font-size:12px;font-style:normal;text-align:justify;">Several recent works discussed application-driven image restoration neural networks, which are capable of not only removing noise in images but also preserving their semantic-aware details, making them suitable for various high-level computer vision tasks as the pre-processing step. However, such approaches require extra annotations for their high-level vision tasks, in order to train the joint pipeline using hybrid losses. The availability of those annotations is yet often limited to a few image sets, potentially restricting the general applicability of these methods to denoising more unseen and unannotated images. Motivated by that, we propose a segmentation-aware image denoising model dubbed U-SAID, based on a novel unsupervised approach with a pixel-wise uncertainty loss. U-SAID does not need any ground-truth segmentation map, and thus can be applied to any image dataset. It generates denoised images with comparable or even better quality, and the denoised results show stronger robustness for subsequent semantic segmentation tasks, when compared to either its supervised counterpart or classical &#8216;application-agnostic&#8217; denoisers. Moreover, we demonstrate the superior generalizability of U-SAID in three-folds, by plugging its &#8216;universal&#8217; denoiser without fine-tuning: (1) denoising unseen types of images; (2) denoising as pre-processing for segmenting unseen noisy images; and (3) denoising for unseen high-level tasks. Extensive experiments demonstrate the effectiveness, robustness and generalizability of the proposed U-SAID over various popular image sets. &#8230; </span><BR/><BR/><a href="https://arxiv.org/abs/1509.09187" target="top" rel="noopener"><strong>Deep Haar Scattering Network</strong></a>  <a href="https://www.google.de/search?q=Deep Haar Scattering Network" target="_blank" rel="noopener"><img decoding="async" class="alignright" src="https://analytixon.files.wordpress.com/2015/01/google.png?w=529" alt="google" data-recalc-dims="1"/></a><BR/><span style="font-size:12px;font-style:normal;text-align:justify;">An orthogonal Haar scattering transform is a deep network, computed with a hierarchy of additions, subtractions and absolute values, over pairs of coefficients. It provides a simple mathematical model for unsupervised deep network learning. It implements non-linear contractions, which are optimized for classification, with an unsupervised pair matching algorithm, of polynomial complexity. A structured Haar scattering over graph data computes permutation invariant representations of groups of connected points in the graph. If the graph connectivity is unknown, unsupervised Haar pair learning can provide a consistent estimation of connected dyadic groups of points. Classification results are given on image data bases, defined on regular grids or graphs, with a connectivity which may be known or unknown. &#8230; </span><BR/><BR/><a href="http://arxiv.org/abs/1802.00212v1" target="top" rel="noopener"><strong>Power Linear Unit (PoLU)</strong></a>  <a href="https://www.google.de/search?q=Power Linear Unit" target="_blank" rel="noopener"><img decoding="async" class="alignright" src="https://analytixon.files.wordpress.com/2015/01/google.png?w=529" alt="google" data-recalc-dims="1"/></a><BR/><span style="font-size:12px;font-style:normal;text-align:justify;">In this paper, we introduce &#8216;Power Linear Unit&#8217; (PoLU) which increases the nonlinearity capacity of a neural network and thus helps improving its performance. PoLU adopts several advantages of previously proposed activation functions. First, the output of PoLU for positive inputs is designed to be identity to avoid the gradient vanishing problem. Second, PoLU has a non-zero output for negative inputs such that the output mean of the units is close to zero, hence reducing the bias shift effect. Thirdly, there is a saturation on the negative part of PoLU, which makes it more noise-robust for negative inputs. Furthermore, we prove that PoLU is able to map more portions of every layer&#8217;s input to the same space by using the power function and thus increases the number of response regions of the neural network. We use image classification for comparing our proposed activation function with others. In the experiments, MNIST, CIFAR-10, CIFAR-100, Street View House Numbers (SVHN) and ImageNet are used as benchmark datasets. The neural networks we implemented include widely-used ELU-Network, ResNet-50, and VGG16, plus a couple of shallow networks. Experimental results show that our proposed activation function outperforms other state-of-the-art models with most networks. &#8230; </span><BR/></p>
]]></content:encoded>
					
					<wfw:commentRss>https://analytixon.com/2022/11/02/if-you-did-not-already-know-1875/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">37443</post-id>	</item>
		<item>
		<title>If you did not already know</title>
		<link>https://analytixon.com/2022/11/01/if-you-did-not-already-know-1874/</link>
					<comments>https://analytixon.com/2022/11/01/if-you-did-not-already-know-1874/#respond</comments>
		
		<dc:creator><![CDATA[Michael Laux]]></dc:creator>
		<pubDate>Tue, 01 Nov 2022 20:21:45 +0000</pubDate>
				<category><![CDATA[What is ...]]></category>
		<guid isPermaLink="false">https://analytixon.com/?p=37441</guid>

					<description><![CDATA[Latent Mixture Sampling (LMS) In this paper we propose a novel neural language modelling (NLM) method based on \textit{error-correcting output &#8230;<p><a href="https://analytixon.com/2022/11/01/if-you-did-not-already-know-1874/">Continue reading <span class="meta-nav">&#8594;</span></a></p>]]></description>
										<content:encoded><![CDATA[<p><a href="http://arxiv.org/abs/1901.07002v1" target="top" rel="noopener"><strong>Latent Mixture Sampling (LMS)</strong></a>  <a href="https://www.google.de/search?q=Latent Mixture Sampling" target="_blank" rel="noopener"><img decoding="async" class="alignright" src="https://analytixon.files.wordpress.com/2015/01/google.png?w=529" alt="google" data-recalc-dims="1"/></a><BR/><span style="font-size:12px;font-style:normal;text-align:justify;">In this paper we propose a novel neural language modelling (NLM) method based on \textit{error-correcting output codes} (ECOC), abbreviated as ECOC-NLM (error-correcting output codes &#8211; neural language modelling). This latent variable based approach provides a principled way to choose a varying amount of latent output codes and avoids exact softmax normalization. Instead of minimizing measures between the predicted probability distribution and true distribution, we use error-correcting codes to represent both predictions and outputs. Secondly, we propose multiple ways to improve accuracy and convergence rates by maximizing the separability between codes that correspond to classes proportional to word embedding similarities. Lastly, we introduce a novel method called \textit{Latent Mixture Sampling}, a technique that is used to mitigate exposure bias and can be integrated into training latent-based neural language models. This involves mixing the latent codes (i.e variables) of past predictions and past targets in one of two ways: (1) according to a predefined sampling schedule or (2) a differentiable sampling procedure whereby the mixing probability is learned throughout training by replacing the greedy argmax operation with a smooth approximation. In evaluating Codeword Mixture Sampling for ECOC-NLM, we also baseline it against CWMS in a closely related Hierarhical Softmax-based NLM. &#8230; </span><BR/><BR/><a href="http://arxiv.org/abs/1904.12639v1" target="top" rel="noopener"><strong>Inner-Imaging Architecture</strong></a>  <a href="https://www.google.de/search?q=Inner-Imaging Architecture" target="_blank" rel="noopener"><img decoding="async" class="alignright" src="https://analytixon.files.wordpress.com/2015/01/google.png?w=529" alt="google" data-recalc-dims="1"/></a><BR/><span style="font-size:12px;font-style:normal;text-align:justify;">Despite the tremendous success in computer vision, deep convolutional networks suffer from serious computation cost and redundancies. Although previous works address this issue by enhancing diversities of filters, they ignore that both complementarity and completeness are required in the internal structure of convolutional network. In this setting, we propose a novel Inner-Imaging architecture, which allows relationships between channels to meet the above requirement. Specifically, we organize the filter signal points in groups using convolutional kernels to model both the intra- and inter-group relationships simultaneously. Consequently, we not only increase diversities of channels but also explicitly enhance the complementarity and completeness. Our proposed architecture is lightweight and easy to be implemented for improving the modelling efficiency and performance. We conduct extensive experiments on CIFAR, SVHN and ImageNet and verify the effectiveness of our inner-imaging architecture with residual networks as the backbone. &#8230; </span><BR/><BR/><a href="http://arxiv.org/abs/1905.05957v1" target="top" rel="noopener"><strong>DoubleSqueeze</strong></a>  <a href="https://www.google.de/search?q=DoubleSqueeze" target="_blank" rel="noopener"><img decoding="async" class="alignright" src="https://analytixon.files.wordpress.com/2015/01/google.png?w=529" alt="google" data-recalc-dims="1"/></a><BR/><span style="font-size:12px;font-style:normal;text-align:justify;">A standard approach in large scale machine learning is distributed stochastic gradient training, which requires the computation of aggregated stochastic gradients over multiple nodes on a network. Communication is a major bottleneck in such applications, and in recent years, compressed stochastic gradient methods such as QSGD (quantized SGD) and sparse SGD have been proposed to reduce communication. It was also shown that error compensation can be combined with compression to achieve better convergence in a scheme that each node compresses its local stochastic gradient and broadcast the result to all other nodes over the network in a single pass. However, such a single pass broadcast approach is not realistic in many practical implementations. For example, under the popular parameter server model for distributed learning, the worker nodes need to send the compressed local gradients to the parameter server, which performs the aggregation. The parameter server has to compress the aggregated stochastic gradient again before sending it back to the worker nodes. In this work, we provide a detailed analysis on this two-pass communication model and its asynchronous parallel variant, with error-compensated compression both on the worker nodes and on the parameter server. We show that the error-compensated stochastic gradient algorithm admits three very nice properties: 1) it is compatible with an \emph{arbitrary} compression technique; 2) it admits an improved convergence rate than the non error-compensated stochastic gradient methods such as QSGD and sparse SGD; 3) it admits linear speedup with respect to the number of workers. The empirical study is also conducted to validate our theoretical results. &#8230; </span><BR/><BR/><a href="http://arxiv.org/abs/1711.04192v1" target="top" rel="noopener"><strong>Latent Constrained Correlation Filter (LCCF)</strong></a>  <a href="https://www.google.de/search?q=Latent Constrained Correlation Filter" target="_blank" rel="noopener"><img decoding="async" class="alignright" src="https://analytixon.files.wordpress.com/2015/01/google.png?w=529" alt="google" data-recalc-dims="1"/></a><BR/><span style="font-size:12px;font-style:normal;text-align:justify;">Correlation filters are special classifiers designed for shift-invariant object recognition, which are robust to pattern distortions. The recent literature shows that combining a set of sub-filters trained based on a single or a small group of images obtains the best performance. The idea is equivalent to estimating variable distribution based on the data sampling (bagging), which can be interpreted as finding solutions (variable distribution approximation) directly from sampled data space. However, this methodology fails to account for the variations existed in the data. In this paper, we introduce an intermediate step &#8212; solution sampling &#8212; after the data sampling step to form a subspace, in which an optimal solution can be estimated. More specifically, we propose a new method, named latent constrained correlation filters (LCCF), by mapping the correlation filters to a given latent subspace, and develop a new learning framework in the latent subspace that embeds distribution-related constraints into the original problem. To solve the optimization problem, we introduce a subspace based alternating direction method of multipliers (SADMM), which is proven to converge at the saddle point. Our approach is successfully applied to three different tasks, including eye localization, car detection and object tracking. Extensive experiments demonstrate that LCCF outperforms the state-of-the-art methods. The source code will be publicly available. <a href="https://github.com/bczhangbczhang/." target="top" rel="noopener">https://&#8230;/.</a>  &#8230; </span><BR/></p>
]]></content:encoded>
					
					<wfw:commentRss>https://analytixon.com/2022/11/01/if-you-did-not-already-know-1874/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">37441</post-id>	</item>
		<item>
		<title>If you did not already know</title>
		<link>https://analytixon.com/2022/10/31/if-you-did-not-already-know-1873/</link>
					<comments>https://analytixon.com/2022/10/31/if-you-did-not-already-know-1873/#respond</comments>
		
		<dc:creator><![CDATA[Michael Laux]]></dc:creator>
		<pubDate>Mon, 31 Oct 2022 02:03:17 +0000</pubDate>
				<category><![CDATA[What is ...]]></category>
		<guid isPermaLink="false">https://analytixon.com/?p=37439</guid>

					<description><![CDATA[Context-Dependent Diffusion Network (CDDN) Visual relationship detection can bridge the gap between computer vision and natural language for scene understanding &#8230;<p><a href="https://analytixon.com/2022/10/31/if-you-did-not-already-know-1873/">Continue reading <span class="meta-nav">&#8594;</span></a></p>]]></description>
										<content:encoded><![CDATA[<p><a href="http://arxiv.org/abs/1809.06213v1" target="top" rel="noopener"><strong>Context-Dependent Diffusion Network (CDDN)</strong></a>  <a href="https://www.google.de/search?q=Context-Dependent Diffusion Network" target="_blank" rel="noopener"><img decoding="async" class="alignright" src="https://analytixon.files.wordpress.com/2015/01/google.png?w=529" alt="google" data-recalc-dims="1"/></a><BR/><span style="font-size:12px;font-style:normal;text-align:justify;">Visual relationship detection can bridge the gap between computer vision and natural language for scene understanding of images. Different from pure object recognition tasks, the relation triplets of subject-predicate-object lie on an extreme diversity space, such as \textit{person-behind-person} and \textit{car-behind-building}, while suffering from the problem of combinatorial explosion. In this paper, we propose a context-dependent diffusion network (CDDN) framework to deal with visual relationship detection. To capture the interactions of different object instances, two types of graphs, word semantic graph and visual scene graph, are constructed to encode global context interdependency. The semantic graph is built through language priors to model semantic correlations across objects, whilst the visual scene graph defines the connections of scene objects so as to utilize the surrounding scene information. For the graph-structured data, we design a diffusion network to adaptively aggregate information from contexts, which can effectively learn latent representations of visual relationships and well cater to visual relationship detection in view of its isomorphic invariance to graphs. Experiments on two widely-used datasets demonstrate that our proposed method is more effective and achieves the state-of-the-art performance. &#8230; </span><BR/><BR/><a href="http://arxiv.org/abs/1712.02517v1" target="top" rel="noopener"><strong>Broadcasting Convolutional Network</strong></a>  <a href="https://www.google.de/search?q=Broadcasting Convolutional Network" target="_blank" rel="noopener"><img decoding="async" class="alignright" src="https://analytixon.files.wordpress.com/2015/01/google.png?w=529" alt="google" data-recalc-dims="1"/></a><BR/><span style="font-size:12px;font-style:normal;text-align:justify;">While convolutional neural networks (CNNs) are widely used for handling spatio-temporal scenes, there exist limitations in reasoning relations among spatial features caused by their inherent structures, which have been issued consistently in many studies. In this paper, we propose Broadcasting Convolutional Networks (BCN) that allow global receptive fields to share spatial information. BCNs are simple network modules that collect effective spatial features, embed location informations and broadcast them to the entire feature maps without much additional computational cost. This method gains great improvements in feature localization problems through efficiently extending the receptive fields, and can easily be implemented within any structure of CNNs. We further utilize BCN to propose Multi-Relational Networks (multiRN) that greatly improve existing Relation Networks (RNs). In pixel-based relation reasoning problems, multiRN with BCNs implanted extends the concept of `pairwise relations&#8217; from conventional RNs to `multiple relations&#8217; by relating each object with multiple objects at once and not in pairs. This yields in O(n) complexity for n number of objects, which is a vast computational gain from RNs that take O(n^2). Through experiments, BCNs are proven for their usability on relation reasoning problems, which is due from their efficient handlings of spatial information. &#8230; </span><BR/><BR/><a href="http://arxiv.org/abs/1808.03908v1" target="top" rel="noopener"><strong>Adversarial Personalized Ranking (APR)</strong></a>  <a href="https://www.google.de/search?q=Adversarial Personalized Ranking" target="_blank" rel="noopener"><img decoding="async" class="alignright" src="https://analytixon.files.wordpress.com/2015/01/google.png?w=529" alt="google" data-recalc-dims="1"/></a><BR/><span style="font-size:12px;font-style:normal;text-align:justify;">Item recommendation is a personalized ranking task. To this end, many recommender systems optimize models with pairwise ranking objectives, such as the Bayesian Personalized Ranking (BPR). Using matrix Factorization (MF) &#8212; the most widely used model in recommendation &#8212; as a demonstration, we show that optimizing it with BPR leads to a recommender model that is not robust. In particular, we find that the resultant model is highly vulnerable to adversarial perturbations on its model parameters, which implies the possibly large error in generalization. To enhance the robustness of a recommender model and thus improve its generalization performance, we propose a new optimization framework, namely Adversarial Personalized Ranking (APR). In short, our APR enhances the pairwise ranking method BPR by performing adversarial training. It can be interpreted as playing a minimax game, where the minimization of the BPR objective function meanwhile defends an adversary, which adds adversarial perturbations on model parameters to maximize the BPR objective function. To illustrate how it works, we implement APR on MF by adding adversarial perturbations on the embedding vectors of users and items. Extensive experiments on three public real-world datasets demonstrate the effectiveness of APR &#8212; by optimizing MF with APR, it outperforms BPR with a relative improvement of 11.2% on average and achieves state-of-the-art performance for item recommendation. Our implementation is available at: <a href="https://github.com/hexiangnan/adversarial_personalized_ranking." target="top" rel="noopener">https://&#8230;/adversarial_personalized_ranking.</a>  &#8230; </span><BR/><BR/><a href="http://arxiv.org/abs/1802.05383v1" target="top" rel="noopener"><strong>DEEPBEAM</strong></a>  <a href="https://www.google.de/search?q=DEEPBEAM" target="_blank" rel="noopener"><img decoding="async" class="alignright" src="https://analytixon.files.wordpress.com/2015/01/google.png?w=529" alt="google" data-recalc-dims="1"/></a><BR/><span style="font-size:12px;font-style:normal;text-align:justify;">Multi-channel speech enhancement with ad-hoc sensors has been a challenging task. Speech model guided beamforming algorithms are able to recover natural sounding speech, but the speech models tend to be oversimplified or the inference would otherwise be too complicated. On the other hand, deep learning based enhancement approaches are able to learn complicated speech distributions and perform efficient inference, but they are unable to deal with variable number of input channels. Also, deep learning approaches introduce a lot of errors, particularly in the presence of unseen noise types and settings. We have therefore proposed an enhancement framework called DEEPBEAM, which combines the two complementary classes of algorithms. DEEPBEAM introduces a beamforming filter to produce natural sounding speech, but the filter coefficients are determined with the help of a monaural speech enhancement neural network. Experiments on synthetic and real-world data show that DEEPBEAM is able to produce clean, dry and natural sounding speech, and is robust against unseen noise. &#8230; </span><BR/></p>
]]></content:encoded>
					
					<wfw:commentRss>https://analytixon.com/2022/10/31/if-you-did-not-already-know-1873/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">37439</post-id>	</item>
		<item>
		<title>If you did not already know</title>
		<link>https://analytixon.com/2022/10/30/if-you-did-not-already-know-1872/</link>
					<comments>https://analytixon.com/2022/10/30/if-you-did-not-already-know-1872/#respond</comments>
		
		<dc:creator><![CDATA[Michael Laux]]></dc:creator>
		<pubDate>Sun, 30 Oct 2022 02:03:19 +0000</pubDate>
				<category><![CDATA[What is ...]]></category>
		<guid isPermaLink="false">https://analytixon.com/?p=37437</guid>

					<description><![CDATA[DensSiam Convolutional Siamese neural networks have been recently used to track objects using deep features. Siamese architecture can achieve real &#8230;<p><a href="https://analytixon.com/2022/10/30/if-you-did-not-already-know-1872/">Continue reading <span class="meta-nav">&#8594;</span></a></p>]]></description>
										<content:encoded><![CDATA[<p><a href="http://arxiv.org/abs/1809.02714v1" target="top" rel="noopener"><strong>DensSiam</strong></a>  <a href="https://www.google.de/search?q=DensSiam" target="_blank" rel="noopener"><img decoding="async" class="alignright" src="https://analytixon.files.wordpress.com/2015/01/google.png?w=529" alt="google" data-recalc-dims="1"/></a><BR/><span style="font-size:12px;font-style:normal;text-align:justify;">Convolutional Siamese neural networks have been recently used to track objects using deep features. Siamese architecture can achieve real time speed, however it is still difficult to find a Siamese architecture that maintains the generalization capability, high accuracy and speed while decreasing the number of shared parameters especially when it is very deep. Furthermore, a conventional Siamese architecture usually processes one local neighborhood at a time, which makes the appearance model local and non-robust to appearance changes. To overcome these two problems, this paper proposes DensSiam, a novel convolutional Siamese architecture, which uses the concept of dense layers and connects each dense layer to all layers in a feed-forward fashion with a similarity-learning function. DensSiam also includes a Self-Attention mechanism to force the network to pay more attention to the non-local features during offline training. Extensive experiments are performed on four tracking benchmarks: OTB2013 and OTB2015 for validation set; and VOT2015, VOT2016 and VOT2017 for testing set. The obtained results show that DensSiam achieves superior results on these benchmarks compared to other current state-of-the-art methods. &#8230; </span><BR/><BR/><a href="http://arxiv.org/abs/1706.01445v1" target="top" rel="noopener"><strong>Ensemble Bayesian Optimization (EBO)</strong></a>  <a href="https://www.google.de/search?q=Ensemble Bayesian Optimization" target="_blank" rel="noopener"><img decoding="async" class="alignright" src="https://analytixon.files.wordpress.com/2015/01/google.png?w=529" alt="google" data-recalc-dims="1"/></a><BR/><span style="font-size:12px;font-style:normal;text-align:justify;">Bayesian Optimization (BO) has been shown to be a very effective paradigm for tackling hard black-box and non-convex optimization problems encountered in Machine Learning. Despite these successes, the computational complexity of the underlying function approximation has restricted the use of BO to problems that can be handled with less than a few thousand function evaluations. Harder problems like those involving functions operating in very high dimensional spaces may require hundreds of thousands or millions of evaluations or more and become computationally intractable to handle using standard Bayesian Optimization methods. In this paper, we propose Ensemble Bayesian Optimization (EBO) to overcome this problem. Unlike conventional BO methods that operate on a single posterior GP model, EBO works with an ensemble of posterior GP models. Further, we represent each GP model using tile coding random features and an additive function structure. Our approach generates speedups by parallelizing the time consuming hyper-parameter posterior inference and functional evaluations on hundreds of cores and aggregating the models in every iteration of BO. Our extensive experimental evaluation shows that EBO can speed up the posterior inference between 2-3 orders of magnitude (400 times in one experiment) compared to the state-of-the-art by putting data into Mondrian bins without sacrificing the sample quality. We demonstrate the ability of EBO to handle sample-intensive hard optimization problems by applying it to a rover navigation problem with tens of thousands of observations. &#8230; </span><BR/><BR/><a href="http://arxiv.org/abs/1905.07375v1" target="top" rel="noopener"><strong>AutoML for Loss Function Search (AM-LFS)</strong></a>  <a href="https://www.google.de/search?q=AutoML for Loss Function Search" target="_blank" rel="noopener"><img decoding="async" class="alignright" src="https://analytixon.files.wordpress.com/2015/01/google.png?w=529" alt="google" data-recalc-dims="1"/></a><BR/><span style="font-size:12px;font-style:normal;text-align:justify;">Designing an effective loss function plays an important role in visual analysis. Most existing loss function designs rely on hand-crafted heuristics that require domain experts to explore the large design space, which is usually sub-optimal and time-consuming. In this paper, we propose AutoML for Loss Function Search (AM-LFS) which leverages REINFORCE to search loss functions during the training process. The key contribution of this work is the design of search space which can guarantee the generalization and transferability on different vision tasks by including a bunch of existing prevailing loss functions in a unified formulation. We also propose an efficient optimization framework which can dynamically optimize the parameters of loss function&#8217;s distribution during training. Extensive experimental results on four benchmark datasets show that, without any tricks, our method outperforms existing hand-crafted loss functions in various computer vision tasks. &#8230; </span><BR/><BR/><a href="http://arxiv.org/abs/1802.06931v1" target="top" rel="noopener"><strong>Empirical Bayes Matrix Factorization (EBMF)</strong></a>  <a href="https://www.google.de/search?q=Empirical Bayes Matrix Factorization" target="_blank" rel="noopener"><img decoding="async" class="alignright" src="https://analytixon.files.wordpress.com/2015/01/google.png?w=529" alt="google" data-recalc-dims="1"/></a><BR/><span style="font-size:12px;font-style:normal;text-align:justify;">Matrix factorization methods &#8211; including Factor analysis (FA), and Principal Components Analysis (PCA) &#8211; are widely used for inferring and summarizing structure in multivariate data. Many matrix factorization methods exist, corresponding to different assumptions on the elements of the underlying matrix factors. For example, many recent methods use a penalty or prior distribution to achieve sparse representations (&#8216;Sparse FA/PCA&#8217;). Here we introduce a general Empirical Bayes approach to matrix factorization (EBMF), whose key feature is that it uses the observed data to estimate prior distributions on matrix elements. We derive a correspondingly-general variational fitting algorithm, which reduces fitting EBMF to solving a simpler problem &#8211; the so-called &#8216;normal means&#8217; problem. We implement this general algorithm, but focus particular attention on the use of sparsity-inducing priors that are uni-modal at 0. This yields a sparse EBMF approach &#8211; essentially a version of sparse FA/PCA &#8211; that automatically adapts the amount of sparsity to the data. We demonstrate the benefits of our approach through both numerical comparisons with competing methods and through analysis of data from the GTEx (Genotype Tissue Expression) project on genetic associations across 44 human tissues. In numerical comparisons EBMF often provides more accurate inferences than other methods. In the GTEx data, EBMF identifies interpretable structure that concords with known relationships among human tissues. Software implementing our approach is available at <a href="https://github.com/stephenslab/flashr." target="top" rel="noopener">https://&#8230;/flashr.</a>  &#8230; </span><BR/></p>
]]></content:encoded>
					
					<wfw:commentRss>https://analytixon.com/2022/10/30/if-you-did-not-already-know-1872/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">37437</post-id>	</item>
		<item>
		<title>If you did not already know</title>
		<link>https://analytixon.com/2022/10/29/if-you-did-not-already-know-1871/</link>
					<comments>https://analytixon.com/2022/10/29/if-you-did-not-already-know-1871/#respond</comments>
		
		<dc:creator><![CDATA[Michael Laux]]></dc:creator>
		<pubDate>Sat, 29 Oct 2022 18:19:33 +0000</pubDate>
				<category><![CDATA[What is ...]]></category>
		<guid isPermaLink="false">https://analytixon.com/?p=37435</guid>

					<description><![CDATA[DeepGini Deep neural network (DNN) based systems have been deployed to assist various tasks, including many safety-critical scenarios such as &#8230;<p><a href="https://analytixon.com/2022/10/29/if-you-did-not-already-know-1871/">Continue reading <span class="meta-nav">&#8594;</span></a></p>]]></description>
										<content:encoded><![CDATA[<p><a href="http://arxiv.org/abs/1903.00661v1" target="top" rel="noopener"><strong>DeepGini</strong></a>  <a href="https://www.google.de/search?q=DeepGini" target="_blank" rel="noopener"><img decoding="async" class="alignright" src="https://analytixon.files.wordpress.com/2015/01/google.png?w=529" alt="google" data-recalc-dims="1"/></a><BR/><span style="font-size:12px;font-style:normal;text-align:justify;">Deep neural network (DNN) based systems have been deployed to assist various tasks, including many safety-critical scenarios such as autonomous driving and medical image diagnostics. In company with the DNN-based systems&#8217; fantastic accuracy on the well-defined tasks, these systems could also exhibit incorrect behaviors and thus severe accidents and losses. Therefore, beyond the conventional accuracy-based evaluation, the testing method that can assist developers in detecting incorrect behaviors in the earlier stage is critical for quality assurance of these systems. However, given the fact that automated oracle is often not available, testing DNN-based system usually requires prohibitively expensive human efforts to label the testing data. In this paper, to reduce the efforts in labeling the testing data of DNN-based systems, we propose DeepGini, a test prioritization technique for assisting developers in identifying the tests that can reveal the incorrect behavior. DeepGini is designed based on a statistical perspective of DNN, which allows us to transform the problem of measuring the likelihood of misclassification to the problem of measuing the impurity of data set. To validate our technique, we conduct an extensive empirical study on four popular datasets. The experiment results show that DeepGini outperforms the neuron-coverage-based test prioritization in terms of both efficacy and efficiency. &#8230; </span><BR/><BR/><a href="https://www.datacamp.com/community/tutorials/gflasso-R" target="top" rel="noopener"><strong>Graph-Guided Fused LASSO (GFLASSO)</strong></a>  <a href="https://www.google.de/search?q=Graph-Guided Fused LASSO" target="_blank" rel="noopener"><img decoding="async" class="alignright" src="https://analytixon.files.wordpress.com/2015/01/google.png?w=529" alt="google" data-recalc-dims="1"/></a><BR/><span style="font-size:12px;font-style:normal;text-align:justify;">Let X be a matrix of size n  p , with n observations and p predictors and Y a matrix of size n  k, with the same n observations and k responses, say, 1390 distinct electronics purchase records in 73 countries, to predict the ratings of 50 Netflix productions over all 73 countries. Models well poised for modeling pairs of high-dimensional datasets include orthogonal two-way Partial Least Squares (O2PLS), Canonical Correlation Analysis (CCA) and Co-Inertia Analysis (CIA), all of which involving matrix decomposition. Additionally, since these models are based on latent variables (that is, projections based on the original predictors), the computational efficiency comes at a cost of interpretability. However, this trade-off does not always pay off, and can be reverted with the direct prediction of k individual responses from selected features in X, in a unified regression framework that takes into account the relationships among the responses. Mathematically, the GFLASSO borrows the regularization of the LASSO discussed above and builds the model on the graph dependency structure underlying Y, as quantified by the k  k correlation matrix (that is the &#8216;strength of association&#8217; that you read about earlier). As a result, similar (or dissimilar) responses will be explained by a similar (or dissimilar) subset of selected predictors. &#8230; </span><BR/><BR/><a href="http://arxiv.org/abs/1902.06992v1" target="top" rel="noopener"><strong>Stochastic Continuous Greedy++ (SCG++)</strong></a>  <a href="https://www.google.de/search?q=Stochastic Continuous Greedy++" target="_blank" rel="noopener"><img decoding="async" class="alignright" src="https://analytixon.files.wordpress.com/2015/01/google.png?w=529" alt="google" data-recalc-dims="1"/></a><BR/><span style="font-size:12px;font-style:normal;text-align:justify;">In this paper, we develop Stochastic Continuous Greedy++ (SCG++), the first efficient variant of a conditional gradient method for maximizing a continuous submodular function subject to a convex constraint. Concretely, for a monotone and continuous DR-submodular function, SCG++ achieves a tight $[(1-1/e)\text{OPT} -\epsilon]$ solution while using $O(1/\epsilon^2)$ stochastic oracle queries and $O(1/\epsilon)$ calls to the linear optimization oracle. The best previously known algorithms either achieve a suboptimal $[(1/2)\text{OPT} -\epsilon]$ solution with $O(1/\epsilon^2)$ stochastic gradients or the tight $[(1-1/e)\text{OPT} -\epsilon]$ solution with suboptimal $O(1/\epsilon^3)$ stochastic gradients. SCG++ enjoys optimality in terms of both approximation guarantee and stochastic stochastic oracle queries. Our novel variance reduction method naturally extends to stochastic convex minimization. More precisely, we develop Stochastic Frank-Wolfe++ (SFW++) that achieves an $\epsilon$-approximate optimum with only $O(1/\epsilon)$ calls to the linear optimization oracle while using $O(1/\epsilon^2)$ stochastic oracle queries in total. Therefore, SFW++ is the first efficient projection-free algorithm that achieves the optimum complexity $O(1/\epsilon^2)$ in terms of stochastic oracle queries. &#8230; </span><BR/><BR/><a href="http://arxiv.org/abs/1803.09010v1" target="top" rel="noopener"><strong>Datasheets for Datasets</strong></a>  <a href="https://www.google.de/search?q=Datasheets for Datasets" target="_blank" rel="noopener"><img decoding="async" class="alignright" src="https://analytixon.files.wordpress.com/2015/01/google.png?w=529" alt="google" data-recalc-dims="1"/></a><BR/><span style="font-size:12px;font-style:normal;text-align:justify;">Currently there is no standard way to identify how a dataset was created, and what characteristics, motivations, and potential skews it represents. To begin to address this issue, we propose the concept of a datasheet for datasets, a short document to accompany public datasets, commercial APIs, and pretrained models. The goal of this proposal is to enable better communication between dataset creators and users, and help the AI community move toward greater transparency and accountability. By analogy, in computer hardware, it has become industry standard to accompany everything from the simplest components (e.g., resistors), to the most complex microprocessor chips, with datasheets detailing standard operating characteristics, test results, recommended usage, and other information. We outline some of the questions a datasheet for datasets should answer. These questions focus on when, where, and how the training data was gathered, its recommended use cases, and, in the case of human-centric datasets, information regarding the subjects&#8217; demographics and consent as applicable. We develop prototypes of datasheets for two well-known datasets: Labeled Faces in The Wild~\cite{lfw} and the Pang \&amp; Lee Polarity Dataset~\cite{polarity}. &#8230; </span><BR/></p>
]]></content:encoded>
					
					<wfw:commentRss>https://analytixon.com/2022/10/29/if-you-did-not-already-know-1871/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">37435</post-id>	</item>
		<item>
		<title>If you did not already know</title>
		<link>https://analytixon.com/2022/10/28/if-you-did-not-already-know-1870/</link>
					<comments>https://analytixon.com/2022/10/28/if-you-did-not-already-know-1870/#respond</comments>
		
		<dc:creator><![CDATA[Michael Laux]]></dc:creator>
		<pubDate>Fri, 28 Oct 2022 04:05:18 +0000</pubDate>
				<category><![CDATA[What is ...]]></category>
		<guid isPermaLink="false">https://analytixon.com/?p=37417</guid>

					<description><![CDATA[Personalized Embedding Propagation (PEP) Neural message passing algorithms for semi-supervised classification on graphs have recently achieved great success. However, these &#8230;<p><a href="https://analytixon.com/2022/10/28/if-you-did-not-already-know-1870/">Continue reading <span class="meta-nav">&#8594;</span></a></p>]]></description>
										<content:encoded><![CDATA[<p><a href="http://arxiv.org/abs/1810.05997v1" target="top" rel="noopener"><strong>Personalized Embedding Propagation (PEP)</strong></a>  <a href="https://www.google.de/search?q=Personalized Embedding Propagation" target="_blank" rel="noopener"><img decoding="async" class="alignright" src="https://analytixon.files.wordpress.com/2015/01/google.png?w=529" alt="google" data-recalc-dims="1"/></a><BR/><span style="font-size:12px;font-style:normal;text-align:justify;">Neural message passing algorithms for semi-supervised classification on graphs have recently achieved great success. However, these methods only consider nodes that are a few propagation steps away and the size of this utilized neighborhood cannot be easily extended. In this paper, we use the relationship between graph convolutional networks (GCN) and PageRank to derive an improved propagation scheme based on personalized PageRank. We utilize this propagation procedure to construct personalized embedding propagation (PEP) and its approximation, PEP$_\text{A}$. Our model&#8217;s training time is on par or faster and its number of parameters on par or lower than previous models. It leverages a large, adjustable neighborhood for classification and can be combined with any neural network. We show that this model outperforms several recently proposed methods for semi-supervised classification on multiple graphs in the most thorough study done so far for GCN-like models. &#8230; </span><BR/><BR/><a href="http://arxiv.org/abs/1905.09979v1" target="top" rel="noopener"><strong>EnsembleNet</strong></a>  <a href="https://www.google.de/search?q=EnsembleNet" target="_blank" rel="noopener"><img decoding="async" class="alignright" src="https://analytixon.files.wordpress.com/2015/01/google.png?w=529" alt="google" data-recalc-dims="1"/></a><BR/><span style="font-size:12px;font-style:normal;text-align:justify;">Ensembling is a universally useful approach to boost the performance of machine learning models. However, individual models in an ensemble are typically trained independently in separate stages, without information access about the overall ensemble. In this paper, model ensembles are treated as first-class citizens, and their performance is optimized end-to-end with parameter sharing and a novel loss structure that improves generalization. On large-scale datasets including ImageNet, Youtube-8M, and Kinetics, we demonstrate a procedure that starts from a strongly performing single deep neural network, and constructs an EnsembleNet that has both a smaller size and better performance. Moreover, an EnsembleNet can be trained in one stage just like a single model without manual intervention. &#8230; </span><BR/><BR/><a href="https://en.wikipedia.org/wiki/Digital_twin" target="top" rel="noopener"><strong>Digital Twin</strong></a>  <a href="https://www.google.de/search?q=Digital Twin" target="_blank" rel="noopener"><img decoding="async" class="alignright" src="https://analytixon.files.wordpress.com/2015/01/google.png?w=529" alt="google" data-recalc-dims="1"/></a><BR/><span style="font-size:12px;font-style:normal;text-align:justify;">Digital twin refers to a digital replica of physical assets, processes and systems that can be used for various purposes. The digital representation provides both the elements and the dynamics of how an Internet of Things device operates and lives throughout its life cycle. Digital Twins integrate artificial intelligence, machine learning and software analytics with data to create living digital Simulation models that update and change as their physical counterparts&#8217; change. A digital twin continuously learns and updates itself from multiple sources to represent their near real-time status, working condition or position. This learning system, learns from itself, using sensor data that conveys various aspects of its operating condition; from human experts, such as engineers with deep and relevant industry domain knowledge; from other similar machines; from other similar fleets of machines; and from the larger systems and environment in which it may be a part of. A digital twin also integrates historical data from past machine usage to factor into its digital model. &#8230; </span><BR/><BR/><a href="http://arxiv.org/abs/1807.04728v1" target="top" rel="noopener"><strong>SciTokens</strong></a>  <a href="https://www.google.de/search?q=SciTokens" target="_blank" rel="noopener"><img decoding="async" class="alignright" src="https://analytixon.files.wordpress.com/2015/01/google.png?w=529" alt="google" data-recalc-dims="1"/></a><BR/><span style="font-size:12px;font-style:normal;text-align:justify;">The management of security credentials (e.g., passwords, secret keys) for computational science workflows is a burden for scientists and information security officers. Problems with credentials (e.g., expiration, privilege mismatch) cause workflows to fail to fetch needed input data or store valuable scientific results, distracting scientists from their research by requiring them to diagnose the problems, re-run their computations, and wait longer for their results. In this paper, we introduce SciTokens, open source software to help scientists manage their security credentials more reliably and securely. We describe the SciTokens system architecture, design, and implementation addressing use cases from the Laser Interferometer Gravitational-Wave Observatory (LIGO) Scientific Collaboration and the Large Synoptic Survey Telescope (LSST) projects. We also present our integration with widely-used software that supports distributed scientific computing, including HTCondor, CVMFS, and XrootD. SciTokens uses IETF-standard OAuth tokens for capability-based secure access to remote scientific data. The access tokens convey the specific authorizations needed by the workflows, rather than general-purpose authentication impersonation credentials, to address the risks of scientific workflows running on distributed infrastructure including NSF resources (e.g., LIGO Data Grid, Open Science Grid, XSEDE) and public clouds (e.g., Amazon Web Services, Google Cloud, Microsoft Azure). By improving the interoperability and security of scientific workflows, SciTokens 1) enables use of distributed computing for scientific domains that require greater data protection and 2) enables use of more widely distributed computing resources by reducing the risk of credential abuse on remote systems. &#8230; </span><BR/></p>
]]></content:encoded>
					
					<wfw:commentRss>https://analytixon.com/2022/10/28/if-you-did-not-already-know-1870/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">37417</post-id>	</item>
		<item>
		<title>If you did not already know</title>
		<link>https://analytixon.com/2022/10/27/if-you-did-not-already-know-1869/</link>
					<comments>https://analytixon.com/2022/10/27/if-you-did-not-already-know-1869/#respond</comments>
		
		<dc:creator><![CDATA[Michael Laux]]></dc:creator>
		<pubDate>Thu, 27 Oct 2022 00:01:16 +0000</pubDate>
				<category><![CDATA[What is ...]]></category>
		<guid isPermaLink="false">https://analytixon.com/?p=37415</guid>

					<description><![CDATA[Batch-Mode Active Learning Recently, Convolutional Neural Networks (CNNs) have shown unprecedented success in the field of computer vision, especially on &#8230;<p><a href="https://analytixon.com/2022/10/27/if-you-did-not-already-know-1869/">Continue reading <span class="meta-nav">&#8594;</span></a></p>]]></description>
										<content:encoded><![CDATA[<p><a href="http://arxiv.org/abs/1905.09247v1" target="top" rel="noopener"><strong>Batch-Mode Active Learning</strong></a>  <a href="https://www.google.de/search?q=Batch-Mode Active Learning" target="_blank" rel="noopener"><img decoding="async" class="alignright" src="https://analytixon.files.wordpress.com/2015/01/google.png?w=529" alt="google" data-recalc-dims="1"/></a><BR/><span style="font-size:12px;font-style:normal;text-align:justify;">Recently, Convolutional Neural Networks (CNNs) have shown unprecedented success in the field of computer vision, especially on challenging image classification tasks by relying on a universal approach, i.e., training a deep model on a massive dataset of supervised examples. While unlabeled data are often an abundant resource, collecting a large set of labeled data, on the other hand, are very expensive, which often require considerable human efforts. One way to ease out this is to effectively select and label highly informative instances from a pool of unlabeled data (i.e., active learning). This paper proposed a new method of batch-mode active learning, Dual Active Sampling(DAS), which is based on a simple assumption, if two deep neural networks (DNNs) of the same structure and trained on the same dataset give significantly different output for a given sample, then that particular sample should be picked for additional training. While other state of the art methods in this field usually require intensive computational power or relying on a complicated structure, DAS is simpler to implement and, managed to get improved results on Cifar-10 with preferable computational time compared to the core-set method. &#8230; </span><BR/><BR/><a href="http://arxiv.org/abs/1811.09955v1" target="top" rel="noopener"><strong>Online Gradient Descent With Expected Gradient (OGDEG)</strong></a>  <a href="https://www.google.de/search?q=Online Gradient Descent With Expected Gradient" target="_blank" rel="noopener"><img decoding="async" class="alignright" src="https://analytixon.files.wordpress.com/2015/01/google.png?w=529" alt="google" data-recalc-dims="1"/></a><BR/><span style="font-size:12px;font-style:normal;text-align:justify;">Online learning with limited information feedback (bandit) tries to solve the problem where an online learner receives partial feedback information from the environment in the course of learning. Under this setting, Flaxman extends Zinkevich&#8217;s classical Online Gradient Descent (OGD) algorithm Zinkevich [2003] by proposing the Online Gradient Descent with Expected Gradient (OGDEG) algorithm. Specifically, it uses a simple trick to approximate the gradient of the loss function $f_t$ by evaluating it at a single point and bounds the expected regret as $\mathcal{O}(T^{5/6})$ Flaxman et al. [2005]. It has been shown that compared with the first-order algorithms, second-order online learning algorithms such as Online Newton Step (ONS) Hazan et al. [2007] can significantly accelerate the convergence rate in traditional online learning. Motivated by this, this paper aims to exploit second-order information to speed up the convergence of OGDEG. In particular, we extend the ONS algorithm with the trick of expected gradient and develop a novel second-order online learning algorithm, i.e., Online Newton Step with Expected Gradient (ONSEG). Theoretically, we show that the proposed ONSEG algorithm significantly reduces the expected regret of OGDEG from $\mathcal{O}(T^{5/6})$ to $\mathcal{O}(T^{2/3})$ in the bandit feedback scenario. Empirically, we demonstrate the advantages of the proposed algorithm on several real-world datasets. &#8230; </span><BR/><BR/><a href="http://arxiv.org/abs/1802.00212v1" target="top" rel="noopener"><strong>Power Linear Unit (PoLU)</strong></a>  <a href="https://www.google.de/search?q=Power Linear Unit" target="_blank" rel="noopener"><img decoding="async" class="alignright" src="https://analytixon.files.wordpress.com/2015/01/google.png?w=529" alt="google" data-recalc-dims="1"/></a><BR/><span style="font-size:12px;font-style:normal;text-align:justify;">In this paper, we introduce &#8216;Power Linear Unit&#8217; (PoLU) which increases the nonlinearity capacity of a neural network and thus helps improving its performance. PoLU adopts several advantages of previously proposed activation functions. First, the output of PoLU for positive inputs is designed to be identity to avoid the gradient vanishing problem. Second, PoLU has a non-zero output for negative inputs such that the output mean of the units is close to zero, hence reducing the bias shift effect. Thirdly, there is a saturation on the negative part of PoLU, which makes it more noise-robust for negative inputs. Furthermore, we prove that PoLU is able to map more portions of every layer&#8217;s input to the same space by using the power function and thus increases the number of response regions of the neural network. We use image classification for comparing our proposed activation function with others. In the experiments, MNIST, CIFAR-10, CIFAR-100, Street View House Numbers (SVHN) and ImageNet are used as benchmark datasets. The neural networks we implemented include widely-used ELU-Network, ResNet-50, and VGG16, plus a couple of shallow networks. Experimental results show that our proposed activation function outperforms other state-of-the-art models with most networks. &#8230; </span><BR/><BR/><a href="http://arxiv.org/abs/1803.09017v1" target="top" rel="noopener"><strong>Global Style Token (GST)</strong></a>  <a href="https://www.google.de/search?q=Global Style Token" target="_blank" rel="noopener"><img decoding="async" class="alignright" src="https://analytixon.files.wordpress.com/2015/01/google.png?w=529" alt="google" data-recalc-dims="1"/></a><BR/><span style="font-size:12px;font-style:normal;text-align:justify;">In this work, we propose &#8216;global style tokens&#8217; (GSTs), a bank of embeddings that are jointly trained within Tacotron, a state-of-the-art end-to-end speech synthesis system. The embeddings are trained with no explicit labels, yet learn to model a large range of acoustic expressiveness. GSTs lead to a rich set of significant results. The soft interpretable &#8216;labels&#8217; they generate can be used to control synthesis in novel ways, such as varying speed and speaking style &#8211; independently of the text content. They can also be used for style transfer, replicating the speaking style of a single audio clip across an entire long-form text corpus. When trained on noisy, unlabeled found data, GSTs learn to factorize noise and speaker identity, providing a path towards highly scalable but robust speech synthesis. &#8230; </span><BR/></p>
]]></content:encoded>
					
					<wfw:commentRss>https://analytixon.com/2022/10/27/if-you-did-not-already-know-1869/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">37415</post-id>	</item>
		<item>
		<title>If you did not already know</title>
		<link>https://analytixon.com/2022/10/26/if-you-did-not-already-know-1868/</link>
					<comments>https://analytixon.com/2022/10/26/if-you-did-not-already-know-1868/#respond</comments>
		
		<dc:creator><![CDATA[Michael Laux]]></dc:creator>
		<pubDate>Wed, 26 Oct 2022 22:23:41 +0000</pubDate>
				<category><![CDATA[What is ...]]></category>
		<guid isPermaLink="false">https://analytixon.com/?p=37413</guid>

					<description><![CDATA[Learnable ScatterNet In this paper we explore tying together the ideas from Scattering Transforms and Convolutional Neural Networks (CNN) for &#8230;<p><a href="https://analytixon.com/2022/10/26/if-you-did-not-already-know-1868/">Continue reading <span class="meta-nav">&#8594;</span></a></p>]]></description>
										<content:encoded><![CDATA[<p><a href="http://arxiv.org/abs/1903.03137v1" target="top" rel="noopener"><strong>Learnable ScatterNet</strong></a>  <a href="https://www.google.de/search?q=Learnable ScatterNet" target="_blank" rel="noopener"><img decoding="async" class="alignright" src="https://analytixon.files.wordpress.com/2015/01/google.png?w=529" alt="google" data-recalc-dims="1"/></a><BR/><span style="font-size:12px;font-style:normal;text-align:justify;">In this paper we explore tying together the ideas from Scattering Transforms and Convolutional Neural Networks (CNN) for Image Analysis by proposing a learnable ScatterNet. Previous attempts at tying them together in hybrid networks have tended to keep the two parts separate, with the ScatterNet forming a fixed front end and a CNN forming a learned backend. We instead look at adding learning between scattering orders, as well as adding learned layers before the ScatterNet. We do this by breaking down the scattering orders into single convolutional-like layers we call &#8216;locally invariant&#8217; layers, and adding a learned mixing term to this layer. Our experiments show that these locally invariant layers can improve accuracy when added to either a CNN or a ScatterNet. We also discover some surprising results in that the ScatterNet may be best positioned after one or more layers of learning rather than at the front of a neural network. &#8230; </span><BR/><BR/><a href="http://arxiv.org/abs/1901.00158v1" target="top" rel="noopener"><strong>Text Infilling</strong></a>  <a href="https://www.google.de/search?q=Text Infilling" target="_blank" rel="noopener"><img decoding="async" class="alignright" src="https://analytixon.files.wordpress.com/2015/01/google.png?w=529" alt="google" data-recalc-dims="1"/></a><BR/><span style="font-size:12px;font-style:normal;text-align:justify;">Recent years have seen remarkable progress of text generation in different contexts, such as the most common setting of generating text from scratch, and the emerging paradigm of retrieval-and-rewriting. Text infilling, which fills missing text portions of a sentence or paragraph, is also of numerous use in real life, yet is under-explored. Previous work has focused on restricted settings by either assuming single word per missing portion or limiting to a single missing portion to the end of the text. This paper studies the general task of text infilling, where the input text can have an arbitrary number of portions to be filled, each of which may require an arbitrary unknown number of tokens. We study various approaches for the task, including a self-attention model with segment-aware position encoding and bidirectional context modeling. We create extensive supervised data by masking out text with varying strategies. Experiments show the self-attention model greatly outperforms others, creating a strong baseline for future research. &#8230; </span><BR/><BR/><a href="http://arxiv.org/abs/1810.08754v1" target="top" rel="noopener"><strong>BCR-Net</strong></a>  <a href="https://www.google.de/search?q=BCR-Net" target="_blank" rel="noopener"><img decoding="async" class="alignright" src="https://analytixon.files.wordpress.com/2015/01/google.png?w=529" alt="google" data-recalc-dims="1"/></a><BR/><span style="font-size:12px;font-style:normal;text-align:justify;">This paper proposes a novel neural network architecture inspired by the nonstandard form proposed by Beylkin, Coifman, and Rokhlin in [Communications on Pure and Applied Mathematics, 44(2), 141-183]. The nonstandard form is a highly effective wavelet-based compression scheme for linear integral operators. In this work, we first represent the matrix-vector product algorithm of the nonstandard form as a linear neural network where every scale of the multiresolution computation is carried out by a locally connected linear sub-network. In order to address nonlinear problems, we propose an extension, called BCR-Net, by replacing each linear sub-network with a deeper and more powerful nonlinear one. Numerical results demonstrate the efficiency of the new architecture by approximating nonlinear maps that arise in homogenization theory and stochastic computation. &#8230; </span><BR/><BR/><a href="http://arxiv.org/abs/1809.02404v1" target="top" rel="noopener"><strong>Joint Spectrum</strong></a>  <a href="https://www.google.de/search?q=Joint Spectrum" target="_blank" rel="noopener"><img decoding="async" class="alignright" src="https://analytixon.files.wordpress.com/2015/01/google.png?w=529" alt="google" data-recalc-dims="1"/></a><BR/><span style="font-size:12px;font-style:normal;text-align:justify;">We introduce the notion of joint spectrum of a compact set of matrices $S \subset$ GL$_{d}(\mathbb{C})$, which is a multi-dimensional generalization of the joint spectral radius. In the irreducible case we describe its properties and examine how it relates to the set of eigenvalues of elements in the semi-group generated by $S$. We also make connections with the theory of random products of matrices. &#8230; </span><BR/></p>
]]></content:encoded>
					
					<wfw:commentRss>https://analytixon.com/2022/10/26/if-you-did-not-already-know-1868/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">37413</post-id>	</item>
	</channel>
</rss>