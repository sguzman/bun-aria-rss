<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>math.OC updates on arXiv.org</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">Mathematics -- Optimization and Control (math.OC) updates on the arXiv.org e-print archive</description>
<dc:language>en-us</dc:language>
<dc:date>2022-11-03T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Mathematics -- Optimization and Control</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.01418" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.01475" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.01486" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.01601" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.01610" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.01661" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.01667" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.01699" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.01758" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.01804" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.01832" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.01851" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.01883" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.01918" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.01961" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.01962" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.01982" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.02032" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.04923" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1910.09143" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.09854" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.14985" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2201.07659" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2206.00529" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2206.07021" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2206.13606" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2208.07919" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2210.05164" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2210.05807" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.00675" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.01122" />
 </rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image>
<item rdf:about="http://arxiv.org/abs/2211.01418">
<title>An Oracle-Structured Bundle Method for Distributed Optimization. (arXiv:2211.01418v1 [math.OC])</title>
<link>http://arxiv.org/abs/2211.01418</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of minimizing a function that is a sum of convex
agent functions plus a convex common public function that couples them. The
agent functions can only be accessed via a subgradient oracle; the public
function is assumed to be structured and expressible in a domain specific
language (DSL) for convex optimization. We focus on the case when the
evaluation of the agent oracles can require significant effort, which justifies
the use of solution methods that carry out significant computation in each
iteration. We propose a cutting-plane or bundle-type method for the distributed
optimization problem, which has a number of advantages over other methods that
are compatible with the access methods, such as proximal subgradient methods:
it has very few parameters that need to be tuned; it often produces a
reasonable approximate solution in just a few tens of iterations; and it
tolerates agent failures. This paper is accompanied by an open source package
that implements the proposed method, available at
\url{https://github.com/cvxgrp/OSBDO}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Parshakova_T/0/1/0/all/0/1&quot;&gt;Tetiana Parshakova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Zhang_F/0/1/0/all/0/1&quot;&gt;Fangzhao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Boyd_S/0/1/0/all/0/1&quot;&gt;Stephen Boyd&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.01475">
<title>Insensitizing controls for a fourth order semi-linear parabolic equations. (arXiv:2211.01475v1 [math.OC])</title>
<link>http://arxiv.org/abs/2211.01475</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper is concerned with the existence of insensitizing controls for a
fourth order semilinear parabolic equation. Here, the initial data is partially
unknown, we would like to find controls such that a specific functional is
insensitive for small perturbations of the initial data. In general, this kind
of problems can be recast as a null controllability problem for a nonlinear
cascade system. We will first prove a null controllability result for a linear
problem by global Carleman estimates and dual arguments. Then, by virtue of
Leray-Schauder&apos;s fixed points theorem, we conclude the null controllability for
the cascade system in the semi-linear case.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+You_B/0/1/0/all/0/1&quot;&gt;Bo You&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Li_F/0/1/0/all/0/1&quot;&gt;Fang Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.01486">
<title>Assessing Resource-Performance Trade-off of Natural Language Models using Data Envelopment Analysis. (arXiv:2211.01486v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2211.01486</link>
<description rdf:parseType="Literal">&lt;p&gt;Natural language models are often summarized through a high-dimensional set
of descriptive metrics including training corpus size, training time, the
number of trainable parameters, inference times, and evaluation statistics that
assess performance across tasks. The high dimensional nature of these metrics
yields challenges with regard to objectively comparing models; in particular it
is challenging to assess the trade-off models make between performance and
resources (compute time, memory, etc.).
&lt;/p&gt;
&lt;p&gt;We apply Data Envelopment Analysis (DEA) to this problem of assessing the
resource-performance trade-off. DEA is a nonparametric method that measures
productive efficiency of abstract units that consume one or more inputs and
yield at least one output. We recast natural language models as units suitable
for DEA, and we show that DEA can be used to create an effective framework for
quantifying model performance and efficiency. A central feature of DEA is that
it identifies a subset of models that live on an efficient frontier of
performance. DEA is also scalable, having been applied to problems with
thousands of units. We report empirical results of DEA applied to 14 different
language models that have a variety of architectures, and we show that DEA can
be used to identify a subset of models that effectively balance resource
demands against performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1&quot;&gt;Zachary Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zachariah_A/0/1/0/all/0/1&quot;&gt;Alisha Zachariah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Conathan_D/0/1/0/all/0/1&quot;&gt;Devin Conathan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kline_J/0/1/0/all/0/1&quot;&gt;Jeffery Kline&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.01601">
<title>A Fast Solution Method for Large-scale Unit Commitment Based on Lagrangian Relaxation and Dynamic Programming. (arXiv:2211.01601v1 [math.OC])</title>
<link>http://arxiv.org/abs/2211.01601</link>
<description rdf:parseType="Literal">&lt;p&gt;The unit commitment problem (UC) is crucial for the operation and market
mechanism of power systems. With the development of modern electricity, the
scale of power systems is expanding, and solving the UC problem is also
becoming more and more difficult. To this end, this paper proposes a new fast
solution method based on Lagrangian relaxation and dynamic program-ming.
Firstly, the UC solution is estimated to be an initial trial UC solution by a
fast method based on Lagrangian relaxation. This initial trial UC solution
fully considers the system-wide con-straints. Secondly, a dynamic programming
module is introduced to adjust the trial UC solution to make it satisfy the
unit-wise constraints. Thirdly, a method for constructing a feasible UC
solution is proposed based on the adjusted trial UC solution. Specifically, a
feasibility-testing model and an updating strategy for the trial UC solution
are established in this part. Numerical tests are implemented on IEEE 24-bus,
IEEE 118-bus, Polish 2383-bus, and French 6468-bus systems, which verify the
effec-tiveness and efficiency of the proposed method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Hou_J/0/1/0/all/0/1&quot;&gt;Jiangwei Hou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Zhai_Q/0/1/0/all/0/1&quot;&gt;Qiaozhu Zhai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Zhou_Y/0/1/0/all/0/1&quot;&gt;Yuzhou Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Guan_X/0/1/0/all/0/1&quot;&gt;Xiaohong Guan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.01610">
<title>Proximal Subgradient Norm Minimization of ISTA and FISTA. (arXiv:2211.01610v1 [math.OC])</title>
<link>http://arxiv.org/abs/2211.01610</link>
<description rdf:parseType="Literal">&lt;p&gt;For first-order smooth optimization, the research on the acceleration
phenomenon has a long-time history. Until recently, the mechanism leading to
acceleration was not successfully uncovered by the gradient correction term and
its equivalent implicit-velocity form. Furthermore, based on the
high-resolution differential equation framework with the corresponding emerging
techniques, phase-space representation and Lyapunov function, the squared
gradient norm of Nesterov&apos;s accelerated gradient descent (\texttt{NAG}) method
at an inverse cubic rate is discovered. However, this result cannot be directly
generalized to composite optimization widely used in practice, e.g., the linear
inverse problem with sparse representation. In this paper, we meticulously
observe a pivotal inequality used in composite optimization about the step size
$s$ and the Lipschitz constant $L$ and find that it can be improved tighter. We
apply the tighter inequality discovered in the well-constructed Lyapunov
function and then obtain the proximal subgradient norm minimization by the
phase-space representation, regardless of gradient-correction or
implicit-velocity. Furthermore, we demonstrate that the squared proximal
subgradient norm for the class of iterative shrinkage-thresholding algorithms
(ISTA) converges at an inverse square rate, and the squared proximal
subgradient norm for the class of faster iterative shrinkage-thresholding
algorithms (FISTA) is accelerated to convergence at an inverse cubic rate.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Li_B/0/1/0/all/0/1&quot;&gt;Bowen Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Shi_B/0/1/0/all/0/1&quot;&gt;Bin Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Yuan_Y/0/1/0/all/0/1&quot;&gt;Ya-xiang Yuan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.01661">
<title>Pairing optimization via statistics: Algebraic structure in pairing problems and its application to performance enhancement. (arXiv:2211.01661v1 [cs.DS])</title>
<link>http://arxiv.org/abs/2211.01661</link>
<description rdf:parseType="Literal">&lt;p&gt;Fully pairing all elements of a set while attempting to maximize the total
benefit is a combinatorically difficult problem. Such pairing problems
naturally appear in various situations in science, technology, economics, and
other fields. In our previous study, we proposed an efficient method to infer
the underlying compatibilities among the entities, under the constraint that
only the total compatibility is observable. Furthermore, by transforming the
pairing problem into a traveling salesman problem with a multi-layer
architecture, a pairing optimization algorithm was successfully demonstrated to
derive a high-total-compatibility pairing. However, there is substantial room
for further performance enhancement by further exploiting the underlying
mathematical properties. In this study, we prove the existence of algebraic
structures in the pairing problem. We transform the initially estimated
compatibility information into an equivalent form where the variance of the
individual compatibilities is minimized. We then demonstrate that the total
compatibility obtained when using the heuristic pairing algorithm on the
transformed problem is significantly higher compared to the previous method.
With this improved perspective on the pairing problem using fundamental
mathematical properties, we can contribute to practical applications such as
wireless communications beyond 5G, where efficient pairing is of critical
importance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fujita_N/0/1/0/all/0/1&quot;&gt;Naoki Fujita&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rohm_A/0/1/0/all/0/1&quot;&gt;Andr&amp;#xe9; R&amp;#xf6;hm&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mihana_T/0/1/0/all/0/1&quot;&gt;Takatomo Mihana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Horisaki_R/0/1/0/all/0/1&quot;&gt;Ryoichi Horisaki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1&quot;&gt;Aohan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hasegawa_M/0/1/0/all/0/1&quot;&gt;Mikio Hasegawa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Naruse_M/0/1/0/all/0/1&quot;&gt;Makoto Naruse&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.01667">
<title>AoI-Based Opportunistic-Fair mmWave Schedulers. (arXiv:2211.01667v1 [math.OC])</title>
<link>http://arxiv.org/abs/2211.01667</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider a system with a Base Station (BS) and multiple mobile/stationary
users. BS uses millimeter waves (mmWaves) for data transmission and hence needs
to align beams in the directions of the end-users. The idea is to avail regular
user-position estimates, which help in accurate beam alignment towards multiple
users, paving way for opportunistic mmWave schedulers. We propose an online
algorithm that uses a dual opportunistic and fair scheduler to allocate data as
well as position-update channels, in each slot. Towards this, well-known
alpha-fair objective functions of utilities of various users, which further
depend upon the age of position-information, are optimized. We illustrate the
advantages of the opportunistic scheduler, by comparing it with the previously
proposed mmWave schemes; these schedulers choose one user in each slot and
start data transmission only after accurate beam alignment. We also discuss two
ways of introducing fairness in such schemes, both of which perform inferior to
the proposed age-based opportunistic scheduler.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Singhal_S/0/1/0/all/0/1&quot;&gt;Shiksha Singhal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Kavitha_V/0/1/0/all/0/1&quot;&gt;Veeraruna Kavitha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Ramanath_S/0/1/0/all/0/1&quot;&gt;Sreenath Ramanath&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.01699">
<title>A Round and Bipartize Approximation Algorithm for Vertex Cover. (arXiv:2211.01699v1 [cs.DS])</title>
<link>http://arxiv.org/abs/2211.01699</link>
<description rdf:parseType="Literal">&lt;p&gt;The vertex cover problem is a fundamental and widely studied combinatorial
optimization problem. It is known that its standard linear programming
relaxation is integral for bipartite graphs and half-integral for general
graphs. As a consequence, the natural rounding algorithm based on this
relaxation computes an optimal solution for bipartite graphs and a
$2$-approximation for general graphs. This raises the question of whether one
can obtain improved bounds on the approximation ratio, depending on how close
the graph is to being bipartite.
&lt;/p&gt;
&lt;p&gt;In this paper, we consider a round-and-bipartize algorithm that exploits the
knowledge of an induced bipartite subgraph to attain improved approximation
ratios. Equivalently, we suppose that we have access to a subset of vertices
$S$ whose removal bipartizes the graph.
&lt;/p&gt;
&lt;p&gt;If $S$ is an independent set, we prove an approximation ratio of $1 +
1/\rho$, where $2\rho -1$ denotes the odd girth of the contracted graph
$\tilde{\mathcal{G}} := \mathcal{G} /S$ and thus satisfies $\rho \geq 2$. We
show that this is tight for any graph and independent set by providing a family
of weight functions for which this bound is attained. In addition, we give
tight upper bounds for the fractional chromatic number and the integrality gap
of such graphs, both of which also depend on the odd girth.
&lt;/p&gt;
&lt;p&gt;If $S$ is an arbitrary set, we prove a tight approximation ratio of
$\left(1+1/\rho \right) (1 - \alpha) + 2 \alpha$, where $\alpha \in [0,1]$
denotes the total normalized dual sum of the edges lying inside of the set $S$.
As an algorithmic application, we show that for any efficiently $k$-colorable
graph with $k \geq 4$ we can find a bipartizing set satisfying $\alpha \leq 1 -
4/k$. This provides an approximation algorithm recovering the bound of $2 -
2/k$ in the worst case (i.e., when $\rho = 2$), which is best possible for this
setting when using the standard relaxation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kashaev_D/0/1/0/all/0/1&quot;&gt;Danish Kashaev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schafer_G/0/1/0/all/0/1&quot;&gt;Guido Sch&amp;#xe4;fer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.01758">
<title>Optimal Algorithms for Stochastic Complementary Composite Minimization. (arXiv:2211.01758v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2211.01758</link>
<description rdf:parseType="Literal">&lt;p&gt;Inspired by regularization techniques in statistics and machine learning, we
study complementary composite minimization in the stochastic setting. This
problem corresponds to the minimization of the sum of a (weakly) smooth
function endowed with a stochastic first-order oracle, and a structured
uniformly convex (possibly nonsmooth and non-Lipschitz) regularization term.
Despite intensive work on closely related settings, prior to our work no
complexity bounds for this problem were known. We close this gap by providing
novel excess risk bounds, both in expectation and with high probability. Our
algorithms are nearly optimal, which we prove via novel lower complexity bounds
for this class of problems. We conclude by providing numerical results
comparing our methods to the state of the art.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+dAspremont_A/0/1/0/all/0/1&quot;&gt;Alexandre d&amp;#x27;Aspremont&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guzman_C/0/1/0/all/0/1&quot;&gt;Crist&amp;#xf3;bal Guzm&amp;#xe1;n&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lezane_C/0/1/0/all/0/1&quot;&gt;Cl&amp;#xe9;ment Lezane&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.01804">
<title>Wasserstein Steepest Descent Flows of Discrepancies with Riesz Kernels. (arXiv:2211.01804v1 [math.OC])</title>
<link>http://arxiv.org/abs/2211.01804</link>
<description rdf:parseType="Literal">&lt;p&gt;The aim of this paper is twofold. Based on the geometric Wasserstein tangent
space, we first introduce Wasserstein steepest descent flows. These are locally
absolutely continuous curves in the Wasserstein space whose tangent vectors
point into a steepest descent direction of a given functional. This allows the
use of Euler forward schemes instead of the minimizing movement scheme (MMS)
introduced by Jordan, Kinderlehrer, and Otto. The MMS finds Wasserstein
gradient flows by successively computing Wasserstein proxies. For locally
Lipschitz continuous functionals which are $\lambda$-convex along generalized
geodesics, we show that there exists a unique Wasserstein steepest descent flow
coinciding with the Wasserstein gradient flow.
&lt;/p&gt;
&lt;p&gt;The second aim is to study Wasserstein flows of the (maximum mean)
discrepancy with respect to Riesz kernels. The crucial part is hereby the
treatment of the interaction energy. Although it is not $\lambda$-convex along
generalized geodesics, we give analytic expressions for Wasserstein steepest
descent flows of the interaction energy starting at Dirac measures. In contrast
to smooth kernels, the particle may explode, i.e., the particle goes over to
non-Dirac measures. The computation of steepest descent flows amounts to
finding equilibrium measures with external fields, which nicely links
Wasserstein flows of interaction energies with potential theory. Furthermore,
we prove convergence of MMS to our Wasserstein steepest descent flows. Finally,
we provide analytic Wasserstein steepest descent flows of discrepancies in one
dimension and numerical simulations in two and three dimensions showing
relations to interaction energy flows.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Hertrich_J/0/1/0/all/0/1&quot;&gt;Johannes Hertrich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Graf_M/0/1/0/all/0/1&quot;&gt;Manuel Gr&amp;#xe4;f&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Beinert_R/0/1/0/all/0/1&quot;&gt;Robert Beinert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Steidl_G/0/1/0/all/0/1&quot;&gt;Gabriele Steidl&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.01832">
<title>Extra-Newton: A First Approach to Noise-Adaptive Accelerated Second-Order Methods. (arXiv:2211.01832v1 [math.OC])</title>
<link>http://arxiv.org/abs/2211.01832</link>
<description rdf:parseType="Literal">&lt;p&gt;This work proposes a universal and adaptive second-order method for
minimizing second-order smooth, convex functions. Our algorithm achieves
$O(\sigma / \sqrt{T})$ convergence when the oracle feedback is stochastic with
variance $\sigma^2$, and improves its convergence to $O( 1 / T^3)$ with
deterministic oracles, where $T$ is the number of iterations. Our method also
interpolates these rates without knowing the nature of the oracle apriori,
which is enabled by a parameter-free adaptive step-size that is oblivious to
the knowledge of smoothness modulus, variance bounds and the diameter of the
constrained set. To our knowledge, this is the first universal algorithm with
such global guarantees within the second-order optimization literature.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Antonakopoulos_K/0/1/0/all/0/1&quot;&gt;Kimon Antonakopoulos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Kavis_A/0/1/0/all/0/1&quot;&gt;Ali Kavis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Cevher_V/0/1/0/all/0/1&quot;&gt;Volkan Cevher&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.01851">
<title>Adaptive Stochastic Variance Reduction for Non-convex Finite-Sum Minimization. (arXiv:2211.01851v1 [math.OC])</title>
<link>http://arxiv.org/abs/2211.01851</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose an adaptive variance-reduction method, called AdaSpider, for
minimization of $L$-smooth, non-convex functions with a finite-sum structure.
In essence, AdaSpider combines an AdaGrad-inspired [Duchi et al., 2011, McMahan
&amp;amp; Streeter, 2010], but a fairly distinct, adaptive step-size schedule with the
recursive stochastic path integrated estimator proposed in [Fang et al., 2018].
To our knowledge, Adaspider is the first parameter-free non-convex
variance-reduction method in the sense that it does not require the knowledge
of problem-dependent parameters, such as smoothness constant $L$, target
accuracy $\epsilon$ or any bound on gradient norms. In doing so, we are able to
compute an $\epsilon$-stationary point with $\tilde{O}\left(n +
\sqrt{n}/\epsilon^2\right)$ oracle-calls, which matches the respective lower
bound up to logarithmic factors.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Kavis_A/0/1/0/all/0/1&quot;&gt;Ali Kavis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Skoulakis_S/0/1/0/all/0/1&quot;&gt;Stratis Skoulakis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Antonakopoulos_K/0/1/0/all/0/1&quot;&gt;Kimon Antonakopoulos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Dadi_L/0/1/0/all/0/1&quot;&gt;Leello Tadesse Dadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Cevher_V/0/1/0/all/0/1&quot;&gt;Volkan Cevher&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.01883">
<title>Faster Adaptive Momentum-Based Federated Methods for Distributed Composition Optimization. (arXiv:2211.01883v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2211.01883</link>
<description rdf:parseType="Literal">&lt;p&gt;Composition optimization recently appears in many machine learning
applications such as meta learning and reinforcement learning. Recently many
composition optimization algorithms have been proposed and studied, however,
few adaptive algorithm considers the composition optimization under the
distributed setting. Meanwhile, the existing distributed composition
optimization methods still suffer from high sample and communication
complexities. In the paper, thus, we develop a class of faster momentum-based
federated compositional gradient descent algorithms (i.e., MFCGD and AdaMFCGD)
to solve the nonconvex distributed composition problems, which builds on the
momentum-based variance reduced and local-SGD techniques. In particular, our
adaptive algorithm (i.e., AdaMFCGD) uses a unified adaptive matrix to flexibly
incorporate various adaptive learning rates. Moreover, we provide a solid
theoretical analysis for our algorithms under non-i.i.d. setting, and prove our
algorithms obtain a lower sample and communication complexities simultaneously
than the existing federated compositional algorithms. Specifically, our
algorithms obtain lower sample complexity of $\tilde{O}(\epsilon^{-3})$ with
lower communication complexity of $\tilde{O}(\epsilon^{-2})$ in finding an
$\epsilon$-stationary point. We conduct the experiments on robust federated
learning and distributed meta learning tasks to demonstrate efficiency of our
algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1&quot;&gt;Feihu Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.01918">
<title>A Dynamic Observer for a Class of Infinite-Dimensional Vibrating Flexible Structures. (arXiv:2211.01918v1 [math.OC])</title>
<link>http://arxiv.org/abs/2211.01918</link>
<description rdf:parseType="Literal">&lt;p&gt;Infinite-dimensional control systems with outputs are considered in the
Hamiltonian formulation with generalized coordinates. An explicit scheme for
constructing a dynamic observer for this class of systems is proposed with
arbitrary gain coefficients. Sufficient conditions for the convergence of the
constructed observer are obtained on the basis of the invariance principle.
This result is applied to a flexible beam model attached to a mass-spring
system with lumped and distributed actuators. The estimation error decay is
illustrated with numerical simulations of finite-dimensional approximations of
the observer dynamics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Zuyev_A/0/1/0/all/0/1&quot;&gt;Alexander Zuyev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Kalosha_J/0/1/0/all/0/1&quot;&gt;Julia Kalosha&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.01961">
<title>The LP-update policy for weakly coupled Markov decision processes. (arXiv:2211.01961v1 [math.OC])</title>
<link>http://arxiv.org/abs/2211.01961</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work we propose a novel policy called the LP-update policy for finite
horizon weakly coupled Markov decision processes. The latter can be seen as
multi-constraint multi-action bandits, and generalizes the classical restless
bandit problems (that are single-constraint two-action bandits), widely studied
in the literature. We consider a scaling model with $N$ statistically identical
arms. We show that our LP-update policy becomes asymptotically optimal at rate
$O(1/\sqrt{N})$ for any problem. This rate can be improved to $O(1/N)$ if the
problem is non-degenerate, and even to $e^{-\Omega(N)}$ if in addition the
problem admits a perfect rounding. The definition of non-degeneracy extends the
same notion for the classical two-action restless bandits. By using this
property, we also provide a more efficient implementation of the LP-update
policy. We illustrate the performance of our policy in a generalized applicant
screening problem.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Gast_N/0/1/0/all/0/1&quot;&gt;Nicolas Gast&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Gaujal_B/0/1/0/all/0/1&quot;&gt;Bruno Gaujal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Yan_C/0/1/0/all/0/1&quot;&gt;Chen Yan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.01962">
<title>A Posterior Sampling Framework for Interactive Decision Making. (arXiv:2211.01962v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2211.01962</link>
<description rdf:parseType="Literal">&lt;p&gt;We study sample efficient reinforcement learning (RL) under the general
framework of interactive decision making, which includes Markov decision
process (MDP), partially observable Markov decision process (POMDP), and
predictive state representation (PSR) as special cases. Toward finding the
minimum assumption that empowers sample efficient learning, we propose a novel
complexity measure, generalized eluder coefficient (GEC), which characterizes
the fundamental tradeoff between exploration and exploitation in online
interactive decision making. In specific, GEC captures the hardness of
exploration by comparing the error of predicting the performance of the updated
policy with the in-sample training error evaluated on the historical data. We
show that RL problems with low GEC form a remarkably rich class, which subsumes
low Bellman eluder dimension problems, bilinear class, low witness rank
problems, PO-bilinear class, and generalized regular PSR, where generalized
regular PSR, a new tractable PSR class identified by us, includes nearly all
known tractable POMDPs. Furthermore, in terms of algorithm design, we propose a
generic posterior sampling algorithm, which can be implemented in both
model-free and model-based fashion, under both fully observable and partially
observable settings. The proposed algorithm modifies the standard posterior
sampling algorithm in two aspects: (i) we use an optimistic prior distribution
that biases towards hypotheses with higher values and (ii) a loglikelihood
function is set to be the empirical loss evaluated on the historical data,
where the choice of loss function supports both model-free and model-based
learning. We prove that the proposed algorithm is sample efficient by
establishing a sublinear regret upper bound in terms of GEC. In summary, we
provide a new and unified understanding of both fully observable and partially
observable RL.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhong_H/0/1/0/all/0/1&quot;&gt;Han Zhong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_W/0/1/0/all/0/1&quot;&gt;Wei Xiong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1&quot;&gt;Sirui Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Liwei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhaoran Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1&quot;&gt;Zhuoran Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1&quot;&gt;Tong Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.01982">
<title>Fast integrators with sensitivity propagation for use in CasADi. (arXiv:2211.01982v1 [math.OC])</title>
<link>http://arxiv.org/abs/2211.01982</link>
<description rdf:parseType="Literal">&lt;p&gt;Efficient integrators with sensitivity propagation are an essential
ingredient for the numerical solution of optimal control problems. This paper
gives an overview on the acados integrators, their Python interface and
presents a workflow that allows using them with their sensitivities within a
nonlinear programming (NLP) solver interfaced by CasADi. The implementation is
discussed, demonstrated and provided as open-source software. The computation
times of the proposed integrator and its sensitivity computation are compared
to the native CasADi collocation integrator, CVODES and IDAS on different
examples. A speedup of one order of magnitude for simulation and of up to three
orders of magnitude for the forward sensitivity propagation is shown for an
airborne wind energy system model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Frey_J/0/1/0/all/0/1&quot;&gt;Jonathan Frey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Schutter_J/0/1/0/all/0/1&quot;&gt;Jochem De Schutter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Diehl_M/0/1/0/all/0/1&quot;&gt;Moritz Diehl&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.02032">
<title>To spike or not to spike: the whims of the Wonham filter in the strong noise regime. (arXiv:2211.02032v1 [math.PR])</title>
<link>http://arxiv.org/abs/2211.02032</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the celebrated Shiryaev-Wonham filter in its historical setup of
Wonham (1964) where the hidden Markov jump process has two states. We are
interested in the weak noise regime for the observation equation.
Interestingly, this becomes a strong noise regime for the filtering equations.
&lt;/p&gt;
&lt;p&gt;Earlier results of the authors show the appearance of spikes in the filtered
process, akin to a metastability phenomenon. This paper is aimed at
understanding the smoothed optimal filter, which is relevant for any system
with feedback. In particular, we demonstrate that there is a sharp phase
transition between a spiking regime and a regime with perfect smoothing.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Cedric_B/0/1/0/all/0/1&quot;&gt;Bernardin C&amp;#xe9;dric&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Reda_C/0/1/0/all/0/1&quot;&gt;Chhaibi Reda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Joseph_N/0/1/0/all/0/1&quot;&gt;Najnudel Joseph&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Clement_P/0/1/0/all/0/1&quot;&gt;Pellegrini Cl&amp;#xe9;ment&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.04923">
<title>Network Identification for Diffusively-Coupled Systems with Minimal Time Complexity. (arXiv:1903.04923v4 [cs.SY] UPDATED)</title>
<link>http://arxiv.org/abs/1903.04923</link>
<description rdf:parseType="Literal">&lt;p&gt;The theory of network identification, namely identifying the (weighted)
interaction topology among a known number of agents, has been widely developed
for linear agents. However, the theory for nonlinear agents using probing
inputs is far less developed, relying on dynamics linearization, and thus
cannot be applied to networks with non-smooth or discontinuous dynamics. We use
global convergence properties of the network, which can be assured using
passivity theory, to present a network identification method for nonlinear
agents. We do so by linearizing the steady-state equations rather than the
dynamics, achieving a sub-cubic time algorithm for network identification. We
also study the problem of network identification from a complexity theory
standpoint, showing that the presented algorithms are optimal in terms of time
complexity. We demonstrate the presented algorithm in two case studies with
discontinuous dynamics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharf_M/0/1/0/all/0/1&quot;&gt;Miel Sharf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zelazo_D/0/1/0/all/0/1&quot;&gt;Daniel Zelazo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1910.09143">
<title>Subgoal-based Exploration via Bayesian Optimization. (arXiv:1910.09143v3 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/1910.09143</link>
<description rdf:parseType="Literal">&lt;p&gt;Policy optimization in unknown, sparse-reward environments with expensive and
limited interactions is challenging, and poses a need for effective
exploration. Motivated by complex navigation tasks that require real-world
training (when cheap simulators are not available), we consider an agent that
faces an unknown distribution of environments and must decide on an exploration
strategy, through a series of training environments, that can benefit policy
learning in a test environment drawn from the environment distribution. Most
existing approaches focus on fixed exploration strategies, while the few that
view exploration as a meta-optimization problem tend to ignore the need for
cost-efficient exploration. We propose a cost-aware Bayesian optimization
approach that efficiently searches over a class of dynamic subgoal-based
exploration strategies. The algorithm adjusts a variety of levers -- the
locations of the subgoals, the length of each episode, and the number of
replications per trial -- in order to overcome the challenges of sparse
rewards, expensive interactions, and noise. Our experimental evaluation
demonstrates that, when averaged across problem domains, the proposed algorithm
outperforms the meta-learning algorithm MAML by 19%, the hyperparameter tuning
method Hyperband by 23%, BO techniques EI and LCB by 24% and 22%, respectively.
We also provide a theoretical foundation and prove that the method
asymptotically identifies a near-optimal subgoal design from the search space.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yijia Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Poloczek_M/0/1/0/all/0/1&quot;&gt;Matthias Poloczek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Jiang_D/0/1/0/all/0/1&quot;&gt;Daniel R. Jiang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.09854">
<title>A New Extension of Chubanov&apos;s Method to Symmetric Cones. (arXiv:2110.09854v3 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/2110.09854</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a new variant of Chubanov&apos;s method for solving the feasibility
problem over the symmetric cone by extending Roos&apos;s method (2018) of solving
the feasibility problem over the nonnegative orthant. The proposed method
considers a feasibility problem associated with a norm induced by the maximum
eigenvalue of an element and uses a rescaling focusing on the upper bound for
the sum of eigenvalues of any feasible solution to the problem. Its
computational bound is (i) equivalent to that of Roos&apos;s original method (2018)
and superior to that of Louren\c{c}o et al.&apos;s method (2019) when the symmetric
cone is the nonnegative orthant, (ii) superior to that of Louren\c{c}o et al.&apos;s
method (2019) when the symmetric cone is a Cartesian product of second-order
cones, (iii) equivalent to that of Louren\c{c}o et al.&apos;s method (2019) when the
symmetric cone is the simple positive semidefinite cone, and (iv) superior to
that of Pena and Soheili&apos;s method (2017) for any simple symmetric cones under
the feasibility assumption of the problem imposed in Pena and Soheili&apos;s method
(2017). We also conduct numerical experiments that compare the performance of
our method with existing methods by generating instances in three types:
strongly (but ill-conditioned) feasible instances, weakly feasible instances,
and infeasible instances. For any of these instances, the proposed method is
rather more efficient than the existing methods in terms of accuracy and
execution time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Kanoh_S/0/1/0/all/0/1&quot;&gt;Shin-ichi Kanoh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Yoshise_A/0/1/0/all/0/1&quot;&gt;Akiko Yoshise&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.14985">
<title>A machine learning approach for fighting the curse of dimensionality in global optimization. (arXiv:2110.14985v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2110.14985</link>
<description rdf:parseType="Literal">&lt;p&gt;Finding global optima in high-dimensional optimization problems is extremely
challenging since the number of function evaluations required to sufficiently
explore the search space increases exponentially with its dimensionality.
Furthermore, multimodal cost functions render local gradient-based search
techniques ineffective. To overcome these difficulties, we propose to trim
uninteresting regions of the search space where global optima are unlikely to
be found by means of autoencoders, exploiting the lower intrinsic
dimensionality of certain cost functions; optima are then searched over
lower-dimensional latent spaces. The methodology is tested on benchmark
functions and on multiple variations of a structural topology optimization
problem, where we show that we can estimate this intrinsic lower dimensionality
and based thereon obtain the global optimum at best or superior results
compared to established optimization procedures at worst.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schumann_J/0/1/0/all/0/1&quot;&gt;Julian F. Schumann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aragon_A/0/1/0/all/0/1&quot;&gt;Alejandro M. Arag&amp;#xf3;n&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2201.07659">
<title>Equilibria of Time-inconsistent Stopping for One-dimensional Diffusion Processes. (arXiv:2201.07659v2 [math.PR] UPDATED)</title>
<link>http://arxiv.org/abs/2201.07659</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider three equilibrium concepts proposed in the literature for
time-inconsistent stopping problems, including mild equilibria, weak equilibria
and strong equilibria. The discount function is assumed to be log sub-additive
and the underlying process is one-dimensional diffusion. We first provide
necessary and sufficient conditions for the characterization of weak
equilibria. The smooth-fit condition is obtained as a by-product. Next, based
on the characterization of weak equilibria, we show that an optimal mild
equilibrium is also weak. Then we provide conditions under which a weak
equilibrium is strong. We further show that an optimal mild equilibrium is also
strong under a certain condition. Finally, we provide several examples
including one shows a weak equilibrium may not be strong, and another one shows
a strong equilibrium may not be optimal mild.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Bayraktar_E/0/1/0/all/0/1&quot;&gt;Erhan Bayraktar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhenhua Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Zhou_Z/0/1/0/all/0/1&quot;&gt;Zhou Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2206.00529">
<title>Variance Reduction is an Antidote to Byzantines: Better Rates, Weaker Assumptions and Communication Compression as a Cherry on the Top. (arXiv:2206.00529v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2206.00529</link>
<description rdf:parseType="Literal">&lt;p&gt;Byzantine-robustness has been gaining a lot of attention due to the growth of
the interest in collaborative and federated learning. However, many fruitful
directions, such as the usage of variance reduction for achieving robustness
and communication compression for reducing communication costs, remain weakly
explored in the field. This work addresses this gap and proposes Byz-VR-MARINA
- a new Byzantine-tolerant method with variance reduction and compression. A
key message of our paper is that variance reduction is key to fighting
Byzantine workers more effectively. At the same time, communication compression
is a bonus that makes the process more communication efficient. We derive
theoretical convergence guarantees for Byz-VR-MARINA outperforming previous
state-of-the-art for general non-convex and Polyak-Lojasiewicz loss functions.
Unlike the concurrent Byzantine-robust methods with variance reduction and/or
compression, our complexity results are tight and do not rely on restrictive
assumptions such as boundedness of the gradients or limited compression.
Moreover, we provide the first analysis of a Byzantine-tolerant method
supporting non-uniform sampling of stochastic gradients. Numerical experiments
corroborate our theoretical findings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gorbunov_E/0/1/0/all/0/1&quot;&gt;Eduard Gorbunov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Horvath_S/0/1/0/all/0/1&quot;&gt;Samuel Horv&amp;#xe1;th&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Richtarik_P/0/1/0/all/0/1&quot;&gt;Peter Richt&amp;#xe1;rik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gidel_G/0/1/0/all/0/1&quot;&gt;Gauthier Gidel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2206.07021">
<title>Federated Optimization Algorithms with Random Reshuffling and Gradient Compression. (arXiv:2206.07021v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2206.07021</link>
<description rdf:parseType="Literal">&lt;p&gt;Gradient compression is a popular technique for improving communication
complexity of stochastic first-order methods in distributed training of machine
learning models. However, the existing works consider only with-replacement
sampling of stochastic gradients. In contrast, it is well-known in practice and
recently confirmed in theory that stochastic methods based on
without-replacement sampling, e.g., Random Reshuffling (RR) method, perform
better than ones that sample the gradients with-replacement. In this work, we
close this gap in the literature and provide the first analysis of methods with
gradient compression and without-replacement sampling. We first develop a
na\&quot;ive combination of random reshuffling with gradient compression (Q-RR).
Perhaps surprisingly, but the theoretical analysis of Q-RR does not show any
benefits of using RR. Our extensive numerical experiments confirm this
phenomenon. This happens due to the additional compression variance. To reveal
the true advantages of RR in the distributed learning with compression, we
propose a new method called DIANA-RR that reduces the compression variance and
has provably better convergence rates than existing counterparts with
with-replacement sampling of stochastic gradients. Next, to have a better fit
to Federated Learning applications, we incorporate local computation, i.e., we
propose and analyze the variants of Q-RR and DIANA-RR -- Q-NASTYA and
DIANA-NASTYA that use local gradient steps and different local and global
stepsizes. Finally, we conducted several numerical experiments to illustrate
our theoretical results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sadiev_A/0/1/0/all/0/1&quot;&gt;Abdurakhmon Sadiev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Malinovsky_G/0/1/0/all/0/1&quot;&gt;Grigory Malinovsky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gorbunov_E/0/1/0/all/0/1&quot;&gt;Eduard Gorbunov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sokolov_I/0/1/0/all/0/1&quot;&gt;Igor Sokolov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khaled_A/0/1/0/all/0/1&quot;&gt;Ahmed Khaled&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Burlachenko_K/0/1/0/all/0/1&quot;&gt;Konstantin Burlachenko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Richtarik_P/0/1/0/all/0/1&quot;&gt;Peter Richt&amp;#xe1;rik&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2206.13606">
<title>Online Resource Allocation under Horizon Uncertainty. (arXiv:2206.13606v2 [cs.DS] UPDATED)</title>
<link>http://arxiv.org/abs/2206.13606</link>
<description rdf:parseType="Literal">&lt;p&gt;We study stochastic online resource allocation: a decision maker needs to
allocate limited resources to stochastically-generated sequentially-arriving
requests in order to maximize reward. At each time step, requests are drawn
independently from a distribution that is unknown to the decision maker. Online
resource allocation and its special cases have been studied extensively in the
past, but prior results crucially and universally rely on the strong assumption
that the total number of requests (the horizon) is known to the decision maker
in advance. In many applications, such as revenue management and online
advertising, the number of requests can vary widely because of fluctuations in
demand or user traffic intensity. In this work, we develop online algorithms
that are robust to horizon uncertainty. In sharp contrast to the known-horizon
setting, no algorithm can achieve even a constant asymptotic competitive ratio
that is independent of the horizon uncertainty. We introduce a novel
generalization of dual mirror descent which allows the decision maker to
specify a schedule of time-varying target consumption rates, and prove
corresponding performance guarantees. We go on to give a fast algorithm for
computing a schedule of target consumption rates that leads to near-optimal
performance in the unknown-horizon setting. In particular, our competitive
ratio attains the optimal rate of growth (up to logarithmic factors) as the
horizon uncertainty grows large. Finally, we also provide a way to incorporate
machine-learned predictions about the horizon which interpolates between the
known and unknown horizon settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balseiro_S/0/1/0/all/0/1&quot;&gt;Santiago Balseiro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kroer_C/0/1/0/all/0/1&quot;&gt;Christian Kroer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_R/0/1/0/all/0/1&quot;&gt;Rachitesh Kumar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2208.07919">
<title>Dynamic Pricing for Non-fungible Resources: Designing Multidimensional Blockchain Fee Markets. (arXiv:2208.07919v2 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/2208.07919</link>
<description rdf:parseType="Literal">&lt;p&gt;Public blockchains implement a fee mechanism to allocate scarce computational
resources across competing transactions. Most existing fee market designs
utilize a joint, fungible unit of account (e.g., gas in Ethereum) to price
otherwise non-fungible resources such as bandwidth, computation, and storage,
by hardcoding their relative prices. Fixing the relative price of each resource
in this way inhibits granular price discovery, limiting scalability and opening
up the possibility of denial-of-service attacks. As a result, many prominent
networks such as Ethereum and Solana have proposed multi-dimensional fee
markets. In this paper, we provide a principled way to design fee markets that
efficiently price multiple non-fungible resources. Starting from a loss
function specified by the network designer, we show how to compute dynamic
prices that align the network&apos;s incentives (to minimize the loss) with those of
the users and miners (to maximize their welfare), even as demand for these
resources changes. Our pricing mechanism follows from a natural decomposition
of the network designer&apos;s problem into two parts that are related to each other
via the resource prices. These results can be used to efficiently set fees in
order to improve network performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Diamandis_T/0/1/0/all/0/1&quot;&gt;Theo Diamandis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Evans_A/0/1/0/all/0/1&quot;&gt;Alex Evans&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Chitra_T/0/1/0/all/0/1&quot;&gt;Tarun Chitra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Angeris_G/0/1/0/all/0/1&quot;&gt;Guillermo Angeris&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2210.05164">
<title>Tight Error Bounds for Nonnegative Orthogonality Constraints and Exact Penalties. (arXiv:2210.05164v4 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/2210.05164</link>
<description rdf:parseType="Literal">&lt;p&gt;For the intersection of the Stiefel manifold and the set of nonnegative
matrices in $\mathbb{R}^{n\times r}$, we present global and local error bounds
with easily computable residual functions and explicit coefficients. Moreover,
we show that the error bounds cannot be improved except for the coefficients,
which explains why two square-root terms are necessary in the bounds when $1 &amp;lt;
r &amp;lt; n$ for the nonnegativity and orthogonality, respectively. The error bounds
are applied to penalty methods for minimizing a Lipschitz continuous function
with nonnegative orthogonality constraints. Under only the Lipschitz continuity
of the objective function, we prove the exactness of penalty problems that
penalize the nonnegativity constraint, or the orthogonality constraint, or both
constraints. Our results cover both global and local minimizers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xiaojun Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+He_Y/0/1/0/all/0/1&quot;&gt;Yifan He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zaikun Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2210.05807">
<title>Solving Convex Smooth Function Constrained Optimization Is Almost As Easy As Unconstrained Optimization. (arXiv:2210.05807v3 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/2210.05807</link>
<description rdf:parseType="Literal">&lt;p&gt;Consider applying first-order methods to solve the smooth convex constrained
optimization problem of the form $\min_{x \in X} F(x).$ For a simple closed
convex set $X$ which is easy to project onto, Nesterov proposed the Accelerated
Gradient Descent (AGD) method to solve the constrained problem as efficiently
as an unconstrained problem in terms of the number of gradient computations of
$F$ (i.e., oracle complexity). For a more complicated $\mathcal{X}$ described
by function constraints, i.e., $\mathcal{X} = \{x \in X: g(x) \leq 0\}$, where
the projection onto $\mathcal{X}$ is not possible, it is an open question
whether the function constrained problem can be solved as efficiently as an
unconstrained problem in terms of the number of gradient computations for $F$
and $g$. In this paper, we provide an affirmative answer to the question by
proposing a single-loop Accelerated Constrained Gradient Descent (ACGD) method.
The ACGD method modifies the AGD method by changing the descent step to a
constrained descent step, which adds only a few linear constraints to the prox
mapping. It enjoys almost the same oracle complexity as the optimal one for
minimizing the optimal Lagrangian function, i.e., the Lagrangian multiplier
$\lambda$ being fixed to the optimal multiplier $\lambda^*$. These upper oracle
complexity bounds are shown to be unimprovable under a certain optimality
regime with new lower oracle complexity bounds. To enhance its efficiency for
large-scale problems with many function constraints, we introduce an ACGD with
Sliding (ACGD-S) method which replaces the possibly computationally demanding
constrained descent step with a sequence of basic matrix-vector
multiplications. The ACGD-S method shares the same oracle complexity as the
ACGD method, and its computation complexity, measured by the number of
matrix-vector multiplications, is also unimprovable.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhe Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lan_G/0/1/0/all/0/1&quot;&gt;Guanghui Lan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.00675">
<title>An Empirical Quantile Estimation Approach to Nonlinear Optimization Problems with Chance Constraints. (arXiv:2211.00675v2 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/2211.00675</link>
<description rdf:parseType="Literal">&lt;p&gt;We investigate an empirical quantile estimation approach to solve
chance-constrained nonlinear optimization problems. Our approach is based on
the reformulation of the chance constraint as an equivalent quantile constraint
to provide stronger signals on the gradient. In this approach, the value of the
quantile function is estimated empirically from samples drawn from the random
parameters, and the gradient of the quantile function is estimated via a
finite-difference approximation on top of the quantile-function-value
estimation. We establish a convergence theory of this approach within the
framework of an augmented Lagrangian method for solving general nonlinear
constrained optimization problems. The foundation of the convergence analysis
is a concentration property of the empirical quantile process, and the analysis
is divided based on whether or not the quantile function is differentiable. In
contrast to the sampling-and-smoothing approach used in the literature, the
method developed in this paper does not involve any smoothing function, and
hence the quantile-function gradient approximation is easier to implement, and
there are fewer accuracy-control parameters to tune. Numerical investigation
shows that our approach can also identify high-quality solutions, especially
with a relatively large step size for the finite-difference estimation, which
works intuitively as an implicit smoothing. Thus,the possibility exists that an
explicit smoothing is not always necessary to handle the chance constraints.
Just improving the estimation of the quantile-function value and gradient
itself likely could already lead to high performance for solving the
chance-constrained nonlinear programs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Luo_F/0/1/0/all/0/1&quot;&gt;Fengqiao Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Larson_J/0/1/0/all/0/1&quot;&gt;Jeffrey Larson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.01122">
<title>Fast Adaptive Federated Bilevel Optimization. (arXiv:2211.01122v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2211.01122</link>
<description rdf:parseType="Literal">&lt;p&gt;Bilevel optimization is a popular hierarchical model in machine learning, and
has been widely applied to many machine learning tasks such as meta learning,
hyperparameter learning and policy optimization. Although many bilevel
optimization algorithms recently have been developed, few adaptive algorithm
focuses on the bilevel optimization under the distributed setting. It is well
known that the adaptive gradient methods show superior performances on both
distributed and non-distributed optimization. In the paper, thus, we propose a
novel adaptive federated bilevel optimization algorithm (i.e.,AdaFBiO) to solve
the distributed bilevel optimization problems, where the objective function of
Upper-Level (UL) problem is possibly nonconvex, and that of Lower-Level (LL)
problem is strongly convex. Specifically, our AdaFBiO algorithm builds on the
momentum-based variance reduced technique and local-SGD to obtain the best
known sample and communication complexities simultaneously. In particular, our
AdaFBiO algorithm uses the unified adaptive matrices to flexibly incorporate
various adaptive learning rates to update variables in both UL and LL problems.
Moreover, we provide a convergence analysis framework for our AdaFBiO
algorithm, and prove it needs the sample complexity of
$\tilde{O}(\epsilon^{-3})$ with communication complexity of
$\tilde{O}(\epsilon^{-2})$ to obtain an $\epsilon$-stationary point.
Experimental results on federated hyper-representation learning and federated
data hyper-cleaning tasks verify efficiency of our algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1&quot;&gt;Feihu Huang&lt;/a&gt;</dc:creator>
</item>
</rdf:RDF>