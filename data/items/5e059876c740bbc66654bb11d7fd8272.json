{
  "title": "Contextual information integration for stance detection via cross-attention. (arXiv:2211.01874v1 [cs.CL])",
  "link": "http://arxiv.org/abs/2211.01874",
  "description": "<p>Stance detection deals with the identification of an author's stance towards\na target and is applied on various text domains like social media and news. In\nmany cases, inferring the stance is challenging due to insufficient access to\ncontextual information. Complementary context can be found in knowledge bases\nbut integrating the context into pretrained language models is non-trivial due\nto their graph structure. In contrast, we explore an approach to integrate\ncontextual information as text which aligns better with transformer\narchitectures. Specifically, we train a model consisting of dual encoders which\nexchange information via cross-attention. This architecture allows for\nintegrating contextual information from heterogeneous sources. We evaluate\ncontext extracted from structured knowledge sources and from prompting large\nlanguage models. Our approach is able to outperform competitive baselines\n(1.9pp on average) on a large and diverse stance detection benchmark, both (1)\nin-domain, i.e. for seen targets, and (2) out-of-domain, i.e. for targets\nunseen during training. Our analysis shows that it is able to regularize for\nspurious label correlations with target-specific cue words.\n</p>",
  "dc:creator": "<a href=\"http://arxiv.org/find/cs/1/au:+Beck_T/0/1/0/all/0/1\">Tilman Beck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Waldis_A/0/1/0/all/0/1\">Andreas Waldis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1\">Iryna Gurevych</a>"
}