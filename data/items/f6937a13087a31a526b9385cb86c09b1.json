{
  "title": "History of Monte Carlo Methods - Part 1",
  "link": "",
  "published": "2015-10-16T21:30:00+01:00",
  "updated": "2015-10-16T21:30:00+01:00",
  "author": {
    "name": "Sebastian Nowozin"
  },
  "id": "tag:www.nowozin.net,2015-10-16:/sebastian/blog/history-of-monte-carlo-methods-part-1.html",
  "summary": "<p>Some time ago in June 2013 I gave a <em>lab tutorial</em> on Monte Carlo methods at\nMicrosoft Research.  These tutorials are seminar-talk length (45 minutes) but\nare supposed to be light, accessible to a general computer science audience,\nand fun â€¦</p>",
  "content": "<p>Some time ago in June 2013 I gave a <em>lab tutorial</em> on Monte Carlo methods at\nMicrosoft Research.  These tutorials are seminar-talk length (45 minutes) but\nare supposed to be light, accessible to a general computer science audience,\nand fun.</p>\n<p>In this tutorial I explain and illustrate a number of Monte Carlo methods\n(rejection sampling, importance sampling, sequential Monte Carlo, Markov chain\nMonte Carlo, and simulated annealing) on the same problem.\nAlthough I am not exactly a comedian, in order to keep the tutorial fun I\npeppered the talk with lots of historical anecdotes from the inventors of the\nmethods.</p>\n<p>This is the first of three parts.</p>\n<h1>Part 1</h1>\n<p>The first part (17 minutes) covers the history of modern Monte Carlo methods,\ntheir use in scientific computation, and one of the most basic Monte Carlo\nmethods, <em>rejection sampling</em>.</p>\n<p>The video files <a href=\"https://1drv.ms/u/s!AniEhJbTwIdrkuMvpGcjY3NR12xbuw?e=YvUIAn\">are also available for offline\nviewing</a> in\nMP4/H.264, WebM/VP8, and WebM/VP9 formats.</p>\n<video width=\"639\" controls>\n<source src=\"https://onedrive.live.com/download?cid=6B87C0D396848478&resid=6B87C0D396848478%21307634&authkey=AN2p0blkF_SVk2g\"\n    type=\"video/mp4\">\nYour browser does not support the video tag.\n</video>\n\n<p><iframe\nsrc=\"https://onedrive.live.com/embed?cid=6B87C0D396848478&resid=6B87C0D396848478%21108435&authkey=AHiRYMuM9wBIKos&em=2\"\nwidth=\"639\" height=\"360\" frameborder=\"0\" scrolling=\"no\"></iframe>\n</p>\n<p>(Click on the slide to advance, or use the previous/next buttons.)</p>\n<h2>Transcript</h2>\n<p>(This is a slightly edited and link-annotated transcript of the audio in the\nabove video.  As this is spoken text, it is not as polished as my writing.)</p>\n<p><strong>Speaker</strong>: Thank you all for coming to this lab tutorial. I know many of you\nhave used Monte Carlo techniques in your research or in your projects. And\nstill I decide to keep the level of this tutorial very basic and I try to show\nyou a few different Monte Carlo methods and how they may be useful in your\nresearch.  I hope that after the talk you basically understand how these\nmethods can be applied and what different limitations the different methods\nhave. And I will introduce these different methods in chronological order and\nalso say a little about the interesting history, how these methods have been\ninvented.</p>\n<p>But before I get to that, I first want to ask you, do you like to play\nsolitaire? I certainly do sometimes play solitaire and when you play a couple\nof games, you realize that some games are actually not solvable. So some games\nare just, no matter what you try, no matter what you do, they are just\nprovably not solvable. And so if you shuffle a random deck of 52 cards and put\nit out as a solitaire deck, it's a valid question to ask is what probability\ndo you get a solvable game? That's the question. And it's precisely this\nquestion, precisely this question for the game of <a href=\"https://en.wikipedia.org/wiki/Canfield_%28solitaire%29\">Canfield\nSolitaire</a> that has\nled to the invention of the modern Monte Carlo methods.</p>\n<p>One way to attack this problem would be instead of trying analytic or\nmathematical approaches, basically having to take into account all the rules\nof the game, is to just take a random set of cards, play a hundred times after\nrandomly shuffling the cards and just looking at how many times you come up\nwith a solvable game. And that would give you a ballpark estimate on the\nprobability. And that's precisely what this man, <a href=\"https://en.wikipedia.org/wiki/Stanislaw_Ulam\">Stanislaw\nUlam</a>, has\nrecognized, that this is possible.</p>\n<p>I want to say a few words about Stanislaw Ulam because he's so crucial to the\ninvention of Monte Carlo methods. So he was born in today's Ukraine in a town\ncalled <a href=\"https://en.wikipedia.org/wiki/Lviv\">Lviv</a> (formerly Lemberg,\nin Austria-Hungary). And he was enjoying a very good education. His family had\na good background. And he very early discovered in his life that he likes to\ndo mathematics. He was part of the <a href=\"https://en.wikipedia.org/wiki/Lw%C3%B3w_School_of_Mathematics\">Lviv School of\nMathematics</a>\nwho has done many contribution to the more abstract mathematics, vector\nspaces. So he's known for some of the mathematical results. But then he had to\nflee to the United States in the 1930s and there became professor in\nMathematics and was recruited to <a href=\"http://www.atomicheritage.org/history/hydrogen-bomb-1950\">Los\nAlamos</a> to do\nresearch on the Hydrogen bomb. Not the first nuclear weapon but on the second\nHydrogen bomb design.</p>\n<p>During that time in 1946, working at Los Alamos, he had a breakdown. For\ncouple of days he had a headache and he had a breakdown and was delivered to a\nhospital. The doctors performed an <a href=\"https://en.wikipedia.org/wiki/Encephalitis\">emergency\nsurgery</a>, removed part of his\nskull, because it turned out he had a brain infection, the brain has swollen\nand he would have died if the doctors didn't perform his operation. And the\ndoctors told him \"You have to recover, you have to stay at home for half a\nyear and don't do any mathematics.\"</p>\n<p>He was obsessed with Mathematics for his whole life. So instead of doing\nmathematics, he tried to pass the time playing Canfield Solitaire. And while\nplaying Canfield Solitaire he asked the question, \"<a href=\"https://en.wikipedia.org/wiki/Canfield_%28solitaire%29#Solvability\">Okay, what's probability to\nsolve this\ngame?</a>\"\nand with his quite broad knowledge of Mathematics he tried a few different\nanalytic attempts to come up with the answer to that question.  But ultimately\nhe realized that it is much easier to get an estimate by just playing games\nrandomly.</p>\n<p>And at that time he was already doing research in Los Alamos. He recognized\nthat this has applications as well for studying different scientific problems\nsuch as <a href=\"https://en.wikipedia.org/wiki/Neutron_transport\">Neutron Transport</a>,\nwhich is essential to understand when designing nuclear weapons. So he is also\nthe inventor of the <a href=\"https://en.wikipedia.org/wiki/History_of_the_Teller%E2%80%93Ulam_design\">first working Hydrogen bomb\ndesign</a>\ntogether with <a href=\"https://en.wikipedia.org/wiki/Edward_Teller\">Edward Teller</a>.\nAnd the inventor of the Monte Carlo method, <a href=\"http://www.amstat.org/misc/TheMonteCarloMethod.pdf\">published a few years\nlater</a> in\n1949. And also he's known for having performed probably the most laborious\nmanual computation ever undertaken (with Cornelius Everett) to disprove Edward\nTeller's earlier nuclear weapon design, to show that it is not possible. So\nvery interesting history. I will talk a little bit later about him some more.</p>\n<p>So nowadays, Monte Carlo methods, and with Monte Carlo methods, really, I\nmean, any method where you perform some random experiment, which is typically\nquite simple, and you aggregate this results into some inferences about a more\ncomplex system. Today, Monte Carlo methods are very popular in simulating\ncomplex systems. For example, models of physical or biological or chemical\nprocesses, for example, weather forecasting, and of course, nuclear weapon\ndesign.\nBut also just last week, it was used to <a href=\"http://www.nature.com/nature/journal/v497/n7451/full/nature12162.html\">simulate the HI Virus\ncapsid</a>.\nA simulation of 64 million atoms, a major breakthrough in understanding the HI\nVirus. So it has huge applications in scientific simulations, it also has\napplications in doing inference in probabilistic models. The most famous\nsystem there would be the <a href=\"http://www.mrc-bsu.cam.ac.uk/software/bugs/\">BUGS\nsystem</a> also developed here in\nCambridge at the University, initially developed in the early '90s.\n<a href=\"http://research.microsoft.com/en-us/um/cambridge/projects/infernet/\">Infer.NET</a>\nalso supports Monte Carlo inference and here at MSRC also the <a href=\"http://research.microsoft.com/en-us/projects/filzbach/\">Filzbach\nsystem</a>\ndoes. Also there's a quite popular system now, from the University of\nColumbia, called <a href=\"http://mc-stan.org/\">STAN</a>. It's actually named STAN because\nof Stanislaw Ulam.</p>\n<p>Monte Carlo methods can also be used for optimization. So not just for\nsimulating but also for optimizing a cost function. We will see an example\nlater, but typically it is often used where very complicated systems are\noptimized. So something like the circuit layout that has many interdependent\nconstraints. And it is also used for planning, for games, and for robotics,\nwhere it is essential to approximate intractable quantities, to perform\nplanning under uncertainty or where measurement noise makes it essential to\nrepresent uncertainty in a representative way. So these are many, many\ndifferent applications, too many to really list. I want to pick out one\napplication for the rest of the talk and illustrate this application with\ndifferent Monte Carlo methods.</p>\n<p>And that application is <a href=\"https://en.wikipedia.org/wiki/Protein_folding\">protein\nfolding</a>. So protein folding\nhappens right now in your body, in every cell of your body. In every cell you\nhave a structure called the Ribosome and that's basically the factory in your\ncell. It transforms information, encoded in the DNA into one linear long\nstructure, the protein. And that structure is such a long chain that folds\nitself into very intricate three dimensional structures.  Very beautiful\nstructures arise, and it is really the three-dimensional shape that this long\nchain folds into that determines the functional properties. It is really\nessential to understand in order to make predictions about what these\nmolecules do. This can take anywhere between a few milliseconds and a few\nhours. And I think the state of the art on a modern machine is to be able to\nsimulate accurately something like 60 nanoseconds per computer day. So we are\nnowhere in reach of being able to accurately fold these structures. But there\nis the <a href=\"https://folding.stanford.edu/\">Stanford Folding@home</a> project which\nuses Monte Carlo methods. And I think right now, they have something like a\nhundred fifty thousand computers working right now on the problem of protein\nfolding. So it is quite essential to understand a couple of different\ndiseases.</p>\n<p>We are not going to solve protein folding in this talk but I am going to use a\nslightly more simplified model. One thing to simplify is you still have a\nchain. But you say, \"Okay, first the chain does not live in three dimensions,\nit only lives on the plane.\" And we do not have many different amino acids, we\nonly have two: the black ones and the white ones. And the white ones repel\nwater, the white ones like water and the black ones repel water and so they\nfold into something that has a black core and a white surrounding. In fact, I\nam going to make it even simpler. I say, \"Okay, it lives on the plane but it\nlives on the grid\". So it is a further simplification. And now for the next\nfew slides, I even simplify this one step further: we only have the white\nbonds. </p>\n<p>So that is a so-called <a href=\"https://en.wikipedia.org/wiki/Self-avoiding_walk\">2D lattice self-avoiding random walk</a> model. So you have\na certain length. Say 48 bonds, 48 elements, and you have a self-avoiding\nwalk, so this walk is not allowed to cross onto itself. And this is a very\nsimplified model but already some questions which are interesting become very\nhard or actually intractable. For example, if I fix a number of elements in\nthis walk, one question is, how many self-avoiding walks are there on the\nplane? Another question is, okay the number is finite, while there are many\nbut finitely many possible combinations, how do I uniformly generate such\nrandom walk? And the third question would be, okay, I am interested in some\naverage properties, for example, the average end-point distance between the\ntwo ends, how do I compute an approximation to that average quantity?</p>\n<p>These are really typical problems that can be addressed with Monte Carlo\nmethods:\n- <em>average quantities</em>,\n- <em>counting problems</em>,\n- <em>random sampling problems</em>.\nSo that's what's going to be with us in the next few slides.</p>\n<p>The first method is a very simple one. It's called <a href=\"https://en.wikipedia.org/wiki/Rejection_sampling\"><em>rejection\nsampling</em></a> and the idea is\nreally very simple to explain. While we have this complicated set, the set of\nall self-avoiding random walks of a certain lengths and we want to generate\none element uniformly at random from the set. This is hard. So what we do is\nwe instead consider a super set, the set of all random walks of a certain\nlengths, and this is allowed to cross onto each other. And it is very easy to\nsimulate from that set. So we just simulate from this orange set, from this\nlarger set, and whenever we end up outside the blue set we discard that\nsample. And whenever we are inside the blue sample set, then we keep the\nsample. And because we uniformly generate samples, we can just keep doing this\nand collect whenever we reach an element in the blue set.</p>\n<p>In practice this would work as follows: we start and we just keep appending in\na randomly chosen direction, one out of three say, and if we happen to cross\non ourselves we can already discard that sample and start over. And we would\nkeep all the sample set that we can grow to the full lengths we want and we\nkeep them and we maybe collect a thousand of them. And compute whatever\nproperty we want from that sample set.</p>\n<p><strong>Attendee 1</strong>: May I ask a question?</p>\n<p><strong>Speaker</strong>: Yes, sure.</p>\n<p><strong>Attendee 1</strong>: What happens when instead you say, \"Oh Dear, I shouldn't have\ngone down, I should have gone-in in a different direction.\" Did you just get a\nbiased sample or something?</p>\n<p><strong>Speaker</strong>: You are anticipating the future. We are still in 1949.</p>\n<p><strong>Attendee 1</strong>: But I thought this was the-- you said, right to begin with,\ngenerating the ones that don't cross themselves is hard. </p>\n<p><strong>Speaker</strong>: Yes and it would still be hard-- just bear with me for a few\nslides, this is actually where it's leading to.</p>\n<p><strong>Attendee 1</strong>: Okay.</p>\n<p><strong>Speaker</strong>: But this is a simple method. And we can, once we have generated the\nset of samples, we can compute average properties. For example, this squared\nextension there where you compute the distance in the plane between the two\nend points, that is a model problem that people considered. And more\ngenerally, what we would like to do is to compute expectations. So we have a\ndistribution <span class=\"math\">\\(\\pi\\)</span> of <span class=\"math\">\\(X\\)</span> over some state <span class=\"math\">\\(X\\)</span> and we would like to evaluate some\nquantity <span class=\"math\">\\(\\phi\\)</span> of <span class=\"math\">\\(X\\)</span>.  For example, this distance between the two endpoints\nof a certain state and we want to compute some sum and the sum contains\nexponentially many terms in this case. We want to compute the sum as an\nexpectation and average quantity. And the Monte Carlo idea is to simply\nreplace it, approximate that huge sum with exponentially many terms with\nsomething that has only say a thousand or 10,000 terms which is the samples we\ngenerated.</p>\n<p>When we do that, when we actually do this rejection sampling here as a\nfunction of the chain lengths. I do that and I generate here 10 million\nsamples, 10 million times I try and I keep all the samples at length that\nhelped me to be self-avoiding. Then I can plot this average distance and\nbecause it is an average of many terms I know that the central limit theorem\napplies so I can also plot <a href=\"https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval#Wilson_score_interval\">confidence\nintervals</a>.\nSo I not only get the inferences that I am interested in now, I also get an\nestimate, a confidence interval that captures with a certain probability the\ntwo value. </p>\n<p>Okay and it works until a chain length of thirty so already quite large chain\nlengths. Then the confidence intervals become larger because I get less and\nless samples accepted. I use 10 million attempts here but actually similar\nmethods are very useful even for a few hundred attempts. This is a picture\naround that time in Los Alamos where they performed the simulation manually by\ndrawing with this drawing device, basically, on a sheet of paper, and whenever\nthey cross from one type of material to another type of material, they would\nchange the wheels and roll a new random number and then move it and turn it in\nrandom directions and they do it a few hundred times and get a global picture\non how the neutrons are scattered in this matter. Because everything was named\nMANIAC, ENIAC, etc., and this idea was from Enrico Fermi they called this\ndevice a <a href=\"https://en.wikipedia.org/wiki/FERMIAC\">FERMIAC</a>.</p>\n<p>But anyway, another thing we could do is solve the counting problem. So we can\nestimate the acceptance rate. We have the number of attempts that we made and\nthe number of attempts that were accepted that happened to be self-avoiding.\nIt gives us the acceptance rate and we can estimate the number of\nself-avoiding walks simply as a product of this acceptance rate with a total\nnumber of 2D walks that are not necessarily self-avoiding. That is easy to\ncalculate as well because the first step was into right direction and we had\nthree possibilities in each step, so we could just have a formula for that one\nand this gives an estimate of the number of self-avoiding walks. \nSo here is a plot of that and in <a href=\"http://arxiv.org/abs/cond-mat/0409355\">this paper I found from\n2005</a> where people have exhaustively\ncomputed that with clever enumeration methods up to a length of 59, but beyond\nthat the exact number is unknown. But it happens to agree very well with these\nknown ground truths.</p>\n<p><strong>Attendee 1</strong>: Quick question. Is that what even with your early rejection\nbusiness?</p>\n<p><strong>Speaker</strong>: Yes, that's the one thing.</p>\n<p><strong>Attendee 1</strong>: Okay.</p>\n<p><strong>Speaker</strong>: It's exactly with the rejection sample here. So the acceptance\nrate is from the rejection sample here.  <span class=\"math\">\\(P\\)</span> is estimated from the rejection\nsample.</p>\n<p><strong>Attendee 1</strong>: What is the acceptance rate when you get to 30?</p>\n<p><strong>Speaker</strong>: Again, next slide here.</p>\n<p><strong>Speaker</strong>: I am impressed. One second. Let us first enjoy what we have\nachieved, let us take a look at Monte Carlo, enjoy some sunshine. So the name\nMonte Carlo, I mean, what first comes to mind is all the casinos, right? And\nthe gambling and that is indeed one of the origins of the name. But the\nparticular reason and the person who suggested this was Nicholas Metropolis,\nthe colleague of Stanislaw Ulam, was very much amused about the stories Stan\nwas telling about his uncle, Michael Ulam, who was a wealthy businessman in\nhis hometown in Lviv. And then switched to the finance industry and spent the\nrest of his life gambling away his fortune in Monte Carlo and Nicholas\nMetropolis found this so amusing that he insisted the method being called,\nMonte Carlo method. So that is the real reason why it is called Monte Carlo\nmethod.</p>\n<p>And it is not all sunny and that is where we come to this slide, which is the\nacceptance rate as a function of the chain lengths. And you see the simpler\nrejection sample for long enough chains. I mean, intuitively you can\nunderstand when you grow the chain very long, the probability to cross onto\nyourself when you walk randomly becomes higher and higher. The acceptance rate\nis very, very small. So I think for a million samples I had only like 15 walks\naccepted at the lengths of 30. And that's why the confidence intervals have\nbeen blowing up because the estimates become unreliable. </p>\n<p>The <a href=\"http://www.nowozin.net/sebastian/blog/history-of-monte-carlo-methods-part-2.html\">next part</a> is available.</p>\n<script type=\"text/javascript\">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {\n    var align = \"center\",\n        indent = \"0em\",\n        linebreak = \"false\";\n\n    if (false) {\n        align = (screen.width < 768) ? \"left\" : align;\n        indent = (screen.width < 768) ? \"0em\" : indent;\n        linebreak = (screen.width < 768) ? 'true' : linebreak;\n    }\n\n    var mathjaxscript = document.createElement('script');\n    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';\n    mathjaxscript.type = 'text/javascript';\n    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';\n\n    var configscript = document.createElement('script');\n    configscript.type = 'text/x-mathjax-config';\n    configscript[(window.opera ? \"innerHTML\" : \"text\")] =\n        \"MathJax.Hub.Config({\" +\n        \"    config: ['MMLorHTML.js'],\" +\n        \"    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } },\" +\n        \"    jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" +\n        \"    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" +\n        \"    displayAlign: '\"+ align +\"',\" +\n        \"    displayIndent: '\"+ indent +\"',\" +\n        \"    showMathMenu: true,\" +\n        \"    messageStyle: 'normal',\" +\n        \"    tex2jax: { \" +\n        \"        inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" +\n        \"        displayMath: [ ['$$','$$'] ],\" +\n        \"        processEscapes: true,\" +\n        \"        preview: 'TeX',\" +\n        \"    }, \" +\n        \"    'HTML-CSS': { \" +\n        \"        availableFonts: ['STIX', 'TeX'],\" +\n        \"        preferredFont: 'STIX',\" +\n        \"        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" +\n        \"        linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" +\n        \"    }, \" +\n        \"}); \" +\n        \"if ('default' !== 'default') {\" +\n            \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" +\n                \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" +\n                \"VARIANT['normal'].fonts.unshift('MathJax_default');\" +\n                \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" +\n                \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" +\n                \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" +\n            \"});\" +\n            \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" +\n                \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" +\n                \"VARIANT['normal'].fonts.unshift('MathJax_default');\" +\n                \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" +\n                \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" +\n                \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" +\n            \"});\" +\n        \"}\";\n\n    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);\n    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);\n}\n</script>",
  "category": ""
}