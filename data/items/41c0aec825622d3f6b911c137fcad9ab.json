{
  "title": "Using pandas and pymapd for ETL into OmniSci",
  "description": "<p>I’ve got <a href=\"https://pydata.org/nyc2018/schedule/presentation/41/\">PyData NYC 2018</a> in two days and rather finishing up my talk, I just realized that my source data has a silent corruption due to non-standard timestamps. Here’s how I fixed this using pandas and then uploaded the data to <a href=\"https://omnisci.com\">OmniSci</a>.</p>",
  "pubDate": "Tue, 16 Oct 2018 00:00:00 +0000",
  "link": "http://randyzwitch.com/omnisci-pymapd-etl/",
  "guid": "http://randyzwitch.com/omnisci-pymapd-etl/",
  "content": "<p>I’ve got <a href=\"https://pydata.org/nyc2018/schedule/presentation/41/\">PyData NYC 2018</a> in two days and rather finishing up my talk, I just realized that my source data has a silent corruption due to non-standard timestamps. Here’s how I fixed this using pandas and then uploaded the data to <a href=\"https://omnisci.com\">OmniSci</a>.</p>\n\n<h2 id=\"computers-are-dumb-make-things-easier-for-them\">Computers Are Dumb, MAKE THINGS EASIER FOR THEM!</h2>\n\n<p>Literally every data tool in the world can read the <a href=\"https://www.iso.org/iso-8601-date-and-time-format.html\">ISO-8601 timestamp format</a>. Conversely, not every tool in the world can read Excel or whatever horrible other tool people use to generate the CSV files seen in the wild. While I should’ve been more diligent checking my data ingestion, I didn’t until I created a wonky report…</p>\n\n<p>Let’s take a look at the format that tripped me up:</p>\n\n<p><img src=\"/assets/img/excelformatdates.png\" alt=\"Excel data format sucks\" /></p>\n\n<p><code class=\"language-plaintext highlighter-rouge\">Month/Day/Year Hour:Minute:Second AM/PM</code> feels very much like an Excel date format that you get when Excel is used as a display medium. Unfortunately, when you write CSV files like this, the next tool to read them has to understand 1) that these columns are <code class=\"language-plaintext highlighter-rouge\">timestamps</code> and 2) if the user doesn’t specify the format, has to guess the format.</p>\n\n<p>In my case, I didn’t do descriptive statistics on my timestamp columns and had a silent truncation(!) of the <code class=\"language-plaintext highlighter-rouge\">AM/PM</code> portion of the data. So instead of having 24 hours in the day, the parser read the data as follows (the <code class=\"language-plaintext highlighter-rouge\">#AM</code> and <code class=\"language-plaintext highlighter-rouge\">#PM</code> are my comments for clarity):</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>datetime_beginning_utc\n2001-01-01 01:00:00 #AM\n2001-01-01 01:00:00 #PM\n2001-01-01 02:00:00 #AM\n2001-01-01 02:00:00 #PM\n2001-01-01 03:00:00 #AM\n2001-01-01 03:00:00 #PM\n2001-01-01 04:00:00 #AM\n2001-01-01 04:00:00 #PM\n2001-01-01 05:00:00 #AM\n2001-01-01 05:00:00 #PM\n2001-01-01 06:00:00 #AM\n2001-01-01 06:00:00 #PM\n2001-01-01 07:00:00 #AM\n2001-01-01 07:00:00 #PM\n2001-01-01 08:00:00 #AM\n2001-01-01 08:00:00 #PM\n2001-01-01 09:00:00 #AM\n2001-01-01 09:00:00 #PM\n2001-01-01 10:00:00 #AM\n2001-01-01 10:00:00 #PM\n2001-01-01 11:00:00 #AM\n2001-01-01 11:00:00 #PM\n2001-01-01 12:00:00 #AM\n2001-01-01 12:00:00 #PM\n</code></pre></div></div>\n\n<p>So while the data looks like it was imported correctly (because, it is a <code class=\"language-plaintext highlighter-rouge\">timestamp</code>), it wasn’t until I realized that hours 13-23 were missing from my data that I realized I had an error.</p>\n\n<h2 id=\"pandas-to-the-rescue\">Pandas To The Rescue!</h2>\n\n<p>Fixing this issue is as straight-forward as reading the CSV into python using pandas and specifying the date format:</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-python\" data-lang=\"python\"><span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"n\">pd</span>\n<span class=\"kn\">import</span> <span class=\"nn\">datetime</span>\n<span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"p\">.</span><span class=\"n\">read_csv</span><span class=\"p\">(</span><span class=\"s\">\"/mnt/storage1TB/hrl_load_metered/hrl_load_metered.csv\"</span><span class=\"p\">,</span>\n                 <span class=\"n\">parse_dates</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">],</span>\n                 <span class=\"n\">date_parser</span><span class=\"o\">=</span> <span class=\"k\">lambda</span> <span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">datetime</span><span class=\"p\">.</span><span class=\"n\">datetime</span><span class=\"p\">.</span><span class=\"n\">strptime</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"s\">\"%m/%d/%Y %I:%M:%S %p\"</span><span class=\"p\">))</span></code></pre></figure>\n\n<p><img src=\"/assets/img/pandasdatetimefix.png\" alt=\"Yay pandas!\" /></p>\n\n<p>We can see from the code above that pandas has taken our directive about the format and it appears the data have been parsed correctly. A good secondary check here is that the difference in timestamps is <code class=\"language-plaintext highlighter-rouge\">-5</code>, which is the offset of the East Coast of the United States relative to UTC.</p>\n\n<h2 id=\"uploading-to-omnisci-directly-from-pandas\">Uploading to OmniSci Directly From Pandas</h2>\n\n<p>Since my PyData talk is going to be using OmniSci, I need to upload this corrected data or rebuild all my work (I’ll opt for fixing my source). Luckily, the <a href=\"https://pymapd.readthedocs.io/en/latest/\">pymapd</a> package provides tight integration to an OmniSci database, providing a means of uploading the data directly from a pandas dataframe:</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-python\" data-lang=\"python\"><span class=\"kn\">import</span> <span class=\"nn\">pymapd</span>\n\n<span class=\"c1\">#connect to database\n</span><span class=\"n\">conn</span> <span class=\"o\">=</span> <span class=\"n\">pymapd</span><span class=\"p\">.</span><span class=\"n\">connect</span><span class=\"p\">(</span><span class=\"n\">host</span><span class=\"o\">=</span><span class=\"s\">\"localhost\"</span><span class=\"p\">,</span> <span class=\"n\">port</span><span class=\"o\">=</span><span class=\"mi\">9091</span><span class=\"p\">,</span> <span class=\"n\">user</span><span class=\"o\">=</span><span class=\"s\">\"mapd\"</span><span class=\"p\">,</span> <span class=\"n\">password</span><span class=\"o\">=</span><span class=\"s\">\"HyperInteractive\"</span><span class=\"p\">,</span> <span class=\"n\">dbname</span><span class=\"o\">=</span><span class=\"s\">\"mapd\"</span><span class=\"p\">)</span>\n\n<span class=\"c1\">#truncate table so that table definition can be reused\n</span><span class=\"n\">conn</span><span class=\"p\">.</span><span class=\"n\">execute</span><span class=\"p\">(</span><span class=\"s\">\"truncate table hrl_load_metered\"</span><span class=\"p\">)</span>\n\n<span class=\"c1\">#re-load data into table\n#with none of the optional arguments, pymapd infers that this is an insert operation, since table name exists\n</span><span class=\"n\">conn</span><span class=\"p\">.</span><span class=\"n\">load_table_columnar</span><span class=\"p\">(</span><span class=\"s\">\"hrl_load_metered\"</span><span class=\"p\">,</span> <span class=\"n\">df</span><span class=\"p\">)</span></code></pre></figure>\n\n<p>I have a pre-existing table <code class=\"language-plaintext highlighter-rouge\">hrl_load_metered</code> on the database, so I can truncate the table to remove its (incorrect) data but keep the table structure. Then I can use <code class=\"language-plaintext highlighter-rouge\">load_table_columnar</code> to insert the cleaned up data into my table and now my data is correct.</p>\n\n<h2 id=\"computers-may-be-dumb-but-humans-are-lazy\">Computers May Be Dumb, But Humans Are Lazy</h2>\n\n<p>At the beginning, I joked that computers are dumb. Computers are just tools that do exactly what a human programs them to do, and really, it was my laziness that caused this data error. Luckily, I did catch this before my talk and the fix is pretty easy.</p>\n\n<p>I’d like to say I’m going to remember to check my data going forward, but in reality, I’m just documenting this here for the next time I make the same, lazy mistake.</p>"
}