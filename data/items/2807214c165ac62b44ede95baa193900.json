{
  "title": "On the practical usefulness of the Hardware Efficient Ansatz. (arXiv:2211.01477v1 [quant-ph])",
  "link": "http://arxiv.org/abs/2211.01477",
  "description": "<p>Variational Quantum Algorithms (VQAs) and Quantum Machine Learning (QML)\nmodels train a parametrized quantum circuit to solve a given learning task. The\nsuccess of these algorithms greatly hinges on appropriately choosing an ansatz\nfor the quantum circuit. Perhaps one of the most famous ansatzes is the\none-dimensional layered Hardware Efficient Ansatz (HEA), which seeks to\nminimize the effect of hardware noise by using native gates and connectives.\nThe use of this HEA has generated a certain ambivalence arising from the fact\nthat while it suffers from barren plateaus at long depths, it can also avoid\nthem at shallow ones. In this work, we attempt to determine whether one should,\nor should not, use a HEA. We rigorously identify scenarios where shallow HEAs\nshould likely be avoided (e.g., VQA or QML tasks with data satisfying a volume\nlaw of entanglement). More importantly, we identify a Goldilocks scenario where\nshallow HEAs could achieve a quantum speedup: QML tasks with data satisfying an\narea law of entanglement. We provide examples for such scenario (such as\nGaussian diagonal ensemble random Hamiltonian discrimination), and we show that\nin these cases a shallow HEA is always trainable and that there exists an\nanti-concentration of loss function values. Our work highlights the crucial\nrole that input states play in the trainability of a parametrized quantum\ncircuit, a phenomenon that is verified in our numerics.\n</p>",
  "dc:creator": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Leone_L/0/1/0/all/0/1\">Lorenzo Leone</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Oliviero_S/0/1/0/all/0/1\">Salvatore F.E. Oliviero</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Cincio_L/0/1/0/all/0/1\">Lukasz Cincio</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Cerezo_M/0/1/0/all/0/1\">M. Cerezo</a>"
}