{
  "title": "Streaming Dataframes",
  "link": "",
  "updated": "2017-10-16T00:00:00+00:00",
  "id": "https://mrocklin.github.io/blog/work/2017/10/16/streaming-dataframes-1",
  "content": "<p><em>This work is supported by <a href=\"http://anaconda.com\">Anaconda Inc</a> and the Data\nDriven Discovery Initiative from the <a href=\"https://www.moore.org/\">Moore Foundation</a></em></p>\n\n<p><em>This post is about experimental software.  This is not ready for public use.\nAll code examples and API in this post are subject to change without warning.</em></p>\n\n<p><a href=\"https://mrocklin.github.io/blog/images/streaming-dataframes-plot.gif\">\n  <img src=\"https://mrocklin.github.io/blog/images/streaming-dataframes-plot.gif\" align=\"right\" width=\"70%\" /></a></p>\n\n<h2 id=\"summary\">Summary</h2>\n\n<p>This post describes a prototype project to handle continuous data sources of\ntabular data using Pandas and Streamz.</p>\n\n<h2 id=\"introduction\">Introduction</h2>\n\n<p>Some data never stops.  It arrives continuously in a constant, never-ending\nstream.  This happens in financial time series, web server logs, scientific\ninstruments, IoT telemetry, and more.  Algorithms to handle this data are\nslightly different from what you find in libraries like NumPy and Pandas, which\nassume that they know all of the data up-front.  It’s still possible to use\nNumPy and Pandas, but you need to combine them with some cleverness and keep\nenough intermediate data around to compute marginal updates when new data comes\nin.</p>\n\n<h2 id=\"example-streaming-mean\">Example: Streaming Mean</h2>\n\n<p>For example, imagine that we have a continuous stream of CSV files arriving\nand we want to print out the mean of our data over time.  Whenever a new CSV\nfile arrives we need to recompute the mean of the entire dataset.  If we’re\nclever we keep around enough state so that we can compute this mean without\nlooking back over the rest of our historical data.  We can accomplish this by keeping\nrunning totals and running counts as follows:</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">total</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>\n<span class=\"n\">count</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>\n\n<span class=\"k\">for</span> <span class=\"n\">filename</span> <span class=\"ow\">in</span> <span class=\"n\">filenames</span><span class=\"p\">:</span>  <span class=\"c1\"># filenames is an infinite iterator\n</span>    <span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"p\">.</span><span class=\"n\">read_csv</span><span class=\"p\">(</span><span class=\"n\">filename</span><span class=\"p\">)</span>\n    <span class=\"n\">total</span> <span class=\"o\">=</span> <span class=\"n\">total</span> <span class=\"o\">+</span> <span class=\"n\">df</span><span class=\"p\">.</span><span class=\"nb\">sum</span><span class=\"p\">()</span>\n    <span class=\"n\">count</span> <span class=\"o\">=</span> <span class=\"n\">count</span> <span class=\"o\">+</span> <span class=\"n\">df</span><span class=\"p\">.</span><span class=\"n\">count</span><span class=\"p\">()</span>\n    <span class=\"n\">mean</span> <span class=\"o\">=</span> <span class=\"n\">total</span> <span class=\"o\">/</span> <span class=\"n\">count</span>\n    <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">mean</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p>Now as we add new files to our <code class=\"language-plaintext highlighter-rouge\">filenames</code> iterator our code prints out new\nmeans that are updated over time.  We don’t have a single mean result, we have\ncontinuous stream of mean results that are each valid for the data up to that\npoint.  Our output data is an infinite stream, just like our input data.</p>\n\n<p>When our computations are linear and straightforward like this a for loop\nsuffices.  However when our computations have several streams branching out or\nconverging, possibly with rate limiting or buffering between them, this\nfor-loop approach can grow complex and difficult to manage.</p>\n\n<h2 id=\"streamz\">Streamz</h2>\n\n<p>A few months ago I pushed a small library called\n<a href=\"http://streamz.readthedocs.io/en/latest/\">streamz</a>, which handled control flow\nfor pipelines, including linear map operations, operations that accumulated\nstate, branching, joining, as well as back pressure, flow control, feedback,\nand so on.  Streamz was designed to handle all of the movement of data and\nsignaling of computation at the right time.  This library was quietly used by a\ncouple of groups and now feels fairly clean and useful.</p>\n\n<p>Streamz was designed to handle the <em>control flow</em> of such a system, but did\nnothing to help you with streaming algorithms.  Over the past week I’ve been\nbuilding a dataframe module on top of streamz to help with common streaming\ntabular data situations.  This module uses Pandas and implements a subset of\nthe Pandas API, so hopefully it will be easy to use for programmers with\nexisting Python knowledge.</p>\n\n<h2 id=\"example-streaming-mean-1\">Example: Streaming Mean</h2>\n\n<p>Our example above could be written as follows with streamz</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">source</span> <span class=\"o\">=</span> <span class=\"n\">Stream</span><span class=\"p\">.</span><span class=\"n\">filenames</span><span class=\"p\">(</span><span class=\"s\">'path/to/dir/*.csv'</span><span class=\"p\">)</span>  <span class=\"c1\"># stream of filenames\n</span><span class=\"n\">sdf</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">source</span><span class=\"p\">.</span><span class=\"nb\">map</span><span class=\"p\">(</span><span class=\"n\">pd</span><span class=\"p\">.</span><span class=\"n\">read_csv</span><span class=\"p\">)</span>                  <span class=\"c1\"># stream of Pandas dataframes\n</span>             <span class=\"p\">.</span><span class=\"n\">to_dataframe</span><span class=\"p\">(</span><span class=\"n\">example</span><span class=\"o\">=</span><span class=\"p\">...))</span>        <span class=\"c1\"># logical streaming dataframe\n</span>\n<span class=\"n\">sdf</span><span class=\"p\">.</span><span class=\"n\">mean</span><span class=\"p\">().</span><span class=\"n\">stream</span><span class=\"p\">.</span><span class=\"n\">sink</span><span class=\"p\">(</span><span class=\"k\">print</span><span class=\"p\">)</span>                   <span class=\"c1\"># printed stream of mean values\n</span></code></pre></div></div>\n\n<p>This example is no more clear than the for-loop version.  On its own this is\nprobably a <em>worse</em> solution than what we had before, just because it involves\nnew technology.  However it starts to become useful in two situations:</p>\n\n<ol>\n  <li>\n    <p>You want to do more complex streaming algorithms</p>\n\n    <div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">sdf</span> <span class=\"o\">=</span> <span class=\"n\">sdf</span><span class=\"p\">[</span><span class=\"n\">sdf</span><span class=\"p\">.</span><span class=\"n\">name</span> <span class=\"o\">==</span> <span class=\"s\">'Alice'</span><span class=\"p\">]</span>\n<span class=\"n\">sdf</span><span class=\"p\">.</span><span class=\"n\">x</span><span class=\"p\">.</span><span class=\"n\">groupby</span><span class=\"p\">(</span><span class=\"n\">sdf</span><span class=\"p\">.</span><span class=\"n\">y</span><span class=\"p\">).</span><span class=\"n\">mean</span><span class=\"p\">().</span><span class=\"n\">sink</span><span class=\"p\">(</span><span class=\"k\">print</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># or\n</span>\n<span class=\"n\">sdf</span><span class=\"p\">.</span><span class=\"n\">x</span><span class=\"p\">.</span><span class=\"n\">rolling</span><span class=\"p\">(</span><span class=\"s\">'300ms'</span><span class=\"p\">).</span><span class=\"n\">mean</span><span class=\"p\">()</span>\n</code></pre></div>    </div>\n\n    <p>It would require more cleverness to build these algorithms with a for loop\nas above.</p>\n  </li>\n  <li>\n    <p>You want to do multiple operations, deal with flow control, etc..</p>\n\n    <div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">sdf</span><span class=\"p\">.</span><span class=\"n\">mean</span><span class=\"p\">().</span><span class=\"n\">sink</span><span class=\"p\">(</span><span class=\"k\">print</span><span class=\"p\">)</span>\n<span class=\"n\">sdf</span><span class=\"p\">.</span><span class=\"n\">x</span><span class=\"p\">.</span><span class=\"nb\">sum</span><span class=\"p\">().</span><span class=\"n\">rate_limit</span><span class=\"p\">(</span><span class=\"mf\">0.500</span><span class=\"p\">).</span><span class=\"n\">sink</span><span class=\"p\">(</span><span class=\"n\">write_to_database</span><span class=\"p\">)</span>\n<span class=\"p\">...</span>\n</code></pre></div>    </div>\n\n    <p>Consistently branching off computations, routing data correctly, and\nhandling time can all be challenging to accomplish consistently.</p>\n  </li>\n</ol>\n\n<h2 id=\"jupyter-integration-and-streaming-outputs\">Jupyter Integration and Streaming Outputs</h2>\n\n<p>During development we’ve found it very useful to have live updating outputs in\nJupyter.</p>\n\n<p>Usually when we evaluate code in Jupyter we have static inputs and static\noutputs:</p>\n\n<p><img src=\"https://mrocklin.github.io/blog/images/jupyter-output-static.png\" width=\"40%\" /></p>\n\n<p>However now both our inputs and our outputs are live:</p>\n\n<p><img src=\"https://mrocklin.github.io/blog/images/jupyter-output-streaming.gif\" width=\"70%\" /></p>\n\n<p>We accomplish this using a combination of\n<a href=\"https://ipywidgets.readthedocs.io/en/stable/\">ipywidgets</a> and <a href=\"https://bokeh.pydata.org/en/latest/\">Bokeh\nplots</a> both of which provide nice hooks to\nchange previous Jupyter outputs and work well with the Tornado IOLoop (streamz,\nBokeh, Jupyter, and Dask all use Tornado for concurrency).  We’re able to build\nnicely responsive feedback whenever things change.</p>\n\n<p>In the following example we build our CSV to dataframe pipeline that updates\nwhenever new files appear in a directory.  Whenever we drag files to the data\ndirectory on the left we see that all of our outputs update on the right.</p>\n\n<p><a href=\"https://mrocklin.github.io/blog/images/streaming-dataframes-files.gif\">\n  <img src=\"https://mrocklin.github.io/blog/images/streaming-dataframes-files.gif\" width=\"100%\" /></a></p>\n\n<h2 id=\"what-is-supported\">What is supported?</h2>\n\n<p>This project is very young and could use some help.  There are plenty of holes\nin the API.  That being said, the following works well:</p>\n\n<p>Elementwise operations:</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">sdf</span><span class=\"p\">[</span><span class=\"s\">'z'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">sdf</span><span class=\"p\">.</span><span class=\"n\">x</span> <span class=\"o\">+</span> <span class=\"n\">sdf</span><span class=\"p\">.</span><span class=\"n\">y</span>\n<span class=\"n\">sdf</span> <span class=\"o\">=</span> <span class=\"n\">sdf</span><span class=\"p\">[</span><span class=\"n\">sdf</span><span class=\"p\">.</span><span class=\"n\">z</span> <span class=\"o\">&gt;</span> <span class=\"mi\">2</span><span class=\"p\">]</span>\n</code></pre></div></div>\n\n<p>Simple reductions:</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">sdf</span><span class=\"p\">.</span><span class=\"nb\">sum</span><span class=\"p\">()</span>\n<span class=\"n\">sdf</span><span class=\"p\">.</span><span class=\"n\">x</span><span class=\"p\">.</span><span class=\"n\">mean</span><span class=\"p\">()</span>\n</code></pre></div></div>\n\n<p>Groupby reductions:</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">sdf</span><span class=\"p\">.</span><span class=\"n\">groupby</span><span class=\"p\">(</span><span class=\"n\">sdf</span><span class=\"p\">.</span><span class=\"n\">x</span><span class=\"p\">).</span><span class=\"n\">y</span><span class=\"p\">.</span><span class=\"n\">mean</span><span class=\"p\">()</span>\n</code></pre></div></div>\n\n<p>Rolling reductions by number of rows or time window</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">sdf</span><span class=\"p\">.</span><span class=\"n\">rolling</span><span class=\"p\">(</span><span class=\"mi\">20</span><span class=\"p\">).</span><span class=\"n\">x</span><span class=\"p\">.</span><span class=\"n\">mean</span><span class=\"p\">()</span>\n<span class=\"n\">sdf</span><span class=\"p\">.</span><span class=\"n\">rolling</span><span class=\"p\">(</span><span class=\"s\">'100ms'</span><span class=\"p\">).</span><span class=\"n\">x</span><span class=\"p\">.</span><span class=\"n\">quantile</span><span class=\"p\">(</span><span class=\"mf\">0.9</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p>Real time plotting with <a href=\"https://bokeh.pydata.org\">Bokeh</a> (one of my favorite features)</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">sdf</span><span class=\"p\">.</span><span class=\"n\">plot</span><span class=\"p\">()</span>\n</code></pre></div></div>\n\n<p><a href=\"https://mrocklin.github.io/blog/images/streaming-dataframes-plot.gif\">\n  <img src=\"https://mrocklin.github.io/blog/images/streaming-dataframes-plot.gif\" width=\"100%\" /></a></p>\n\n<h2 id=\"whats-missing\">What’s missing?</h2>\n\n<ol>\n  <li><strong>Parallel computing:</strong>  The core streamz library has an optional\n<a href=\"https;//dask.pydata.org/\">Dask</a> backend for parallel computing.  I haven’t\nyet made any attempt to attach this to the dataframe implementation.</li>\n  <li><strong>Data ingestion</strong> from common streaming sources like Kafka.  We’re in the\nprocess now of building asynchronous-aware wrappers around Kafka Python\nclient libraries, so this is likely to come soon.</li>\n  <li><strong>Out-of-order data access:</strong> soon after parallel data ingestion (like\nreading from multiple Kafka partitions at once) we’ll need to figure out\nhow to handle out-of-order data access.  This is doable, but will take some\neffort.  This is where more mature libraries like\n<a href=\"https://flink.apache.org/\">Flink</a> are quite strong.</li>\n  <li><strong>Performance:</strong> Some of the operations above (particularly rolling\noperations) do involve non-trivial copying, especially with larger windows.\nWe’re relying heavily on the Pandas library which wasn’t designed with\nrapidly changing data in mind.  Hopefully future iterations of Pandas\n(Arrow/libpandas/Pandas 2.0?) will make this more efficient.</li>\n  <li><strong>Filled out API:</strong>  Many common operations (like variance) haven’t yet\nbeen implemented.  Some of this is due to laziness and some is due to\nwanting to find the right algorithm.</li>\n  <li><strong>Robust plotting:</strong> Currently this works well for numeric data with a\ntimeseries index but not so well for other data.</li>\n</ol>\n\n<p>But most importantly this needs <strong>use</strong> by people with real problems to help us\nunderstand what here is valuable and what is unpleasant.</p>\n\n<p>Help would be welcome with any of this.</p>\n\n<p>You can install this from github</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>pip install git+https://github.com/mrocklin/streamz.git\n</code></pre></div></div>\n\n<p>Documentation and code are here:</p>\n\n<ul>\n  <li><a href=\"https://streamz.readthedocs.io/en/latest/\">streamz.readthedocs.io</a></li>\n  <li><a href=\"https://github.com/mrocklin/streamz\">github.com/mrocklin/streamz</a></li>\n</ul>\n\n<h2 id=\"current-work\">Current work</h2>\n\n<p>Current and upcoming work is focused on data ingestion from Kafka and\nparallelizing with Dask.</p>"
}