{
  "title": "An Introduction to BigBird",
  "link": "https://www.analyticsvidhya.com/blog/2022/11/an-introduction-to-bigbird/",
  "comments": "https://www.analyticsvidhya.com/blog/2022/11/an-introduction-to-bigbird/#respond",
  "dc:creator": "Drishti Sharma",
  "pubDate": "Tue, 01 Nov 2022 20:06:14 +0000",
  "category": [
    "Datasets",
    "Intermediate",
    "NLP",
    "Python",
    "BERT",
    "BERT model",
    "bigbird",
    "blogathon"
  ],
  "guid": "https://www.analyticsvidhya.com/?p=98903",
  "description": "<p>Â This article was published as a part of the Data Science Blogathon. Source: Canva&#124;Arxiv Introduction In 2018 GoogleAI researchers developed Bidirectional Encoder Representations from Transformers (BERT) for various NLP tasks. However, one of the key limitations of this technique was the quadratic dependency, due to which the BERT-like model can handle sequences of 512 tokens [&#8230;]</p>\n<p>The post <a rel=\"nofollow\" href=\"https://www.analyticsvidhya.com/blog/2022/11/an-introduction-to-bigbird/\">An Introduction to BigBird</a> appeared first on <a rel=\"nofollow\" href=\"https://www.analyticsvidhya.com\">Analytics Vidhya</a>.</p>\n",
  "wfw:commentRss": "https://www.analyticsvidhya.com/blog/2022/11/an-introduction-to-bigbird/feed/",
  "slash:comments": 0,
  "post-id": 98903
}