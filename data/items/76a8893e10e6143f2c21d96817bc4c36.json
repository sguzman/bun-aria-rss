{
  "title": "Deep learning for hackers with MXnet (1) GPU installation and MNIST",
  "link": "https://no2147483647.wordpress.com/2015/12/07/deep-learning-for-hackers-with-mxnet-1/",
  "comments": "https://no2147483647.wordpress.com/2015/12/07/deep-learning-for-hackers-with-mxnet-1/#comments",
  "dc:creator": "phunterlau",
  "pubDate": "Mon, 07 Dec 2015 06:32:41 +0000",
  "category": [
    "Machine Learning",
    "deep learning",
    "DMLC",
    "mxnet"
  ],
  "guid": "http://no2147483647.wordpress.com/?p=130",
  "description": "&#160; I am going to have a series of blogs about implementing deep learning models and algorithms with MXnet. The topic list covers MNIST, LSTM/RNN, image recognition, neural artstyle image generation etc. Everything here is about programing deep learning (a.k.a. deep learning for hackers), instead of theoritical tutorials, so basic knowledge of machine learning and [&#8230;]",
  "content:encoded": "<p>&nbsp;</p>\n<p>I am going to have a series of blogs about implementing deep learning models and algorithms with <a href=\"https://github.com/dmlc/mxnet\">MXnet</a>. The topic list covers MNIST, LSTM/RNN, image recognition, neural artstyle image generation etc. Everything here is about programing deep learning (a.k.a. deep learning for hackers), instead of theoritical tutorials, so basic knowledge of machine learning and neural network is a prerequisite. I assume readers know how neural network works and what <a href=\"https://en.wikipedia.org/wiki/Backpropagation\"><code>backpropagation</code></a> is. If difficulties, please review Andew Ng&#8217;s coursera class Week 4: <a href=\"https://www.coursera.org/learn/machine-learning\">https://www.coursera.org/learn/machine-learning</a>.</p>\n<p>Surely, this blog doesn&#8217;t cover everything about deep learning. It is very important to understand the fundamental deep learning knowledge. For readers who want to know in-depth theoritical deep learning knowledge, please read some good tutorials, for example, <a href=\"http://deeplearning.net/reading-list/tutorials/\">http://deeplearning.net/reading-list/tutorials/</a>.</p>\n<h2>MXnet: lightweight, distributed, portable deep learning toolkit</h2>\n<p><a href=\"https://github.com/dmlc/mxnet\">MXnet</a> is a deep learning toolkit written in C++11, and it comes with <a href=\"http://dmlc.ml/\">DMLC</a> (Distributed (Deep) Machine Learning Common<br />\n<a href=\"http://dmlc.ml/\">http://dmlc.ml/</a>). You might have known MXnet&#8217;s famous DMLC-sibling <code>xgboost</code> <a href=\"https://github.com/dmlc/xgboost\">https://github.com/dmlc/xgboost</a>, a parallel gradient boosting decision tree which dominates most <a href=\"https://www.kaggle.com/competitions\">Kaggle competitions</a> and is generally used in many projects.</p>\n<p>MXnet is very lightweight, dynamic, portable, easy to distribute, memory efficient, and one of the coolest features is, it can run on portable devices (e.g. <a href=\"http://dmlc.ml/mxnet/2015/11/10/deep-learning-in-a-single-file-for-smart-device.html\">image recognition on your Android phone</a> ) MXnet also has clear design plus clean C++11 code, let go star and fork it on github: <a href=\"https://github.com/dmlc/mxnet\">https://github.com/dmlc/mxnet</a></p>\n<p>Recently MXnet has received much attention in multiple conferences and blogs for its unique features of speed and efficient memory usage. Professionals are comparing MXnet with <a href=\"http://caffe.berkeleyvision.org/\">Caffe</a>, <a href=\"https://github.com/torch/torch7\">Torch7</a> and Google&#8217;s <a href=\"https://www.tensorflow.org/\">TensorFlow</a>. These benchmarks show that MXnet is a new rising star. Go check this recent tweet from Quora&#8217;s Xavier Amatriain: <a href=\"https://twitter.com/xamat/status/665222179668168704\">https://twitter.com/xamat/status/665222179668168704</a></p>\n<h2>Install MXnet with GPU</h2>\n<p>MXnet natively supports multiple platforms (Linux, Mac OS X and Windows) and multiple languages (C++, Java, Python, R and Julia, plus a recent support on javascript, no joking <a href=\"https://github.com/dmlc/mxnet.js\">MXnet.js</a>). In this tutorial, we use Ubuntu 14.04 LTS and Python for example. Just a reminder that, since we use CUDA for GPU computing and CUDA hasn&#8217;t yet support ubuntu 15.10 or newer (with gcc 5.2), let&#8217;s stay with 14.04 LTS, or, at latest 15.04.</p>\n<p>The installation can be done on physical machines with nVidia CUDA GPUs or cloud instance, for example <a href=\"http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using_cluster_computing.html\">AWS GPU instance</a> <code>g2.2xlarge</code> or <code>g2.8xlarge</code>. The following steps mostly come from the official installation guide <a href=\"http://mxnt.ml/en/latest/build.html#building-on-linux\">http://mxnt.ml/en/latest/build.html#building-on-linux</a>, with some CUDA modification.</p>\n<p>Please note: for installing CUDA on AWS from scratch, some additional steps are needed for updating <code>linux-image-extra-virtual</code> and disabling <code>nouveau</code>, for more details, please refer to Caffe&#8217;s guide: <a href=\"https://github.com/BVLC/caffe/wiki/Install-Caffe-on-EC2-from-scratch-(Ubuntu,-CUDA-7,-cuDNN)\">https://github.com/BVLC/caffe/wiki/Install-Caffe-on-EC2-from-scratch-(Ubuntu,-CUDA-7,-cuDNN)</a></p>\n<h3>Install dependency</h3>\n<p>MXnet only needs minimal dependency: gcc, BLAS, and OpenCV (optional), that is it. One can install <code>git</code> just in case it hasn&#8217;t been installed.</p>\n<pre><code>sudo apt-get update\nsudo apt-get install -y build-essential git libblas-dev libopencv-dev\n</code></pre>\n<h3>Clone mxnet</h3>\n<pre><code>git clone --recursive https://github.com/dmlc/mxnet\n</code></pre>\n<p>Just another reminder that <code>--recursive</code> is needed: MXnet depends on DMLC common packages <code>mshadow</code>, <code>ps-lite</code> and <code>dmlc-core</code>, where <code>--recursive</code> can clone all necessary ones. Please don&#8217;t compile now, and we need to install CUDA firstly.</p>\n<h3>Install CUDA</h3>\n<p>CUDA installation here is universal for other deep learning packages. Please go to <a href=\"https://developer.nvidia.com/cuda-downloads\">https://developer.nvidia.com/cuda-downloads</a> for selecting the CUDA installation for the corresponding system. For example, installing CUDA for Ubuntu 14.04 should looks like this, and <code>deb(network)</code> is suggested for fastest downloading from the closest Ubuntu source.</p>\n<p><img data-attachment-id=\"137\" data-permalink=\"https://no2147483647.wordpress.com/2015/12/07/deep-learning-for-hackers-with-mxnet-1/yymd1dsdtnkfbhjuck2o_cuda-selection/#main\" data-orig-file=\"https://no2147483647.files.wordpress.com/2015/12/yymd1dsdtnkfbhjuck2o_cuda-selection.png\" data-orig-size=\"615,560\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"yymd1dsdtnkfbhjuck2o_cuda-selection\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://no2147483647.files.wordpress.com/2015/12/yymd1dsdtnkfbhjuck2o_cuda-selection.png?w=300\" data-large-file=\"https://no2147483647.files.wordpress.com/2015/12/yymd1dsdtnkfbhjuck2o_cuda-selection.png?w=615\" class=\"alignnone size-full wp-image-137\" src=\"https://no2147483647.files.wordpress.com/2015/12/yymd1dsdtnkfbhjuck2o_cuda-selection.png?w=1008\" alt=\"yymd1dsdtnkfbhjuck2o_cuda-selection\" srcset=\"https://no2147483647.files.wordpress.com/2015/12/yymd1dsdtnkfbhjuck2o_cuda-selection.png 615w, https://no2147483647.files.wordpress.com/2015/12/yymd1dsdtnkfbhjuck2o_cuda-selection.png?w=150 150w, https://no2147483647.files.wordpress.com/2015/12/yymd1dsdtnkfbhjuck2o_cuda-selection.png?w=300 300w\" sizes=\"(max-width: 615px) 100vw, 615px\"   /></p>\n<p>Or, here it is the command-line-only solution：</p>\n<pre><code>wget http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1404/x86_64/cuda-repo-ubuntu1404_7.5-18_amd64.deb\nsudo dpkg -i cuda-repo-ubuntu1404_7.5-18_amd64.deb\nsudo apt-get update\nsudo apt-get install cuda\n</code></pre>\n<p>If everything goes well, please check the video card status by <code>nvidia-smi</code>, and it should look like this：</p>\n<p><img data-attachment-id=\"140\" data-permalink=\"https://no2147483647.wordpress.com/2015/12/07/deep-learning-for-hackers-with-mxnet-1/zhbzdjy3sbeoc6x6hcyu_idle-gpu/#main\" data-orig-file=\"https://no2147483647.files.wordpress.com/2015/12/zhbzdjy3sbeoc6x6hcyu_idle-gpu.png\" data-orig-size=\"641,322\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"zhbzdjy3sbeoc6x6hcyu_idle-gpu\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://no2147483647.files.wordpress.com/2015/12/zhbzdjy3sbeoc6x6hcyu_idle-gpu.png?w=300\" data-large-file=\"https://no2147483647.files.wordpress.com/2015/12/zhbzdjy3sbeoc6x6hcyu_idle-gpu.png?w=641\" class=\"alignnone size-full wp-image-140\" src=\"https://no2147483647.files.wordpress.com/2015/12/zhbzdjy3sbeoc6x6hcyu_idle-gpu.png?w=1008\" alt=\"zhbzdjy3sbeoc6x6hcyu_idle-gpu\" srcset=\"https://no2147483647.files.wordpress.com/2015/12/zhbzdjy3sbeoc6x6hcyu_idle-gpu.png 641w, https://no2147483647.files.wordpress.com/2015/12/zhbzdjy3sbeoc6x6hcyu_idle-gpu.png?w=150 150w, https://no2147483647.files.wordpress.com/2015/12/zhbzdjy3sbeoc6x6hcyu_idle-gpu.png?w=300 300w\" sizes=\"(max-width: 641px) 100vw, 641px\"   /></p>\n<p>CPU info may vary, and I am using a GTX 960 4GB (approximately 200$ now). MXnet has very efficient memory usage, and 4GB is good for most of the problems. If your video card has only 2GB, MXnet is fine with it with some small parameter tunes too.</p>\n<p><strong>Optional: CuDNN.</strong> Mxnet supports <code>cuDNN</code> too. <code>cuDNN</code> is nVidia deep learning toolkit which optimizes operations like convolution, poolings etc, for better speed and memory usage. Usually it can speed up MXnet by 40% to 50%. If interested, please go apply for the developer program here <a href=\"https://developer.nvidia.com/cudnn\">https://developer.nvidia.com/cudnn</a>, and install <code>cuDNN</code> by the official instruction when approved,</p>\n<h3>Compile MXnet with CUDA support</h3>\n<p>MXnet needs to turn on CUDA support in the configuration. Please find <code>config.mk</code> from <code>mxnet/make/</code>, copy to <code>mxnet/</code>, and edit these three lines:</p>\n<pre><code>USE_CUDA = 1\nUSE_CUDA_PATH = /usr/local/cuda\nUSE_BLAS = blas\n</code></pre>\n<p>where the second line is for CUDA installation path. The path usually is <code>/usr/local/cuda</code> or <code>/usr/local/cuda-7.5</code>. If readers prefer other <code>BLAS</code> implementations. e.g. <code>OpenBlas</code> or <code>Atlas</code>, please change <code>USE_BLAS</code> to <code>openblas</code> or <code>atlas</code> and add the blas path to <code>ADD_LDFLAGS</code> and <code>ADD_CFLAGS</code>.</p>\n<p>We can compile MXnet with CUDA (<code>-j4</code> for multi-thread compiling):</p>\n<pre><code>make -j4\n</code></pre>\n<p>One more reminder that, if one has non-CUDA video cards, for example Intel Iris or AMD R9, or there is not video card, please change <code>USE_CUDA</code> to <code>0</code>. MXnet is dynamic for switching between CPU and GPU: instead of GPU version, one can compile multi-theading CPU version by setting <code>USE_OPENMP = 1</code> or leave it to 0 so <code>BLAS</code> can take care of multi-threading, either way is fine with MXnet.</p>\n<h3>Install Python support</h3>\n<p>MXnet natively supports Python, one can simply do:</p>\n<pre><code>cd python; python setup.py install\n</code></pre>\n<p>Python 2.7 is suggested while Python 3.4 is also supported. One might need <code>setuptools</code> and <code>numpy</code> if not yet installed. I personally suggest Python from <a href=\"https://www.continuum.io/downloads\"><code>Anaconda</code></a> or <a href=\"http://conda.pydata.org/miniconda.html\"><code>Miniconda</code></a></p>\n<pre><code>wget https://repo.continuum.io/miniconda/Miniconda-latest-Linux-x86_64.sh\nbash Miniconda-latest-Linux-x86_64.sh\n(answer some installation questions)\nconda install numpy\n</code></pre>\n<h2>Let&#8217;s run MNIST, a handwritten digit recognizer</h2>\n<p>Now we have a GPU-ready MXnet, let&#8217;s have the first deep learning example: MNIST. MNIST is a handwritten digit dataset with 60,000 training samples and 10,000 testing samples, where each sample is a 28X28 greyscale picture of digits, and the goal of MNIST is training a smart machine learning model for recognizing hand-writing digits, for example, it recognizes the zip code that people write on envelops and helps our post masters distribute the mails.</p>\n<p>Let&#8217;s run the example:</p>\n<pre><code>cd mxnet/example/image-classification/\npython train_mnist.py\n</code></pre>\n<p><code>train_mnist.py</code> will download MNIST dataset for the first time, please be patient while downloading. The sample code will print out the loss and precision for each step, and the final result should be approximately 97%.</p>\n<p><code>train_mnist.py</code> by default uses CPU only. MXnet has easy switch between CPU and GPU. Since we have GPU, let&#8217;s turn it on by:</p>\n<pre><code>python train_mnist.py --gpus 0\n</code></pre>\n<p>That is it. <code>--gpus 0</code> means using the first GPU. If one has multiple GPUs, for example 4 GPUs, one can set <code>--gpus 0,1,2,3</code> for using all of them. While running with GPU, the <code>nvidia-smi</code> should look like this：</p>\n<p><img data-attachment-id=\"142\" data-permalink=\"https://no2147483647.wordpress.com/2015/12/07/deep-learning-for-hackers-with-mxnet-1/oa8r4sairgmijrrest1k_mnist-gpu/#main\" data-orig-file=\"https://no2147483647.files.wordpress.com/2015/12/oa8r4sairgmijrrest1k_mnist-gpu.png\" data-orig-size=\"647,309\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"oa8r4sairgmijrrest1k_mnist-gpu\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://no2147483647.files.wordpress.com/2015/12/oa8r4sairgmijrrest1k_mnist-gpu.png?w=300\" data-large-file=\"https://no2147483647.files.wordpress.com/2015/12/oa8r4sairgmijrrest1k_mnist-gpu.png?w=647\" class=\"alignnone size-full wp-image-142\" src=\"https://no2147483647.files.wordpress.com/2015/12/oa8r4sairgmijrrest1k_mnist-gpu.png?w=1008\" alt=\"oa8r4sairgmijrrest1k_mnist-gpu\" srcset=\"https://no2147483647.files.wordpress.com/2015/12/oa8r4sairgmijrrest1k_mnist-gpu.png 647w, https://no2147483647.files.wordpress.com/2015/12/oa8r4sairgmijrrest1k_mnist-gpu.png?w=150 150w, https://no2147483647.files.wordpress.com/2015/12/oa8r4sairgmijrrest1k_mnist-gpu.png?w=300 300w\" sizes=\"(max-width: 647px) 100vw, 647px\"   /></p>\n<p>where one can see <code>python</code> is using GPU. Since MNIST is not a heavy task, with MXnet efficient GPU meomory usage, GPU usage is about 30-40% while memory usage at 67MB。</p>\n<h3>Trouble shooting</h3>\n<p>When run with GPU for the first time, readers may encounter something like this：</p>\n<pre><code>ImportError: libcudart.so.7.0: cannot open shared object file: No such file \n</code></pre>\n<p>It is because of the PATH of CUDA dynamic link lib, one can add this to <code>./bashrc</code>：</p>\n<pre><code>export LD_LIBRARY_PATH=/usr/local/cuda-7.5/targets/x86_64-linux/lib/:$LD_LIBRARY_PATH\n</code></pre>\n<p>Or compile it to MXnet by adding in <code>config.mk</code>:</p>\n<pre><code>ADD_LDFLAGS = -I/usr/local/cuda-7.5/targets/x86_64-linux/lib/\nADD_CFLAGS =-I/usr/local/cuda-7.5/targets/x86_64-linux/lib/\n</code></pre>\n<h3>MNIST code secrete revealed: design a simple MLP</h3>\n<p>In <code>train_mnist.py</code>, there is an function <code>get_mlp()</code>. It implements a <a href=\"https://en.wikipedia.org/wiki/Multilayer_perceptron\">multilayer perceptron (MLP)</a>. In MXnet, a MLP needs some structure definition, like this in the code:</p>\n<pre><code>data = mx.symbol.Variable('data')\nfc1 = mx.symbol.FullyConnected(data = data, name='fc1', num_hidden=128)\nact1 = mx.symbol.Activation(data = fc1, name='relu1', act_type=\"relu\")\nfc2 = mx.symbol.FullyConnected(data = act1, name = 'fc2', num_hidden = 64)\nact2 = mx.symbol.Activation(data = fc2, name='relu2', act_type=\"relu\")\nfc3 = mx.symbol.FullyConnected(data = act2, name='fc3', num_hidden=10)\nmlp = mx.symbol.Softmax(data = fc3, name = 'mlp')\n</code></pre>\n<p>Let&#8217;s understand what is going on for this neural network. Samples in MNIST look like these:<br />\n<img data-attachment-id=\"144\" data-permalink=\"https://no2147483647.wordpress.com/2015/12/07/deep-learning-for-hackers-with-mxnet-1/hqdefault/#main\" data-orig-file=\"https://no2147483647.files.wordpress.com/2015/12/hqdefault.jpg\" data-orig-size=\"480,360\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"hqdefault\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://no2147483647.files.wordpress.com/2015/12/hqdefault.jpg?w=300\" data-large-file=\"https://no2147483647.files.wordpress.com/2015/12/hqdefault.jpg?w=480\" class=\"alignnone size-full wp-image-144\" src=\"https://no2147483647.files.wordpress.com/2015/12/hqdefault.jpg?w=1008\" alt=\"hqdefault\" srcset=\"https://no2147483647.files.wordpress.com/2015/12/hqdefault.jpg 480w, https://no2147483647.files.wordpress.com/2015/12/hqdefault.jpg?w=150 150w, https://no2147483647.files.wordpress.com/2015/12/hqdefault.jpg?w=300 300w\" sizes=\"(max-width: 480px) 100vw, 480px\"   /></p>\n<ul>\n<li>Each same (a digit) is a 28X28 pixel grey scale image, which can be represented as a vector of 28X28=784 float value where each value is the grey scale of the pixel.</li>\n<li>In MLP, each layer needs a layer structure. For example in the first layer, <code>fc1</code> is a full connected layer <code>mx.symbol.FullyConnected</code> which takes input from <code>data</code>. This first layer has 128 nodes, defined as <code>num_hidden</code>.</li>\n<li>Each layer also need an activation function <code>Activation</code> to connect to the next layer, in other words, transferring values from the current layer to the next layer. In this example, the <code>Activation</code> function for connecting layer <code>fc1</code> and <code>fc2</code> is <code>ReLu</code>, which is short for <code>rectified linear unit</code> or <code>Rectifier</code>, a function as <code>f(x)=max(0,x)</code>. <code>ReLU</code> is a very commonly used activation function in deep learning, mostly because it is easy to calculate and easy to converge in gradient decent. In addition, we choose <code>ReLU</code> for the MNIST problem because MNIST has sparse feature where most values are 0. For more information about <code>ReLU</code>, please check <a href=\"https://en.wikipedia.org/wiki/Rectifier_(neural_networks\">wikipedia</a> ) and other deep learning books or tutorials.</li>\n<li>The second layer <code>fc2</code> is similar to the first layer <code>fc1</code>: it takes the output from <code>fc1</code> as input, and output to the third layer <code>fc3</code>.</li>\n<li><code>fc3</code> works similar to the previous layer, and the only difference is that, it is an output layer, which has 10 nodes where each node outputs the probability of being one of the 10 digits, thus <code>num_hidden=10</code>.</li>\n</ul>\n<p>With this network structure, MXnet also needs the stucture of input. Since each sample is 28X28 grey scale, MXnet takes the grey scale value vector of 28X28=784 elements, and give a python iterator <code>get_iterator()</code> for feeding data to the network defined above. The detailed code is in the example which is very clean, so I don&#8217;t copy-n-paste here.</p>\n<p>The final step is running the model. If readers know <code>scikit-learn</code>, MXnet&#8217;s python looks very familiar, right?</p>\n<pre><code>train_model.fit(args, net, get_iterator)\n</code></pre>\n<p>Congratulations! We can implement a MLP! It is the first step of deep learning, not hard, right?</p>\n<p>It is Q&A time now. Some of my dear readers may ask, &#8220;Do I need to design my MNIST recognizer or some other deep learning network exactly like what you did here?&#8221; &#8220;hey, I see another function <code>get_lenet()</code> in the code, what is that?&#8221;</p>\n<p>The answer to these two questions can be, most real life problems on deep learning are about designing the networks, and, <strong>no, you don&#8217;t have to design your network exactly like what I did here</strong>. Designing the neural network is art, and each problem needs a different network, and a single problem may have multiple solutions. In the MNIST example code, <code>get_lenet()</code> implements Yann Lecun&#8217;s convolution network <code>LeNet</code> for digit recognition, where each layer needs <code>Convolution</code> <code>Activation</code> and <code>Pooling</code> where the kernel size and filter are needed, instead of <code>FullyConnected</code> and <code>ReLU</code>. FYI: the detailed explanation of super cool convolution network (ConvNet) can be found at Yann Lecun&#8217;s tutorial: <a href=\"http://www.cs.nyu.edu/~yann/talks/lecun-ranzato-icml2013.pdf\">http://www.cs.nyu.edu/~yann/talks/lecun-ranzato-icml2013.pdf</a> . Another good reference can be <a href=\"http://colah.github.io/posts/2014-07-Understanding-Convolutions/\">&#8220;Understanding ConvNet&#8221; by Colah</a>. I may later on write a blog post for explaining ConvNet, since convnet is my personal favorite.</p>\n<p>I have a fun homework for my dear readers. Let&#8217;s tune up some network parameters like the number of nodes and the activation function in <code>get_mlp()</code>, and see how it helps the precision and accuracy. One can also try changing <code>num_epoch</code> (number of iterations of learning from the data) and <code>learning_rate</code> (the speed of gradient decent, a.k.a the rate of learning) for better speed and precision. Please leave your comment for your network structure and precision score. Kaggle also has a MNIST competition, one can also go compete with mxnet MNIST models, please mention it is MXnet model. The portal: <a href=\"https://www.kaggle.com/c/digit-recognizer\">https://www.kaggle.com/c/digit-recognizer</a></p>\n<h2>Outlook</h2>\n<p>Thanks for reading the first blog of &#8220;Deep learning for hackers with MXnet&#8221;. The following blogs will include some examples in MXnet, which may include RNN/LSTM for generating a Shakespeare script (well, looks like Shakespeare), generative models of simulating Van Gogh for painting a cat, etc. Some of these models are available now on MXnet github <a href=\"https://github.com/dmlc/mxnet/tree/master/example\">https://github.com/dmlc/mxnet/tree/master/example</a>. Is MXnet cool? Go star and fork it on github <a href=\"https://github.com/dmlc/mxnet\">https://github.com/dmlc/mxnet</a></p>\n",
  "wfw:commentRss": "https://no2147483647.wordpress.com/2015/12/07/deep-learning-for-hackers-with-mxnet-1/feed/",
  "slash:comments": 7,
  "media:content": [
    {
      "media:title": "phunterlau"
    },
    {
      "media:title": "yymd1dsdtnkfbhjuck2o_cuda-selection"
    },
    {
      "media:title": "zhbzdjy3sbeoc6x6hcyu_idle-gpu"
    },
    {
      "media:title": "oa8r4sairgmijrrest1k_mnist-gpu"
    },
    {
      "media:title": "hqdefault"
    }
  ]
}