{
  "title": "Custom Parallel Algorithms on a Cluster with Dask",
  "link": "",
  "updated": "2017-01-24T00:00:00+00:00",
  "id": "https://mrocklin.github.io/blog/work/2017/01/24/dask-custom",
  "content": "<p><em>This work is supported by <a href=\"http://continuum.io\">Continuum Analytics</a>\nthe <a href=\"http://www.darpa.mil/program/XDATA\">XDATA Program</a>\nand the Data Driven Discovery Initiative from the <a href=\"https://www.moore.org/\">Moore\nFoundation</a></em></p>\n\n<h3 id=\"summary\">Summary</h3>\n\n<p>This post describes Dask as a computational task scheduler that fits somewhere\non a spectrum between big data computing frameworks like Hadoop/Spark and task\nschedulers like Airflow/Celery/Luigi.  We see how, by combining elements from\nboth of these types of systems Dask is able to handle complex data science\nproblems particularly well.</p>\n\n<p>This post is in contrast to two recent posts on structured parallel\ncollections:</p>\n\n<ol>\n  <li><a href=\"https://mrocklin.github.com/blog/work/2017/01/12/dask-dataframes\">Distributed DataFrames</a></li>\n  <li><a href=\"https://mrocklin.github.com/blog/work/2017/01/17/dask-images\">Distributed Arrays</a></li>\n</ol>\n\n<h3 id=\"big-data-collections\">Big Data Collections</h3>\n\n<p>Most distributed computing systems like Hadoop or Spark or SQL databases\nimplement a small but powerful set of parallel operations like map, reduce,\ngroupby, and join.  As long as you write your programs using only those\noperations then the platforms understand your program and serve you well.  Most\nof the time this is great because most big data problems are pretty simple.</p>\n\n<p>However, as we explore new complex algorithms or messier data science problems,\nthese large parallel operations start to become insufficiently flexible.  For\nexample, consider the following data loading and cleaning problem:</p>\n\n<ol>\n  <li>Load data from 100 different files (this is a simple <code class=\"language-plaintext highlighter-rouge\">map</code> operation)</li>\n  <li>Also load a reference dataset from a SQL database (not parallel at all, but\ncould run alongside the map above)</li>\n  <li>Normalize each of the 100 datasets against the reference dataset (sort of\nlike a map, but with another input)</li>\n  <li>Consider a sliding window of every three normalized datasets (Might be able\nto hack this with a very clever join?  Not sure.)</li>\n  <li>Of all of the 98 outputs of the last stage, consider all pairs.  (Join or\ncartesian product) However, because we don’t want to compute all ~10000\npossibilities, let’s just evaluate a random sample of these pairs</li>\n  <li>Find the best of all of these possibilities (reduction)</li>\n</ol>\n\n<p>In sequential for-loopy code this might look like the following:</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">filenames</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s\">'mydata-%d.dat'</span> <span class=\"o\">%</span> <span class=\"n\">i</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">100</span><span class=\"p\">)]</span>\n<span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"n\">fn</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">fn</span> <span class=\"ow\">in</span> <span class=\"n\">filenames</span><span class=\"p\">]</span>\n\n<span class=\"n\">reference</span> <span class=\"o\">=</span> <span class=\"n\">load_from_sql</span><span class=\"p\">(</span><span class=\"s\">'sql://mytable'</span><span class=\"p\">)</span>\n<span class=\"n\">processed</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">process</span><span class=\"p\">(</span><span class=\"n\">d</span><span class=\"p\">,</span> <span class=\"n\">reference</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">d</span> <span class=\"ow\">in</span> <span class=\"n\">data</span><span class=\"p\">]</span>\n\n<span class=\"n\">rolled</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n<span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">processed</span><span class=\"p\">)</span> <span class=\"o\">-</span> <span class=\"mi\">2</span><span class=\"p\">):</span>\n    <span class=\"n\">a</span> <span class=\"o\">=</span> <span class=\"n\">processed</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span>\n    <span class=\"n\">b</span> <span class=\"o\">=</span> <span class=\"n\">processed</span><span class=\"p\">[</span><span class=\"n\">i</span> <span class=\"o\">+</span> <span class=\"mi\">1</span><span class=\"p\">]</span>\n    <span class=\"n\">c</span> <span class=\"o\">=</span> <span class=\"n\">processed</span><span class=\"p\">[</span><span class=\"n\">i</span> <span class=\"o\">+</span> <span class=\"mi\">2</span><span class=\"p\">]</span>\n    <span class=\"n\">r</span> <span class=\"o\">=</span> <span class=\"n\">roll</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">b</span><span class=\"p\">,</span> <span class=\"n\">c</span><span class=\"p\">)</span>\n    <span class=\"n\">rolled</span><span class=\"p\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">r</span><span class=\"p\">)</span>\n\n<span class=\"n\">compared</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n<span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">200</span><span class=\"p\">):</span>\n    <span class=\"n\">a</span> <span class=\"o\">=</span> <span class=\"n\">random</span><span class=\"p\">.</span><span class=\"n\">choice</span><span class=\"p\">(</span><span class=\"n\">rolled</span><span class=\"p\">)</span>\n    <span class=\"n\">b</span> <span class=\"o\">=</span> <span class=\"n\">random</span><span class=\"p\">.</span><span class=\"n\">choice</span><span class=\"p\">(</span><span class=\"n\">rolled</span><span class=\"p\">)</span>\n    <span class=\"n\">c</span> <span class=\"o\">=</span> <span class=\"n\">compare</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">b</span><span class=\"p\">)</span>\n    <span class=\"n\">compared</span><span class=\"p\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">c</span><span class=\"p\">)</span>\n\n<span class=\"n\">best</span> <span class=\"o\">=</span> <span class=\"n\">reduction</span><span class=\"p\">(</span><span class=\"n\">compared</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p>This code is clearly parallelizeable, but it’s not clear how to write it down\nas a MapReduce program, a Spark computation, or a SQL query.  These tools\ngenerally fail when asked to express complex or messy problems.  We can still\nuse Hadoop/Spark to solve this problem, but we are often forced to change and\nsimplify our objectives a bit.  (This problem is not particularly complex, and I\nsuspect that there are clever ways to do it, but it’s not trivial and often\ninefficient.)</p>\n\n<h3 id=\"task-schedulers\">Task Schedulers</h3>\n\n<p>So instead people use task schedulers like Celery, Luigi, or Airflow.  These\nsystems track hundreds of <em>tasks</em>, each of which is just a normal Python\nfunction that runs on some normal Python data.  The task scheduler tracks\ndependencies between tasks and so runs as many as it can at once if they don’t\ndepend on each other.</p>\n\n<p>This is a far more granular approach than the Big-Bulk-Collection approach of\nMapReduce and Spark.  However systems like Celery, Luigi, and Airflow are also\ngenerally less efficient.  This is both because they know less about their computations (map is much easier to schedule than an arbitrary graph) and because they just don’t have machinery for inter-worker communication, efficient serialization of custom datatypes, etc..</p>\n\n<h3 id=\"dask-mixes-task-scheduling-with-efficient-computation\">Dask Mixes Task Scheduling with Efficient Computation</h3>\n\n<p>Dask is both a big data system like Hadoop/Spark that is aware of resilience,\ninter-worker communication, live state, etc. and also a general task scheduler\nlike Celery, Luigi, or Airflow, capable of arbitrary task execution.</p>\n\n<p>Many Dask users use something like Dask dataframe, which generates these graphs\nautomatically, and so never really observe the task scheduler aspect of Dask\nThis is, however, the core of what distinguishes Dask from other systems like\nHadoop and Spark.  Dask is incredibly <em>flexible</em> in the kinds of algorithms it\ncan run.  This is because, at its core, it can run <em>any</em> graph of tasks and not\njust map, reduce, groupby, join, etc..  Users can do this natively, without\nhaving to subclass anything or extend Dask to get this extra power.</p>\n\n<p>There are significant performance advantages to this.  For example:</p>\n\n<ol>\n  <li>Dask.dataframe can easily represent nearest neighbor computations for\nfast time-series algorithms</li>\n  <li>Dask.array can implement complex linear algebra solvers or SVD algorithms\nfrom the latest research</li>\n  <li>Complex Machine Learning algorithms are often easier to implement in Dask,\nallowing it to be more efficient through smarter algorithms, as well as\nthrough scalable computing.</li>\n  <li>Complex hierarchies from bespoke data storage solutions can be explicitly\nmodeled and loaded in to other Dask systems</li>\n</ol>\n\n<p>This doesn’t come for free.  Dask’s scheduler has to be very intelligent to\nsmoothly schedule arbitrary graphs while still optimizing for data locality,\nworker failure, minimal communication, load balancing, scarce resources like\nGPUs and more.  It’s a tough job.</p>\n\n<h3 id=\"daskdelayed\">Dask.delayed</h3>\n\n<p>So let’s go ahead and run the data ingestion job described with Dask.</p>\n\n<p>We craft some fake functions to simulate actual work:</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">import</span> <span class=\"nn\">random</span>\n<span class=\"kn\">from</span> <span class=\"nn\">time</span> <span class=\"kn\">import</span> <span class=\"n\">sleep</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">load</span><span class=\"p\">(</span><span class=\"n\">address</span><span class=\"p\">):</span>\n    <span class=\"n\">sleep</span><span class=\"p\">(</span><span class=\"n\">random</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">()</span> <span class=\"o\">/</span> <span class=\"mi\">2</span><span class=\"p\">)</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">load_from_sql</span><span class=\"p\">(</span><span class=\"n\">address</span><span class=\"p\">):</span>\n    <span class=\"n\">sleep</span><span class=\"p\">(</span><span class=\"n\">random</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">()</span> <span class=\"o\">/</span> <span class=\"mi\">2</span> <span class=\"o\">+</span> <span class=\"mf\">0.5</span><span class=\"p\">)</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">process</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">reference</span><span class=\"p\">):</span>\n    <span class=\"n\">sleep</span><span class=\"p\">(</span><span class=\"n\">random</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">()</span> <span class=\"o\">/</span> <span class=\"mi\">2</span><span class=\"p\">)</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">roll</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">b</span><span class=\"p\">,</span> <span class=\"n\">c</span><span class=\"p\">):</span>\n    <span class=\"n\">sleep</span><span class=\"p\">(</span><span class=\"n\">random</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">()</span> <span class=\"o\">/</span> <span class=\"mi\">5</span><span class=\"p\">)</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">compare</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">b</span><span class=\"p\">):</span>\n    <span class=\"n\">sleep</span><span class=\"p\">(</span><span class=\"n\">random</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">()</span> <span class=\"o\">/</span> <span class=\"mi\">10</span><span class=\"p\">)</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">reduction</span><span class=\"p\">(</span><span class=\"n\">seq</span><span class=\"p\">):</span>\n    <span class=\"n\">sleep</span><span class=\"p\">(</span><span class=\"n\">random</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">()</span> <span class=\"o\">/</span> <span class=\"mi\">1</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p>We annotate these functions with <code class=\"language-plaintext highlighter-rouge\">dask.delayed</code>, which changes a function so\nthat instead of running immediately it captures its inputs and puts everything\ninto a task graph for future execution.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">from</span> <span class=\"nn\">dask</span> <span class=\"kn\">import</span> <span class=\"n\">delayed</span>\n\n<span class=\"n\">load</span> <span class=\"o\">=</span> <span class=\"n\">delayed</span><span class=\"p\">(</span><span class=\"n\">load</span><span class=\"p\">)</span>\n<span class=\"n\">load_from_sql</span> <span class=\"o\">=</span> <span class=\"n\">delayed</span><span class=\"p\">(</span><span class=\"n\">load_from_sql</span><span class=\"p\">)</span>\n<span class=\"n\">process</span> <span class=\"o\">=</span> <span class=\"n\">delayed</span><span class=\"p\">(</span><span class=\"n\">process</span><span class=\"p\">)</span>\n<span class=\"n\">roll</span> <span class=\"o\">=</span> <span class=\"n\">delayed</span><span class=\"p\">(</span><span class=\"n\">roll</span><span class=\"p\">)</span>\n<span class=\"n\">compare</span> <span class=\"o\">=</span> <span class=\"n\">delayed</span><span class=\"p\">(</span><span class=\"n\">compare</span><span class=\"p\">)</span>\n<span class=\"n\">reduction</span> <span class=\"o\">=</span> <span class=\"n\">delayed</span><span class=\"p\">(</span><span class=\"n\">reduction</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p>Now we just call our normal Python for-loopy code from before.  However now\nrather than run immediately our functions capture a computational graph that\ncan be run elsewhere.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">filenames</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s\">'mydata-%d.dat'</span> <span class=\"o\">%</span> <span class=\"n\">i</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">100</span><span class=\"p\">)]</span>\n<span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"n\">fn</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">fn</span> <span class=\"ow\">in</span> <span class=\"n\">filenames</span><span class=\"p\">]</span>\n\n<span class=\"n\">reference</span> <span class=\"o\">=</span> <span class=\"n\">load_from_sql</span><span class=\"p\">(</span><span class=\"s\">'sql://mytable'</span><span class=\"p\">)</span>\n<span class=\"n\">processed</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">process</span><span class=\"p\">(</span><span class=\"n\">d</span><span class=\"p\">,</span> <span class=\"n\">reference</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">d</span> <span class=\"ow\">in</span> <span class=\"n\">data</span><span class=\"p\">]</span>\n\n<span class=\"n\">rolled</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n<span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">processed</span><span class=\"p\">)</span> <span class=\"o\">-</span> <span class=\"mi\">2</span><span class=\"p\">):</span>\n    <span class=\"n\">a</span> <span class=\"o\">=</span> <span class=\"n\">processed</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span>\n    <span class=\"n\">b</span> <span class=\"o\">=</span> <span class=\"n\">processed</span><span class=\"p\">[</span><span class=\"n\">i</span> <span class=\"o\">+</span> <span class=\"mi\">1</span><span class=\"p\">]</span>\n    <span class=\"n\">c</span> <span class=\"o\">=</span> <span class=\"n\">processed</span><span class=\"p\">[</span><span class=\"n\">i</span> <span class=\"o\">+</span> <span class=\"mi\">2</span><span class=\"p\">]</span>\n    <span class=\"n\">r</span> <span class=\"o\">=</span> <span class=\"n\">roll</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">b</span><span class=\"p\">,</span> <span class=\"n\">c</span><span class=\"p\">)</span>\n    <span class=\"n\">rolled</span><span class=\"p\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">r</span><span class=\"p\">)</span>\n\n<span class=\"n\">compared</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n<span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">200</span><span class=\"p\">):</span>\n    <span class=\"n\">a</span> <span class=\"o\">=</span> <span class=\"n\">random</span><span class=\"p\">.</span><span class=\"n\">choice</span><span class=\"p\">(</span><span class=\"n\">rolled</span><span class=\"p\">)</span>\n    <span class=\"n\">b</span> <span class=\"o\">=</span> <span class=\"n\">random</span><span class=\"p\">.</span><span class=\"n\">choice</span><span class=\"p\">(</span><span class=\"n\">rolled</span><span class=\"p\">)</span>\n    <span class=\"n\">c</span> <span class=\"o\">=</span> <span class=\"n\">compare</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">b</span><span class=\"p\">)</span>\n    <span class=\"n\">compared</span><span class=\"p\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">c</span><span class=\"p\">)</span>\n\n<span class=\"n\">best</span> <span class=\"o\">=</span> <span class=\"n\">reduction</span><span class=\"p\">(</span><span class=\"n\">compared</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p>Here is an image of that graph for a smaller input of only 10 files and 20\nrandom pairs</p>\n\n<p><a href=\"https://mrocklin.github.io/blog/images/custom-etl.png\">\n    <img src=\"https://mrocklin.github.io/blog/images/custom-etl.png\" alt=\"Custom ETL Dask Graph\" width=\"80%\" /></a></p>\n\n<p>We can connect to a small cluster with 20 cores</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">from</span> <span class=\"nn\">dask.distributed</span> <span class=\"kn\">import</span> <span class=\"n\">Client</span>\n<span class=\"n\">client</span> <span class=\"o\">=</span> <span class=\"n\">Client</span><span class=\"p\">(</span><span class=\"s\">'scheduler-address:8786'</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p>We compute the result and see the trace of the computation running in real\ntime.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">best</span><span class=\"p\">.</span><span class=\"n\">compute</span><span class=\"p\">()</span>\n</code></pre></div></div>\n\n<p><a href=\"https://mrocklin.github.io/blog/images/task-stream-custom-etl.gif\">\n    <img src=\"https://mrocklin.github.io/blog/images/task-stream-custom-etl.gif\" alt=\"Custom ETL Task Stream\" width=\"80%\" /></a></p>\n\n<p>The completed <a href=\"https://bokeh.pydata.org\">Bokeh</a> image below is interactive.\nYou can pan and zoom by selecting the tools in the upper right.  You can see\nevery task, which worker it ran on and how long it took by hovering over the\nrectangles.</p>\n\n<iframe src=\"https://cdn.rawgit.com/mrocklin/52e1c411878fcdd64e04574877fe265e/raw/98d9f38c51b250523e9c584779e74156ab14a4fe/task-stream-custom-etl.html\" width=\"800\" height=\"400\"></iframe>\n\n<p>We see that we use all 20 cores well.  Intermediate results are transferred\nbetween workers as necessary (these are the red rectangles).  We can scale this\nup as necessary.  Dask scales to thousands of cores.</p>\n\n<h2 id=\"final-thoughts\">Final Thoughts</h2>\n\n<p>Dask’s ability to write down arbitrary computational graphs\nCelery/Luigi/Airflow-style and yet run them with the scalability promises of\nHadoop/Spark allows for a pleasant freedom to write comfortably and yet still\ncompute scalably.  This ability opens up new possibilities both to support more\nsophisticated algorithms and also to handle messy situations that arise in the\nreal world (enterprise data systems are sometimes messy) while still remaining\nwithin the bounds of “normal and supported” Dask operation.</p>"
}