{
  "title": "Second Annual Data Science Bowl &#8211; Part 2",
  "link": "https://colinpriest.com/2016/03/07/second-annual-data-science-bowl-part-2/",
  "comments": "https://colinpriest.com/2016/03/07/second-annual-data-science-bowl-part-2/#comments",
  "dc:creator": "Colin Priest",
  "pubDate": "Mon, 07 Mar 2016 00:27:23 +0000",
  "category": [
    "Automation",
    "Image Processing",
    "Kaggle",
    "Medical Imaging",
    "R"
  ],
  "guid": "http://colinpriest.com/?p=723",
  "description": "In Part 1 of this blog series, I described how to fix the brightness and contrast of the MRI images. In this blog I finish cleaning up the input data. Once we have done these steps, the data is ready to go into a convolutional neural network (to be described in my next blog).<p><a href=\"https://colinpriest.com/2016/03/07/second-annual-data-science-bowl-part-2/\">Continue reading <span class=\"meta-nav\">&#8594;</span></a></p>",
  "content:encoded": "<p>In <a href=\"https://colinpriest.com/2016/03/06/second-annual-data-science-bowl-part-1/\" target=\"_blank\">Part 1</a> of this blog series, I described how to fix the brightness and contrast of the MRI images. In this blog we finish cleaning up the input data.</p>\n<p>Other than brightness and contrast, we need to fix up the following problems:</p>\n<ul>\n<li>different image sizes</li>\n<li>different image rotations &#8211; portrait versus landscape</li>\n<li>different pixel spacing</li>\n<li>different short axis slice spacing</li>\n<li>image sets from duplicate locations</li>\n<li>sax sets aren&#8217;t in the same order as their locations</li>\n<li>some sax image sets have multiple locations</li>\n</ul>\n<h1>Different Image Sizes and Rotations</h1>\n<p>There are approximately a dozen different image sizes, include rotated images. Not all of the image sizes scale to the same 4:3 aspect ratio that is the most common across the training set. Some of the machine learning algorithms I used later need fixed dimension images, so I compromised and decided to use a standard sizing of 256 x 192 pixels portrait aspect ratio. This meant that I wasn&#8217;t always scaling the x-axis and the y-axis by the same amount, and occasionally I was even upscaling an image.</p>\n<pre class=\"brush: r; title: ; notranslate\">\n\nlibrary(pacman)\npacman::p_load(EBImage)\nrescaleImage = function(img)\n{\n imgOut = img\n # check for landscape aspect ratio and correct\n if (nrow(img) > ncol(img)) imgOut = t(img)\n imgOut = resize(imgOut, 256, 192) # standardise image size to 256 x 192\n return (imgOut)\n}\n\n</pre>\n<p><img loading=\"lazy\" data-attachment-id=\"778\" data-permalink=\"https://colinpriest.com/2016/03/07/second-annual-data-science-bowl-part-2/20160307image01/\" data-orig-file=\"https://colinpriestdotcom.files.wordpress.com/2016/03/20160307image01.png\" data-orig-size=\"256,192\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"20160307image01\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://colinpriestdotcom.files.wordpress.com/2016/03/20160307image01.png?w=256\" data-large-file=\"https://colinpriestdotcom.files.wordpress.com/2016/03/20160307image01.png?w=256\" class=\"alignnone size-full wp-image-778\" src=\"https://colinpriestdotcom.files.wordpress.com/2016/03/20160307image01.png\" alt=\"20160307image01\" width=\"256\" height=\"192\" srcset=\"https://colinpriestdotcom.files.wordpress.com/2016/03/20160307image01.png 256w, https://colinpriestdotcom.files.wordpress.com/2016/03/20160307image01.png?w=150&h=113 150w\" sizes=\"(max-width: 256px) 100vw, 256px\" /><img loading=\"lazy\" data-attachment-id=\"779\" data-permalink=\"https://colinpriest.com/2016/03/07/second-annual-data-science-bowl-part-2/20160307image02/\" data-orig-file=\"https://colinpriestdotcom.files.wordpress.com/2016/03/20160307image02.png\" data-orig-size=\"192,256\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"20160307image02\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://colinpriestdotcom.files.wordpress.com/2016/03/20160307image02.png?w=192\" data-large-file=\"https://colinpriestdotcom.files.wordpress.com/2016/03/20160307image02.png?w=192\" class=\"alignnone size-full wp-image-779\" src=\"https://colinpriestdotcom.files.wordpress.com/2016/03/20160307image02.png\" alt=\"20160307image02\" width=\"192\" height=\"256\" srcset=\"https://colinpriestdotcom.files.wordpress.com/2016/03/20160307image02.png 192w, https://colinpriestdotcom.files.wordpress.com/2016/03/20160307image02.png?w=113&h=150 113w\" sizes=\"(max-width: 192px) 100vw, 192px\" /></p>\n<p>Note that I used matrix transpose to rotate the image 90 degrees. I could also have used the rotate function in EBImage. Either way could work, but I felt that matrix transpose would be a faster operation.</p>\n<h1>Image Locations and Spacing</h1>\n<p>The DICOM images contain information about image slice location, pixel spacing (how far apart are adjacent pixel centroids), and slice spacing (how far apart are adjacent sax slices).</p>\n<pre class=\"brush: r; title: ; notranslate\">\n\nlibrary(pacman)\npacman::p_load(oro.dicom)\n\n# function to extract the dicom header info\ngetDicomHeaderInfo = function(path)\n{\n img = readDICOMFile(path)\n width = ncol(img$img)\n height = nrow(img$img)\n headers = img$hdr\n patientID = extractHeader(img$hdr, 'PatientID', numeric = TRUE)\n patientAge = as.integer(substr(extractHeader(img$hdr, 'PatientsAge', numeric = FALSE), 1, 3))\n patientGender = as.character(extractHeader(img$hdr, 'PatientsSex', numeric = FALSE))\n ps = extractHeader(img$hdr, 'PixelSpacin', numeric = FALSE)\n pixelSpacingX = as.numeric(unlist(strsplit(ps, ' '))[1])\n pixelSpacingY = as.numeric(unlist(strsplit(ps, ' '))[2])\n seriesNum = extractHeader(img$hdr, 'SeriesNumber', numeric = TRUE)\n location = round(extractHeader(img$hdr, 'SliceLocation', numeric = TRUE), digits = 1)\n pathSplit = unlist(strsplit(path, '/&amp;amp;', fixed = TRUE))\n filename = pathSplit[length(pathSplit)]\n prefix = unlist(strsplit(filename, '.', fixed = TRUE))[1]\n frame = as.integer(unlist(strsplit(prefix, '-'))[3])\n sliceNum = 0\n if (length(unlist(strsplit(prefix, '-'))) &amp;gt; 3) sliceNum = as.integer(unlist(strsplit(prefix, '-'))[4])\n time = extractHeader(img$hdr, 'InstanceCreationTime', numeric = FALSE)\n #\n return (list(\n id = patientID,\n age = patientAge,\n gender = patientGender,\n pixelSpacingX = pixelSpacingX,\n pixelSpacingY = pixelSpacingY,\n width = width,\n height = height,\n series = seriesNum,\n location = location,\n frame = frame,\n sliceNum = sliceNum,\n time = time,\n path = path\n ))\n}\n</pre>\n<p>I&#8217;m not a medical expert. So when there are images from duplicate locations, I don&#8217;t know which image sets are the best to use. Therefore I just assumed that the medical specialist repeated the MRI scans until the image quality was adequate. This meant that I chose the image set with the latest time stamps (from the header information inside the DICOM files, not the file system date).</p>\n<p>Then I just</p>\n<ol>\n<li>searched for DICOM images in all of the subfolders for each patient</li>\n<li>filtered to use only sax slices, ignoring those images that did not come from a folder that contained the substring &#8220;sax&#8221;</li>\n<li>read the DICOM header information from each image to find its location and time</li>\n<li>searched for the high time stamp for each location and kept that image</li>\n<li>wrote outÂ a new folder structure where sax_01, sax_02, &#8230; were the sax slice image sets for that patient, order by their location along the long axis of the heart</li>\n</ol>\n<p>The R script to do this isn&#8217;t too difficult. I&#8217;ve pasted it below:</p>\n<pre class=\"brush: r; title: ; notranslate\">\n\n# this script creates a cleaner version of the image data\n# plus an extract of the file headers\n# 1) removes duplicate images\n# 2) reorders images by location\n\n# read a poor image and translate the pixel brightnesses\nrebalanceImage = function(badImage)\n{\nv = matrix(badImage, nrow(badImage) * ncol(badImage))\no2 = order(v)\nvIn = sample(vAll, nrow(badImage) * ncol(badImage))\nvIn = vIn[order(vIn)]\nv2 = v\nv2[o2] = vIn\ncleanImage = matrix(v2, nrow(badImage), ncol(badImage))\nreturn (cleanImage)\n}\n\n# check whether a folder exists and make it if it doesn't exist\ncheckFolder = function(mainDir, subDir)\n{\nif(!dir.exists(file.path(mainDir, subDir)))\ndir.create(file.path(mainDir, subDir))\n}\n\n# function to extract the dicom header info\ngetDicomHeaderInfo = function(path)\n{\nimg = readDICOMFile(path)\nwidth = ncol(img$img)\nheight = nrow(img$img)\nheaders = img$hdr\npatientID = extractHeader(img$hdr, 'PatientID', numeric = TRUE)\npatientAge = as.integer(substr(extractHeader(img$hdr, 'PatientsAge', numeric = FALSE), 1, 3))\npatientGender = as.character(extractHeader(img$hdr, 'PatientsSex', numeric = FALSE))\nps = extractHeader(img$hdr, 'PixelSpacing', numeric = FALSE)\npixelSpacingX = as.numeric(unlist(strsplit(ps, ' '))[1])\npixelSpacingY = as.numeric(unlist(strsplit(ps, ' '))[2])\nseriesNum = extractHeader(img$hdr, 'SeriesNumber', numeric = TRUE)\nlocation = round(extractHeader(img$hdr, 'SliceLocation', numeric = TRUE), digits = 1)\npathSplit = unlist(strsplit(path, '/', fixed = TRUE))\nfilename = pathSplit[length(pathSplit)]\nprefix = unlist(strsplit(filename, '.', fixed = TRUE))[1]\nframe = as.integer(unlist(strsplit(prefix, '-'))[3])\nsliceNum = 0\nif (length(unlist(strsplit(prefix, '-'))) &amp;gt; 3) sliceNum = as.integer(unlist(strsplit(prefix, '-'))[4])\ntime = extractHeader(img$hdr, 'InstanceCreationTime', numeric = FALSE)\n#\nreturn (list(\nid = patientID,\nage = patientAge,\ngender = patientGender,\npixelSpacingX = pixelSpacingX,\npixelSpacingY = pixelSpacingY,\nwidth = width,\nheight = height,\nseries = seriesNum,\nlocation = location,\nframe = frame,\nsliceNum = sliceNum,\ntime = time,\npath = path\n))\n}\n############################################################################################################################\n\nlibrary(pacman)\npacman::p_load(oro.dicom, raster, data.table, png, flexclust, foreach, doParallel, snowfall)\n\n# whether this run is for the training set (FALSE) or the validation set (TRUE)\nuseValidation = FALSE\n#useValidation = TRUE\n\n# create a benchmark histogram from an exemplar image\ndicomBenchmark = readDICOM('/home/colin/data/Second-Annual-Data-Science-Bowl/train/1/study/sax_13')\nimages = dicomBenchmark[[2]]\nimg = images[[1]]\nvAll = unname(unlist(images))\nvAll = vAll[order(vAll)]\n\n# loop through all of the patients\nrootFolder = '/home/colin/data/Second-Annual-Data-Science-Bowl/train'\noutFolder = '/home/colin/data/Second-Annual-Data-Science-Bowl/train-cleaned'\nif (useValidation)\n{\nrootFolder = '/home/colin/data/Second-Annual-Data-Science-Bowl/validate'\noutFolder = '/home/colin/data/Second-Annual-Data-Science-Bowl/validate-cleaned'\n}\ncases = list.dirs(rootFolder, recursive=FALSE)\n#cases = cases[grep('123', cases)]\nsimpleData = matrix(0, 500, 3)\nsimpleFeatures = data.frame(id = rep(0, 500), age = rep(0, 500), gender = rep('U', 500),\npixelSpacingX = integer(500), pixelSpacingY = integer(500),\nwidth = integer(500), height = integer(500),\nnumSlices = rep(0, 500), stringsAsFactors = FALSE)\nallImages = NULL\n\nsfInit(parallel=TRUE, cpus=14)\nsfLibrary(oro.dicom)\n\nfor (patient in cases)\n{\npatientFolder = paste0(patient, '/study')\nimgSequences = list.dirs(patientFolder, recursive=FALSE)\n# filter for 'sax' folders\nimgSequences = imgSequences[grep('sax', imgSequences, fixed = TRUE)]\nnMax = 10000\nimgTable = data.table(id = integer(nMax), age = integer(nMax), gender = character(nMax),\npixelSpacingX = integer(nMax), pixelSpacingY = integer(nMax),\nwidth = integer(nMax), height = integer(nMax),\nlocation = numeric(nMax), frame = integer(nMax), series = integer(nMax),\nsliceNum = integer(nMax), time = numeric(nMax),\npath = character(nMax))\nfor (imgFolder in imgSequences)\n{\n# find the first file in imgs\nimgFiles = list.files(imgFolder)\nif (length(imgFiles) &lt; 30)\n{\nprint(paste0('length = ', length(imgFiles), '! in ', imgFolder))\n} else {\nif (length(imgFiles) %% 30 != 0)\n{\nprint(paste0('length = ', length(imgFiles), '! in ', imgFolder))\n}\n}\n# do the next part regardless of the number of images\npaths = unlist(lapply(imgFiles, function(x) return (paste0(imgFolder, '/', x))))\nresult <- sfLapply(paths, getDicomHeaderInfo)\nfor (row in result)\n{\nn = sum(imgTable$id > 0) + 1\nimgTable$id[n] = row$id\nimgTable$age[n] = row$age\nimgTable$gender[n] = row$gender\nimgTable$pixelSpacingX[n] = row$pixelSpacingX\nimgTable$pixelSpacingY[n] = row$pixelSpacingY\nimgTable$width[n] = row$width\nimgTable$height[n] = row$height\nimgTable$series[n] = row$series\nimgTable$location[n] = row$location\nimgTable$frame[n] = row$frame\nimgTable$sliceNum[n] = row$sliceNum\nimgTable$time[n] = row$time\nimgTable$path[n] = row$path\n}\n}\n# remove surplus records from table\nimgTable= imgTable[imgTable$id > 0]\n# grab the latest image for each location and frame\nlatestImages = imgTable[order(id, age, gender, pixelSpacingX, pixelSpacingY, width, height, location, frame, time, sliceNum, series), .SD[c(.N)], by=c(&amp;amp;amp;quot;id&amp;amp;amp;quot;, &amp;amp;amp;quot;age&amp;amp;amp;quot;, &amp;amp;amp;quot;gender&amp;amp;amp;quot;, &amp;amp;amp;quot;pixelSpacingX&amp;amp;amp;quot;, &amp;amp;amp;quot;pixelSpacingY&amp;amp;amp;quot;, &amp;amp;amp;quot;width&amp;amp;amp;quot;, &amp;amp;amp;quot;height&amp;amp;amp;quot;, &amp;amp;amp;quot;location&amp;amp;amp;quot;, &amp;amp;amp;quot;frame&amp;amp;amp;quot;)]\n#\nprint(paste0('Patient: ', latestImages$id[1]))\nuniqueLocs = sort(unique(latestImages$location[abs(latestImages$location) > 0.000001]))\nsimpleFeatures[latestImages$id[1], ] = list(latestImages$id[1], latestImages$age[1], latestImages$gender[1],\nlatestImages$pixelSpacingX[1], latestImages$pixelSpacingY[1],\nlatestImages$width[1], latestImages$height[1],\nlength(uniqueLocs))\n# create the cleaned-up images for CNN training\nimgTable$cleanPath = '---'\niSax = 1\npatientID = latestImages$id[1]\nfor (loc in uniqueLocs)\n{\nimgset = latestImages$path[latestImages$location == loc]\niImage = 1\nfor (imgPath in imgset)\n{\ndicomImage = readDICOMFile(imgPath)\n# fix the contrast and brightness\nfixedImage = rebalanceImage(dicomImage$img)\n# get the details of this image\n###patientID = extractHeader(dicomImage$hdr, 'PatientID', numeric = TRUE)\nsliceID = iSax\nimageID = iImage\noutPath = paste0(outFolder, '/', patientID, '/study/sax_', formatC(sliceID, width=2, flag='0'), '/image-', formatC(imageID, width=2, flag='0'), '.png')\n#print(outPath)\n#plot(raster(fixedImage))\ncheckFolder(outFolder, as.character(patientID))\ncheckFolder(paste0(outFolder, '/', patientID), 'study')\ncheckFolder(paste0(outFolder, '/', patientID, '/study'), paste0('sax_', formatC(sliceID, width=2, flag='0')))\nwritePNG(fixedImage / max(fixedImage), outPath)\nimgTable$cleanPath[imgTable$path == imgPath] = outPath\n#\niImage = iImage + 1\n}\niSax = iSax + 1\n}\n\nif (patient == cases[1])\n{\nallImages = imgTable\n} else\n{\nallImages = data.frame(rbind(allImages, imgTable))\n}\n}\n\nsfStop()\n\n</pre>\n<p>I stored all of the DICOM header information in a table. Some of this will be required later, when calculating the volume of the left ventricle chamber.</p>\n<p>The next step, which will be described in my next blog, is to design a convolutional neural network that will automatically find the left ventricle in an image.</p>\n",
  "wfw:commentRss": "https://colinpriest.com/2016/03/07/second-annual-data-science-bowl-part-2/feed/",
  "slash:comments": 3,
  "media:thumbnail": "",
  "media:content": [
    {
      "media:title": "20160307image01"
    },
    {
      "media:title": "colinpriest1966"
    },
    {
      "media:title": "20160307image02"
    }
  ]
}