{
  "title": "Dask Release 0.14.0",
  "link": "",
  "updated": "2017-02-27T00:00:00+00:00",
  "id": "https://mrocklin.github.io/blog/work/2017/02/27/dask-0.14.0",
  "content": "<p><em>This work is supported by <a href=\"http://continuum.io\">Continuum Analytics</a>\nthe <a href=\"http://www.darpa.mil/program/XDATA\">XDATA Program</a>\nand the Data Driven Discovery Initiative from the <a href=\"https://www.moore.org/\">Moore\nFoundation</a></em></p>\n\n<h2 id=\"summary\">Summary</h2>\n\n<p>Dask just released version 0.14.0.  This release contains some significant\ninternal changes as well as the usual set of increased API coverage and bug\nfixes.  This blogpost outlines some of the major changes since the last release\nJanuary, 27th 2017.</p>\n\n<ol>\n  <li>Structural sharing of graphs between collections</li>\n  <li>Refactor communications system</li>\n  <li>Many small dataframe improvements</li>\n  <li>Top-level persist function</li>\n</ol>\n\n<p>You can install new versions using Conda or Pip</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>conda install -c conda-forge dask distributed\n</code></pre></div></div>\n\n<p>or</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>pip install dask[complete] distributed --upgrade\n</code></pre></div></div>\n\n<h2 id=\"share-graphs-between-collections\">Share Graphs between Collections</h2>\n\n<p>Dask collections (arrays, bags, dataframes, delayed) hold onto task graphs that\nhave all of the tasks necessary to create the desired result.  For larger\ndatasets or complex calculations these graphs may have thousands, or sometimes\neven millions of tasks.  In some cases the overhead of handling these graphs\ncan become significant.</p>\n\n<p>This is especially true because dask collections don’t modify their graphs in\nplace, they make new graphs with updated computations.  Copying graph data\nstructures with millions of nodes can take seconds and interrupt interactive\nworkflows.</p>\n\n<p>To address this dask.arrays and dask.delayed collections now use special graph\ndata structures with structural sharing.  This significantly cuts down on the\namount of overhead when building repetitive computations.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">import</span> <span class=\"nn\">dask.array</span> <span class=\"k\">as</span> <span class=\"n\">da</span>\n\n<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">da</span><span class=\"p\">.</span><span class=\"n\">ones</span><span class=\"p\">(</span><span class=\"mi\">1000000</span><span class=\"p\">,</span> <span class=\"n\">chunks</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">1000</span><span class=\"p\">,))</span>  <span class=\"c1\"># 1000 chunks of size 1000\n</span></code></pre></div></div>\n\n<h3 id=\"version-0130\">Version 0.13.0</h3>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">%</span><span class=\"n\">time</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">100</span><span class=\"p\">):</span> <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">x</span> <span class=\"o\">+</span> <span class=\"mi\">1</span>\n<span class=\"n\">CPU</span> <span class=\"n\">times</span><span class=\"p\">:</span> <span class=\"n\">user</span> <span class=\"mf\">2.69</span> <span class=\"n\">s</span><span class=\"p\">,</span> <span class=\"n\">sys</span><span class=\"p\">:</span> <span class=\"mi\">96</span> <span class=\"n\">ms</span><span class=\"p\">,</span> <span class=\"n\">total</span><span class=\"p\">:</span> <span class=\"mf\">2.78</span> <span class=\"n\">s</span>\n<span class=\"n\">Wall</span> <span class=\"n\">time</span><span class=\"p\">:</span> <span class=\"mf\">2.78</span> <span class=\"n\">s</span>\n</code></pre></div></div>\n\n<h3 id=\"version-0140\">Version 0.14.0</h3>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">%</span><span class=\"n\">time</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">100</span><span class=\"p\">):</span> <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">x</span> <span class=\"o\">+</span> <span class=\"mi\">1</span>\n<span class=\"n\">CPU</span> <span class=\"n\">times</span><span class=\"p\">:</span> <span class=\"n\">user</span> <span class=\"mi\">756</span> <span class=\"n\">ms</span><span class=\"p\">,</span> <span class=\"n\">sys</span><span class=\"p\">:</span> <span class=\"mi\">8</span> <span class=\"n\">ms</span><span class=\"p\">,</span> <span class=\"n\">total</span><span class=\"p\">:</span> <span class=\"mi\">764</span> <span class=\"n\">ms</span>\n<span class=\"n\">Wall</span> <span class=\"n\">time</span><span class=\"p\">:</span> <span class=\"mi\">763</span> <span class=\"n\">ms</span>\n</code></pre></div></div>\n\n<p>The difference in this toy problem is moderate but for real world cases this\ncan difference can grow fairly large.  This was also one of the blockers\nidentified by the climate science community stopping them from handling\npetabyte scale analyses.</p>\n\n<p>We chose to roll this out for arrays and delayed first just because those are\nthe two collections that typically produce large task graphs.  Dataframes and\nbags remain as before for the time being.</p>\n\n<h2 id=\"communications-system\">Communications System</h2>\n\n<p>Dask communicates over TCP sockets.  It uses Tornado’s IOStreams to handle\nnon-blocking communication, framing, etc..  We’ve run into some performance\nissues with Tornado when moving large amounts of data.  Some of this <a href=\"https://github.com/tornadoweb/tornado/pull/1873\">has been\nimproved upstream</a> in Tornado\ndirectly, but we still want the ability to optionally drop Tornado’s\nbyte-handling communication stack in the future.  This is especially important\nas dask gets used in institutions with faster and more exotic interconnects\n(supercomputers).  We’ve been asked a few times to support other transport\nmechanisms like MPI.</p>\n\n<p>The first step (and probably hardest step) was to make Dask’s communication\nsystem is pluggable so that we can use different communication options without\nsignificant source-code changes.  We managed this a month ago and now it is\npossible to add other transports to Dask relatively easily.  TCP remains the\nonly real choice today though there is also an experimental ZeroMQ option\n(which provides little-to-no performance benefit over TCP) as well as a fully\nin-memory option in development.</p>\n\n<p>For users the main difference you’ll see is that <code class=\"language-plaintext highlighter-rouge\">tcp://</code> is now prepended many\nplaces.  For example:</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>$ dask-scheduler\ndistributed.scheduler - INFO - -----------------------------------------------\ndistributed.scheduler - INFO -   Scheduler at:  tcp://192.168.1.115:8786\n...\n</code></pre></div></div>\n\n<h2 id=\"variety-of-dataframe-changes\">Variety of Dataframe Changes</h2>\n\n<p>As usual the Pandas API has been more fully covered by community contributors.\nSome representative changes include the following:</p>\n\n<ol>\n  <li>\n    <p>Support non-uniform categoricals: We no longer need to do a full pass\nthrough the data when categorizing a column.  Instead we categorize each\npartition independently (even if they have different category values) and\nthen unify these categories only when necessary</p>\n\n    <div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s\">'x'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s\">'x'</span><span class=\"p\">].</span><span class=\"n\">astype</span><span class=\"p\">(</span><span class=\"s\">'category'</span><span class=\"p\">)</span>  <span class=\"c1\"># this is now fast\n</span></code></pre></div>    </div>\n  </li>\n  <li>\n    <p>Groupby cumulative reductions</p>\n\n    <div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">df</span><span class=\"p\">.</span><span class=\"n\">groupby</span><span class=\"p\">(</span><span class=\"s\">'x'</span><span class=\"p\">).</span><span class=\"n\">cumsum</span><span class=\"p\">()</span>\n</code></pre></div>    </div>\n  </li>\n  <li>\n    <p>Support appending to Parquet collections</p>\n\n    <div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">df</span><span class=\"p\">.</span><span class=\"n\">to_parquet</span><span class=\"p\">(</span><span class=\"s\">'/path/to/foo.parquet'</span><span class=\"p\">,</span> <span class=\"n\">append</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">)</span>\n</code></pre></div>    </div>\n  </li>\n  <li>\n    <p>A new string and HTML representation of dask.dataframes.  Typically Pandas\nprints dataframes on the screen by rendering the first few rows of data.\nHowever, Because Dask.dataframes are lazy we don’t have this data and so\ntypically render some metadata about the dataframe</p>\n\n    <div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">df</span>  <span class=\"c1\"># version 0.13.0\n</span><span class=\"n\">dd</span><span class=\"p\">.</span><span class=\"n\">DataFrame</span><span class=\"o\">&lt;</span><span class=\"n\">make</span><span class=\"o\">-</span><span class=\"n\">ti</span><span class=\"p\">...,</span> <span class=\"n\">npartitions</span><span class=\"o\">=</span><span class=\"mi\">366</span><span class=\"p\">,</span> <span class=\"n\">divisions</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"n\">Timestamp</span><span class=\"p\">(</span><span class=\"s\">'2000-01-01\n00:00:00'</span><span class=\"p\">,</span> <span class=\"n\">freq</span><span class=\"o\">=</span><span class=\"s\">'D'</span><span class=\"p\">),</span> <span class=\"n\">Timestamp</span><span class=\"p\">(</span><span class=\"s\">'2000-01-02 00:00:00'</span><span class=\"p\">,</span> <span class=\"n\">freq</span><span class=\"o\">=</span><span class=\"s\">'D'</span><span class=\"p\">),</span>\n<span class=\"n\">Timestamp</span><span class=\"p\">(</span><span class=\"s\">'2000-01-03 00:00:00'</span><span class=\"p\">,</span> <span class=\"n\">freq</span><span class=\"o\">=</span><span class=\"s\">'D'</span><span class=\"p\">),</span> <span class=\"p\">...,</span> <span class=\"n\">Timestamp</span><span class=\"p\">(</span><span class=\"s\">'2000-12-31\n00:00:00'</span><span class=\"p\">,</span> <span class=\"n\">freq</span><span class=\"o\">=</span><span class=\"s\">'D'</span><span class=\"p\">),</span> <span class=\"n\">Timestamp</span><span class=\"p\">(</span><span class=\"s\">'2001-01-01 00:00:00'</span><span class=\"p\">,</span> <span class=\"n\">freq</span><span class=\"o\">=</span><span class=\"s\">'D'</span><span class=\"p\">))</span><span class=\"o\">&gt;</span>\n</code></pre></div>    </div>\n\n    <p>This rendering, while informative, can be improved.  Now we render\ndataframes as a Pandas dataframe, but place metadata in the dataframe\ninstead of the actual data.</p>\n\n    <div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">df</span>  <span class=\"c1\"># version 0.14.0\n</span><span class=\"n\">Dask</span> <span class=\"n\">DataFrame</span> <span class=\"n\">Structure</span><span class=\"p\">:</span>\n                       <span class=\"n\">x</span>        <span class=\"n\">y</span>      <span class=\"n\">z</span>\n<span class=\"n\">npartitions</span><span class=\"o\">=</span><span class=\"mi\">366</span>\n<span class=\"mi\">2000</span><span class=\"o\">-</span><span class=\"mi\">01</span><span class=\"o\">-</span><span class=\"mi\">01</span>       <span class=\"n\">float64</span>  <span class=\"n\">float64</span>  <span class=\"n\">int64</span>\n<span class=\"mi\">2000</span><span class=\"o\">-</span><span class=\"mi\">01</span><span class=\"o\">-</span><span class=\"mi\">02</span>           <span class=\"p\">...</span>      <span class=\"p\">...</span>    <span class=\"p\">...</span>\n<span class=\"p\">...</span>                  <span class=\"p\">...</span>      <span class=\"p\">...</span>    <span class=\"p\">...</span>\n<span class=\"mi\">2000</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">31</span>           <span class=\"p\">...</span>      <span class=\"p\">...</span>    <span class=\"p\">...</span>\n<span class=\"mi\">2001</span><span class=\"o\">-</span><span class=\"mi\">01</span><span class=\"o\">-</span><span class=\"mi\">01</span>           <span class=\"p\">...</span>      <span class=\"p\">...</span>    <span class=\"p\">...</span>\n<span class=\"n\">Dask</span> <span class=\"n\">Name</span><span class=\"p\">:</span> <span class=\"n\">make</span><span class=\"o\">-</span><span class=\"n\">timeseries</span><span class=\"p\">,</span> <span class=\"mi\">366</span> <span class=\"n\">tasks</span>\n</code></pre></div>    </div>\n\n    <p>Additionally this renders nicely as an HTML table in a Jupyter notebook</p>\n  </li>\n</ol>\n\n<h2 id=\"variety-of-distributed-system-changes\">Variety of Distributed System Changes</h2>\n\n<p>There have also been a wide variety of changes to the distributed system.  I’ll\ninclude a representative sample here to give a flavor of what has been\nhappening:</p>\n\n<ol>\n  <li>Ensure first-come-first-served priorities when dealing with multiple\nclients</li>\n  <li>\n    <p>Send small amounts of data through Channels.  Channels are a way for\nmultiple clients/users connected to the same scheduler to publish and\nexchange data between themselves.  Previously they only transmitted Futures\n(which could in trun point to larger data living on the cluster).  However\nwe found that it was useful to communicate small bits of metadata as well,\nfor example to signal progress or stopping critera between clients\ncollaborating on the same workloads.  Now you can publish any msgpack\nserializable data on Channels.</p>\n\n    <div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\"># Publishing Client\n</span><span class=\"n\">scores</span> <span class=\"o\">=</span> <span class=\"n\">client</span><span class=\"p\">.</span><span class=\"n\">channel</span><span class=\"p\">(</span><span class=\"s\">'scores'</span><span class=\"p\">)</span>\n<span class=\"n\">scores</span><span class=\"p\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"mf\">123.456</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Subscribing Client\n</span><span class=\"n\">scores</span> <span class=\"o\">=</span> <span class=\"n\">client</span><span class=\"p\">.</span><span class=\"n\">channel</span><span class=\"p\">(</span><span class=\"s\">'scores'</span><span class=\"p\">)</span>\n<span class=\"k\">while</span> <span class=\"n\">scores</span><span class=\"p\">.</span><span class=\"n\">data</span><span class=\"p\">[</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"o\">&lt;</span> <span class=\"n\">THRESHOLD</span><span class=\"p\">:</span>\n    <span class=\"p\">...</span> <span class=\"k\">continue</span> <span class=\"n\">working</span> <span class=\"p\">...</span>\n</code></pre></div>    </div>\n  </li>\n  <li>We’re better at estimating the size in data of SciPy Sparse matrices and\nKeras models.  This allows Dask to make smarter choices about when it\nshould and should not move data around for load balancing.  Additionally\nDask can now also serialize Keras models.</li>\n  <li>\n    <p>To help people deploying on clusters that have a shared network file system\n(as is often the case in scientific or academic institutions) the scheduler\nand workers can now communicate connection information using the\n<code class=\"language-plaintext highlighter-rouge\">--scheduler-file</code> keyword</p>\n\n    <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>dask-scheduler --scheduler-file /path/to/scheduler.json\ndask-worker --scheduler-file /path/to/scheduler.json\ndask-worker --scheduler-file /path/to/scheduler.json\n\n&gt;&gt;&gt; client = Client(scheduler_file='/path/to/scheudler.json')\n</code></pre></div>    </div>\n\n    <p>Previously we needed to communicate the address of the scheduler, which\ncould be challenging when we didn’t know on which node the scheduler would\nbe run.</p>\n  </li>\n</ol>\n\n<h2 id=\"other\">Other</h2>\n\n<p>There are a number of smaller details not mentioned in this blogpost.  For more\ninformation visit the changelogs and documentation</p>\n\n<ul>\n  <li><a href=\"http://dask.pydata.org/en/latest/\">Dask/dask docs</a></li>\n  <li><a href=\"http://dask.pydata.org/en/latest/changelog.html\">Dask/dask changelog</a></li>\n  <li><a href=\"http://distributed.readthedocs.org/en/latest/\">Dask/distributed docs</a></li>\n  <li><a href=\"http://distributed.readthedocs.org/en/latest/changelog.html\">Dask/distributed changelog</a></li>\n</ul>\n\n<p>Additionally a great deal of Dask work over the last month has happened\n<em>outside</em> of these core dask repositories.</p>\n\n<p>You can install or upgrade using Conda or Pip</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>conda install -c conda-forge dask distributed\n</code></pre></div></div>\n\n<p>or</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>pip install dask[complete] distributed --upgrade\n</code></pre></div></div>\n\n<h2 id=\"acknowledgements\">Acknowledgements</h2>\n\n<p>Since the last 0.13.0 release on January 27th the following developers have\ncontributed to the dask/dask repository:</p>\n\n<ul>\n  <li>Antoine Pitrou</li>\n  <li>Chris Barber</li>\n  <li>Daniel Davis</li>\n  <li>Elmar Ritsch</li>\n  <li>Erik Welch</li>\n  <li>jakirkham</li>\n  <li>Jim Crist</li>\n  <li>John Crickett</li>\n  <li>jspreston</li>\n  <li>Juan Luis Cano Rodríguez</li>\n  <li>kayibal</li>\n  <li>Kevin Ernst</li>\n  <li>Markus Gonser</li>\n  <li>Matthew Rocklin</li>\n  <li>Martin Durant</li>\n  <li>Nir</li>\n  <li>Sinhrks</li>\n  <li>Talmaj Marinc</li>\n  <li>Vlad Frolov</li>\n  <li>Will Warner</li>\n</ul>\n\n<p>And the following developers have contributed to the dask/distributed\nrepository:</p>\n\n<ul>\n  <li>Antoine Pitrou</li>\n  <li>Ben Schreck</li>\n  <li>bmaisonn</li>\n  <li>Brett Naul</li>\n  <li>Demian Wassermann</li>\n  <li>Israel Saeta Pérez</li>\n  <li>John Crickett</li>\n  <li>Joseph Crail</li>\n  <li>Malte Gerken</li>\n  <li>Martin Durant</li>\n  <li>Matthew Rocklin</li>\n  <li>Min RK</li>\n  <li>strets123</li>\n</ul>"
}