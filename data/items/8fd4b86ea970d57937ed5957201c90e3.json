{
  "title": "A machine learning approach for fighting the curse of dimensionality in global optimization. (arXiv:2110.14985v2 [cs.LG] UPDATED)",
  "link": "http://arxiv.org/abs/2110.14985",
  "description": "<p>Finding global optima in high-dimensional optimization problems is extremely\nchallenging since the number of function evaluations required to sufficiently\nexplore the search space increases exponentially with its dimensionality.\nFurthermore, multimodal cost functions render local gradient-based search\ntechniques ineffective. To overcome these difficulties, we propose to trim\nuninteresting regions of the search space where global optima are unlikely to\nbe found by means of autoencoders, exploiting the lower intrinsic\ndimensionality of certain cost functions; optima are then searched over\nlower-dimensional latent spaces. The methodology is tested on benchmark\nfunctions and on multiple variations of a structural topology optimization\nproblem, where we show that we can estimate this intrinsic lower dimensionality\nand based thereon obtain the global optimum at best or superior results\ncompared to established optimization procedures at worst.\n</p>",
  "dc:creator": "<a href=\"http://arxiv.org/find/cs/1/au:+Schumann_J/0/1/0/all/0/1\">Julian F. Schumann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aragon_A/0/1/0/all/0/1\">Alejandro M. Arag&#xf3;n</a>"
}