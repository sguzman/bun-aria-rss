{
  "title": "Tay: A Teenage Bot Gone Rogue",
  "link": "https://malicious.life/tay-a-teenage-bot-gone-rouge/",
  "pubDate": "Tue, 30 Nov 2021 16:51:34 +0000",
  "guid": "https://malicious.life/?p=1471",
  "comments": "https://malicious.life/tay-a-teenage-bot-gone-rouge/#respond",
  "wfw:commentRss": "https://malicious.life/tay-a-teenage-bot-gone-rouge/feed/",
  "slash:comments": 0,
  "category": "Uncategorized",
  "description": "In March, 2016, Microsoft had something exciting to tell the world: the tech giant unveiled an AI chatbot with the personality of a teenager. Microsoft Tay - as it was nicknamed - could tweet, answer questions and even make its own memes. But within mere hours of going live, Tay began outputting racist, anti-Semitic and misogynist tweets.",
  "content:encoded": "\n<hr class=\"wp-block-separator\"/>\n\n\n\n<p>In March 2016, Microsoft had something exciting to tell the world: the tech giant unveiled an AI chatbot with the personality of a teenager. Microsoft Tay &#8211; as it was nicknamed &#8211; could tweet, answer questions and even make its own memes. But within mere hours of going live, Tay began outputting racist, anti-Semitic, and misogynist tweets.</p>\n",
  "enclosure": "",
  "itunes:subtitle": "In March, 2016, Microsoft had something exciting to tell the world: the tech giant unveiled an AI chatbot with the personality of a teenager. Microsoft Tay - as it was nicknamed - could tweet, answer questions and even make its own memes.",
  "itunes:summary": "In March, 2016, Microsoft had something exciting to tell the world: the tech giant unveiled an AI chatbot with the personality of a teenager. Microsoft Tay - as it was nicknamed - could tweet, answer questions and even make its own memes. But within mere hours of going live, Tay began outputting racist, anti-Semitic and misogynist tweets.",
  "itunes:author": "Cybereason",
  "itunes:image": "",
  "itunes:duration": "28:45"
}