{
  "title": "Speeding up NAS with Adaptive Subset Selection. (arXiv:2211.01454v1 [cs.LG])",
  "link": "http://arxiv.org/abs/2211.01454",
  "description": "<p>A majority of recent developments in neural architecture search (NAS) have\nbeen aimed at decreasing the computational cost of various techniques without\naffecting their final performance. Towards this goal, several low-fidelity and\nperformance prediction methods have been considered, including those that train\nonly on subsets of the training data. In this work, we present an adaptive\nsubset selection approach to NAS and present it as complementary to\nstate-of-the-art NAS approaches. We uncover a natural connection between\none-shot NAS algorithms and adaptive subset selection and devise an algorithm\nthat makes use of state-of-the-art techniques from both areas. We use these\ntechniques to substantially reduce the runtime of DARTS-PT (a leading one-shot\nNAS algorithm), as well as BOHB and DEHB (leading multifidelity optimization\nalgorithms), without sacrificing accuracy. Our results are consistent across\nmultiple datasets, and towards full reproducibility, we release our code at\nhttps: //anonymous.4open.science/r/SubsetSelection NAS-B132.\n</p>",
  "dc:creator": "<a href=\"http://arxiv.org/find/cs/1/au:+C_V/0/1/0/all/0/1\">Vishak Prasad C</a>, <a href=\"http://arxiv.org/find/cs/1/au:+White_C/0/1/0/all/0/1\">Colin White</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_P/0/1/0/all/0/1\">Paarth Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nayak_S/0/1/0/all/0/1\">Sibasis Nayak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramakrishnan_G/0/1/0/all/0/1\">Ganesh Ramakrishnan</a>"
}