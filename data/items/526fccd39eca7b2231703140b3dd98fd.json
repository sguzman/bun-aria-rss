{
  "title": "156 | Catherine D’Ignazio on Data, Objectivity, and Bias",
  "description": "<p>How can data be biased? Isn’t it supposed to be an objective reflection of the real world? We all know that these are somewhat naive rhetorical questions, since data can easily inherit bias from the people who collect and analyze it, just as an algorithm can make biased suggestions if it’s trained on biased datasets. A better question is, how do biases creep in, and what can we do about them? Catherine D’Ignazio is an MIT professor who has studied how biases creep into our data and algorithms, and even into the expression of values that purport to protect objective analysis. We discuss examples of these processes and how to use data to make things better.</p><p><em>Support Mindscape on&nbsp;</em><a href=\"https://www.patreon.com/seanmcarroll\" rel=\"noopener noreferrer\" target=\"_blank\"><em>Patreon</em></a><em>.</em></p><p>Catherine D’Ignazio received a Master of Fine Arts from Maine College of Art and a Master of Science in Media Arts and Sciences from the MIT Media Lab. She is currently an assistant professor of Urban Science and Planning and Director of the Data+Feminism Lab at MIT. She is the co-author, with Lauren F. Klein, of the book&nbsp;<a href=\"https://mitpress.mit.edu/books/data-feminism\" rel=\"noopener noreferrer\" target=\"_blank\"><em>Data Feminism</em></a>.</p><ul><li><a href=\"http://www.kanarinka.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Web site</a></li><li><a href=\"https://dusp.mit.edu/faculty/catherine-dignazio\" rel=\"noopener noreferrer\" target=\"_blank\">MIT web page</a></li><li><a href=\"https://scholar.google.com/citations?user=yHJdpokAAAAJ&hl=en\" rel=\"noopener noreferrer\" target=\"_blank\">Google Scholar publications</a></li><li><a href=\"https://dataplusfeminism.mit.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">Data + Feminism Lab</a></li><li><a href=\"https://en.wikipedia.org/wiki/Catherine_D%27Ignazio\" rel=\"noopener noreferrer\" target=\"_blank\">Wikipedia</a></li><li><a href=\"https://twitter.com/kanarinka\" rel=\"noopener noreferrer\" target=\"_blank\">Twitter</a></li></ul><p><br></p><p>See Privacy Policy at <a href=\"https://art19.com/privacy\" rel=\"noopener noreferrer\" target=\"_blank\">https://art19.com/privacy</a> and California Privacy Notice at <a href=\"https://art19.com/privacy#do-not-sell-my-info\" rel=\"noopener noreferrer\" target=\"_blank\">https://art19.com/privacy#do-not-sell-my-info</a>.</p>",
  "itunes:title": "Catherine D’Ignazio on Data, Objectivity, and Bias",
  "itunes:episodeType": "full",
  "itunes:episode": 156,
  "itunes:summary": "I speak with data scientist Catherine D'Ignazio about the ways in which data and algorithms can be biased, and the ways in which data can be used to correct against bias.",
  "content:encoded": "<p>How can data be biased? Isn’t it supposed to be an objective reflection of the real world? We all know that these are somewhat naive rhetorical questions, since data can easily inherit bias from the people who collect and analyze it, just as an algorithm can make biased suggestions if it’s trained on biased datasets. A better question is, how do biases creep in, and what can we do about them? Catherine D’Ignazio is an MIT professor who has studied how biases creep into our data and algorithms, and even into the expression of values that purport to protect objective analysis. We discuss examples of these processes and how to use data to make things better.</p><p><em>Support Mindscape on&nbsp;</em><a href=\"https://www.patreon.com/seanmcarroll\" rel=\"noopener noreferrer\" target=\"_blank\"><em>Patreon</em></a><em>.</em></p><p>Catherine D’Ignazio received a Master of Fine Arts from Maine College of Art and a Master of Science in Media Arts and Sciences from the MIT Media Lab. She is currently an assistant professor of Urban Science and Planning and Director of the Data+Feminism Lab at MIT. She is the co-author, with Lauren F. Klein, of the book&nbsp;<a href=\"https://mitpress.mit.edu/books/data-feminism\" rel=\"noopener noreferrer\" target=\"_blank\"><em>Data Feminism</em></a>.</p><ul><li><a href=\"http://www.kanarinka.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Web site</a></li><li><a href=\"https://dusp.mit.edu/faculty/catherine-dignazio\" rel=\"noopener noreferrer\" target=\"_blank\">MIT web page</a></li><li><a href=\"https://scholar.google.com/citations?user=yHJdpokAAAAJ&hl=en\" rel=\"noopener noreferrer\" target=\"_blank\">Google Scholar publications</a></li><li><a href=\"https://dataplusfeminism.mit.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">Data + Feminism Lab</a></li><li><a href=\"https://en.wikipedia.org/wiki/Catherine_D%27Ignazio\" rel=\"noopener noreferrer\" target=\"_blank\">Wikipedia</a></li><li><a href=\"https://twitter.com/kanarinka\" rel=\"noopener noreferrer\" target=\"_blank\">Twitter</a></li></ul><p><br></p><p>See Privacy Policy at <a href=\"https://art19.com/privacy\" rel=\"noopener noreferrer\" target=\"_blank\">https://art19.com/privacy</a> and California Privacy Notice at <a href=\"https://art19.com/privacy#do-not-sell-my-info\" rel=\"noopener noreferrer\" target=\"_blank\">https://art19.com/privacy#do-not-sell-my-info</a>.</p>",
  "guid": "gid://art19-episode-locator/V0/CXiLE3AYQt-xp26qqLLoiVyTvsastOpjjZDcOw-m2Q4",
  "pubDate": "Mon, 19 Jul 2021 15:57:54 -0000",
  "itunes:explicit": "no",
  "itunes:image": "",
  "itunes:keywords": "CULTURE,philosophy,society,Science,ideas,data,bias,feminism",
  "itunes:duration": "01:28:13",
  "enclosure": ""
}