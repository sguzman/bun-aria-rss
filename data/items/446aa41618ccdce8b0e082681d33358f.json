{
  "title": "Build a web scraper for a literature search - from soup to nuts",
  "link": "",
  "published": "2015-08-25T17:43:00-07:00",
  "updated": "2015-08-25T17:43:00-07:00",
  "author": {
    "name": "Cathy Yeh"
  },
  "id": "tag:efavdb.com,2015-08-25:/build-a-web-scraper-lit-search",
  "summary": "<p><em>Code, references, and examples of this project are on <a href=\"https://github.com/EFavDB/PubmedCentral_Scraper\">Github</a>.</em></p>\n<p>In this post, I&#8217;ll describe the soup to nuts process of automating a literature search in <a href=\"http://www.ncbi.nlm.nih.gov/pmc/\">Pubmed Central</a> using&nbsp;R.</p>\n<p>It feels deeply satisfying to sit back and let the code do the dirty&nbsp;work.</p>\n<p>Is it as satisfying …</p>",
  "content": "<p><em>Code, references, and examples of this project are on <a href=\"https://github.com/EFavDB/PubmedCentral_Scraper\">Github</a>.</em></p>\n<p>In this post, I&#8217;ll describe the soup to nuts process of automating a literature search in <a href=\"http://www.ncbi.nlm.nih.gov/pmc/\">Pubmed Central</a> using&nbsp;R.</p>\n<p>It feels deeply satisfying to sit back and let the code do the dirty&nbsp;work.</p>\n<p>Is it as satisfying as a bowl of red-braised beef noodle soup with melt-in-your-mouth tendons from Taipei&#8217;s Yong Kang Restaurant (featured&nbsp;image)?</p>\n<p>If you have to do a lit search like this more than once, then I have to say the answer is yes &#8212; unequivocally,&nbsp;yes.</p>\n<p>The three components of the project&nbsp;are</p>\n<p><a href=\"#Section1\">I. Design a database to store the contents of a scraping session</a>\n<a href=\"#Section2\"><span class=\"caps\">II</span>. Extract information via an <span class=\"caps\">API</span> and web scraper</a>\n<a href=\"#Section3\"><span class=\"caps\">III</span>. Generate summary&nbsp;reports</a></p>\n<p>If you want to skip the explanations and go straight to using the program, check out the quick-start <span class=\"caps\">HTML5</span> <a href=\"https://efavdb.com/wp-content/uploads/2015/08/PubmedCentralSlides.html\">presentation</a> or <a href=\"https://efavdb.com/wp-content/uploads/2015/08/scraper_manual.html\">manual</a> and an example of a <a href=\"https://github.com/EFavDB/PubmedCentral_Scraper/blob/master/example/scraper_TGI_plots_for_trastuzumab.md\">report</a> generated by this&nbsp;project.</p>\n<hr>\n<p>The task is to capture plots of tumor growth inhibition (<span class=\"caps\">TGI</span>), i.e. tumor growth as a function of time, in animals treated with a particular cancer drug, then aggregate all the plots in a summary&nbsp;report.</p>\n<p>An example of a <span class=\"caps\">TGI</span> plot is provided below (source: <a href=\"http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3792566/\" title=\"PMC3792566\">Qi 2011</a>) for <span class=\"caps\">TGI</span> in mice treated with the cancer drug,&nbsp;Docetaxel.</p>\n<p><a href=\"https://efavdb.com/wp-content/uploads/2015/07/TGIplot.png\"><img alt=\"\" src=\"https://efavdb.com/wp-content/uploads/2015/07/TGIplot-300x217.png\"></a></p>\n<p><span class=\"caps\">TGI</span> plots for several drugs (image credit: Qi&nbsp;2011)</p>\n<p>Since the scraper was intended for a casual (non-exhaustive) literature search, I decided to confine the search to online articles in Pubmed Central (as opposed to Pubmed in general) since they are entirely open-access and available in a mostly uniform&nbsp;format.</p>\n<hr>\n<h2>I. Set up the the&nbsp;database</h2>\n<p>This project called for data storage beyond the scope of data frames and external flat files, e.g. Excel spreadsheets or csv files, since the following attributes were required of the&nbsp;data:</p>\n<ul>\n<li>Persistence outside the R environment =&gt; data frames&nbsp;unsuitable</li>\n<li>Ease of access and manipulation =&gt; writing to and reading from text/csv files would be&nbsp;cumbersome</li>\n<li>The data would be structured =&gt; relational&nbsp;database</li>\n</ul>\n<p>With a view towards expediency, we cover just enough to get things up and running and leave the finer details of relational database design to the&nbsp;experts.</p>\n<p><a href=\"http://www.sqlite.org/about.html\" title=\"SQLite\">SQLite</a> is well-suited for this small project; it&#8217;s self-contained and doesn&#8217;t require fussing with servers. To lower the barrier even further, the <a href=\"http://cran.r-project.org/web/packages/RSQLite/index.html\" title=\"RSQLite\">RSQLite</a> package embeds SQLite in R (no separate installation needed) and allows you to very easily interface with your database within the R environment. The database itself is stored in a single file on your hard disk and easily&nbsp;transferred.</p>\n<h3>What data will be&nbsp;collected?</h3>\n<p>The first step is to decide what data should be collected during the web scraping process. We want to aggregate images of plots in a (html)&nbsp;report.</p>\n<p>However, downloading the images themselves is inefficient; instead, we&#8217;ll just grab the image URLs on Pubmed Central. (The image URLs are useful because they can be referred to by markdown code to embed the images in the html&nbsp;report.)</p>\n<p>The image urls should be captured, along with associated information&nbsp;below:</p>\n<hr>\n<p><strong>image data</strong>                         image url, figure name in the article, image caption\n  <strong>article metadata</strong>                   Pubmed Central id, <span class=\"caps\">DOI</span>, title, journal, year of publication, authors, abstracts, keywords\n  <strong>search criteria met by the image</strong>   topic/drug, type of&nbsp;plot</p>\n<hr>\n<p>The last point addresses the foreseeable need to be able to modify the search parameters. In the next section, we allow for the possibility that the same image might show up for more than one kind of drug or plot&nbsp;type.</p>\n<h3>Decide on a layout for the&nbsp;database</h3>\n<p>After pinning down the content itself, the next step is to decide how it should be arranged in the database.&nbsp;Namely,</p>\n<ul>\n<li>What tables are&nbsp;needed?</li>\n<li>Which fields go in which&nbsp;tables?</li>\n<li>How do the tables relate to one&nbsp;another?</li>\n</ul>\n<p>This particularly helpful <a href=\"http://db.grussell.org/section008.html\" title=\"normalization\">page</a> walks you through the concept of database normalization by providing lots of concrete examples, including &#8220;anomalies&#8221; that arise in poorly designed&nbsp;databases.</p>\n<p>Some ideas on normalization are intuitive. Let&#8217;s take a look at how to restructure a table to satisfy first normal form (<span class=\"caps\">1NF</span>). The table below is not in <span class=\"caps\">1NF</span> because it contains sets of values within single&nbsp;rows.</p>\n<table>\n<thead>\n<tr>\n<th>student_id</th>\n<th>name</th>\n<th>subjects</th>\n<th>grades</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1234</td>\n<td>Andrew</td>\n<td>a.i. <br> linear algebra <br> physics</td>\n<td>A <br> A <br> B+</td>\n</tr>\n<tr>\n<td>5678</td>\n<td>Yaser</td>\n<td>statistics <br> algorithms</td>\n<td>A- <br> A</td>\n</tr>\n</tbody>\n</table>\n<p>Instead, we can break it up into two&nbsp;tables:</p>\n<p>table:&nbsp;student</p>\n<table>\n<thead>\n<tr>\n<th>student_id</th>\n<th>name</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1234</td>\n<td>Andrew</td>\n</tr>\n<tr>\n<td>5678</td>\n<td>Yaser</td>\n</tr>\n</tbody>\n</table>\n<p>table:grades:</p>\n<table>\n<thead>\n<tr>\n<th>student_id</th>\n<th>subject</th>\n<th>grade</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1234</td>\n<td>a.i.</td>\n<td>A</td>\n</tr>\n<tr>\n<td>1234</td>\n<td>linear algebra</td>\n<td>A</td>\n</tr>\n<tr>\n<td>1234</td>\n<td>physics</td>\n<td>B+</td>\n</tr>\n<tr>\n<td>5678</td>\n<td>statistics</td>\n<td>A-</td>\n</tr>\n<tr>\n<td>5678</td>\n<td>algorithms</td>\n<td>A</td>\n</tr>\n</tbody>\n</table>\n<p>Column names that are primary keys are underlined. A primary key is a column, or combination of columns, whose values uniquely identify a row in a table (and accordingly guards against duplicate rows). In a first go at a schema, a table without a logical primary key reared its ugly&nbsp;head:</p>\n<table>\n<thead>\n<tr>\n<th>pmcid</th>\n<th>topic</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>123456</td>\n<td>drug A</td>\n</tr>\n<tr>\n<td>123456</td>\n<td>drug B</td>\n</tr>\n<tr>\n<td>100000</td>\n<td>drug A</td>\n</tr>\n</tbody>\n</table>\n<p>Note that the <strong>pmcid</strong> value is not guaranteed to be unique in the above table because the same article may show up in searches for multiple drugs. This situation hinted at the need to restructure the tables. We finally settled on the three tables below, which all had natural primary keys&nbsp;(underlined):</p>\n<p>table:&nbsp;article</p>\n<table>\n<thead>\n<tr>\n<th>pmcid</th>\n<th>doi</th>\n<th>title</th>\n<th>journal</th>\n<th>year</th>\n<th>authors</th>\n<th>abstract</th>\n<th>keywords</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<p>table:&nbsp;figure</p>\n<table>\n<thead>\n<tr>\n<th>topic</th>\n<th>plot_type</th>\n<th>img_url</th>\n<th>pmc_id</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<p>table:&nbsp;figure_text</p>\n<table>\n<thead>\n<tr>\n<th>img_url</th>\n<th>fig_name</th>\n<th>caption</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<p><a href=\"https://efavdb.com/wp-content/uploads/2015/07/a_hanging.jpg\"><img alt=\"\" src=\"https://efavdb.com/wp-content/uploads/2015/07/a_hanging-263x300.jpg\"></a></p>\n<p>Their tables were not in <span class=\"caps\">1NF</span>.</p>\n<p>The tables &#8220;figure&#8221; and &#8220;figure_text&#8221; are kept separate in order to minimize redundancies. For instance, the same img_url can appear in the table &#8220;figure&#8221; multiple times if it matches a number of different drugs or plot types, but its caption would only need to be stored once in the table&nbsp;&#8220;figure_text&#8221;.</p>\n<p>The table &#8220;figure&#8221; is not in second normal form (<span class=\"caps\">2NF</span>) because of a partial key dependency; the pmcid field only depends on img_url, rather than the entire composite key {topic, plot_type, and&nbsp;img_url}.</p>\n<p>Although the normalization rules sound a bit intimidating, they are just guidelines&#8212;apparently, one can even get carried away with&nbsp;over-normalizing.</p>\n<p>The database has held up fine so far, but any suggestions on how to improve the design are very&nbsp;welcome!</p>\n<h3>Creating a SQLite database in&nbsp;R</h3>\n<p>With a schema in hand, creating the SQLite database in R is a matter of minutes. First, we load the packages for interfacing with the&nbsp;database.</p>\n<div class=\"highlight\"><pre><span></span><span class=\"nf\">library</span><span class=\"p\">(</span><span class=\"n\">DBI</span><span class=\"p\">)</span>\n<span class=\"nf\">library</span><span class=\"p\">(</span><span class=\"n\">RSQLite</span><span class=\"p\">)</span>\n</pre></div>\n\n\n<p>Then we create a connection to the database, which we&#8217;ll call&nbsp;&#8220;myDb.sqlite&#8221;.</p>\n<div class=\"highlight\"><pre><span></span><span class=\"n\">con</span> <span class=\"o\">=</span> <span class=\"nf\">dbConnect</span><span class=\"p\">(</span><span class=\"nf\">SQLite</span><span class=\"p\">(),</span> <span class=\"n\">dbname</span> <span class=\"o\">=</span> <span class=\"s\">&quot;myDb.sqlite&quot;</span><span class=\"p\">)</span>\n</pre></div>\n\n\n<p>Next, we create the three tables &#8220;article&#8221;, &#8220;figure&#8221;, and&nbsp;&#8220;figure_text&#8221;.</p>\n<p>create figure_text&nbsp;table:</p>\n<div class=\"highlight\"><pre><span></span><span class=\"n\">query</span> <span class=\"o\">=</span> <span class=\"s\">&#39;CREATE TABLE figure_text(img_url TEXT, fig_name TEXT, caption TEXT, PRIMARY KEY(img_url))&#39;</span>\n<span class=\"nf\">dbGetQuery</span><span class=\"p\">(</span><span class=\"n\">con</span><span class=\"p\">,</span> <span class=\"n\">query</span><span class=\"p\">)</span>\n</pre></div>\n\n\n<p>create figure&nbsp;table:</p>\n<div class=\"highlight\"><pre><span></span><span class=\"n\">query</span> <span class=\"o\">=</span> <span class=\"s\">&#39;CREATE TABLE figure(topic TEXT, plot_type TEXT, img_url TEXT, pmcid INTEGER, PRIMARY KEY(topic, plot_type, img_url))&#39;</span>\n<span class=\"nf\">dbGetQuery</span><span class=\"p\">(</span><span class=\"n\">con</span><span class=\"p\">,</span> <span class=\"n\">query</span><span class=\"p\">)</span>\n</pre></div>\n\n\n<p>create article&nbsp;table:</p>\n<div class=\"highlight\"><pre><span></span><span class=\"n\">query</span> <span class=\"o\">=</span> <span class=\"s\">&#39;CREATE TABLE article(pmcid INTEGER, doi TEXT, title TEXT, journal TEXT, year INTEGER, authors TEXT, abstract TEXT, keywords TEXT, PRIMARY KEY(pmcid))&#39;</span>\n<span class=\"nf\">dbGetQuery</span><span class=\"p\">(</span><span class=\"n\">con</span><span class=\"p\">,</span> <span class=\"n\">query</span><span class=\"p\">)</span>\n</pre></div>\n\n\n<p>Last, we close the connection to the&nbsp;database.</p>\n<div class=\"highlight\"><pre><span></span><span class=\"nf\">dbDisconnect</span><span class=\"p\">(</span><span class=\"n\">con</span><span class=\"p\">)</span>\n</pre></div>\n\n\n<p>The SQLite database is now ready to be used! The script above is available on github as <code>createSQLiteDatabase.R</code></p>\n<hr>\n<h2><span class=\"caps\">II</span>. Scrape Pubmed Central&nbsp;articles</h2>\n<p>The script <code>pubmedcentral_scraper.R</code> is where the action happens. It takes input from the user to query the Pubmed Central Database, scrape articles, and load the extracted information into the&nbsp;database.</p>\n<h3>Input keywords for literature search and labels in&nbsp;database</h3>\n<p>The user input section is shown&nbsp;below.</p>\n<div class=\"highlight\"><pre><span></span><span class=\"c1\">## &lt;---------USER INPUT STARTS HERE---------&gt;</span>\n\n<span class=\"c1\">## name of database where scraper results are stored</span>\n<span class=\"n\">database.name</span> <span class=\"o\">=</span> <span class=\"s\">&quot;myDb.sqlite&quot;</span>\n\n<span class=\"c1\">## maximum number of results to retrieve from query</span>\n<span class=\"n\">retmax</span> <span class=\"o\">=</span> <span class=\"m\">10</span>\n\n<span class=\"c1\">## topic terms to be queried via the pubmed search engine</span>\n<span class=\"n\">query.topic</span> <span class=\"o\">=</span> <span class=\"nf\">c</span><span class=\"p\">(</span><span class=\"s\">&quot;Docetaxel&quot;</span><span class=\"p\">,</span> <span class=\"s\">&quot;Docetaxol&quot;</span><span class=\"p\">)</span>\n\n<span class=\"c1\">## keywords to identify plot type to be captured</span>\n<span class=\"c1\">## terms should be lower-case</span>\n<span class=\"n\">query.plottype</span> <span class=\"o\">=</span> <span class=\"nf\">c</span><span class=\"p\">(</span><span class=\"s\">&quot;tumor growth&quot;</span><span class=\"p\">,</span> <span class=\"s\">&quot;tumor volume&quot;</span><span class=\"p\">,</span>\n                    <span class=\"s\">&quot;tumor size&quot;</span><span class=\"p\">,</span> <span class=\"s\">&quot;tumor inhibition&quot;</span><span class=\"p\">,</span>\n                    <span class=\"s\">&quot;tumor growth inhibition&quot;</span><span class=\"p\">,</span> <span class=\"s\">&quot;tgi&quot;</span><span class=\"p\">,</span>\n                    <span class=\"s\">&quot;tumor response&quot;</span><span class=\"p\">,</span> <span class=\"s\">&quot;tumor regression&quot;</span><span class=\"p\">)</span>\n</pre></div>\n\n\n<p>The user input for variables <code>query.topic</code> and <code>query.plottype</code> are used to construct the query to Pubmed Central via the Entrez Programming Utilities interface (details in the <a href=\"http://www.ncbi.nlm.nih.gov/books/NBK25499/\">E-utilities guide</a>), made available through the <a href=\"http://www.ncbi.nlm.nih.gov/\">National Center for Biotechnology</a> (<span class=\"caps\">NCBI</span>). To maximize hits to the query, the user can supply multiple terms for each&nbsp;variable.</p>\n<div class=\"highlight\"><pre><span></span><span class=\"c1\">## topic/drug label for database</span>\n<span class=\"n\">topic</span> <span class=\"o\">=</span> <span class=\"s\">&quot;Docetaxel&quot;</span>\n\n<span class=\"c1\">## plot type label for database</span>\n<span class=\"n\">plot_type</span> <span class=\"o\">=</span> <span class=\"s\">&quot;TGI&quot;</span>\n\n<span class=\"c1\">## &lt;---------USER INPUT ENDS HERE-----------&gt;</span>\n</pre></div>\n\n\n<p>The variables <code>topic</code> and <code>plot_type</code> label the data in the SQLite database (the labels should be consistent between queries in order to simplify the information retrieval process, e.g. stick to one spelling convention for a particular drug, like &#8220;Docetaxel&#8221;, in&nbsp;myDb.sqlite).</p>\n<p>The first E-utility we will use is ESearch, which returns the <span class=\"caps\">PMC</span> ids of articles matching a query, along with other metadata. The E-utilities <span class=\"caps\">API</span> is extremely easy to use. Simply string together the set of parameters (<span class=\"caps\">NCBI</span> database name, utility name, etc.) and go to the <span class=\"caps\">URL</span>.</p>\n<div class=\"highlight\"><pre><span></span><span class=\"c1\">## compose url for eSearch</span>\n<span class=\"n\">url.esearch</span> <span class=\"o\">=</span> <span class=\"nf\">paste0</span><span class=\"p\">(</span><span class=\"n\">url.base</span><span class=\"p\">,</span> <span class=\"n\">esearch</span><span class=\"p\">,</span> <span class=\"n\">db</span><span class=\"p\">,</span> <span class=\"s\">&quot;&amp;&quot;</span><span class=\"p\">,</span> <span class=\"n\">retmax</span><span class=\"p\">,</span><span class=\"s\">&quot;&amp;&quot;</span><span class=\"p\">,</span> <span class=\"n\">sortmethod</span><span class=\"p\">,</span> <span class=\"s\">&quot;&amp;&quot;</span><span class=\"p\">,</span> <span class=\"n\">query</span><span class=\"p\">)</span>\n\n<span class=\"c1\">## get and parse xml data returned by eSearch</span>\n<span class=\"n\">data.esearch</span> <span class=\"o\">=</span> <span class=\"nf\">getURL</span><span class=\"p\">(</span><span class=\"n\">url.esearch</span><span class=\"p\">)</span>\n</pre></div>\n\n\n<p>The explicit <span class=\"caps\">URL</span> constructed from the above example user input is:\n<em>http://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pmc&amp;retmax=10&amp;sort=relevance&amp;term=(&#34;Docetaxel&#34;+<span class=\"caps\">OR</span>+&#34;Docetaxol&#34;)+<span class=\"caps\">AND</span>+(&#34;tumor+growth&#34;+<span class=\"caps\">OR</span>+&#34;tumor+volume&#34;+<span class=\"caps\">OR</span>+&#34;tumor+size&#34;+<span class=\"caps\">OR</span>+&#34;tumor+inhibition&#34;+<span class=\"caps\">OR</span>+&#34;tumor+growth+inhibition&#34;+<span class=\"caps\">OR</span>+&#34;tgi&#34;+<span class=\"caps\">OR</span>+&#34;tumor+response&#34;+<span class=\"caps\">OR</span>+&#34;tumor+regression&#34;)</em></p>\n<p>Try copying and pasting the above <span class=\"caps\">URL</span> in your browser to see a sample of the xml file returned by E-utilities. Here&#8217;s an excerpt of the <span class=\"caps\">XML</span> document from a query to ESearch on August 25,&nbsp;2015:</p>\n<p><a href=\"https://efavdb.com/wp-content/uploads/2015/08/esearchXML.jpg\"><img alt=\"\" src=\"https://efavdb.com/wp-content/uploads/2015/08/esearchXML-164x300.jpg\"></a></p>\n<p><span class=\"caps\">XML</span> output from a query to <span class=\"caps\">PMC</span> via the ESearch <span class=\"caps\">API</span>.</p>\n<p>We extract the <span class=\"caps\">PMC</span> ids, which are sandwiched between the <Id> <span class=\"caps\">XML</span> tags, using functions from the <span class=\"caps\">XML</span> and rvest&nbsp;packages:</p>\n<div class=\"highlight\"><pre><span></span><span class=\"n\">data.xml</span> <span class=\"o\">=</span> <span class=\"nf\">xmlParse</span><span class=\"p\">(</span><span class=\"n\">data.esearch</span><span class=\"p\">)</span>\n<span class=\"c1\">## get pmcid&#39;s</span>\n<span class=\"n\">pmcids</span> <span class=\"o\">=</span> <span class=\"n\">data.xml</span> <span class=\"o\">%&gt;%</span> <span class=\"nf\">xml_nodes</span><span class=\"p\">(</span><span class=\"s\">&quot;Id&quot;</span><span class=\"p\">)</span> <span class=\"o\">%&gt;%</span> <span class=\"nf\">xml_text</span><span class=\"p\">()</span>\n</pre></div>\n\n\n<p><code>%&gt;%</code> is a pipe operator for chaining commands (from the <a href=\"https://cran.r-project.org/web/packages/magrittr/index.html\">magrittr</a>&nbsp;package).</p>\n<p>The URLs of the html article can be simply constructed from their <span class=\"caps\">PMC</span> ids. For example, the html version of the article with <span class=\"caps\">PMC</span> id 3792566 is found at:&nbsp;http://www.ncbi.nlm.nih.gov/pmc/articles/3792566</p>\n<h3>Scrape <span class=\"caps\">HTML</span>&nbsp;articles</h3>\n<p>The scraping of the <span class=\"caps\">HTML</span> article is performed by <code>scrapeArticle.R</code>. Note, <span class=\"caps\">PMC</span> ids returned by ESearch which have already been scraped for that particular combination of search terms are&nbsp;skipped.</p>\n<p>The html version of the <span class=\"caps\">PMC</span> articles only show excerpts of captions, so we have to extract the individual figure URLs in order to scrape their full captions (and search for keyword matches). In order to extract a data element from an html document, we need to identify the tag associated with that&nbsp;element.</p>\n<p><a href=\"http://selectorgadget.com/\">SelectorGadget</a> is a nifty tool to help you hone in on the <span class=\"caps\">CSS</span> selectors of interest. Installation is ridiculously easy: just drag the link on the SelectorGadget page to your browser bookmark&nbsp;bar!</p>\n<p>For example, let&#8217;s identify the <span class=\"caps\">CSS</span> selector for figure URLs using SelectorGadget in 3 clicks of the mouse. We&#8217;ll demo SelectorGadget on a <span class=\"caps\">PMC</span> <a href=\"http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3792566/\">article</a> that is returned in a query on Docetaxel and <span class=\"caps\">TGI</span>.</p>\n<p>In the screenshot below, I clicked on the &#8220;Figure 3&#8221; link as a starting point for selecting all such figure URLs. SelectorGadget identified the element as &#8220;.figpopup&#8221; in the gray toolbar at the bottom of the screenshot, highlighted the direct click in green, and highlighted all the other elements in yellow (total: 35 elements). Notice, however, that two links to Figure 4 have been automatically highlighted in the screenshot, one of which is a reference in the body of the&nbsp;text.</p>\n<p><a href=\"https://efavdb.com/wp-content/uploads/2015/08/selectorgadg1.png\"><img alt=\"A click of the &quot;Figure 3&quot; link next to thumbnail highlights it in green, and similar elements are automatically highlighted in yellow.\" src=\"https://efavdb.com/wp-content/uploads/2015/08/selectorgadg1.png\"></a></p>\n<p>A click of the &#8220;Figure 3&#8221; link next to thumbnail highlights it in green. Similar elements are automatically highlighted in&nbsp;yellow.</p>\n<p>To reduce the number of redundant figure <span class=\"caps\">URL</span> links, I then clicked on the Figure 4 link in the body of the text in order to exclude it; it is accordingly highlighted in red to signify its&nbsp;exclusion.</p>\n<p>The pattern-matching is momentarily worsened since the link to Figure 4 (bottom) is no longer highlighted. SelectorGadget&#8217;s guess for the <span class=\"caps\">CSS</span> selector becomes &#8220;#lgnd_F3 .figpopup&#8221;, of which there is only one element, highlighted in&nbsp;green.</p>\n<p><a href=\"https://efavdb.com/wp-content/uploads/2015/08/selectorgadg2.png\"><img alt=\"Elements excluded from the pattern matching are highlighted in red.\" src=\"https://efavdb.com/wp-content/uploads/2015/08/selectorgadg2.png\"></a></p>\n<p>Elements excluded from the pattern matching are highlighted in&nbsp;red.</p>\n<p>After making the pattern match more specific with an exclusion, we have to re-generalize by re-selecting the Figure 4 bottom link. This time, SelectorGadget gets the pattern right with the <span class=\"caps\">CSS</span> selector &#8220;.icnblk_cntnt .figpopup&#8221;, which describes 5 elements on the&nbsp;page.</p>\n<p><a href=\"https://efavdb.com/wp-content/uploads/2015/08/selectorgadg3.png\"><img alt=\"Third time's the charm: SelectorGadget has honed in on the CSS selectors that match the desired figure URLs.\" src=\"https://efavdb.com/wp-content/uploads/2015/08/selectorgadg3.png\"></a></p>\n<p>Third time&#8217;s the charm: SelectorGadget has honed in on the <span class=\"caps\">CSS</span> selectors that match the desired figure&nbsp;URLs.</p>\n<p>Using rvest&#8217;s <code>xml_nodes</code> function, we extract components characterized by the <span class=\"caps\">CSS</span> selector <code>.icnblk_cntnt .figpopup</code> &#8212; namely, the URLs of tables and&nbsp;figures.</p>\n<div class=\"highlight\"><pre><span></span><span class=\"n\">popups.tags</span> <span class=\"o\">=</span> <span class=\"n\">article</span> <span class=\"o\">%&gt;%</span> <span class=\"nf\">xml_nodes</span><span class=\"p\">(</span><span class=\"s\">&quot;.icnblk_cntnt .figpopup&quot;</span><span class=\"p\">)</span>\n</pre></div>\n\n\n<p>With some more parsing and filtering similar to the above, the full image captions can be grepped for keywords. Caption and image metadata for keyword matches are stored in the SQLite database by <code>pubmedcentral_scraper.R</code>.</p>\n<hr>\n<h2><span class=\"caps\">III</span>. Generate a report of the scraped&nbsp;results</h2>\n<p>The results of the scraping can be examined by directly querying the SQLite&nbsp;database.</p>\n<p>I also put together an R script, <code>markdown_and_plot.R</code>, that automatically creates an html report in the simple case where only one topic and plot_type need to be included. The user only has to input the topic and plot_type, and the report is subsequently&nbsp;generated.</p>\n<p><code>markdown_and_plot.R</code> calls on <code>generate_markdown_code.R</code>, which extracts the image URLs from the&nbsp;database:</p>\n<div class=\"highlight\"><pre><span></span><span class=\"n\">query</span> <span class=\"o\">=</span> <span class=\"nf\">sprintf</span><span class=\"p\">(</span><span class=\"s\">&#39;</span><span class=\"err\">SELECT *\\</span>\n                    <span class=\"nf\">FROM </span><span class=\"p\">((</span><span class=\"n\">figure</span> <span class=\"n\">JOIN</span> <span class=\"n\">article</span> <span class=\"nf\">USING </span><span class=\"p\">(</span><span class=\"n\">pmcid</span><span class=\"p\">))</span><span class=\"n\">\\</span>\n                    <span class=\"n\">JOIN</span> <span class=\"n\">figure_text</span> <span class=\"nf\">USING </span><span class=\"p\">(</span><span class=\"n\">img_url</span><span class=\"p\">))</span><span class=\"n\">\\</span>\n                    <span class=\"nf\">WHERE </span><span class=\"p\">(</span><span class=\"n\">topic</span> <span class=\"o\">=</span> <span class=\"s\">&quot;%s&quot;</span> <span class=\"n\">AND</span> <span class=\"n\">plot_type</span> <span class=\"o\">=</span> <span class=\"s\">&quot;%s&quot;</span><span class=\"p\">)</span><span class=\"n\">\\</span>\n                    <span class=\"n\">ORDER</span> <span class=\"n\">BY</span> <span class=\"n\">pmcid</span> <span class=\"n\">ASC</span><span class=\"s\">&#39;</span><span class=\"err\">,topic, plot_type)</span>\n<span class=\"n\">images</span> <span class=\"o\">=</span> <span class=\"nf\">dbGetQuery</span><span class=\"p\">(</span><span class=\"n\">con</span><span class=\"p\">,</span> <span class=\"n\">query</span><span class=\"p\">)</span>\n\n<span class=\"c1\">## construct image URLs</span>\n<span class=\"n\">img_links</span> <span class=\"o\">=</span> <span class=\"nf\">paste0</span><span class=\"p\">(</span><span class=\"s\">&quot;http://www.ncbi.nlm.nih.gov&quot;</span><span class=\"p\">,</span> <span class=\"n\">images</span><span class=\"o\">$</span><span class=\"n\">img_url</span><span class=\"p\">)</span>\n</pre></div>\n\n\n<p><code>generate_markdown_code.R</code> then loops through the <em>i</em> images per article and, line by line, writes out markdown code of the image URLs and&nbsp;captions.</p>\n<div class=\"highlight\"><pre><span></span><span class=\"nf\">for</span><span class=\"p\">(</span><span class=\"n\">i</span> <span class=\"n\">in</span> <span class=\"nf\">seq_along</span><span class=\"p\">(</span><span class=\"n\">img_links</span><span class=\"p\">))</span> <span class=\"p\">{</span>\n<span class=\"c1\">## ...</span>\n<span class=\"n\">img_md</span> <span class=\"o\">=</span> <span class=\"nf\">paste0</span><span class=\"p\">(</span><span class=\"s\">&quot;![pmcid: &quot;</span><span class=\"p\">,</span><span class=\"n\">images</span><span class=\"o\">$</span><span class=\"n\">pmcid[i]</span><span class=\"p\">,</span><span class=\"s\">&quot;](\\`r img_links[&quot;</span><span class=\"p\">,</span><span class=\"n\">i</span><span class=\"p\">,</span><span class=\"s\">&quot;]\\`)&quot;</span><span class=\"p\">)</span>\n<span class=\"nf\">cat</span><span class=\"p\">(</span><span class=\"n\">img_md</span><span class=\"p\">,</span> <span class=\"n\">file</span><span class=\"o\">=</span><span class=\"n\">outfile</span><span class=\"p\">,</span> <span class=\"n\">append</span><span class=\"o\">=</span><span class=\"bp\">T</span><span class=\"p\">,</span> <span class=\"n\">sep</span><span class=\"o\">=</span><span class=\"s\">&quot;\\n&quot;</span><span class=\"p\">)</span>\n<span class=\"c1\">## ...</span>\n<span class=\"p\">}</span>\n</pre></div>\n\n\n<p><code>markdown_and_plot.R</code> then reads in the markdown file and renders it into the final html report, containing images embedded via href links, using the <code>knit2html</code> function in the knitr&nbsp;package.</p>\n<div class=\"highlight\"><pre><span></span><span class=\"n\">html.filename</span> <span class=\"o\">=</span> <span class=\"nf\">sprintf</span><span class=\"p\">(</span><span class=\"s\">&quot;scraper_%s_plots_for_%s.html&quot;</span><span class=\"p\">,</span> <span class=\"n\">plot_type</span><span class=\"p\">,</span> <span class=\"n\">topic</span><span class=\"p\">)</span>\n<span class=\"nf\">knit2html</span><span class=\"p\">(</span><span class=\"n\">md.filename</span><span class=\"p\">,</span> <span class=\"n\">output</span><span class=\"o\">=</span><span class=\"n\">html.filename</span><span class=\"p\">)</span>\n</pre></div>\n\n\n<p>For a sample report that was generated for topic = Trastuzumab and plot_type = <span class=\"caps\">TGI</span>, see <a href=\"https://github.com/EFavDB/PubmedCentral_Scraper/blob/master/example/scraper_TGI_plots_for_trastuzumab.md\">here</a>. Note, github automatically renders markdown files into html, whereas html files are displayed as source code. However, the file that is actually intended for human perusal outside Github is the <a href=\"https://github.com/EFavDB/PubmedCentral_Scraper/blob/master/example/scraper_TGI_plots_for_trastuzumab.html\">html</a> version, located in the same example subdirectory on&nbsp;Github.</p>\n<hr>\n<p>A look at the example report shows that there are a few false positives, i.e. images that don&#8217;t actually correspond to plots of <span class=\"caps\">TGI</span>, but the simplistic grep-keyword-method works well overall. There&#8217;s plenty of room for improving the code, but as it stands, this code sure beats compiling reports by&nbsp;hand!</p>\n<p>We&#8217;ve talked about the thought process behind building the program, but to put it to use, check it out on <a href=\"https://github.com/EFavDB/PubmedCentral_Scraper\">Github</a>.</p>",
  "category": [
    "",
    "",
    "",
    "",
    "",
    "",
    ""
  ]
}