{
  "title": "Dask Release 0.16.0",
  "link": "",
  "updated": "2017-11-21T00:00:00+00:00",
  "id": "https://mrocklin.github.io/blog/work/2017/11/21/dask-0.16.0",
  "content": "<p><em>This work is supported by <a href=\"http://anaconda.com\">Anaconda Inc.</a>\nand the Data Driven Discovery Initiative from the <a href=\"https://www.moore.org/\">Moore\nFoundation</a>.</em></p>\n\n<p>I’m pleased to announce the release of Dask version 0.16.0.  This is a major\nrelease with new features, breaking changes, and stability improvements.  This\nblogpost outlines notable changes since the 0.15.3 release on September 24th.</p>\n\n<p>You can conda install Dask:</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>conda install dask\n</code></pre></div></div>\n\n<p>or pip install from PyPI:</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>pip install dask[complete] --upgrade\n</code></pre></div></div>\n\n<p>Conda packages are available on both conda-forge and default channels.</p>\n\n<p>Full changelogs are available here:</p>\n\n<ul>\n  <li><a href=\"https://github.com/dask/dask/blob/master/docs/source/changelog.rst\">dask/dask</a></li>\n  <li><a href=\"https://github.com/dask/distributed/blob/master/docs/source/changelog.rst\">dask/distributed</a></li>\n</ul>\n\n<p>Some notable changes follow.</p>\n\n<h2 id=\"breaking-changes\">Breaking Changes</h2>\n\n<ul>\n  <li>The <code class=\"language-plaintext highlighter-rouge\">dask.async</code> module was moved to <code class=\"language-plaintext highlighter-rouge\">dask.local</code> for Python 3.7\ncompatibility.  This was previously deprecated and is now fully removed.</li>\n  <li>The distributed scheduler’s diagnostic JSON pages have been removed and\nreplaced by more informative templated HTML.</li>\n  <li>The use of commonly-used private methods <code class=\"language-plaintext highlighter-rouge\">_keys</code> and <code class=\"language-plaintext highlighter-rouge\">_optimize</code> have been\nreplaced with the Dask collection interface (see below).</li>\n</ul>\n\n<h2 id=\"dask-collection-interface\">Dask collection interface</h2>\n\n<p>It is now easier to implement custom collections using the Dask collection\ninterface.</p>\n\n<p>Dask collections (arrays, dataframes, bags, delayed) interact with Dask\nschedulers (single-machine, distributed) with a few internal methods.  We\nformalized this interface into protocols like <code class=\"language-plaintext highlighter-rouge\">.__dask_graph__()</code> and\n<code class=\"language-plaintext highlighter-rouge\">.__dask_keys__()</code> and have\n<a href=\"http://dask.pydata.org/en/latest/custom-collections.html\">published that interface</a>.\nAny object that implements the methods described in that document will interact\nwith all Dask scheduler features as a first-class Dask object.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">class</span> <span class=\"nc\">MyDaskCollection</span><span class=\"p\">(</span><span class=\"nb\">object</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"nf\">__dask_graph__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"p\">...</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">__dask_keys__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"p\">...</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">__dask_optimize__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"p\">...):</span>\n        <span class=\"p\">...</span>\n\n    <span class=\"p\">...</span>\n</code></pre></div></div>\n\n<p>This interface has already been implemented within the XArray project for\nlabeled and indexed arrays.  Now all XArray classes (DataSet, DataArray,\nVariable) are fully understood by all Dask schedulers.  They are as first-class\nas dask.arrays or dask.dataframes.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">import</span> <span class=\"nn\">xarray</span> <span class=\"k\">as</span> <span class=\"n\">xa</span>\n<span class=\"kn\">from</span> <span class=\"nn\">dask.distributed</span> <span class=\"kn\">import</span> <span class=\"n\">Client</span>\n\n<span class=\"n\">client</span> <span class=\"o\">=</span> <span class=\"n\">Client</span><span class=\"p\">()</span>\n\n<span class=\"n\">ds</span> <span class=\"o\">=</span> <span class=\"n\">xa</span><span class=\"p\">.</span><span class=\"n\">open_mfdataset</span><span class=\"p\">(</span><span class=\"s\">'*.nc'</span><span class=\"p\">,</span> <span class=\"p\">...)</span>\n\n<span class=\"n\">ds</span> <span class=\"o\">=</span> <span class=\"n\">client</span><span class=\"p\">.</span><span class=\"n\">persist</span><span class=\"p\">(</span><span class=\"n\">ds</span><span class=\"p\">)</span>  <span class=\"c1\"># XArray object integrate seamlessly with Dask schedulers\n</span></code></pre></div></div>\n\n<ul>\n  <li>Documentation:\n<a href=\"http://dask.pydata.org/en/latest/custom-collections.html\">http://dask.pydata.org/en/latest/custom-collections.html</a></li>\n</ul>\n\n<p><em>Work on Dask’s collection interfaces was primarily done by Jim Crist.</em></p>\n\n<h2 id=\"bandwidth-and-tornado-5-compatibility\">Bandwidth and Tornado 5 compatibility</h2>\n\n<p>Dask is built on the Tornado library for concurrent network programming. In an\neffort to improve inter-worker bandwidth on exotic hardware (Infiniband), Dask\ndevelopers are proposing changes to Tornado’s network infrastructure.</p>\n\n<p>However, in order to use these changes Dask itself needs to run on the next\nversion of Tornado in development, Tornado 5.0.0, which breaks a number of\ninterfaces on which Dask has relied.  Dask developers have been resolving these\nand we encourage other PyData developers to do the same. For example, neither\nBokeh nor Jupyter work on Tornado 5.0.0-dev.</p>\n\n<p>Dask inter-worker bandwidth is peaking at around 1.5-2GB/s on a network\ntheoretically capable of 3GB/s.  <a href=\"https://github.com/pangeo-data/pangeo/issues/6\">GitHub issue: pangeo #6</a></p>\n\n<p><a href=\"https://mrocklin.github.io/blog/images/bandwidth-plot.png\">\n  <img src=\"https://mrocklin.github.io/blog/images/bandwidth-plot.png\" alt=\"Dask worker bandwidth\" width=\"100%\" /></a></p>\n\n<p><em>Network performance and Tornado compatibility are primarily being handled by\nAntoine Pitrou.</em></p>\n\n<h2 id=\"parquet-compatibility\">Parquet Compatibility</h2>\n\n<p>Dask.dataframe can use either of the two common Parquet libraries in Python,\nApache Arrow and Fastparquet.  Each has its own strengths and its own base of\nusers who prefer it.  We’ve significantly extended Dask’s parquet test suite to\ncover each library, extending roundtrip compatibility.  Notably, you can now\nboth read and write with PyArrow.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">df</span><span class=\"p\">.</span><span class=\"n\">to_parquet</span><span class=\"p\">(</span><span class=\"s\">'...'</span><span class=\"p\">,</span> <span class=\"n\">engine</span><span class=\"o\">=</span><span class=\"s\">'fastparquet'</span><span class=\"p\">)</span>\n<span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">dd</span><span class=\"p\">.</span><span class=\"n\">read_parquet</span><span class=\"p\">(</span><span class=\"s\">'...'</span><span class=\"p\">,</span> <span class=\"n\">engine</span><span class=\"o\">=</span><span class=\"s\">'pyarrow'</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p>There is still work to be done here.  The variety of parquet reader/writers and\nconventions out there makes completely solving this problem difficult.  It’s\nnice seeing the various projects slowly converge on common functionality.</p>\n\n<p><em>This work was jointly done by Uwe Korn, Jim Crist, and Martin Durant.</em></p>\n\n<h2 id=\"retrying-tasks\">Retrying Tasks</h2>\n\n<p>One of the most requested features for the Dask.distributed scheduler is the\nability to retry failed tasks.  This is particularly useful to people using\nDask as a task queue, rather than as a big dataframe or array.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">future</span> <span class=\"o\">=</span> <span class=\"n\">client</span><span class=\"p\">.</span><span class=\"n\">submit</span><span class=\"p\">(</span><span class=\"n\">func</span><span class=\"p\">,</span> <span class=\"o\">*</span><span class=\"n\">args</span><span class=\"p\">,</span> <span class=\"n\">retries</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p><em>Task retries were primarily built by Antoine Pitrou.</em></p>\n\n<h2 id=\"transactional-work-stealing\">Transactional Work Stealing</h2>\n\n<p>The Dask.distributed task scheduler performs load balancing through work\nstealing.  Previously this would sometimes result in the same task running\nsimultaneously in two locations.  Now stealing is transactional, meaning that\nit will avoid accidentally running the same task twice. This behavior is\nespecially important for people using Dask tasks for side effects.</p>\n\n<p>It is still possible for the same task to run twice, but now this only happens\nin more extreme situations, such as when a worker dies or a TCP connection is\nsevered, neither of which are common on standard hardware.</p>\n\n<p><em>Transactional work stealing was primarily implemented by Matthew Rocklin.</em></p>\n\n<h2 id=\"new-diagnostic-pages\">New Diagnostic Pages</h2>\n\n<p>There is a new set of diagnostic web pages available in the <em>Info</em> tab of the\ndashboard.  These pages provide more in-depth information about each worker and\ntask, but are not dynamic in any way.  They use Tornado templates rather than\nBokeh plots, which means that they are less responsive but are much easier to\nbuild.  This is an easy and cheap way to expose more scheduler state.</p>\n\n<p><a href=\"https://mrocklin.github.io/blog/images/scheduler-info-task.png\">\n  <img src=\"https://mrocklin.github.io/blog/images/scheduler-info-task.png\" alt=\"Task page of Dask's scheduler info dashboard\" width=\"100%\" /></a></p>\n\n<ul>\n  <li><a href=\"https://github.com/dask/distributed/tree/master/distributed/bokeh/templates\">Existing templates</a></li>\n</ul>\n\n<h2 id=\"nested-compute-calls\">Nested compute calls</h2>\n\n<p>Calling <code class=\"language-plaintext highlighter-rouge\">.compute()</code> <em>within</em> a task now invokes the same distributed\nscheduler.  This enables writing more complex workloads with less thought to\nstarting worker clients.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">import</span> <span class=\"nn\">dask</span>\n<span class=\"kn\">from</span> <span class=\"nn\">dask.distributed</span> <span class=\"kn\">import</span> <span class=\"n\">Client</span>\n<span class=\"n\">client</span> <span class=\"o\">=</span> <span class=\"n\">Client</span><span class=\"p\">()</span>  <span class=\"c1\"># only works for the newer scheduler\n</span>\n<span class=\"o\">@</span><span class=\"n\">dask</span><span class=\"p\">.</span><span class=\"n\">delayed</span>\n<span class=\"k\">def</span> <span class=\"nf\">f</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">):</span>\n    <span class=\"p\">...</span>\n    <span class=\"k\">return</span> <span class=\"n\">dask</span><span class=\"p\">.</span><span class=\"n\">compute</span><span class=\"p\">(...)</span>  <span class=\"c1\"># can call dask.compute within delayed task\n</span>\n<span class=\"n\">dask</span><span class=\"p\">.</span><span class=\"n\">compute</span><span class=\"p\">([</span><span class=\"n\">f</span><span class=\"p\">(</span><span class=\"n\">i</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"p\">...])</span>\n</code></pre></div></div>\n\n<p><em>Nested compute calls were primarily developed by Matthew Rocklin and Olivier\nGrisel.</em></p>\n\n<h2 id=\"more-aggressive-garbage-collection\">More aggressive Garbage Collection</h2>\n\n<p>The workers now explicitly call <code class=\"language-plaintext highlighter-rouge\">gc.collect()</code> at various times when under\nmemory pressure and when releasing data.  This helps to avoid some memory\nleaks, especially when using Pandas dataframes.  Doing this carefully proved\nto require a surprising degree of detail.</p>\n\n<p><em>Improved garbage collection was primarily implemented and tested by Fabian\nKeller and Olivier Grisel, with recommendations by Antoine Pitrou.</em></p>\n\n<h2 id=\"related-projects\">Related projects</h2>\n\n<h3 id=\"dask-ml\">Dask-ML</h3>\n\n<p>A variety of Dask Machine Learning projects are now being assembled under one\nunified repository, <a href=\"http://dask-ml.readthedocs.io/en/latest/\">dask-ml</a>.  We\nencourage users and researchers alike to read through that project.  We believe\nthere are many useful and interesting approaches contained within.</p>\n\n<ul>\n  <li>Docs: <a href=\"http://dask-ml.readthedocs.io/en/latest/\">dask-ml.readthedocs.io</a></li>\n  <li>Github: <a href=\"https://github.com/dask/dask-ml\">github.com/dask/dask-ml</a></li>\n</ul>\n\n<p><em>The work to assemble and curate these algorithms is primarily being handled by\nTom Augspurger.</em></p>\n\n<h3 id=\"xarray\">XArray</h3>\n\n<p>The <a href=\"http://xarray.pydata.org/en/stable/\">XArray</a> project for indexed and\nlabeled arrays is also releasing their major 0.10.0 release this week, which\nincludes many performance improvements, particularly for using Dask on larger\ndatasets.</p>\n\n<ul>\n  <li>Docs: <a href=\"http://xarray.pydata.org/en/stable/\">xarray.pydata.org</a></li>\n  <li>Release notes: <a href=\"http://xarray.pydata.org/en/latest/whats-new.html\">xarray.pydata.org/en/latest/whats-new.html</a></li>\n</ul>\n\n<h2 id=\"acknowledgements\">Acknowledgements</h2>\n\n<p>The following people contributed to the dask/dask repository since the 0.15.3\nrelease on September 24th:</p>\n\n<ul>\n  <li>Ced4</li>\n  <li>Christopher Prohm</li>\n  <li>fjetter</li>\n  <li>Hai Nguyen Mau</li>\n  <li>Ian Hopkinson</li>\n  <li>James Bourbeau</li>\n  <li>James Munroe</li>\n  <li>Jesse Vogt</li>\n  <li>Jim Crist</li>\n  <li>John Kirkham</li>\n  <li>Keisuke Fujii</li>\n  <li>Matthias Bussonnier</li>\n  <li>Matthew Rocklin</li>\n  <li>mayl</li>\n  <li>Martin Durant</li>\n  <li>Olivier Grisel</li>\n  <li>severo</li>\n  <li>Simon Perkins</li>\n  <li>Stephan Hoyer</li>\n  <li>Thomas A Caswell</li>\n  <li>Tom Augspurger</li>\n  <li>Uwe L. Korn</li>\n  <li>Wei Ji</li>\n  <li>xwang777</li>\n</ul>\n\n<p>The following people contributed to the dask/distributed repository since the\n1.19.1 release on September 24nd:</p>\n\n<ul>\n  <li>Alvaro Ulloa</li>\n  <li>Antoine Pitrou</li>\n  <li>chkoar</li>\n  <li>Fabian Keller</li>\n  <li>Ian Hopkinson</li>\n  <li>Jim Crist</li>\n  <li>Kelvin Yang</li>\n  <li>Krisztián Szűcs</li>\n  <li>Matthew Rocklin</li>\n  <li>Mike DePalatis</li>\n  <li>Olivier Grisel</li>\n  <li>rbubley</li>\n  <li>Tom Augspurger</li>\n</ul>\n\n<p>The following people contributed to the dask/dask-ml repository</p>\n\n<ul>\n  <li>Evan Welch</li>\n  <li>Matthew Rocklin</li>\n  <li>severo</li>\n  <li>Tom Augspurger</li>\n  <li>Trey Causey</li>\n</ul>\n\n<p>In addition, we are proud to announce that Olivier Grisel has accepted commit\nrights to the Dask projects.  Olivier has been particularly active on the\ndistributed scheduler, and on related projects like Joblib, SKLearn, and\nCloudpickle.</p>"
}