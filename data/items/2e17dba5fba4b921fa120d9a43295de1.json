{
  "title": "SymPy and Theano -- Matrix Expressions",
  "link": "",
  "updated": "2013-04-05T00:00:00+00:00",
  "id": "https://mrocklin.github.io/blog/work/2013/04/05/SymPy-Theano-part-3",
  "content": "<h2 id=\"introduction\">Introduction</h2>\n\n<p><em>This post uses some LaTeX.  You may want to read it on the <a href=\"http://matthewrocklin.com/blog/work/2013/04/05/SymPy-Theano-part-3/\">original site</a>.</em></p>\n\n<p>This is the last of a three part series connecting SymPy and Theano to transform mathematical expressions into efficient numeric code (see <a href=\"http://matthewrocklin.com/blog/work/2013/03/19/SymPy-Theano-part-1/\">part 1</a> and <a href=\"http://matthewrocklin.com/blog/work/2013/03/28/SymPy-Theano-part-2/\">part 2</a>).  We have seen that it is simple and computationally profitable to combine the best parts of both projects.</p>\n\n<p>In this post we’ll switch from computing scalar expressionss to computing matrix expressions.  We’ll define the Kalman filter in SymPy and send it to Theano for code generation.  We’ll then use SymPy to define a more performant blocked version of the same algorithm.</p>\n\n<h2 id=\"kalman-filter\">Kalman Filter</h2>\n\n<p>The <a href=\"http://en.wikipedia.org/wiki/Kalman_filter\">Kalman filter</a> is an algorithm to compute the Bayesian update of a normal random variable given a linear observation with normal noise.  It is commonly used when an uncertain quantity is updated with the results of noisy observations.  For example it is used in weather forecasting after weather stations report in with new measurements, in aircraft/car control to automatically adjust for external conditions real-time, or even on your smartphone’s GPS navigation as you update your position based on fuzzy GPS signals.   It’s everywhere, it’s important, and it needs to be computed quickly and continuously.  It suits our needs today because it can be completely defined with a pair of matrix expressions.</p>\n\n<figure class=\"highlight\">\n  <pre><code class=\"language-python\" data-lang=\"python\"><span class=\"kn\">from</span> <span class=\"nn\">sympy</span> <span class=\"kn\">import</span> <span class=\"n\">MatrixSymbol</span><span class=\"p\">,</span> <span class=\"n\">latex</span>\n<span class=\"n\">n</span>       <span class=\"o\">=</span> <span class=\"mi\">1000</span>                          <span class=\"c1\"># Number of variables in our system/current state\n</span><span class=\"n\">k</span>       <span class=\"o\">=</span> <span class=\"mi\">500</span>                           <span class=\"c1\"># Number of variables in the observation\n</span><span class=\"n\">mu</span>      <span class=\"o\">=</span> <span class=\"n\">MatrixSymbol</span><span class=\"p\">(</span><span class=\"s\">'mu'</span><span class=\"p\">,</span> <span class=\"n\">n</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">)</span>      <span class=\"c1\"># Mean of current state\n</span><span class=\"n\">Sigma</span>   <span class=\"o\">=</span> <span class=\"n\">MatrixSymbol</span><span class=\"p\">(</span><span class=\"s\">'Sigma'</span><span class=\"p\">,</span> <span class=\"n\">n</span><span class=\"p\">,</span> <span class=\"n\">n</span><span class=\"p\">)</span>   <span class=\"c1\"># Covariance of current state\n</span><span class=\"n\">H</span>       <span class=\"o\">=</span> <span class=\"n\">MatrixSymbol</span><span class=\"p\">(</span><span class=\"s\">'H'</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"p\">,</span> <span class=\"n\">n</span><span class=\"p\">)</span>       <span class=\"c1\"># A measurement operator on current state\n</span><span class=\"n\">R</span>       <span class=\"o\">=</span> <span class=\"n\">MatrixSymbol</span><span class=\"p\">(</span><span class=\"s\">'R'</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"p\">)</span>       <span class=\"c1\"># Covariance of measurement noise\n</span><span class=\"n\">data</span>    <span class=\"o\">=</span> <span class=\"n\">MatrixSymbol</span><span class=\"p\">(</span><span class=\"s\">'data'</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">)</span>    <span class=\"c1\"># Observed measurement data\n</span>\n<span class=\"n\">newmu</span>   <span class=\"o\">=</span> <span class=\"n\">mu</span> <span class=\"o\">+</span> <span class=\"n\">Sigma</span><span class=\"o\">*</span><span class=\"n\">H</span><span class=\"p\">.</span><span class=\"n\">T</span> <span class=\"o\">*</span> <span class=\"p\">(</span><span class=\"n\">R</span> <span class=\"o\">+</span> <span class=\"n\">H</span><span class=\"o\">*</span><span class=\"n\">Sigma</span><span class=\"o\">*</span><span class=\"n\">H</span><span class=\"p\">.</span><span class=\"n\">T</span><span class=\"p\">).</span><span class=\"n\">I</span> <span class=\"o\">*</span> <span class=\"p\">(</span><span class=\"n\">H</span><span class=\"o\">*</span><span class=\"n\">mu</span> <span class=\"o\">-</span> <span class=\"n\">data</span><span class=\"p\">)</span>      <span class=\"c1\"># Updated mean\n</span><span class=\"n\">newSigma</span><span class=\"o\">=</span> <span class=\"n\">Sigma</span> <span class=\"o\">-</span> <span class=\"n\">Sigma</span><span class=\"o\">*</span><span class=\"n\">H</span><span class=\"p\">.</span><span class=\"n\">T</span> <span class=\"o\">*</span> <span class=\"p\">(</span><span class=\"n\">R</span> <span class=\"o\">+</span> <span class=\"n\">H</span><span class=\"o\">*</span><span class=\"n\">Sigma</span><span class=\"o\">*</span><span class=\"n\">H</span><span class=\"p\">.</span><span class=\"n\">T</span><span class=\"p\">).</span><span class=\"n\">I</span> <span class=\"o\">*</span> <span class=\"n\">H</span> <span class=\"o\">*</span> <span class=\"n\">Sigma</span>       <span class=\"c1\"># Updated covariance\n</span>\n<span class=\"k\">print</span> <span class=\"n\">latex</span><span class=\"p\">(</span><span class=\"n\">newmu</span><span class=\"p\">)</span>\n<span class=\"k\">print</span> <span class=\"n\">latex</span><span class=\"p\">(</span><span class=\"n\">newSigma</span><span class=\"p\">)</span></code></pre>\n</figure>\n\n<p>\\(\\Sigma H^T \\left(H \\Sigma H^T + R\\right)^{-1} \\left(-data + H \\mu\\right) + \\mu\\)\n\\(- \\Sigma H^T \\left(H \\Sigma H^T + R\\right)^{-1} H \\Sigma + \\Sigma\\)</p>\n\n<h2 id=\"theano-execution\">Theano Execution</h2>\n\n<p>The objects above are for symbolic mathematics, not for numeric computation.  If we want to compute this expression we pass our expressions to Theano.</p>\n\n<figure class=\"highlight\">\n  <pre><code class=\"language-python\" data-lang=\"python\"><span class=\"n\">inputs</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">mu</span><span class=\"p\">,</span> <span class=\"n\">Sigma</span><span class=\"p\">,</span> <span class=\"n\">H</span><span class=\"p\">,</span> <span class=\"n\">R</span><span class=\"p\">,</span> <span class=\"n\">data</span><span class=\"p\">]</span>\n<span class=\"n\">outputs</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">newmu</span><span class=\"p\">,</span> <span class=\"n\">newSigma</span><span class=\"p\">]</span>\n<span class=\"n\">dtypes</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"n\">inp</span><span class=\"p\">:</span> <span class=\"s\">'float64'</span> <span class=\"k\">for</span> <span class=\"n\">inp</span> <span class=\"ow\">in</span> <span class=\"n\">inputs</span><span class=\"p\">}</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">sympy.printing.theanocode</span> <span class=\"kn\">import</span> <span class=\"n\">theano_function</span>\n<span class=\"n\">f</span> <span class=\"o\">=</span> <span class=\"n\">theano_function</span><span class=\"p\">(</span><span class=\"n\">inputs</span><span class=\"p\">,</span> <span class=\"n\">outputs</span><span class=\"p\">,</span> <span class=\"n\">dtypes</span><span class=\"o\">=</span><span class=\"n\">dtypes</span><span class=\"p\">)</span></code></pre>\n</figure>\n\n<p>Theano builds a Python function that calls down to a combination of low-level <code class=\"language-plaintext highlighter-rouge\">C</code> code, <code class=\"language-plaintext highlighter-rouge\">scipy</code> functions, and calls to the highly optimized <code class=\"language-plaintext highlighter-rouge\">DGEMM</code> routine for matrix multiplication.  As input this function takes five numpy arrays corresponding to our five symbolic <code class=\"language-plaintext highlighter-rouge\">inputs</code> and produces two numpy arrays corresponding to our two symbolic <code class=\"language-plaintext highlighter-rouge\">outputs</code>.  <a href=\"https://github.com/sympy/sympy/pull/1965\">Recent work</a> allows <em>any</em> SymPy matrix expression to be translated to and run by Theano.</p>\n\n<figure class=\"highlight\">\n  <pre><code class=\"language-python\" data-lang=\"python\"><span class=\"kn\">import</span> <span class=\"nn\">numpy</span>\n<span class=\"n\">ninputs</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">.</span><span class=\"n\">rand</span><span class=\"p\">(</span><span class=\"o\">*</span><span class=\"n\">i</span><span class=\"p\">.</span><span class=\"n\">shape</span><span class=\"p\">).</span><span class=\"n\">astype</span><span class=\"p\">(</span><span class=\"s\">'float64'</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"n\">inputs</span><span class=\"p\">]</span>\n<span class=\"n\">nmu</span><span class=\"p\">,</span> <span class=\"n\">nSigma</span> <span class=\"o\">=</span> <span class=\"n\">f</span><span class=\"p\">(</span><span class=\"o\">*</span><span class=\"n\">ninputs</span><span class=\"p\">)</span></code></pre>\n</figure>\n\n<h2 id=\"blocked-execution\">Blocked Execution</h2>\n\n<p>These arrays are too large to fit comfortably in the fastest parts of the memory hierarchy.  As a result each sequential <code class=\"language-plaintext highlighter-rouge\">C</code>, <code class=\"language-plaintext highlighter-rouge\">scipy</code>, or <code class=\"language-plaintext highlighter-rouge\">DGEMM</code> call needs to move big chunks of memory around while it computes.  After one operation completes the next operation moves around the same memory while it performs its task.  This repeated memory shuffling hurts performance.</p>\n\n<p>A common approach to reduce memory shuffling is to cut the computation into smaller blocks.  We then perform as many computations as possible on a single block before moving on.  This is a standard technique in matrix multiplication.</p>\n\n<figure class=\"highlight\">\n  <pre><code class=\"language-python\" data-lang=\"python\"><span class=\"kn\">from</span> <span class=\"nn\">sympy</span> <span class=\"kn\">import</span> <span class=\"n\">BlockMatrix</span><span class=\"p\">,</span> <span class=\"n\">block_collapse</span>\n<span class=\"n\">A</span><span class=\"p\">,</span> <span class=\"n\">B</span><span class=\"p\">,</span> <span class=\"n\">C</span><span class=\"p\">,</span> <span class=\"n\">D</span><span class=\"p\">,</span> <span class=\"n\">E</span><span class=\"p\">,</span> <span class=\"n\">F</span><span class=\"p\">,</span> <span class=\"n\">G</span><span class=\"p\">,</span> <span class=\"n\">K</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">MatrixSymbol</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">n</span><span class=\"p\">,</span> <span class=\"n\">n</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">a</span> <span class=\"ow\">in</span> <span class=\"s\">'ABCDEFGK'</span><span class=\"p\">]</span>\n<span class=\"n\">X</span> <span class=\"o\">=</span> <span class=\"n\">BlockMatrix</span><span class=\"p\">([[</span><span class=\"n\">A</span><span class=\"p\">,</span> <span class=\"n\">B</span><span class=\"p\">],</span>\n                 <span class=\"p\">[</span><span class=\"n\">C</span><span class=\"p\">,</span> <span class=\"n\">D</span><span class=\"p\">]])</span>\n<span class=\"n\">Y</span> <span class=\"o\">=</span> <span class=\"n\">BlockMatrix</span><span class=\"p\">([[</span><span class=\"n\">E</span><span class=\"p\">,</span> <span class=\"n\">F</span><span class=\"p\">],</span>\n                 <span class=\"p\">[</span><span class=\"n\">G</span><span class=\"p\">,</span> <span class=\"n\">K</span><span class=\"p\">]])</span>\n<span class=\"k\">print</span> <span class=\"n\">latex</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"o\">*</span><span class=\"n\">Y</span><span class=\"p\">)</span></code></pre>\n</figure>\n\n\\[\\begin{bmatrix} A &amp; B \\\\\\\\ C &amp; D \\end{bmatrix}\n   \\begin{bmatrix} E &amp; F \\\\\\\\ G &amp; K \\end{bmatrix}\\]\n\n<figure class=\"highlight\">\n  <pre><code class=\"language-python\" data-lang=\"python\"><span class=\"k\">print</span> <span class=\"n\">latex</span><span class=\"p\">(</span><span class=\"n\">block_collapse</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"o\">*</span><span class=\"n\">Y</span><span class=\"p\">))</span></code></pre>\n</figure>\n\n\\[\\begin{bmatrix} A E + B G &amp; A F + B K \\\\\\\\\n                   C E + D G &amp; C F + D K\\end{bmatrix}\\]\n\n<p>We are now able to focus on substantially smaller chunks of the array.  For example we can choose to keep <code class=\"language-plaintext highlighter-rouge\">A</code> in local memory and perform all computations that involve <code class=\"language-plaintext highlighter-rouge\">A</code>.  We will still need to shuffle some memory around (this is inevitable) but by organizing with blocks we’re able to shuffle less.</p>\n\n<p>This idea extends beyond matrix multiplication.  For example, SymPy knows how to block a matrix inverse</p>\n\n<figure class=\"highlight\">\n  <pre><code class=\"language-python\" data-lang=\"python\"><span class=\"k\">print</span> <span class=\"n\">latex</span><span class=\"p\">(</span><span class=\"n\">block_collapse</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">.</span><span class=\"n\">I</span><span class=\"p\">))</span></code></pre>\n</figure>\n\n\\[\\begin{bmatrix}\n\\left(- B D^{-1} C + A\\right)^{-1} &amp; - A^{-1} B \\left(- C A^{-1} B + D\\right)^{-1} \\\\\\\\\n- \\left(- C A^{-1} B + D\\right)^{-1} C A^{-1} &amp; \\left(- C A^{-1} B + D\\right)^{-1}\n\\end{bmatrix}\\]\n\n<p>High performance dense linear algebra libraries hard-code all of these tricks into each individual routine.  The call to the general matrix multiply routine <code class=\"language-plaintext highlighter-rouge\">DGEMM</code> performs blocked matrix multiply within the call.  The call to the general matrix solve routine <code class=\"language-plaintext highlighter-rouge\">DGESV</code> can perform blocked matrix solve.  Unfortunately these routines are unable to coordinate blocked computation <em>between</em> calls.</p>\n\n<p>Fortunately, SymPy and Theano can.</p>\n\n<p>SymPy can define and reduce the blocked matrix expressions using relations like what are shown above.</p>\n\n<figure class=\"highlight\">\n  <pre><code class=\"language-python\" data-lang=\"python\"><span class=\"kn\">from</span> <span class=\"nn\">sympy</span> <span class=\"kn\">import</span> <span class=\"n\">blockcut</span><span class=\"p\">,</span> <span class=\"n\">block_collapse</span>\n<span class=\"n\">blocksizes</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n        <span class=\"n\">Sigma</span><span class=\"p\">:</span> <span class=\"p\">[(</span><span class=\"n\">n</span><span class=\"o\">/</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">n</span><span class=\"o\">/</span><span class=\"mi\">2</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"n\">n</span><span class=\"o\">/</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">n</span><span class=\"o\">/</span><span class=\"mi\">2</span><span class=\"p\">)],</span>\n        <span class=\"n\">H</span><span class=\"p\">:</span>     <span class=\"p\">[(</span><span class=\"n\">k</span><span class=\"o\">/</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"o\">/</span><span class=\"mi\">2</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"n\">n</span><span class=\"o\">/</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">n</span><span class=\"o\">/</span><span class=\"mi\">2</span><span class=\"p\">)],</span>\n        <span class=\"n\">R</span><span class=\"p\">:</span>     <span class=\"p\">[(</span><span class=\"n\">k</span><span class=\"o\">/</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"o\">/</span><span class=\"mi\">2</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"n\">k</span><span class=\"o\">/</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"o\">/</span><span class=\"mi\">2</span><span class=\"p\">)],</span>\n        <span class=\"n\">mu</span><span class=\"p\">:</span>    <span class=\"p\">[(</span><span class=\"n\">n</span><span class=\"o\">/</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">n</span><span class=\"o\">/</span><span class=\"mi\">2</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,)],</span>\n        <span class=\"n\">data</span><span class=\"p\">:</span>  <span class=\"p\">[(</span><span class=\"n\">k</span><span class=\"o\">/</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"o\">/</span><span class=\"mi\">2</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,)]</span>\n        <span class=\"p\">}</span>\n<span class=\"n\">blockinputs</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">blockcut</span><span class=\"p\">(</span><span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"o\">*</span><span class=\"n\">blocksizes</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">])</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"n\">inputs</span><span class=\"p\">]</span>\n<span class=\"n\">blockoutputs</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">o</span><span class=\"p\">.</span><span class=\"n\">subs</span><span class=\"p\">(</span><span class=\"nb\">dict</span><span class=\"p\">(</span><span class=\"nb\">zip</span><span class=\"p\">(</span><span class=\"n\">inputs</span><span class=\"p\">,</span> <span class=\"n\">blockinputs</span><span class=\"p\">)))</span> <span class=\"k\">for</span> <span class=\"n\">o</span> <span class=\"ow\">in</span> <span class=\"n\">outputs</span><span class=\"p\">]</span>\n<span class=\"n\">collapsed_outputs</span> <span class=\"o\">=</span> <span class=\"nb\">map</span><span class=\"p\">(</span><span class=\"n\">block_collapse</span><span class=\"p\">,</span> <span class=\"n\">blockoutputs</span><span class=\"p\">)</span>\n\n<span class=\"n\">fblocked</span> <span class=\"o\">=</span> <span class=\"n\">theano_function</span><span class=\"p\">(</span><span class=\"n\">inputs</span><span class=\"p\">,</span> <span class=\"n\">collapsed_outputs</span><span class=\"p\">,</span> <span class=\"n\">dtypes</span><span class=\"o\">=</span><span class=\"n\">dtypes</span><span class=\"p\">)</span></code></pre>\n</figure>\n\n<p>Theano is then able to coordinate this computation and compile it to low-level code.  At this stage the expresssions/computations are fairly complex and difficult to present.  Here is an image of the computation (click for zoomable PDF) as a directed acyclic graph.</p>\n\n<p><a href=\"https://mrocklin.github.io/blog/images/fblocked.pdf\"><img src=\"https://mrocklin.github.io/blog/images/fblocked-small.png\" alt=\"\" /></a></p>\n\n<h2 id=\"results\">Results</h2>\n\n<p>Lets time each function on the same inputs and see which is faster</p>\n\n<figure class=\"highlight\">\n  <pre><code class=\"language-python\" data-lang=\"python\"><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">timeit</span> <span class=\"n\">f</span><span class=\"p\">(</span><span class=\"o\">*</span><span class=\"n\">ninputs</span><span class=\"p\">)</span>\n<span class=\"mi\">1</span> <span class=\"n\">loops</span><span class=\"p\">,</span> <span class=\"n\">best</span> <span class=\"n\">of</span> <span class=\"mi\">3</span><span class=\"p\">:</span> <span class=\"mf\">2.69</span> <span class=\"n\">s</span> <span class=\"n\">per</span> <span class=\"n\">loop</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">timeit</span> <span class=\"n\">fblocked</span><span class=\"p\">(</span><span class=\"o\">*</span><span class=\"n\">ninputs</span><span class=\"p\">)</span>\n<span class=\"mi\">1</span> <span class=\"n\">loops</span><span class=\"p\">,</span> <span class=\"n\">best</span> <span class=\"n\">of</span> <span class=\"mi\">3</span><span class=\"p\">:</span> <span class=\"mf\">2.12</span> <span class=\"n\">s</span> <span class=\"n\">per</span> <span class=\"n\">loop</span></code></pre>\n</figure>\n\n<p>That’s a 20% performance increase from just a few lines of high-level code.</p>\n\n<p>Blocked matrix multiply and blocked solve routines have long been established as <em>a good idea</em>.  High level mathematical and array programming libraries like SymPy and Theano allow us to extend this good idea to <em>arbitrary</em> array computations.</p>\n\n<h2 id=\"analysis\">Analysis</h2>\n\n<h3 id=\"good-things\">Good Things</h3>\n\n<p>First, lets note that we’re not introducing a new library for dense linear algebra.  Instead we’re noting that pre-existing general purpose high-level tools can be composed to that effect.</p>\n\n<p>Second, lets acknoledge that we could take this further.  For example Theano seemlessly handles GPU interactions.  We could take this same code to a GPU accelerated machine and it would just run faster without any action on our part.</p>\n\n<h3 id=\"bad-things\">Bad Things</h3>\n\n<p>However, there are some drawbacks.</p>\n\n<p>Frequent readers of my blog might recall a <a href=\"http://matthewrocklin.com/blog/work/2012/11/24/Kalman-Filter/\">previous post about the Kalman filter</a>.  In it I showed how we could use SymPy’s inference engine to select appropriate BLAS/LAPACK calls.  For example we could infer that because $ H \\Sigma H^T + R $ was symmetric positive definite we could use the substantially more efficient <code class=\"language-plaintext highlighter-rouge\">POSV</code> routine for matrix solve rather than <code class=\"language-plaintext highlighter-rouge\">GESV</code> (<code class=\"language-plaintext highlighter-rouge\">POSV</code> uses the Cholesky algorithm for decomposition rather than straight LU).  Theano doesn’t support the specialized BLAS/LAPACK routines though, so we are unable to take advantage of this benefit.  The lower-level interface (Theano) is not sufficiently rich to use all information captured in the higher-level (SymPy) representation.</p>\n\n<p>Also, I’ve noticed that the blocked version of this computation experiences some significant roundoff errors (on the order of <code class=\"language-plaintext highlighter-rouge\">1e-3</code>).  I’m in the process of tracking this down.  The problem must occur somewhere in the following tool-chain</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>SymPy -&gt; Blocking -&gt; Theano -&gt; SciPy -&gt; C routines -&gt; BLAS\n</code></pre></div></div>\n\n<p>Debugging in this context can be wonderful if all elements are well unit-tested.  If they’re not (they’re not) then tracking down errors like this requires an unfortunate breadth of expertise.</p>\n\n<h2 id=\"references\">References</h2>\n\n<p>Scripts</p>\n\n<ul>\n  <li><a href=\"https://mrocklin.github.io/blog/scripts/kalman.py\">Kalman example</a></li>\n  <li><a href=\"https://mrocklin.github.io/blog/scripts/blocks.py\">Block Matrix example</a></li>\n  <li><a href=\"https://mrocklin.github.io/blog/scripts/kalman_blocked.py\">Block Kalman</a></li>\n</ul>"
}