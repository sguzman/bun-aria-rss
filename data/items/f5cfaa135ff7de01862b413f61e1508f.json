{
  "title": "Some comments to Daniel Abadi's blog about Apache Arrow",
  "link": "",
  "published": "2017-11-01T00:00:00-07:00",
  "updated": "2017-11-01T00:00:00-07:00",
  "author": {
    "name": "Wes McKinney"
  },
  "id": "tag:wesmckinney.com,2017-11-01:/blog/arrow-columnar-abadi/",
  "summary": "<p>Well-known database systems researcher <a href=\"http://www.cs.yale.edu/homes/dna/\">Daniel Abadi</a> published a blog post\nyesterday asking <a href=\"http://dbmsmusings.blogspot.com/2017/10/apache-arrow-vs-parquet-and-orc-do-we.html\">Apache Arrow vs. Parquet and ORC: Do we really need a third\nApache project for columnar data representation?</a>.</p>\n<p>Despite the somewhat confrontational title, based on his analysis, the answer\nis <strong>\"Yes, we do\"</strong>, but I have a number â€¦</p>",
  "content": "<p>Well-known database systems researcher <a href=\"http://www.cs.yale.edu/homes/dna/\">Daniel Abadi</a> published a blog post\nyesterday asking <a href=\"http://dbmsmusings.blogspot.com/2017/10/apache-arrow-vs-parquet-and-orc-do-we.html\">Apache Arrow vs. Parquet and ORC: Do we really need a third\nApache project for columnar data representation?</a>.</p>\n<p>Despite the somewhat confrontational title, based on his analysis, the answer\nis <strong>\"Yes, we do\"</strong>, but I have a number of issues to discuss, including in\npart the premise of the article.</p>\n<h3>Storage and runtime formats, in context</h3>\n<p><strong>Arrow is not competing with Parquet and ORC</strong>. The article's implied premise\nis that Arrow is a third technology for columnar storage, in the same category\nof projects as Parquet and ORC. We have made abundantly clear since the early\ndays of our work that <strong>Arrow is a complementary, companion technology</strong> to\ndisk-oriented columnar storage formats like Parquet and ORC. Indeed, many\nApache Arrow committers are also Apache Parquet committers. It would not be in\nour interest to be competing with ourselves.</p>\n<p>You can certainly utilize Arrow as the data representation for a column store\nin a database, but that is not the primary objective of the project.</p>\n<p>To make this more clear for lay-people:</p>\n<ul>\n<li>Parquet and ORC are file formats designed for persistent, long-term storage\n  on disk that require non-trivial decoding and decompression to be able to\n  perform computations on their contents in-memory</li>\n<li>Arrow is an ephemeral, runtime in-memory representation that can be processed\n  without any overhead on a per array-cell basis (unless you compress or encode\n  in-memory, more on this later. It is not by design a file format (though you\n  can <a href=\"https://wesmckinney.com/blog/feather-arrow-future/\">use it to create file formats</a>) nor is it intended for long-term\n  storage</li>\n</ul>\n<p>To give you a small example of what this means in practice. Let's consider\nParquet format, and the semantic values:</p>\n<div class=\"github\"><pre><span></span><code>[0, 1, null, 3, null, null, 6, 7, null]\n</code></pre></div>\n\n<p>Now suppose that you want to write a function to sum a batch of integers. Your\nnative result is:</p>\n<div class=\"github\"><pre><span></span><code><span class=\"kt\">int64_t</span><span class=\"w\"> </span><span class=\"nf\">sum_int64</span><span class=\"p\">(</span><span class=\"k\">const</span><span class=\"w\"> </span><span class=\"kt\">int64_t</span><span class=\"o\">*</span><span class=\"w\"> </span><span class=\"n\">values</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"kt\">size_t</span><span class=\"w\"> </span><span class=\"n\">length</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\"></span>\n<span class=\"w\">  </span><span class=\"kt\">int64_t</span><span class=\"w\"> </span><span class=\"n\">result</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"mi\">0</span><span class=\"p\">;</span><span class=\"w\"></span>\n<span class=\"w\">  </span><span class=\"k\">for</span><span class=\"w\"> </span><span class=\"p\">(</span><span class=\"kt\">size_t</span><span class=\"w\"> </span><span class=\"n\">i</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"mi\">0</span><span class=\"p\">;</span><span class=\"w\"> </span><span class=\"n\">i</span><span class=\"w\"> </span><span class=\"o\">&lt;</span><span class=\"w\"> </span><span class=\"n\">length</span><span class=\"p\">;</span><span class=\"w\"> </span><span class=\"o\">++</span><span class=\"n\">i</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\"></span>\n<span class=\"w\">    </span><span class=\"n\">result</span><span class=\"w\"> </span><span class=\"o\">+=</span><span class=\"w\"> </span><span class=\"n\">values</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">];</span><span class=\"w\"></span>\n<span class=\"w\">  </span><span class=\"p\">}</span><span class=\"w\"></span>\n<span class=\"w\">  </span><span class=\"k\">return</span><span class=\"w\"> </span><span class=\"n\">result</span><span class=\"p\">;</span><span class=\"w\"></span>\n<span class=\"p\">}</span><span class=\"w\"></span>\n</code></pre></div>\n\n<p>But wait, this doesn't handle nulls. So suppose we use some special sentinel\nvalue (like <code>INT64_MIN</code>) to encode nulls:</p>\n<div class=\"github\"><pre><span></span><code><span class=\"kt\">int64_t</span><span class=\"w\"> </span><span class=\"nf\">sum_int64</span><span class=\"p\">(</span><span class=\"k\">const</span><span class=\"w\"> </span><span class=\"kt\">int64_t</span><span class=\"o\">*</span><span class=\"w\"> </span><span class=\"n\">values</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"kt\">size_t</span><span class=\"w\"> </span><span class=\"n\">length</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\"></span>\n<span class=\"w\">  </span><span class=\"kt\">int64_t</span><span class=\"w\"> </span><span class=\"n\">result</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"mi\">0</span><span class=\"p\">;</span><span class=\"w\"></span>\n<span class=\"w\">  </span><span class=\"k\">for</span><span class=\"w\"> </span><span class=\"p\">(</span><span class=\"kt\">size_t</span><span class=\"w\"> </span><span class=\"n\">i</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"mi\">0</span><span class=\"p\">;</span><span class=\"w\"> </span><span class=\"n\">i</span><span class=\"w\"> </span><span class=\"o\">&lt;</span><span class=\"w\"> </span><span class=\"n\">length</span><span class=\"p\">;</span><span class=\"w\"> </span><span class=\"o\">++</span><span class=\"n\">i</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\"></span>\n<span class=\"w\">    </span><span class=\"k\">if</span><span class=\"w\"> </span><span class=\"p\">(</span><span class=\"n\">values</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span><span class=\"w\"> </span><span class=\"o\">!=</span><span class=\"w\"> </span><span class=\"n\">NULL_SENTINEL_INT64</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\"></span>\n<span class=\"w\">      </span><span class=\"n\">result</span><span class=\"w\"> </span><span class=\"o\">+=</span><span class=\"w\"> </span><span class=\"n\">values</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">];</span><span class=\"w\"></span>\n<span class=\"w\">    </span><span class=\"p\">}</span><span class=\"w\"></span>\n<span class=\"w\">  </span><span class=\"p\">}</span><span class=\"w\"></span>\n<span class=\"w\">  </span><span class=\"k\">return</span><span class=\"w\"> </span><span class=\"n\">result</span><span class=\"p\">;</span><span class=\"w\"></span>\n<span class=\"p\">}</span><span class=\"w\"></span>\n</code></pre></div>\n\n<p>Now we've already decided on a quite opinionated columnar memory format for\nrepresenting integers with nulls.</p>\n<p>But, if the data is in Parquet, we can't use this function as is. Omitting\nParquet-specific details like dictionary encoding and compression, we may have\nthe data represented using the Google Dremel definition level encoding:</p>\n<div class=\"github\"><pre><span></span><code>definition levels: 1 1 0 1 0 0 1 1 0\nvalues: 0 1 3 6 7\n</code></pre></div>\n\n<p>If you want to use your <code>sum_int64</code> function, you have to allocate memory then\ndecode this data into the appropriate data structure:</p>\n<div class=\"github\"><pre><span></span><code><span class=\"kt\">void</span><span class=\"w\"> </span><span class=\"nf\">parquet_decode_int64</span><span class=\"p\">(</span><span class=\"k\">const</span><span class=\"w\"> </span><span class=\"kt\">int16_t</span><span class=\"o\">*</span><span class=\"w\"> </span><span class=\"n\">def_levels</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"k\">const</span><span class=\"w\"> </span><span class=\"kt\">int64_t</span><span class=\"o\">*</span><span class=\"w\"> </span><span class=\"n\">values</span><span class=\"p\">,</span><span class=\"w\"></span>\n<span class=\"w\">                          </span><span class=\"kt\">size_t</span><span class=\"w\"> </span><span class=\"n\">num_levels</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"kt\">int64_t</span><span class=\"o\">*</span><span class=\"w\"> </span><span class=\"n\">out</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\"></span>\n<span class=\"w\">  </span><span class=\"k\">for</span><span class=\"w\"> </span><span class=\"p\">(</span><span class=\"kt\">size_t</span><span class=\"w\"> </span><span class=\"n\">i</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"mi\">0</span><span class=\"p\">;</span><span class=\"w\"> </span><span class=\"n\">i</span><span class=\"w\"> </span><span class=\"o\">&lt;</span><span class=\"w\"> </span><span class=\"n\">num_levels</span><span class=\"p\">;</span><span class=\"w\"> </span><span class=\"o\">++</span><span class=\"n\">i</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\"></span>\n<span class=\"w\">    </span><span class=\"k\">if</span><span class=\"w\"> </span><span class=\"p\">(</span><span class=\"n\">def_levels</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span><span class=\"w\"> </span><span class=\"o\">==</span><span class=\"w\"> </span><span class=\"mi\">1</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\"></span>\n<span class=\"w\">      </span><span class=\"o\">*</span><span class=\"n\">out</span><span class=\"o\">++</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"o\">*</span><span class=\"n\">values</span><span class=\"o\">++</span><span class=\"p\">;</span><span class=\"w\"></span>\n<span class=\"w\">    </span><span class=\"p\">}</span><span class=\"w\"> </span><span class=\"k\">else</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\"></span>\n<span class=\"w\">      </span><span class=\"o\">*</span><span class=\"n\">out</span><span class=\"o\">++</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">NULL_SENTINEL_INT64</span><span class=\"p\">;</span><span class=\"w\"></span>\n<span class=\"w\">    </span><span class=\"p\">}</span><span class=\"w\"></span>\n<span class=\"w\">  </span><span class=\"p\">}</span><span class=\"w\"></span>\n<span class=\"p\">}</span><span class=\"w\"></span>\n</code></pre></div>\n\n<p>In practice, what happens is:</p>\n<ul>\n<li>Systems define their own way to represent in-memory data, including nulls,\n  nested types, strings, and all the complex data types out there</li>\n<li>Algorithms written for a particular system are not portable to other\n  environments</li>\n</ul>\n<p>What Arrow provides a Parquet or ORC columnar storage user is a <strong>standardized\nin-memory data structure to place decoded data</strong>. This provides the additional\nbenefits that any algorithms that understand Arrow memory can process decoded\ndata at no cost. <strong>If you don't use something standardized, in many cases you\nwill have to roll your own \"proprietary\", non-portable data structures.</strong></p>\n<p>It's true that some analytic database systems have their own highly specialized\nquery engines with code generation and many kinds of hardware\noptimizations. The developers of these systems may be unmotivated by the\nbenefits of a standardized in-memory data representation, and that's fine.</p>\n<h3>Zero-copy data access and non-sequential reads</h3>\n<p>One of the most game-changing aspects of Apache Arrow, is its role in data\naccess and data movement. I <a href=\"https://wesmckinney.com/blog/apache-arrow-pandas-internals/\">discussed this extensively as it relates to data\nscience in my September 21 blog post</a>.</p>\n<p>Whether Arrow data is placed in RAM, in POSIX shared memory, non-volatile\nmemory, or memory-mapped files on disk, the cost of accessing a single value in\na single column is not dependent on the size of the dataset. This means that\nwhether you have 1 megabyte of data or 1 terabyte, the cost to access any\nportion of the dataset (outside of the cost of performing general IO on RAM or\ndisk) is effectively zero (there is a tiny, fixed overhead relating to\ninspecting a dataset's metadata).</p>\n<p>Having the option to abstract away the difference between data on-disk and data\nin-memory from a coding perspective is hugely liberating from an architectural\nstandpoint, particularly when there are multiple processes or multiple runtime\nenvironments involved. Two processes can access the same dataset on disk or in\nshared-memory without any additional overhead. A dataset can be streamed\nthrough a high-bandwidth socket and immediately analyzed on receipt without any\nadditional processing overhead.</p>\n<p>We have already seen huge benefits from this serialization-free, zero-copy data\naccess:</p>\n<ul>\n<li><a href=\"http://arrow.apache.org/blog/2017/10/15/fast-python-serialization-with-ray-and-arrow/\">Zero-copy reads of machine learning datasets in the Ray project</a></li>\n<li><a href=\"https://databricks.com/blog/2017/10/30/introducing-vectorized-udfs-for-pyspark.html\">Vectorized UDFs in Apache Spark</a></li>\n<li><a href=\"https://github.com/mapd/pymapd/pull/53#issuecomment-331762835\">Faster data ingest from Python in the MapD GPU database</a></li>\n<li><a href=\"https://www.mapd.com/blog/2017/09/26/end-to-end-machine-learning-with-goai/\">On-GPU IPC for the GPU Open Analytics Initiative</a></li>\n</ul>\n<p>In fact, one of the reasons I've spent less time on things like compression and\nencodings is that zero-copy data access and transport has more meaningful\nimmediate benefits to downstream use cases.</p>\n<h3>Some other points</h3>\n<hr>\n<p>Prof. Abadi writes:</p>\n<blockquote>\n<p>Now we can understand some of the key differences between Apache Parquet/ORC\n  and Apache Arrow. Parquet and ORC, since they are designed for disk-resident\n  data, support high-ratio compression algorithms such as snappy (both), gzip\n  (Parquet), and zlib (ORC) all of which typically require decompression before\n  data processing (and the associated CPU costs). <strong>Meanwhile, Arrow, which is\n  designed for memory-resident-data, does not support these algorithms. The\n  only compression currently supported by Arrow is dictionary compression, a\n  scheme that usually does not require decompression before data processing.</strong></p>\n</blockquote>\n<p>See <a href=\"https://issues.apache.org/jira/browse/ARROW-300\">ARROW-300</a>. Support for other kinds of compression has been discussed\nsince the early days of the project, and the main reason it is not yet\nsupported is limited developer bandwidth. In the C++ library, we already ship\nlibraries with <a href=\"https://github.com/apache/arrow/tree/master/cpp/src/arrow/util\">built-in codec support for gzip, zlib, Snappy, LZ4, and\nZSTD</a>. We could certainly add RLE, bit-packing, or other compression\nstrategies for integers or other highly-compressible data types. We need to add\nmetadata so that Arrow streams or IPC payloads can be transported with\ncompressed vectors.</p>\n<p>So far our time has been consumed with fine details of data representation\n(especially logical types like timestamps and decimals) so that work can\nproceed with building libraries of algorithms that process fully-decompressed\nArrow data natively.</p>\n<p>He writes further:</p>\n<blockquote>\n<p>I assume that the Arrow developers will eventually read my 2006 paper on\n  compression in column-stores and expand their compression options to include\n  other schemes which can be operated on directly (such as run-length-encoding\n  and bit-vector compression). I also expect that they will read the X100\n  compression paper which includes schemes which can be decompressed using\n  vectorized processing. Thus, I expect that Arrow will eventually support an\n  expanded set of compression options beyond just dictionary compression. But\n  it is far less likely that we will see heavier-weight schemes like gzip and\n  snappy in the Apache Arrow library any time soon.</p>\n</blockquote>\n<p>I'm familiar with these papers as are many of the other Arrow PMC members. That\nwe have not implemented these compression schemes is not a function of our\nignorance, but rather our available time and engineering resources. We must\nwalk before we can run.</p>\n<p>As far as compression libraries like Snappy and GZIP, I see no reason not to\nsupport them as there may be use cases for Arrow where network transfer\nbandwidth is more of a concern, and using Arrow with buffer compression as an\nalternative to producing the more expensive Parquet format might be an\nattractive and simple tradeoff for ephemeral data RPC.</p>\n<hr>\n<p>Prof. Abadi later writes:</p>\n<blockquote>\n<p>But for main memory, it takes less than ten sequential reads to amortize the\n  cost of the original random read. This enables the batch size of Apache Arrow\n  data to be much smaller than batch sizes of disk-oriented storage\n  formats. Apache Arrow actually fixes batches to be no more 64K records.</p>\n</blockquote>\n<p>It is true that a system may choose to use small batches, but it is not correct\nthat Arrow constrains batch sizes to be no larger than 64K records. A batch can\ncontain 1 record or a billion. The metadata provides for arbitrarily long Arrow\nvectors, and we leverage this in the C++ implementation.</p>\n<h3>Conclusions</h3>\n<p>I'm excited to engage more with luminaries in the analytic database world on\nArrow. One of my objectives with helping start the project was to create the\nenvironment for cross-pollination between the analytic database community and\nthe data science community. Compared with the types of runtime systems in use\nby Python and R programmers, analytic databases are, generally speaking, much\nmore sophisticated in performance and scalability.</p>\n<p>We certainly have a lot of work to do, and Prof. Abadi points out areas where\nmore work and community investment is needed. As more pieces of Arrow fall into\nplace, and more integrations in other projects get built, things are going to\nget very exciting for all involved.</p>"
}