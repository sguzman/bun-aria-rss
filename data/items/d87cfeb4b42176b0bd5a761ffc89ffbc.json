{
  "id": "tag:blogger.com,1999:blog-15045980.post-8115141727768781054",
  "published": "2020-08-07T09:01:00.005-07:00",
  "updated": "2020-08-07T09:18:56.367-07:00",
  "category": [
    "",
    "",
    ""
  ],
  "title": "Code Coverage Best Practices",
  "content": "By Carlos Arguelles, Marko Ivanković‎, and Adam Bender<div><br /></div><div><br /></div><div><i>We have spent several decades driving software testing initiatives in various very large software companies. One of the areas that we have consistently advocated for is the use of code coverage data to assess risk and identify gaps in testing. However, the value of code coverage is a highly debated subject with strong opinions, and a surprisingly polarizing topic. Every time code coverage is mentioned in any large group of people, seemingly endless arguments ensue. These tend to lead the conversation away from any productive progress, as people securely bunker in their respective camps. The purpose of this document is to give you tools to steer people on all ends of the spectrum to find common ground so that you can move forward and use coverage information pragmatically. We put forth best practices in the domain of code coverage to work effectively with code health.</i></div><div><br /></div><div><ul style=\"text-align: left;\"><li style=\"padding: 15px 0px;\"><span style=\"font-weight: bold;\">Code coverage provides significant benefits to the developer workflow.</span> It is not a perfect measure of test quality, but it does offer a reasonable, objective, industry standard metric with actionable data. It does not require significant human interaction, it applies universally to all products, and there are ample tools available in the industry for most languages. You must treat it with the understanding that it’s a lossy and indirect metric that compresses a lot of information into a single number so it should not be your only source of truth.&nbsp; Instead, use it in conjunction with other techniques to create a more holistic assessment of your testing efforts.</li><li style=\"padding: 15px 0px;\"><span style=\"font-weight: bold;\">It is an open research question whether code coverage alone reduces defects,</span> but our experience shows that efforts in increasing code coverage can often lead to culture changes in engineering excellence that in the long run reduce defects. For example, teams that give code coverage priority tend to treat testing as a first class citizen, and tend to bake stronger testability into their product design, so that they can achieve their testing goals with less effort. All this in turn leads to writing higher quality code to begin with (more modular, cleaner contracts in their APIs, more manageable code reviews, etc.). They also start caring more about their overall health, and engineering and operational excellence.</li><li style=\"padding: 15px 0px;\"><span style=\"font-weight: bold;\">A <u>high</u> code coverage percentage does not guarantee high quality in the test coverage.</span> Focusing on getting the number as close as possible to 100% leads to a false sense of security. It could also be wasteful, burning machine cycles and creating technical debt from low-value tests that now need to be maintained. Bad code being pushed to production due to missing tests could happen either because (a) your tests did not cover a specific path of code, a test gap that is easy to identify with code coverage analysis, or (b) because your tests did not cover a specific edge case in an area that did have code coverage, which is difficult or impossible to catch with code coverage analysis. Code coverage does not guarantee that the covered lines or branches have been tested <i>correctly</i>, it just guarantees that they have been executed by a test. Be mindful of copy/pasting tests just for the sake of increasing coverage, or adding tests with little actual value, to comply with the number. A better technique to assess whether you’re adequately exercising the lines your tests cover, and adequately asserting on failures, is <a href=\"https://research.google/pubs/pub46584/\">mutation</a> testing.</li><li style=\"padding: 15px 0px;\"><span style=\"font-weight: bold;\">But a <u>low</u> code coverage number does guarantee that large areas of the product are going completely untested</span> by automation on every single deployment. This increases our risk of pushing bad code to production, so it should receive attention. <i>In fact a lot of the value of code coverage data is to highlight not what’s covered, but what’s not covered.</i></li><li style=\"padding: 15px 0px;\"><span style=\"font-weight: bold;\">There is no “ideal code coverage number” that universally applies to all products.</span> The level of testing you want/need for a set of code should be a function of (a) business impact/criticality of the code; (b) how often you will need to touch/change the code; (c) how much longer you expect the code to live, its complexity, and domain variables. We cannot mandate every single team should have x% code coverage; this is a business decision best made by the owners of the product with domain-specific knowledge. Any mandate to reach x% code coverage should be accompanied by infrastructure investments to make testing easy, such as integrating tools into the developer workflow. Be mindful that engineers may start treating your target like a checkbox and avoid increasing coverage beyond the target, even if doing so would be prudent.</li><li style=\"padding: 15px 0px;\"><span style=\"font-weight: bold;\">In general code coverage of a lot of products is below the bar; we should aim at significantly improving code coverage across the board.</span> Although there is no “ideal code coverage number,” at Google we offer the general guidelines of 60% as “acceptable”, 75% as “commendable” and 90% as “exemplary.” However we like to stay away from broad top-down mandates and encourage every team to select the value that makes sense for their business needs.</li><li style=\"padding: 15px 0px;\"><span style=\"font-weight: bold;\">We should not be obsessing on how to get from 90% code coverage to 95%.</span> The gains of increasing code coverage beyond a certain point are logarithmic. But we should be taking concrete steps to get from 30% to 70% and always making sure new code meets our desired threshold.</li><li style=\"padding: 15px 0px;\"><span style=\"font-weight: bold;\">More important than the percentage of lines covered is human judgment over the actual lines of code (and behaviors)&nbsp; that aren’t being covered</span> (analyzing the gaps in testing) and whether this risk is acceptable or not. What’s not covered is more meaningful than what is covered. Pragmatic discussions over specific lines of code not covered that take place during the code review process are more valuable than over-indexing on an arbitrary target number. We have found out that embedding code coverage into your code review process makes code reviews faster and easier. Not all code is equally important, for example testing debug log lines is often not as important, so when developers can see not just the coverage number, but each covered line highlighted as part of the code review, they will make sure that the most important code is covered.&nbsp;</li><li style=\"padding: 15px 0px;\"><span style=\"font-weight: bold;\">Just because your product has low code coverage doesn’t mean you can’t take concrete, incremental steps to improve it over time.</span> Inheriting a legacy system with poor testing and poor testability can be daunting, and you may not feel empowered to turn it around, or even know where to start. But at the very least, you can adopt the ‘boy-scout rule’ (leave the campground cleaner than you found it). Over time, and incrementally, you will get to a healthy location.</li><li style=\"padding: 15px 0px;\"><span style=\"font-weight: bold;\">Make sure that frequently changing code is covered.</span> While project wide goals above 90% are most likely not worth it, per-commit coverage goals of 99% are reasonable, and 90% is a good lower threshold. We need to ensure that our tests are not getting worse over time.</li><li style=\"padding: 15px 0px;\"><span style=\"font-weight: bold;\">Unit test code coverage is only a piece of the puzzle.</span> Integration/System test code coverage is important too. And the aggregate view of the coverage of all sources in your Pipeline (unit and integration) is paramount, as it gives you the bigger picture of how much of your code is not exercised by your test automation as it makes its way in your pipeline to a production environment. One thing you should be aware of is while unit tests have high correlation between executed and evaluated code, some of the coverage from integration tests and end-to-end tests is incidental and not deliberate. But incorporating code coverage from integration tests can help you avoid situations where you have a false sense of security that even though you’re not covering code in your unit tests, you think you’re covering it in your integration tests.</li><li style=\"padding: 15px 0px;\"><span style=\"font-weight: bold;\">We should gate deployments that do not meet our code coverage standards.</span> Teams should debate and decide which gating mechanism makes sense to them. You should however be careful that it doesn’t turn into being treated as a checkbox that is required to be filled, as it can backfire (pressure to 'hit the metric' almost never yields the desired outcome). There are many mechanisms available:&nbsp; gate on coverage for all code vs gate on coverage to new code only; gate on a specific hard-coded code coverage number vs gate on delta from prior version, specific parts of the code to ignore or focus on. And then, commit to upholding these as a team. Drops in code coverage violating the gate should prevent the code from being checked in and reaching production.&nbsp;</li></ul><div><br /></div></div><div><i>If you would like to learn more about Google's coverage infrastructure, we welcome you to read our paper “Coverage at Google” which can be found <a href=\"https://research.google/pubs/pub48413/\">here</a>.</i></div>",
  "link": [
    "",
    "",
    "",
    "",
    ""
  ],
  "author": {
    "name": "Google Testing Bloggers",
    "uri": "http://www.blogger.com/profile/03153388556673050910",
    "email": "noreply@blogger.com",
    "gd:image": ""
  },
  "thr:total": 3
}