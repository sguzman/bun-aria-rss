{
  "title": "MSPred: Video Prediction at Multiple Spatio-Temporal Scales with Hierarchical Recurrent Networks. (arXiv:2203.09303v3 [cs.CV] UPDATED)",
  "link": "http://arxiv.org/abs/2203.09303",
  "description": "<p>Autonomous systems not only need to understand their current environment, but\nshould also be able to predict future actions conditioned on past states, for\ninstance based on captured camera frames. However, existing models mainly focus\non forecasting future video frames for short time-horizons, hence being of\nlimited use for long-term action planning. We propose Multi-Scale Hierarchical\nPrediction (MSPred), a novel video prediction model able to simultaneously\nforecast future possible outcomes of different levels of granularity at\ndifferent spatio-temporal scales. By combining spatial and temporal\ndownsampling, MSPred efficiently predicts abstract representations such as\nhuman poses or locations over long time horizons, while still maintaining a\ncompetitive performance for video frame prediction. In our experiments, we\ndemonstrate that MSPred accurately predicts future video frames as well as\nhigh-level representations (e.g. keypoints or semantics) on bin-picking and\naction recognition datasets, while consistently outperforming popular\napproaches for future frame prediction. Furthermore, we ablate different\nmodules and design choices in MSPred, experimentally validating that combining\nfeatures of different spatial and temporal granularity leads to a superior\nperformance. Code and models to reproduce our experiments can be found in\nhttps://github.com/AIS-Bonn/MSPred.\n</p>",
  "dc:creator": "<a href=\"http://arxiv.org/find/cs/1/au:+Villar_Corrales_A/0/1/0/all/0/1\">Angel Villar-Corrales</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karapetyan_A/0/1/0/all/0/1\">Ani Karapetyan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boltres_A/0/1/0/all/0/1\">Andreas Boltres</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Behnke_S/0/1/0/all/0/1\">Sven Behnke</a>"
}