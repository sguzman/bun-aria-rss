{
  "id": "yt:video:htjpbbvHJQo",
  "yt:videoId": "htjpbbvHJQo",
  "yt:channelId": "UCBa5G_ESCn8Yd4vw5U-gIcg",
  "title": "Stanford Seminar - ML Explainability Part 4 I Evaluating Model Interpretations/Explanations",
  "link": "",
  "author": {
    "name": "Stanford Online",
    "uri": "https://www.youtube.com/channel/UCBa5G_ESCn8Yd4vw5U-gIcg"
  },
  "published": "2022-11-05T16:30:05+00:00",
  "updated": "2022-11-05T16:30:05+00:00",
  "media:group": {
    "media:title": "Stanford Seminar - ML Explainability Part 4 I Evaluating Model Interpretations/Explanations",
    "media:content": "",
    "media:thumbnail": "",
    "media:description": "Professor Hima Lakkaraju describes how explanation methods can be compared and evaluated. Interpretability evaluation techniques range from the highly quantitative, where interpretability is replaced with a metric such as the number of rules or parameters, to qualitative where humans are asked to rate the interpretation.\n\nView the full playlist: https://www.youtube.com/playlist?list=PLoROMvodv4rPh6wa6PGcHH6vMG9sEIPxL",
    "media:community": {
      "media:starRating": "",
      "media:statistics": ""
    }
  }
}