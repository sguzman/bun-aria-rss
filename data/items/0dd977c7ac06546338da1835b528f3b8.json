{
  "title": "Why Tech Companies Are Limiting Police Use of Facial Recognition",
  "description": "In June 2020, Amazon, Microsoft and IBM announced that they were limiting some uses of their facial recognition technology. In this encore episode, Maddie and Emily talk to AI policy analyst <a href=\"https://cyber.harvard.edu/people/mutale-nkonde\">Mutale Nkonde</a> about algorithmic bias — how facial recognition software can discriminate and reflect the biases of society and the current debate about policing has brought up the issue about how law enforcement should use this technology.",
  "pubDate": "Thu, 18 Feb 2021 04:00:00 -0500",
  "copyright": "Copyright 2019-2021 NPR - For Personal Use Only",
  "guid": "5390b707-19c0-4b5d-a07b-5862a1fae6b0",
  "link": "https://www.npr.org/2021/02/17/968710172/why-tech-companies-are-limiting-police-use-of-facial-recognition",
  "itunes:title": "Why Tech Companies Are Limiting Police Use of Facial Recognition",
  "itunes:author": "NPR",
  "itunes:summary": "AI policy analyst Mutale Nkonde talks about bias in AI — how facial recognition software can be discriminatory, reflecting societal biases.",
  "itunes:subtitle": "AI policy analyst Mutale Nkonde talks about bias in AI — how facial recognition software can be discriminatory, reflecting societal biases.",
  "itunes:image": "",
  "itunes:duration": 825,
  "itunes:explicit": "no",
  "itunes:episodeType": "full",
  "content:encoded": "In June 2020, Amazon, Microsoft and IBM announced that they were limiting some uses of their facial recognition technology. In this encore episode, Maddie and Emily talk to AI policy analyst <a href=\"https://cyber.harvard.edu/people/mutale-nkonde\">Mutale Nkonde</a> about algorithmic bias — how facial recognition software can discriminate and reflect the biases of society and the current debate about policing has brought up the issue about how law enforcement should use this technology.",
  "enclosure": ""
}