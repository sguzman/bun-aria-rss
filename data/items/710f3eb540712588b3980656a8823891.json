{
  "title": "Data carpentry",
  "link": "http://mimno.infosci.cornell.edu/b/articles/carpentry/",
  "pubDate": "Mon, 18  Aug 2014 20:00:00 -0400",
  "guid": "http://mimno.infosci.cornell.edu/b/articles/carpentry/",
  "author": "",
  "description": "<p>The New York Times has an article titled <a href=\"http://www.nytimes.com/2014/08/18/technology/for-big-data-scientists-hurdle-to-insights-is-janitor-work.html\">For Big-Data Scientists, ‘Janitor Work’ Is Key Hurdle to Insights</a>. \nMostly I really like it. The fact that raw data is rarely usable for analysis without significant work is a point I try hard to\nmake with my students.\nI told them “do not underestimate the difficulty of data preparation”. \nWhen they turned in their projects, many of them reported that they had underestimated the difficulty of data preparation.\nRecognizing this as a hard problem is great.</p>\n<p>What I’m less thrilled about is calling this “janitor work”.\nFor one thing, it’s not particularly respectful of custodians, whose work I really appreciate.\nBut it also mischaracterizes what this type of work is about.\nI’d like to propose a different analogy that I think fits a lot better: <em>data carpentry</em>.</p>\n<p><span class=\"more\"></span></p>\n<p><em>Note: <a href=\"http://software-carpentry.org/blog/2014/05/our-first-data-carpentry-workshop.html\">data carpentry</a> seems to already be a thing</em></p>\n<p>Why is woodworking a better analogy?\nThe article uses a few other terms, like data wrangling (data as unruly beasts to be tamed?) and munging (what is that, anyway?), neither of which mean much to me. I also like <em>data curation</em> but that’s also a bit vague.\nData carpentry probably has something to do with wishing I could make things like <a href=\"http://bridge.library.wisc.edu/Projects_VictorianEyes_Roll_of_the_Topics.html\">Carrie Roy</a>, but\nI should start by saying what I don’t like about the “data cleaning” or “janitor work” terms.\nTo me these imply that there is some kind of pure or clean data buried in a thin layer of non-clean data, and that one need only hose the dataset off to reveal the hard porcelain underneath the muck.\nIn reality, the process is more like deciding how to cut into a piece of material, or how much to plane down a surface.\nIt’s not that there’s any real distinction between good and bad, it’s more that some parts are softer or knottier than others.\nJudgement is critical.</p>\n<p>The scale of data work is more like woodworking, as well.\nSometimes you may have a whole tree in front of you, and only need a single board.\nThere’s nothing wrong with the rest of it, you just don’t need it right now.</p>\n<p>Finally, as the article points out, data work is as much about joining things together as it is selecting and pruning.\nLike building a data chair —- you turn a dataset on the data lathe, and then glue it to the appropriate slot in another dataset.\nCarpentry has all these aspects, from selecting and shaping to careful joinery.</p>\n<p>But there are other aspects of carpentry that make it an appealing metaphor.\nI don’t know as much as I’d like about woodworking, but my impression is that it is not so much a single discipline as a vast array of specific skills.\nNone of these are particularly difficult by themselves, but knowing which tool or method to use at each stage and carrying out each one cleanly and efficiently takes years of practice.\nData carpentry, which I’ve been practicing in one way or another for about 15 years (though never as my official responsibility), is likewise not a single process but a thousand little skills and techniques.\nInstead of feeling the grain of a pine board, I spot the distinctive marks of broken UTF-8.\nInstead of a router and drill press I use perl (that’s right, perl) and shell scripts.\nBut even after that much time, I would still say I’m just fairly good. Building up solid instincts and a suite of processes makes me a lot faster than beginners, but I can’t foresee running out of scripts to write.</p>\n<p>So where does this leave us? \nI got the impression that the main purpose of the NYT article was to introduce a class of promising startups.\nI think these will do a good job of knocking off 60-80% of common cases, which will certainly save a lot of people a lot of time.\nI also think that if anyone can systematize data work, Jeff Heer and his team are a good bet (although writing an article about data work and not mentioning Hadley Wickham at RStudio is like writing an article about symphonies and not mentioning Beethoven).\nBut I cannot imagine that data carpentry will not be a major part of the work of data science in the future.\nEvery data set has its idiosyncrasies. You can streamline the process, but you can’t avoid it.\nTo draw out the analogy a bit more: sure, there’s Ikea, but the best furniture is still made by Amish carpenters.</p>\n<p>Most importantly, I don’t think we want to make data carpentry automated —- and therefore invisible.\nLillian Lee and I were recently commiserating about the tendency of machine learning students to never look at the data they’re working with.\nWe both felt that to be really effective, you have to understand both the generalities and the specifics of a model.\nThere’s no substitute for experiencing the data set directly, and comparing this experience to a skilled, hands-on craft like woodwork feels right to me.</p>"
}