{
  "title": "Human Pose Detection",
  "link": "https://medium.com/@samim/human-pose-detection-51268e95ddc2?source=rss-f3c8148878e1------2",
  "guid": "https://medium.com/p/51268e95ddc2",
  "category": [
    "machine-learning",
    "artificial-intelligence"
  ],
  "dc:creator": "samim",
  "pubDate": "Mon, 22 May 2017 23:01:55 GMT",
  "atom:updated": "2017-05-23T20:21:08.641Z",
  "content:encoded": "<h4>Mining Body Language from Videos</h4><p>From Gene Kelly’s Step-Dance to Bruce Lee’s Kung-Fu — iconic movement has made history. Communicating through <a href=\"https://en.wikipedia.org/wiki/Body_language\">Body Language</a> is an ancient art form, currently evolving in fascinating ways: <strong>Computationally detecting human body language is becoming effective and accessible. </strong>This experiment explores enabling technologies, applications & implications.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/916/1*2lETIHaA48xDPnxlhTvWqg.jpeg\" /><figcaption>Human Pose Estimation, using OpenPose. Footage by Boston Dynamics.</figcaption></figure><p><strong>For over 20 years</strong>, <a href=\"https://en.wikipedia.org/wiki/Motion_capture\">Motion Capture</a> has enabled us to record actions of humans and then use that information to animate a digital character or analyse poses. While movie makers and game developers embraced such technologies — it until recently required expensive equipment which captured only few aspects of the overall performance.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/694/1*o74wXStwInealT7VjK-wrQ.jpeg\" /><figcaption>Human Pose Estimation. Image by OpenPose</figcaption></figure><p><strong>Today</strong>, a new generation of machine learning based systems is making it possible to <strong>detect human body language directly from images. </strong>A growing number of research papers and open-source libraries addresses key aspects: <em>Body, Hand, Face, Gaze Tracking. Identity, Gender, Age, Emotion and Muscle strain Detection. Action Classification & Prediction. </em>We now can...</p><blockquote><strong>Imagine a world where every camera is a realtime body language detector — and every video can be analysed.</strong></blockquote><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/928/1*LVMs2B1yuCDHCGzDkExOow.jpeg\" /><figcaption><a href=\"https://en.wikipedia.org/wiki/The_Ministry_of_Silly_Walks\">Ministry of Silly Walks</a> — John Cleese — <a href=\"https://en.wikipedia.org/wiki/Monty_Python\">Monty Python</a> — processed with OpenPose.</figcaption></figure><h3>Experiment: Human Pose Detection in Videos</h3><p>Cinema and online video sites are a vast source of recorded human performances. Any imaginable movement has been discovered and perfected: walks, dances, gestures, drama, love and fight scenes. As the new generation of body tracking tools enables us to “mine” body language data from any video, we can now easily “steal” motion from famous movies and then use that data to drive characters in AR/VR — to name just one example.</p><p><strong>The following video is made using the OpenPose library to detect human body poses in movie scenes and video clips.</strong></p><iframe src=\"https://cdn.embedly.com/widgets/media.html?url=http%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3D9veagUn1KFY&src=https%3A%2F%2Fwww.youtube.com%2Fembed%2F9veagUn1KFY&type=text%2Fhtml&key=d04bfffea46d4aeda930ec88cc64b87c&schema=youtube\" width=\"854\" height=\"480\" frameborder=\"0\" scrolling=\"no\"><a href=\"https://medium.com/media/759e86ce3b475ebe58df1564419dc6fe/href\">https://medium.com/media/759e86ce3b475ebe58df1564419dc6fe/href</a></iframe><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/890/1*AD9waikeC5dyg_p9I4wHbg.jpeg\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Sn4iLt-jRLOQ17yRnY_Eqw.jpeg\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*yfMVs6SOgFpQGDc9LeSKGg.jpeg\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*z-M0EE3B2VdWmIGaYHM9sA.jpeg\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/920/1*b3usXach-i5LHz6-j6ZLTA.jpeg\" /></figure><p>The video tests OpenPose on diverse sources, including sport games, James Brown’s dance routines and Kung-Fu scenes. The Library detected a wide range of footage robustly — failing infrequently in delightfully comedic ways.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*FYGPQWlHUhlAGtjJkf_BuA.jpeg\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*zlqbgFqsE97S-_BmsykLDA.jpeg\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*1bQaCi8OdZ3oY3z1H8iTcQ.jpeg\" /><figcaption>Cloning Yoga & Tai-Chi Class Videos is exceptionally easy todo.</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*F9jlOpSQegs52EyKMhByQQ.jpeg\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Fi0MtXvEynN2r1n8efpzpQ.jpeg\" /><figcaption>Stick Figures & Skeletons.</figcaption></figure><h3>OpenPose</h3><p>All experiment videos were processes with <a href=\"https://github.com/CMU-Perceptual-Computing-Lab/openpose\">OpenPose</a> - a open-source <strong>library for real-time multi-person keypoint detection</strong> — <a href=\"https://arxiv.org/abs/1611.08050\">authored</a> by <a href=\"https://www.linkedin.com/in/gineshidalgo/\">Gines Hidalgo</a>, <a href=\"http://www.andrew.cmu.edu/user/zhecao\">Zhe Cao</a>, <a href=\"http://www.cs.cmu.edu/~tsimon/\">Tomas Simon</a>, <a href=\"https://scholar.google.com/citations?user=sFQD3k4AAAAJ&hl=en\">Shih-En Wei</a>, <a href=\"http://www.cs.cmu.edu/~hanbyulj/\">Hanbyul Joo</a> and <a href=\"http://www.cs.cmu.edu/~yaser/\">Yaser Sheikh</a>. It enables the detection of 18 body keypoints from images and is invariant to the number of detected people. Even though the library is in rapid development, it works reliably out of the box and is fun to use.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*K-PHx6CcfjJRnuMP5W51Eg.jpeg\" /></figure><p>OpenPose uses a interesting pipeline to achieve it’s robust performance. The paper “<a href=\"https://arxiv.org/abs/1611.08050\">Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields</a>” gives a overview of the inner workings of the System. Finally, this:</p><h4><strong>“Hands & Face Estimation — Coming Soon!”</strong></h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/800/1*WRvs7kp-Q3ib_0rY-LLNew.gif\" /><figcaption>Hands & Face Estimation Image — by OpenPose</figcaption></figure><h3>Body Language?</h3><p>OpenPose does not model the entire spectrum of human body language. Today’s systems are still struggling with hard challenges and are limited in scope, yet development is moving very fast. Combined with components such as <a href=\"https://github.com/oarriaga/face_classification\"><strong>Face, Gender and age classification</strong></a><strong>, </strong><a href=\"https://arxiv.org/abs/1611.08860v2\"><strong>Gaze Estimation</strong></a><strong>, </strong><a href=\"https://github.com/ShuangLI59/person_search\"><strong>Person Identification</strong></a><strong>, </strong><a href=\"https://arxiv.org/abs/1705.02445v1\"><strong>motion prediction</strong></a><strong> and </strong><a href=\"https://github.com/search?utf8=%E2%9C%93&q=emotion+detection&type=\"><strong>emotion detection</strong></a><strong>, </strong>we are gradually arriving at a computational perspective of human body language.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/435/1*Lyg8qUARKe3k2s8D1V-Ahg.jpeg\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/599/1*hfOQU5UDCGEjGOuIIfCY0A.jpeg\" /><figcaption><a href=\"https://github.com/oarriaga/face_classification\">Real-time face detection and emotion/gender classification</a> | <a href=\"https://github.com/ShuangLI59/person_search\">Person Identification and Search</a></figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*7_7IwVnC_9tBpUv50wPJBQ.jpeg\" /></figure><h3>Applications</h3><p><strong>The list of possible applications is long and growing. Here is a summery of fields, where human body language detection might find heavy use:</strong></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*It9I-C3I3mdVIIE4-CRSaA.jpeg\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/698/1*ipvpFKUJyMDt1O5u70-xQA.jpeg\" /><figcaption><strong>Human Computer Interaction: </strong><a href=\"http://resources.mpi-inf.mpg.de/coactivationclustering/bachynskyi2015.pdf\">Novel Input Methods with Muscle Coactivation Clustering</a><strong> — Games and VR: </strong><a href=\"https://www.youtube.com/watch?v=MSTge5IDxF4\">Real-time Mocap and VR in UDK</a></figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*BqddVOS2LyRQiU-KKMQhaA.jpeg\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*FXr7B_GlBsY8anA6UM1xww.jpeg\" /><figcaption><strong>Surveillance: </strong><a href=\"http://www.arabianbusiness.com/world-s-first-robocop-joins-dubai-police-force-674837.html\">“Robocop” joins Dubai Police </a><strong>| </strong><a href=\"http://www.mirror.co.uk/news/uk-news/saatchis-intelligent-billboard-can-tell-6125060\"><strong>Advertising</strong></a><strong>: </strong><a href=\"http://www.mirror.co.uk/news/uk-news/saatchis-intelligent-billboard-can-tell-6125060\">Intelligent billboard can tell if you are smiling</a></figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*SAezIbd-3PT0LAV_-AIXEg.jpeg\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*xqABNEL6hYWJw8BpfR_jFQ.jpeg\" /><figcaption><strong>Military, Science, Art, Magic and Comedy</strong></figcaption></figure><h4>Pantomim, Butoh and Gnawa Performances — as seen by OpenPose:</h4><iframe src=\"https://cdn.embedly.com/widgets/media.html?url=http%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DZxa9ZyEXTlo&src=https%3A%2F%2Fwww.youtube.com%2Fembed%2FZxa9ZyEXTlo&type=text%2Fhtml&key=d04bfffea46d4aeda930ec88cc64b87c&schema=youtube\" width=\"854\" height=\"480\" frameborder=\"0\" scrolling=\"no\"><a href=\"https://medium.com/media/46577139778e0f3c94507d0375029364/href\">https://medium.com/media/46577139778e0f3c94507d0375029364/href</a></iframe><h3>Final Thoughts</h3><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Eug-PdynzO6m5nkRrj-0EQ.jpeg\" /></figure><blockquote>Get in touch here: <a href=\"https://twitter.com/samim\">twitter.com/samim</a> |<a href=\"http://samim.io/\">http://samim.io</a></blockquote><blockquote><a href=\"https://tinyletter.com/samim\">Sign up for the Newsletter for more experiments like this!</a></blockquote><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Orm9_-Ocu2dZa1lGEfMVoQ.jpeg\" /><figcaption>OpenPose meets a yoga master…</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/623/1*wZ8cOGzrOtJxDuh3C02wpg.jpeg\" /></figure><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=51268e95ddc2\" width=\"1\" height=\"1\" alt=\"\">"
}