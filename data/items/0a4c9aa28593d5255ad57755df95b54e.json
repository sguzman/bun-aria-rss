{
  "title": "Two papers released on arXiv, \"Operator Variational Inference\" and \"Model Criticism for Bayesian Causal Inference\"",
  "link": "http://dustintran.com/blog/two-papers-released-on-arxiv",
  "guid": "http://dustintran.com/blog/two-papers-released-on-arxiv",
  "description": "<p>Two papers of mine were released today on arXiv.</p>\n\n<ul>\n  <li><a href=\"https://arxiv.org/abs/1610.09033\">Operator variational inference</a>, in collaboration with Rajesh Ranganath, Jaan Altosaar, and David Blei.</li>\n  <li><a href=\"https://arxiv.org/abs/1610.09037\">Model criticism for Bayesian causal inference</a>, in collaboration with Francisco Ruiz, Susan Athey, and David Blei.</li>\n</ul>\n\n<p>Last week, I gave a talk at OpenAI on operator variational\ninference and Edward. I can now release those\n<a href=\"http://dustintran.com/talks/Tran_Operator_Edward.pdf\">slides online</a>.</p>\n\n<h2 id=\"operator-variational-inference\">Operator variational inference</h2>\n\n<p>Operator VI is a paper I’m really excited about. It is at\n<a href=\"https://nips.cc\">NIPS</a> this year. Most directly, it’s a continuation of work that\nRajesh and I have been developing on the aim for more expressive\napproximations for variational inference.  We’ve seen this with the\nvariational Gaussian process <a href=\"#tran2016variational\">(Tran, Ranganath, &amp; Blei, 2016)</a> and hierarchical variational models <a href=\"#ranganath2016hierarchical\">(Ranganath, Tran, &amp; Blei, 2016)</a> (and if you’ve\nread my older work, copula variational inference\n<a href=\"#tran2015copula\">(Tran, Blei, &amp; Airoldi, 2015)</a>).</p>\n\n<p>More generally, in variational inference, we always make tradeoffs\nbetween the statistical efficiency of the approximation and the\ncomputational complexity of the algorithm. (This is partly what Andrew\nGelman calls the “efficiency frontier”.) However, we don’t quite have\na knob for controlling this tradeoff, nor do we have a way of even\nformalizing these notions.</p>\n\n<p>Operator VI is a proposed solution to this problem. It formalizes\nthese tradeoffs, and it analyzes how we can characterize different\napproaches to variational inference in order to achieve specific\naims. As one example, we show how to develop the most expressive\nposterior approximations, which we call “variational programs”.\nVariational programs do not require a tractable density, and they bring\nvariational inference closer to powerful inferential techniques as in\ngenerative adversarial networks\n<a href=\"#goodfellow2014generative\">(Goodfellow et al., 2014)</a>.</p>\n\n<h2 id=\"model-criticism-for-bayesian-causal-inference\">Model criticism for Bayesian causal inference</h2>\n\n<p>To me, causal inference is one of the most interesting fields in statistics\nand machine learning, and with the greatest potential for long term impact.\nIt can significantly speed up progress towards something like\nartificial general intelligence (and is arguably necessary to achieve it). And most immediately, it enables richer\ndata analyses to capture scientific phenomena. In order for our models\nto truly infer generative processes, they must understand and learn\ncausal notions of the world.</p>\n\n<p>Much of the work in the causal inference community has focused on\nnonparametric models, which make few modeling assumptions. They\nsatisfy theoretic notions such as asymptotics and can perform well on\nsmall-to-medium size data sets (a typical setting setting in applied\ncausal inference). However, in higher-dimensional and massive data\nsettings, we require more complex generative models,\nas we’ve seen in probabilistic machine learning.</p>\n\n<p>There’s a caveat to this. Before being able to build rich, complex (and possibly deep)\ncausal models, we first need a way of evaluating them.  This arXiv\npaper addresses that issue. It is a foundational question\nmore generally in the area of model criticism, also known as model\nchecking and diagnostics. We ask the question, “To what extent\nis my model falsified by the empirical data?”. By answering it, we can\nprobe different assumptions in our model and possibly revise them,\nthus better capturing causal mechanisms.</p>\n\n<h2 id=\"references\">References</h2>\n\n<ol class=\"bibliography\"><li><span id=\"goodfellow2014generative\">Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., … Bengio, Y. (2014). Generative adversarial nets. In <i>Neural Information Processing Systems</i>.</span></li>\n<li><span id=\"ranganath2016hierarchical\">Ranganath, R., Tran, D., &amp; Blei, D. M. (2016). Hierarchical variational models. In <i>International Conference on Machine Learning</i>.</span></li>\n<li><span id=\"tran2015copula\">Tran, D., Blei, D. M., &amp; Airoldi, E. M. (2015). Copula variational inference. In <i>Neural Information Processing Systems</i>.</span></li>\n<li><span id=\"tran2016variational\">Tran, D., Ranganath, R., &amp; Blei, D. M. (2016). The variational Gaussian process. In <i>International Conference on Learning Representations</i>.</span></li></ol>",
  "pubDate": "Sun, 30 Oct 2016 00:00:00 -0700"
}