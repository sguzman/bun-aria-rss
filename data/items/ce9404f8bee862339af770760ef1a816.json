{
  "title": "MemoNet:Memorizing Representations of All Cross Features Efficiently via Multi-Hash Codebook Network for CTR Prediction. (arXiv:2211.01334v2 [cs.IR] UPDATED)",
  "link": "http://arxiv.org/abs/2211.01334",
  "description": "<p>New findings in natural language processing(NLP) demonstrate that the strong\nmemorization capability contributes a lot to the success of large language\nmodels.This inspires us to explicitly bring an independent memory mechanism\ninto CTR ranking model to learn and memorize all cross\nfeatures'representations. In this paper,we propose multi-Hash Codebook\nNETwork(HCNet) as the memory mechanism for efficiently learning and memorizing\nrepresentations of all cross features in CTR tasks.HCNet uses multi-hash\ncodebook as the main memory place and the whole memory procedure consists of\nthree phases: multi-hash addressing,memory restoring and feature\nshrinking.HCNet can be regarded as a general module and can be incorporated\ninto any current deep CTR model.We also propose a new CTR model named MemoNet\nwhich combines HCNet with a DNN backbone.Extensive experimental results on\nthree public datasets show that MemoNet reaches superior performance over\nstate-of-the-art approaches and validate the effectiveness of HCNet as a strong\nmemory module.Besides, MemoNet shows the prominent feature of big models in\nNLP,which means we can enlarge the size of codebook in HCNet to sustainably\nobtain performance gains.Our work demonstrates the importance and feasibility\nof learning and memorizing representations of all cross features ,which sheds\nlight on a new promising research direction.\n</p>",
  "dc:creator": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1\">Pengtao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Junlin Zhang</a>"
}