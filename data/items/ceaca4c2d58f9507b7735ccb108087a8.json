{
  "title": "Algorithms, Algorithmic Discrimination, and Autonomous Vehicles with Caleb Watney",
  "pubDate": "Sat, 10 Feb 2018 02:37:19 +0000",
  "guid": "987c3d4ff04b0ad008023a4d3752d37d",
  "link": "https://traffic.libsyn.com/secure/economicsdetective/EP84Watney_EDR.mp3",
  "itunes:image": "",
  "description": "<p>Algorithms, Algorithmic Discrimination, and Autonomous Vehicles with Caleb Watney</p> <p>Today's guest is <a href= \"http://www.rstreet.org/author/cwatney/\" target=\"_blank\" rel= \"noopener\">Caleb Watney</a> of the R Street Institute. In our conversation, we discuss algorithms, particularly with respect to their role in judicial decision making. Later in the conversation, we discuss the algorithms that will one day replace ape brains as the primary controllers of our cars.</p> <div style=\"float: right; padding-left: 10px;\"><a href= \"https://www.amazon.com/Weapons-Math-Destruction-Increases-Inequality/dp/B01JPAE44S/ref=as_li_ss_il?ie=UTF8&linkCode=li2&tag=economicsde0f-20&linkId=b18791283cd808b01c94fd02af14f4bc\" target=\"_blank\" rel=\"noopener\"><img src= \"//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&ASIN=B01JPAE44S&Format=_SL160_&ID=AsinImage&MarketPlace=US&ServiceVersion=20070822&WS=1&tag=economicsde0f-20\" border=\"0\" /></a><img style= \"border: none !important; margin: 0px !important;\" src= \"https://ir-na.amazon-adsystem.com/e/ir?t=economicsde0f-20&l=li2&o=1&a=B01JPAE44S\" alt=\"\" width=\"1\" height=\"1\" border=\"0\" /></div> <p>Caleb wrote <a href= \"http://www.rstreet.org/2017/12/01/when-it-comes-to-criminal-justice-ai-we-need-transparency-and-accountability/\" target=\"_blank\" rel=\"noopener\">a Cato Unbound essay</a> in response to <a href= \"https://www.cato-unbound.org/2017/08/07/cathy-oneil/why-we-need-accountable-algorithms\" target=\"_blank\" rel=\"noopener\">an article by Cathy O'Neil</a>. O'Neil, a mathematician, argues that algorithms could potentially lead us astray. Her book <a href=\"http://amzn.to/2C8b0T7\" target= \"_blank\" rel=\"noopener\">Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy</a> has sounded the alarm about the potential harms of an over-reliance on algorithms.</p> <p>In Caleb's view, O'Neil has pushed too far in the anti-algorithm direction. He points out that private companies have used algorithms to generate amazing innovations. Government is a different story:</p> <blockquote>\"The most compelling concerns about the improper use of AI and algorithms stem primarily from government use of these technologies. Indeed, all the tangible examples of harm O’Neil cites in her essay are the result of poor incentives and structures designed by government. Namely, hiring models at a public teaching hospital, teacher value-added models, recidivism risk models, and Centrelink’s tax-fraud detection model. The poor results of these kinds of interactions, in which governments purchase algorithms from private developers, could be viewed primarily as a failure of the government procurement process. Government contracting creates opportunities for rent-seeking, and the process doesn’t benefit from the same kinds of feedback loops that are ubiquitous in private markets. So it should be no surprise that governments end up with inferior technology.\"</blockquote> <p>We discuss the merits and demerits of algorithms, how different private and public incentives interact with algorithms, and the difficulties in creating algorithms that can be fair and transparent. Caleb's ultimate solution for many of the problems associated with algorithms used by the government <a href= \"http://www.rstreet.org/2017/12/01/when-it-comes-to-criminal-justice-ai-we-need-transparency-and-accountability/\" target=\"_blank\" rel=\"noopener\">is for those algorithms to be open source</a> in order to foster public scrutiny of their processes and outcomes.</p> <hr /> <p>During the conversation, Caleb alludes to <a href= \"https://arxiv.org/abs/1609.05807\" target=\"_blank\" rel= \"noopener\">this paper by Kleinberg, Mullainathan, and Raghavan</a>, which shows that there are three competing definitions of algorithmic fairness that cannot all be achieved simultaneously.</p>",
  "content:encoded": "<p>Algorithms, Algorithmic Discrimination, and Autonomous Vehicles with Caleb Watney</p> <p>Today's guest is <a href= \"http://www.rstreet.org/author/cwatney/\" target=\"_blank\" rel= \"noopener\">Caleb Watney</a> of the R Street Institute. In our conversation, we discuss algorithms, particularly with respect to their role in judicial decision making. Later in the conversation, we discuss the algorithms that will one day replace ape brains as the primary controllers of our cars.</p> <a href= \"https://www.amazon.com/Weapons-Math-Destruction-Increases-Inequality/dp/B01JPAE44S/ref=as_li_ss_il?ie=UTF8&linkCode=li2&tag=economicsde0f-20&linkId=b18791283cd808b01c94fd02af14f4bc\" target=\"_blank\" rel=\"noopener\"></a> <p>Caleb wrote <a href= \"http://www.rstreet.org/2017/12/01/when-it-comes-to-criminal-justice-ai-we-need-transparency-and-accountability/\" target=\"_blank\" rel=\"noopener\">a Cato Unbound essay</a> in response to <a href= \"https://www.cato-unbound.org/2017/08/07/cathy-oneil/why-we-need-accountable-algorithms\" target=\"_blank\" rel=\"noopener\">an article by Cathy O'Neil</a>. O'Neil, a mathematician, argues that algorithms could potentially lead us astray. Her book <a href=\"http://amzn.to/2C8b0T7\" target= \"_blank\" rel=\"noopener\">Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy</a> has sounded the alarm about the potential harms of an over-reliance on algorithms.</p> <p>In Caleb's view, O'Neil has pushed too far in the anti-algorithm direction. He points out that private companies have used algorithms to generate amazing innovations. Government is a different story:</p> \"The most compelling concerns about the improper use of AI and algorithms stem primarily from government use of these technologies. Indeed, all the tangible examples of harm O’Neil cites in her essay are the result of poor incentives and structures designed by government. Namely, hiring models at a public teaching hospital, teacher value-added models, recidivism risk models, and Centrelink’s tax-fraud detection model. The poor results of these kinds of interactions, in which governments purchase algorithms from private developers, could be viewed primarily as a failure of the government procurement process. Government contracting creates opportunities for rent-seeking, and the process doesn’t benefit from the same kinds of feedback loops that are ubiquitous in private markets. So it should be no surprise that governments end up with inferior technology.\" <p>We discuss the merits and demerits of algorithms, how different private and public incentives interact with algorithms, and the difficulties in creating algorithms that can be fair and transparent. Caleb's ultimate solution for many of the problems associated with algorithms used by the government <a href= \"http://www.rstreet.org/2017/12/01/when-it-comes-to-criminal-justice-ai-we-need-transparency-and-accountability/\" target=\"_blank\" rel=\"noopener\">is for those algorithms to be open source</a> in order to foster public scrutiny of their processes and outcomes.</p>  <p>During the conversation, Caleb alludes to <a href= \"https://arxiv.org/abs/1609.05807\" target=\"_blank\" rel= \"noopener\">this paper by Kleinberg, Mullainathan, and Raghavan</a>, which shows that there are three competing definitions of algorithmic fairness that cannot all be achieved simultaneously.</p>",
  "enclosure": "",
  "itunes:duration": "48:44",
  "itunes:explicit": false,
  "itunes:keywords": "",
  "itunes:subtitle": "Algorithms, Algorithmic Discrimination, and Autonomous Vehicles with Caleb Watney Today's guest is  of the R Street Institute. In our conversation, we discuss algorithms, particularly with respect to their role in judicial decision making. Later in...",
  "itunes:episode": 84,
  "itunes:episodeType": "full"
}