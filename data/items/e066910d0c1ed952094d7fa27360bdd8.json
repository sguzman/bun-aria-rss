{
  "id": "tag:blogger.com,1999:blog-6141980.post-6896190481346695664",
  "published": "2019-12-18T06:25:00.000-06:00",
  "updated": "2019-12-19T04:47:08.724-06:00",
  "category": [
    "",
    "",
    "",
    "",
    ""
  ],
  "title": "LightOn’s AI Research Workshop — FoRM #4: The Future of Random Matrices. Thursday, December 19th",
  "content": "**&nbsp;<a href=\"https://nuit-blanche.blogspot.com/\">Nuit Blanche</a> is now on Twitter: <a href=\"https://twitter.com/NuitBlog\">@NuitBlog</a>&nbsp;** <br /><br /><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://1.bp.blogspot.com/-30Q09HCFZj8/XfoWhtOgPbI/AAAAAAAAXFQ/_09FuPxkadwW-0QErVx9MraD3CItk805ACLcBGAsYHQ/s1600/LightOn%2BFORM%2B4.jpg\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"675\" data-original-width=\"1200\" height=\"225\" src=\"https://1.bp.blogspot.com/-30Q09HCFZj8/XfoWhtOgPbI/AAAAAAAAXFQ/_09FuPxkadwW-0QErVx9MraD3CItk805ACLcBGAsYHQ/s400/LightOn%2BFORM%2B4.jpg\" width=\"400\" /></a></div><br /><div style=\"text-align: justify;\"><br /></div><div style=\"text-align: justify;\"><br /></div><div style=\"text-align: justify;\">Tomorrow we will feature LightOn’s 4th AI Research workshop on the Future of Random Matrices (FoRM). It starts at <a href=\"https://www.timeanddate.com/worldclock/personal.html?cities=195,179,136,248,224,1232\">2pm on Thursday, December 19th</a>&nbsp;(That’s 2pm CET/Paris, 1pm GMT/UTC/London, 8am EST/NY-Montreal, 5am PST/California, 9pm UTC+8/ Shenzhen). We have an exciting and diverse line-up with talks on compressive learning, binarized neural networks, particle physics, and matrix factorization.</div><div style=\"text-align: justify;\"><br /></div><div style=\"text-align: justify;\">Feel free to <a href=\"https://www.meetup.com/fr-FR/LightOn-meetup/events/266805517/\">join us</a>, or to catch the event livestream — link to be available on this page on the day of the event.<br /><div style=\"text-align: center;\"><br /></div><div style=\"text-align: center;\"><iframe allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen=\"\" frameborder=\"0\" height=\"240\" src=\"https://www.youtube.com/embed/xpDNDKMHu1g\" width=\"424\"></iframe></div><div style=\"text-align: center;\"><br /></div>Without further ado, here is the program:</div><div style=\"text-align: justify;\"><br /></div><div style=\"text-align: justify;\"><br /></div><div style=\"text-align: justify;\">Program</div><ul><li>1:45pm — Welcome coffee and opening. A short introduction about <a href=\"http://lighton.ai/\">LightOn</a>, <a href=\"https://www.linkedin.com/in/IgorCarron\">Igor Carron</a></li><li>2:00pm — Compressive Learning with Random Projections, <a href=\"https://www.cs.bham.ac.uk/~axk/\">Ata Kaban</a></li><li>2:45pm — Medical Applications of Low Precision Neuromorphic Systems, <a href=\"http://penkovsky.com/\">Bodgan Penkovsky</a></li><li>3:30pm — Comparing Low Complexity Linear Transforms, <a href=\"https://gra.ygav.in/\">Gavin Gray</a>4:00pm — Coffee break and discussions</li><li>4:20pm —LightOn’s OPU+Particle Physics, <a href=\"https://scholar.google.com/citations?user=Xzdm_9IAAAAJ&amp;hl=fr\">David Rousseau</a>, <a href=\"https://twitter.com/Aishik_Ghosh_\">Aishik Ghosh</a>, <a href=\"https://www.lri.fr/membre.php?mb=2590\">Laurent Basara</a>, Biswajit Biswas</li><li>5:00pm — Accelerated Weighted (Nonnegative) Matrix Factorization with Random Projections, <a href=\"http://www-lisic.univ-littoral.fr/~puigt/\">Matthieu Puigt</a></li><li>5:45pm — Wrapping-up and beers on our rooftop</li></ul><div style=\"text-align: justify;\"><br /></div><div style=\"text-align: justify;\"><br /></div><div style=\"text-align: justify;\">Talks and abstracts</div><br /><div style=\"box-sizing: inherit; line-height: 1.18; margin: 1.72em 0px -0.31em;\"><a href=\"https://www.cs.bham.ac.uk/~axk/\" style=\"text-align: justify;\">Ata Kaban</a><span style=\"text-align: justify;\">, University of Birmingham.</span><br />Compressive Learning with Random Projections</div><blockquote class=\"tr_bq\"><div style=\"text-align: justify;\">By direct analogy to compressive sensing, compressive learning has been originally coined to mean learning efficiently from random projections of high dimensional massive data sets that have a sparse representation. In this talk we discuss compressive learning without the sparse representation requirement, where instead we exploit the</div><div style=\"text-align: justify;\">natural structure of learning problems.</div></blockquote><br /><div style=\"box-sizing: inherit; line-height: 1.18; margin: 1.72em 0px -0.31em;\"><a href=\"http://penkovsky.com/\" style=\"text-align: justify;\">Bodgan Penkovsky</a><span style=\"text-align: justify;\">, Paris-Sud University.</span><br />Medical Applications of Low Precision Neuromorphic Systems</div><div style=\"box-sizing: inherit; line-height: 1.18; margin: 1.72em 0px -0.31em;\"></div><blockquote class=\"tr_bq\" style=\"text-align: justify;\">The advent of deep learning has considerably accelerated machine learning development, but its development at the edge is limited by its high energy cost and memory requirement. With new memory technology available, emerging Binarized Neural Networks (BNNs) are promising to reduce the energy impact of the forthcoming machine learning hardware generation, enabling machine learning on the edge devices and avoiding data transfer over the network. In this talk we will discuss strategies to apply BNNs to biomedical signals such as electrocardiography and electroencephalography, without sacrificing accuracy and improving energy use. The ultimate goal of this research is to enable smart autonomous healthcare devices.</blockquote><br /><a href=\"https://gra.ygav.in/\">Gavin Gray</a>, Edinburgh University.<br />Comparing Low Complexity Linear Transforms<br /><div><blockquote class=\"tr_bq\" style=\"text-align: justify;\">In response to the development of recent efficient dense layers, this talk discusses replacing linear components in pointwise convolutions with structured linear decompositions for substantial gains in the efficiency/accuracy tradeoff. Pointwise convolutions are fully connected layers and are thus prepared for replacement by structured transforms. Networks using such layers are able to learn the same tasks as those using standard convolutions, and provide Pareto-optimal benefits in efficiency/accuracy, both in terms of computation (mult-adds) and parameter count (and hence memory).</blockquote><div style=\"box-sizing: inherit; line-height: 1.18; margin: 1.72em 0px -0.31em;\"><br /></div><div style=\"text-align: justify;\"><a href=\"https://scholar.google.com/citations?user=Xzdm_9IAAAAJ&amp;hl=fr\">David Rousseau</a>,&nbsp;<a href=\"https://twitter.com/Aishik_Ghosh_\">Aishik Ghosh</a>,&nbsp;<a href=\"https://www.lri.fr/membre.php?mb=2590\">Laurent Basara</a>, Biswajit Biswas. LAL Orsay, LRI Orsay, BITS University.</div><div style=\"text-align: justify;\">OPU+Particle Physics</div><div style=\"text-align: justify;\"><br /></div><div style=\"text-align: justify;\">LightOn’s OPU is opening a new machine learning paradigm. Two use cases have been selected to investigate the potentiality of OPU for particle physics:</div><div style=\"text-align: justify;\"><ul><li><b>End-to-End learning</b>: high energy proton collision at the Large Hadron Collider have been simulated, each collision being recorded as an image representing the energy flux in the detector. Two classes of events have been simulated: signal are created by a hypothetical supersymmetric particle, and background by known processes. The task is to train a classifier to separate the signal from the background. Several techniques using the OPU will be presented, compared with more classical particle physics approaches.</li><li><b>Tracking</b>: high energy proton collisions at the LHC yield billions of records with typically 100,000 3D points corresponding to the trajectory of 10,000 particles. Various investigations of the potential of the OPU to digest this high dimensional data will be reported.</li></ul></div><div style=\"text-align: justify;\"><br /></div><br /><div style=\"text-align: justify;\"><a href=\"http://www-lisic.univ-littoral.fr/~puigt/\">Matthieu Puigt</a>, Université du Littoral Côte d’Opale.</div><div style=\"text-align: justify;\">Accelerated Weighted (Nonnegative) Matrix Factorization with Random Projections</div><div style=\"box-sizing: inherit; line-height: 1.18; margin: 1.72em 0px -0.31em;\"></div><blockquote class=\"tr_bq\" style=\"text-align: justify;\">Random projections belong to the major techniques used to process big data. They have been successfully applied to, e.g., (Nonnegative) Matrix Factorization ((N)MF). However, missing entries in the matrix to factorize (or more generally weights which model the confidence in the entries of the data matrix) prevent their use. In this talk, I will present the framework that we recently proposed to solve this issue, i.e., to apply random projections to weighted (N)MF. We experimentally show the proposed framework to significantly speed-up state-of-the-art weighted NMF methods under some mild conditions.</blockquote><div style=\"text-align: justify;\"><br /></div><div style=\"text-align: justify;\"><br /></div><div style=\"text-align: justify;\"><br /></div><div style=\"text-align: justify;\">The workshop will take place at <a href=\"https://www.google.com/maps/place/6+Rue+Jean+Calvin,+75005+Paris/@48.841676,2.346878,17z/data=!3m1!4b1!4m5!3m4!1s0x47e671eead849419:0xd554b5d8ece400aa!8m2!3d48.841676!4d2.3490667\">IPGG, 6 Rue Jean Calvin, 75005 Paris</a>. The location is close to both the Place Monge and the Censier-Daubenton subway stations on line7. it is also close to the Luxembourg station on the RER B line. The location is close to bus stops on the 21, 24, 27, 47, and 89 routes. Note that <a href=\"https://www.ratp.fr/presse-mouvementsocial\">strikes are still ongoing</a>, and some of these options may not be available.</div><div style=\"text-align: justify;\"><br /></div><div style=\"text-align: justify;\">We will be in the main amphitheater, downstairs on your right when you enter the building. Please register in advance on our <a href=\"https://www.meetup.com/fr-FR/LightOn-meetup/events/266805517/\">meetup group</a> so as to help us in the organization of the workshop.</div><div style=\"text-align: justify;\"><br /></div><br /><br /><br />Follow <a href=\"https://twitter.com/NuitBlog\">@NuitBlog</a>&nbsp;or join the <a href=\"http://www.reddit.com/r/CompressiveSensing/\">CompressiveSensing Reddit</a>,&nbsp;the <a href=\"https://www.facebook.com/pages/Nuit-Blanche/166441866740790\">Facebook page</a>, the Compressive Sensing group on&nbsp;<a href=\"http://www.linkedin.com/groups?gid=683737&amp;trk=myg_ugrp_ovr\">LinkedIn</a><a href=\"http://www.linkedin.com/groups?gid=683737&amp;trk=myg_ugrp_ovr\">&nbsp;</a>&nbsp;or&nbsp;the Advanced Matrix Factorization group on&nbsp;<a href=\"http://www.linkedin.com/groups?gid=4084620&amp;trk=myg_ugrp_ovr\">LinkedIn</a><br /><br /><a href=\"http://feeds.feedburner.com/blogspot/wCeDd\" rel=\"alternate\" title=\"Subscribe to my feed\" type=\"application/rss+xml\"></a><a href=\"http://feeds.feedburner.com/blogspot/wCeDd\" rel=\"alternate\" title=\"Subscribe to my feed\" type=\"application/rss+xml\"><img alt=\"\" src=\"http://www.feedburner.com/fb/images/pub/feed-icon32x32.png\" style=\"border: 0;\" /></a><a href=\"http://feeds.feedburner.com/blogspot/wCeDd\" rel=\"alternate\" title=\"Subscribe to my feed\" type=\"application/rss+xml\">Liked this entry ? subscribe to Nuit Blanche's feed, there's more where that came from</a>.&nbsp;You can also <a href=\"http://feedburner.google.com/fb/a/mailverify?uri=blogspot/wCeDd&amp;loc=en_US\">subscribe to Nuit Blanche by Email</a>.<br /><br />Other links:<br /><b><u><i>Paris Machine Learning</i></u></b>:&nbsp;<a href=\"http://www.meetup.com/Paris-Machine-learning-applications-group/\">Meetup.com</a>||<a href=\"http://nuit-blanche.blogspot.dk/p/paris-based-meetups-on-machine-learning.html\">@Archives</a>||<a href=\"https://www.linkedin.com/groups/6400776/\">LinkedIn</a>||<a href=\"https://www.facebook.com/ParisMachineLearning\">Facebook</a>|| <a href=\"https://twitter.com/ParisMLgroup\">@ParisMLGroup</a><br />&nbsp;<b><u><i>About&nbsp;<a href=\"http://www.lighton.io/\">LightOn</a></i></u></b>:&nbsp;<a href=\"http://us14.campaign-archive1.com/home/?u=701605c9443ad5e332f87331f&amp;id=85e0ce1094\">Newsletter</a> ||<a href=\"https://twitter.com/LightOnIO\">@LightOnIO</a>|| on <a href=\"https://www.linkedin.com/company/lighton/\">LinkedIn </a>|| on <a href=\"https://www.crunchbase.com/organization/lighton\">CrunchBase</a> || our <a href=\"https://medium.com/@LightOnIO/\">Blog</a><br /><u><i><b>About myself</b></i></u>:&nbsp;<a href=\"http://www.lighton.io/\">LightOn</a> || <a href=\"https://scholar.google.fr/citations?user=Cjrs0lAAAAAJ&amp;hl=fr&amp;oi=sra\">Google Scholar</a> || <a href=\"http://www.linkedin.com/in/igorcarron\">LinkedIn</a> ||<a href=\"http://www.twitter.com/igorcarron\">@IgorCarron</a> ||<a href=\"https://sites.google.com/site/igorcarron2/home\">Homepage</a>||<a href=\"https://arxiv.org/search/?query=igor+carron&amp;searchtype=all\">ArXiv</a></div>",
  "link": [
    "",
    "",
    "",
    "",
    ""
  ],
  "author": {
    "name": "Igor",
    "uri": "http://www.blogger.com/profile/17474880327699002140",
    "email": "noreply@blogger.com",
    "gd:image": ""
  },
  "media:thumbnail": "",
  "thr:total": 0
}