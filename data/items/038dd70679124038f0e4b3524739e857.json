{
  "title": "Why Latent Dirichlet Allocation Sucks",
  "link": "",
  "id": "https://www.georgeho.org/lda-sucks/",
  "updated": "2018-03-06T00:00:00Z",
  "published": "2018-03-06T00:00:00Z",
  "content": "<p>As I learn more and more about data science and machine learning, I&rsquo;ve noticed\nthat a lot of resources out there go something like this:</p>\n<blockquote>\n<p>Check out this thing! It&rsquo;s great at this task! The important task! The one\nthat was impossible/hard to do before! Look how well it does! So good! So\nfast!</p>\n<p>Take this! It&rsquo;s our algorithm/code/paper! We used it to do the thing! And now\nyou can do the thing too!</p>\n</blockquote>\n<p>Jokes aside, I do think it’s true that a lot of research and resources focus on\nwhat things <em>can</em> do, or what things are <em>good</em> at doing. Whenever I actually\nimplement the hyped-up “thing”, I’m invariably frustrated when it doesn’t\nperform so well as originally described.</p>\n<p>Maybe I&rsquo;m not smart enough to see this, but after I learn about a new technique\nor tool or model, it&rsquo;s not immediately obvious to me when <em>not</em> to use it. I\nthink it would be very helpful to learn what things <em>aren&rsquo;t</em> good at doing, or\nwhy things just plain <em>suck</em> at times. Doing so not only helps you understand\nthe technique/tool/model better, but also sharpens your understanding of your\nuse case and the task at hand: what is it about your application that makes it\nunsuitable for such a technique?</p>\n<p>Which is why I&rsquo;m writing the first of what will (hopefully) be a series of posts\non <em>“Why [Thing] Sucks”</em>. The title is provocative but reductive: a better name\nmight be <em>When and Why [Thing] Might Suck</em>… but that doesn&rsquo;t have quite the\nsame ring to it! In these articles I&rsquo;ll be outlining what I tried and why it\ndidn&rsquo;t work: documenting my failures and doing a quick post-mortem, if you will.\nMy hope is that this will be useful to anyone else trying to do the same thing\nI&rsquo;m doing.</p>\n<hr>\n<p>So first up: topic modelling. Specifically, <a href=\"https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation\">latent Dirichlet\nallocation</a>, or LDA\nfor short (not to be confused with <a href=\"https://www.georgeho.org/lda/\">the other\nLDA</a>, which I wrote a blog post about before).</p>\n<p>If you&rsquo;ve already encountered LDA and have seen <a href=\"https://en.wikipedia.org/wiki/Plate_notation\">plate\nnotation</a> before, this picture\nwill probably refresh your memory:</p>\n<p><img src=\"https://www.georgeho.org/assets/images/latent-dirichlet-allocation.png\" alt=\"Latent Dirichlet allocation\"></p>\n<p>If you don&rsquo;t know what LDA is, fret not, for there is\n<a href=\"http://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf\">no</a>\n<a href=\"http://obphio.us/pdfs/lda_tutorial.pdf\">shortage</a>\n<a href=\"http://blog.echen.me/2011/08/22/introduction-to-latent-dirichlet-allocation/\">of</a>\n<a href=\"https://rstudio-pubs-static.s3.amazonaws.com/79360_850b2a69980c4488b1db95987a24867a.html\">resources</a>\n<a href=\"http://scikit-learn.org/stable/modules/decomposition.html#latentdirichletallocation\">about</a>\n<a href=\"https://radimrehurek.com/gensim/models/ldamodel.html\">this</a>\n<a href=\"https://www.quora.com/What-is-a-good-explanation-of-Latent-Dirichlet-Allocation\">stuff</a>.\nI&rsquo;m going to move on to when and why LDA isn&rsquo;t the best idea.</p>\n<p><strong>tl;dr:</strong> <em>LDA and topic modelling doesn&rsquo;t work well with a) short documents,\nin which there isn&rsquo;t much text to model, or b) documents that don&rsquo;t coherently\ndiscuss a single topic.</em></p>\n<p>Wait, what? Did George just say that topic modelling sucks when there&rsquo;s not much\ntopic, and not much text to model? Isn&rsquo;t that obvious?</p>\n<p><em>Yes! Exactly!</em> Of course it&rsquo;s <a href=\"https://en.wikipedia.org/wiki/Egg_of_Columbus\">obvious in\nretrospect</a>! Which is why I was\nso upset when I realized I spent two whole weeks faffing around with LDA when\ntopic models were the opposite of what I needed, and so frustrated that more\npeople aren&rsquo;t talking about when <em>not</em> to use/do certain things.</p>\n<p>But anyways, <code>&lt;\\rant&gt;</code> and let&rsquo;s move on to why I say what I&rsquo;m saying.</p>\n<p>Recently, I&rsquo;ve taken up a project in modelling the textual data on Reddit using\nNLP techniques. There are, of course, many ways one count take this, but\nsomething I was interested in was finding similarities between subreddits,\nclustering comments, and visualizing these clusters somehow: what does Reddit\ntalk about on average? Of course, I turned to topic modelling and dimensionality\nreduction.</p>\n<p>The techniques that I came across first were LDA (<a href=\"https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation\">latent Dirichlet\nallocation</a>) and\nt-SNE (<a href=\"https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding\">t-distributed stochastic neighbor\nembedding</a>).\nBoth techniques are well known and well documented, but I can&rsquo;t say that using\nthem together is a popular choice of two techniques. However, there have been\nsome successes. For instance, <code>ShuaiW</code> had some success with this method <a href=\"https://web.archive.org/web/20171219104016/https://shuaiw.github.io/2016/12/22/topic-modeling-and-tsne-visualzation.html\">when\nusing it the 20 newsgroups\ndataset</a><sup id=\"fnref:1\"><a href=\"#fn:1\" class=\"footnote-ref\" role=\"doc-noteref\">1</a></sup>;\nsome work done by Kagglers have <a href=\"https://www.kaggle.com/ykhorramz/lda-and-t-sne-interactive-visualization\">yielded reasonable\nresults</a>,\nand <a href=\"https://stats.stackexchange.com/questions/305356/plot-latent-dirichlet-allocation-output-using-t-sne\">the StackExchange community doesn&rsquo;t think its a ridiculous\nidea</a>.</p>\n<p>The dataset that I applied this technique to was the <a href=\"https://bigquery.cloud.google.com/dataset/fh-bigquery:reddit\">Reddit dataset on Google\nBigQuery</a>, which contains\ndata on all subreddits, posts and comments for as long as Reddit has been around.\nI limited myself to the top 10 most active subreddits in December 2017 (the most\nrecent month for which we have data, at the time of writing), and chose 20 to be\nthe number of topics to model (any choice is as arbitrary as any other).</p>\n<p>I ran LDA and t-SNE exactly as Shuai described on <a href=\"https://web.archive.org/web/20171219104016/https://shuaiw.github.io/2016/12/22/topic-modeling-and-tsne-visualzation.html\">this blog\npost</a><sup id=\"fnref1:1\"><a href=\"#fn:1\" class=\"footnote-ref\" role=\"doc-noteref\">1</a></sup>,\nexcept using the great <a href=\"https://radimrehurek.com/gensim/\"><code>gensim</code></a> library to\nperform LDA, which was built with large corpora and efficient online algorithms\nin mind. (Specifically, <code>gensim</code> implements online variational inference with\nthe EM algorthm, instead of using MCMC-based algorithms, which <code>lda</code> does. It\nseems that variational Bayes scales better to very large corpora than collapsed\nGibbs sampling.)</p>\n<p>Here are the results:</p>\n<p><img src=\"https://www.georgeho.org/assets/images/lda-sucks.png\" alt=\"LDA followed by t-SNE on the Reddit dataset\"></p>\n<p>Horrible, right? Nowhere near the well-separated clusters that Shuai got with\nthe 20 newsgroups. In fact, the tiny little huddles of around 5 to 10 comments\nare probably artifacts of the dimensionality reduction done by t-SNE, so those\nmight even just be noise! You might say that there are at least 3 very large\nclusters, but even that&rsquo;s bad news! If they&rsquo;re clustered together, you would\nhope that they have the same topics, and that&rsquo;s definitely not the case here!\nThese large clusters tells us that a lot of comments have roughly the same topic\ndistribution (i.e. they&rsquo;re close to each other in the high-dimensional\ntopic-space), but their dominant topics (i.e. the topic with greatest\nprobability) don&rsquo;t end up being the same.</p>\n<p>By the way, t-SNE turns out to be <a href=\"https://distill.pub/2016/misread-tsne/\">a really devious dimensionality reduction\ntechnique</a>, and you really need to\nexperiment with the perplexity values in order to use it properly. I used the\ndefault <code>perplexity=30</code> from sklearn for the previous plot, but I repeated the\nvisualizations for multiple other values and the results aren&rsquo;t so hot either.\nNote that I did these on a random subsample of 1000 comments, so as to reduce\ncompute time.</p>\n<figure>\n<a href=\"https://www.georgeho.org/assets/images/perplexity50.png\"><img src=\"https://www.georgeho.org/assets/images/perplexity50.png\" alt=\"t-SNE with perplexity value of 50\"></a>\n<a href=\"https://www.georgeho.org/assets/images/perplexity100.png\"><img src=\"https://www.georgeho.org/assets/images/perplexity100.png\" alt=\"t-SNE with perplexity value of 100\"></a>\n<figcaption>t-SNE with perplexity values of 50 and 100, respectively.</figcaption>\n</figure>\n<p>So, what went wrong? There&rsquo;s a <a href=\"https://stackoverflow.com/questions/29786985/whats-the-disadvantage-of-lda-for-short-texts\">nice StackOverflow\npost</a>\nthat describes the problem well.</p>\n<p>Firstly, latent Dirichlet allocation and other probabilistic topic models are\nvery complex and flexible. While this means that they have very high variance\nand low bias, it also means that they need a lot of data (or data with a decent\nsignal-to-noise ratio) for them to learn anything meaningful. Particularly for\nLDA, which infers topics on a document-by-document basis, if there aren&rsquo;t enough\nwords in a document, there simply isn&rsquo;t enough data to infer a reliable topic\ndistribution for that document.</p>\n<p>Secondly, Reddit comments are by their nature very short and very-context\ndependent, since they respond to a post, or another comment. So not only are\nReddit comments just short: it&rsquo;s actually worse than that! They don&rsquo;t even\ndiscuss a certain topic coherently (by which I mean, they don&rsquo;t necessarily use\nwords that pertain to what they&rsquo;re talking about). I&rsquo;ll give an example:</p>\n<pre tabindex=\"0\"><code>&#34;I&#39;m basing my knowledge on the fact that I watched the fucking rock fall.&#34;\n</code></pre><p>Now, stopwords compose a little less than half of this comment, and they would\nbe stripped before LDA even looks at it. But that aside, what is this comment\nabout? What does the rock falling mean? What knowledge is this user claiming?\nIt&rsquo;s a very confusing comment, but probably made complete sense in the context\nof the post it responded to and the comments that came before it. As it is,\nhowever, its impossible for <em>me</em> to figure out what topic this comment is about,\nlet alone an algorithm!</p>\n<p>Also, just to drive the point home, here are the top 10 words in each of the 20\ntopics that LDA came up with, on the same dataset as before:</p>\n<pre tabindex=\"0\"><code>Topic #0:\ngot just time day like went friend told didn kids\nTopic #1:\njust gt people say right doesn know law like government\nTopic #2:\nremoved com https www https www tax money http watch news\nTopic #3:\npeople don just like think really good know want things\nTopic #4:\nyears time did great ago ve just work life damn\nTopic #5:\nmovie like love just really school star movies film story\nTopic #6:\nlike just fucking shit head car looks new makes going\nTopic #7:\ngame team season year good win play teams playing best\nTopic #8:\nright thing yeah don think use internet ok water case\nTopic #9:\ngoing like work just need way want money free fuck\nTopic #10:\nbetter just play games make ve ll seen lol fun\nTopic #11:\nlike don know did feel shit big man didn guys\nTopic #12:\ndeleted fuck guy year old man amp year old state lmao\nTopic #13:\nsure believe trump wrong saying comment post mueller evidence gt\nTopic #14:\ngt yes https com good oh wikipedia org en wiki\nTopic #15:\nthink like good 10 look point lebron just pretty net\nTopic #16:\ngt said fucking american agree trump thanks obama states did\nTopic #17:\ntrump vote party republicans election moore president republican democrats won\nTopic #18:\nwar world country israel countries china military like happy does\nTopic #19:\nreddit message askreddit post questions com reddit com subreddit compose message compose\n</code></pre><p>Now, it&rsquo;s not entirely bad: topic 2 seems like its collecting the tokens from links\n(I didn&rsquo;t stopword those out, oops), topic 7 looks like its about football or\nsome other sport, 13 is probably about American politics, and 18 looks like\nits about world news, etc.</p>\n<p>But almost all other topics are just collections of words: it&rsquo;s not immediately\nobvious to me what each topic represents.</p>\n<p>So yeah, there you have it, LDA really sucks sometimes.</p>\n<hr>\n<p><strong>Update (8/12/2018):</strong> In retrospect, I think that this whole blog post is\nsummarized well in the following tweet thread. Clustering algorithms will give\nyou clusters because that&rsquo;s what they do, not because there actually <em>are</em>\nclusters. In this case, extremely short and context-dependent documents make it\nhard to justify that there are topic clusters in the first place.</p>\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">Algorithms that have to report something will always report something, even if it&#39;s a bad idea. Please do not use these algorithms unless you have principled reasons why there should be something. <a href=\"https://t.co/kzxZiuBfmm\">https://t.co/kzxZiuBfmm</a></p>&mdash; \\mathfrak{Michael Betancourt} (@betanalpha) <a href=\"https://twitter.com/betanalpha/status/1026619046626828288?ref_src=twsrc%5Etfw\">August 7, 2018</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n<div class=\"footnotes\" role=\"doc-endnotes\">\n<hr>\n<ol>\n<li id=\"fn:1\">\n<p><a href=\"https://github.com/ShuaiW\"><code>ShuaiW</code></a> has since taken down his blog, so I\nam linking to the Internet Archive of his blog post instead.&#160;<a href=\"#fnref:1\" class=\"footnote-backref\" role=\"doc-backlink\">&#x21a9;&#xfe0e;</a>&#160;<a href=\"#fnref1:1\" class=\"footnote-backref\" role=\"doc-backlink\">&#x21a9;&#xfe0e;</a></p>\n</li>\n</ol>\n</div>"
}