{
  "title": "~~Fruit~~ Loops and Learning - The LUPI Paradigm and SVM+",
  "link": "",
  "id": "https://www.georgeho.org/lupi/",
  "updated": "2018-01-30T00:00:00Z",
  "published": "2018-01-30T00:00:00Z",
  "content": "<p>Here&rsquo;s a short story you might know: you have a black box, whose name is\n<em>Machine Learning Algorithm</em>. It&rsquo;s got two modes: training mode and testing\nmode. You set it to training mode, and throw in a lot (sometimes <em>a lot</em> a lot)\nof ordered pairs $(x_i, y_i), 1 \\leq i \\leq l$. Here, the $x_i$ are called\nthe <em>examples</em> and the $y_i$ are called the <em>targets</em>. Then, you set it to\ntesting mode and throw in some more examples, for which you don&rsquo;t have the\ncorresponding targets. You hope the $y_i$s that come out are in some sense\nthe “right” ones.</p>\n<p>Generally speaking, this is a parable of <em>supervised learning</em>. However, Vapnik\n(the inventor of the\n<a href=\"https://en.wikipedia.org/wiki/Support_vector_machine\">SVM</a>) recently described\na new way to think about machine learning (e.g.\n<a href=\"http://jmlr.csail.mit.edu/papers/volume16/vapnik15b/vapnik15b.pdf\">here</a>):\n<em>learning using privileged information</em>, or <em>LUPI</em> for short.</p>\n<p>This post is meant to introduce the LUPI paradigm of machine learning to\npeople who are generally familiar with supervised learning and SVMs, and are\ninterested in seeing the math and intuition behind both things extended to the\nLUPI paradigm.</p>\n<h2 id=\"what-is-lupi\">What is LUPI?</h2>\n<p>The main idea is that instead of two-tuples $(x_i, y_i)$, the black box is fed\nthree-tuples $(x_i, x_i^{<em>}, y_i) $, where the $x^{</em>}$s are the so-called\n<em>privileged information</em> that is only available during training, and not during\ntesting. The hope is that this information will train the model to better\ngeneralize during the testing phase.</p>\n<p>Vapnik offers many examples in which LUPI can be applied in real life: in\nbioinformatics and proteomics (where advanced biological models, which the\nmachine might not necessarily “understand”, serve as the privileged\ninformation), in financial time series analysis (where future movements of the\ntime series are the unknown at prediction time, but are available\nretrospectively), and in the classic MNIST dataset, where the images were\nconverted to a lower resolution, but each annotated with a “poetic description”\n(which was available for the training data but not for the testing data).</p>\n<p>Vapnik&rsquo;s team ran tests on well-known datasets in all three application areas\nand found that his newly-developed LUPI methods performed noticeably better than\nclassical SVMs in both convergence time (i.e. the number of examples necessary\nto achieve a certain degree of accuracy) and estimation of a good predictor\nfunction. In fact, Vapnik&rsquo;s proof-of-concept experiments are so whacky that\nthey actually <a href=\"https://nautil.us/issue/6/secret-codes/teaching-me-softly\">make for an entertaining read\n</a>!</p>\n<h2 id=\"classical-svms-separable-and-non-separable-case\">Classical SVMs (separable and non-separable case)</h2>\n<p>There are many ways of thinking about SVMs, but I think that the one that is\nmost instructive here is to think of them as solving the following optimization\nproblem:</p>\n<blockquote>\n<p>Minimize $ \\frac{1}{2} |w|^2 $</p>\n<p>subject to $y_i [ w \\cdot x_i + b ] \\geq 1, 1 \\leq i \\leq l$.</p>\n</blockquote>\n<p>Basically all this is saying is that we want to find the hyperplane that\nseparates our data by the maximum margin. More technically speaking, this finds\nthe parameters ($w$ and $b$) of the maximum margin hyperplane, with $l_2$\nregularization.</p>\n<p>In the non-separable case, we concede that our hyperplane may not classify all\nexamples perfectly (or that it may not be desireable to do so: think of\noverfitting), and so we introduce a so-called <em>slack variable</em> $\\xi_i \\geq 0$\nfor each example $i$, which measures the severity of misclassification of that\nexample. With that, the optimization becomes:</p>\n<blockquote>\n<p>Minimize $\\frac{1}{2} |w|^2 + C\\sum_{i=1}^{l}{\\xi_i}$</p>\n<p>subject to $y_i [ w \\cdot x_i + b ] \\geq 1 - \\xi_i, \\xi_i \\geq 0, 1\n\\leq i \\leq l$.</p>\n</blockquote>\n<p>where $C$ is some regularization parameter.</p>\n<p>This says the same thing as the previous optimization problem, but now allows\npoints to be (a) classified properly ($\\xi_i = 0$), (b) within the margin but\nstill classified properly ($0 &lt; \\xi_i &lt; 1$), or (c) misclassified\n($1 \\leq \\xi_i$).</p>\n<p>In both the separable and non-separable cases, the decision rule is simply\n$\\hat{y} = \\text{sign}(w \\cdot x + b)$.</p>\n<p>An important thing to note is that, in the separable case, the SVM uses $l$\nexamples to estimate the $n$ components of $w$, whereas in the nonseparable\ncase, the SVM uses $l$ examples to estimate $n+l$ parameters: the $n$\ncomponents of $w$ and $l$ values of slacks $\\xi_i$. Thus, in the\nnon-separable case, the number of parameters to be estimated is always larger\nthan the number of examples: it does not matter here that most of slacks may be\nequal to zero: the SVM still has to estimate all of them.</p>\n<p>The way both optimization problems are actually <em>solved</em> is fairly involved (they\nrequire <a href=\"https://en.wikipedia.org/wiki/Lagrange_multiplier\">Lagrange\nmultipliers</a>), but in terms\nof getting an intuitive feel for how SVMs work, I think that examining the\noptimization problems suffice!</p>\n<h2 id=\"what-is-svm\">What is SVM+?</h2>\n<p>In his paper introducing the LUPI paradigm, Vapnik outlines <em>SVM+</em>, a\nmodified form of the SVM that fits well into the LUPI paradigm, using privileged\ninformation to improve performance. It should be emphasized that LUPI is a\nparadigm - a way of thinking about machine learning - and not just a collection\nof algorithms. SVM+ is just one technique that interoperates with the LUPI\nparadigm.</p>\n<p>The innovation of the SVM+ algorithm is that is uses the privileged information\nto estimate the slack variables. Given the training three-tuple $(x, x^{*},\ny)$, we map $x$ to the feature space $Z$, and $x^{*}$ to a separate feature\nspace $Z^{*}$. Then, the decision rule is $\\hat{y} = \\text{sign}(w \\cdot x +\nb)$ and the slack variables are estimated by $\\xi = w^{*} \\cdot x^{*} +\nb^{*}$.</p>\n<p>In order to find $w$, $b$, $w^{*}$ and $b^{*}$, we solve the following\noptimization problem:</p>\n<blockquote>\n<p>Minimize $\\frac{1}{2} (|w|^2 + \\gamma |w^{*}|^2) +\nC \\sum_{i=1}^{l}{(w^{*} \\cdot x_i^{*} + b^{*})}$</p>\n<p>subject to $y_i [ w \\cdot x_i + b ] \\geq 1 - (w^{*} \\cdot x^{*} + b^{*}),\n(w^{*} \\cdot x^{*} + b^{*}) \\geq 0, 1 \\leq i \\leq l$.</p>\n</blockquote>\n<p>where $\\gamma$ indicates the extent to which the slack estimation should be\nregularized in comparison to the SVM. Notice how this optimization problem is\nessentially identical to the non-separable classical SVM, except the slacks\n$\\xi_i$ are now estimated with $w^{*} \\cdot x^{*} + b^{*}$.</p>\n<p>Again, the method of actually solving this optimization problem involves\nLagrange multipliers and quadratic programming, but I think the intuition is\ncaptured in the optimization problem statement.</p>\n<h2 id=\"interpretation-of-svm\">Interpretation of SVM+</h2>\n<p>The SVM+ has a very ready interpretation. Instead of a single feature space, it\nhas two: one in which the non-privileged information lives (where decisions are\nmade), and one in which the privileged information lives (where slack variables\nare estimated).</p>\n<p>But what&rsquo;s the point of this second feature space? How does it help us? Vapnik\nterms this problem <em>knowledge transfer</em>: it&rsquo;s all well and good for us to learn\nfrom the privileged information, but it&rsquo;s all for naught if we can&rsquo;t use this\nnewfound knowledge in the test phase.</p>\n<p>The way knowledge transfer is resolved here is by assuming that <em>examples in the\ntraining set that are hard to separate in the privileged space, are also hard to\nseparate in the regular space</em>. Therefore, we can use the privileged information\nto obtain an estimate for the slack variables.</p>\n<p>Of course, SVMs are a technique with many possible interpretations, of which my\npresentation (in terms of the optimization of $w$ and $b$) is just one. For\nexample, it&rsquo;s possible to think of SVMs in terms of kernels functions, or as\nlinear classifiers minimizing hinge loss. In all cases, it&rsquo;s possible and\nworthwhile to understand that interpretation of SVMs, and how the LUPI paradigm\ncontributes to or extends that interpretation. I&rsquo;m hoping to write a piece later\nto explain these exact topics.</p>\n<p>Vapnik also puts a great emphasis on analyzing SVM+ based on its statistical\nlearning theoretic properties (in particular, analyzing its rate of convergence\nvia the <a href=\"https://en.wikipedia.org/wiki/VC_dimension\">VC dimension</a>). Vapnik was\none of the main pioneers behind statistical learning theory, and has written an\n<a href=\"https://www.amazon.com/Statistical-Learning-Theory-Vladimir-Vapnik/dp/0471030031\">entire\nbook</a>\non this stuff <del>which I have not read</del>, so I&rsquo;ll leave that part aside for now. I\nhope to understand this stuff one day.</p>\n<h2 id=\"implementation-of-svm\">Implementation of SVM+</h2>\n<p>There&rsquo;s just one catch: SVM+ is actually an fairly inefficient algorithm, and\ndefinitely will not scale to large data sets. What&rsquo;s so bad about it? <em>It has\n$n$ training examples but $2n$ variables to estimate.</em> This is twice as many\nvariables to estimate as the standard formulation of the <a href=\"https://en.wikipedia.org/wiki/Support_vector_machine#Computing_the_SVM_classifier\">vanilla\nSVM</a>.\nThis isn&rsquo;t something that we can patch: the problem is inherent to the\nLagrangian dual formulation that Vapnik and Vashist proposed in 1995.</p>\n<p>Even worse, the optimization problem has constraints that are very different\nfrom those of the standard SVM. In essence, this means that efficient libraries\nout-of-the-box solvers for the standard SVM (e.g.\n<a href=\"https://www.csie.ntu.edu.tw/~cjlin/libsvm/\">LIBSVM</a> and\n<a href=\"https://www.csie.ntu.edu.tw/~cjlin/liblinear/\">LIBLINEAR</a>) can&rsquo;t be used to\ntrain an SVM+ model.</p>\n<p>Luckily, <a href=\"https://www.researchgate.net/publication/301880839_Simple_and_Efficient_Learning_using_Privileged_Information\">a recent paper by Xu et\nal.</a>\ndescribes a neat mathematical trick to implement SVM+ in a simple and efficient\nway. With this amendment, the authors rechristen the algorithm as SVM2+.\nEssentially, instead of using the hinge loss when training SVM+, we will instead\nuse the <em>squared</em> hinge loss. It turns out that changing the loss function in\nthis way leads to a tiny miracle.</p>\n<p>This (re)formulation of SVM+ becomes <em>identical</em> to that of the standard SVM,\nexcept we replace the Gram matrix (a.k.a. kernel matrix) $\\bf K$ by $\\bf K +\n\\bf Q_\\lambda \\odot (\\bf y y^t)$, where</p>\n<ul>\n<li>$\\bf y$ is the target vector</li>\n<li>$\\odot$ denotes the Hadamard product</li>\n<li>$\\bf{Q_\\lambda}$ is given by $Q_\\lambda = \\frac{1}{\\lambda} (\\tilde{K}\n(\\frac{\\lambda}{C} I_n + \\tilde{K})^{-1} \\tilde{K})$, and</li>\n<li>$\\bf \\tilde{K}$ is the Gram matrix formed by the privileged information</li>\n</ul>\n<p>So by replacing the hinge loss with the squared hinge loss, the SVM+ formulation\ncan now be solved with existing libraries!</p>\n<h2 id=\"extensions-to-svm\">Extensions to SVM+</h2>\n<p>In his paper, Vapnik makes it clear that LUPI is a very general and abstract\nparadigm, and as such there is plenty of room for creativity and innovation -\nnot just in researching and developing new LUPI methods and algorithms, but also\nin implementing and applying them. It is unknown how to best go about supplying\nprivileged information so as to get good performance. How should the data be\nfeature engineered? How much signal should be in the privileged information?\nThese are all open questions.</p>\n<p>Vapnik himself opens up three avenues to extend the SVM+ algorithm:</p>\n<ol>\n<li><em>a mixture model of slacks:</em> when slacks are estimated by a mixture of a\nsmooth function and some prior</li>\n<li><em>a model where privileged information is available only for a part of the\ntraining data:</em> where we can only supply privileged information on a small\nsubset of the training examples</li>\n<li><em>multiple-space privileged information:</em> where the privileged information we\ncan supply do not all share the same features</li>\n</ol>\n<p>Clearly, there&rsquo;s a lot of potential in the LUPI paradigm, as well as a lot of\nreasons to be skeptical. It&rsquo;s very much a nascent perspective of machine\nlearning, so I&rsquo;m interested in keeping an eye on it going forward. I&rsquo;m hoping\nto write more posts on LUPI in the future!</p>"
}