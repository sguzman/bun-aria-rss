{
  "id": "tag:blogger.com,1999:blog-15418143.post-8839595873640006183",
  "published": "2016-06-17T06:24:00.000-05:00",
  "updated": "2016-06-17T06:31:00.089-05:00",
  "category": [
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    ""
  ],
  "title": "Making Deep Networks Probabilistic via Test-time Dropout",
  "content": "In Quantum Mechanics, Heisenberg's Uncertainty Principle states that there is a fundamental limit to how well one can measure a particle's <b>position</b> and <b>momentum</b>. In the context of machine learning systems, a similar principle has emerged, but relating <b>interpretability</b> and <b>performance</b>. By using a manually wired or shallow machine learning model, you'll have no problem understanding the moving pieces, but you will seldom be happy with the results. Or you can use a black-box deep neural network and enjoy the model's exceptional performance. Today we'll see one simple and effective trick to make our deep black boxes a bit more intelligible. The trick allows us to convert neural network outputs into probabilities, with no cost to performance, and minimal computational overhead.<br /><br /><table cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"float: left; text-align: center;\"><tbody><tr><td class=\"tr-caption\" style=\"font-size: 12.8px;\"></td></tr><tr><td style=\"text-align: center;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://3.bp.blogspot.com/-NGrIzxbkvR8/V2PfIKuNdFI/AAAAAAAAOzc/k91SxOfkDSkQvDGaLtmCUYjCKH33pbSJACLcB/s1600/interpretable_vs_deep_neural_networks.png\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" height=\"112\" src=\"https://3.bp.blogspot.com/-NGrIzxbkvR8/V2PfIKuNdFI/AAAAAAAAOzc/k91SxOfkDSkQvDGaLtmCUYjCKH33pbSJACLcB/s400/interpretable_vs_deep_neural_networks.png\" width=\"400\" /></a></div></td></tr><tr><td class=\"tr-caption\" style=\"font-size: 12.8px;\"><b>Interpretability vs Performance: </b>Deep Neural Networks perform well on most computer vision tasks, yet they are notoriously difficult to interpret.</td></tr></tbody></table><br /><br /><br /><br /><br /><br /><br /><br /><br /><br />The desire to understand deep neural networks has triggered a flurry of research into Neural Network Visualization, but in practice we are often forced to treat deep learning systems as black-boxes. (See my recent <a href=\"http://www.computervisionblog.com/2016/06/deep-learning-trends-iclr-2016.html\">Deep Learning Trends @ ICLR 2016</a>&nbsp;post for an overview of recent neural network visualization techniques.) But just because we can't grok the inner-workings of our favorite deep models, it doesn't mean we can't ask more out of our deep learning systems.<br /><br /><blockquote class=\"tr_bq\"><span style=\"font-size: large;\">There exists a simple trick for upgrading black-box neural network outputs into probability distributions.</span>&nbsp;</blockquote><br />The probabilistic approach provides confidences, or \"uncertainty\" measures, alongside predictions and can make almost any deep learning systems into a smarter one. For robotic applications or any kind of software that must make decisions based on the output of a deep learning system, being able to provide meaningful uncertainties is a true game-changer.<br /><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"clear: left; margin-bottom: 1em; margin-left: auto; margin-right: auto; text-align: right;\"><tbody><tr><td style=\"text-align: center;\"><br /><br /><a href=\"https://2.bp.blogspot.com/-t4hhbhJbvFE/V2Jmj2NJ_gI/AAAAAAAAOy0/_X5QrKOSx447h-CMBsc1ChX1nhb2CcItQCLcB/s1600/brain_zap_neural_network_dropout.jpg\" imageanchor=\"1\" style=\"clear: left; margin-bottom: 1em; margin-left: auto; margin-right: auto;\"><img border=\"0\" height=\"274\" src=\"https://2.bp.blogspot.com/-t4hhbhJbvFE/V2Jmj2NJ_gI/AAAAAAAAOy0/_X5QrKOSx447h-CMBsc1ChX1nhb2CcItQCLcB/s320/brain_zap_neural_network_dropout.jpg\" width=\"320\" /></a></td></tr><tr><td class=\"tr-caption\" style=\"font-size: 12.8px; text-align: center;\">Applying<b> Dropout</b>&nbsp;to your Deep Neural Network is like occasionally zapping your brain</td></tr></tbody></table><span style=\"background-color: white;\">The key ingredient is <b>dropout</b>, an anti-overfitting deep learning trick handed down from Hinton himself (Krizhevsky's pioneering 2012 paper). Dropout sets some of the weights to zero during training, reducing feature co-adaptation, thus improving generalization.</span><br /><blockquote class=\"tr_bq\"><span style=\"font-size: large;\">Without dropout, it is too easy to make a moderately deep network attain 100% accuracy on the training set.&nbsp;</span></blockquote>The accepted knowledge is that an un-regularized network (one without dropout) is too good at memorizing the training set. For a great introductory machine learning video lecture on dropout, I highly recommend you watch Hugo Larochelle's lecture on Dropout for Deep learning.<br /><br /><center> <iframe allowfullscreen=\"\" frameborder=\"0\" height=\"315\" src=\"https://www.youtube.com/embed/UcKPdAM8cnI\" width=\"420\"></iframe> </center><br /><span style=\"background-color: white;\">Geoff Hinton's dropout lecture, also a great introduction, focuses on interpreting dropout as an ensemble method. If you're looking for new research ideas in the dropout space, a thorough understanding of Hinton's interpretation is a must.</span><br /><br /><center> <iframe allowfullscreen=\"\" frameborder=\"0\" height=\"315\" src=\"https://www.youtube.com/embed/G3KUvHx9GDY\" width=\"420\"></iframe> </center><br /><span style=\"background-color: white;\">But while dropout is typically used at&nbsp;</span>training-time<span style=\"background-color: white;\">, today we'll highlight the keen observation that&nbsp;</span><b style=\"background-color: white;\">dropout used at&nbsp;test-time&nbsp;is one of the simplest ways to turn raw neural network outputs into probability distributions</b><span data-mce-style=\"font-family: Times; font-size: medium; line-height: normal;\" style=\"background-color: white;\">. Not only does this probabilistic \"free upgrade\" often improve classification results, it provides a meaningful notion of uncertainty, something typically&nbsp;<span data-mce-style=\"font-family: Times; font-size: medium; line-height: normal;\">missing</span>&nbsp;in Deep Learning systems.</span><br /><blockquote class=\"tr_bq\"><span style=\"font-size: large;\">The idea is quite simple: t</span><span style=\"text-align: center;\"><span style=\"font-size: large;\">o estimate the predictive mean and predictive uncertainty, simply collect the results of stochastic forward passes through the model using dropout.</span>&nbsp;</span></blockquote><h3><b>How to use dropout: 2016 edition</b></h3><ol><li>Start with a moderately sized network</li><li>Increase your network size with dropout turned off until you perfectly fit your data</li><li>Then, train with dropout turned on</li><li>At test-time, turn on dropout and run the network T times to get T samples</li><li>The mean of the samples is your output and the variance is your measure of uncertainty</li></ol><a href=\"https://arxiv.org/abs/1506.02142\"></a><br /><div>Remember that drawing more samples will increase computation time during testing unless you're clever about re-using partial computations in the network. Please note that if you're only using dropout near the end of your network, you can reuse most of the computations. If you're not happy with the uncertainty estimates, consider adding more layers of dropout at test-time. Since you'll already have a pre-trained network, experimenting with test-time dropout layers is easy.<br /><br /></div><h3><b>Bayesian Convolutional Neural Networks</b></h3>To be truly Bayesian about a deep network's parameters, we wouldn't learn a single set of parameters&nbsp;<b>w</b>, we would infer a distribution over weights given the data, p(<b>w</b>|<b>X</b>,<b>Y</b>). Training is already quite expensive, requiring large datasets and expensive GPUs.<br /><blockquote class=\"tr_bq\"><span style=\"font-size: large;\">Bayesian learning algorithms can in theory provide much better parameter estimates for ConvNets and I'm sure some of our friends at Google are working on this already.&nbsp;</span></blockquote>But today we aren't going to talk about such full Bayesian Deep Learning systems, only systems that \"upgrade\" the model prediction&nbsp;<b>y</b>&nbsp;to p(<b>y</b>|<b>x</b>,<b>w</b>). In other words, only the network outputs gain a probabilistic interpretation.<br /><br />An excellent deep learning computer vision system which uses test-time dropout comes from a recent University of Cambridge technique called SegNet. The SegNet approach introduced an Encoder-Decoder framework for dense semantic segmentation. More recently, SegNet includes a Bayesian extension that uses dropout at test-time for providing uncertainty estimates. Because the system provides a dense per-pixel labeling, the confidences can be visualized as per-pixel heatmaps. Segmentation system is not performing well? Just look at the confidence heatmaps!<br /><br /><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><a href=\"https://1.bp.blogspot.com/-DlcqJ0a4h9I/V2CJFJiKGtI/AAAAAAAAOwQ/tmGgcBUKd7sy1lEqsXFx6llhMqMb8lJpACLcB/s1600/bayesian_segnet_uncertainty_dropout.png\" imageanchor=\"1\" style=\"margin-left: auto; margin-right: auto;\"><img border=\"0\" height=\"110\" src=\"https://1.bp.blogspot.com/-DlcqJ0a4h9I/V2CJFJiKGtI/AAAAAAAAOwQ/tmGgcBUKd7sy1lEqsXFx6llhMqMb8lJpACLcB/s400/bayesian_segnet_uncertainty_dropout.png\" width=\"400\" /></a></td></tr><tr><td class=\"tr-caption\" style=\"font-size: 12.8px;\"><div style=\"font-size: 12.8px;\"><b>Bayesian SegNet.</b>&nbsp;A fully convolutional neural network architecture which provides&nbsp;</div><div style=\"font-size: 12.8px;\">per-pixel class uncertainty estimates using dropout.</div><div><br /></div></td></tr></tbody></table><div class=\"separator\" style=\"clear: both; text-align: center;\"><br /></div>The Bayesian SegNet authors tested different strategies for dropout placement and determined that a handful of dropout layers near the encoder-decoder bottleneck is better than simply using dropout near the output layer. Interestingly, Bayesian SegNet improves the accuracy over vanilla SegNet. Their confidence maps shown high uncertainty near object boundaries, but different test-time dropout schemes could provide a more diverse set of uncertainty estimates.<br /><br /><a href=\"https://arxiv.org/abs/1511.02680\">Bayesian SegNet: Model Uncertainty in Deep Convolutional Encoder-Decoder Architectures for Scene Understanding</a>&nbsp;Alex Kendall, Vijay Badrinarayanan, Roberto Cipolla, in arXiv:1511.02680, November 2015. [<a href=\"http://mi.eng.cam.ac.uk/projects/segnet/\">project page with videos</a>]<br /><div><span style=\"font-size: x-small;\"><br /></span></div><br />Confidences are quite useful for evaluation purposes, because instead of providing a single average result across all pixels in all images, we can sort the pixels and/or images by the overall confidence in prediction. When evaluation the top 10% most confident pixels, we should expect significantly higher performance. For example, the Bayesian SegNet approach achieves 75.4% global accuracy on the SUN RGBD dataset, and an astonishing 97.6% on most confident 10% of the test-set [personal communication with Bayesian SegNet authors]. This kind of sort-by-confidence evaluation was popularized by the PASCAL VOC Object Detection Challenge, where precision/recall curves were the norm. Unfortunately, as the research community moved towards large-scale classification, the notion of confidence was pushed aside. Until now.<br /><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody></tbody></table><h3><b>Theoretical Bayesian Deep Learning</b></h3><span style=\"background-color: white;\">Deep networks that model uncertainty are truly meaningful machine learning systems. It ends up that we don't really have to understand how a deep network's neurons process image features&nbsp;</span><span data-mce-style=\"font-family: Times; font-size: medium; line-height: normal;\" style=\"background-color: white;\">to</span><span style=\"background-color: white;\">&nbsp;trust the system to make decisions. As long as the model provides uncertainty estimates, we'll know when the model is struggling. This is particularly important when your network is given&nbsp;</span><span data-mce-style=\"font-family: Times; font-size: medium; line-height: normal;\" style=\"background-color: white;\"><span data-mce-style=\"font-family: Times; font-size: medium; line-height: normal;\"><span data-mce-style=\"font-family: Times; font-size: medium; line-height: normal;\">inputs</span></span></span><span style=\"background-color: white;\">&nbsp;that are far from the training data.</span><br /><br /><h3><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><a href=\"https://2.bp.blogspot.com/-y_QxwwRRcUg/V2ERx6CArWI/AAAAAAAAOxk/uxsSlL_SssU8TxODMLI7q_Rno0EHFT9AwCLcB/s1600/gaussian_process_confidence_values.png\" imageanchor=\"1\" style=\"margin-left: auto; margin-right: auto;\"><img border=\"0\" height=\"132\" src=\"https://2.bp.blogspot.com/-y_QxwwRRcUg/V2ERx6CArWI/AAAAAAAAOxk/uxsSlL_SssU8TxODMLI7q_Rno0EHFT9AwCLcB/s400/gaussian_process_confidence_values.png\" width=\"400\" /></a></td></tr><tr><td class=\"tr-caption\" style=\"font-size: 12.8px;\"><b>The Gaussian Process:</b> A machine learning approach with built-in uncertainty modeling<br /><div><br /></div></td></tr></tbody></table></h3>In a recent ICML 2016 paper, <a href=\"http://mlg.eng.cam.ac.uk/yarin/\">Yarin Gal</a> and <a href=\"http://mlg.eng.cam.ac.uk/zoubin/\">Zoubin Ghahramani</a>&nbsp;develop&nbsp;<span style=\"background-color: white;\">a new theoretical framework casting dropout training in deep neural networks as approximate Bayesian inference in deep Gaussian processes. Gal's paper gives a complete theoretical treatment of the link between Gaussian processes and dropout, and develops the tools necessary to represent uncertainty in deep learning. They show that a neural network with arbitrary depth and non-linearities, with dropout applied before every weight layer, is mathematically equivalent to an approximation to the probabilistic deep Gaussian process. I have yet to see researchers use dropout between every layer, so the discrepancy between theory and practice suggests that more research is necessary.</span><br /><br /><a href=\"https://arxiv.org/abs/1506.02142\">Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning</a>&nbsp;Yarin Gal, Zoubin Ghahramani, in ICML. June 2016. [<a href=\"https://arxiv.org/abs/1506.02157\">Appendix</a>&nbsp;with relationship to Gaussian Processes]<br /><a href=\"https://arxiv.org/abs/1512.05287\">A Theoretically Grounded Application of Dropout in Recurrent Neural Networks</a>&nbsp;Yarin Gal, in&nbsp;arXiv:1512.05287. May 2016.<br /><div><a href=\"http://mlg.eng.cam.ac.uk/yarin/blog_3d801aa532c1ce.html\">What My Deep Model Doesn't Know</a>. Yarin Gal. Blog Post. July 2015&nbsp;</div><div><a href=\"https://github.com/yaringal/HeteroscedasticDropoutUncertainty\">Homoscedastic and Heteroscedastic Regression with Dropout Uncertainty</a>. Yarin Gal. Blog Post. February 2016.</div><div><br /></div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"></td></tr></tbody></table><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: right;\"><tbody><tr><td style=\"text-align: center;\"><a href=\"https://4.bp.blogspot.com/-vwollbVk8dA/V2J4Ekoi9AI/AAAAAAAAOzE/Y4aYoKkYZN0FvWJbssXZ-fpnaHtLPIAvACLcB/s1600/black_box.png\" imageanchor=\"1\" style=\"clear: right; margin-bottom: 1em; margin-left: auto; margin-right: auto;\"><img border=\"0\" height=\"228\" src=\"https://4.bp.blogspot.com/-vwollbVk8dA/V2J4Ekoi9AI/AAAAAAAAOzE/Y4aYoKkYZN0FvWJbssXZ-fpnaHtLPIAvACLcB/s400/black_box.png\" width=\"400\" /></a></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\">Test-time dropout is used to provide uncertainty estimates for deep learning systems.</td></tr></tbody></table><br />In conclusion, maybe we can never get both interpretability and performance when it comes to deep learning systems. But, we can all agree that providing confidences, or uncertainty estimates, alongside predictions is <i>always</i> a good idea. Dropout, the very single regularization trick used to battle overfitting in deep models, shows up, yet again. Sometimes all you need is to add some random variations to your input, and average the results over many trials. Dropout lets you not only wiggle the network inputs but the entire architecture.<br /><br />I do wonder what Yann LeCun thinks about Bayesian ConvNets... Last I heard, he was allergic to sampling.<br /><br /><b>Related Posts&nbsp;</b><br /><a href=\"http://www.computervisionblog.com/2015/04/deep-learning-vs-probabilistic.html\">Deep Learning vs Probabilistic Graphical Models vs Logic</a> April 2015<br /><a href=\"http://www.computervisionblog.com/2016/06/deep-learning-trends-iclr-2016.html\">Deep Learning Trends&nbsp;@ ICLR 2016</a> June 2016<br /><br />",
  "link": [
    "",
    "",
    "",
    "",
    ""
  ],
  "author": {
    "name": "Tomasz Malisiewicz",
    "uri": "http://www.blogger.com/profile/17507234774392358321",
    "email": "noreply@blogger.com",
    "gd:image": ""
  },
  "media:thumbnail": "",
  "thr:total": 0
}