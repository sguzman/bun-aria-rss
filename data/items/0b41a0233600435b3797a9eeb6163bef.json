{
  "title": "Reducing Instagram’s basic video compute time by 94 percent",
  "link": "https://engineering.fb.com/2022/11/04/video-engineering/instagram-video-processing-encoding-reduction/",
  "dc:creator": "",
  "pubDate": "Fri, 04 Nov 2022 13:00:15 +0000",
  "category": [
    "Connectivity",
    "Video Engineering",
    "Web",
    "Instagram"
  ],
  "guid": "https://engineering.fb.com/?p=19536",
  "description": "<p>In our constant quest to prioritize efficiency, Instagram’s engineers have developed a way to process new videos that reduces the cost to produce basic video encodings by 94 percent. With this method in place, Meta’s video infrastructure can continue to scale without needing to add more machines. This frees up resources so more people can [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2022/11/04/video-engineering/instagram-video-processing-encoding-reduction/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2022/11/04/video-engineering/instagram-video-processing-encoding-reduction/\">Reducing Instagram’s basic video compute time by 94 percent</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
  "content:encoded": "<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">In our constant quest to <a href=\"https://engineering.fb.com/2019/03/14/data-center-engineering/accelerating-infrastructure/\" target=\"_blank\" rel=\"noopener\">prioritize efficiency</a>, Instagram’s engineers have developed a way to process new videos that reduces the cost to produce basic video encodings by 94 percent.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">With this method in place, <a href=\"https://engineering.fb.com/2021/04/05/video-engineering/how-facebook-encodes-your-videos/\" target=\"_blank\" rel=\"noopener\">Meta’s video infrastructure</a> can continue to scale without needing to add more machines.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">This frees up resources so more people can watch advanced encodings, which provide clearer video that plays more smoothly. This is especially beneficial for people in countries that have slower internet connections.</span></li>\n</ul>\n<p><span style=\"font-weight: 400;\">Instagram’s growing user base of more than 2 billion monthly active users requires us to get the best possible performance from our fleet of servers. In early 2021, we ran projections that showed that within 12 months we would not have enough capacity to provide video uploads for everyone. But in our never-ending quest to prioritize efficiency, we uncovered a way to handle this increasing demand and <a href=\"https://engineering.fb.com/2022/09/06/data-center-engineering/viewing-the-world-as-a-computer-global-capacity-management/\" target=\"_blank\" rel=\"noopener\">scale our infrastructure</a> by doing more with the machines we already have. </span></p>\n<p><span style=\"font-weight: 400;\">Instagram creates multiple encoded versions of uploaded videos, each with different characteristics. By repurposing one type of video encoding to help generate another type, we reduced the compute resources we spend on less-watched video encodings by 94 percent. With more resources available, we can produce more advanced encodings — allowing more people to experience clearer video with smoother playback.</span></p>\n<h2><span style=\"font-weight: 400;\">Where Instagram spends video compute</span></h2>\n<p><span style=\"font-weight: 400;\">We generate two types of video encoding for each video uploaded to Instagram:</span></p>\n<ol>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><b>Minimum functionality encodings</b><span style=\"font-weight: 400;\"> are compatible with all Instagram clients. Their lower-efficiency compression is easier for older devices to decode and play.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><b>Advanced encodings</b><span style=\"font-weight: 400;\"> use <a href=\"https://engineering.fb.com/2018/04/10/video-engineering/av1-beats-x264-and-libvpx-vp9-in-practical-use-case/\" target=\"_blank\" rel=\"noopener\">newer compression technologies</a> for higher-quality playback. In the example below, close-ups of two video frames show that we can provide sharper detail with fewer bits (note the clarity of the video on the right compared with that on the left).</span></li>\n</ol>\n<div style=\"width: 720px;\" class=\"wp-video\"><!--[if lt IE 9]><script>document.createElement('video');</script><![endif]-->\n<video class=\"wp-video-shortcode\" id=\"video-19536-1\" width=\"720\" height=\"720\" poster=\"https://engineering.fb.com/wp-content/uploads/2022/11/Facebook_Cover.png\" loop=\"1\" autoplay=\"1\" muted=\"1\" playsinline=\"1\" preload=\"metadata\" controls=\"controls\"><source type=\"video/mp4\" src=\"https://engineering.fb.com/wp-content/uploads/2022/11/Facebook_VIDEO_COMPUTE_1X1.mp4?_=1\" /><a href=\"https://engineering.fb.com/wp-content/uploads/2022/11/Facebook_VIDEO_COMPUTE_1X1.mp4\">https://engineering.fb.com/wp-content/uploads/2022/11/Facebook_VIDEO_COMPUTE_1X1.mp4</a></video></div>\n<p><span style=\"font-weight: 400;\">The problem was that we were spending more than 80 percent of our resources processing minimum functionality encodings. If we stayed on that trajectory, minimum functionality would monopolize our resources within a year. As a result, videos would start to take longer to publish — or fail to publish altogether. Our advanced encodings covered only 15 percent of total watch time, and we projected that spending all our compute on minimum functionality versions would soon prevent us from being able to provide advanced video encoding watch time. </span></p>\n<h2><span style=\"font-weight: 400;\">Removing redundant workloads</span></h2>\n<p><span style=\"font-weight: 400;\">Instagram creates two classes of minimum functionality encodings. For every video, we generate basic adaptive bit rate (ABR) encodings — our most-watched minimum functionality type. For the steadiest playback, clients can select the version that best fits their connection speed to prevent stalling caused by changes in bandwidth — a technique called </span><a href=\"https://howvideo.works/#adaptive-bitrate-streaming\" target=\"_blank\" rel=\"noopener\"><span style=\"font-weight: 400;\">adaptive bit rate streaming</span></a><span style=\"font-weight: 400;\">.</span></p>\n<p><span style=\"font-weight: 400;\">We rarely deliver progressive encodings, the other minimum functionality type, but we continue to produce them to maintain compatibility with old versions of the Instagram app that don’t support ABR playback.</span></p>\n<p><span style=\"font-weight: 400;\">Traditionally, we have created both ABR and progressive encodings from the original file the client uploaded to our back end. But this process hogs compute resources: As the following terminal command shows, it takes 86.17 seconds of CPU time to transcode a 23-second video to 720p.</span></p>\n<pre class=\"line-numbers\"><code class=\"language-none\">$ time ffmpeg -i input.mp4 -vf scale=-1:720 -c:v libx264 output.mp4\n86.17s user 1.32s system 964% cpu 9.069 total</code></pre>\n<p><span style=\"font-weight: 400;\">We noticed that the settings of the two sets of encodings were similar. They used the same codec with only minor differences in the encoding profile and preset. Then it dawned on us: We could</span><b> replace our basic ABR encodings with the progressive encodings’ video frames by repackaging them into an ABR-capable file structure</b><span style=\"font-weight: 400;\">. This would virtually eliminate the cost of generating our basic ABR encodings. The following terminal command times show that it takes only 0.36 seconds to generate a manifest file and repackage the video frames into an ABR-capable file structure for the same input video.</span></p>\n<pre class=\"line-numbers\"><code class=\"language-none\">$ time MP4Box -add input.mp4 -dash 2000 -profile dashavc264:onDemand -out manifest.mpd \nvideo_output.mp4\n0.36s user 2.22s system 95% cpu 2.690 total</code></pre>\n<p><span style=\"font-weight: 400;\">This approach frees up compute for advanced encoding production, although it comes at the expense of the compression efficiency of our basic ABR encodings. Our theory was that </span><b>generating a greater number of advanced encodings would be a net positive for people who use Instagram.</b></p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"alignnone size-large wp-image-19538\" src=\"https://engineering.fb.com/wp-content/uploads/2022/10/Reducing-Instagram-Video-Compute_image2.png?w=760\" alt=\"Instagram video compute\" width=\"760\" height=\"611\" srcset=\"https://engineering.fb.com/wp-content/uploads/2022/10/Reducing-Instagram-Video-Compute_image2.png 760w, https://engineering.fb.com/wp-content/uploads/2022/10/Reducing-Instagram-Video-Compute_image2.png?resize=96,77 96w, https://engineering.fb.com/wp-content/uploads/2022/10/Reducing-Instagram-Video-Compute_image2.png?resize=192,154 192w\" sizes=\"(max-width: 992px) 100vw, 62vw\" /></p>\n<h2><span style=\"font-weight: 400;\">Building a framework to test our theory</span></h2>\n<p><span style=\"font-weight: 400;\">We needed to prove our theory before we could ship to production. If we compared the basic ABR encodings before and after our change, we would see only regressions. We also needed to measure the net effect from more advanced encodings. The diagram below shows the higher watch time we expected for advanced encodings after freeing up compute from our basic ABR. This would make up for the poorer compression efficiency of the new basic ABR.</span></p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"alignnone size-large wp-image-19539\" src=\"https://engineering.fb.com/wp-content/uploads/2022/10/Reducing-Instagram-Video-Compute_image3.png?w=1024\" alt=\"Instagram video compute\" width=\"1024\" height=\"478\" srcset=\"https://engineering.fb.com/wp-content/uploads/2022/10/Reducing-Instagram-Video-Compute_image3.png 1157w, https://engineering.fb.com/wp-content/uploads/2022/10/Reducing-Instagram-Video-Compute_image3.png?resize=916,428 916w, https://engineering.fb.com/wp-content/uploads/2022/10/Reducing-Instagram-Video-Compute_image3.png?resize=768,358 768w, https://engineering.fb.com/wp-content/uploads/2022/10/Reducing-Instagram-Video-Compute_image3.png?resize=1024,478 1024w, https://engineering.fb.com/wp-content/uploads/2022/10/Reducing-Instagram-Video-Compute_image3.png?resize=96,45 96w, https://engineering.fb.com/wp-content/uploads/2022/10/Reducing-Instagram-Video-Compute_image3.png?resize=192,90 192w\" sizes=\"(max-width: 992px) 100vw, 62vw\" /></p>\n<p><span style=\"font-weight: 400;\">To measure this, we built a testing framework that replicated some small percentage of traffic across a test pool and a control pool of equal processing power. We saved the encodings from each pool to different namespaces so we could later identify them as part of the control or test catalog of videos. Then, at delivery time, people would see encodings from only one catalog or the other. This would allow us to measure whether the new encoding scheme was better.</span></p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"alignnone size-large wp-image-19540\" src=\"https://engineering.fb.com/wp-content/uploads/2022/10/Reducing-Instagram-Video-Compute_image4.png?w=1008\" alt=\"Instagram video compute\" width=\"1008\" height=\"463\" srcset=\"https://engineering.fb.com/wp-content/uploads/2022/10/Reducing-Instagram-Video-Compute_image4.png 1008w, https://engineering.fb.com/wp-content/uploads/2022/10/Reducing-Instagram-Video-Compute_image4.png?resize=916,421 916w, https://engineering.fb.com/wp-content/uploads/2022/10/Reducing-Instagram-Video-Compute_image4.png?resize=768,353 768w, https://engineering.fb.com/wp-content/uploads/2022/10/Reducing-Instagram-Video-Compute_image4.png?resize=96,44 96w, https://engineering.fb.com/wp-content/uploads/2022/10/Reducing-Instagram-Video-Compute_image4.png?resize=192,88 192w\" sizes=\"(max-width: 992px) 100vw, 62vw\" /></p>\n<p><span style=\"font-weight: 400;\">From this test, we proved that although we were degrading the compression efficiency of the basic ABR encodings in the test pool, the higher watch time for advanced encodings more than made up for it.</span></p>\n<h2><span style=\"font-weight: 400;\">Pushing to production</span></h2>\n<p><span style=\"font-weight: 400;\">After we launched this optimization, we saw major gains in compute savings and higher advanced encoding watch time. </span><b>Our new encoding scheme reduced the cost of generating our basic ABR encodings by 94 percent.</b><span style=\"font-weight: 400;\"> With more resources available, we were able to increase the overall watch time coverage of advanced encodings by 33 percent. This means that today more people on Instagram get to experience clearer video that plays more smoothly. This is especially important in providing a great experience to people in countries that have slower internet connections.</span></p>\n<p><span style=\"font-weight: 400;\">There is still more engineering innovation needed, as Instagram’s growing user base will continue to place increasing demand on our fleet of servers. Stay tuned!</span></p>\n<p><span style=\"font-weight: 400;\">Over the years, Instagram has worked continuously to i<a href=\"https://engineering.fb.com/2022/10/31/ml-applications/instagram-notification-management-machine-learning/\" target=\"_blank\" rel=\"noopener\">mprove its product offerings</a>. Given our scale — including 2 billion monthly active users on our platform and more than 140 billion Reels plays across Instagram and Facebook every day — our work can make a huge impact. If this sounds interesting to you, <a href=\"https://www.facebookcareers.com/jobs/?is_leadership=0&teams%5B0%5D=Software%20Engineering&is_in_page=0\">join us!</a></span></p>\n<h2><span style=\"font-weight: 400;\">Acknowledgments</span></h2>\n<p><i><span style=\"font-weight: 400;\">Thanks to Haixia Shi for incepting the idea for this efficiency optimization. Thanks to Richard Shyong for implementing the optimization and the testing framework, which enables us to measure all compute efficiency investments. Thanks to Runshen Zhu and Ang Li for discussions that resulted in the investment in this scope. Thanks to our partners Atasay Gokkaya, Justin Li, Chia-I Wei, and Zainab Zahid for helping with testing pool provisioning and discussions on video compute efficiency.</span></i></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2022/11/04/video-engineering/instagram-video-processing-encoding-reduction/\">Reducing Instagram’s basic video compute time by 94 percent</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
  "post-id": 19536
}