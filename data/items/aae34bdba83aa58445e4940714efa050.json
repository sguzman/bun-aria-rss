{
  "title": "These Are Your Tweets on LDA (Part I)",
  "link": "https://wellecks.wordpress.com/2014/09/03/these-are-your-tweets-on-lda-part-i/",
  "comments": "https://wellecks.wordpress.com/2014/09/03/these-are-your-tweets-on-lda-part-i/#comments",
  "dc:creator": "wellecks",
  "pubDate": "Thu, 04 Sep 2014 03:09:32 +0000",
  "category": [
    "artificial intelligence",
    "machine learning",
    "Artificial intelligence",
    "Latent Dirichlet Allocation",
    "LDA",
    "Machine learning",
    "mallet",
    "topic modeling",
    "tutorial",
    "tweets",
    "twitter",
    "wordle"
  ],
  "guid": "http://wellecks.wordpress.com/?p=723",
  "description": "How can we get a sense of what someone tweets about? One way would be to identify themes, or topics, that tend to occur in a user&#8217;s tweets. Perhaps we can look through the user&#8217;s profile, continually scrolling down and getting a feel for the different topics that they tweet about. But what if we could [&#8230;]",
  "content:encoded": "<p>How can we get a sense of what someone tweets about? One way would be to identify themes, or topics, that tend to occur in a user&#8217;s tweets. Perhaps we can look through the user&#8217;s profile, continually scrolling down and getting a feel for the different topics that they tweet about.</p>\n<p>But what if we could use machine learning to discover topics <em>automatically</em>, to measure<em> how much</em> each topic occurs, and even tell us the words that make up the topic?</p>\n<p>In this post, we&#8217;ll do just that. We&#8217;ll retrieve users&#8217; tweets, and use an unsupervised machine learning technique called <a title=\"Wikipedia - Latent Dirichlet Allocation\" href=\"http://en.wikipedia.org/wiki/Latent_Dirichlet_allocation\">Latent Dirichlet Allocation</a> (LDA) to uncover topics within the tweets. Then we&#8217;ll create visualizations for the topics based on the words that define them. Our tools will be Java, <a title=\"Twitter4J\" href=\"http://twitter4j.org/en/\">Twitter4J</a>, and <a title=\"MALLET\" href=\"http://mallet.cs.umass.edu/\">Mallet</a>. All of the code is available on <a href=\"https://github.com/wellecks/lda_tweets\">GitHub</a> for reference.</p>\n<p>As a sneak preview, here&#8217;s a visualization of a topic from <a title=\"@gvanrossum\" href=\"https://twitter.com/gvanrossum\">@gvanrossum</a>:</p>\n<p style=\"text-align:center;\"><a href=\"https://wellecks.files.wordpress.com/2014/08/screen-shot-2014-08-30-at-10-04-54-pm.png\"><img loading=\"lazy\" data-attachment-id=\"733\" data-permalink=\"https://wellecks.wordpress.com/2014/09/03/these-are-your-tweets-on-lda-part-i/screen-shot-2014-08-30-at-10-04-54-pm/#main\" data-orig-file=\"https://wellecks.files.wordpress.com/2014/08/screen-shot-2014-08-30-at-10-04-54-pm.png\" data-orig-size=\"1636,1088\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"Screen Shot 2014-08-30 at 10.04.54 PM\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://wellecks.files.wordpress.com/2014/08/screen-shot-2014-08-30-at-10-04-54-pm.png?w=300\" data-large-file=\"https://wellecks.files.wordpress.com/2014/08/screen-shot-2014-08-30-at-10-04-54-pm.png?w=525\" class=\"alignnone size-medium wp-image-733\" src=\"https://wellecks.files.wordpress.com/2014/08/screen-shot-2014-08-30-at-10-04-54-pm.png?w=300&#038;h=199\" alt=\"Screen Shot 2014-08-30 at 10.04.54 PM\" width=\"300\" height=\"199\" srcset=\"https://wellecks.files.wordpress.com/2014/08/screen-shot-2014-08-30-at-10-04-54-pm.png?w=300&h=199 300w, https://wellecks.files.wordpress.com/2014/08/screen-shot-2014-08-30-at-10-04-54-pm.png?w=598&h=398 598w, https://wellecks.files.wordpress.com/2014/08/screen-shot-2014-08-30-at-10-04-54-pm.png?w=150&h=100 150w\" sizes=\"(max-width: 300px) 100vw, 300px\" /></a></p>\n<p>First I&#8217;ll give an intuitive background of LDA, then explain some of the underlying math, and finally move to the code and applications.</p>\n<p style=\"text-align:center;\"><strong>What&#8217;s LDA?</strong></p>\n<p style=\"text-align:left;\">Intuitively, Latent Dirichlet Allocation provides a thematic summary of a set of documents (in our case, a set of tweets). It gives this summary by discovering &#8216;topics&#8217;, and telling us the proportion of each topic found in a document.</p>\n<p style=\"text-align:left;\">To do so, LDA attempts to model how a document was &#8216;generated&#8217; by assuming that a document is a mixture of different topics, and assuming that each word is &#8216;generated&#8217; by one of the topics.</p>\n<p style=\"text-align:left;\">As a simple example, consider the following tweets:</p>\n<blockquote>\n<p class=\"p1\">(1) Fruits and vegetables are healthy.</p>\n<p class=\"p1\">(2) I like apples, oranges, and avocados. I don&#8217;t like the flu or colds.</p>\n</blockquote>\n<p style=\"text-align:left;\">Let&#8217;s remove stop words, giving:</p>\n<blockquote>\n<p class=\"p1\">(1) fruits vegetables healthy</p>\n<p class=\"p1\">(2) apples oranges avocados flu colds</p>\n</blockquote>\n<p style=\"text-align:left;\">We&#8217;ll let <img src=\"https://s0.wp.com/latex.php?latex=k+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=k+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"k \" class=\"latex\" /> denote the number of topics that we think these tweets are generated from. Let&#8217;s say there are <img src=\"https://s0.wp.com/latex.php?latex=k+%3D+2+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=k+%3D+2+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k+%3D+2+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"k = 2 \" class=\"latex\" /> topics. Note that there are <img src=\"https://s0.wp.com/latex.php?latex=V+%3D+8&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=V+%3D+8&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=V+%3D+8&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"V = 8\" class=\"latex\" /> words in our corpus. LDA would tell us that:</p>\n<pre style=\"text-align:left;\">Topic 1 = Fruits, Vegetables, Apples, Oranges, Avocados\nTopic 2 = Healthy, Flu, Colds</pre>\n<p style=\"text-align:left;\">And that:</p>\n<pre style=\"text-align:left;\">Tweet 1 = (2/3) Topic 1, (1/3) Topic 2\nTweet 2 = (3/5) Topic 1, (2/5) Topic 2</pre>\n<p style=\"text-align:left;\">We can conclude that there&#8217;s a <em>food</em> topic and a <em>health </em>topic, see words that define those topics, and view the topic composition of each tweet.</p>\n<p style=\"text-align:left;\">Each topic in LDA is a probability distribution over the words. In our case, LDA would give <img src=\"https://s0.wp.com/latex.php?latex=k+%3D+2&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=k+%3D+2&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k+%3D+2&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"k = 2\" class=\"latex\" /> distributions of size <img src=\"https://s0.wp.com/latex.php?latex=V+%3D+8&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=V+%3D+8&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=V+%3D+8&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"V = 8\" class=\"latex\" />. Each item of the distribution corresponds to a word in the vocabulary. For instance, let&#8217;s call one of these distributions <img src=\"https://s0.wp.com/latex.php?latex=%5Cbeta_%7B1%7D.+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Cbeta_%7B1%7D.+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta_%7B1%7D.+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;beta_{1}. \" class=\"latex\" /> It might look something like:</p>\n<p style=\"text-align:center;\"><img src=\"https://s0.wp.com/latex.php?latex=%5Cbeta_%7B1%7D+%3D+%5B0.4%2C+0.2%2C+0.15%2C+0.05%2C+0.05%2C+0.05%2C+0.05%5D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Cbeta_%7B1%7D+%3D+%5B0.4%2C+0.2%2C+0.15%2C+0.05%2C+0.05%2C+0.05%2C+0.05%5D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta_%7B1%7D+%3D+%5B0.4%2C+0.2%2C+0.15%2C+0.05%2C+0.05%2C+0.05%2C+0.05%5D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;beta_{1} = [0.4, 0.2, 0.15, 0.05, 0.05, 0.05, 0.05]\" class=\"latex\" /></p>\n<p style=\"text-align:left;\"><img src=\"https://s0.wp.com/latex.php?latex=%5Cbeta_%7B1%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Cbeta_%7B1%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta_%7B1%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;beta_{1}\" class=\"latex\" /> lets us answer questions such as: given that our topic is Topic #1 (&#8216;Food&#8217;), what is the probability of generating word #1 (&#8216;Fruits&#8217;)?</p>\n<p style=\"text-align:left;\">Now, I&#8217;ll jump into the math underlying LDA to explore specifically what LDA does and how it works. If you still need some more intuition-building, see <a href=\"http://blog.echen.me/2011/08/22/introduction-to-latent-dirichlet-allocation/\">Edwin Chen&#8217;s great blog post</a>. Or feel free to skip to the application if you&#8217;d like, but I&#8217;d encourage you to read on!</p>\n<p style=\"text-align:center;\"><strong>A Bit More Formal</strong></p>\n<p style=\"text-align:left;\">LDA assumes that documents (assumed to be bags of words) are generated by a mixture of topics (distributions over words). We define the following variables and notation:</p>\n<pre style=\"text-align:left;\"><img src=\"https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"k\" class=\"latex\" /> is the number of topics.\n\n<img src=\"https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"V\" class=\"latex\" /> is the number of unique words in the vocabulary.\n\n<img src=\"https://s0.wp.com/latex.php?latex=%5Ctheta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Ctheta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctheta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;theta \" class=\"latex\" /> is the topic distribution (of length <img src=\"https://s0.wp.com/latex.php?latex=k+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=k+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"k \" class=\"latex\" />) for a document, drawn from a uniform Dirichlet distribution with parameter <img src=\"https://s0.wp.com/latex.php?latex=%5Calpha+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Calpha+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;alpha \" class=\"latex\" />.\n\n<img src=\"https://s0.wp.com/latex.php?latex=z_%7Bn%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=z_%7Bn%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=z_%7Bn%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"z_{n}\" class=\"latex\" /> is a topic 'assignment' for word <img src=\"https://s0.wp.com/latex.php?latex=w_%7Bn%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=w_%7Bn%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w_%7Bn%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"w_{n}\" class=\"latex\" />, sampled from <img src=\"https://s0.wp.com/latex.php?latex=p%28z_%7Bn%7D+%3D+i%7C%5Ctheta%29+%3D+%5Ctheta_%7Bi%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=p%28z_%7Bn%7D+%3D+i%7C%5Ctheta%29+%3D+%5Ctheta_%7Bi%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p%28z_%7Bn%7D+%3D+i%7C%5Ctheta%29+%3D+%5Ctheta_%7Bi%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"p(z_{n} = i|&#92;theta) = &#92;theta_{i}\" class=\"latex\" />.\n\n<img src=\"https://s0.wp.com/latex.php?latex=%5Ctextbf%7Bw%7D+%3D+%28w_%7B1%7D%2C+...+%2C+w_%7BN%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Ctextbf%7Bw%7D+%3D+%28w_%7B1%7D%2C+...+%2C+w_%7BN%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctextbf%7Bw%7D+%3D+%28w_%7B1%7D%2C+...+%2C+w_%7BN%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;textbf{w} = (w_{1}, ... , w_{N})\" class=\"latex\" /> is a document with N words.\n\n<img src=\"https://s0.wp.com/latex.php?latex=w_%7Bn%7D%5E%7Bi%7D+%3D+1&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=w_%7Bn%7D%5E%7Bi%7D+%3D+1&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w_%7Bn%7D%5E%7Bi%7D+%3D+1&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"w_{n}^{i} = 1\" class=\"latex\" /> means that the word <img src=\"https://s0.wp.com/latex.php?latex=w_%7Bn%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=w_%7Bn%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w_%7Bn%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"w_{n}\" class=\"latex\" /> is the i'th word of the vocabulary.\n\n<img src=\"https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;beta \" class=\"latex\" /> is a <img src=\"https://s0.wp.com/latex.php?latex=k+%5Ctimes+V&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=k+%5Ctimes+V&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k+%5Ctimes+V&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"k &#92;times V\" class=\"latex\" /> matrix, where each row <img src=\"https://s0.wp.com/latex.php?latex=%5Cbeta_%7Bi%7D+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Cbeta_%7Bi%7D+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta_%7Bi%7D+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;beta_{i} \" class=\"latex\" /> is the multinomial distribution for the <img src=\"https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"i\" class=\"latex\" />th topic. That is, <img src=\"https://s0.wp.com/latex.php?latex=%5Cbeta_%7Bij%7D+%3D+p%28w%5E%7Bj%7D+%3D+1+%7C+z_%7Bj%7D+%3D+i%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Cbeta_%7Bij%7D+%3D+p%28w%5E%7Bj%7D+%3D+1+%7C+z_%7Bj%7D+%3D+i%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta_%7Bij%7D+%3D+p%28w%5E%7Bj%7D+%3D+1+%7C+z_%7Bj%7D+%3D+i%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;beta_{ij} = p(w^{j} = 1 | z_{j} = i)\" class=\"latex\" />.\n\n</pre>\n<p style=\"text-align:left;\">LDA then posits that a document is generated according to the following process:</p>\n<p style=\"text-align:left;\">1. Fix <img src=\"https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"k\" class=\"latex\" /> and <img src=\"https://s0.wp.com/latex.php?latex=N&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=N&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=N&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"N\" class=\"latex\" />.</p>\n<p style=\"text-align:left;\">2. Sample a topic distribution <img src=\"https://s0.wp.com/latex.php?latex=%5Ctheta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Ctheta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctheta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;theta \" class=\"latex\" /> from <img src=\"https://s0.wp.com/latex.php?latex=Dir%28%5Calpha_%7B1%7D%2C+...+%2C+%5Calpha_%7Bk%7D%29+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=Dir%28%5Calpha_%7B1%7D%2C+...+%2C+%5Calpha_%7Bk%7D%29+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=Dir%28%5Calpha_%7B1%7D%2C+...+%2C+%5Calpha_%7Bk%7D%29+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"Dir(&#92;alpha_{1}, ... , &#92;alpha_{k}) \" class=\"latex\" />.</p>\n<p style=\"text-align:left;padding-left:30px;\"><img src=\"https://s0.wp.com/latex.php?latex=%5Ctheta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Ctheta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctheta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;theta \" class=\"latex\" /> defines the topic mixture of the document, so intuitively <img src=\"https://s0.wp.com/latex.php?latex=%5Ctheta_%7Bi%7D+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Ctheta_%7Bi%7D+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctheta_%7Bi%7D+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;theta_{i} \" class=\"latex\" /> is the degree to which <img src=\"https://s0.wp.com/latex.php?latex=topic_%7Bi%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=topic_%7Bi%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=topic_%7Bi%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"topic_{i}\" class=\"latex\" /> appears in the document.</p>\n<p style=\"text-align:left;\">3. For each word index <img src=\"https://s0.wp.com/latex.php?latex=n+%5Cin+%5Cleft%5C%7B1%2C...%2C+N%5Cright%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=n+%5Cin+%5Cleft%5C%7B1%2C...%2C+N%5Cright%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n+%5Cin+%5Cleft%5C%7B1%2C...%2C+N%5Cright%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"n &#92;in &#92;left&#92;{1,..., N&#92;right&#92;}\" class=\"latex\" />:</p>\n<p style=\"text-align:left;padding-left:30px;\">4. Draw <img src=\"https://s0.wp.com/latex.php?latex=z_%7Bn%7D+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=z_%7Bn%7D+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=z_%7Bn%7D+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"z_{n} \" class=\"latex\" /> from <img src=\"https://s0.wp.com/latex.php?latex=%5Ctheta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Ctheta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctheta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;theta\" class=\"latex\" />.</p>\n<p style=\"text-align:left;padding-left:60px;\"><img src=\"https://s0.wp.com/latex.php?latex=z_%7Bn%7D+%3D+i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=z_%7Bn%7D+%3D+i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=z_%7Bn%7D+%3D+i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"z_{n} = i\" class=\"latex\" /> tells us that the word we are about to generate will be generated by topic <img src=\"https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"i\" class=\"latex\" />.</p>\n<p style=\"text-align:left;padding-left:30px;\">5. Draw a word <img src=\"https://s0.wp.com/latex.php?latex=w_%7Bn%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=w_%7Bn%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w_%7Bn%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"w_{n}\" class=\"latex\" /> from <img src=\"https://s0.wp.com/latex.php?latex=%5Cbeta_%7Bz_%7Bn%7D%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Cbeta_%7Bz_%7Bn%7D%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta_%7Bz_%7Bn%7D%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;beta_{z_{n}}\" class=\"latex\" />.</p>\n<p style=\"text-align:left;padding-left:60px;\">In other words, we choose the row of <img src=\"https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;beta \" class=\"latex\" /> based on our value of <img src=\"https://s0.wp.com/latex.php?latex=z_%7Bn%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=z_%7Bn%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=z_%7Bn%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"z_{n}\" class=\"latex\" /> from (4), then sample from the distribution that this row defines. Going back to our example, if we drew the &#8220;Food&#8221; row in step (4), then it&#8217;s more likely that we&#8217;ll generate &#8220;Fruits&#8221; than &#8220;Flu&#8221; in step (5).</p>\n<p style=\"text-align:left;\">We can see that this does in fact generate a document based on the topic mixture <img src=\"https://s0.wp.com/latex.php?latex=%5Ctheta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Ctheta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctheta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;theta \" class=\"latex\" />, the topic-word assignments <strong><em>z</em></strong>, and the probability matrix <img src=\"https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;beta \" class=\"latex\" />.</p>\n<p style=\"text-align:left;\">However, we <strong>observe</strong><strong> the document</strong>, and must <strong>infer the latent topic mixture and topic-word assignments</strong>. Hence LDA aims to infer:</p>\n<p style=\"text-align:center;\"><img src=\"https://s0.wp.com/latex.php?latex=p%28%5Ctheta%2C+%5Ctextbf%7Bz%7D+%7C%5Ctextbf%7Bw%7D%2C+%5Calpha%2C+%5Cbeta%29+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=p%28%5Ctheta%2C+%5Ctextbf%7Bz%7D+%7C%5Ctextbf%7Bw%7D%2C+%5Calpha%2C+%5Cbeta%29+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p%28%5Ctheta%2C+%5Ctextbf%7Bz%7D+%7C%5Ctextbf%7Bw%7D%2C+%5Calpha%2C+%5Cbeta%29+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"p(&#92;theta, &#92;textbf{z} |&#92;textbf{w}, &#92;alpha, &#92;beta) \" class=\"latex\" />.</p>\n<p style=\"text-align:center;\"><strong>Coupling Problems</strong></p>\n<p style=\"text-align:left;\">The story&#8217;s not over quite yet, though. We have:</p>\n<p style=\"text-align:center;\"><img src=\"https://s0.wp.com/latex.php?latex=p%28%5Ctheta%2C+%5Ctextbf%7Bz%7D+%7C%5Ctextbf%7Bw%7D%2C+%5Calpha%2C+%5Cbeta%29+%3D+%5Cfrac%7Bp%28%5Ctheta%2C+%5Ctextbf%7Bz%7D%2C+%5Ctextbf%7Bw%7D+%7C+%5Calpha%2C+%5Cbeta%29%7D%7Bp%28%5Ctextbf%7Bw%7D+%7C+%5Calpha%2C+%5Cbeta%29%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=p%28%5Ctheta%2C+%5Ctextbf%7Bz%7D+%7C%5Ctextbf%7Bw%7D%2C+%5Calpha%2C+%5Cbeta%29+%3D+%5Cfrac%7Bp%28%5Ctheta%2C+%5Ctextbf%7Bz%7D%2C+%5Ctextbf%7Bw%7D+%7C+%5Calpha%2C+%5Cbeta%29%7D%7Bp%28%5Ctextbf%7Bw%7D+%7C+%5Calpha%2C+%5Cbeta%29%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p%28%5Ctheta%2C+%5Ctextbf%7Bz%7D+%7C%5Ctextbf%7Bw%7D%2C+%5Calpha%2C+%5Cbeta%29+%3D+%5Cfrac%7Bp%28%5Ctheta%2C+%5Ctextbf%7Bz%7D%2C+%5Ctextbf%7Bw%7D+%7C+%5Calpha%2C+%5Cbeta%29%7D%7Bp%28%5Ctextbf%7Bw%7D+%7C+%5Calpha%2C+%5Cbeta%29%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"p(&#92;theta, &#92;textbf{z} |&#92;textbf{w}, &#92;alpha, &#92;beta) = &#92;frac{p(&#92;theta, &#92;textbf{z}, &#92;textbf{w} | &#92;alpha, &#92;beta)}{p(&#92;textbf{w} | &#92;alpha, &#92;beta)}\" class=\"latex\" /></p>\n<p style=\"text-align:left;\">Let&#8217;s consider the denominator. I&#8217;m going to skip the derivation here (see <a href=\"http://obphio.us/pdfs/lda_tutorial.pdf\">pg. 5 of Reed</a> for the full story), but we have:</p>\n<p style=\"text-align:left;\"><img src=\"https://s0.wp.com/latex.php?latex=p%28%5Ctextbf%7Bw%7D+%7C+%5Calpha%2C+%5Cbeta%29+%3D+%5Cfrac%7B%5CGamma%28%5Csum_%7Bi%3D1%7D%5E%7Bk%7D%5Calpha_%7Bi%7D%29%7D%7B%5Cprod_%7Bi%3D1%7D%5E%7Bk%7D%5CGamma%28%5Calpha_%7Bi%7D%29%7D+%5Cint+%28%5Cprod_%7Bi%3D1%7D%5E%7Bk%7D%5Ctheta_%7Bi%7D%5E%7B%5Calpha_%7Bi%7D-1%7D%29%28%5Cprod_%7Bn%3D1%7D%5E%7BN%7D%5Csum_%7Bi%3D1%7D%5E%7Bk%7D%5Cprod_%7Bj%3D1%7D%5E%7BV%7D%28%5Ctheta_%7Bi%7D%5Cbeta_%7Bij%7D%29%5E%7Bw_%7Bn%7D%5E%7Bj%7D%7D%29%5C%2Cd%5Ctheta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=p%28%5Ctextbf%7Bw%7D+%7C+%5Calpha%2C+%5Cbeta%29+%3D+%5Cfrac%7B%5CGamma%28%5Csum_%7Bi%3D1%7D%5E%7Bk%7D%5Calpha_%7Bi%7D%29%7D%7B%5Cprod_%7Bi%3D1%7D%5E%7Bk%7D%5CGamma%28%5Calpha_%7Bi%7D%29%7D+%5Cint+%28%5Cprod_%7Bi%3D1%7D%5E%7Bk%7D%5Ctheta_%7Bi%7D%5E%7B%5Calpha_%7Bi%7D-1%7D%29%28%5Cprod_%7Bn%3D1%7D%5E%7BN%7D%5Csum_%7Bi%3D1%7D%5E%7Bk%7D%5Cprod_%7Bj%3D1%7D%5E%7BV%7D%28%5Ctheta_%7Bi%7D%5Cbeta_%7Bij%7D%29%5E%7Bw_%7Bn%7D%5E%7Bj%7D%7D%29%5C%2Cd%5Ctheta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p%28%5Ctextbf%7Bw%7D+%7C+%5Calpha%2C+%5Cbeta%29+%3D+%5Cfrac%7B%5CGamma%28%5Csum_%7Bi%3D1%7D%5E%7Bk%7D%5Calpha_%7Bi%7D%29%7D%7B%5Cprod_%7Bi%3D1%7D%5E%7Bk%7D%5CGamma%28%5Calpha_%7Bi%7D%29%7D+%5Cint+%28%5Cprod_%7Bi%3D1%7D%5E%7Bk%7D%5Ctheta_%7Bi%7D%5E%7B%5Calpha_%7Bi%7D-1%7D%29%28%5Cprod_%7Bn%3D1%7D%5E%7BN%7D%5Csum_%7Bi%3D1%7D%5E%7Bk%7D%5Cprod_%7Bj%3D1%7D%5E%7BV%7D%28%5Ctheta_%7Bi%7D%5Cbeta_%7Bij%7D%29%5E%7Bw_%7Bn%7D%5E%7Bj%7D%7D%29%5C%2Cd%5Ctheta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"p(&#92;textbf{w} | &#92;alpha, &#92;beta) = &#92;frac{&#92;Gamma(&#92;sum_{i=1}^{k}&#92;alpha_{i})}{&#92;prod_{i=1}^{k}&#92;Gamma(&#92;alpha_{i})} &#92;int (&#92;prod_{i=1}^{k}&#92;theta_{i}^{&#92;alpha_{i}-1})(&#92;prod_{n=1}^{N}&#92;sum_{i=1}^{k}&#92;prod_{j=1}^{V}(&#92;theta_{i}&#92;beta_{ij})^{w_{n}^{j}})&#92;,d&#92;theta\" class=\"latex\" /></p>\n<p style=\"text-align:left;\">We cannot separate the <img src=\"https://s0.wp.com/latex.php?latex=%5Ctheta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Ctheta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctheta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;theta\" class=\"latex\" /> and <img src=\"https://s0.wp.com/latex.php?latex=%5Cbeta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Cbeta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;beta\" class=\"latex\" />, so computing this term is intractable; we must find another approach to infer the hidden variables.</p>\n<p style=\"text-align:center;\"><strong>A Simpler Problem</strong></p>\n<p style=\"text-align:left;\">A workaround is to find a convex distribution that lower-bounds the distribution that we want to estimate. Then we can find an optimal lower bound to estimate the distribution that is intractable to compute. We simplify the problem to:</p>\n<p style=\"text-align:center;\"><img src=\"https://s0.wp.com/latex.php?latex=q%28%5Ctheta%2C+%5Ctextbf%7Bz%7D%7C%5Cgamma%2C+%5Cphi%29+%3D+q%28%5Ctheta%7C%5Cgamma%29%5Cprod_%7Bn%3D1%7D%5E%7BN%7Dq%28z_%7Bn%7D%7C%5Cphi_%7Bn%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=q%28%5Ctheta%2C+%5Ctextbf%7Bz%7D%7C%5Cgamma%2C+%5Cphi%29+%3D+q%28%5Ctheta%7C%5Cgamma%29%5Cprod_%7Bn%3D1%7D%5E%7BN%7Dq%28z_%7Bn%7D%7C%5Cphi_%7Bn%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q%28%5Ctheta%2C+%5Ctextbf%7Bz%7D%7C%5Cgamma%2C+%5Cphi%29+%3D+q%28%5Ctheta%7C%5Cgamma%29%5Cprod_%7Bn%3D1%7D%5E%7BN%7Dq%28z_%7Bn%7D%7C%5Cphi_%7Bn%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"q(&#92;theta, &#92;textbf{z}|&#92;gamma, &#92;phi) = q(&#92;theta|&#92;gamma)&#92;prod_{n=1}^{N}q(z_{n}|&#92;phi_{n})\" class=\"latex\" /></p>\n<p style=\"text-align:left;\">And minimize the <a href=\"http://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence\">KL-Divergence</a> between this distribution and the actual distribution <img src=\"https://s0.wp.com/latex.php?latex=p%28%5Ctheta%2C+%5Ctextbf%7Bz%7D+%7C%5Ctextbf%7Bw%7D%2C+%5Calpha%2C+%5Cbeta%29+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=p%28%5Ctheta%2C+%5Ctextbf%7Bz%7D+%7C%5Ctextbf%7Bw%7D%2C+%5Calpha%2C+%5Cbeta%29+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p%28%5Ctheta%2C+%5Ctextbf%7Bz%7D+%7C%5Ctextbf%7Bw%7D%2C+%5Calpha%2C+%5Cbeta%29+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"p(&#92;theta, &#92;textbf{z} |&#92;textbf{w}, &#92;alpha, &#92;beta) \" class=\"latex\" />, resulting in the problem:</p>\n<p style=\"text-align:center;\"><img src=\"https://s0.wp.com/latex.php?latex=%28%5Cgamma%5E%7B%2A%7D%2C+%5Cphi%5E%7B%2A%7D%29+%3D+argmin_%7B%5Cgamma%2C+%5Cphi%7D+D_%7BKL%7D%28q%28%5Ctheta%2C+z%7C%5Cgamma%2C+%5Cphi%29%7C%7Cp%28%5Ctheta%2C+z%7Cw%2C+%5Calpha%2C+%5Cbeta%29%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%28%5Cgamma%5E%7B%2A%7D%2C+%5Cphi%5E%7B%2A%7D%29+%3D+argmin_%7B%5Cgamma%2C+%5Cphi%7D+D_%7BKL%7D%28q%28%5Ctheta%2C+z%7C%5Cgamma%2C+%5Cphi%29%7C%7Cp%28%5Ctheta%2C+z%7Cw%2C+%5Calpha%2C+%5Cbeta%29%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28%5Cgamma%5E%7B%2A%7D%2C+%5Cphi%5E%7B%2A%7D%29+%3D+argmin_%7B%5Cgamma%2C+%5Cphi%7D+D_%7BKL%7D%28q%28%5Ctheta%2C+z%7C%5Cgamma%2C+%5Cphi%29%7C%7Cp%28%5Ctheta%2C+z%7Cw%2C+%5Calpha%2C+%5Cbeta%29%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"(&#92;gamma^{*}, &#92;phi^{*}) = argmin_{&#92;gamma, &#92;phi} D_{KL}(q(&#92;theta, z|&#92;gamma, &#92;phi)||p(&#92;theta, z|w, &#92;alpha, &#92;beta))\" class=\"latex\" /></p>\n<p style=\"text-align:left;\">Since we also do not know <img src=\"https://s0.wp.com/latex.php?latex=%5Cbeta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Cbeta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;beta\" class=\"latex\" /> and <img src=\"https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;alpha\" class=\"latex\" />, we use <a href=\"http://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm\">Expectation Maximization</a> (EM) to alternate between estimating <img src=\"https://s0.wp.com/latex.php?latex=%5Cbeta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Cbeta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;beta\" class=\"latex\" /> and <img src=\"https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;alpha\" class=\"latex\" /> using our current estimates of <img src=\"https://s0.wp.com/latex.php?latex=%5Cgamma&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Cgamma&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cgamma&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;gamma\" class=\"latex\" /> and <img src=\"https://s0.wp.com/latex.php?latex=%5Cphi&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Cphi&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;phi\" class=\"latex\" />, and estimating <img src=\"https://s0.wp.com/latex.php?latex=%5Cgamma&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Cgamma&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cgamma&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;gamma\" class=\"latex\" /> and <img src=\"https://s0.wp.com/latex.php?latex=%5Cphi&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Cphi&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;phi\" class=\"latex\" /> using our current estimates of <img src=\"https://s0.wp.com/latex.php?latex=%5Cbeta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Cbeta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;beta\" class=\"latex\" /> and <img src=\"https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;alpha\" class=\"latex\" />.</p>\n<p style=\"text-align:left;\">More specifically, in the E-step, we solve for <img src=\"https://s0.wp.com/latex.php?latex=%28%5Cgamma%5E%7B%2A%7D%2C+%5Cphi%5E%7B%2A%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%28%5Cgamma%5E%7B%2A%7D%2C+%5Cphi%5E%7B%2A%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28%5Cgamma%5E%7B%2A%7D%2C+%5Cphi%5E%7B%2A%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"(&#92;gamma^{*}, &#92;phi^{*})\" class=\"latex\" />, and in the M-step, we perform the updates:</p>\n<p style=\"text-align:center;\"><img src=\"https://s0.wp.com/latex.php?latex=%5Cbeta_%7Bij%7D+%5Cpropto%5Csum_%7Bd%3D1%7D%5E%7BM%7D%5Csum_%7Bn%3D1%7D%5E%7BN_%7Bd%7D%7D%5Cphi%5E%7B%2A%7D_%7Bdni%7Dw%5E%7Bj%7D_%7Bdn%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Cbeta_%7Bij%7D+%5Cpropto%5Csum_%7Bd%3D1%7D%5E%7BM%7D%5Csum_%7Bn%3D1%7D%5E%7BN_%7Bd%7D%7D%5Cphi%5E%7B%2A%7D_%7Bdni%7Dw%5E%7Bj%7D_%7Bdn%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta_%7Bij%7D+%5Cpropto%5Csum_%7Bd%3D1%7D%5E%7BM%7D%5Csum_%7Bn%3D1%7D%5E%7BN_%7Bd%7D%7D%5Cphi%5E%7B%2A%7D_%7Bdni%7Dw%5E%7Bj%7D_%7Bdn%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;beta_{ij} &#92;propto&#92;sum_{d=1}^{M}&#92;sum_{n=1}^{N_{d}}&#92;phi^{*}_{dni}w^{j}_{dn}\" class=\"latex\" /></p>\n<p style=\"text-align:left;\">and</p>\n<p style=\"text-align:center;\"><img src=\"https://s0.wp.com/latex.php?latex=log%28%5Calpha%5E%7Bt%2B1%7D%29+%3D+log%28%5Calpha%5E%7Bt%7D%29+-+%5Cfrac%7B%5Cfrac%7BdL%7D%7Bd%5Calpha%7D%7D%7B%5Cfrac%7Bd%5E%7B2%7DL%7D%7Bd%5Calpha%5E%7B2%7D%5Calpha%7D%2B%5Cfrac%7BdL%7D%7Bd%5Calpha%7D%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=log%28%5Calpha%5E%7Bt%2B1%7D%29+%3D+log%28%5Calpha%5E%7Bt%7D%29+-+%5Cfrac%7B%5Cfrac%7BdL%7D%7Bd%5Calpha%7D%7D%7B%5Cfrac%7Bd%5E%7B2%7DL%7D%7Bd%5Calpha%5E%7B2%7D%5Calpha%7D%2B%5Cfrac%7BdL%7D%7Bd%5Calpha%7D%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=log%28%5Calpha%5E%7Bt%2B1%7D%29+%3D+log%28%5Calpha%5E%7Bt%7D%29+-+%5Cfrac%7B%5Cfrac%7BdL%7D%7Bd%5Calpha%7D%7D%7B%5Cfrac%7Bd%5E%7B2%7DL%7D%7Bd%5Calpha%5E%7B2%7D%5Calpha%7D%2B%5Cfrac%7BdL%7D%7Bd%5Calpha%7D%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"log(&#92;alpha^{t+1}) = log(&#92;alpha^{t}) - &#92;frac{&#92;frac{dL}{d&#92;alpha}}{&#92;frac{d^{2}L}{d&#92;alpha^{2}&#92;alpha}+&#92;frac{dL}{d&#92;alpha}}\" class=\"latex\" /></p>\n<p style=\"text-align:left;\">I&#8217;ve glossed over this part a bit, but the takeaway is that we must compute a lower bound of the actual distribution, and we use EM to do so since we have two sets of unknown parameters. And in the end, we end up with estimates of <img src=\"https://s0.wp.com/latex.php?latex=%5Ctheta%2C+%5Ctextbf%7Bz%7D%2C+%5Cbeta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Ctheta%2C+%5Ctextbf%7Bz%7D%2C+%5Cbeta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctheta%2C+%5Ctextbf%7Bz%7D%2C+%5Cbeta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;theta, &#92;textbf{z}, &#92;beta\" class=\"latex\" /> as desired.</p>\n<p style=\"text-align:left;\">For more in depth coverage, see <a href=\"http://obphio.us/pdfs/lda_tutorial.pdf\">Reed&#8217;s LDA Tutorial</a> or the <a href=\"http://jmlr.org/papers/volume3/blei03a/blei03a.pdf\">original LDA paper</a>.</p>\n<p style=\"text-align:left;\">Now, let&#8217;s move to the code.</p>\n<p style=\"text-align:center;\"><strong>The Plan</strong></p>\n<p style=\"text-align:left;\">We&#8217;ll use <a href=\"https://twitter.com/BarackObama\">@BarackObama</a> as the running example. First we&#8217;ll download @BarackObama&#8217;s tweets, which will be our corpus, with each tweet representing a &#8216;document&#8217;.</p>\n<p style=\"text-align:left;\">Then, we&#8217;ll run LDA on the corpus in order to discover 50 topics and the top 20 words associated with each topic. Next, we will infer the topic distribution over the <em>entire</em> set of tweets. Hence we&#8217;ll be able to see topics and the degree to which they appear in @BarackObama&#8217;s tweets.</p>\n<p style=\"text-align:left;\">Finally, we&#8217;ll visualize the top 20 words for a given topic based on the relative frequency of the words.</p>\n<p style=\"text-align:left;\">I&#8217;ll walk through the important parts of the code, but I&#8217;ll skip the details in the interest of brevity. For the whole picture, check out the code on <a href=\"https://github.com/wellecks/lda_tweets\">GitHub</a>; running the <em>main() </em>method of <a href=\"https://github.com/wellecks/lda_tweets/blob/master/src/lda/TopicModel.java\">TopicModel.java</a> will run the entire process and produce similar results to those shown below.</p>\n<p style=\"text-align:center;\"><strong>Getting the Tweets</strong></p>\n<p style=\"text-align:left;\">To retrieve the tweets, we&#8217;ll rely on the <a title=\"Twitter4J\" href=\"http://twitter4j.org/en/\">Twitter4J</a> library, an unofficial Java library for the Java API. The code found in <a href=\"https://github.com/wellecks/lda_tweets/blob/master/src/lda/TwitterClient.java\">TwitterClient.java</a> is a wrapper that helps out with the things we need. The method that does the &#8216;work&#8217; is</p>\n<pre class=\"p1\"><span class=\"s1\">public</span> List<String> getUserTweetsText(String <span class=\"s2\">username</span>, <span class=\"s1\">int</span> <span class=\"s2\">n</span>)</pre>\n<p class=\"p1\">which retrieves the last <em>n</em> of a user&#8217;s tweets and returns them as a List of Strings. In this method we access 1 page (200 tweets) at a time, so the main loop has <em>n/200</em> iterations.</p>\n<p class=\"p1\"><span class=\"s1\">The highest-level method is</span></p>\n<pre class=\"p1\"><span class=\"s1\">public</span> <span class=\"s1\">void</span> downloadTweetsFromUser(String <span class=\"s2\">username</span>, <span class=\"s1\">int</span> <span class=\"s2\">numTweets</span>)</pre>\n<p class=\"p1\">which calls <em>getUserTweetsText()</em> and saves the output to files. For organization&#8217;s sake, it saves the user&#8217;s tweets to</p>\n<ul>\n<li class=\"p1\"><em>./data/{username}/{username}_tweets.txt</em>, which contains one tweet per line</li>\n<li class=\"p1\"><em>./data/{username}/{username}_tweets_single.txt</em>, which contains all of the tweets on a single line. This second file will be used later to infer the topic distribution over the user&#8217;s <em>entire</em> set of tweets.</li>\n</ul>\n<p class=\"p1\">Hence we can download 3000 of @BarackObama&#8217;s tweets like so:</p>\n<pre class=\"p1\">TwitterClient <span class=\"s1\">tc</span> = <span class=\"s2\">new</span> TwitterClient();\n<span class=\"s1\">tc</span>.downloadTweetsFromUser(<span class=\"s3\">\"BarackObama\"</span>, 3000);</pre>\n<p class=\"p1\" style=\"text-align:center;\"><strong>Hammering Out Some Topics</strong></p>\n<p class=\"p1\">Now it&#8217;s time to take a <a title=\"MALLET\" href=\"http://mallet.cs.umass.edu/\">Mallet</a> to the tweets in order to mine some topics. Mallet is a powerful library for text-based machine learning; we can use its topic modeling through its <a href=\"http://mallet.cs.umass.edu/api/\">Java API</a> to load and clean the tweet data, train an LDA model, and output results. In order to use the Mallet API, you&#8217;ll have to follow the <a href=\"http://mallet.cs.umass.edu/download.php\">download instructions</a> and build a jar file, or get it from this post&#8217;s <a href=\"https://github.com/wellecks/lda_tweets\">GitHub</a> repo.</p>\n<p class=\"p1\">The Mallet-related code that I&#8217;ll discuss next is found in <a href=\"https://github.com/wellecks/lda_tweets/blob/master/src/lda/TopicModel.java\">TopicModel.java</a>.</p>\n<p class=\"p1\" style=\"text-align:center;\"><strong>Loading the Data</strong></p>\n<p class=\"p1\">The first step is to prepare and load the data. Our goal is to get the data in the <em>{username}_tweets.txt</em> file into an <a href=\"http://mallet.cs.umass.edu/api/cc/mallet/types/InstanceList.html\"><em>InstanceList</em></a> object, i.e. a form that can be used by Mallet models.</p>\n<p class=\"p1\">To do so, we first create a series of &#8220;<em><a href=\"http://mallet.cs.umass.edu/api/cc/mallet/pipe/Pipe.html\">Pipe</a></em>s&#8221; to feed the data through. The idea is that each <em><a href=\"http://mallet.cs.umass.edu/api/cc/mallet/pipe/Pipe.html\">Pipe</a></em> performs some transformation of the data and feeds it to the next <em>Pipe</em>. In our case, in</p>\n<pre class=\"p1\"><span class=\"s1\">static</span> ArrayList<Pipe> makePipeList()</pre>\n<p class=\"p1\">we create a series of <em>Pipe</em>s that will lowercase and tokenize the tweets, remove stop words, and convert the tweets to a sequence of features.</p>\n<p class=\"p1\">Then, in</p>\n<pre class=\"p1\"><span class=\"s1\">static</span> InstanceList fileToInstanceList(String <span class=\"s2\">filename</span>)</pre>\n<p class=\"p1\">we iterate through the input file, and use our <em>Pipe</em> list to modify and prepare the data, returning the <em>InstanceList</em> that we set out to build.</p>\n<p class=\"p1\" style=\"text-align:center;\"> <strong>Training Time</strong></p>\n<p class=\"p1\">It&#8217;s training time. Using</p>\n<pre class=\"p1\"><span class=\"s1\">public</span> <span class=\"s1\">static</span> ParallelTopicModel trainModel(InstanceList <span class=\"s2\">instances</span>,\n<span class=\"s1\">                                      int</span> <span class=\"s2\">numTopics</span>, <span class=\"s1\">int</span> <span class=\"s2\">numIters</span>,\n<span class=\"s1\">                                      double</span> <span class=\"s2\">alphaT</span>, <span class=\"s1\">double</span> <span class=\"s2\">betaW</span>)</pre>\n<p style=\"text-align:left;\">we train an LDA model called <em>ParallelTopicModel</em> on the <em>InstanceList</em> data. The <em>betaW</em> parameter is a uniform prior for <img src=\"https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;beta \" class=\"latex\" />, and the <em>alphaT</em> parameter is the sum of the <img src=\"https://s0.wp.com/latex.php?latex=%5Calpha+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Calpha+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;alpha \" class=\"latex\" /> parameter; recall from the math section that <img src=\"https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;beta \" class=\"latex\" /> is the <img src=\"https://s0.wp.com/latex.php?latex=numtopics+%5Ctimes+vocabsize+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=numtopics+%5Ctimes+vocabsize+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=numtopics+%5Ctimes+vocabsize+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"numtopics &#92;times vocabsize \" class=\"latex\" /> matrix that gives word probabilities given a topic, and <img src=\"https://s0.wp.com/latex.php?latex=%5Calpha+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Calpha+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;alpha \" class=\"latex\" /> is the parameter for the distribution over topics.</p>\n<p style=\"text-align:center;\"><strong>Looking at the Output, Part I</strong></p>\n<p style=\"text-align:left;\">With a trained model, we can now look at the words that make up the topics using <img src=\"https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;beta \" class=\"latex\" />, and the composition <img src=\"https://s0.wp.com/latex.php?latex=%5Ctheta_i+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Ctheta_i+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctheta_i+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;theta_i \" class=\"latex\" /> for <img src=\"https://s0.wp.com/latex.php?latex=tweet_i+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=tweet_i+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=tweet_i+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"tweet_i \" class=\"latex\" />.</p>\n<p style=\"text-align:left;\">Printed to stdout, we see the 50 topics, with the top 20 words for each topic. The number attached to each word is the number of occurrences:</p>\n<pre class=\"p1\"><strong>Topic 0</strong> \nfamilies:13 republican:11 read:7 fast:5 ed:5 op:5 family:5 marine:4 democrat:4 efforts:4 policies:4 story:4 pendleton:3 camp:3 explains:3 military:3 #cir:3 california:3 #familiessucceed:3 workplace:3</pre>\n<pre class=\"p1\"><strong>Topic 1</strong> \npresident:175 obama:165 middle:61 class:59 jobs:47 #abetterbargain:37 economy:37 good:32 growing:20 #opportunityforall:20 isn:19 #rebuildamerica:18 today:18 create:17 watch:17 infrastructure:16 americans:16 plan:15 live:15 american:15</pre>\n<p class=\"p1\">&#8230;</p>\n<pre class=\"p1\"><strong>Topic 48</strong> \npresident:72 address:62 obama:57 watch:56 weekly:49 opportunity:15 economic:15 discusses:14 issue:11 importance:10 working:10 week:10 speak:9 budget:8 discuss:8 congress:7 calls:6 building:6 #opportunityforall:6 lady:5</pre>\n<pre class=\"p1\"><strong>Topic 49</strong> \ndiscrimination:19 lgbt:17 rights:15 #enda:15 americans:14 law:10 act:10 today:10 thedreamisnow:7 screening:7 voting:7 protections:7 basic:7 stand:7 add:7 american:7 anniversary:6 workplace:6 workers:6 support:6</pre>\n<p style=\"text-align:left;\">Each box corresponds to taking a row of <img src=\"https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;beta \" class=\"latex\" />, finding the indices with the 20 highest probabilities, and choosing the words that correspond to these indices.</p>\n<p style=\"text-align:left;\">Since each tweet is a document, the model also contains the topic distribution for each tweet. However, our goal is to get a sense of the <em>overall topic </em><em>distribution</em> for <em>all</em> of the user&#8217;s tweets, which will require an additional step. In other words, we&#8217;d like to see a summary of the major topics that the user tends to tweet about.</p>\n<p style=\"text-align:center;\"><strong>Getting An Overall Picture</strong></p>\n<p style=\"text-align:left;\">To do so, we will use our trained model to <em>infer</em> the distribution over <em>all</em> of the user&#8217;s tweets. We create a single <a href=\"http://mallet.cs.umass.edu/api/cc/mallet/types/Instance.html\">Instance</a> containing all of the tweets using</p>\n<pre style=\"text-align:left;\"><em>singleLineFile = {username}_tweets_single.txt</em></pre>\n<p style=\"text-align:left;\">and find the topic distribution:</p>\n<pre class=\"p1\"><span class=\"s1\">double</span>[] <span class=\"s2\">dist</span> = inferTopicDistribution(<span class=\"s2\">model</span>, \n                    TopicModel.fileToInstanceList(<span class=\"s2\">singleLineFile</span>));</pre>\n<p style=\"text-align:left;\">We can then look at the distribution in  ./data/{username}/<em>{username}_composition.txt:</em></p>\n<pre class=\"p1\"><strong>0</strong> 0.006840685214902167\n<strong>1</strong> 0.048881207831654686\n...\n<strong>29</strong> 0.09993216645340489\n...\n<strong>48</strong> 0.022192334924649955\n<strong>49</strong> 0.01473112438501846</pre>\n<p class=\"p1\">We see, for instance, that topic 29 is more prominent than topic 0; specifically, the model inferred that more words were generated by topic 29 than topic 0.</p>\n<p class=\"p1\">In <em>./data/{username}/{username}_ranked.txt</em> we have the top 10 topics, ranked by composition, along with each topic&#8217;s top words. For instance, at the top of the file is:</p>\n<pre class=\"p1\" style=\"text-align:center;\"><strong>Topic 29</strong>:\nobama:474\npresident:474\namerica:77\n...\naction:23\nmaking:21\njob:21</pre>\n<p class=\"p1\" style=\"text-align:left;\">This topic could probably be labeled as &#8220;presidential&#8221;; a topic we&#8217;d expect to find near the top for @BarackObama.</p>\n<p class=\"p1\" style=\"text-align:left;\">Looking on, we see a topic that is clearly about healthcare:</p>\n<pre class=\"p1\" style=\"text-align:center;\"><strong>Topic 24\n</strong>health:103\ninsurance:94\namericans:56\n#obamacare:55\n...\nuninsured:21\ncovered:21</pre>\n<p class=\"p1\" style=\"text-align:left;\">and one about climate change:</p>\n<pre class=\"p1\" style=\"text-align:center;\"><strong>Topic 28\n</strong>change:125\nclimate:90\n#actonclimate:59\n#climate:39\n...\ntime:19\n#sciencesaysso:14\nact:14\ncall:13\nscience:13</pre>\n<p style=\"text-align:left;\">The inferred topics are pretty amazing; a job well done by LDA. But while viewing words and their frequencies may be fun, let&#8217;s visualize a topic in a nicer way.</p>\n<p style=\"text-align:center;\"><strong>Into the Clouds</strong></p>\n<p style=\"text-align:left;\">We now have the words that make up the most prominent topics, along with the frequency of each word. A natural visualization for a topic is a <a href=\"http://en.wikipedia.org/wiki/Tag_cloud\">word cloud</a>, which allows us to easily see the words and their relative weights.</p>\n<p style=\"text-align:left;\">It turns out that a word-cloud generator named Wordle <a title=\"Wordle Advanced\" href=\"http://www.wordle.net/advanced\">can create word clouds given a list of weighted words</a>&#8230;exactly the format found in ./data/{username}/{username}_ranked.txt !</p>\n<p style=\"text-align:left;\">Let&#8217;s copy the <em>word:frequency</em> list for Topic 29 and throw it into Wordle (dialing down <em>obama</em> and <em>president</em> to 200):</p>\n<p style=\"text-align:center;\"><a href=\"https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-48-pm.png\"><img loading=\"lazy\" data-attachment-id=\"820\" data-permalink=\"https://wellecks.wordpress.com/2014/09/03/these-are-your-tweets-on-lda-part-i/screen-shot-2014-09-03-at-8-48-48-pm/#main\" data-orig-file=\"https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-48-pm.png\" data-orig-size=\"1250,686\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-48-pm.png?w=300\" data-large-file=\"https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-48-pm.png?w=525\" class=\"aligncenter size-large wp-image-820\" src=\"https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-48-pm.png?w=525&#038;h=288\" alt=\"\" width=\"525\" height=\"288\" srcset=\"https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-48-pm.png?w=525&h=288 525w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-48-pm.png?w=1050&h=576 1050w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-48-pm.png?w=150&h=82 150w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-48-pm.png?w=300&h=165 300w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-48-pm.png?w=768&h=421 768w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-48-pm.png?w=1024&h=562 1024w\" sizes=\"(max-width: 525px) 100vw, 525px\" /></a></p>\n<p style=\"text-align:left;\">and the results:</p>\n<div data-shortcode=\"caption\" id=\"attachment_817\" style=\"width: 535px\" class=\"wp-caption alignleft\"><a href=\"https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-46-24-pm.png\"><img loading=\"lazy\" aria-describedby=\"caption-attachment-817\" data-attachment-id=\"817\" data-permalink=\"https://wellecks.wordpress.com/2014/09/03/these-are-your-tweets-on-lda-part-i/screen-shot-2014-09-03-at-8-46-24-pm/#main\" data-orig-file=\"https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-46-24-pm.png\" data-orig-size=\"1628,1086\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-46-24-pm.png?w=300\" data-large-file=\"https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-46-24-pm.png?w=525\" class=\"wp-image-817 size-large\" src=\"https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-46-24-pm.png?w=525&#038;h=350\" alt=\"\" width=\"525\" height=\"350\" srcset=\"https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-46-24-pm.png?w=525&h=350 525w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-46-24-pm.png?w=1050&h=700 1050w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-46-24-pm.png?w=150&h=100 150w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-46-24-pm.png?w=300&h=200 300w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-46-24-pm.png?w=768&h=512 768w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-46-24-pm.png?w=1024&h=683 1024w\" sizes=\"(max-width: 525px) 100vw, 525px\" /></a><p id=\"caption-attachment-817\" class=\"wp-caption-text\">Topic 29 &#8211; &#8220;Presidential&#8221;</p></div>\n<div data-shortcode=\"caption\" id=\"attachment_818\" style=\"width: 535px\" class=\"wp-caption aligncenter\"><a href=\"https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-14-pm.png\"><img loading=\"lazy\" aria-describedby=\"caption-attachment-818\" data-attachment-id=\"818\" data-permalink=\"https://wellecks.wordpress.com/2014/09/03/these-are-your-tweets-on-lda-part-i/screen-shot-2014-09-03-at-8-47-20-pm/#main\" data-orig-file=\"https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-47-20-pm.png\" data-orig-size=\"1604,1078\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-47-20-pm.png?w=300\" data-large-file=\"https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-47-20-pm.png?w=525\" class=\"wp-image-818 size-large\" src=\"https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-47-20-pm.png?w=525&#038;h=352\" alt=\"\" width=\"525\" height=\"352\" srcset=\"https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-47-20-pm.png?w=525&h=352 525w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-47-20-pm.png?w=1048&h=704 1048w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-47-20-pm.png?w=150&h=101 150w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-47-20-pm.png?w=300&h=202 300w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-47-20-pm.png?w=768&h=516 768w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-47-20-pm.png?w=1024&h=688 1024w\" sizes=\"(max-width: 525px) 100vw, 525px\" /></a><p id=\"caption-attachment-818\" class=\"wp-caption-text\">Topic 24 &#8211; &#8220;Healthcare&#8221;</p></div>\n<div data-shortcode=\"caption\" id=\"attachment_819\" style=\"width: 535px\" class=\"wp-caption aligncenter\"><a href=\"https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-14-pm.png\"><img loading=\"lazy\" aria-describedby=\"caption-attachment-819\" data-attachment-id=\"819\" data-permalink=\"https://wellecks.wordpress.com/2014/09/03/these-are-your-tweets-on-lda-part-i/screen-shot-2014-09-03-at-8-48-14-pm/#main\" data-orig-file=\"https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-14-pm.png\" data-orig-size=\"1534,1084\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-14-pm.png?w=300\" data-large-file=\"https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-14-pm.png?w=525\" class=\"wp-image-819 size-large\" src=\"https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-14-pm.png?w=525&#038;h=370\" alt=\"\" width=\"525\" height=\"370\" srcset=\"https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-14-pm.png?w=525&h=370 525w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-14-pm.png?w=1047&h=740 1047w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-14-pm.png?w=150&h=106 150w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-14-pm.png?w=300&h=212 300w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-14-pm.png?w=768&h=543 768w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-14-pm.png?w=1024&h=724 1024w\" sizes=\"(max-width: 525px) 100vw, 525px\" /></a><p id=\"caption-attachment-819\" class=\"wp-caption-text\">Topic 28 &#8211; &#8220;Climate Change&#8221;</p></div>\n<p style=\"text-align:center;\"><strong>A Brief Pause</strong></p>\n<p style=\"text-align:left;\">Let&#8217;s pause for a second. This is a nice moment and a beautiful result.</p>\n<p style=\"text-align:left;\">Take a look at the words : LDA inferred a relationship between &#8220;country&#8221;, &#8220;america&#8221;, and &#8220;obama&#8221;. It grouped &#8220;insurance&#8221;, &#8220;#obamacare&#8221;, and &#8220;health&#8221;. It discovered a link between &#8220;climate&#8221;, &#8220;deniers&#8221;, and &#8220;#sciencesaysso&#8221;.</p>\n<p style=\"text-align:left;\">Glance back up at the math section. We never told it about presidents, countries, or healthcare. Nowhere in there is there a hard-coded link between climate words and science hash tags. In fact, it didn&#8217;t even know it would be dealing with words or tweets.</p>\n<p style=\"text-align:left;\">It&#8217;s &#8216;just&#8217; an optimization problem, but when applied it can discover complex relationships that have real meaning. This is an aspect that I personally find fascinating about LDA and, more generally, about machine learning.</p>\n<p style=\"text-align:left;\">As a next step, feel free to download the code and try out other usernames to get a sense of LDA&#8217;s generality; its not just limited to @BarackObama, climate, or healthcare.</p>\n<p style=\"text-align:center;\"><b>Next Steps: From One to Many<br />\n</b></p>\n<p style=\"text-align:left;\">Currently, we have a nice way of viewing the content of one topic, in isolation. In the next post, we&#8217;ll develop a visualization using <a title=\"d3.js\" href=\"http://d3js.org/\">d3.js</a> for <em>all</em> of the top topics at once. We&#8217;ll be able to see and compare topics side by side, and obtain a higher level view of the overall topic distribution. As a sneak preview, here&#8217;s a visualization of the top 10 topics from <a title=\"@nytimes\" href=\"https://twitter.com/nytimes\">@nytimes</a>:</p>\n<p><a href=\"https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-7-34-09-pm1.png\"><img loading=\"lazy\" data-attachment-id=\"824\" data-permalink=\"https://wellecks.wordpress.com/2014/09/03/these-are-your-tweets-on-lda-part-i/screen-shot-2014-09-03-at-7-34-09-pm-2/#main\" data-orig-file=\"https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-7-34-09-pm1.png\" data-orig-size=\"1862,1544\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"@nytimes top 10\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-7-34-09-pm1.png?w=300\" data-large-file=\"https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-7-34-09-pm1.png?w=525\" class=\"aligncenter size-large wp-image-824\" src=\"https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-7-34-09-pm1.png?w=525&#038;h=435\" alt=\"@nytimes top 10\" width=\"525\" height=\"435\" srcset=\"https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-7-34-09-pm1.png?w=525&h=435 525w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-7-34-09-pm1.png?w=1050&h=870 1050w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-7-34-09-pm1.png?w=150&h=124 150w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-7-34-09-pm1.png?w=300&h=249 300w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-7-34-09-pm1.png?w=768&h=637 768w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-7-34-09-pm1.png?w=1024&h=849 1024w\" sizes=\"(max-width: 525px) 100vw, 525px\" /></a></p>\n<p style=\"text-align:center;\"><strong>Credits and Links</strong></p>\n<p style=\"text-align:left;\">Much of the mathematical content is derived from <a href=\"http://obphio.us/pdfs/lda_tutorial.pdf\">Reed&#8217;s Tutorial</a> and the<a href=\"http://machinelearning.wustl.edu/mlpapers/paper_files/BleiNJ03.pdf\"> LDA Paper</a> (or the <a href=\"http://ai.stanford.edu/~ang/papers/nips01-lda.pdf\">shorter version</a>). These are also great resources for learning more. Edwin Chen&#8217;s <a href=\"http://blog.echen.me/2011/08/22/introduction-to-latent-dirichlet-allocation/\">blog post</a> also provides a good introduction and an intuition-building example. The Mallet <a href=\"http://mallet.cs.umass.edu/topics-devel.php\">developer&#8217;s guide</a> and data <a href=\"http://mallet.cs.umass.edu/import.php\">importing guide</a> provide good examples of using the Mallet API. The Programming Historian has a <a href=\"http://programminghistorian.org/lessons/topic-modeling-and-mallet\">great intro</a> to using Mallet for LDA from the command line.</p>\n",
  "wfw:commentRss": "https://wellecks.wordpress.com/2014/09/03/these-are-your-tweets-on-lda-part-i/feed/",
  "slash:comments": 1,
  "media:content": [
    {
      "media:title": "wellecks"
    },
    {
      "media:title": "Screen Shot 2014-08-30 at 10.04.54 PM"
    },
    "",
    "",
    "",
    "",
    {
      "media:title": "@nytimes top 10"
    }
  ]
}