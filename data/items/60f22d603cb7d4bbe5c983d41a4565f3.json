{
  "id": "tag:blogger.com,1999:blog-15418143.post-3339709172492766899",
  "published": "2015-06-26T21:45:00.000-05:00",
  "updated": "2016-06-14T04:58:40.614-05:00",
  "category": [
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    ""
  ],
  "title": "Deep down the rabbit hole: CVPR 2015 and beyond",
  "content": "<div class=\"p1\">CVPR is the premier Computer Vision conference, and it's fair to think of it as <b>the Olympics of Computer Vision Research.</b> This year it was held in my own back yard -- less than a mile away from lovely Cambridge, MA! &nbsp;Plenty of my MIT colleagues attended, but I wouldn't be surprised if <a href=\"http://googleresearch.blogspot.com/2015/06/google-computer-vision-research-at-cvpr.html\">Google</a> had the largest showing at CVPR 2015. I have been going to CVPR almost every year since 2004, so let's take a brief tour at what's new in the exciting world of computer vision research.<br /><div class=\"separator\" style=\"clear: both; text-align: center;\"><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://1.bp.blogspot.com/-7MdQJ4NJlyo/V1rAnoDGOPI/AAAAAAAAOsk/IgVsXeuTMywDMrrrsvnTPSSa-Pq6yIjAgCLcB/s1600/rabbit_hole.png\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" height=\"278\" src=\"https://1.bp.blogspot.com/-7MdQJ4NJlyo/V1rAnoDGOPI/AAAAAAAAOsk/IgVsXeuTMywDMrrrsvnTPSSa-Pq6yIjAgCLcB/s400/rabbit_hole.png\" width=\"400\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://frostyshadows.deviantart.com/art/Down-the-Rabbit-Hole-358090601\">Down the rabbit hole art by frostyshadows</a></div><br /><br />A lot has changed. Nothing has changed. Academics used to be on top, defending their Universities and the awesomeness happening inside their non-industrial research labs. Academics are still on top, but now defending their Google, Facebook, Amazon, and Company X affiliations. And with the hiring budget to acquire the best and a heavy publishing-oriented culture, don't be surprised if the massive academia exodus continues for years to come. It's only been two weeks since CVPR, and Google has since then been busy making <a href=\"http://googleresearch.blogspot.be/2015/06/inceptionism-going-deeper-into-neural.html\">ConvNet art</a>, showing the world that if you want to do the best Deep Learning research, they are King.<br /><br />An army of PhD students and Postdocs simply cannot defeat an army of Software Engineers and Research Scientists. Back in the day, students used to typically depart after a Computer Vision PhD (there used to be few vision research jobs and Wall Street jobs were tempting). Now the former PhD students run research labs at big companies which have been feverishly getting into vision. It seems there aren't enough deep experts to fill the deep demand.<br /><br />Datasets used to be the big thing -- please download my data!&nbsp; Datasets are still the big thing -- but we regret to inform you that your university’s computational resources won’t make the cut (but at Company X we’re always hiring, so come join us, and help push the frontier of research together).<br /><br /><b>Related Article:</b> <a href=\"https://research.facebook.com/ai\">Under LeCun's Leadership, Facebook's AI Research Lab is beefing up their research presence</a></div><div class=\"p2\"><span class=\"s1\"></span></div><div class=\"p2\"><span class=\"s1\"></span><br />If you want to check out the individual papers, I recommend Andrej Karpathy's&nbsp;<a href=\"http://cs.stanford.edu/people/karpathy/cvpr2015papers/\">online navigation tool for CVPR 2015 papers</a>&nbsp;or take a look at the vanilla listing of <a href=\"http://www.cv-foundation.org/openaccess/CVPR2015.py\">CVPR 2015 papers on the CV foundation website</a>.&nbsp;<a href=\"http://web.mit.edu/zoya/www/\">Zoya Bylinskii,</a> an MIT PhD Candidate, also put together <a href=\"http://zoyathinks.blogspot.com/2015/06/cvpr-recap-and-where-were-going.html\">a list of interesting CVPR 2015 papers</a>.<br /><br /></div><div class=\"p1\"><h3><b>The ConvNet Revolution: There's a pre-trained network for that</b></h3><span class=\"s1\">Machine Learning used to be the Queen. Machine Learning is now the King. Machine Learning used to be shallow, but today's learning approaches are <b>so deep that the diagrams barely fit on a single slide</b>. Grad students used to pass around jokes about Yann LeCun and his insistence that machine learning will one day do the work of the feature engineering stage. Now it seems that the entire vision community gets to ignore you when you insist that “manual feature engineering” is going to save the day. <a href=\"http://yann.lecun.com/\">Yann LeCun</a> gave a keynote presentation with the intriguing title \"<a href=\"https://drive.google.com/file/d/0BxKBnD5y2M8NVHRiVXBnOVpiYUk/view\">What's wrong with Deep Learning</a>\" and it seems that Convolutional Neural Networks (also called CNNs or ConvNets) are everywhere at CVPR.</span><br /><span class=\"s1\"><br /></span><br /><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://3.bp.blogspot.com/-M5JZccnj1Ec/VY3zTmGV8YI/AAAAAAAAOP4/q0c-QCtmi2o/s1600/convnet.jpeg\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" height=\"191\" src=\"https://3.bp.blogspot.com/-M5JZccnj1Ec/VY3zTmGV8YI/AAAAAAAAOP4/q0c-QCtmi2o/s400/convnet.jpeg\" width=\"400\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://cs231n.github.io/convolutional-networks/\">Figure from Karpathy's Convolutional Neural Network tutorial</a></div><span class=\"s1\"><br /></span><span class=\"s1\"><br /></span><span class=\"s1\">It used to be hard to publish ConvNet research papers at CVPR, it's now hard to get a CVPR paper if you didn't at least compare against a ConvNet baseline.&nbsp;</span><b>Got a new cool problem? Oooh, you didn’t try a ConvNet-based baseline? Well, that explains why nobody cares.</b><br /><span class=\"s1\"><br /></span><span class=\"s1\">But it's not like the machines are taking over the job of the vision scientist. Today's vision scientist is much more of an applied machine learning hacker than anything else, and because of the strong CNN theme, it is much easier to understand and re-implement today's vision systems. What we're seeing at CVPR is essentially a revisiting of the classic problems like segmentation and motion, using this new machinery. As <a href=\"http://people.csail.mit.edu/samson/\">Samson Timoner</a> phrased it at the local <a href=\"http://www.meetup.com/bostonimagevision/\">Boston Vision Meetup</a>, when <a href=\"https://en.wikipedia.org/wiki/Mutual_information\">Mutual Information</a> was popular, the community jumped on that bandwagon -- it's ConvNets this time around. But it's not just a trend, the non-CNN competition is getting crushed.</span><br /><span class=\"s1\"><br /></span><br /><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://3.bp.blogspot.com/-PMO1RTHdFc0/VY30k5m5PnI/AAAAAAAAOQE/IVxRFXbVSzg/s1600/hypercolumns.png\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" height=\"210\" src=\"https://3.bp.blogspot.com/-PMO1RTHdFc0/VY30k5m5PnI/AAAAAAAAOQE/IVxRFXbVSzg/s320/hypercolumns.png\" width=\"320\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\">Figure from <a href=\"http://www.cs.berkeley.edu/~bharath2/\">Bharath Hariharan</a>'s&nbsp;<a href=\"http://www.cs.berkeley.edu/~bharath2/pubs/pdfs/BharathCVPR2015.pdf\">Hypercolumns</a>&nbsp;CVPR 2015 paper on segmentation using CNNs</div><span class=\"s1\"><br /></span><span class=\"s1\"><br /></span><span class=\"s1\">There's still plenty to be done by a vision scientist, and a solid formal education in mathematics is more important than ever. We used to train via gradient descent. We still train via gradient descent. We used to drink Coffee, now we all drink Caffe. But behind the scenes, it is still mathematics.</span><br /><br /><b>Related Page:</b> <a href=\"https://github.com/BVLC/caffe/wiki/Model-Zoo\">Caffe Model Zoo where you can download lots of pretrained ConvNets</a><br /><br /><h3>Deep down the rabbit hole</h3><br /></div><div class=\"p2\"><span class=\"s1\"></span></div><div class=\"p2\"><span class=\"s1\"></span></div><div class=\"p1\"><span class=\"s1\">CVPR 2015 reminds of the pre-Newtonian days of physics. A lot of smart scientists were able to predict the motions of objects using mathematics once the ingenious <a href=\"https://en.wikipedia.org/wiki/Ren%C3%A9_Descartes\">Descartes</a> taught us how to embed our physical thinking into a coordinate system. And it's pretty clear that by casting your computer vision problem in the language of ConvNets, you are going to beat just about anybody doing computer vision by hand. <b>I think of <a href=\"http://yann.lecun.com/\">Yann LeCun</a> (one of the fathers of Deep Learning) as a modern day Descartes, </b>only because I think the ground-breaking work is right around the corner. His mental framework of ConvNets is like a much needed coordinate system -- we might not know what the destination looks like, but we now know how to build a map.</span><br /><span class=\"s1\"><br /></span><span class=\"s1\">Deep Networks are performing better every month, but I’m still waiting for Isaac to come in and make our lives even easier. I want a simplification. But I'm not being pessimistic -- there is a flurry of activity in the ConvNet space for a very good reason (in case you didn't get to attend CVPR 2015), so I'll just be blunt:&nbsp;<b>ConvNets fuckin' work</b>! I just want the F=ma of deep learning.</span></div><div class=\"p1\"><span class=\"s1\"><br /></span></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://1.bp.blogspot.com/-Lu7umrplafc/VYsIdA-y9EI/AAAAAAAAOOU/S-a6qd0ruMU/s1600/yann_descartes-01.png\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" height=\"166\" src=\"https://1.bp.blogspot.com/-Lu7umrplafc/VYsIdA-y9EI/AAAAAAAAOOU/S-a6qd0ruMU/s400/yann_descartes-01.png\" width=\"400\" /></a></div><div class=\"p1\"><br /></div><h3>Open Source Deep Learning for Computer Vision: Torch vs Caffe</h3><div class=\"p1\">CVPR 2015 started off with some excellent software tutorials on day one. &nbsp;There is some great non-alpha deep learning software out there and it has been making everybody's life easier. &nbsp;At CVPR, we had both a&nbsp;<a href=\"http://torch.ch/docs/cvpr15.html\">Torch tutorial</a> and a Caffe tutorial. &nbsp;I attended the <a href=\"http://tutorial.caffe.berkeleyvision.org/\">DIY Deep Learning Caffe tutorial</a> and it was a full house -- standing room only for slackers like me who join the party only 5 minutes before it starts. Caffe is much more popular that Torch, but when talking to some power users of Deep Learning (like <a class=\"g-profile\" href=\"https://plus.google.com/100209651993563042175\" target=\"_blank\">+Andrej Karpathy</a>&nbsp;and other DeepMind scientists), a certain group of experts seems to be migrating from Caffe to Torch.<br /><br /><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://3.bp.blogspot.com/-YIql8zIlTNc/VY3y8q-pmPI/AAAAAAAAOPw/HS78ACtebo4/s1600/torch_vs_caffe-01.jpg\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" height=\"160\" src=\"https://3.bp.blogspot.com/-YIql8zIlTNc/VY3y8q-pmPI/AAAAAAAAOPw/HS78ACtebo4/s320/torch_vs_caffe-01.jpg\" width=\"320\" /></a></div><br /><br />Caffe is developed at Berkeley, has a vibrant community, Python bindings, and seems to be quite popular among University students. <a href=\"http://www.eecs.berkeley.edu/~trevor/\">Prof. Trevor Darrell</a>&nbsp;at Berkeley is even looking for a Postdoc to help the Caffe effort. If I was a couple of years younger and a fresh PhD, I would definitely apply.<br /><br />Instead of following the Python trend, Torch is Lua-based. There is no need for an interpreter like Matlab or Python -- Lua gives you the magic console. Torch is heavily used by Facebook AI Research Labs and Google's DeepMind Lab in London. &nbsp;For those afraid of new languages like Lua, don't worry -- Lua is going to feel \"easy\" if you've dabbled in Python, Javascript, or Matlab. And if you don't like editing protocol buffer files by hand, definitely check out Torch.<br /><br /><b>It's starting to become clear that the future power of deep learning is going to come with its own self-contained software package like Caffe or Torch, and not from a dying breed of all-around&nbsp;tool-belts&nbsp;like OpenCV or Matlab.</b>&nbsp;When you share creations made in OpenCV, you end up sharing source files, but with the Deep Learning toolkits, you end up sharing your pre-trained networks. &nbsp;No longer do you have to think about a combination of 20 \"little\" algorithms for your computer vision pipeline -- you just think about which popular network architecture you want, and then the dataset. &nbsp;If you have the GPUs and ample data, you can do full end-to-end training. &nbsp;And if your dataset is small/medium, you can fine-tune the last few layers. You can even train a linear classifier on top of the final layer, if you're afraid of getting your hands dirty -- just doing that will beat the SIFTs, the HOGs, the GISTs, and all that was celebrated in the past two decades of computer vision.<br /><br /><b>Related Article:</b> <a href=\"http://fastml.com/torch-vs-theano/\">Torch vs Theano on fastml.com</a><br /><b>Related Code:</b> <a href=\"http://www.vlfeat.org/matconvnet/\">Andrea Vedaldi's MatConvNet Deep Learning Library for MATLAB users</a><br /><br />The way in which ConvNets are being used at CVPR 2015 makes me feel like we're close to something big. &nbsp;But before we strike gold, ConvNets still feel like a Calculus of Shadows, merely \"hoping\" to get at something bigger, something deeper, and something more meaningful. I think the flurry of research which investigates visualization algorithms for ConvNets suggests that even the network architects aren't completely sure what is happening behind the scenes.<br /><br /><h3>The Video Game Engine Inside Your Head: A different path towards Machine Intelligence</h3><br /><a href=\"http://web.mit.edu/cocosci/josh.html\">Josh Tenenbaum</a> gave an invited talk titled The Video Game Engine Inside Your Head at the <a href=\"http://sunw.csail.mit.edu/\">Scene Understanding Workshop</a> on the last day of the CVPR 2015 conference. You can read a summary of his ideas in a <a href=\"http://www.scientificamerican.com/article/the-video-game-engine-in-your-head/\">short Scientific American article</a>. While his talk might appear to be unconventional by CVPR standards, it is classic Tenenbaum. In his world, there is no benchmark to beat, no curves to fit to shadows, and if you allow my LeCun-Descartes analogy, then in some sense Prof. Tenenbaum might be the modern day Aristotle. As <a href=\"http://vision.princeton.edu/people/xj/\">Prof. Jianxiong Xiao</a>&nbsp;introduced Josh with a grand intro, he was probably right -- this is one of the most intelligent speakers you can find. &nbsp;He speaks 100 words a second, you can't help but feel your brain enlarge as you listen.<br /><br />One of Josh's main research themes is going beyond the shadows of image-based recognition. &nbsp;Josh's work is all about building mental models of the world, and his work can really be thought of as analysis-by-synthesis. Inside his models is something like a video game engine, and he showed lots of compelling examples of inferences that are easy for people, but nearly impossible for the data-driven ConvNets of today. &nbsp;It's not surprising that his student is working at Google's DeepMind this summer.<br /><br />A couple of years ago, <a href=\"http://pgm.stanford.edu/\">Probabilistic Graphical Models</a> (the marriage of Graph Theory and Probabilistic Methods) used to be all the rage. &nbsp;Josh gave us a taste of <b>Probabilistic Programming</b>, and while we're not yet seeing these new methods dominate the world of computer vision research, keep your eyes open. He mentioned a recent Nature paper (citation below) from another well respected machine intelligence research, which should keep the trendsetters excited for quite some time. Just take a look at the bad-ass looking <a href=\"http://julialang.org/\">Julia</a> code below:<br /><br />Probabilistic machine learning and artificial intelligence. <a href=\"http://mlg.eng.cam.ac.uk/zoubin/\">Zoubin Ghahramani</a>. Nature 521, 452–459 (28 May 2015) doi:10.1038/nature14541<br /><br /><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://4.bp.blogspot.com/-KpKw8OQq2CE/VYs5NIPpjbI/AAAAAAAAOOs/kqxc5aJt2TY/s1600/nature14541-f2.jpg\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" height=\"117\" src=\"https://4.bp.blogspot.com/-KpKw8OQq2CE/VYs5NIPpjbI/AAAAAAAAOOs/kqxc5aJt2TY/s400/nature14541-f2.jpg\" width=\"400\" /></a></div><br /><br /><br />To see some of Prof. Tenenbaum's ideas in action, take a look at the following CVPR 2015 paper, titled&nbsp;<a href=\"http://mrkulk.github.io/www_cvpr15/\">Picture: A Probabilistic Programming Language for Scene Perception</a>. Congrats to&nbsp;<a href=\"http://tejask.com/\">Tejas D. Kulkarni</a>, the first author, an MIT student, who got the Best Paper Honorable Mention prize for this exciting new work. Google DeepMind, you're going to have one fun summer.<br /><br /><br /><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://1.bp.blogspot.com/-oYEe0sbaCao/VYs4zlLYzLI/AAAAAAAAOOk/rzTaG2jtwoI/s1600/tenenbaum_cvpr2015.png\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" height=\"240\" src=\"https://1.bp.blogspot.com/-oYEe0sbaCao/VYs4zlLYzLI/AAAAAAAAOOk/rzTaG2jtwoI/s320/tenenbaum_cvpr2015.png\" width=\"320\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://mrkulk.github.io/www_cvpr15/\">Picture: A Probabilistic Programming Language for Scene Perception</a></div><br /><br /><h3>Object Detectors Emerge in Deep Scene CNNs</h3>There were lots of great presentation as the Scene Understanding Workshop, and another talk that truly stood out was about a new large-scale dataset (MIT Places) and a thorough investigation of what happens when you train with scenes vs. objects.<br /><br /><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://3.bp.blogspot.com/-SMTxAQ_gQ9U/VY3vega-VNI/AAAAAAAAOPk/Zrd5yn4pSiU/s1600/emerge.jpg\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" height=\"145\" src=\"https://3.bp.blogspot.com/-SMTxAQ_gQ9U/VY3vega-VNI/AAAAAAAAOPk/Zrd5yn4pSiU/s400/emerge.jpg\" width=\"400\" /></a></div><br /><br /><a href=\"http://web.mit.edu/torralba/www/\">Antonio Torralba</a>&nbsp;from MIT gave the talk about the Places Database and an in-depth analysis of what is learned when you train on object-centric databases like ImageNet vs. Scene-scentric databases like <a href=\"http://places.csail.mit.edu/\">MIT Places.</a> You can check out \"<a href=\"http://places.csail.mit.edu/slide_iclr2015.pdf\">Object Detectors Emerge</a>\" slides or their <a href=\"http://arxiv.org/pdf/1412.6856v1.pdf\">ArXiv paper</a> to learn more. Great work by an upcoming researcher, <a href=\"http://people.csail.mit.edu/bzhou/\">Bolei Zhou</a>!<br /><br /><h3>Overheard at CVPR: ArXiv Publishing Frenzy &amp; Baidu Fiasco&nbsp;</h3><br />In the long run, the recent trend of <b>rapidly pushing preprints</b> to <a href=\"http://arxiv.org/\">ArXiv.org</a> is great for&nbsp;academic and industry research alike. When you have a large collection of experts exploring ideas at very fast rates, waiting 6 months until the next conference deadline just doesn't make sense. &nbsp;The only downside is that it makes new CVPR papers feel old. It seems like everybody has already perused the good stuff the day it went up on ArXiv. But you get your \"idea claim\" without worrying that a naughty reviewer will be influenced by your submission. <b>Double blind reviewing, get ready for a serious revamp.</b>&nbsp; We now know who's doing what, significantly before publication time. &nbsp;Students, publish-or-perish just got a new name. Whether the ArXiv frenzy is a good or a bad thing, is up to you, and probably more a function of your seniority than anything else. But the CV buzz is definitely getting louder and will continue to do so.<br /><br />The <a href=\"http://www.technologyreview.com/view/538111/why-and-how-baidu-cheated-an-artificial-intelligence-test/\">Baidu cheating scandal</a> might appear to be big news for outsiders just reading the Artificial Intelligence headlines, but overfitting to the testing set is nothing new in Computer Vision. Papers get retracted, grad students often evaluate their algorithms on test sets too many times, and the truth is that nobody's perfect. &nbsp;When it's important to be #1, don't be surprised that your competition is being naughty. But it's important to realize the difference between ground-breaking research and petty percentage chasing. We all make mistakes, and under heavy pressure, we're all likely to show our weaknesses. &nbsp;So let's laugh about it. &nbsp;<b>Let's hire the best of the best, encourage truly great research, and stop chasing percentages.</b> &nbsp;The truth is that a lot of the top performing methods are more similar than different.<br /><br /><br /><b>Conclusion</b><br />CVPR has been constantly growing in attendance. We now have Phd Students, startups, Professors, recruiters, big companies, and even undergraduates coming to the show. Will CVPR become the new SIGGRAPH?<br /><br /><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://4.bp.blogspot.com/-Mu-G1cfyImE/VY3tZRiS0kI/AAAAAAAAOPY/gf-QZnvFgqk/s1600/cvpr_attendance.jpg\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" height=\"250\" src=\"https://4.bp.blogspot.com/-Mu-G1cfyImE/VY3tZRiS0kI/AAAAAAAAOPY/gf-QZnvFgqk/s400/cvpr_attendance.jpg\" width=\"400\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\">CVPR attendance plot from&nbsp;<a href=\"http://www.cs.cmu.edu/~changbo/\">Changbo Hu</a>.&nbsp;</div><br /><br />ConvNets are here to stay, but if we want ConvNets to be more than than a mere calculus of shadows, there's still ample work do be done. Geoff Hinton's capsules keep popping up during midnight discussions. \"<b>I want to replace unstructured layers with groups of neurons that I call 'capsules' that are a lot more like cortical columns</b>\" -- <a href=\"http://www.reddit.com/r/MachineLearning/comments/2lmo0l/ama_geoffrey_hinton\">Geoff Hinton during his Reddit AMA</a>. A lot of people (like <a href=\"http://www.cs.cmu.edu/~abhinavg/\">Prof. Abhinav Gupta</a> from CMU) are also talking about unsupervised CNN training, and my prediction is that learning large ConvNets from videos without annotations is going to be big at next year's CVPR.<br /><br />Most importantly, when the titans of Deep Learning get to mention what's wrong with their favorite methods, I only expect the best research to follow. Happy computing and remember, never stop learning.<br /><br /><br /></div>",
  "link": [
    "",
    "",
    "",
    "",
    ""
  ],
  "author": {
    "name": "Tomasz Malisiewicz",
    "uri": "http://www.blogger.com/profile/17507234774392358321",
    "email": "noreply@blogger.com",
    "gd:image": ""
  },
  "media:thumbnail": "",
  "thr:total": 7
}