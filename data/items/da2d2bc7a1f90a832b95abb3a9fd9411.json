{
  "title": "Clustering Search Keywords Using K-Means Clustering",
  "description": "<p>One of the key tenets to doing impactful digital analysis is understanding what your visitors are trying to accomplish. One of the easiest methods to do this is by analyzing the words your visitors use to arrive on site (search keywords) and what words they are using while on the site (on-site search). </p>",
  "pubDate": "Tue, 17 Sep 2013 14:41:01 +0000",
  "link": "http://randyzwitch.com/rsitecatalyst-k-means-clustering/",
  "guid": "http://randyzwitch.com/rsitecatalyst-k-means-clustering/",
  "content": "<p>One of the key tenets to doing impactful digital analysis is understanding what your visitors are trying to accomplish. One of the easiest methods to do this is by analyzing the words your visitors use to arrive on site (search keywords) and what words they are using while on the site (on-site search). </p>\n\n<p>Although Google has made it much more difficult to analyze search keywords over the past several years (due to their passing of <a title=\"(not provided): Using R and the Google Analytics API\" href=\"http://randyzwitch.com/r-google-analytics-api/\" target=\"_blank\">“(not provided)”</a> instead of the actual keywords), we can create customer intent segments based on the keywords that are still being passed using unsupervised clustering methods such as k-means clustering.</p>\n\n<h2 id=\"concept-k-means-clusteringunsupervised-learning\">Concept: K-Means Clustering/Unsupervised Learning</h2>\n\n<p><a title=\"k-means clustering\" href=\"http://en.wikipedia.org/wiki/K-means_clustering\" target=\"_blank\">K-means clustering</a> is one of many techniques within <a title=\"Unsupervised learning Wikipedia\" href=\"http://en.wikipedia.org/wiki/Unsupervised_learning\" target=\"_blank\">unsupervised learning</a> that can be used for text analysis. <em>Unsupervised</em> refers to the fact that we’re trying to understand the structure of our underlying data, rather than trying to optimize for a specific, pre-labeled criterion (such as creating a predictive model for conversion). Unsupervised learning is a great technique for exploratory analysis in that the analyst enforces few assumptions on the data, so previously unexamined relationships can be determined <em>then</em> analyzed; contrast that with pre-defined relationships specified by the analyst (such as <em>visitors from mobile</em> or <em>visitors from social</em>), then evaluating how various metrics differ across these pre-defined groups.</p>\n\n<p>Without getting too technical, k-means clustering is a method of partitioning data into ‘k’ subsets, where each data element is assigned to the closest cluster based on the distance of the data element from the center of the cluster. In order to use k-means clustering with text data, we need to do some text-to-numeric transformation of our text data. Luckily, R provides several packages to simplify the process.</p>\n\n<h2 id=\"converting-text-to-numeric-data-document-term-matrix\">Converting Text to Numeric Data: Document-Term Matrix</h2>\n\n<p>Since I use Adobe Analytics on this blog, I’m going to use the <a title=\"RSiteCatalyst\" href=\"http://randyzwitch.com/rsitecatalyst\" target=\"_blank\">RSiteCatalyst package</a> to get my natural search keywords into a dataframe. Once the keywords are in a dataframe, we can use the <a title=\"RTextTools\" href=\"http://www.rtexttools.com/\" target=\"_blank\">RTextTools</a> package to create a document-term matrix, where each row is our search term and each column is a 1/0 representation of whether a single word is contained within natural search term. </p>\n\n<figure class=\"highlight\"><pre><code class=\"language-r\" data-lang=\"r\"><table class=\"rouge-table\"><tbody><tr><td class=\"gutter gl\"><pre class=\"lineno\">1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n</pre></td><td class=\"code\"><pre><span class=\"c1\">#### 0. Setup</span><span class=\"w\">\n</span><span class=\"n\">library</span><span class=\"p\">(</span><span class=\"s2\">\"RSiteCatalyst\"</span><span class=\"p\">)</span><span class=\"w\">\n</span><span class=\"n\">library</span><span class=\"p\">(</span><span class=\"s2\">\"RTextTools\"</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"c1\">#Loads many packages useful for text mining</span><span class=\"w\">\n\n</span><span class=\"c1\">#### 1. RSiteCatalyst code - Get Natural Search Keywords &amp; Metrics</span><span class=\"w\">\n\n</span><span class=\"c1\">#Set credentials</span><span class=\"w\">\n</span><span class=\"n\">SCAuth</span><span class=\"p\">(</span><span class=\"o\">&lt;</span><span class=\"n\">username</span><span class=\"o\">:</span><span class=\"n\">company</span><span class=\"o\">&gt;</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"o\">&lt;</span><span class=\"n\">shared</span><span class=\"w\"> </span><span class=\"n\">secret</span><span class=\"o\">&gt;</span><span class=\"p\">)</span><span class=\"w\">\n\n</span><span class=\"c1\">#Get list of search engine terms</span><span class=\"w\">\n</span><span class=\"n\">searchkeywords</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"n\">QueueRanked</span><span class=\"p\">(</span><span class=\"o\">&lt;</span><span class=\"n\">report_suite</span><span class=\"o\">&gt;</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"s2\">\"2013-02-01\"</span><span class=\"p\">,</span><span class=\"s2\">\"2013-09-16\"</span><span class=\"p\">,</span><span class=\"w\">\n                  </span><span class=\"nf\">c</span><span class=\"p\">(</span><span class=\"s2\">\"entries\"</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"s2\">\"visits\"</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"s2\">\"pageviews\"</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"s2\">\"instances\"</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"s2\">\"bounces\"</span><span class=\"p\">),</span><span class=\"w\">\n                  </span><span class=\"s2\">\"searchenginenaturalkeyword\"</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">top</span><span class=\"o\">=</span><span class=\"s2\">\"100000\"</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">startingWith</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"s2\">\"1\"</span><span class=\"p\">)</span><span class=\"w\">\n\n</span><span class=\"c1\">#### 2. Process keywords into format suitable for text mining</span><span class=\"w\">\n\n</span><span class=\"c1\">#Create document-term matrix, passing data cleaning options</span><span class=\"w\">\n</span><span class=\"c1\">#Stem the words to avoid multiples of similar words</span><span class=\"w\">\n</span><span class=\"c1\">#Need to set wordLength to minimum of 1 because \"r\" a likely term</span><span class=\"w\">\n</span><span class=\"n\">dtm</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"n\">create_matrix</span><span class=\"p\">(</span><span class=\"n\">searchkeywords</span><span class=\"o\">$</span><span class=\"s1\">'Natural Search Keyword'</span><span class=\"p\">,</span><span class=\"w\">\n                     </span><span class=\"n\">stemWords</span><span class=\"o\">=</span><span class=\"kc\">TRUE</span><span class=\"p\">,</span><span class=\"w\">\n                     </span><span class=\"n\">removeStopwords</span><span class=\"o\">=</span><span class=\"kc\">FALSE</span><span class=\"p\">,</span><span class=\"w\">\n                     </span><span class=\"n\">minWordLength</span><span class=\"o\">=</span><span class=\"m\">1</span><span class=\"p\">,</span><span class=\"w\">\n                     </span><span class=\"n\">removePunctuation</span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"kc\">TRUE</span><span class=\"p\">)</span>\n</pre></td></tr></tbody></table></code></pre></figure>\n\n<p>Within the <code class=\"language-plaintext highlighter-rouge\">create_matrix</code> function, I’m using four keyword arguments to process the data:</p>\n\n<ol>\n  <li><code class=\"language-plaintext highlighter-rouge\">stemWords</code> reduces a word down to its root, which is a standardization method to avoid having multiple versions of words referring to the same concept (e.g. argue, arguing, argued reduces to ‘argu’)</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">removeStopwords</code> eliminates common English words such as “they”, “he” , “always”</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">minWordLength</code> sets the minimum number of characters that constitutes a ‘word’, which I set to 1 because of the high likelihood of ‘r’ being a keyword</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">removePunctuation</code> removes periods, commas, etc.</li>\n</ol>\n\n<h2 id=\"popular-words\">Popular Words</h2>\n\n<p>If you are unfamiliar with the terms that might be contained in your dataset, you can use the <code class=\"language-plaintext highlighter-rouge\">findFreqTerms</code> to see which terms occur with a minimum frequency. Here are the terms that occur at least 20 times on this blog:</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-r\" data-lang=\"r\"><table class=\"rouge-table\"><tbody><tr><td class=\"gutter gl\"><pre class=\"lineno\">1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n</pre></td><td class=\"code\"><pre><span class=\"o\">&gt;</span><span class=\"w\"> </span><span class=\"c1\">#Inspect most popular words, minimum frequency of 20</span><span class=\"w\">\n</span><span class=\"o\">&gt;</span><span class=\"w\"> </span><span class=\"n\">findFreqTerms</span><span class=\"p\">(</span><span class=\"n\">dtm</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">lowfreq</span><span class=\"o\">=</span><span class=\"m\">20</span><span class=\"p\">)</span><span class=\"w\">\n  </span><span class=\"p\">[</span><span class=\"m\">1</span><span class=\"p\">]</span><span class=\"w\"> </span><span class=\"s2\">\"15\"</span><span class=\"w\">           </span><span class=\"s2\">\"2008\"</span><span class=\"w\">         </span><span class=\"s2\">\"2009\"</span><span class=\"w\">         </span><span class=\"s2\">\"2011\"</span><span class=\"w\">         </span><span class=\"s2\">\"a\"</span><span class=\"w\">            </span><span class=\"s2\">\"ad\"</span><span class=\"w\">           </span><span class=\"s2\">\"add\"</span><span class=\"w\">          </span><span class=\"s2\">\"adsens\"</span><span class=\"w\">      \n  </span><span class=\"p\">[</span><span class=\"m\">9</span><span class=\"p\">]</span><span class=\"w\"> </span><span class=\"s2\">\"air\"</span><span class=\"w\">          </span><span class=\"s2\">\"analyt\"</span><span class=\"w\">       </span><span class=\"s2\">\"and\"</span><span class=\"w\">          </span><span class=\"s2\">\"appl\"</span><span class=\"w\">         </span><span class=\"s2\">\"at\"</span><span class=\"w\">           </span><span class=\"s2\">\"back\"</span><span class=\"w\">         </span><span class=\"s2\">\"bezel\"</span><span class=\"w\">        </span><span class=\"s2\">\"black\"</span><span class=\"w\">       \n </span><span class=\"p\">[</span><span class=\"m\">17</span><span class=\"p\">]</span><span class=\"w\"> </span><span class=\"s2\">\"book\"</span><span class=\"w\">         </span><span class=\"s2\">\"bookmark\"</span><span class=\"w\">     </span><span class=\"s2\">\"break\"</span><span class=\"w\">        </span><span class=\"s2\">\"broke\"</span><span class=\"w\">        </span><span class=\"s2\">\"broken\"</span><span class=\"w\">       </span><span class=\"s2\">\"bubbl\"</span><span class=\"w\">        </span><span class=\"s2\">\"by\"</span><span class=\"w\">           </span><span class=\"s2\">\"can\"</span><span class=\"w\">         \n </span><span class=\"p\">[</span><span class=\"m\">25</span><span class=\"p\">]</span><span class=\"w\"> </span><span class=\"s2\">\"case\"</span><span class=\"w\">         </span><span class=\"s2\">\"chang\"</span><span class=\"w\">        </span><span class=\"s2\">\"child\"</span><span class=\"w\">        </span><span class=\"s2\">\"code\"</span><span class=\"w\">         </span><span class=\"s2\">\"comment\"</span><span class=\"w\">      </span><span class=\"s2\">\"comput\"</span><span class=\"w\">       </span><span class=\"s2\">\"cost\"</span><span class=\"w\">         </span><span class=\"s2\">\"cover\"</span><span class=\"w\">       \n </span><span class=\"p\">[</span><span class=\"m\">33</span><span class=\"p\">]</span><span class=\"w\"> </span><span class=\"s2\">\"crack\"</span><span class=\"w\">        </span><span class=\"s2\">\"css\"</span><span class=\"w\">          </span><span class=\"s2\">\"custom\"</span><span class=\"w\">       </span><span class=\"s2\">\"data\"</span><span class=\"w\">         </span><span class=\"s2\">\"delet\"</span><span class=\"w\">        </span><span class=\"s2\">\"disabl\"</span><span class=\"w\">       </span><span class=\"s2\">\"display\"</span><span class=\"w\">      </span><span class=\"s2\">\"do\"</span><span class=\"w\">          \n </span><span class=\"p\">[</span><span class=\"m\">41</span><span class=\"p\">]</span><span class=\"w\"> </span><span class=\"s2\">\"doe\"</span><span class=\"w\">          </span><span class=\"s2\">\"drop\"</span><span class=\"w\">         </span><span class=\"s2\">\"edit\"</span><span class=\"w\">         </span><span class=\"s2\">\"eleven\"</span><span class=\"w\">       </span><span class=\"s2\">\"em209\"</span><span class=\"w\">        </span><span class=\"s2\">\"entri\"</span><span class=\"w\">        </span><span class=\"s2\">\"fix\"</span><span class=\"w\">          </span><span class=\"s2\">\"footer\"</span><span class=\"w\">      \n </span><span class=\"p\">[</span><span class=\"m\">49</span><span class=\"p\">]</span><span class=\"w\"> </span><span class=\"s2\">\"footerphp\"</span><span class=\"w\">    </span><span class=\"s2\">\"for\"</span><span class=\"w\">          </span><span class=\"s2\">\"free\"</span><span class=\"w\">         </span><span class=\"s2\">\"from\"</span><span class=\"w\">         </span><span class=\"s2\">\"get\"</span><span class=\"w\">          </span><span class=\"s2\">\"glue\"</span><span class=\"w\">         </span><span class=\"s2\">\"googl\"</span><span class=\"w\">        </span><span class=\"s2\">\"hadoop\"</span><span class=\"w\">      \n </span><span class=\"p\">[</span><span class=\"m\">57</span><span class=\"p\">]</span><span class=\"w\"> </span><span class=\"s2\">\"header\"</span><span class=\"w\">       </span><span class=\"s2\">\"hing\"</span><span class=\"w\">         </span><span class=\"s2\">\"how\"</span><span class=\"w\">          </span><span class=\"s2\">\"i\"</span><span class=\"w\">            </span><span class=\"s2\">\"if\"</span><span class=\"w\">           </span><span class=\"s2\">\"imag\"</span><span class=\"w\">         </span><span class=\"s2\">\"in\"</span><span class=\"w\">           </span><span class=\"s2\">\"is\"</span><span class=\"w\">          \n </span><span class=\"p\">[</span><span class=\"m\">65</span><span class=\"p\">]</span><span class=\"w\"> </span><span class=\"s2\">\"it\"</span><span class=\"w\">           </span><span class=\"s2\">\"laptop\"</span><span class=\"w\">       </span><span class=\"s2\">\"late\"</span><span class=\"w\">         </span><span class=\"s2\">\"lcd\"</span><span class=\"w\">          </span><span class=\"s2\">\"lid\"</span><span class=\"w\">          </span><span class=\"s2\">\"link\"</span><span class=\"w\">         </span><span class=\"s2\">\"logo\"</span><span class=\"w\">         </span><span class=\"s2\">\"loos\"</span><span class=\"w\">        \n </span><span class=\"p\">[</span><span class=\"m\">73</span><span class=\"p\">]</span><span class=\"w\"> </span><span class=\"s2\">\"mac\"</span><span class=\"w\">          </span><span class=\"s2\">\"macbook\"</span><span class=\"w\">      </span><span class=\"s2\">\"make\"</span><span class=\"w\">         </span><span class=\"s2\">\"mobil\"</span><span class=\"w\">        </span><span class=\"s2\">\"modifi\"</span><span class=\"w\">       </span><span class=\"s2\">\"much\"</span><span class=\"w\">         </span><span class=\"s2\">\"my\"</span><span class=\"w\">           </span><span class=\"s2\">\"navig\"</span><span class=\"w\">       \n </span><span class=\"p\">[</span><span class=\"m\">81</span><span class=\"p\">]</span><span class=\"w\"> </span><span class=\"s2\">\"of\"</span><span class=\"w\">           </span><span class=\"s2\">\"off\"</span><span class=\"w\">          </span><span class=\"s2\">\"omnitur\"</span><span class=\"w\">      </span><span class=\"s2\">\"on\"</span><span class=\"w\">           </span><span class=\"s2\">\"page\"</span><span class=\"w\">         </span><span class=\"s2\">\"permalink\"</span><span class=\"w\">    </span><span class=\"s2\">\"php\"</span><span class=\"w\">          </span><span class=\"s2\">\"post\"</span><span class=\"w\">        \n </span><span class=\"p\">[</span><span class=\"m\">89</span><span class=\"p\">]</span><span class=\"w\"> </span><span class=\"s2\">\"power\"</span><span class=\"w\">        </span><span class=\"s2\">\"pro\"</span><span class=\"w\">          </span><span class=\"s2\">\"problem\"</span><span class=\"w\">      </span><span class=\"s2\">\"program\"</span><span class=\"w\">      </span><span class=\"s2\">\"proud\"</span><span class=\"w\">        </span><span class=\"s2\">\"r\"</span><span class=\"w\">            </span><span class=\"s2\">\"remov\"</span><span class=\"w\">        </span><span class=\"s2\">\"repair\"</span><span class=\"w\">      \n </span><span class=\"p\">[</span><span class=\"m\">97</span><span class=\"p\">]</span><span class=\"w\"> </span><span class=\"s2\">\"replac\"</span><span class=\"w\">       </span><span class=\"s2\">\"report\"</span><span class=\"w\">       </span><span class=\"s2\">\"sas\"</span><span class=\"w\">          </span><span class=\"s2\">\"screen\"</span><span class=\"w\">       </span><span class=\"s2\">\"separ\"</span><span class=\"w\">        </span><span class=\"s2\">\"site\"</span><span class=\"w\">         </span><span class=\"s2\">\"sitecatalyst\"</span><span class=\"w\"> </span><span class=\"s2\">\"store\"</span><span class=\"w\">       \n</span><span class=\"p\">[</span><span class=\"m\">105</span><span class=\"p\">]</span><span class=\"w\"> </span><span class=\"s2\">\"tag\"</span><span class=\"w\">          </span><span class=\"s2\">\"text\"</span><span class=\"w\">         </span><span class=\"s2\">\"the\"</span><span class=\"w\">          </span><span class=\"s2\">\"theme\"</span><span class=\"w\">        </span><span class=\"s2\">\"this\"</span><span class=\"w\">         </span><span class=\"s2\">\"tighten\"</span><span class=\"w\">      </span><span class=\"s2\">\"to\"</span><span class=\"w\">           </span><span class=\"s2\">\"top\"</span><span class=\"w\">         \n</span><span class=\"p\">[</span><span class=\"m\">113</span><span class=\"p\">]</span><span class=\"w\"> </span><span class=\"s2\">\"turn\"</span><span class=\"w\">         </span><span class=\"s2\">\"twenti\"</span><span class=\"w\">       </span><span class=\"s2\">\"twentyeleven\"</span><span class=\"w\"> </span><span class=\"s2\">\"uncategor\"</span><span class=\"w\">    </span><span class=\"s2\">\"unibodi\"</span><span class=\"w\">      </span><span class=\"s2\">\"use\"</span><span class=\"w\">          </span><span class=\"s2\">\"variabl\"</span><span class=\"w\">      </span><span class=\"s2\">\"version\"</span><span class=\"w\">     \n</span><span class=\"p\">[</span><span class=\"m\">121</span><span class=\"p\">]</span><span class=\"w\"> </span><span class=\"s2\">\"view\"</span><span class=\"w\">         </span><span class=\"s2\">\"vs\"</span><span class=\"w\">           </span><span class=\"s2\">\"warranti\"</span><span class=\"w\">     </span><span class=\"s2\">\"was\"</span><span class=\"w\">          </span><span class=\"s2\">\"what\"</span><span class=\"w\">         </span><span class=\"s2\">\"will\"</span><span class=\"w\">         </span><span class=\"s2\">\"with\"</span><span class=\"w\">         </span><span class=\"s2\">\"wordpress\"</span><span class=\"w\">   \n</span><span class=\"p\">[</span><span class=\"m\">129</span><span class=\"p\">]</span><span class=\"w\"> </span><span class=\"s2\">\"wp\"</span><span class=\"w\">           </span><span class=\"s2\">\"you\"</span><span class=\"w\">    </span>\n</pre></td></tr></tbody></table></code></pre></figure>\n\n<h2 id=\"guessing-at-k-a-first-run-at-clustering\">Guessing at ‘k’: A First Run at Clustering</h2>\n\n<p>Once we have our data set up, we can very quickly run the k-means algorithm within R. The one downside to using k-means clustering as a technique is that the user must choose ‘k’, the number of clusters expected from the dataset. In absence of any heuristics about what ‘k’ to use, I can guess that there are five topics on this blog:\n1. Data Science</p>\n<ol>\n  <li>Digital Analytics  </li>\n  <li>R</li>\n  <li>Julia</li>\n  <li>WordPress</li>\n</ol>\n\n<p>Running the following code, we can see if the algorithm agrees:</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-r\" data-lang=\"r\"><table class=\"rouge-table\"><tbody><tr><td class=\"gutter gl\"><pre class=\"lineno\">1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n</pre></td><td class=\"code\"><pre><span class=\"c1\">#I think there are 5 main topics: Data Science, Web Analytics, R, Julia, Wordpress</span><span class=\"w\">\n</span><span class=\"n\">kmeans5</span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"n\">kmeans</span><span class=\"p\">(</span><span class=\"n\">dtm</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"m\">5</span><span class=\"p\">)</span><span class=\"w\">\n\n</span><span class=\"c1\">#Merge cluster assignment back to keywords</span><span class=\"w\">\n</span><span class=\"n\">kw_with_cluster</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"n\">as.data.frame</span><span class=\"p\">(</span><span class=\"n\">cbind</span><span class=\"p\">(</span><span class=\"n\">searchkeywords</span><span class=\"o\">$</span><span class=\"s1\">'Natural Search Keyword'</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">kmeans5</span><span class=\"o\">$</span><span class=\"n\">cluster</span><span class=\"p\">))</span><span class=\"w\">\n</span><span class=\"nf\">names</span><span class=\"p\">(</span><span class=\"n\">kw_with_cluster</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"nf\">c</span><span class=\"p\">(</span><span class=\"s2\">\"keyword\"</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"s2\">\"kmeans5\"</span><span class=\"p\">)</span><span class=\"w\">\n\n</span><span class=\"c1\">#Make df for each cluster result, quickly \"eyeball\" results</span><span class=\"w\">\n</span><span class=\"n\">cluster1</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"n\">subset</span><span class=\"p\">(</span><span class=\"n\">kw_with_cluster</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">subset</span><span class=\"o\">=</span><span class=\"n\">kmeans5</span><span class=\"w\"> </span><span class=\"o\">==</span><span class=\"w\"> </span><span class=\"m\">1</span><span class=\"p\">)</span><span class=\"w\">\n</span><span class=\"n\">cluster2</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"n\">subset</span><span class=\"p\">(</span><span class=\"n\">kw_with_cluster</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">subset</span><span class=\"o\">=</span><span class=\"n\">kmeans5</span><span class=\"w\"> </span><span class=\"o\">==</span><span class=\"w\"> </span><span class=\"m\">2</span><span class=\"p\">)</span><span class=\"w\">\n</span><span class=\"n\">cluster3</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"n\">subset</span><span class=\"p\">(</span><span class=\"n\">kw_with_cluster</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">subset</span><span class=\"o\">=</span><span class=\"n\">kmeans5</span><span class=\"w\"> </span><span class=\"o\">==</span><span class=\"w\"> </span><span class=\"m\">3</span><span class=\"p\">)</span><span class=\"w\">\n</span><span class=\"n\">cluster4</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"n\">subset</span><span class=\"p\">(</span><span class=\"n\">kw_with_cluster</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">subset</span><span class=\"o\">=</span><span class=\"n\">kmeans5</span><span class=\"w\"> </span><span class=\"o\">==</span><span class=\"w\"> </span><span class=\"m\">4</span><span class=\"p\">)</span><span class=\"w\">\n</span><span class=\"n\">cluster5</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"n\">subset</span><span class=\"p\">(</span><span class=\"n\">kw_with_cluster</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">subset</span><span class=\"o\">=</span><span class=\"n\">kmeans5</span><span class=\"w\"> </span><span class=\"o\">==</span><span class=\"w\"> </span><span class=\"m\">5</span><span class=\"p\">)</span>\n</pre></td></tr></tbody></table></code></pre></figure>\n\n<p>Opening the dataframes to observe the results, it seems that the algorithm disagrees:</p>\n\n<ul>\n  <li>Cluster 1: “Free-for-All” cluster: not well separated (41.1% of terms)</li>\n  <li>Cluster 2: “wordpress” and “remove” (4.9% of terms)</li>\n  <li>Cluster 3: “powered by wordpress” (4.3% of terms)</li>\n  <li>Cluster 4: “twenty eleven” (13.5% of terms)</li>\n  <li>Cluster 5: “macbook” (36.2% of terms)</li>\n</ul>\n\n<p>Of the clusters, the strongest cluster in terms of performance is cluster 5, which is pretty homogenous in terms of being about ‘macbook’ terms. Clusters 2-4 are all about WordPress, albeit different topics surrounding blogging. And cluster 1 is a large hodge-podge of terms that seem unrelated. Clearly, five clusters isn’t the proper value for ‘k’.   </p>\n\n<h2 id=\"selecting-k-using-elbow-method\">Selecting ‘k’ Using ‘Elbow Method’</h2>\n\n<p>Instead of randomly choosing values of ‘k’, then looking at each cluster result until we find one we like, we can take a more automated approach to picking ‘k’. For every <code class=\"language-plaintext highlighter-rouge\">kmeans</code> object returned by R, there is a metric <code class=\"language-plaintext highlighter-rouge\">tot.withinss</code> that provides the total of the squared distance metric for each cluster.</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-r\" data-lang=\"r\"><table class=\"rouge-table\"><tbody><tr><td class=\"gutter gl\"><pre class=\"lineno\">1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n</pre></td><td class=\"code\"><pre><span class=\"c1\">#accumulator for cost results</span><span class=\"w\">\n</span><span class=\"n\">cost_df</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"n\">data.frame</span><span class=\"p\">()</span><span class=\"w\">\n\n</span><span class=\"c1\">#run kmeans for all clusters up to 100</span><span class=\"w\">\n</span><span class=\"k\">for</span><span class=\"p\">(</span><span class=\"n\">i</span><span class=\"w\"> </span><span class=\"k\">in</span><span class=\"w\"> </span><span class=\"m\">1</span><span class=\"o\">:</span><span class=\"m\">100</span><span class=\"p\">){</span><span class=\"w\">\n  </span><span class=\"c1\">#Run kmeans for each level of i, allowing up to 100 iterations for convergence</span><span class=\"w\">\n  </span><span class=\"n\">kmeans</span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"n\">kmeans</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"o\">=</span><span class=\"n\">dtm</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">centers</span><span class=\"o\">=</span><span class=\"n\">i</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">iter.max</span><span class=\"o\">=</span><span class=\"m\">100</span><span class=\"p\">)</span><span class=\"w\">\n\n  </span><span class=\"c1\">#Combine cluster number and cost together, write to df</span><span class=\"w\">\n  </span><span class=\"n\">cost_df</span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"n\">rbind</span><span class=\"p\">(</span><span class=\"n\">cost_df</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">cbind</span><span class=\"p\">(</span><span class=\"n\">i</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">kmeans</span><span class=\"o\">$</span><span class=\"n\">tot.withinss</span><span class=\"p\">))</span><span class=\"w\">\n\n</span><span class=\"p\">}</span><span class=\"w\">\n</span><span class=\"nf\">names</span><span class=\"p\">(</span><span class=\"n\">cost_df</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"nf\">c</span><span class=\"p\">(</span><span class=\"s2\">\"cluster\"</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"s2\">\"cost\"</span><span class=\"p\">)</span>\n</pre></td></tr></tbody></table></code></pre></figure>\n\n<p>The <code class=\"language-plaintext highlighter-rouge\">cost_df</code> dataframe accumulates the results for each run, which can then be plotted using ggplot2 (<a title=\"ggplot2 k-means elbow method gist\" href=\"https://gist.github.com/randyzwitch/6597905\" target=\"_blank\">ggplot2 Gist here</a>):</p>\n\n<p><img src=\"/wp-content/uploads/2013/09/elbow-plot.png\" alt=\"elbow-plot\" /></p>\n\n<p>The plot above is a technique known informally as the ‘elbow method’, where we are looking for breakpoints in our cost plot to understand where we should stop adding clusters. We can see that the slope of the cost function gets flatter at 10 clusters, then flatter again around 20 clusters. This means that as we add clusters above 10 (or 20), each additional cluster becomes less effective at reducing the distance from the each data center (i.e. reduces the variance less). So while we haven’t determined an absolute, single ‘best’ value of ‘k’, we have narrowed down a range of values for ‘k’ to evaluate.</p>\n\n<p>Ultimately, the best value of ‘k’ will be determined as a combination of a heuristic method like the ‘Elbow Method’, along with analyst judgement after looking at the results. Once you’ve determined your optimal cluster definitions, it’s trivial to calculate metrics such as Bounce Rate, Pageviews per Visit, Conversion Rate or Average Order Value to see how well the clusters actually describe different behaviors on-site.</p>\n\n<h2 id=\"summary\">Summary</h2>\n\n<p>K-means clustering is one of many unsupervised learning techniques that can be used to understand the underlying structure of a dataset. When used with text data, k-means clustering can provide a great way to organize the thousands-to-millions of words being used by your customers to describe their visits. Once you understand what your customers are trying to do, you can tailor your on-site experiences to match these needs, as well as adjusting your reporting/dashboards to monitor the various customer groups.</p>\n\n<p><em>EDIT: For those who want to play around with the code but don’t use Adobe Analytics, here is the <a title=\"search keyword file\" href=\"http://randyzwitch.com/wp-content/uploads/2013/09/searchkeywords_0913.csv\" target=\"_blank\">file of search keywords</a> I used. Once you read in the .csv file into a dataframe and name it searchkeywords, you should be able to replicate everything in this blog post.</em></p>"
}