{
  "title": "Denoising Dirty Documents: Part 8",
  "link": "https://colinpriest.com/2015/10/02/denoising-dirty-documents-part-8/",
  "comments": "https://colinpriest.com/2015/10/02/denoising-dirty-documents-part-8/#comments",
  "dc:creator": "Colin Priest",
  "pubDate": "Fri, 02 Oct 2015 13:58:47 +0000",
  "category": [
    "Image Processing",
    "Kaggle",
    "Machine Learning",
    "R"
  ],
  "guid": "http://colinpriest.com/?p=528",
  "description": "In this blog we will engineer a new feature to go into our model. So far we have predominantly been &#8230;<p><a href=\"https://colinpriest.com/2015/10/02/denoising-dirty-documents-part-8/\">Continue reading <span class=\"meta-nav\">&#8594;</span></a></p>",
  "content:encoded": "<p>In this blog we will engineer a new feature to go into our model. So far we have predominantly been using localised features &#8211; information about pixels that are located nearby the pixel whose brightness we are predicting. In this blog we will consider the structure of a document, and use that to improve our model.</p>\n<p><a href=\"https://colinpriestdotcom.files.wordpress.com/2015/08/20150801-after.png\"><img loading=\"lazy\" data-attachment-id=\"232\" data-permalink=\"https://colinpriest.com/2015/08/01/denoising-dirty-documents-part-1/20150801-after/\" data-orig-file=\"https://colinpriestdotcom.files.wordpress.com/2015/08/20150801-after.png\" data-orig-size=\"540,258\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"20150801 &#8211; after\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://colinpriestdotcom.files.wordpress.com/2015/08/20150801-after.png?w=300\" data-large-file=\"https://colinpriestdotcom.files.wordpress.com/2015/08/20150801-after.png?w=529\" class=\"alignnone size-medium wp-image-232\" src=\"https://colinpriestdotcom.files.wordpress.com/2015/08/20150801-after.png?w=300\" alt=\"20150801 - after\" width=\"300\" height=\"143\" srcset=\"https://colinpriestdotcom.files.wordpress.com/2015/08/20150801-after.png?w=300 300w, https://colinpriestdotcom.files.wordpress.com/2015/08/20150801-after.png?w=150 150w, https://colinpriestdotcom.files.wordpress.com/2015/08/20150801-after.png 540w\" sizes=\"(max-width: 300px) 100vw, 300px\" /></a></p>\n<p>The image consists of multiple lines of text, arranged into one or more paragraphs with multiple sentences in each paragraph.</p>\n<p><a href=\"https://colinpriestdotcom.files.wordpress.com/2015/09/ducks-lined-up.jpg\"><img loading=\"lazy\" data-attachment-id=\"529\" data-permalink=\"https://colinpriest.com/2015/10/02/denoising-dirty-documents-part-8/ducks-lined-up/\" data-orig-file=\"https://colinpriestdotcom.files.wordpress.com/2015/09/ducks-lined-up.jpg\" data-orig-size=\"1600,731\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"ducks lined up\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://colinpriestdotcom.files.wordpress.com/2015/09/ducks-lined-up.jpg?w=300\" data-large-file=\"https://colinpriestdotcom.files.wordpress.com/2015/09/ducks-lined-up.jpg?w=529\" class=\"alignnone size-medium wp-image-529\" src=\"https://colinpriestdotcom.files.wordpress.com/2015/09/ducks-lined-up.jpg?w=300\" alt=\"ducks lined up\" width=\"300\" height=\"137\" srcset=\"https://colinpriestdotcom.files.wordpress.com/2015/09/ducks-lined-up.jpg?w=300 300w, https://colinpriestdotcom.files.wordpress.com/2015/09/ducks-lined-up.jpg?w=600 600w, https://colinpriestdotcom.files.wordpress.com/2015/09/ducks-lined-up.jpg?w=150 150w\" sizes=\"(max-width: 300px) 100vw, 300px\" /></a></p>\n<p>If we get our ducks in a row, we can use the fact that the text (like our metaphorical ducks) is arranged into lines, and that there are gaps between those lines of text. In particular, if we can find the gaps between the lines, we can ensure that the predicted value within those gaps is always the background colour.</p>\n<p>Let&#8217;s look at the horizontal profile of a sample input image:</p>\n<pre class=\"brush: r; title: ; notranslate\">\n\n# libraries\nif (!require(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(png)\n\ndirtyFolder = \"C:\\\\Users\\\\Colin\\\\dropbox\\\\Kaggle\\\\Denoising Dirty Documents\\\\data\\\\train\"\n\nf = \"135.png\"\nimgX = readPNG(file.path(dirtyFolder, f))\n\nhProfileX = unlist(apply(imgX, 1, mean))\nhProfileY = unlist(apply(imgY, 1, mean))\n\nx = 1:nrow(imgX)\nplot(x, hProfileX, col=\"red\", type=\"l\", xlab = \"row\", ylab = \"brightness\")\n\n</pre>\n<p><a href=\"https://colinpriestdotcom.files.wordpress.com/2015/09/20150930-output-01.png\"><img loading=\"lazy\" data-attachment-id=\"532\" data-permalink=\"https://colinpriest.com/2015/10/02/denoising-dirty-documents-part-8/20150930-output-01/\" data-orig-file=\"https://colinpriestdotcom.files.wordpress.com/2015/09/20150930-output-01.png\" data-orig-size=\"672,672\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"20150930 output 01\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://colinpriestdotcom.files.wordpress.com/2015/09/20150930-output-01.png?w=300\" data-large-file=\"https://colinpriestdotcom.files.wordpress.com/2015/09/20150930-output-01.png?w=529\" class=\"alignnone size-medium wp-image-532\" src=\"https://colinpriestdotcom.files.wordpress.com/2015/09/20150930-output-01.png?w=300\" alt=\"20150930 output 01\" width=\"300\" height=\"300\" srcset=\"https://colinpriestdotcom.files.wordpress.com/2015/09/20150930-output-01.png?w=300 300w, https://colinpriestdotcom.files.wordpress.com/2015/09/20150930-output-01.png?w=600 600w, https://colinpriestdotcom.files.wordpress.com/2015/09/20150930-output-01.png?w=150 150w\" sizes=\"(max-width: 300px) 100vw, 300px\" /></a></p>\n<p>The rows with low brightness show where text occurs at regular intervals. But the absolute level of the row brightness varies, according to the noise and stains, so much that sometimes the gaps between the lines of text are darker than the rows in which text occurs. This will make it more difficult to determine which rows are which.</p>\n<p>But what if we used the predicted images from our <a href=\"https://colinpriest.com/2015/09/23/denoising-dirty-documents-part-7/\" target=\"_blank\">stacked model from the last blog</a> as the inputs to this predictor?</p>\n<pre class=\"brush: r; title: ; notranslate\">\n\n# libraries\nif (!require(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(png)\n\ndirtyFolder = \"C:\\\\Users\\\\Colin\\\\dropbox\\\\Kaggle\\\\Denoising Dirty Documents\\\\stacking\\\\stacked\"\n\nf = \"135.png\"\nimgX = readPNG(file.path(dirtyFolder, f))\n\nhProfileX = unlist(apply(imgX, 1, mean))\nhProfileY = unlist(apply(imgY, 1, mean))\n\nx = 1:nrow(imgX)\nplot(x, hProfileX, col=\"red\", type=\"l\", xlab = \"row\", ylab = \"brightness\")\n\n</pre>\n<p><a href=\"https://colinpriestdotcom.files.wordpress.com/2015/09/20150930-output-02.png\"><img loading=\"lazy\" data-attachment-id=\"533\" data-permalink=\"https://colinpriest.com/2015/10/02/denoising-dirty-documents-part-8/20150930-output-02/\" data-orig-file=\"https://colinpriestdotcom.files.wordpress.com/2015/09/20150930-output-02.png\" data-orig-size=\"672,672\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"20150930 output 02\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://colinpriestdotcom.files.wordpress.com/2015/09/20150930-output-02.png?w=300\" data-large-file=\"https://colinpriestdotcom.files.wordpress.com/2015/09/20150930-output-02.png?w=529\" class=\"alignnone size-medium wp-image-533\" src=\"https://colinpriestdotcom.files.wordpress.com/2015/09/20150930-output-02.png?w=300\" alt=\"20150930 output 02\" width=\"300\" height=\"300\" srcset=\"https://colinpriestdotcom.files.wordpress.com/2015/09/20150930-output-02.png?w=300 300w, https://colinpriestdotcom.files.wordpress.com/2015/09/20150930-output-02.png?w=600 600w, https://colinpriestdotcom.files.wordpress.com/2015/09/20150930-output-02.png?w=150 150w\" sizes=\"(max-width: 300px) 100vw, 300px\" /></a></p>\n<p>Now it&#8217;s much easier to find the gaps between the lines of text. To do this we need estimate three parameters:</p>\n<ol>\n<li>cycle length: the number of rows from one line of text to the next line of text</li>\n<li>gap length: the height of the gap between lines of text</li>\n<li>starting location of the first cycle</li>\n</ol>\n<p>The constraints that we can use for determining these parameters are:</p>\n<ul>\n<li>cycle length is a positive number</li>\n<li>gap length is a positive number</li>\n<li>gap length is less than cycle length</li>\n<li>gap rows are white</li>\n<li>most letters (e.g. weruioaszxcvnm) are short and these letters are located in the darkest rows, which we will call the &#8220;core rows&#8221;</li>\n<li>some letters are taller (e.g. tdfhklb) and create slightly darker rows above the core rows</li>\n<li>some letters are taller (e.g. qypgj) and create slightly darker rows below the core rows</li>\n<li>if we cluster the values, the darker cluster contains the core of the letters (the core rows), but these rows may be lighter when a paragraph starts or ends</li>\n<li>the in-between valued rows next to the white rows are possibly where the taller letters are located and their darkness will vary according to the number of tall letters</li>\n</ul>\n<p>Let&#8217;s start by clustering the row brightnesses, and checking where the rows switch from one cluster to another, and using this to estimate cycle length.</p>\n<pre class=\"brush: r; title: ; notranslate\">\n\nkm = kmeans(hProfileX, 2)\ncutoff = (max(hProfileX[km$cluster == which.min(km$centers)]) + min(hProfileX[km$cluster == which.max(km$centers)])) / 2\nplot(hProfileX, type=\"l\")\nlines(hProfileX * 0 + cutoff, col=\"red\")\n\nstarts = (2:length(hProfileX))[sapply(2:length(hProfileX), function(x) hProfileX[x] < cutoff & hProfileX[x-1] > cutoff)]\ncycleLength = mean(diff(starts))\n\n</pre>\n<p><a href=\"https://colinpriestdotcom.files.wordpress.com/2015/10/20150930-output-03.png\"><img loading=\"lazy\" data-attachment-id=\"539\" data-permalink=\"https://colinpriest.com/2015/10/02/denoising-dirty-documents-part-8/20150930-output-03/\" data-orig-file=\"https://colinpriestdotcom.files.wordpress.com/2015/10/20150930-output-03.png\" data-orig-size=\"672,672\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"20150930 output 03\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://colinpriestdotcom.files.wordpress.com/2015/10/20150930-output-03.png?w=300\" data-large-file=\"https://colinpriestdotcom.files.wordpress.com/2015/10/20150930-output-03.png?w=529\" class=\"alignnone size-medium wp-image-539\" src=\"https://colinpriestdotcom.files.wordpress.com/2015/10/20150930-output-03.png?w=300\" alt=\"20150930 output 03\" width=\"300\" height=\"300\" srcset=\"https://colinpriestdotcom.files.wordpress.com/2015/10/20150930-output-03.png?w=300 300w, https://colinpriestdotcom.files.wordpress.com/2015/10/20150930-output-03.png?w=600 600w, https://colinpriestdotcom.files.wordpress.com/2015/10/20150930-output-03.png?w=150 150w\" sizes=\"(max-width: 300px) 100vw, 300px\" /></a></p>\n<p><a href=\"https://colinpriestdotcom.files.wordpress.com/2015/10/20150930-output-04.png\"><img loading=\"lazy\" data-attachment-id=\"540\" data-permalink=\"https://colinpriest.com/2015/10/02/denoising-dirty-documents-part-8/20150930-output-04/\" data-orig-file=\"https://colinpriestdotcom.files.wordpress.com/2015/10/20150930-output-04.png\" data-orig-size=\"393,72\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"20150930 output 04\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://colinpriestdotcom.files.wordpress.com/2015/10/20150930-output-04.png?w=300\" data-large-file=\"https://colinpriestdotcom.files.wordpress.com/2015/10/20150930-output-04.png?w=393\" class=\"alignnone size-medium wp-image-540\" src=\"https://colinpriestdotcom.files.wordpress.com/2015/10/20150930-output-04.png?w=300\" alt=\"20150930 output 04\" width=\"300\" height=\"55\" srcset=\"https://colinpriestdotcom.files.wordpress.com/2015/10/20150930-output-04.png?w=300 300w, https://colinpriestdotcom.files.wordpress.com/2015/10/20150930-output-04.png?w=150 150w, https://colinpriestdotcom.files.wordpress.com/2015/10/20150930-output-04.png 393w\" sizes=\"(max-width: 300px) 100vw, 300px\" /></a></p>\n<p>Next we will estimate the starting location of the first cycle. But before we do that, we need to define the &#8220;start&#8221; of the cycle. Let&#8217;s define the cycle as starting at the row in which the first letter starts. That would be the first non-white row before the first core rows.</p>\n<p>cycleStarts = starts[1]<br />\nwhile (hProfileX[cycleStarts] < 0.99)<br />\n cycleStarts = cycleStarts &#8211; 1</p>\n<p>The first cycle starts at row 3.</p>\n<p>To estimate the gap length, we should measure the number of white rows before each cycle starts.</p>\n<pre class=\"brush: r; title: ; notranslate\">\n\ngaps = matrix(0, length(starts) - 1)\nfor (i in 2:length(starts))\n{\n cycleStarts = starts[i]\n while (hProfileX[cycleStarts] < 0.99)\n cycleStarts = cycleStarts - 1\n gapStarts = cycleStarts - 1\n while (hProfileX[gapStarts] > 0.99)\n gapStarts = gapStarts - 1\n gapLength = cycleStarts - gapStarts\n gaps[i - 1] = gapLength\n}\ngaps\n\n</pre>\n<p>The gaps are (13, 12, 17, 13, 12, 11, 12, 18, 12, 12). The two outliers occur after rows of text that do not contain any of the characters (q, y, p, g, j). After removing these two outliers, the gaps do not exceed 13 rows. So we can write code to allow for this as follows:</p>\n<pre class=\"brush: r; title: ; notranslate\">\n\nmGaps = median(gaps)\ngapLength = mean(gaps[abs(gaps - mGaps) <= 2])\n\n</pre>\n<p>This gives us a gap length estimate of 13.125 and completes our line location model for this image. The quick way to use this model is to white out the gap rows. A more complex model could use the newly estimated row types (core, gap, other) as predictors.</p>\n<pre class=\"brush: r; title: ; notranslate\">\n\nimgCleaned = imgX\nnumCycles = length(starts)\nfor (i in 1:numCycles)\n{\ncycleStart = starts[i] - min(gaps[abs(gaps - mGaps) <= 2])\nimgCleaned[cycleStart:(starts[i]-1)] = 1\n}\n\n</pre>\n<p>The script above would clean up any minor image blemishes that exist between the lines of text.</p>\n",
  "wfw:commentRss": "https://colinpriest.com/2015/10/02/denoising-dirty-documents-part-8/feed/",
  "slash:comments": 4,
  "media:thumbnail": "",
  "media:content": [
    {
      "media:title": "ducks lined up"
    },
    {
      "media:title": "colinpriest1966"
    },
    {
      "media:title": "20150801 - after"
    },
    {
      "media:title": "ducks lined up"
    },
    {
      "media:title": "20150930 output 01"
    },
    {
      "media:title": "20150930 output 02"
    },
    {
      "media:title": "20150930 output 03"
    },
    {
      "media:title": "20150930 output 04"
    }
  ]
}