{
  "title": "Improved Analysis of Score-based Generative Modeling: User-Friendly Bounds under Minimal Smoothness Assumptions. (arXiv:2211.01916v1 [cs.LG])",
  "link": "http://arxiv.org/abs/2211.01916",
  "description": "<p>In this paper, we focus on the theoretical analysis of diffusion-based\ngenerative modeling. Under an $L^2$-accurate score estimator, we provide\nconvergence guarantees with polynomial complexity for any data distribution\nwith second-order moment, by either employing an early stopping technique or\nassuming smoothness condition on the score function of the data distribution.\nOur result does not rely on any log-concavity or functional inequality\nassumption and has a logarithmic dependence on the smoothness. In particular,\nwe show that under only a finite second moment condition, approximating the\nfollowing in KL divergence in $\\epsilon$-accuracy can be done in $\\tilde\nO\\left(\\frac{d^2 \\log^2 (1/\\delta)}{\\epsilon^2}\\right)$ steps: 1) the\nvariance-$\\delta$ Gaussian perturbation of any data distribution; 2) data\ndistributions with $1/\\delta$-smooth score functions. Our theoretical analysis\nalso provides quantitative comparison between different discrete approximations\nand may guide the choice of discretization points in practice.\n</p>",
  "dc:creator": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hongrui Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Holden Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jianfeng Lu</a>"
}