{
  "title": "Useful Unix commands for data science",
  "link": "",
  "published": "2013-07-15T00:00:00-07:00",
  "updated": "2022-11-03T04:16:07-07:00",
  "author": {
    "name": "Greg Reda"
  },
  "id": "tag:www.gregreda.com,2013-07-15:/2013/07/15/unix-commands-for-data-science/",
  "summary": "<p>Imagine you have a 4.2GB CSV file.  It has over 12 million records and 50 columns.  All you need from this file is the sum of all values in one particular column.</p>\n<p>How would you do it?</p>\n<p>Writing a script in <a href=\"http://www.python.org/\">python</a>/<a href=\"http://www.ruby-lang.org/\">ruby</a>/<a href=\"http://www.perl.org/\">perl</a>/whatever would probably take a â€¦</p>",
  "content": "<p>Imagine you have a 4.2GB CSV file.  It has over 12 million records and 50 columns.  All you need from this file is the sum of all values in one particular column.</p>\n<p>How would you do it?</p>\n<p>Writing a script in <a href=\"http://www.python.org/\">python</a>/<a href=\"http://www.ruby-lang.org/\">ruby</a>/<a href=\"http://www.perl.org/\">perl</a>/whatever would probably take a few minutes and then even more time for the script to actually complete.  A <a href=\"http://en.wikipedia.org/wiki/Database\">database</a> and <a href=\"http://en.wikipedia.org/wiki/SQL\">SQL</a> would be fairly quick, but then you'd have load the data, which is kind of a pain.</p>\n<p>Thankfully, the <a href=\"http://en.wikipedia.org/wiki/List_of_Unix_utilities\">Unix utilities</a> exist and they're awesome.</p>\n<p>To get the sum of a column in a huge text file, we can easily use <a href=\"http://en.wikipedia.org/wiki/AWK_(programming_language)\">awk</a>.  And we won't even need to read the entire file into memory.</p>\n<p>Let's assume our data, which we'll call <em>data.csv</em>, is pipe-delimited ( | ), and we want to sum the fourth column of the file.</p>\n<div class=\"highlight\"><pre><span></span><code><span class=\"n\">cat</span> <span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">csv</span> <span class=\"o\">|</span> <span class=\"n\">awk</span> <span class=\"o\">-</span><span class=\"n\">F</span> <span class=\"s2\">&quot;|&quot;</span> <span class=\"s1\">&#39;{ sum += $4 } END { printf &quot;</span><span class=\"si\">%.2f</span><span class=\"se\">\\n</span><span class=\"s1\">&quot;, sum }&#39;</span>\n</code></pre></div>\n\n<p>The above line says:</p>\n<ol>\n<li>Use the <a href=\"http://en.wikipedia.org/wiki/Cat_(Unix)\">cat</a> command to stream (print) the contents of the file to <a href=\"http://en.wikipedia.org/wiki/Standard_streams\">stdout</a>.</li>\n<li><a href=\"http://en.wikipedia.org/wiki/Pipeline_(Unix)\">Pipe</a> the streaming contents from our cat command to the next one - awk. </li>\n<li>\n<p>With <a href=\"http://en.wikipedia.org/wiki/AWK_(programming_language)\">awk</a>:</p>\n<ol>\n<li>Set the field separator to the pipe character (-F \"|\"). Note that this has nothing to do with our pipeline in point #2.</li>\n<li>Increment the variable <em>sum</em> with the value in the fourth column ($4). Since we used a pipeline in point #2, the contents of each line are being streamed to this statement.</li>\n<li>Once the stream is done, print out the value of <em>sum</em>, using <a href=\"http://www.gnu.org/software/gawk/manual/html_node/Printf-Examples.html\">printf</a> to format the value with two decimal places.</li>\n</ol>\n</li>\n</ol>\n<p>It took less than two minutes to run on the entire file - much faster than other options and written in a lot fewer characters.</p>\n<p><a href=\"http://www.hilarymason.com\">Hilary Mason</a> and <a href=\"http://www.columbia.edu/~chw2/\">Chris Wiggins</a> wrote over at the <a href=\"http://www.dataists.com/\">dataists blog</a> about the importance of any <a href=\"http://www.dataists.com/2010/09/a-taxonomy-of-data-science/\">data scientist being familiar with the command line</a>, and I couldn't agree with them more.  The command line is essential to my daily work, so I wanted to share some of the commands I've found most useful.</p>\n<p>For those who are a bit newer to the command line than the rest of this post assumes, Hilary previously wrote a <a href=\"http://www.hilarymason.com/articles/intro-to-the-linux-command-line/\">nice introduction to it</a>.</p>\n<h3>Other commands</h3>\n<h4><a href=\"http://en.wikipedia.org/wiki/Head_(Unix)\">head</a> &amp; <a href=\"http://en.wikipedia.org/wiki/Tail_(Unix)\">tail</a></h4>\n<p>Sometimes you just need to inspect the structure of a huge file.  That's where <a href=\"http://en.wikipedia.org/wiki/Head_(Unix)\">head</a> and <a href=\"http://en.wikipedia.org/wiki/Tail_(Unix)\">tail</a> come in.  Head prints the first ten lines of a file, while tail prints the last ten lines.  Optionally, you can include the <em>-N</em> parameter to change the number of lines displayed.</p>\n<div class=\"highlight\"><pre><span></span><code><span class=\"n\">head</span> <span class=\"o\">-</span><span class=\"n\">n</span> <span class=\"mi\">3</span> <span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">csv</span>\n<span class=\"c1\"># time|away|score|home</span>\n<span class=\"c1\"># 20:00||0-0|Jump Ball won by Virginia Commonwealt.</span>\n<span class=\"c1\"># 19:45||0-0|Juvonte Reddic Turnover.</span>\n\n<span class=\"n\">tail</span> <span class=\"o\">-</span><span class=\"n\">n</span> <span class=\"mi\">3</span> <span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">csv</span>\n<span class=\"c1\"># 0:14|Trey Davis Turnover.|62-71|</span>\n<span class=\"c1\"># 0:14||62-71|Briante Weber Steal.</span>\n<span class=\"c1\"># 0:00|End Game|End Game|End Game</span>\n</code></pre></div>\n\n<h4><a href=\"http://en.wikipedia.org/wiki/Wc_(Unix)\">wc</a> (word count)</h4>\n<p>By default, <a href=\"http://en.wikipedia.org/wiki/Wc_(Unix)\">wc</a> will quickly tell you how many lines, words, and bytes are in a file.  If you're looking for just the line count, you can pass the <em>-l</em> parameter in.</p>\n<p>I use it most often to verify record counts between files or database tables throughout an analysis.</p>\n<div class=\"highlight\"><pre><span></span><code><span class=\"n\">wc</span> <span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">csv</span>\n<span class=\"c1\">#     377    1697   17129 data.csv</span>\n<span class=\"n\">wc</span> <span class=\"o\">-</span><span class=\"n\">l</span> <span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">csv</span>\n<span class=\"c1\">#     377 data.csv</span>\n</code></pre></div>\n\n<h4><a href=\"http://en.wikipedia.org/wiki/Grep\">grep</a></h4>\n<p><a href=\"http://en.wikipedia.org/wiki/Grep\">Grep</a> allows you to search through plain text files using <a href=\"http://en.wikipedia.org/wiki/Regular_expression\">regular expressions</a>.  I tend <a href=\"http://regex.info/blog/2006-09-15/247\">avoid regular expressions</a> when possible, but still find grep to be invaluable when searching through log files for a particular event.</p>\n<p>There's an assortment of extra parameters you can use with grep, but the ones I tend to use the most are <em>-i</em> (ignore case), <em>-r</em> (recursively search directories), <em>-B N</em> (N lines before), <em>-A N</em> (N lines after).</p>\n<div class=\"highlight\"><pre><span></span><code><span class=\"n\">grep</span> <span class=\"o\">-</span><span class=\"n\">i</span> <span class=\"o\">-</span><span class=\"n\">B</span> <span class=\"mi\">1</span> <span class=\"o\">-</span><span class=\"n\">A</span> <span class=\"mi\">1</span> <span class=\"n\">steal</span> <span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">csv</span>\n<span class=\"c1\"># 17:25||2-4|Darius Theus Turnover.</span>\n<span class=\"c1\"># 17:25|Terrell Vinson Steal.|2-4|</span>\n<span class=\"c1\"># 17:18|Chaz Williams made Layup.  Assisted by Terrell Vinson.|4-4|</span>\n</code></pre></div>\n\n<h4><a href=\"http://en.wikipedia.org/wiki/Sed\">sed</a></h4>\n<p><a href=\"http://en.wikipedia.org/wiki/Sed\">Sed</a> is similar to <a href=\"http://en.wikipedia.org/wiki/Grep\">grep</a> and <a href=\"http://en.wikipedia.org/wiki/AWK_(programming_language)\">awk</a> in many ways, however I find that I most often use it when needing to do some find and replace magic on a very large file.  The usual occurrence is when I've received a CSV file that was generated on Windows and my <a href=\"http://stackoverflow.com/questions/6373888/converting-newline-formatting-from-mac-to-windows\">Mac isn't able to handle the carriage return</a> properly.</p>\n<div class=\"highlight\"><pre><span></span><code><span class=\"n\">grep</span> <span class=\"n\">Block</span> <span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">csv</span> <span class=\"o\">|</span> <span class=\"n\">head</span> <span class=\"o\">-</span><span class=\"n\">n</span> <span class=\"mi\">3</span>\n<span class=\"c1\"># 16:43||5-4|Juvonte Reddic Block.</span>\n<span class=\"c1\"># 15:37||7-6|Troy Daniels Block.</span>\n<span class=\"c1\"># 14:05|Raphiael Putney Block.|11-8|</span>\n\n<span class=\"n\">sed</span> <span class=\"o\">-</span><span class=\"n\">e</span> <span class=\"s1\">&#39;s/Block/Rejection/g&#39;</span> <span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">csv</span> <span class=\"o\">&gt;</span> <span class=\"n\">rejection</span><span class=\"o\">.</span><span class=\"n\">csv</span>\n<span class=\"c1\"># replace all instances of the word &#39;Block&#39; in data.csv with &#39;Rejection&#39;</span>\n<span class=\"c1\"># stream the results to a new file called rejection.csv</span>\n\n<span class=\"n\">grep</span> <span class=\"n\">Rejection</span> <span class=\"n\">rejection</span><span class=\"o\">.</span><span class=\"n\">csv</span> <span class=\"o\">|</span> <span class=\"n\">head</span> <span class=\"o\">-</span><span class=\"n\">n</span> <span class=\"mi\">3</span>\n<span class=\"c1\"># 16:43||5-4|Juvonte Reddic Rejection.</span>\n<span class=\"c1\"># 15:37||7-6|Troy Daniels Rejection.</span>\n<span class=\"c1\"># 14:05|Raphiael Putney Rejection.|11-8|</span>\n</code></pre></div>\n\n<h4><a href=\"http://en.wikipedia.org/wiki/Sort_(Unix)\">sort</a> &amp; <a href=\"http://en.wikipedia.org/wiki/Uniq\">uniq</a></h4>\n<p><a href=\"http://en.wikipedia.org/wiki/Sort_(Unix)\">Sort</a> outputs the lines of a file in order based on a column key using the <em>-k</em> parameter.  If a key isn't specified, sort will treat each line as a concatenated string and sort based on the values of the first column.  The <em>-n</em> and <em>-r</em> parameters allow you to sort numerically and in reverse order, respectively.</p>\n<div class=\"highlight\"><pre><span></span><code><span class=\"n\">head</span> <span class=\"o\">-</span><span class=\"n\">n</span> <span class=\"mi\">5</span> <span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">csv</span>\n<span class=\"c1\"># time|away|score|home</span>\n<span class=\"c1\"># 20:00||0-0|Jump Ball won by Virginia Commonwealt.</span>\n<span class=\"c1\"># 19:45||0-0|Juvonte Reddic Turnover.</span>\n<span class=\"c1\"># 19:45|Chaz Williams Steal.|0-0|</span>\n<span class=\"c1\"># 19:39|Sampson Carter missed Layup.|0-0|</span>\n\n<span class=\"n\">head</span> <span class=\"o\">-</span><span class=\"n\">n</span> <span class=\"mi\">5</span> <span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">csv</span> <span class=\"o\">|</span> <span class=\"n\">sort</span>\n<span class=\"c1\"># 19:39|Sampson Carter missed Layup.|0-0|</span>\n<span class=\"c1\"># 19:45|Chaz Williams Steal.|0-0|</span>\n<span class=\"c1\"># 19:45||0-0|Juvonte Reddic Turnover.</span>\n<span class=\"c1\"># 20:00||0-0|Jump Ball won by Virginia Commonwealt.</span>\n<span class=\"c1\"># time|away|score|home</span>\n\n<span class=\"c1\"># columns separated by &#39;|&#39;, sort on column 2 (-k2), case insensitive (-f)</span>\n<span class=\"n\">head</span> <span class=\"o\">-</span><span class=\"n\">n</span> <span class=\"mi\">5</span> <span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">csv</span> <span class=\"o\">|</span> <span class=\"n\">sort</span> <span class=\"o\">-</span><span class=\"n\">f</span> <span class=\"o\">-</span><span class=\"n\">t</span><span class=\"s1\">&#39;|&#39;</span> <span class=\"o\">-</span><span class=\"n\">k2</span>\n<span class=\"c1\"># time|away|score|home</span>\n<span class=\"c1\"># 19:45|Chaz Williams Steal.|0-0|</span>\n<span class=\"c1\"># 19:39|Sampson Carter missed Layup.|0-0|</span>\n<span class=\"c1\"># 20:00||0-0|Jump Ball won by Virginia Commonwealt.</span>\n<span class=\"c1\"># 19:45||0-0|Juvonte Reddic Turnover.</span>\n</code></pre></div>\n\n<p>Sometimes you want to check for duplicate records in a large text file - that's when <a href=\"http://en.wikipedia.org/wiki/Uniq\">uniq</a> comes in handy.  By using the <em>-c</em> parameter, uniq will output the count of occurrences along with the line.  You can also use the <em>-d</em> and <em>-u</em> parameters to output only duplicated or unique records.</p>\n<div class=\"highlight\"><pre><span></span><code><span class=\"n\">sort</span> <span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">csv</span> <span class=\"o\">|</span> <span class=\"n\">uniq</span> <span class=\"o\">-</span><span class=\"n\">c</span> <span class=\"o\">|</span> <span class=\"n\">sort</span> <span class=\"o\">-</span><span class=\"n\">nr</span> <span class=\"o\">|</span> <span class=\"n\">head</span> <span class=\"o\">-</span><span class=\"n\">n</span> <span class=\"mi\">7</span>\n<span class=\"c1\">#   2 8:47|Maxie Esho missed Layup.|46-54|</span>\n<span class=\"c1\">#   2 8:47|Maxie Esho Offensive Rebound.|46-54|</span>\n<span class=\"c1\">#   2 7:38|Trey Davis missed Free Throw.|51-56|</span>\n<span class=\"c1\">#   2 12:12||16-11|Rob Brandenberg missed Free Throw.</span>\n<span class=\"c1\">#   1 time|away|score|home</span>\n<span class=\"c1\">#   1 9:51||20-11|Juvonte Reddic Steal.</span>\n\n<span class=\"n\">sort</span> <span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">csv</span> <span class=\"o\">|</span> <span class=\"n\">uniq</span> <span class=\"o\">-</span><span class=\"n\">d</span>\n<span class=\"c1\"># 12:12||16-11|Rob Brandenberg missed Free Throw.</span>\n<span class=\"c1\"># 7:38|Trey Davis missed Free Throw.|51-56|</span>\n<span class=\"c1\"># 8:47|Maxie Esho Offensive Rebound.|46-54|</span>\n<span class=\"c1\"># 8:47|Maxie Esho missed Layup.|46-54|</span>\n\n<span class=\"n\">sort</span> <span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">csv</span> <span class=\"o\">|</span> <span class=\"n\">uniq</span> <span class=\"o\">-</span><span class=\"n\">u</span> <span class=\"o\">|</span> <span class=\"n\">wc</span> <span class=\"o\">-</span><span class=\"n\">l</span>\n<span class=\"c1\">#     369 (unique lines)</span>\n</code></pre></div>\n\n<p>While it's sometimes difficult to remember all of the parameters for the Unix commands, getting familiar with them has been beneficial to my productivity and allowed me to avoid many headaches when working with large text files.</p>\n<p>Hopefully you'll find them as useful as I have.</p>\n<p><em>Additional Resources:</em></p>\n<ul>\n<li><a href=\"http://www.drbunsen.org/explorations-in-unix/\">Explorations in Unix</a> by <a href=\"http://www.drbunsen.org/\">Seth Brown</a></li>\n<li><a href=\"http://www.ceri.memphis.edu/computer/docs/unix/bshell.htm\">An Introduction to the Unix Shell</a></li>\n<li><a href=\"http://blog.comsysto.com/2013/04/25/data-analysis-with-the-unix-shell/\">Data Analysis with the Unix Shell</a></li>\n<li><a href=\"http://jeroenjanssens.com/2013/09/19/seven-command-line-tools-for-data-science.html\">7 Command Line Tools for Data Science</a></li>\n</ul>",
  "category": [
    "",
    "",
    "",
    "",
    "",
    "",
    ""
  ]
}