{
  "title": "End-to-end deep multi-score model for No-reference stereoscopic image quality assessment. (arXiv:2211.01374v1 [eess.IV])",
  "link": "http://arxiv.org/abs/2211.01374",
  "description": "<p>Deep learning-based quality metrics have recently given significant\nimprovement in Image Quality Assessment (IQA). In the field of stereoscopic\nvision, information is evenly distributed with slight disparity to the left and\nright eyes. However, due to asymmetric distortion, the objective quality\nratings for the left and right images would differ, necessitating the learning\nof unique quality indicators for each view. Unlike existing stereoscopic IQA\nmeasures which focus mainly on estimating a global human score, we suggest\nincorporating left, right, and stereoscopic objective scores to extract the\ncorresponding properties of each view, and so forth estimating stereoscopic\nimage quality without reference. Therefore, we use a deep multi-score\nConvolutional Neural Network (CNN). Our model has been trained to perform four\ntasks: First, predict the left view's quality. Second, predict the quality of\nthe left view. Third and fourth, predict the quality of the stereo view and\nglobal quality, respectively, with the global score serving as the ultimate\nquality. Experiments are conducted on Waterloo IVC 3D Phase 1 and Phase 2\ndatabases. The results obtained show the superiority of our method when\ncomparing with those of the state-of-the-art. The implementation code can be\nfound at: https://github.com/o-messai/multi-score-SIQA\n</p>",
  "dc:creator": "<a href=\"http://arxiv.org/find/eess/1/au:+Messai_O/0/1/0/all/0/1\">Oussama Messai</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chetouani_A/0/1/0/all/0/1\">Aladine Chetouani</a>"
}