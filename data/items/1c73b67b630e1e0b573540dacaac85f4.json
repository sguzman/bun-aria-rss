{
  "title": "Generating Stories about Images",
  "link": "https://medium.com/@samim/generating-stories-about-images-d163ba41e4ed?source=rss-f3c8148878e1------2",
  "guid": "https://medium.com/p/d163ba41e4ed",
  "category": [
    "artificial-intelligence",
    "machine-learning"
  ],
  "dc:creator": "samim",
  "pubDate": "Thu, 05 Nov 2015 21:52:08 GMT",
  "atom:updated": "2015-12-12T18:38:02.204Z",
  "content:encoded": "<h4>Recurrent neural network for generating stories about images</h4><p>Stories are a fundamental human tool that we use to communicate thought. Creating a stories about a image is a difficult task that many struggle with. New machine-learning experiments are enabling us to generate stories based on the content of images.<strong> </strong>This experiment explores <strong>how to generate <em>little romantic stories about images</em> (incl. guest star <em>Taylor Swift).</em></strong></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*rUzuHpOqB8q1cRjsl65rmw.jpeg\" /></figure><h3>neural-storyteller</h3><p><strong>neural-storyteller</strong> is a recently published experiment by <a href=\"https://github.com/ryankiros\">Ryan Kiros</a> (University of Toronto). It combines <em>recurrent neural networks (RNN), </em><a href=\"http://arxiv.org/pdf/1506.06726v1.pdf\">skip-thoughts vectors</a> and other techniques to generate <em>little story about images</em>. Neural-storyteller’s<strong> </strong>outputs are <em>creative and </em>often <em>comedic. </em>It is <a href=\"https://github.com/ryankiros/neural-storyteller\">open-source</a>.</p><h3>Experiment</h3><p>This experiment started by running 5000 randomly selected web-images through neural-storyteller and experimenting with hyper-parameters. <strong>neural-storyteller </strong>comes with 2 pre-trained models: One trained on 14 million passages of <a href=\"http://www.cs.toronto.edu/~mbweb/\">romance novels</a>, the other trained on<em> Taylor Swift Lyrics</em>. Inputs and outputs were manually filtered and recombined into two videos.</p><h4>Generating Romance</h4><p>Using Romantic Novel Model. Voices generated with a Text-to-Speech.</p><iframe src=\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fwww.youtube.com%2Fembed%2FpKDzKzDnwtQ%3Ffeature%3Doembed&url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DpKDzKzDnwtQ&image=https%3A%2F%2Fi.ytimg.com%2Fvi%2FpKDzKzDnwtQ%2Fhqdefault.jpg&key=d04bfffea46d4aeda930ec88cc64b87c&type=text%2Fhtml&schema=youtube\" width=\"854\" height=\"480\" frameborder=\"0\" scrolling=\"no\"><a href=\"https://medium.com/media/802b75b6a55dc7a09004bb2d37c1cdf3/href\">https://medium.com/media/802b75b6a55dc7a09004bb2d37c1cdf3/href</a></iframe><h4>Generating Taylor Swift</h4><p>Using Taylor Swift Model. Combined with a well known Swift instrumental.</p><iframe src=\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fwww.youtube.com%2Fembed%2FcersRTtjFcU%3Ffeature%3Doembed&url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DcersRTtjFcU&image=https%3A%2F%2Fi.ytimg.com%2Fvi%2FcersRTtjFcU%2Fhqdefault.jpg&key=d04bfffea46d4aeda930ec88cc64b87c&type=text%2Fhtml&schema=youtube\" width=\"854\" height=\"480\" frameborder=\"0\" scrolling=\"no\"><a href=\"https://medium.com/media/0c18cbef8e777d5b10ee0eaa43f4a041/href\">https://medium.com/media/0c18cbef8e777d5b10ee0eaa43f4a041/href</a></iframe><h3>How does it work?</h3><ol><li>Train a recurrent neural network (<a href=\"https://en.wikipedia.org/wiki/Recurrent_neural_network\">RNN</a>) decoder on romance novels.</li><li>Each passage from a novel is mapped to a <a href=\"http://arxiv.org/pdf/1506.06726v1.pdf\">skip-thought vector</a>.</li><li>Conditions RNN on skip-thought vector & generate the encoded passage.</li><li>Train a visual-semantic embedding between <a href=\"http://mscoco.org/\">COCO</a> images and captions. <em>Captions and images are mapped into a common vector space.</em></li><li>After training, embed new images and retrieve captions.</li></ol><h3>A selection of generated stories</h3><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*aVVktwEOz_BjX8eFu3ewHQ.jpeg\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*brmI0US0cs00qwg4y0lMvg.jpeg\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*CCF_gTs16d_FmosXZAb_UA.jpeg\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*BCC0mvK6eMFWbkUC-fZYWw.jpeg\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*ZLXqCT1_K7R5L7wZT6VFEQ.jpeg\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*KqmeCjamtIz227I-aKLqQg.jpeg\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*eeEGqvq20wRxSC1D2QKuEQ.jpeg\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*fVJkGqSwdqveRSWmL9ff4g.jpeg\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*WQzbzkvLb7GKjkM6T1wOJw.jpeg\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*nCLRnwgQef3Fv98ctv3mfQ.jpeg\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*c8eKdZpvqCFcRjq_0dHozA.jpeg\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*B2gtOWUWUl4_9cvk4btg8g.jpeg\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*63kjGm-IX1mBUnHJR3tIkw.jpeg\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*iXcpxBIth0IgXGhU-pmWhA.jpeg\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*RvhRVuSw85ymK1K2Po9aag.jpeg\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*H--j4jWVw-iR0YK5Ed8MPw.jpeg\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*zQlAprPoLmbZlxNeTVARgw.jpeg\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*-gBgp67CDBWJZeeNFR-BDg.jpeg\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*8vG3p8ra8qMIjkewD3pPOQ.jpeg\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*DmKmcYzGjGhFYf0m77ROqQ.jpeg\" /></figure><h3>Final thoughts</h3><p>neural-storyteller gives us a fascinating glimpse into the future of storytelling. Even though these technologies are not fully mature yet, the art of storytelling is bound to change. In the near future, <strong>authors will be</strong> <strong>training</strong> custom models, <strong>combining</strong> styles across genres and <strong>generating</strong> text with images & sounds. Exploring this exiting new medium is rewarding!</p><blockquote>Get in touch here: <a href=\"https://twitter.com/samim\">twitter.com/samim</a> |<a href=\"http://samim.io/\">http://samim.io</a></blockquote><blockquote><a href=\"https://tinyletter.com/samim\">Sign up for the Newsletter for more experiments like this!</a></blockquote><h3>Follow up discussions</h3><h3>Hendrik on Twitter</h3><p>@samim Another great experiment! Though I think the future of storytelling will be interactive machine learning & aided associative thinking</p><h3>yoav goldberg on Twitter</h3><p>@samim public-service reminder: it is the readers who put meaning into the images and the associated generated verse. not the algorithms.</p><h3>samim on Twitter</h3><p>@yoavgo exactly! thats the fun bit :-)</p><h3>Mario Klingemann on Twitter</h3><p>@samim I wonder when authors are starting to sue for \"stealing\" samples? How many consecutive words constitute plagiarism?</p><h3>samim on Twitter</h3><p>https://t.co/X5nFXBoJIs</p><h3>samim on Twitter</h3><p>@azeem requested running this photo through neural-storyteller, there u go ;-) cc @mpshanahan @AndrewYNg @ylecun pic.twitter.com/cKrn98jezP</p><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=d163ba41e4ed\" width=\"1\" height=\"1\" alt=\"\">"
}