{
  "title": "Better than BERT:  Pick your best model",
  "link": "https://calculatedcontent.com/2022/07/22/better-than-bert-pick-your-best-model/",
  "comments": "https://calculatedcontent.com/2022/07/22/better-than-bert-pick-your-best-model/#respond",
  "dc:creator": "Charles H Martin, PhD",
  "pubDate": "Fri, 22 Jul 2022 19:05:40 +0000",
  "category": "Uncategorized",
  "guid": "http://calculatedcontent.com/?p=14535",
  "description": "Have you ever had to sort through HuggingFace to find your best model ? There are over 54,000 models on &#8230; <a class=\"more-link\" href=\"https://calculatedcontent.com/2022/07/22/better-than-bert-pick-your-best-model/\">More</a>",
  "content:encoded": "\n<p>Have you ever had to sort through HuggingFace to find your best model ?  There are over 54,000 models on HuggingFace!  So it&#8217;s not an easy task.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"alignleft size-large is-resized\"><a href=\"https://charlesmartin14.files.wordpress.com/2022/07/image.png\"><img loading=\"lazy\" data-attachment-id=\"14539\" data-permalink=\"https://calculatedcontent.com/2022/07/22/better-than-bert-pick-your-best-model/image-5/\" data-orig-file=\"https://charlesmartin14.files.wordpress.com/2022/07/image.png\" data-orig-size=\"1226,675\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"image\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://charlesmartin14.files.wordpress.com/2022/07/image.png?w=300\" data-large-file=\"https://charlesmartin14.files.wordpress.com/2022/07/image.png?w=1024\" src=\"https://charlesmartin14.files.wordpress.com/2022/07/image.png?w=1024\" alt=\"\" class=\"wp-image-14539\" width=\"236\" height=\"129\" srcset=\"https://charlesmartin14.files.wordpress.com/2022/07/image.png?w=234 234w, https://charlesmartin14.files.wordpress.com/2022/07/image.png?w=469 469w, https://charlesmartin14.files.wordpress.com/2022/07/image.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2022/07/image.png?w=300 300w\" sizes=\"(max-width: 236px) 100vw, 236px\" /></a></figure></div>\n\n\n<p>Most people just choose the most popular model&#8211;and this is usually BERT.  Or some BERT variant.  Bert was created by Google, so it must be good.  </p>\n\n\n\n<p>But is BERT the really best choice for you ?  </p>\n\n\n\n<p>How can you find out ? You can search through the literature, read blogs, ask on Reddit, etc, and try to find a better model.  This is time consuming and imperfect.  Fortunately, there is a better way.</p>\n\n\n\n<p class=\"has-text-align-center\">The <a href=\"https://weightwatcher.ai\" target=\"_blank\" rel=\"noreferrer noopener\">weightwatcher</a> tool can tell you.</p>\n\n\n\n<p>WeightWatcher is an open-source, data-free diagnostic tool that can estimate the quality of an DNN model like BERT, GPT, etc&#8211;without needing any data!  (No training or test data&#8211;just the weights).   It has been featured in <a rel=\"noreferrer noopener\" href=\"https://jmlr.org/papers/v22/20-410.html\" target=\"_blank\">JMLR</a>, at ICML and KDD, and even in <a rel=\"noreferrer noopener\" href=\"https://www.nature.com/articles/s41467-021-24025-8\" target=\"_blank\">Nature</a>.</p>\n\n\n\n<p>Here&#8217;s an example using weightwatcher to compare of 3 NLP models: <mark style=\"background-color:rgba(0, 0, 0, 0);color:#181fc6;\" class=\"has-inline-color\"><strong>BERT</strong></mark>, <mark style=\"background-color:rgba(0, 0, 0, 0);color:#d51e1e;\" class=\"has-inline-color\"><strong>RoBERTa</strong></mark>, and <mark style=\"background-color:rgba(0, 0, 0, 0);color:#2d820a;\" class=\"has-inline-color\"><strong>XNLet</strong></mark> </p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-large is-resized\"><a href=\"https://charlesmartin14.files.wordpress.com/2022/07/image-1.png\"><img loading=\"lazy\" data-attachment-id=\"14541\" data-permalink=\"https://calculatedcontent.com/2022/07/22/better-than-bert-pick-your-best-model/image-1-3/\" data-orig-file=\"https://charlesmartin14.files.wordpress.com/2022/07/image-1.png\" data-orig-size=\"1342,746\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"image-1\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://charlesmartin14.files.wordpress.com/2022/07/image-1.png?w=300\" data-large-file=\"https://charlesmartin14.files.wordpress.com/2022/07/image-1.png?w=1024\" src=\"https://charlesmartin14.files.wordpress.com/2022/07/image-1.png?w=1024\" alt=\"\" class=\"wp-image-14541\" width=\"528\" height=\"293\" srcset=\"https://charlesmartin14.files.wordpress.com/2022/07/image-1.png?w=1024 1024w, https://charlesmartin14.files.wordpress.com/2022/07/image-1.png?w=528 528w, https://charlesmartin14.files.wordpress.com/2022/07/image-1.png?w=1054 1054w, https://charlesmartin14.files.wordpress.com/2022/07/image-1.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2022/07/image-1.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2022/07/image-1.png?w=768 768w\" sizes=\"(max-width: 528px) 100vw, 528px\" /></a></figure></div>\n\n\n<p>The WeightWatcher Power-Law (PL) metric <em>alpha</em> <img src=\"https://s0.wp.com/latex.php?latex=%28%5Calpha%29&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%28%5Calpha%29&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28%5Calpha%29&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"(&#92;alpha)\" class=\"latex\" /> is a DNN model quality metric; smaller is better.  This plot above displays all the layer <em>alpha</em> <img src=\"https://s0.wp.com/latex.php?latex=%28%5Calpha%29&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%28%5Calpha%29&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28%5Calpha%29&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"(&#92;alpha)\" class=\"latex\" /> values for the 3 models.  It is immediately clear that the<mark style=\"background-color:rgba(0, 0, 0, 0);color:#2d820a;\" class=\"has-inline-color\"> <strong>XNLet layers</strong> </mark>look much better than <mark style=\"background-color:rgba(0, 0, 0, 0);color:#181fc6;\" class=\"has-inline-color\"><strong>BERT</strong></mark> or <mark style=\"background-color:rgba(0, 0, 0, 0);color:#d51e1e;\" class=\"has-inline-color\"><strong>RoBERTa</strong></mark>; the <em>alpha</em> <img src=\"https://s0.wp.com/latex.php?latex=%28%5Calpha%29&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%28%5Calpha%29&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28%5Calpha%29&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"(&#92;alpha)\" class=\"latex\" /> values are smaller on average, and  there are no <em>alpha</em>s larger than 5: <img src=\"https://s0.wp.com/latex.php?latex=%28%5Calpha+%3C%3D5%29&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%28%5Calpha+%3C%3D5%29&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28%5Calpha+%3C%3D5%29&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"(&#92;alpha <=5)\" class=\"latex\" />.  In contrast, the <mark style=\"background-color:rgba(0, 0, 0, 0);\" class=\"has-inline-color\"><strong style=\"color:rgb(24, 31, 198);\">BERT</strong></mark> and <mark style=\"background-color:rgba(0, 0, 0, 0);color:#d51e1e;\" class=\"has-inline-color\"><strong>RoBERTa</strong></mark> alphas are much larger on average, and both models have too many large <em>alphas</em>.  </p>\n\n\n\n<p>This is totally consistent with the published results.: <a rel=\"noreferrer noopener\" href=\"https://arxiv.org/abs/1906.08237\" target=\"_blank\">In the original paper (from Microsoft Research)</a>,  XLNet outperforms BERT on 20 different NLP tasks.  </p>\n\n\n\n<p><strong>Do it yourself:</strong></p>\n\n\n\n<p>WeightWatcher will work with any HuggingFace Transformer (or CV) model.</p>\n\n\n\n<p><a href=\"https://github.com/CalculatedContent/WeightWatcher/blob/master/examples/WW-BERT-BlogExample.ipynb\" target=\"_blank\" rel=\"noreferrer noopener\">Here is a Google Colab notebook that lets you reproduce this yourself</a></p>\n\n\n\n<p>Give it a try.   And if you need help with AI, ML, or just Data Science, please reach out. I provide strategy consulting, data science leadership, and hands-on, heads-down development. I will have availability in Q3 2022 for new projects. Reach out today.&nbsp;<a href=\"https://www.linkedin.com/feed/hashtag/?keywords=talktochuck&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A6941808930264150016\">#talkToChuck</a>&nbsp;<a href=\"https://www.linkedin.com/feed/hashtag/?keywords=theaiguy&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A6941808930264150016\">#theAIguy</a></p>\n",
  "wfw:commentRss": "https://calculatedcontent.com/2022/07/22/better-than-bert-pick-your-best-model/feed/",
  "slash:comments": 0,
  "media:thumbnail": "",
  "media:content": [
    {
      "media:title": "image-1"
    },
    {
      "media:title": "charlesmartin14"
    },
    "",
    ""
  ]
}