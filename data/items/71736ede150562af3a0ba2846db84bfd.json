{
  "id": "yt:video:_DYQdP_F-LA",
  "yt:videoId": "_DYQdP_F-LA",
  "yt:channelId": "UCBa5G_ESCn8Yd4vw5U-gIcg",
  "title": "Stanford Seminar - ML Explainability Part 1 I Overview and Motivation for Explainability",
  "link": "",
  "author": {
    "name": "Stanford Online",
    "uri": "https://www.youtube.com/channel/UCBa5G_ESCn8Yd4vw5U-gIcg"
  },
  "published": "2022-11-02T23:51:00+00:00",
  "updated": "2022-11-02T23:58:42+00:00",
  "media:group": {
    "media:title": "Stanford Seminar - ML Explainability Part 1 I Overview and Motivation for Explainability",
    "media:content": "",
    "media:thumbnail": "",
    "media:description": "In the first segment of the workshop, Professor Hima Lakkaraju motivates the need for interpretable machine learning in order to diagnose and build trust in autonomous systems.\n\nProfessor Hima Lakkaraju's day-long workshop at Stanford covered modern techniques for interpretable machine learning. \n\nAbout the speaker: Himabindu (Hima) Lakkaraju is an assistant professor at Harvard University focusing on explainability, fairness, and robustness of machine learning models. She has also been working with various domain experts in policy and healthcare to understand the real-world implications of explainable and fair ML. Hima has been named as one of the worldâ€™s top innovators under 35 by both MIT Tech Review and Vanity Fair. Her research has also received best paper awards at SIAM International Conference on Data Mining (SDM) and INFORMS, and grants from NSF, Google, Amazon, and Bayer. Hima has given keynote talks at various top ML conferences and workshops including CIKM, ICML, NeurIPS, AAAI, and CVPR, and her research has also been showcased by popular media outlets including the New York Times, MIT Tech Review, TIME magazine, and Forbes. More recently, she co-founded the Trustworthy ML Initiative to enable easy access to resources on trustworthy ML and to build a community of researchers/practitioners working on the topic. Learn more on her website: https://himalakkaraju.github.io/\n\nView the full playlist: https://www.youtube.com/playlist?list=PLoROMvodv4rPh6wa6PGcHH6vMG9sEIPxL",
    "media:community": {
      "media:starRating": "",
      "media:statistics": ""
    }
  }
}