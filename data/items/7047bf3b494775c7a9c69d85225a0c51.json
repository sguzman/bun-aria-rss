{
  "title": "Towards glass-box CNNs. (arXiv:2101.10443v2 [cs.CV] UPDATED)",
  "link": "http://arxiv.org/abs/2101.10443",
  "description": "<p>Convolution neural networks (CNNs) are brain-inspired architectures popular\nfor their ability to train and relearn visually complex tasks. It is\nincremental and scalable; however, CNN is mostly treated as black-box and\ninvolves multiple trial &amp; error runs. We observe that CNN constructs powerful\ninternal representations that help achieve state-of-the-art performance. Here\nwe propose three layer glass-box (analytical) CNN for two-class image\nclassifcation problems. First is a representation layer that encompasses both\nthe class information (group invariant) and symmetric transformations (group\nequivariant) of input images. It is then passed through dimension reduction\nlayer (PCA). Finally the compact yet complete representation is provided to a\nclassifer. Analytical machine learning classifers and multilayer perceptrons\nare used to assess sensitivity. Proposed glass-box CNN is compared with\nequivariance of AlexNet (CNN) internal representation for better understanding\nand dissemination of results. In future, we would like to construct glass-box\nCNN for multiclass visually complex tasks.\n</p>",
  "dc:creator": "<a href=\"http://arxiv.org/find/cs/1/au:+Manaswini_P/0/1/0/all/0/1\">Piduguralla Manaswini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhatt_J/0/1/0/all/0/1\">Jignesh S. Bhatt</a>"
}