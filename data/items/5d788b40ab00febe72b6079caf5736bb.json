{
  "title": "PyData and the GIL",
  "link": "",
  "updated": "2015-03-10T00:00:00+00:00",
  "id": "https://mrocklin.github.io/blog/work/2015/03/10/PyData-GIL",
  "content": "<p><em>This work is supported by <a href=\"http://continuum.io\">Continuum Analytics</a>\nand the <a href=\"http://www.darpa.mil/program/XDATA\">XDATA Program</a>\nas part of the <a href=\"http://blaze.pydata.org\">Blaze Project</a></em></p>\n\n<p><strong>tl;dr</strong> Many PyData projects release the GIL.  Multi-core parallelism is\nalive and well.</p>\n\n<h2 id=\"introduction\">Introduction</h2>\n\n<p>Machines grow more cores every year.  My cheap laptop has four cores and a\nheavy workstation rivals a decent cluster without the hardware hassle.  When I\nbring this up in conversation people often ask about <em>the GIL</em> and whether or\nnot this poses a problem to the PyData ecosystem and shared-memory parallelism.</p>\n\n<p>Q: <em>Given the growth of shared-memory parallelism, should the PyData ecosystem\n    be concerned about the GIL?</em></p>\n\n<p>A: <em>No, we should be very excited about this growth.  We’re well poised to\n    exploit it.</em></p>\n\n<p>For those who aren’t familiar, the Global Interpreter Lock (GIL) is a\nCPython feature/bug that stops threads from manipulating Python objects in\nparallel.  This cripples Pure Python shared-memory parallelism.</p>\n\n<p>This sounds like a big deal but it doesn’t really affect the PyData stack\n(NumPy/Pandas/SciKits).  Most PyData projects don’t spend much time in Python\ncode.  They spend 99% of their time in C/Fortran/Cython code.  This code can\noften release the GIL.  The following projects release the GIL at various\nstages:</p>\n\n<ul>\n  <li>NumPy</li>\n  <li>SciPy</li>\n  <li>Numba (<a href=\"http://numba.pydata.org/numba-doc/0.17.0/user/jit.html#nogil\">if requested</a>)\n(<a href=\"http://numba.pydata.org/numba-doc/dev/user/examples.html#multi-threading\">example docs</a>)</li>\n  <li>SciKit Learn</li>\n  <li>Anything that mostly uses the above projects</li>\n  <li><em>if you add more in the comments then I will post them here</em></li>\n</ul>\n\n<p>Our software stack has roots in scientific computing which has an amazing\nrelationship with using all-of-the-hardware.  I would like to see the\ndevelopment community lean in to the use of shared-memory parallelism.  This\nfeels like a large low-hanging fruit.</p>\n\n<h2 id=\"quick-example-with-daskarray\">Quick Example with dask.array</h2>\n\n<p>As a quick example, we compute a large random dot product with\n<a href=\"http://dask.pydata.org/\">dask.array</a> and look at <code class=\"language-plaintext highlighter-rouge\">top</code>.  Dask.array computes\nlarge array operations by breaking arrays up in to many small NumPy arrays and\nthen executing those array operations in multiple threads.</p>\n\n<figure class=\"highlight\">\n  <pre><code class=\"language-python\" data-lang=\"python\"><span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]:</span> <span class=\"kn\">import</span> <span class=\"nn\">dask.array</span> <span class=\"k\">as</span> <span class=\"n\">da</span>\n\n<span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">]:</span> <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">da</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">((</span><span class=\"mi\">10000</span><span class=\"p\">,</span> <span class=\"mi\">10000</span><span class=\"p\">),</span> <span class=\"n\">blockshape</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">1000</span><span class=\"p\">,</span> <span class=\"mi\">1000</span><span class=\"p\">))</span>\n\n<span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">]:</span> <span class=\"nb\">float</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">.</span><span class=\"n\">dot</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">.</span><span class=\"n\">T</span><span class=\"p\">).</span><span class=\"nb\">sum</span><span class=\"p\">())</span>\n<span class=\"n\">Out</span><span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">]:</span> <span class=\"mf\">250026827523.19141</span></code></pre>\n</figure>\n\n<p><img src=\"https://mrocklin.github.io/blog/images/350percent-cpu-usage-alpha.png\" alt=\"Full resource utilization with Python\" /></p>\n\n<p><em>Technical note: my BLAS is set to use one thread only, the parallelism in the\nabove example is strictly due to multiple Python worker threads, and not due to\nparallelism in the underlying native code.</em></p>\n\n<p>Note the 361.0% CPU utilization in the <code class=\"language-plaintext highlighter-rouge\">ipython</code> process.</p>\n\n<p>Because the PyData stack is fundamentally based on native compiled code,\nmultiple Python threads can crunch data in parallel without worrying about the\nGIL.  The GIL does not have to affect us in a significant way.</p>\n\n<h2 id=\"thats-not-true-the-gil-hurts-python-in-the-following-cases\">That’s not true, the GIL hurts Python in the following cases</h2>\n\n<h3 id=\"text\">Text</h3>\n\n<p>We don’t have a good C/Fortran/Cython solution for text. When given a\npile-of-text-files we often switch from threads to processes and use the\n<code class=\"language-plaintext highlighter-rouge\">multiprocessing</code> module.  This limits inter-worker communication but this is\nrarely an issue for this kind of embarrassingly parallel work.</p>\n\n<p>The multiprocessing workflow is fairly simple.  I’ve written about this in the\n<a href=\"http://toolz.readthedocs.org/en/latest/parallelism.html\">toolz docs</a> and in a\nblogpost about\n<a href=\"http://matthewrocklin.com/blog/work/2015/02/17/Towards-OOC-Bag/\">dask.bag</a>.</p>\n\n<h3 id=\"pandas\">Pandas</h3>\n\n<p>Pandas does not yet release the GIL in computationally intensive code.\nIt probably could though.  This requires momentum from the community and some\ngrunt-work by some of the Pandas devs.  I have a small issue\n<a href=\"https://github.com/pydata/pandas/issues/8882\">here</a> and I think that <a href=\"https://github.com/cpcloud\">Phil\nCloud</a> is looking into it.</p>\n\n<h2 id=\"pydata-3-shared-memory-parallelism\">PyData &lt;3 Shared Memory Parallelism</h2>\n\n<p>If you’re looking for more speed in compute-bound applications then consider\nthreading and heavy workstation machines.  I personally find this approach to\nbe more convenient than spinning up a cluster.</p>"
}