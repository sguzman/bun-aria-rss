{
  "title": "The Fair Price to Pay a Spy: An Introduction to the Value of Information",
  "link": "",
  "published": "2016-01-09T22:30:00+00:00",
  "updated": "2016-01-09T22:30:00+00:00",
  "author": {
    "name": "Sebastian Nowozin"
  },
  "id": "tag:www.nowozin.net,2016-01-09:/sebastian/blog/the-fair-price-to-pay-a-spy-an-introduction-to-the-value-of-information.html",
  "summary": "<p><img alt=\"Spy image\" src=\"http://www.nowozin.net/sebastian/blog/images/voi-spy-illustration.png\"></p>\n<p>(This article covers the decision-theoretic concept of <em>value of information</em>\nthrough a classic example.)</p>\n<p>What is the value of a piece of information?</p>\n<p>It depends.\nTwo factors determine the value of information:\nfirst, whether the information is new to you â€¦</p>",
  "content": "<p><img alt=\"Spy image\" src=\"http://www.nowozin.net/sebastian/blog/images/voi-spy-illustration.png\"></p>\n<p>(This article covers the decision-theoretic concept of <em>value of information</em>\nthrough a classic example.)</p>\n<p>What is the value of a piece of information?</p>\n<p>It depends.\nTwo factors determine the value of information:\nfirst, whether the information is new to you;\nsecond, whether the information causes you to change your decisions.</p>\n<p>The first point is immediately clear as you would be unwilling to pay a reward\nfor information which you already know.\nInformation is understood here in the sense of probabilistic knowledge\nrepresented by a probability distribution.  As such, if the information keeps\nyour beliefs unchanged, it cannot have any value.</p>\n<p>The second point is more subtle.\nOnly decisions and actions can have value, information itself has only\nindirect value through the decisions and actions that it influences.\nThe consequence of a decision is a realized utility which can be both positive\nor negative.\nAs a simple monetary example, imagine you buy a share of a company.  Then the\nutility is a function of the change in the share price.  Information such as\ninsider information can lead to a belief that the share price will drop, thus\nleading to the decision to sell the share and realize the utility.\nIf the information I learn about the company does not change my decision\nwhether to sell the share or not, then it also cannot change the utility.\nTherefore <em>value</em> is understood as a subjective but quantitative utility that\nis realized at decision time.</p>\n<h2>The Fair Price to Pay a Spy</h2>\n<p>The following example is from one of the important papers on decision theory\nand decision analysis, now in its 50th anniversary year(!),\n<a href=\"http://dx.doi.org/10.1109/TSSC.1966.300074\">(Howard, \"Information Value Theory\",\n1966)</a>.\nUnfortunately the paper is behind a paywall, but I will keep the presentation\nbelow self-contained and also took the liberty to update the exotic notation\nused in the paper to a more modern form.</p>\n<p>Imagine you run a construction company and the government advertises a\ncontract to build a large development.\nThe bidding happens via a lowest price closed bidding, where every construction company submits a price for which they would construct the development in a technically acceptable manner.\nYou do not see any competing bids and the lowest-price bid wins.</p>\n<p>Leaving moral and legal concerns aside, how much would you pay a spy to reveal\nto you the lowest competing bid prior to you making your bid?\nWe will follow <a href=\"https://profiles.stanford.edu/ronald-howard\">Ronald Howard</a> in\nanswering this question using decision theory, thus putting a monetary value\non a piece of information.</p>\n<p>The following are the key quantities in this problem:</p>\n<ul>\n<li><span class=\"math\">\\(E\\)</span>, the expense to your company in constructing the development.  It is a\n  random variable.</li>\n<li><span class=\"math\">\\(L\\)</span>, the lowest price among all competing bids.  It is a random variable.</li>\n<li><span class=\"math\">\\(B\\)</span>, your bid.  It is a decision variable under your control, not a random\n  variable.</li>\n<li><span class=\"math\">\\(V\\)</span>, the profit you realize, a random variable.</li>\n</ul>\n<p>The situation is represented using <a href=\"https://en.wikipedia.org/wiki/Influence_diagram\">influence\ndiagrams</a> in the following\nfigure.  (Incidentally influence diagrams were also first formally published\nby Ronald Howard in (Howard and Matheson, \"Influence diagrams\", 1981), and a\nnice historical piece on them is available from Judea Pearl in <a href=\"http://ftp.cs.ucla.edu/pub/stat_ser/r326.pdf\">(Pearl,\n\"Influence Diagrams - Historical and Personal Perspectives\",\n2005)</a>.)</p>\n<p><img alt=\"Influence diagram for the construction company\" src=\"http://www.nowozin.net/sebastian/blog/images/voi-spy.png\"></p>\n<p>In the diagram the round nodes represent random variables, just like in\ndirected graphical models (Bayesian networks).\nThe rectangular node represents a decision node under our control, here the\nbid <span class=\"math\">\\(B\\)</span> we submit.\nThe diamond shaped utility node represents a value achieved, in our case the\nprofit <span class=\"math\">\\(V\\)</span>.\nThe above diagram is not enough, we need to specify how our profit <span class=\"math\">\\(V\\)</span> comes\nabout.</p>\n<p>The first step in applying decision theory is to assume that everything is\nknown.  So let us assume <span class=\"math\">\\(B\\)</span>, <span class=\"math\">\\(E\\)</span>, <span class=\"math\">\\(L\\)</span> are known.\nThen, it is easy to see whether we actually won the contract, i.e. whether\nour bid is small enough, <span class=\"math\">\\(B &lt; L\\)</span>.  If <span class=\"math\">\\(B \\geq L\\)</span>, we do not obtain the\ncontract and the profit is zero.  (We assume here, for simplicity, that the\ncost for making the bid is zero.)\nIf we won the bid, that is, if <span class=\"math\">\\(B &lt; L\\)</span> is true, then the profit is simply the\nbid price minus our expenses, <span class=\"math\">\\(B - E\\)</span>.\nTherefore we have the profit as a function of <span class=\"math\">\\(B\\)</span>, <span class=\"math\">\\(E\\)</span>, and <span class=\"math\">\\(L\\)</span> as\n</p>\n<div class=\"math\">$$V = \\left\\{\\begin{array}{cl}0,&amp;\\textrm{if $B \\geq L$,}\\\\\nB-E,&amp;\\textrm{if $B &lt; L$.}\\end{array}\\right.$$</div>\n<p>\nThe above expression can also be written using indicator notation as\n<span class=\"math\">\\(V = \\mathbb{1}_{\\{B &lt; L\\}} \\cdot (B-E)\\)</span>.</p>\n<p>But <span class=\"math\">\\(B\\)</span>, <span class=\"math\">\\(E\\)</span>, <span class=\"math\">\\(L\\)</span> are not known.  The second step in applying decision theory\nis therefore to take expectations with respect to everything that is unknown\n(<span class=\"math\">\\(E\\)</span> and <span class=\"math\">\\(L\\)</span> in our case) and to maximize utility with respect to all\ndecisions (<span class=\"math\">\\(B\\)</span> in our case).\nWe do this in two steps.  Let us first assume <span class=\"math\">\\(B\\)</span> is fixed.  Then we take the\nexpectation of the above expression with respect to the unknown <span class=\"math\">\\(E\\)</span> and <span class=\"math\">\\(L\\)</span>,</p>\n<div class=\"math\">$$\\mathbb{E}[V | B] = \\mathbb{E}_{E,L}[\\mathbb{1}_{\\{B &lt; L\\}} \\cdot (B-E)].$$</div>\n<p>Now we further assume independence of the cost <span class=\"math\">\\(E\\)</span> and the lowest competing\nbid <span class=\"math\">\\(L\\)</span>, that is <span class=\"math\">\\(P(E,L) = P(E) \\, P(L)\\)</span>, a reasonable assumption.\nHere is an example visualization of priors\n<span class=\"math\">\\(P(E) = \\textrm{Gamma}(\\textrm{Shape}=80,\\textrm{Scale}=6)\\)</span> and\n<span class=\"math\">\\(P(L) = \\mathcal{N}(\\mu=1100, \\sigma=120)\\)</span>.  </p>\n<p><img alt=\"Priors of cost and lowest bid\" src=\"http://www.nowozin.net/sebastian/blog/images/voi-example.svg\"></p>\n<p>Assuming independence we obtain</p>\n<div class=\"math\">\\begin{eqnarray}\n\\mathbb{E}[V | B] &amp; = &amp; \\mathbb{E}_{E,L}[\\mathbb{1}_{\\{B &lt; L\\}} \\cdot (B-E)]\\nonumber\\\\\n&amp; = &amp; P(B &lt; L) (B - \\mathbb{E}_E[E]).\\label{eqn:VgivenB}\n\\end{eqnarray}</div>\n<p>The expression (\\ref{eqn:VgivenB}) is intuitive: the expected profit is given\nby the probability of winning the bidding times the difference between bid and\nexpected cost.\nHere is a visualization for the above priors, with our bid <span class=\"math\">\\(B\\)</span> on the\nhorizontal axis.</p>\n<p><img alt=\"Expected profit as a function of our bid\" src=\"http://www.nowozin.net/sebastian/blog/images/voi-expectedprofit.svg\"></p>\n<p>You can see three regimes: 1. When <span class=\"math\">\\(P(B &lt; L)\\)</span> is very large (up to about\n<span class=\"math\">\\(B=850\\)</span>) the expected profit behaves linearly as <span class=\"math\">\\(B-\\mathbb{E}_E[E]\\)</span>, and if\nwe bid below our actual cost we realize a negative profit (loss).\n2. When <span class=\"math\">\\(P(B &lt; L)\\)</span> is very small (above <span class=\"math\">\\(B=1300\\)</span>) the expected profit drops to\nzero.  3. Between <span class=\"math\">\\(B=850\\)</span> and <span class=\"math\">\\(B=1300\\)</span> we see the product expression resulting\nin a nonlinear profit as a function of B.</p>\n<p>To finish the second step of applying decision theory we have to maximize\n(\\ref{eqn:VgivenB}) over our decision <span class=\"math\">\\(B\\)</span>, yielding</p>\n<div class=\"math\">$$\\mathbb{E}[V] = \\max_{B} \\mathbb{E}[V|B].$$</div>\n<p>This tells us how to bid without the help of a spy:\nin the above example figures, we obtain an expected profit\n<span class=\"math\">\\(\\mathbb{E}[V] = 421.8\\)</span> for a bid of <span class=\"math\">\\(B=966.2\\)</span>.</p>\n<p>Revealing <span class=\"math\">\\(L\\)</span> gives a large competitive advantage, but how much would we be\nwilling to pay a spy for this information?\nTo this end Howard introduces the concept of <em>clairvoyance</em> and\n<em>value of information</em>.</p>\n<p>In <em>clairvoyance</em> we consider what could happen if a clairvoyant appears and\noffers us perfect information about <span class=\"math\">\\(L\\)</span>.\nIf we would know <span class=\"math\">\\(L\\)</span> we can compute as before</p>\n<div class=\"math\">\\begin{eqnarray}\n\\mathbb{E}[V | B, L] &amp; = &amp; P(B &lt; L) (B - \\mathbb{E}_E[E])\\nonumber\\\\\n&amp; = &amp; \\mathbb{1}_{\\{B &lt; L\\}} (B - \\mathbb{E}_E[E]),\\nonumber\n\\end{eqnarray}</div>\n<p>\nwhere the probability <span class=\"math\">\\(P(B &lt; L)\\)</span> is now deterministic one or zero as <span class=\"math\">\\(B\\)</span> is\nour decision and <span class=\"math\">\\(L\\)</span> is known.\nAs <span class=\"math\">\\(B\\)</span> is our decision we again maximize over it.\n</p>\n<div class=\"math\">\\begin{eqnarray}\n\\mathbb{E}[V | L] &amp; = &amp; \\max_B \\mathbb{E}[V | B,L]\\nonumber\\\\\n&amp; = &amp; \\max_B \\mathbb{1}_{\\{B &lt; L\\}} (B - \\mathbb{E}_E[E])\\nonumber\\\\\n&amp; = &amp; \\left\\{\\begin{array}{cl}L - \\mathbb{E}_E[E], &amp; \\textrm{if $L &gt;\n\\mathbb{E}_E[E]$,}\\\\\n0, &amp; \\textrm{otherwise (do not bid).}\\end{array}\\right.\\nonumber\n\\end{eqnarray}</div>\n<p>\nThe last step can be seen as follows: our bid <span class=\"math\">\\(B\\)</span> should be above\nour expected expenses <span class=\"math\">\\(\\mathbb{E}_E[E]\\)</span> otherwise we would incur a negative\nprofit but <span class=\"math\">\\(B\\)</span> should also be as high as possible just below <span class=\"math\">\\(L\\)</span>.  Hence if\nthis is impossible (<span class=\"math\">\\(L \\leq \\mathbb{E}_E[E]\\)</span>) we do not bid.  Otherwise we bid\n<span class=\"math\">\\(B=L-\\epsilon\\)</span> and realize the expected profit <span class=\"math\">\\(L-\\mathbb{E}_E[E]\\)</span>.</p>\n<p>Ok, so this tells us how to bid when we know <span class=\"math\">\\(L\\)</span>.  But we do not know <span class=\"math\">\\(L\\)</span> yet.\nInstead we would like to put a value on the information about <span class=\"math\">\\(L\\)</span>.\nWe do this by integrating out <span class=\"math\">\\(L\\)</span>,</p>\n<div class=\"math\">$$\\mathbb{E}_L[\\mathbb{E}[V|L]]$$</div>\n<p>(Howard introduces a special notation for\nthe above expression, but I am not a fan of it and will omit it here.)</p>\n<p>The <em>value of information</em> (value of <span class=\"math\">\\(L\\)</span>) is now defined as</p>\n<div class=\"math\">$$\\textrm{EVPI}(L) = \\mathbb{E}_L[\\mathbb{E}[V|L]] - \\mathbb{E}[V].$$</div>\n<p>This quantity is again intuitive: the value of knowing <span class=\"math\">\\(L\\)</span> is the expected\ndifference between the utility achieved with knowledge of <span class=\"math\">\\(L\\)</span> and the expected\nutility achieved without such knowledge.</p>\n<p>The abbreviation <span class=\"math\">\\(\\textrm{EVPI}\\)</span> denotes the <a href=\"https://en.wikipedia.org/wiki/Expected_value_of_perfect_information\"><em>expected value of perfect\ninformation</em></a>,\na term that was introduced later and has become standard in decision analysis.</p>\n<p>So how much is the knowledge of <span class=\"math\">\\(L\\)</span> worth in our example?\nWe compute </p>\n<div class=\"math\">$$\\mathbb{E}_L[\\mathbb{E}[V|L]] \\approx 620.0$$</div>\n<p> with Monte Carlo\nand we had <span class=\"math\">\\(\\mathbb{E}[V] = 421.8\\)</span> from earlier, hence\n</p>\n<div class=\"math\">$$\\textrm{EVPI}(L) \\approx 620.0 - 421.8 = 198.2,$$</div>\n<p>\nis the maximum price we should pay our spy for telling us <span class=\"math\">\\(L\\)</span> exactly.</p>\n<h2>The Fair Price to Pay an Expert</h2>\n<p>The above was the original scenario described in Howard's paper.\nIn practice obtaining perfect knowledge is often infeasible.\nBut the above reasoning extends easily to the general case where we only\nobtain partial information.</p>\n<p>Here is an example for our setup: consider that we can ask an expert to\nprovide us an estimate <span class=\"math\">\\(L'\\)</span> of what the lowest bid <span class=\"math\">\\(L\\)</span> could be.</p>\n<p><img alt=\"Expert advice\" src=\"http://www.nowozin.net/sebastian/blog/images/voi-experts-lovelornpoets.jpg\"></p>\n<p>By assuming a probability model <span class=\"math\">\\(P(L' | L)\\)</span> we can relate the true unknown\nlowest bid <span class=\"math\">\\(L\\)</span> to the experts guess.</p>\n<p>The influence diagram looks as follows:</p>\n<p><img alt=\"Influence diagram for the construction company with expert advice\" src=\"http://www.nowozin.net/sebastian/blog/images/voi-expert.png\"></p>\n<h3>Recipe for Value of Information Computation</h3>\n<p>To understand how the above derivation extends to this case, let us state a\nrecipe of computing value of information:</p>\n<ol>\n<li>State the expected utility, conditioned on <em>decisions</em> and the <em>information\nto be valued</em>.</li>\n<li>Maximize the expression of step 1 over all <em>decisions</em>.</li>\n<li>Marginalize the expression of step 2 over the <em>information to be valued</em>,\nusing your prior beliefs.  The resulting expression is the expected utility\nwith information.</li>\n<li>Start over: state the expected utility, conditioned only on <em>decisions</em>.</li>\n<li>Maximize the expression of step 4 over all <em>decisions</em>.  The resulting\nexpression is the expected utility without information.</li>\n<li>Compute the value of information as the difference between the two expected\nutilities (step 3 minus step 5).</li>\n</ol>\n<p>This recipe works for any single-step decision problem, and any potential\ndifficulties are computational.</p>\n<h3>Application of the Recipe to our Example</h3>\n<p>Here is its application to our generalized example:</p>\n<ol>\n<li>This is <span class=\"math\">\\(\\mathbb{E}[V | L', B]\\)</span> which is obtained by marginalizing over <span class=\"math\">\\(E\\)</span>\nand <span class=\"math\">\\(L\\)</span> in <span class=\"math\">\\(\\mathbb{E}[V | L', B, E, L]\\)</span> and the marginal of <span class=\"math\">\\(L\\)</span> is <span class=\"math\">\\(P(L|L')\\)</span>\nobtained by Bayes rule.</li>\n<li>Maximize over <span class=\"math\">\\(B\\)</span>, obtaining <span class=\"math\">\\(\\max_B \\mathbb{E}[V | L', B]\\)</span>.</li>\n<li>Take the expectation over <span class=\"math\">\\(L'\\)</span>, which is defined via <span class=\"math\">\\(P(L') = \\mathbb{E}_{L}[P(L'|L)]\\)</span>, yielding\n<div class=\"math\">\\begin{equation}\n\\mathbb{E}_{L'}[\\max_B \\mathbb{E}[V | L', B]]\\label{eqn:Ltick-withinfo}\n\\end{equation}</div>\n</li>\n<li>This is <span class=\"math\">\\(\\mathbb{E}[V | B]\\)</span> which is obtained by marginalizing over <span class=\"math\">\\(E\\)</span> and\n<span class=\"math\">\\(L\\)</span>, here the marginal of <span class=\"math\">\\(L\\)</span> is the prior <span class=\"math\">\\(P(L)\\)</span>.</li>\n<li>Maximize over <span class=\"math\">\\(B\\)</span>, obtaining\n<div class=\"math\">\\begin{equation}\n\\max_B \\mathbb{E}[V | B].\\label{eqn:Ltick-withoutinfo}\n\\end{equation}</div>\n</li>\n<li>The value of information is the difference between (\\ref{eqn:Ltick-withinfo}) and (\\ref{eqn:Ltick-withoutinfo}),\n<div class=\"math\">$$\n\\textrm{EVPI}(L') = \\mathbb{E}_{L'}[\\max_B \\mathbb{E}[V | L', B]] - \\max_B \\mathbb{E}[V | B].$$</div>\n</li>\n</ol>\n<p>To make the above example concrete, let us assume that our expert is unbiased\nand we have\n</p>\n<div class=\"math\">$$P(L'|L) = \\mathcal{N}(L, \\sigma),$$</div>\n<p>\nwhere <span class=\"math\">\\(\\sigma &gt; 0\\)</span> is the standard deviation.\nComputing <span class=\"math\">\\(\\textrm{EVPI}(L')\\)</span> as a function of <span class=\"math\">\\(\\sigma\\)</span> is possible by solving\nthe maximization and integration problems.</p>\n<p>Using the same parameters as before and using Monte Carlo for the integration,\nhere is a visualization of the fair price to pay our expert.</p>\n<p><img alt=\"Price for expert advice as a function of expert reliability\" src=\"http://www.nowozin.net/sebastian/blog/images/voi-expert-confidence.svg\"></p>\n<p>We can see that for <span class=\"math\">\\(\\sigma \\to 0\\)</span> we recover the previous case of perfect\ninformation as the expert provides increasingly accurate knowledge about <span class=\"math\">\\(L\\)</span>\nwhen <span class=\"math\">\\(\\sigma\\)</span> decreases.\nConversely, with increasing expert uncertainty the value of his expert advice\ndecreases.</p>\n<h2>Computation</h2>\n<p>(This was added in April 2016 after the original article was published.)</p>\n<p>Computing the EVPI can be challenging because in many cases both the\nmaximization problem and the expectation are intractable analytically and\nsample-based Monte Carlo approximations induce a non-negligible bias.</p>\n<p>The recent work of <a href=\"http://arxiv.org/abs/1604.01120\">(Takashi Goda, \"Unbiased Monte Carlo estimation for the\nexpected value of partial perfect information\",\narXiv:1604.01120)</a> addresses part of the\ncomputation diffulties by application of a randomly truncated series to\nde-bias the ordinary Monte Carlo estimate.\nI have not performed any experiments but it seems to be a potentially useful\nmethod in the context of value of information computation problems.</p>\n<h2>Summary</h2>\n<p>From a formal decision theory point of view the <em>value of information</em> does not\noccupy a special place.  It just measures the difference between two different\nexpected utilities, given optimal decisions.</p>\n<p>But <em>value of information</em> appears frequently in almost any statistical\ndecision task.\nHere are two more examples.</p>\n<p>In <em>active learning</em> we are interested in minimizing the amount of supervision\nneeded to learn to perform a task and we can obtain supervision (ground truth\nclass labels, for example) for instances of our choice at a cost.\nBy applying value of information we can select for supervision the instances\nwhose revealed label information brings the highest expected increase in\nutility.</p>\n<p>In <em>experimental design</em> we have to make choices about which information to\nacquire, such as the number of patients to sample in a medical trial, or what\ninformation to collect at different costs in a customer survey.\nValue of information provides a way to make these choices, both statically, or\nbetter, adaptively.</p>\n<h3>Limitations</h3>\n<p>While decision theory is rather uncontroversial, it is a normative theory,\nthat is, it tells you how to derive decisions which are optimal and coherent\n(rational).\nThere are two main limitations I would like to point out:</p>\n<ol>\n<li>As a normative theory it cannot claim to be a description of how humans (or\nother intelligent agents) make decisions.</li>\n<li>It assumes infinite reasoning resources on behalf of the acting agent.</li>\n</ol>\n<p>Both limitations are related of course in that real intelligent agents may\ndeviate from normative decision theory precisely because they are limited in\ntheir reasoning abilities.\nThere are both normative and descriptive theories to address these\nlimitations.\nOn the normative side we have for example <a href=\"http://web.mit.edu/sjgershm/www/GershmanHorvitzTenenbaum15.pdf\">computational\nrationality</a>,\ntaking into account the computational costs of reasoning and deriving optimal\ndecisions within these constraints.\nOn the descriptive side we have for example <a href=\"https://en.wikipedia.org/wiki/Prospect_theory\">prospect\ntheory</a>, aiming to describe\nhuman decision making.</p>\n<h3>Further Reading</h3>\n<p>A great introduction to decision theory, including value of information, is\nthe very accessible\n<a href=\"http://eu.wiley.com/WileyCDA/WileyTitle/productCd-047149657X.html\">(Parmigiani and Inoue, \"Decision Theory: Principles and Approaches\",\n2009)</a>.</p>\n<p>Three classic textbooks on decision theoretic topics are\n<a href=\"http://eu.wiley.com/WileyCDA/WileyTitle/productCd-047168029X.html\">(DeGroot, \"Optimal Statistical Decisions\",\n1970)</a>,\n<a href=\"http://www.springer.com/us/book/9780387960982\">(Berger, \"Statistical Decision Theory and Bayesian Analysis\",\n1985)</a>, and\n<a href=\"http://eu.wiley.com/WileyCDA/WileyTitle/productCd-047138349X.html\">(Raiffa and Schlaifer, \"Applied Statistical Decision Theory\",\n1961)</a>\n(available as outrageously priced reprint-paperback by Wiley).</p>\n<p><em>Acknowledgements</em>.  The expert image is CC-BY-2.0 licensed art by\n<a href=\"https://www.flickr.com/photos/lovelornpoets/6214449310/\">lovelornpoets</a>.</p>\n<script type=\"text/javascript\">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {\n    var align = \"center\",\n        indent = \"0em\",\n        linebreak = \"false\";\n\n    if (false) {\n        align = (screen.width < 768) ? \"left\" : align;\n        indent = (screen.width < 768) ? \"0em\" : indent;\n        linebreak = (screen.width < 768) ? 'true' : linebreak;\n    }\n\n    var mathjaxscript = document.createElement('script');\n    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';\n    mathjaxscript.type = 'text/javascript';\n    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';\n\n    var configscript = document.createElement('script');\n    configscript.type = 'text/x-mathjax-config';\n    configscript[(window.opera ? \"innerHTML\" : \"text\")] =\n        \"MathJax.Hub.Config({\" +\n        \"    config: ['MMLorHTML.js'],\" +\n        \"    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } },\" +\n        \"    jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" +\n        \"    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" +\n        \"    displayAlign: '\"+ align +\"',\" +\n        \"    displayIndent: '\"+ indent +\"',\" +\n        \"    showMathMenu: true,\" +\n        \"    messageStyle: 'normal',\" +\n        \"    tex2jax: { \" +\n        \"        inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" +\n        \"        displayMath: [ ['$$','$$'] ],\" +\n        \"        processEscapes: true,\" +\n        \"        preview: 'TeX',\" +\n        \"    }, \" +\n        \"    'HTML-CSS': { \" +\n        \"        availableFonts: ['STIX', 'TeX'],\" +\n        \"        preferredFont: 'STIX',\" +\n        \"        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" +\n        \"        linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" +\n        \"    }, \" +\n        \"}); \" +\n        \"if ('default' !== 'default') {\" +\n            \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" +\n                \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" +\n                \"VARIANT['normal'].fonts.unshift('MathJax_default');\" +\n                \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" +\n                \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" +\n                \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" +\n            \"});\" +\n            \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" +\n                \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" +\n                \"VARIANT['normal'].fonts.unshift('MathJax_default');\" +\n                \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" +\n                \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" +\n                \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" +\n            \"});\" +\n        \"}\";\n\n    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);\n    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);\n}\n</script>",
  "category": ""
}