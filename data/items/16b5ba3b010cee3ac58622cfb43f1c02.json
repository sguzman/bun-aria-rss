{
  "title": "Java Image Cat&#038;Dog Recognition with Deep Neural Networks",
  "link": "http://ramok.tech/2018/01/03/java-image-cat-vs-dog-recognizer-with-deep-neural-networks/",
  "dc:creator": "Klevis Ramo",
  "pubDate": "Wed, 03 Jan 2018 20:42:32 +0000",
  "category": [
    "Convolutional Neural Network",
    "Machine Learning",
    "Neural Networks",
    "animal classification",
    "cat and dog image recognition",
    "cat vs dog recognition",
    "deeplearning4j cat and dog",
    "image classification",
    "image recognition",
    "imagenet",
    "java deep learning",
    "java machine learning",
    "java neural network",
    "vgg-16"
  ],
  "guid": "http://ramok.tech/?p=1572",
  "description": "Are you Java Developer and eager to learn more about Deep Learning and his applications, but you are not feeling like learning another language at the moment ? Are you facing lack of the support or confusion with Machine Learning and Java? Well you are not alone , as a Java Developer with more than &#8230; <a href=\"http://ramok.tech/2018/01/03/java-image-cat-vs-dog-recognizer-with-deep-neural-networks/\" class=\"more-link\">Continue reading<span class=\"screen-reader-text\"> \"Java Image Cat&#038;Dog Recognition with Deep Neural Networks\"</span></a>",
  "content:encoded": "<p style=\"text-align: center;\"><span style=\"font-weight: 400; font-family: helvetica, arial, sans-serif; font-size: 10pt;\">Are you<strong> Java Developer</strong> and eager to learn more about <a href=\"https://www.packtpub.com/big-data-and-business-intelligence/java-machine-learning-computer-vision-video\">Deep Learning and his applications</a>, but you are not feeling like learning another language at the moment ? Are you facing lack of the support or confusion with Machine Learning and Java?</span></p>\n<p style=\"text-align: center;\"><span style=\"font-weight: 400; font-family: helvetica, arial, sans-serif; font-size: 10pt;\">Well you are not alone , as a Java Developer with more than 10 years of experience and several java certification I understand the obstacles and how you feel.</span></p>\n<p style=\"text-align: center;\"><span style=\"font-family: helvetica, arial, sans-serif; font-size: 10pt;\"><span style=\"font-weight: 400;\">From my experience I know what obstacles a Java software engineering faces with the Deep Learning so I can</span><a href=\"https://www.packtpub.com/big-data-and-business-intelligence/java-machine-learning-computer-vision-video\"><span style=\"font-weight: 400;\"> be of a great</span><span style=\"font-weight: 400;\"> help </span></a><span style=\"font-weight: 400;\">to you in making the </span><span style=\"font-weight: 400;\">journey with <a href=\"https://www.packtpub.com/big-data-and-business-intelligence/java-machine-learning-computer-vision-video\">deep learning an exciting experience</a>.</span></span></p>\n<p>In this post we are going to develop a <a href=\"https://www.dropbox.com/s/4vr2ez8l1ecnqbf/CatAndDogRecognizer.zip?dl=0\">Cat&Dog Recognizer Java Application</a> using <a href=\"https://deeplearning4j.org\">deeplearning4j</a>.If you would like to experiment on your own cat or dog  feel free to check out the<a href=\"https://github.com/klevis/CatAndDogRecognizer\"> source code</a> or download the <a href=\"https://www.dropbox.com/s/4vr2ez8l1ecnqbf/CatAndDogRecognizer.zip?dl=0\">application</a>(fairly short instructions at the end).</p>\n<h2>Computer Vision Nature</h2>\n<p>Although with the great progress of deep learning, computer vision problems tend to be hard to solve. One of the reason is because Neural Networks(NN) are trying to learn a highly complex function like Image Recognition or Image Object Detection. We have a bunch of pixels values and from there we would like to figure out what is inside, so this really is a complex problem on his own.</p>\n<p>Another reason why even today Computer Vision struggle is the amount of date we have. For sure the amount of data we have now is way bigger than before but still it looks like is not enough for Computer Vision problems. In particular Image Object Detection has even less data in comparison to Image Recognition(is a cat? is a dog? is a flower?) because it requires more intensive data labeling(going in each image and specifically mark each object).</p>\n<p>Because Computer Vision is hard, traditionally it has developed complex architectures and techniques to achieve better results. We saw in <a href=\"http://ramok.tech/2017/12/13/java-digit-recognizer-with-convolutional-neural-networks/\">previous post</a> how adding Convolution(specialized image feature detectors) to Neural Networks greatly improved the performance in handwritten digit recognizing problem(97% to 99.5%) but in the same time introduced higher complexity ,parameters and greatly increased training time(to more than 2 hours).</p>\n<p>Usually a NN that worked for particular image recognition problem can also work for other image related problems. So fortunately there are several ways we can approach Computer Vision problems and still be productive and have great results:</p>\n<p style=\"padding-left: 30px;\">We can re-use already successfully known architectures by reducing the time needed for choosing different neural hidden layers, convolution layers other configuration parameters(learning rate).</p>\n<p style=\"padding-left: 30px;\">We can re-use already trained Neural Networks(maybe someone already let NN to learn for weeks or months) by cutting the training time with great factor(<strong>transfer learning</strong>)</p>\n<p style=\"padding-left: 30px;\">Play with training data by cropping, color change, rotate&#8230; to obtain more data so we can help NN learn more and be smarter.</p>\n<p> Lets see how we can solve the problem of Detecting a Cat&Dog!</p>\n<h2>Well Known Architectures</h2>\n<h3>LeNet &#8211; 5</h3>\n<p>This is a classical Neural Network architecture successfully used on handwritten digit recognizer problem back in 1998. You can find more information also for other versions of LeNet architecture <a href=\"http://yann.lecun.com/exdb/mnist/\">here</a> . There is an already existing implementation in <a href=\"https://deeplearning4j.org/\">deeplearning4j</a> library in <a href=\"https://github.com/deeplearning4j/deeplearning4j/blob/master/deeplearning4j-zoo/src/main/java/org/deeplearning4j/zoo/model/LeNet.java\">github(although not exactly as the paper).</a></p>\n<p>LeNet &#8211; 5 architecture looks like below(if not familiar with convolution please have a quick look <a href=\"http://ramok.tech/2017/12/13/java-digit-recognizer-with-convolutional-neural-networks/#Edge_Detection\">here</a>):</p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-1580\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-30_23h07_00.jpg?resize=840%2C388\" alt=\"\" width=\"840\" height=\"388\" srcset=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-30_23h07_00.jpg?w=1465 1465w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-30_23h07_00.jpg?resize=300%2C138 300w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-30_23h07_00.jpg?resize=768%2C354 768w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-30_23h07_00.jpg?resize=1024%2C473 1024w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-30_23h07_00.jpg?resize=1200%2C554 1200w\" sizes=\"(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px\" data-recalc-dims=\"1\" /></p>\n<p>In principle this architecture introduced the idea of applying several convolution and pooling layer before going to connect to a Neural Network and than to the outputs.</p>\n<p>So it takes as input a <strong>32x32x1</strong>(third dimension is one for black and white for RGB it will be 3) matrix than applies a <strong>6 Convolution 5&#215;5</strong> matrices which by applying formula described in details <a href=\"http://ramok.tech/2017/12/13/java-digit-recognizer-with-convolutional-neural-networks/#Putting_all_together\">here</a> gives a <strong>28x28x6 </strong>matrix. Notice  how that third dimension is equal to the number of convolution matrices. Usually convolution will reduce first two dimension(width X height) but increase the third dimension(channels).</p>\n<p>After that we apply a <strong>2&#215;2 with stride 2</strong> <a href=\"http://ramok.tech/2017/12/13/java-digit-recognizer-with-convolutional-neural-networks/#Pooling_Layers\">Max Pooling Laye</a>r(in paper was <a href=\"http://ramok.tech/2017/12/13/java-digit-recognizer-with-convolutional-neural-networks/#Average_Pooling\">average pool</a>) which gives a matrix <strong>14x14x6. </strong>Notice how Pooling Layer left the third dimension unchanged but reduced first two(width X height) by dividing with 2 so Pooling Layers are used to reduce only first two dimensions.</p>\n<p>Additionally we apply <b>16 Convolution 5&#215;5 matrices  </b>which gives a <strong>10x10x16 </strong>and than by adding <strong>2&#215;2 Max Pooling </strong>we end up with <strong>5x5x16.</strong></p>\n<p>We use the output <strong>5x5x16 </strong>of several convolution and pooling to feed a <strong>500 neural network</strong> with only one hidden layer and<strong> 10 outputs</strong>(0-9 digits). The model has to learn <strong>approx. 60.000 </strong><strong>parameters</strong>.</p>\n<p>According to paper this model was able to achieve a <strong>99.05 </strong>which is impressive!</p>\n<h3>AlexNet</h3>\n<p>This is rather a more modern architecture(2012) which works on RGB colored imaged and has way more convolutions and full connected Neurons. This architecture showed great results and therefore convinced a lot of people that deep learning works pretty well for image problems. Anyway we will see that in a way this is similar to LeNet &#8211; 5 just bigger and deeper because at that time the processing power was also way greater(gpu&#8217;s were widely introduced).</p>\n<p>There is also an already existing implementation in <a href=\"https://deeplearning4j.org/\">deeplearning4j</a> library in <a href=\"https://github.com/deeplearning4j/deeplearning4j/blob/master/deeplearning4j-zoo/src/main/java/org/deeplearning4j/zoo/model/LeNet.java\">github.</a></p>\n<p>The architecture will look like below:</p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-1592\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-31_01h31_40.jpg?resize=840%2C455\" alt=\"\" width=\"840\" height=\"455\" srcset=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-31_01h31_40.jpg?w=1314 1314w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-31_01h31_40.jpg?resize=300%2C163 300w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-31_01h31_40.jpg?resize=768%2C416 768w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-31_01h31_40.jpg?resize=1024%2C555 1024w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-31_01h31_40.jpg?resize=1200%2C650 1200w\" sizes=\"(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px\" data-recalc-dims=\"1\" /></p>\n<p>We start with more pixels and also colored images <strong>224x224x3 </strong>RGB image. In principle is the same as LeNet &#8211; 5 above but just with more convolutions and pooling layers.Convolutions are used to increase third dimension and usually leave first two dimension unchanged(except the first one with stride s=4). Pooling layers are used to decrease(usually by dividing with two) the first two dimension(width X height) and leave the third dimension untouched. If you are wondering about <strong>Conv Same </strong>it simply means leave two first dimension (width X height) unchanged. Following formulas described on<a href=\"http://ramok.tech/2017/12/13/java-digit-recognizer-with-convolutional-neural-networks/#Putting_all_together\"> previous post</a> is fairly easy to get same values as in picture.</p>\n<p>After adding several convolution and pooling layers we end up with a <strong>6x6x256 </strong>matrix which is used to feed a big Neural Network with three hidden layers respectively 9216, 4096,4096.</p>\n<p>AlexNet is trying to detect more categories,<strong>1000 of them</strong> in comparison to LeNet &#8211; 5 which had only<strong> 10</strong>(0-9 digits) in same time it has way more parameters to learn <strong>approx. 60 million(100 times more than LeNet &#8211; 5)</strong>.</p>\n<h3>VGG &#8211; 16</h3>\n<p>This architecture from 2015 beside having even more parameters is also more uniform and simple. Instead of having different sizes of Convolution and pooling layers VGG &#8211; 16 uses only one size for each of them and than just applying them several times.</p>\n<p>There is also an already existing implementation in <a href=\"https://deeplearning4j.org/\">deeplearning4j</a> library in <a href=\"https://github.com/deeplearning4j/deeplearning4j/blob/master/deeplearning4j-zoo/src/main/java/org/deeplearning4j/zoo/model/VGG16.java\">github.</a></p>\n<p>It always uses <strong>Convolution Same <span style=\"text-decoration: underline;\">3X3XN</span> with stride S=1,</strong> the third dimension differs from time to time<strong> </strong>to increase/decrease the third dimension(<strong>N</strong>). Also it uses <strong>Max Pooling <span style=\"text-decoration: underline;\">2&#215;2</span> stride S=2, </strong>pooling layer always have the same third dimension value as input(they play only with width and height) so we do not show the third dimension.  Lets see how this architecture will look like:</p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-1589\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-31_01h04_38.jpg?resize=840%2C469\" alt=\"\" width=\"840\" height=\"469\" srcset=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-31_01h04_38.jpg?w=1265 1265w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-31_01h04_38.jpg?resize=300%2C167 300w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-31_01h04_38.jpg?resize=768%2C429 768w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-31_01h04_38.jpg?resize=1024%2C571 1024w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-31_01h04_38.jpg?resize=1200%2C670 1200w\" sizes=\"(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px\" data-recalc-dims=\"1\" /></p>\n<p>Notice again how step by step height and width was decreased by adding Pooling Layers and channels(third dimension) increased  by adding Convolutions. Although the model is bigger in same time is easier to read and understand thanks to the uniform way of using convolution and pooling layers.</p>\n<p>This architecture has 138 million parameters , approx 3 times more than AlexNet(60 million) and similarly it try to detect 1000 image categories.</p>\n<h3>Other Great Architectures</h3>\n<p>There more architectures even bigger and deeper than the three above. For implementation and list of the other architecture please refer at <strong>deeplearning4j</strong> classes list on <a href=\"https://github.com/deeplearning4j/deeplearning4j/tree/master/deeplearning4j-zoo/src/main/java/org/deeplearning4j/zoo/model\">github</a>. But just to mention a few there is also:</p>\n<ul>\n<li>VGG- 19 a bigger version of VGG &#8211; 16</li>\n<li>ResNet &#8211; 50 which uses Residual Neural Networks</li>\n<li>GoogLeNet which uses Inception Networks. Was developed by Google and took the name in honor to the classic LeNet &#8211; 5.</li>\n</ul>\n<h2>Transfer Learning</h2>\n<p>One great thing about Machine Learning applications is that they are highly portable between different frameworks and even programming languages. Once you trained a neural network what you get is a bunch or parameters values(decimal values). In case of LeNet-5 60.000 parameter values, AlexNet 60 million and for VGG- 16 138 million. Than we use those parameters values to classify new coming images into one of 1000 in case of AlexNet and VGG-16 and 10 for LeNet-5.</p>\n<p>In a few words the most valuable part of our application are the parameters. If we save parameters on disk and load them later we will get the same result as prior to saving (for same previously predicted images). Even if we save with <strong>python</strong> and load with <strong>java(</strong>or other way around<strong>)</strong> we will get the same result assuming the Neural Network implementation is correct on both of them.</p>\n<p>Transfer learning as the name suggest it transfers already trained neural weights to others. Others can be different machines, operating systems, frameworks, languages like java,python or anything as long as you can read/save the weights values.</p>\n<p>It maybe someone else already trained the network for really long time like weeks or months and with transfer learning we can re-use that work in a few minutes and start from there. Beside we get for free the painful tuning of hyper-parameters it is especially useful when we do not have a lot of processing power(someone else trained with thousands of GPU&#8217;s).As we will see later <a href=\"https://deeplearning4j.org/\">deeplearning4j</a> already has the ability to save and load pretrained neural networks even from frameworks like <a href=\"https://keras.io/\">Keras</a>.</p>\n<p>There are several things we can do once we load a pretrained neural network:</p>\n<ol>\n<li>Directly use the network to classify or predict for already trained outputs</li>\n<li>We can modify only the output layer from lets say 1000 to 5 and freeze everything else. So we train only from last layer to output and re-use everything else by speeding up the training time. Freezing means we do not train and not use any processing power for those layer parameters but rather use as they are.</li>\n<li>Freeze some of the layers and add/remove other layers. Than we only train the network on new added layers and not freeze/removed layers. The reason why we freeze some of the layers is because most of the layers already are useful for our problem as well(we have similar problem to trained network) and it will take long time to train all layers(without improving much).</li>\n<li>We use the new wights only as initial values and than train all the network including also possible new added layers. Usually this a good choice when we have a lot of processing power and more data so we are almost sure this will bring new findings and maybe better performance.</li>\n</ol>\n<p>As we will see <a href=\"https://deeplearning4j.org/\">deeplearning4j</a> supports freezing layers and adding/removing layers to a pretrained neural network.</p>\n<h2>Cat&Dog Recognizer</h2>\n<h3>Data</h3>\n<p>As always every Machine Learning problem starts with the data. The amount and quality of data are very crucial for the performance of system and most of the time it requires great deal of effort and resources. So we need to rely on online public data sets as a start and than try to augment or transform existing images to create a larger variety.</p>\n<p>For cat&dog recognizer problem fortunately we have a good data set provided by <a href=\"https://www.microsoft.com/en-us/download/details.aspx?id=54765\">Microsoft</a>. Also the same data set can be found on <a href=\"https://www.kaggle.com/c/dogs-vs-cats\">Kaggle</a>. Originally this is a Dog & Cat data set with<strong> 12.500</strong> cat photos and <strong>12.500</strong> dog photos and with <strong>12.500</strong> dog&cat as a test data set.</p>\n<h3>Chosen Architecture</h3>\n<p>Since 2010, <a href=\"http://image-net.org/\">ImageNet</a> has hosted an annual <a href=\"http://www.image-net.org/challenges/LSVRC/\">challenge</a> where research teams present solutions to image classification and other tasks by training on the ImageNet dataset. ImageNet currently has millions of labeled images; it’s one of the largest high-quality image datasets in the world. The Visual Geometry group at the University of Oxford did really well in 2014 with: VGG-16 and VGG-19(<a href=\"http://www.image-net.org/challenges/LSVRC/2014/results#clsloc\">results</a>). We will choose VGG-16 trained with ImageNet for our cat problem  because it is similar to what we want to predict. VGG-16 with ImageNet already is trained to detect different races of cats&dogs, please find <a href=\"http://image-net.org/challenges/LSVRC/2014/browse-synsets\">here the list</a>(search with &#8216;cat&#8217;,&#8217;dog&#8217;).</p>\n<p>The size of all trained weights and the model is about 500MB so if you are going to use the code to train it may take few moments to download the pretrained weights first. The code in <strong>deeplearning4j </strong>for downloading<strong> VGG-16</strong> trained with <a href=\"http://image-net.org/\">ImageNet</a> looks like below:</p>\n<pre>ZooModel zooModel = new VGG16();\nComputationGraph pretrainedNet = (ComputationGraph) zooModel.initPretrained(PretrainedType.IMAGENET);</pre>\n<h3>Architecture Adaption</h3>\n<p>VGG-16 predicts 1000 classes of images while we need only two;if the image is cat or a dog. So we need to slightly modify the model to output only two classes instead of 1000. Everything else we leave it as it is since our problem is similar to what VGG-16 is already trained for(freeze all other layers). Modified VGG-16 will look like below:</p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter wp-image-1623\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2018/01/2018-01-02_21h00_50.jpg?resize=840%2C440\" alt=\"\" width=\"840\" height=\"440\" srcset=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2018/01/2018-01-02_21h00_50.jpg?w=1429 1429w, https://i0.wp.com/ramok.tech/wp-content/uploads/2018/01/2018-01-02_21h00_50.jpg?resize=300%2C157 300w, https://i0.wp.com/ramok.tech/wp-content/uploads/2018/01/2018-01-02_21h00_50.jpg?resize=768%2C402 768w, https://i0.wp.com/ramok.tech/wp-content/uploads/2018/01/2018-01-02_21h00_50.jpg?resize=1024%2C536 1024w, https://i0.wp.com/ramok.tech/wp-content/uploads/2018/01/2018-01-02_21h00_50.jpg?resize=1200%2C628 1200w\" sizes=\"(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px\" data-recalc-dims=\"1\" /></p>\n<p>In gray is marked the part which is freeze so we do not use any processing power to trained but instead use the weights initial downloaded values.In green is the part we trained so we are going to train only <strong>8192</strong> parameters (from 138 million)from the last layer to the two outputs. The code will look like below:</p>\n<pre>FineTuneConfiguration fineTuneConf = new FineTuneConfiguration.Builder()\n        .learningRate(5e-5)\n        .optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT)\n        .updater(Updater.NESTEROVS)\n        .seed(seed)\n        .build();\n\nComputationGraph vgg16Transfer = new TransferLearning.GraphBuilder(preTrainedNet)\n        .fineTuneConfiguration(fineTuneConf)\n        .setFeatureExtractor(featurizeExtractionLayer)\n        .removeVertexKeepConnections(\"predictions\")\n        .addLayer(\"predictions\",\n                new OutputLayer.Builder(LossFunctions.LossFunction.NEGATIVELOGLIKELIHOOD)\n                        .nIn(4096).nOut(<strong>NUM_POSSIBLE_LABELS</strong>)//2\n                        .weightInit(WeightInit.XAVIER)\n                        .activation(Activation.SOFTMAX).build(), featurizeExtractionLayer)\n        .build();</pre>\n<p>The method which freezes the weights is <strong>setFeatureExtractor.</strong>From java doc of deeplearning4j :</p>\n<pre>/**\n * Specify a layer vertex to set as a \"feature extractor\"\n * <strong>The specified layer vertex and the layers on the path from an input vertex to it it will be \"frozen\" with parameters staying constant</strong>\n * @param layerName\n * @return Builder\n */\npublic GraphBuilder setFeatureExtractor(String... layerName) {\n    this.hasFrozen = true;\n    this.frozenOutputAt = layerName;\n    return this;\n}</pre>\n<p>So everything from the input to the layer name you defined will be freeze. If you are wondering what is the layer name and how to find than you can print first the model architecture like below:</p>\n<pre>ZooModel zooModel = new VGG16();\nComputationGraph pretrainedNet = (ComputationGraph) zooModel.initPretrained(PretrainedType.IMAGENET);\n<strong>log.info(pretrainedNet.summary());</strong></pre>\n<p>After that you will get in console something that looks like below:</p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter wp-image-1612 zoooom\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2018/01/2018-01-01_19h15_11.jpg?resize=840%2C381\" alt=\"\" width=\"840\" height=\"381\" srcset=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2018/01/2018-01-01_19h15_11.jpg?w=1145 1145w, https://i0.wp.com/ramok.tech/wp-content/uploads/2018/01/2018-01-01_19h15_11.jpg?resize=300%2C136 300w, https://i0.wp.com/ramok.tech/wp-content/uploads/2018/01/2018-01-01_19h15_11.jpg?resize=768%2C348 768w, https://i0.wp.com/ramok.tech/wp-content/uploads/2018/01/2018-01-01_19h15_11.jpg?resize=1024%2C464 1024w\" sizes=\"(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px\" data-recalc-dims=\"1\" /></p>\n<p>Notice that trainable parameters are equal to total parameters 138 million. In our case we are going to freeze from input to the last dense layer which <strong>&#8216;fc2&#8217; </strong>so <strong>featurizeExtractionLayer variable value will be &#8220;fc2&#8221;. </strong>Please find below a view after freeze:</p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter wp-image-1624 zoooom\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2018/01/2018-01-02_21h07_23.jpg?resize=840%2C393\" alt=\"\" width=\"840\" height=\"393\" srcset=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2018/01/2018-01-02_21h07_23.jpg?w=1149 1149w, https://i0.wp.com/ramok.tech/wp-content/uploads/2018/01/2018-01-02_21h07_23.jpg?resize=300%2C140 300w, https://i0.wp.com/ramok.tech/wp-content/uploads/2018/01/2018-01-02_21h07_23.jpg?resize=768%2C359 768w, https://i0.wp.com/ramok.tech/wp-content/uploads/2018/01/2018-01-02_21h07_23.jpg?resize=1024%2C479 1024w\" sizes=\"(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px\" data-recalc-dims=\"1\" /></p>\n<p>Notice how names are ending with <em><strong>frozen</strong> </em>now and the trainable parameters changed from <strong>138 million to 8194(8192+ 2 bias parameters)</strong>.</p>\n<h3>Train and Results</h3>\n<p>Now we are ready to train the model and this results to fairly few lines of code:</p>\n<pre>DataSetIterator testIterator = getDataSetIterator(test.sample(PATH_FILTER, 1, 0)[0]);\nint iEpoch = 0;\nint i = 0;\nwhile (iEpoch < EPOCH) {\n    while (trainIterator.hasNext()) {\n        DataSet trained = trainIterator.next();\n        vgg16Transfer.fit(trained);\n        if (i % SAVED_INTERVAL == 0 && i != 0) {\n\n            ModelSerializer.writeModel(vgg16Transfer, new File(SAVING_PATH), false);\n            evalOn(vgg16Transfer, devIterator, i);\n        }\n        i++;\n    }\n\n    trainIterator.reset();\n    iEpoch++;\n\n    evalOn(vgg16Transfer, testIterator, iEpoch);\n}</pre>\n<p>We are using a batch size of <strong>16 and 3 epochs. </strong>First while loop will be executed three times since epoch=3.Second inner while loop will be executed <strong>1563</strong>  (<strong>25.000 cats and dogs/16).</strong>One epoch is full traversal through the data and one iteration is one forward and back propagation on the batch size(16 images in our case). So our model learns with small steps of 16 images and each time becomes smarter and smarter.</p>\n<p>Before was common to <strong>not</strong> train Neural Networks  with batches but rather feed all the data at once and have epochs with bigger values like 100,200&#8230; In modern Deep Learning Era due to the really big amount of data this way is not used anymore because is really slow. If we feed the network all the data at once than we will wait until the model iterates all the data(million of images )before making any progress with learning while with batch we have the model learning and progressing faster with small steps. There is more about batch vs no batch and is out of this post scope so we will leave for another post.</p>\n<p>You can find the <a href=\"https://github.com/klevis/CatAndDogRecognizer/blob/master/src/main/java/ramo/klevis/ml/vg16/TrainImageNetVG16.java\">full code</a> used for training in <a href=\"https://github.com/klevis/CatAndDogRecognizer/blob/master/src/main/java/ramo/klevis/ml/vg16/TrainImageNetVG16.java\">github</a>. For the first time it has to download and unzip<a href=\"https://www.dropbox.com/s/tqnp49apphpzb40/dataTraining.zip?dl=0\"><strong> 600MB</strong> of data image</a>s to resources folder, so this may take some time for the first run.</p>\n<p>After training on<strong><span style=\"font-size: 12pt;\"> 85%</span> of training set(25000)</strong> for few hours(3 hours) we were able to get below results(<a href=\"https://github.com/klevis/CatAndDogRecognizer/blob/master/src/main/java/ramo/klevis/ml/vg16/VG16ForCat.java\">code used for evaluating</a>):</p>\n<h4>Dev Set Accuracy</h4>\n<p><strong>15% of Training Set Used as Dev Set</strong></p>\n<p>Examples labeled as cat classified by model as cat: 1833 times<br />\nExamples labeled as cat classified by model as dog: 42 times<br />\nExamples labeled as dog classified by model as cat: 31 times<br />\nExamples labeled as dog classified by model as dog: 1844 times</p>\n<p>==========================Scores==========================<br />\n# of classes: 2<br />\nAccuracy: 0.9805<br />\nPrecision: 0.9805<br />\nRecall: 0.9805<br />\nF1 Score: 0.9806<br />\n=========================================================</p>\n<h4>Test set Accuracy</h4>\n<p><strong>1246 Cats and 1009 Dogs</strong></p>\n<p>Examples labeled as cat classified by model as cat: 934 times<br />\nExamples labeled as cat classified by model as dog: 12 times<br />\nExamples labeled as dog classified by model as cat: 46 times<br />\nExamples labeled as dog classified by model as dog: 900 times</p>\n<p>==========================Scores========================================<br />\n# of classes: 2<br />\nAccuracy: 0.9693<br />\nPrecision: 0.9700<br />\nRecall: 0.9693<br />\nF1 Score: 0.9688<br />\n========================================================================</p>\n<h2>Application</h2>\n<p><a href=\"https://www.dropbox.com/s/4vr2ez8l1ecnqbf/CatAndDogRecognizer.zip?dl=0\">Application </a>can be <a href=\"https://www.dropbox.com/s/4vr2ez8l1ecnqbf/CatAndDogRecognizer.zip?dl=0\">downloaded </a>and executed without any knowledge of java beside JAVA has to be installed on your computer. Feel to try with your own cat.</p>\n<p>It is possible to run the from <a href=\"https://github.com/klevis/CatAndDogRecognizer\">source </a>by simply executing the <strong>RUN</strong> class or if you do not fill to open it with IDE just run <em><strong>mvn clean install exec:java. </strong></em></p>\n<ul>\n<li><em><strong>Please be aware for the first time it will <a href=\"https://www.dropbox.com/s/djmh91tk1bca4hz/RunEpoch_class_2_soft_10_32_1800.zip?dl=0\">download 500MB wights</a> from dropbox so it may take some time depending on network.</strong></em></li>\n<li>To speedup training time model was trained <strong>only on Cats and Dogs images</strong> therefore the model has not seen(trained) other than cats or dogs. So to avoid predicting <strong>non cat or dog images</strong> as cat or dog the threshold was increased to <strong>0.95).</strong> Meaning that we classify as cat or dog only when the confidence of the model is very high like <strong>95%.</strong> In reality the threshold will be much lower like <strong>50%(0.5)</strong> so if you are not satisfy with the prediction try to lower the threshold.<strong> </strong></li>\n<li><em><strong>The <a href=\"https://www.dropbox.com/s/4vr2ez8l1ecnqbf/CatAndDogRecognizer.zip?dl=0\">downloadable</a> <a href=\"https://www.dropbox.com/s/4vr2ez8l1ecnqbf/CatAndDogRecognizer.zip?dl=0\">application</a> has the threshold set to 95%.</strong></em></li>\n<li>Training is not provided with graphical user interface since it really takes a lot of time and memory. Anyway feel free to train and experiment on you own choice by modifying this <a href=\"https://github.com/klevis/CatAndDogRecognizer/blob/master/src/main/java/ramo/klevis/ml/vg16/TrainImageNetVG16.java\">class</a>. Please expect some time for the code to download <strong>500MB of VG-166 ImageNet weights</strong> and <strong><a href=\"https://www.dropbox.com/s/tqnp49apphpzb40/dataTraining.zip?dl=0\">training data 600MB</a> </strong>for the first time.</li>\n</ul>\n<p>After running the <a href=\"https://www.dropbox.com/s/4vr2ez8l1ecnqbf/CatAndDogRecognizer.zip?dl=0\">application</a> you should be able to see below view:</p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-1648\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2018/01/feature2.jpg?resize=454%2C342\" alt=\"\" width=\"454\" height=\"342\" srcset=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2018/01/feature2.jpg?w=454 454w, https://i0.wp.com/ramok.tech/wp-content/uploads/2018/01/feature2.jpg?resize=300%2C226 300w\" sizes=\"(max-width: 454px) 85vw, 454px\" data-recalc-dims=\"1\" /></p>\n<p>Enjoy!</p>\n",
  "post-id": 1572
}