{
  "title": "Daphne Keller on Legal Liability for Tech Platforms",
  "itunes:title": "Daphne Keller on Legal Liability for Tech Platforms",
  "pubDate": "Thu, 07 Nov 2019 17:08:14 GMT",
  "itunes:duration": "57:05",
  "enclosure": "",
  "guid": "af532c8772f44addb4138b1a08b00fab",
  "itunes:explicit": "no",
  "link": "https://shows.acast.com/lawfare/episodes/60518a63bd84d92f9a7e56b9",
  "acast:episodeId": "60518a63bd84d92f9a7e56b9",
  "acast:settings": "ozu8rXK33NzX6c6CybB5UOF04GhvlOgDa40P9ZFPAybvfyg0UxkGS28ZOgnOo+59hYWZ43P8iM2gznOgM5mBpsMAKCMa/C1B7LRWhJHIObkB4A9FVaPrr4xBHxLTFpyyb4hpsKc1k488zHrp4SG1XK06zM2lJd1QtIXlCW7ofTw=",
  "itunes:subtitle": "Episode 469",
  "itunes:episodeType": "full",
  "itunes:episode": 469,
  "description": "<p>In this episode of the Arbiters of Truth series—Lawfare's new podcast series on disinformation in the run-up to the 2020 election—Quinta Jurecic and Evelyn Douek spoke with Daphne Keller, the director of intermediary liability at Stanford's Center for Internet and Society, about the nuts and bolts of content moderation. People often have big ideas for how tech platforms should decide what content to take down and what to keep up, but what kind of moderation is actually possible at scale? And what happens when those decisions come into conflict with different norms of free speech—for example, between the U.S. and Europe? They talked about intermediary liability law in the United States, recent rulings by the Court of Justice of the European Union, and everything in-between.</p><p>Support this show <a target=\"_blank\" rel=\"payment\" href=\"http://supporter.acast.com/lawfare\">http://supporter.acast.com/lawfare</a>.</p><br /><hr><p style='color:grey; font-size:0.75em;'> Hosted on Acast. See <a style='color:grey;' target='_blank' rel='noopener noreferrer' href='https://acast.com/privacy'>acast.com/privacy</a> for more information.</p>",
  "itunes:summary": "<p>In this episode of the Arbiters of Truth series—Lawfare's new podcast series on disinformation in the run-up to the 2020 election—Quinta Jurecic and Evelyn Douek spoke with Daphne Keller, the director of intermediary liability at Stanford's Center for Internet and Society, about the nuts and bolts of content moderation. People often have big ideas for how tech platforms should decide what content to take down and what to keep up, but what kind of moderation is actually possible at scale? And what happens when those decisions come into conflict with different norms of free speech—for example, between the U.S. and Europe? They talked about intermediary liability law in the United States, recent rulings by the Court of Justice of the European Union, and everything in-between.</p><p>Support this show <a target=\"_blank\" rel=\"payment\" href=\"http://supporter.acast.com/lawfare\">http://supporter.acast.com/lawfare</a>.</p><br /><hr><p style='color:grey; font-size:0.75em;'> Hosted on Acast. See <a style='color:grey;' target='_blank' rel='noopener noreferrer' href='https://acast.com/privacy'>acast.com/privacy</a> for more information.</p>"
}