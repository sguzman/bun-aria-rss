{
  "title": "M-to-N Backdoor Paradigm: A Stealthy and Fuzzy Attack to Deep Learning Models. (arXiv:2211.01875v1 [cs.CR])",
  "link": "http://arxiv.org/abs/2211.01875",
  "description": "<p>Recent studies show that deep neural networks (DNNs) are vulnerable to\nbackdoor attacks. A backdoor DNN model behaves normally with clean inputs,\nwhereas outputs attacker's expected behaviors when the inputs contain a\npre-defined pattern called a trigger. However, in some tasks, the attacker\ncannot know the exact target that shows his/her expected behavior, because the\ntask may contain a large number of classes and the attacker does not have full\naccess to know the semantic details of these classes. Thus, the attacker is\nwilling to attack multiple suspected targets to achieve his/her purpose. In\nlight of this, in this paper, we propose the M-to-N backdoor attack, a new\nattack paradigm that allows an attacker to launch a fuzzy attack by\nsimultaneously attacking N suspected targets, and each of the N targets can be\nactivated by any one of its M triggers. To achieve a better stealthiness, we\nrandomly select M clean images from the training dataset as our triggers for\neach target. Since the triggers used in our attack have the same distribution\nas the clean images, the inputs poisoned by the triggers are difficult to be\ndetected by the input-based defenses, and the backdoor models trained on the\npoisoned training dataset are also difficult to be detected by the model-based\ndefenses. Thus, our attack is stealthier and has a higher probability of\nachieving the attack purpose by attacking multiple suspected targets\nsimultaneously in contrast to prior backdoor attacks. Extensive experiments\nshow that our attack is effective against different datasets with various\nmodels and achieves high attack success rates (e.g., 99.43% for attacking 2\ntargets and 98.23% for attacking 4 targets on the CIFAR-10 dataset) when\npoisoning only an extremely small portion of the training dataset (e.g., less\nthan 2%). Besides, it is robust to pre-processing operations and can resist\nstate-of-the-art defenses.\n</p>",
  "dc:creator": "<a href=\"http://arxiv.org/find/cs/1/au:+Hou_L/0/1/0/all/0/1\">Linshan Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hua_Z/0/1/0/all/0/1\">Zhongyun Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuhong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Leo Yu Zhang</a>"
}