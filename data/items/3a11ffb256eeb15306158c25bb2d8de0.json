{
  "title": "Covariance Matrices and Data Distributions",
  "link": "https://theclevermachine.wordpress.com/2013/03/29/covariance-matrices-and-data-distributions/",
  "comments": "https://theclevermachine.wordpress.com/2013/03/29/covariance-matrices-and-data-distributions/#comments",
  "dc:creator": "dustinstansbury",
  "pubDate": "Sat, 30 Mar 2013 00:12:45 +0000",
  "category": [
    "Statistics",
    "Bivariate Gaussian",
    "correlation",
    "Covariance Matrix",
    "Diagonal matrix",
    "Gaussian distribution",
    "identity matrix",
    "statistically white"
  ],
  "guid": "http://theclevermachine.wordpress.com/?p=3679",
  "description": "Correlation between variables in a -dimensional dataset are often summarized by a covariance matrix. To get a better understanding of how correlation matrices characterize correlations between data points, we plot data points drawn from 3 different 2-dimensional Gaussian distributions, each of which is defined by a different covariance matrix. The left plots below display the [&#8230;]",
  "content:encoded": "<p>Correlation between variables in a <img src=\"https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=4e4e4e&#038;s=0&#038;c=20201002\" alt=\"K\" class=\"latex\" />-dimensional dataset are often summarized by a <img src=\"https://s0.wp.com/latex.php?latex=K+%5Ctimes+K&#038;bg=ffffff&#038;fg=4e4e4e&#038;s=0&#038;c=20201002\" alt=\"K &#92;times K\" class=\"latex\" /> covariance matrix. To get a better understanding of how correlation matrices characterize correlations between data points, we plot data points drawn from 3 different 2-dimensional Gaussian distributions, each of which is defined by a different covariance matrix.</p>\n<p>The left plots below display the <img src=\"https://s0.wp.com/latex.php?latex=2+%5Ctimes+2&#038;bg=ffffff&#038;fg=4e4e4e&#038;s=0&#038;c=20201002\" alt=\"2 &#92;times 2\" class=\"latex\" /> covariance matrix for each Gaussian distribution. The values along the diagonal represent the variance of the data along each dimension, and the off-diagonal values represent the covariances between the dimensions. Thus the <img src=\"https://s0.wp.com/latex.php?latex=i%2Cj&#038;bg=ffffff&#038;fg=4e4e4e&#038;s=0&#038;c=20201002\" alt=\"i,j\" class=\"latex\" />-th entry of each matrix represents the correlation between the <img src=\"https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=4e4e4e&#038;s=0&#038;c=20201002\" alt=\"i\" class=\"latex\" />-th and <img src=\"https://s0.wp.com/latex.php?latex=j&#038;bg=ffffff&#038;fg=4e4e4e&#038;s=0&#038;c=20201002\" alt=\"j\" class=\"latex\" />-th dimensions. The right plots show data drawn from the corresponding 2D Gaussian.</p>\n<h2><a href=\"https://theclevermachine.files.wordpress.com/2013/03/whitening-covariances.png\"><img loading=\"lazy\" data-attachment-id=\"3657\" data-permalink=\"https://theclevermachine.wordpress.com/2013/03/30/the-statistical-whitening-transform/whitening-covariances/\" data-orig-file=\"https://theclevermachine.files.wordpress.com/2013/03/whitening-covariances.png\" data-orig-size=\"522,776\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\"}\" data-image-title=\"whitening-Covariances\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://theclevermachine.files.wordpress.com/2013/03/whitening-covariances.png?w=202\" data-large-file=\"https://theclevermachine.files.wordpress.com/2013/03/whitening-covariances.png?w=522\" class=\"aligncenter  wp-image-3657\" alt=\"whitening-Covariances\" src=\"https://theclevermachine.files.wordpress.com/2013/03/whitening-covariances.png?w=357&#038;h=531\" width=\"357\" height=\"531\" srcset=\"https://theclevermachine.files.wordpress.com/2013/03/whitening-covariances.png?w=357&h=531 357w, https://theclevermachine.files.wordpress.com/2013/03/whitening-covariances.png?w=101&h=150 101w, https://theclevermachine.files.wordpress.com/2013/03/whitening-covariances.png?w=202&h=300 202w, https://theclevermachine.files.wordpress.com/2013/03/whitening-covariances.png 522w\" sizes=\"(max-width: 357px) 100vw, 357px\" /></a></h2>\n<p>The top row plot display a covariance matrix equal to the identity matrix, and the points drawn from the corresponding Gaussian distribution. The diagonal values are 1, indicating the data have variance of 1 along both of the dimensions. Additionally, the off-diagonal elements are zero, meaning that the two dimensions are uncorrelated. Â We can see this in the data drawn from the distribution as well. The data are distributed in a sphere about origin. For such a distribution of points, it is difficult (impossible) to draw any single regression line that can predict the second dimension from the first, and vice versa. Thus an identity covariance matrix is equivalent to having independent dimensions, each of which has unit (i.e. 1) variance. Such a dataset is often called &#8220;white&#8221; (this naming convention comes from the notion that white noise signals&#8211;which can be sampled from independent Gaussian distributions&#8211;have equal power at all frequencies in the Fourier domain).</p>\n<p>The middle row plots the points that result from a diagonal, but not identity covariance matrix. The off-diagonal elements are still zero, indicating that the dimensions are uncorrelated. However, the variances along each dimension are not equal to one, and are not equal. This is demonstrated by the elongated distribution in red. The elongation is along the second dimension, as indicated by the larger value in the bottom-right (point <img src=\"https://s0.wp.com/latex.php?latex=%28i%2Cj%29+%3D+%282%2C2%29&#038;bg=ffffff&#038;fg=4e4e4e&#038;s=0&#038;c=20201002\" alt=\"(i,j) = (2,2)\" class=\"latex\" />) of the covariance matrix.</p>\n<p>The bottom row plots points that result from a non-diagonal covariance matrix. Here the off-diagonal elements of covariance matrix have non-zero values, indicating a correlation between the dimensions. This correlation is reflected in the distribution of drawn datapoints (in blue). We can see that the primary axis along which the points are distributed is not along either of the dimensions, but a linear combination of the dimensions.</p>\n<p>The MATLAB code to create the above plots is here</p>\n<pre class=\"brush: matlabkey; collapse: true; light: false; title: ; toolbar: true; notranslate\">\n% INITIALIZE SOME CONSTANTS\nmu = [0 0];         % ZERO MEAN\nS = [1 .9; .9 3];   % NON-DIAGONAL COV.\nSDiag = [1 0; 0 3]; % DIAGONAL COV.\nSId = eye(2);       % IDENTITY COV.\n\n% SAMPLE SOME DATAPOINTS\nnSamples = 1000;\nsamples = mvnrnd(mu,S,nSamples)';\nsamplesId = mvnrnd(mu,SId,nSamples)';\nsamplesDiag = mvnrnd(mu,SDiag,nSamples)';\n\n% DISPLAY\nsubplot(321);\nimagesc(SId); axis image,\ncaxis([0 1]), colormap hot, colorbar\ntitle('Identity Covariance')\n\nsubplot(322)\nplot(samplesId(1,:),samplesId(2,:),'ko'); axis square\nxlim([-5 5]), ylim([-5 5])\ngrid\ntitle('White Data')\n\nsubplot(323);\nimagesc(SDiag); axis image,\ncaxis([0 3]), colormap hot, colorbar\ntitle('Diagonal Covariance')\n\nsubplot(324)\nplot(samplesDiag(1,:),samplesDiag(2,:),'r.'); axis square\nxlim([-5 5]), ylim([-5 5])\ngrid\ntitle('Uncorrelated Data')\n\nsubplot(325);\nimagesc(S); axis image,\ncaxis([0 3]), colormap hot, colorbar\ntitle('Non-diagonal Covariance')\n\nsubplot(326)\nplot(samples(1,:),samples(2,:),'b.'); axis square\nxlim([-5 5]), ylim([-5 5])\ngrid\ntitle('Correlated Data')\n</pre>\n",
  "wfw:commentRss": "https://theclevermachine.wordpress.com/2013/03/29/covariance-matrices-and-data-distributions/feed/",
  "slash:comments": 2,
  "media:content": [
    {
      "media:title": "dustinstansbury"
    },
    {
      "media:title": "whitening-Covariances"
    }
  ]
}