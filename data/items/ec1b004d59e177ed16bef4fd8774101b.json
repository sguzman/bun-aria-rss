{
  "title": "Pangeo: JupyterHub, Dask, and XArray on the Cloud",
  "link": "",
  "updated": "2018-01-22T00:00:00+00:00",
  "id": "https://mrocklin.github.io/blog/work/2018/01/22/pangeo-2",
  "content": "<p><em>This work is supported by <a href=\"http://anaconda.com\">Anaconda Inc</a>, the NSF\nEarthCube program, and UC Berkeley BIDS</em></p>\n\n<p>A few weeks ago a few of us stood up <a href=\"http://pangeo.pydata.org\">pangeo.pydata.org</a>,\nan experimental deployment of JupyterHub, Dask, and XArray on Google Container Engine (GKE)\nto support atmospheric and oceanographic data analysis on large datasets.\nThis follows on <a href=\"../../../2017/09/18/pangeo-1\">recent work</a> to deploy Dask and XArray for the same workloads on super computers.\nThis system is a proof of concept that has taught us a great deal about how to move forward.\nThis blogpost briefly describes the problem,\nthe system,\nthen describes the collaboration,\nand finally discusses a number of challenges that we’ll be working on in coming months.</p>\n\n<h2 id=\"the-problem\">The Problem</h2>\n\n<p>Atmospheric and oceanographic sciences collect (with satellites) and generate (with simulations) large datasets\nthat they would like to analyze with distributed systems.\nLibraries like Dask and XArray already solve this problem computationally if scientists have their own clusters,\nbut we seek to expand access by deploying on cloud-based systems.\nWe build a system to which people can log in, get Jupyter Notebooks, and launch Dask clusters without much hassle.\nWe hope that this increases access, and connects more scientists with more cloud-based datasets.</p>\n\n<h2 id=\"the-system\">The System</h2>\n\n<p>We integrate several pre-existing technologies to build a system where people can log in,\nget access to a Jupyter notebook,\nlaunch distributed compute clusters using Dask,\nand analyze large datasets stored in the cloud.\nThey have a full user environment available to them through a website,\ncan leverage thousands of cores for computation,\nand use existing APIs and workflows that look familiar to how they work on their laptop.</p>\n\n<p>A video walk-through follows below:</p>\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/rSOJKbfNBNk\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen=\"\"></iframe>\n\n<p>We assembled this system from a number of pieces and technologies:</p>\n\n<ul>\n  <li><a href=\"https://jupyterhub.readthedocs.io/en/latest/\">JupyterHub</a>: Provides both the ability to launch single-user notebook servers\nand handles user management for us.\nIn particular we use the KubeSpawner and the excellent documentation at <a href=\"https://zero-to-jupyterhub.readthedocs.io/en/latest\">Zero to JupyterHub</a>,\nwhich we recommend to anyone interested in this area.</li>\n  <li><a href=\"https://github.com/jupyterhub/kubespawner\">KubeSpawner</a>: A JupyterHub spawner that makes it easy to launch single-user notebook servers on Kubernetes systems</li>\n  <li><a href=\"http://jupyterlab-tutorial.readthedocs.io/en/latest/\">JupyterLab</a>: The newer version of the classic notebook,\nwhich we use to provide a richer remote user interface,\ncomplete with terminals, file management, and more.</li>\n  <li><a href=\"https://xarray.pydata.org\">XArray</a>: Provides computation on NetCDF-style data.\nXArray extends NumPy and Pandas to enable scientists to express complex computations on complex datasets\nin ways that they find intuitive.</li>\n  <li><a href=\"https://dask.pydata.org\">Dask</a>: Provides the parallel computation behind XArray</li>\n  <li><a href=\"https://github.com/dask/daskernetes\">Daskernetes</a>: Makes it easy to launch Dask clusters on Kubernetes</li>\n  <li><a href=\"https://kubernetes.io/\">Kubernetes</a>: In case it’s not already clear, all of this is based on Kubernetes,\nwhich manages launching programs (like Jupyter notebook servers or Dask workers) on different machines,\nwhile handling load balancing, permissions, and so on</li>\n  <li><a href=\"https://cloud.google.com/kubernetes-engine/\">Google Container Engine</a>: Google’s managed Kubernetes service.\nEvery major cloud provider now has such a system,\nwhich makes us happy about not relying too heavily on one system</li>\n  <li><a href=\"http://gcsfs.readthedocs.io/en/latest/\">GCSFS</a>: A Python library providing intuitive access to Google Cloud Storage,\neither through Python file interfaces or through a <a href=\"https://en.wikipedia.org/wiki/Filesystem_in_Userspace\">FUSE</a> file system</li>\n  <li><a href=\"http://zarr.readthedocs.io/en/stable/\">Zarr</a>: A chunked array storage format that is suitable for the cloud</li>\n</ul>\n\n<h2 id=\"collaboration\">Collaboration</h2>\n\n<p>We were able to build, deploy, and use this system to answer real science questions in a couple weeks.\nWe feel that this result is significant in its own right,\nand is largely because we collaborated widely.\nThis project required the expertise of several individuals across several projects, institutions, and funding sources.\nHere are a few examples of who did what from which organization.\nWe list institutions and positions mostly to show the roles involved.</p>\n\n<ul>\n  <li>Alistair Miles, Professor, Oxford:\nHelped to optimize Zarr for XArray on GCS</li>\n  <li>Jacob Tomlinson, Staff, UK Met Informatics Lab:\nDeveloped original JADE deployment and early Dask-Kubernetes work.</li>\n  <li>Joe Hamman, Postdoc, National Center for Atmospheric Research:\nProvided scientific use case, data, and work flow.\nTuned XArray and Zarr for efficient data storing and saving.</li>\n  <li>Martin Durant, Software developer, Anaconda Inc.:\nTuned GCSFS for many-access workloads.  Also provided FUSE system for NetCDF support</li>\n  <li>Matt Pryor, Staff, Centre for Envronmental Data Analysis:\nExtended original JADE deployment and early Dask-Kubernetes work.</li>\n  <li>Matthew Rocklin, Software Developer, Anaconda Inc.\nIntegration.  Also performance testing.</li>\n  <li>Ryan Abernathey, Assistant Professor, Columbia University:\nXArray + Zarr support, scientific use cases, coordination</li>\n  <li>Stephan Hoyer, Software engineer, Google:\nXArray support</li>\n  <li>Yuvi Panda, Staff, UC Berkeley BIDS and Data Science Education Program:\nProvided assistance configuring JupyterHub with KubeSpawner.\nAlso prototyped the Daskernetes Dask + Kubernetes tool.</li>\n</ul>\n\n<p>Notice the mix of academic and for-profit institutions.\nAlso notice the mix of scientists, staff, and professional software developers.\nWe believe that this mixture helps ensure the efficient construction of useful solutions.</p>\n\n<h2 id=\"lessons\">Lessons</h2>\n\n<p>This experiment has taught us a few things that we hope to explore further:</p>\n\n<ol>\n  <li>\n    <p>Users can launch Kubernetes deployments from Kubernetes pods,\nsuch as launching Dask clusters from their JupyterHub single-user notebooks.</p>\n\n    <p>To do this well we need to start defining user roles more explicitly within JupyterHub.\nWe need to give users a safe an isolated space on the cluster to use without affecting their neighbors.</p>\n  </li>\n  <li>\n    <p>HDF5 and NetCDF on cloud storage is an open question</p>\n\n    <p>The file formats used for this sort of data are pervasive,\nbut not particulary convenient or efficent on cloud storage.\nIn particular the libraries used to read them make many small reads,\neach of which is costly when operating on cloud object storage</p>\n\n    <p>I see a few options:</p>\n\n    <ol>\n      <li>Use FUSE file systems,\nbut tune them with tricks like read-ahead and caching\nin order to compensate for HDF’s access patterns</li>\n      <li>Use the HDF group’s proposed HSDS service,\nwhich promises to resolve these issues</li>\n      <li>Adopt new file formats that are more cloud friendly.\nZarr is one such example that has so far performed admirably,\nbut certainly doesn’t have the long history of trust that HDF and NetCDF have earned.</li>\n    </ol>\n  </li>\n  <li>\n    <p>Environment customization is important and tricky, especially when adding distributed computing.</p>\n\n    <p>Immediately after showing this to science groups they want to try it out with their own software environments.\nThey can do this easily in their notebook session with tools like pip or conda,\nbut to apply those same changes to their dask workers is a bit more challenging,\nespecially when those workers come and go dynamically.</p>\n\n    <p>We have solutions for this.\nThey can bulid and publish docker images.\nThey can add environment variables to specify extra pip or conda packages.\nThey can deploy their own pangeo deployment for their own group.</p>\n\n    <p>However these have all taken some work to do well so far.\nWe hope that some combination of Binder-like publishing and small modification tricks like environment variables resolve this problem.</p>\n  </li>\n  <li>\n    <p>Our docker images are very large.\nThis means that users sometimes need to wait a minute or more for their session or their dask workers to start up\n(less after things have warmed up a bit).</p>\n\n    <p>It is surprising how much of this comes from conda and node packages.\nWe hope to resolve this both by improving our Docker hygeine\nand by engaging packaging communities to audit package size.</p>\n  </li>\n  <li>\n    <p>Explore other clouds</p>\n\n    <p>We started with Google just because their Kubernetes support has been around the longest,\nbut all major cloud providers (Google, AWS, Azure) now provide some level of managed Kubernetes support.\nEverything we’ve done has been cloud-vendor agnostic, and various groups with data already on other clouds have reached out and are starting deployment on those systems.</p>\n  </li>\n  <li>\n    <p>Combine efforts with other groups</p>\n\n    <p>We’re actually not the first group to do this.\nThe UK Met Informatics Lab quietly built a similar prototype, JADE (Jupyter and Dask Environment) many months ago.\nWe’re now collaborating to merge efforts.</p>\n\n    <p>It’s also worth mentioning that they prototyped the first iteration of Daskernetes.</p>\n  </li>\n  <li>\n    <p>Reach out to other communities</p>\n\n    <p>While we started our collaboration with atmospheric and oceanographic scientists,\nthese same solutions apply to many other disciplines.\nWe should investigate other fields and start collaborations with those communities.</p>\n  </li>\n  <li>\n    <p>Improve Dask + XArray algorithms</p>\n\n    <p>When we try new problems in new environments we often uncover new opportunities to improve Dask’s internal scheduling algorithms.\nThis case is no different :)</p>\n  </li>\n</ol>\n\n<p>Much of this upcoming work is happening in the upstream projects\nso this experimentation is both of concrete use to ongoing scientific research\nas well as more broad use to the open source communities that these projects serve.</p>\n\n<h2 id=\"community-uptake\">Community uptake</h2>\n\n<p>We presented this at a couple conferences over the past week.</p>\n\n<ul>\n  <li>American Meteorological Society, Python Symposium, Keynote.  Slides: <a href=\"http://matthewrocklin.com/slides/ams-2018.html#/\">http://matthewrocklin.com/slides/ams-2018.html#/</a></li>\n  <li>Earth Science Information Partners Winter Meeting.  Video: <a href=\"https://www.youtube.com/watch?v=mDrjGxaXQT4\">https://www.youtube.com/watch?v=mDrjGxaXQT4</a></li>\n</ul>\n\n<p>We found that this project aligns well with current efforts from many government agencies to publish large datasets on cloud stores (mostly S3).\nMany of these data publication endeavors seek a computational system to enable access for the scientific public.\nOur project seems to complement these needs without significant coordination.</p>\n\n<h2 id=\"disclaimers\">Disclaimers</h2>\n\n<p>While we encourage people to try out <a href=\"http://pangeo.pydata.org\">pangeo.pydata.org</a> we also warn you that this system is immature.\nIn particular it has the following issues:</p>\n\n<ol>\n  <li>it is insecure, please do not host sensitive data</li>\n  <li>it is unstable, and may be taken down at any time</li>\n  <li>it is small, we only have a handful of cores deployed at any time, mostly for experimentation purposes</li>\n</ol>\n\n<p>However it is also <em>open</em>, and instructions to deploy your own <a href=\"https://github.com/pangeo-data/pangeo/tree/master/gce\">live here</a>.</p>\n\n<h2 id=\"come-help\">Come help</h2>\n\n<p>We are a growing group comprised of many institutions including technologists, scientists, and open source projects.\nThere is plenty to do and plenty to discuss.\nPlease engage with us at <a href=\"https://github.com/pangeo-data/pangeo/issues/new\">github.com/pangeo-data/pangeo/issues/new</a></p>"
}