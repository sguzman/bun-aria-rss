{
  "guid": "tag:blogger.com,1999:blog-6300367579216018061.post-4907209467989693658",
  "pubDate": "Tue, 10 Mar 2015 08:01:00 +0000",
  "atom:updated": "2015-12-08T00:38:05.643-08:00",
  "category": [
    "apache spark",
    "docker",
    "docker compose",
    "docker swarm",
    "graphx",
    "Mazerunner",
    "neo4j",
    "spark neo4j",
    "tutorial"
  ],
  "title": "Getting Started with Apache Spark and Neo4j Using Docker Compose",
  "description": "<div class=\"separator\" style=\"clear: both; text-align: center; margin-right: 1em;\"><a href=\"http://i.imgur.com/SPwFYVD.png\" imageanchor=\"1\" style=\"clear: left; float: right; margin-bottom: 1em; margin-right: 1em; padding-left: 2em;\"><img border=\"0\" style=\"max-width: 300px;\" src=\"http://i.imgur.com/SPwFYVD.png\" /></a></div><p>I've received a lot of interest in <a href=\"http://www.kennybastani.com/2014/11/using-apache-spark-and-neo4j-for-big.html\">Neo4j Mazerunner</a> since first announcing it a few months ago. People from around the world have reached out to me and are excited about the possibilities of using <a href=\"https://github.com/kbastani/neo4j-mazerunner\">Apache Spark and Neo4j together</a>. From authors who are writing new books about big data to PhD researchers who need it to solve the world's most challenging problems.  <p>I'm glad to see such a wide range of needs for a simple integration like this. Spark and Neo4j are two great open source projects that are focusing on doing one thing very well. Integrating both products together makes for an awesome result.</p> <h2>Less is always more, simpler is always better.</h2><p>Both <a href=\"https://spark.apache.org/\">Apache Spark</a> and <a href=\"http://www.neo4j.com\">Neo4j</a> are two tremendously useful tools. I've seen how both of these two tools give their users a way to transform problems that start out both large and complex into problems that become <i>simpler and easier to solve</i>. That's what the companies behind these platforms are getting at. They are two sides of the same coin.   <p>One tool solves for scaling the size, complexity, and retrieval of data, while the other is solving for the complexity of processing the enormity of data by distributed computation at scale. Both of these products are achieving this without sacrificing ease of use.</p> <p>Inspired by this, I've been working to make the integration in <a href=\"https://registry.hub.docker.com/u/kbastani/neo4j-graph-analytics/\">Neo4j Mazerunner</a> easier to install and deploy. I believe I've taken a step forward in this and I'm excited to announce it in this blog post.</p> <div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://i.imgur.com/6DanVHg.png\" imageanchor=\"1\" style=\"margin-left: 1em; display: block; margin-bottom: 2em; margin-right: 1em;\"><img border=\"0\" style=\"height: auto; max-width: 42em; vertical-align: middle; width: 100%;\" src=\"http://i.imgur.com/6DanVHg.png\" /></a></div> <a name='more'></a> <h2>Announcing Spark Neo4j for Docker</h2> <p>I'll start by saying that I'm not announcing yet another new open source project. <a href=\"https://registry.hub.docker.com/u/kbastani/spark-neo4j/\">Spark Neo4j</a> is a Docker image that uses the new <a href=\"https://docs.docker.com/compose/\">Compose</a> tool to make it easier to deploy and eventually scale both Neo4j and Spark into their own clusters using <a href=\"https://docs.docker.com/swarm/\">Docker Swarm</a>.</p> <p>Docker Compose is something I've been waiting awhile for. It's one pillar of Docker's answer to cluster computing using containers. This previously not so easy thing to do on Docker is now completely doable. In a simple way. That's really exciting.</p> <p>Now let's get on to this business of processing graphs.</p> <h2>Installing Spark Neo4j</h2> <p>The tutorial below is meant for Mac users. If you're on Linux, I've got you covered: <a href=\"https://github.com/kbastani/spark-neo4j/wiki/Linux-Install-Guide\">Spark Neo4j Linux install guide</a>. </p><p>This tutorial will walk you through:</p><ul><li>Setting up Spark Neo4j cluster using Docker</li><li>Streaming log output from Spark and Neo4j</li><li>Using Spark GraphX to calculate PageRank and Closeness Centrality on a celebrity graph</li><li>Querying the results in Neo4j to find the most influential actor in Hollywood</li></ul><h3 id=\"requirements\">Requirements</h3><p>Get Docker:  <a href=\"https://docs.docker.com/installation/\">https://docs.docker.com/installation/</a></p><p>After you&#39;ve installed Docker on Mac OSX with boot2docker, you&#39;ll need to make sure that the <code>DOCKER_HOST</code> environment variable points to the URL of the Docker daemon.</p><pre class=\"cm-s-pastel-on-dark CodeMirror\" data-lang=\"text/x-sh\"><br />$ export DOCKER_HOST=tcp://$(boot2docker ip 2&gt;/dev/null):2375<br /></pre><blockquote><p>Neo4j Spark uses the <code>DOCKER_HOST</code> environment variable to manage multiple containers with <a href=\"https://docs.docker.com/compose/\">Docker Compose</a>.</p></blockquote><p>Run the following command in your current shell to generate the other necessary Docker configurations:</p><pre class=\"cm-s-pastel-on-dark CodeMirror\" data-lang=\"text/x-sh\"><br />$ $(boot2docker shellinit)</pre><blockquote><p>You&#39;ll need to repeat this process if you open a new shell. Spark Neo4j requires the following environment variables: <code>DOCKER_HOST</code>, <code>DOCKER_CERT_PATH</code>, and <code>DOCKER_TLS_VERIFY</code>.</p></blockquote><h4 id=\"start-the-spark-neo4j-cluster\">Start the Spark Neo4j cluster</h4><p>In your current shell, run the following command to download and launch the Spark Neo4j cluster.</p><pre class=\"cm-s-pastel-on-dark CodeMirror\" data-lang=\"text/x-sh\"><br />$ docker run  --env DOCKER_HOST=$DOCKER_HOST \\<br />              --env DOCKER_TLS_VERIFY=$DOCKER_TLS_VERIFY \\<br />              --env DOCKER_CERT_PATH=/docker/cert \\<br />              -v $DOCKER_CERT_PATH:/docker/cert \\<br />              -ti kbastani/spark-neo4j up -d<br /></pre><blockquote><p>This command will pull down multiple docker images the first time you run it. Grab a beer or coffee. You&#39;ll soon be taking over the world with your new found graph processing skills.</p></blockquote><h4 id=\"stream-log-output-from-the-cluster\">Stream log output from the cluster</h4><p>After the Docker images are installed and configured, you will be able to access the Neo4j browser. To know whether or not Neo4j has been started, you can stream the log output from your Spark Neo4j cluster by running this command in your current shell:</p><pre class=\"cm-s-pastel-on-dark CodeMirror\" data-lang=\"text/x-sh\">$ docker run  --env DOCKER_HOST=$DOCKER_HOST \\<br />              --env DOCKER_TLS_VERIFY=$DOCKER_TLS_VERIFY \\<br />              --env DOCKER_CERT_PATH=/docker/cert \\<br />              -v $DOCKER_CERT_PATH:/docker/cert \\<br />              -ti kbastani/spark-neo4j logs graphdb<br /></pre><p>This command will stream the log output from Neo4j to your current shell.</p> <pre class=\"cm-s-pastel-on-dark CodeMirror\" style=\"word-wrap: initial; overflow: auto;\" data-lang=\"text/x-sh\"><br />...<br />graphdb_1    | 20:18:36.736 [main] INFO  o.e.jetty.server.ServerConnector - Started ServerConnector@788ddc1f{HTTP/1.1}{0.0.0.0:7474}<br />graphdb_1    | 20:18:36.908 [main] INFO  o.e.jetty.server.ServerConnector - Started ServerConnector@24d61e4{SSL-HTTP/1.1}{0.0.0.0:7473}<br />graphdb_1    | 2015-03-08 20:18:36.908+0000 INFO  [API] Server started on: http://0.0.0.0:7474/<br />graphdb_1    | 2015-03-08 20:18:36.909+0000 INFO  [API] Remote interface ready and available at [http://0.0.0.0:7474/]<br /></pre> <p>Confirm that Neo4j has started before continuing.</p><blockquote><p><code>CTRL-C</code> will exit the log view and bring you back to your current shell.</p><p>You can alter the above command to stream log output from all service containers simultaneously by removing <code>graphdb</code> from the last line.</p></blockquote><h4 id=\"open-the-neo4j-browser\">Open the Neo4j browser</h4><p>Now that you&#39;ve confirmed Neo4j is running as a container in your Docker host, let&#39;s open up Neo4j&#39;s browser and test running PageRank on actors in a movie dataset.</p><p>Run the following command to open a browser window that navigates to Neo4j&#39;s URL.</p><pre class=\"cm-s-pastel-on-dark CodeMirror\" data-lang=\"text/x-sh\">$ open $(echo \\&quot;$(echo $DOCKER_HOST)\\&quot;|<br />              \\sed &#39;s/tcp:\\/\\//http:\\/\\//g&#39;|<br />              \\sed &#39;s/[0-9]\\{4,\\}/7474/g&#39;|<br />              \\sed &#39;s/\\&quot;//g&#39;)<br /></pre><blockquote><p>This command finds the <code>$DOCKER_HOST</code> environment variable to generate the URL of Neo4j&#39;s browser. On Linux, this would be <a href=\"http://localhost:7474\">http://localhost:7474</a>.</p></blockquote><h4 id=\"import-the-movie-graph\">Import the movie graph</h4><p>In the Neo4j console type <code>:play movies</code> and press enter. Follow the directions to import the movie sample dataset.</p><blockquote><p>We&#39;ll use this dataset to test the Spark integration by running PageRank on the &quot;Celebrity Graph&quot; of actors.</p></blockquote><p>Now that the movie dataset has been imported, let&#39;s create new relationships between actors who appeared together in the same movie. Copy and paste the following command into the Neo4j console and press <code>CTRL+Enter</code> to execute.</p><pre class=\"cm-neo CodeMirror\" data-lang=\"cypher\"><code>MATCH (p1:Person)-[:ACTED_IN]-&gt;(m:Movie),<br />      (p2:Person)-[:ACTED_IN]-&gt;(m)<br />CREATE (p1)-[:KNOWS]-&gt;(p2)<br /></code></pre><blockquote><p>PageRank measures the probability of finding a node on the graph by randomly following links from one node to another node. It&#39;s a measure of a node&#39;s importance.</p></blockquote><h4 id=\"calculate-pagerank-on-the-celebrity-graph\">Calculate PageRank on the celebrity graph</h4><p>Now that we&#39;ve generated our &quot;Celebrity Graph&quot; by inferring the <code>:KNOWS</code> relationship between co-actors, we can run PageRank on all nodes connected by this new relationship.</p><p>In the Neo4j console, copy and paste the following command:</p><pre><code>:GET /service/mazerunner/analysis/pagerank/KNOWS<br /></code></pre><p>and press enter.</p><p>If everything ran correctly, we should have a result of:</p><pre><code>{<br />  &quot;result&quot;: &quot;success&quot;<br />}<br /></code></pre><blockquote><p>This means that the graph was exported to Spark for processing. </p></blockquote><h4 id=\"monitor-spark-s-log-output\">Monitor Spark&#39;s log output</h4><p>We can monitor the log output from Spark by returning to the terminal we used during setup from earlier. From that shell, run the following command:</p><pre class=\"cm-s-pastel-on-dark CodeMirror\" data-lang=\"text/x-sh\">$ docker run  --env DOCKER_HOST=$DOCKER_HOST \\<br />              --env DOCKER_TLS_VERIFY=$DOCKER_TLS_VERIFY \\<br />              --env DOCKER_CERT_PATH=/docker/cert \\<br />              -v $DOCKER_CERT_PATH:/docker/cert \\<br />              -ti kbastani/spark-neo4j logs<br /></pre><h4 id=\"calculate-closeness-centrality\">Calculate Closeness Centrality</h4><p>You&#39;ll now be able to monitor the real-time log output from the <strong>Spark Neo4j</strong> cluster as you submit new graph processing jobs.</p><p>Return back to the Neo4j browser and run the following command to calculate the Closeness Centrality of our &quot;Celebrity Graph&quot;.</p><pre><code>:GET /service/mazerunner/analysis/closeness_centrality/KNOWS<br /></code></pre><blockquote><p>If your log output from the terminal is visible, you&#39;ll see a flurry of activity from Spark as it calculates this new metric. Don&#39;t blink, you might miss it.</p></blockquote><h4 id=\"querying-the-metrics-from-neo4j\">Querying the metrics from Neo4j</h4><p>You can now query on the newly calculated metrics from Neo4j. In the Neo4j browser, run the following command:</p><pre class=\"cm-neo\" data-lang=\"cypher\">MATCH (p:Person) WHERE has(p.pagerank) AND has(p.closeness_centrality)<br />RETURN p.name, p.pagerank as pagerank, p.closeness_centrality<br />ORDER BY pagerank DESC<br /></pre><p>The results show which of the celebrities have the most influence in Hollywood.</p><blockquote><p>Go forth and process graphs.</p></blockquote>",
  "enclosure": "",
  "link": "https://www.kennybastani.com/2015/03/spark-neo4j-tutorial-docker.html",
  "author": "noreply@blogger.com (Kenny Bastani)",
  "thr:total": 0
}