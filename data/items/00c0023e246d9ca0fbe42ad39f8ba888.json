{
  "title": "Your Opinion Matters",
  "description": "<div style=\"text-align:center\">\n  <img src=\"/assets/posts/2022-07-19-your-opinion-matters/header-screenshot.png\" width=\"80%\" />\n</div>\n\n<h2 id=\"motivation\">Motivation</h2>\n<p>Client feedback is at the heart of Stitch Fix.\nA core part of what powers our personalization engine is the moments of interaction and engagement with our clients – these provide rich, \nactionable feedback and fuel our ability to adapt to the rapidly changing client trends.\nAt Stitch Fix, feedback comes in a variety of shapes: from Style Shuffle likes and dislikes and product ratings on style, \nquality, fit, size and price, to the rich, free form comments in Fix requests or reviews of items.</p>\n\n<p>As our business continues to evolve, we are looking for innovative ways to act on all client feedback, \nno matter if it comes from a new client or someone who has been with us for years. \nIn particular to improve our recommendations and client satisfaction, we realized that free form text feedback is especially important, \nyet challenging to distill for both our Stylists and Algorithms. \nIn the case of Stylists, there can be a high volume of content to read through –  imagine analyzing 100+ comments, \nFix notes, and written feedback from a loyal client who has been with us for years. \nIn the case of Algorithms, understanding human language has been a difficult task for machine learning models. \nHowever, our analysis shows that it is essential to account for written feedback in our Algorithms in order to provide the best possible personalization for our clients.</p>\n\n<p>This blog post uncovers the behind-the-scenes of how we ensure we meet our clients expectations of personalization \nby acting on their written feedback at scale using the new advances in natural language processing (NLP), \nand how this solution opens doors to many other downstream applications.</p>\n\n<h2 id=\"context\">Context</h2>\n<p>The recommendations from our technology are a complementary partner to our Stylists. \nThese recommendations free them up from tedious tasks enabling them to focus on what they are extraordinarily good at—building relationships with clients, \nbeing creative, understanding the nuance and context of a client’s request. \nOur Stylists leverage these recommendations through a custom-built, web-based styling application. \nThey then apply their judgment to select what they believe to be the best items for each Fix.</p>\n\n<p>One of these time consuming tasks is reading through client notes and feedback. There are hundreds of millions of notes clients have sent on our platform. \nClients may describe their preferences and specific needs in a Fix request, or provide feedback on a particular item their Stylist sent. \nEvery time a Stylist prepares a Fix for a client, they are expected to read and take into consideration the content of these notes. \nSome of our most loyal clients submit a high volume of notes, and it can take significant time for a Stylist to acquaint themselves with the content.</p>\n\n<p>We’ve already developed mechanisms to support our Stylists in absorbing this information. As Stylists review free form feedback from a client, \nthey can highlight and save the most important information, such as what a client repeatedly mentions they really like or \ndislike or what a client already owns, in a structured way. Next time, when the same or a different Stylist styles this client, \nthey can quickly reference these crucial facts ensuring the client is heard and their preferences are taken into account.</p>\n\n<h2 id=\"can-we-do-better\">Can we do better?</h2>\n<p>While these tools are helpful for Stylists, we hoped to find a way to streamline this process and help our Algorithm absorb this information at scale, \nto ensure our clients are consistently being recommended products they love and align with their past feedback.</p>\n\n<p>We began to focus on a way to algorithmically extract insights from text feedback from clients and harness them in the recommendation \nsystem that aids Stylists in picking the best items for our clients. The solution was two-fold – first, \nwe extract product characteristics from the client reviews and client preferences from all the different sources of text feedback they provide. \nThen, we leverage the characteristics mentioned to determine what products are the most and least suitable for our clients.</p>\n\n<h2 id=\"opinio1---extraction-of-product-characteristics-at-scale\"><em>Opinio</em><a name=\"back-1\"></a><sup><a href=\"#f1\">1</a></sup> - Extraction of product characteristics at scale</h2>\n<p>Extracting structured product characteristics from free form text feedback is no easy feat. \nWe utilized our experts-in-the-loop – our Stylists to collect the training data. Stylists read a few hundred examples of client feedback notes \nand write down all product characteristics that can be extracted from them. For example:</p>\n\n<p><em>“Super soft and stretchy. I like the pattern.” →  “soft, stretchy, patterned”</em></p>\n\n<p>Altogether, our expert Stylists generated around 10k training examples. \nThanks to this work and the resulting dataset, we can train a GPT-3 model that is able to extract product characteristics \nfrom client feedback it has not seen before.</p>\n\n<p>You may ask why not just use a simple approach like TF-IDF? There are multiple reasons:</p>\n<ul>\n  <li>Relevancy: There are many instances where the client leaves feedback about an attribute they wish the product had. \nA TF-IDF approach would mistakenly assign such attributes to the product. For example, let’s say a client left the following comment on a skirt: \n<em>“LOVED this skirt. The deal breaker was that it did not have pockets.”</em> A TF-IDF approach would result in a high score for <em>“pockets”</em> on this product.</li>\n  <li>Abstraction and reasoning: Sometimes the attribute is not directly mentioned in the comment and some reasoning is required to extract it. \nIn these cases, TF-IDF fails to extract a meaningful attribute. Here are some examples of what TF-IDF can’t do:\n    <ul>\n      <li><em>“Just not my style and too fitted. I like more flowy maxi dresses and the price of this dress is way too high for what it is.” → “fitted, expensive”</em></li>\n      <li><em>“I would have kept this piece but the fabric is see through” → “sheer”</em></li>\n      <li><em>“This style is better for someone much older than me” → “mature”</em></li>\n    </ul>\n  </li>\n</ul>\n\n<p>Up until recently, such problems have been tackled by specialized algorithms and huge datasets, but thanks to new advances in NLP, \noutstanding results can be achieved with just a moderate amount of data. New language models, like GPT-3, \nare pre-trained on massive corpora to learn the syntax and semantics of the English language (and others), \nwhich has enabled us to finetune GPT-3 for our use case with our limited labeled dataset.</p>\n\n<h2 id=\"tag-it---extraction-of-client-preferences-at-scale\">Tag it - Extraction of client preferences at scale</h2>\n<p>After we’ve extracted the attributes themselves, we need to extract if the client likes or dislikes these attributes from \ntheir free form text. We once again leverage our Stylists (experts-in-the-loop) to “tag” free form comments – each expert \nreads a sample of a few hundred client notes and writes down what product characteristics the client likes and dislikes. For example:</p>\n\n<p><em>“It all seems a bit too business casual for me. I’m looking for something a little bit more bohemian and casual. \nMore funky styles for Austin concerts.” → “dislikes business casual, likes bohemian, likes casual, likes funky styles”</em></p>\n\n<p>Again, our experts generated around 10k training examples. We then use this data to finetune a GPT-3 model that is able to extract client \nlikes and dislikes from client notes at scale.</p>\n\n<h2 id=\"accounting-for-structured-insights-in-the-recommendation-system\">Accounting for structured insights in the recommendation system</h2>\n\n<p>Now that we have extracted the specific characteristics of products each client likes and dislikes, \nwe can incorporate this knowledge into our algorithm, and therefore our recommendations to clients.<br />\nAfter an analysis, we decided to first focus on suppressing items that had attributes a client disliked \n(and act on “boosting” items with positive attributes in the future stages of the project).</p>\n\n<p>As you may already know from our previous blog posts (<a href=\"https://multithreaded.stitchfix.com/blog/2019/07/09/simulacra-and-selection/\">Simulacra and Selection</a>), \nour Stylists have the ultimate say in what products end up in a client’s Fix. But our recommendation system helps them \nin picking the best products using data science by predicting what they’ll like and matches their size and budget.\nWe algorithmically account for clients’ dislikes in our recommendations by reducing the probability of showing a \nproduct which has “negative” characteristics (what a client dislikes). This can be achieved by playing with some levers \navailable in the recommendation system.</p>\n\n<p>The advantage of having a Stylist is that human supervision can cover many edge cases. \nA Stylist is still able to override any of these interventions, in the case the client specifically asks for \nsomething in a note which they’ve previously indicated they’ve disliked. For example, if a client said they hate dresses, \nbut then requests a dress for a wedding, Stylists can override this mechanism.</p>\n\n<p>Before recommending a set of products for a client to a Stylist, we identify which products from the set of available \nproducts for this client should be suppressed. There are multiple ways of finding these products – in this case, \nwe made use of a search algorithm that leverages <em>Opinio</em> extracted product characteristics plus the standard attributes we \nhave for all products at Stitch Fix. For each client, we have an indicated list of their disliked product characteristics. \nFor each of these dislikes, we perform a search query to find which products from the current available inventory match this dislike. \nWe consecutively reduce the probability of showing those products to the Stylist as they find the best selections for the client.</p>\n\n<p>For example, if a client has indicated in past notes that they don’t like <em>“busy patterns,”</em> the Algorithm has extracted \nthat information on the client and we’ve incorporated that into our algorithm. When a Stylist is working on a Fix for this client, \nthe algorithm will suppress items currently available in the inventory that are tagged with a <em>“patterned”</em> attribute, \nto assist Stylists and ensure they select an item that is NOT patterned.</p>\n\n<p>Experimentation is in progress to assess the impact of these interventions on our client satisfaction.</p>\n\n<h2 id=\"ideas-for-other-use-cases\">Ideas for other use cases</h2>\n<p>As a result of our work, we generated a large data set of structured insights about our products and client preferences. \nLeveraging this data set to improve recommendations for our clients was of the highest priority, \nhowever there are many other applications of this data. As mentioned earlier, the advances in machine learning have opened \ndoors to many possibilities, and if we can combine the results of this work with other cutting-edge models, \nwe can unlock many new unforseen capabilities.</p>\n\n<p>For example, we experimented with utilizing DALL-E 2 to visualize our products based on extracted structured \nproduct characteristics that have a high TF-IDF score. This way we could surface the most informative \ncharacteristics of a product in a visual way:</p>\n\n<p><em>Opinio</em> product characteristics: high rise, skinny, great color, red, fun color, great fit, stretchy, without distressing jeans</p>\n\n<p>Image generated by DALL-E 2:</p>\n\n<div style=\"text-align:center\">\n  <img src=\"/assets/posts/2022-07-19-your-opinion-matters/red_jean_gen.png\" width=\"80%\" />\n</div>\n\n<p>The actual product:</p>\n\n<div style=\"text-align:center\">\n  <img src=\"/assets/posts/2022-07-19-your-opinion-matters/red_jean_actual.png\" width=\"80%\" />\n</div>\n\n<p><em>Opinio</em> product characteristics: soft, olive green, great color, pockets, patterned, cute texture, long, cardigan</p>\n\n<p>Image generated by DALL-E 2:</p>\n\n<div style=\"text-align:center\">\n  <img src=\"/assets/posts/2022-07-19-your-opinion-matters/olive_card_gen.png\" width=\"80%\" />\n</div>\n\n<p>The actual product:</p>\n\n<div style=\"text-align:center\">\n  <img src=\"/assets/posts/2022-07-19-your-opinion-matters/olive_card_actual.png\" width=\"80%\" />\n</div>\n\n<p>Moreover, <em>Opinio</em> product characteristics can help with improving precision and recall of search queries for our products. \nThey can also be used to inform issues with our inventory. When tracked over time, \nthey can be an interesting source of insights about client preferences and how they change. \nFinally, we could also surface them directly to either our Stylists or clients to help them understand in more detail what \nthe qualities of each product are and bring more confidence to their purchase or recommendation decisions.</p>\n\n<p>This is one of the many ways we incorporate data into our decision making and recommendations. \nWe’re continuing to build on these efforts and find new ways to utilize our clients’ feedback for long term trust \nand satisfaction in our recommendations.</p>\n\n<h4 id=\"footnotes\">Footnotes</h4>\n\n<p><a name=\"f1\"></a>\n<a href=\"#back-1\">[1]↩</a>The name was generated by us using GPT-3.</p>",
  "pubDate": "Tue, 19 Jul 2022 09:00:00 +0000",
  "link": "https://multithreaded.stitchfix.com/blog/2022/07/19/your-opinion-matters/",
  "guid": "https://multithreaded.stitchfix.com/blog/2022/07/19/your-opinion-matters/"
}