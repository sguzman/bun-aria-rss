{
  "title": "If you did not already know",
  "link": "https://analytixon.com/2022/10/27/if-you-did-not-already-know-1869/",
  "comments": "https://analytixon.com/2022/10/27/if-you-did-not-already-know-1869/#respond",
  "dc:creator": "Michael Laux",
  "pubDate": "Thu, 27 Oct 2022 00:01:16 +0000",
  "category": "What is ...",
  "guid": "https://analytixon.com/?p=37415",
  "description": "Batch-Mode Active Learning Recently, Convolutional Neural Networks (CNNs) have shown unprecedented success in the field of computer vision, especially on &#8230;<p><a href=\"https://analytixon.com/2022/10/27/if-you-did-not-already-know-1869/\">Continue reading <span class=\"meta-nav\">&#8594;</span></a></p>",
  "content:encoded": "<p><a href=\"http://arxiv.org/abs/1905.09247v1\" target=\"top\" rel=\"noopener\"><strong>Batch-Mode Active Learning</strong></a>  <a href=\"https://www.google.de/search?q=Batch-Mode Active Learning\" target=\"_blank\" rel=\"noopener\"><img decoding=\"async\" class=\"alignright\" src=\"https://analytixon.files.wordpress.com/2015/01/google.png?w=529\" alt=\"google\" data-recalc-dims=\"1\"/></a><BR/><span style=\"font-size:12px;font-style:normal;text-align:justify;\">Recently, Convolutional Neural Networks (CNNs) have shown unprecedented success in the field of computer vision, especially on challenging image classification tasks by relying on a universal approach, i.e., training a deep model on a massive dataset of supervised examples. While unlabeled data are often an abundant resource, collecting a large set of labeled data, on the other hand, are very expensive, which often require considerable human efforts. One way to ease out this is to effectively select and label highly informative instances from a pool of unlabeled data (i.e., active learning). This paper proposed a new method of batch-mode active learning, Dual Active Sampling(DAS), which is based on a simple assumption, if two deep neural networks (DNNs) of the same structure and trained on the same dataset give significantly different output for a given sample, then that particular sample should be picked for additional training. While other state of the art methods in this field usually require intensive computational power or relying on a complicated structure, DAS is simpler to implement and, managed to get improved results on Cifar-10 with preferable computational time compared to the core-set method. &#8230; </span><BR/><BR/><a href=\"http://arxiv.org/abs/1811.09955v1\" target=\"top\" rel=\"noopener\"><strong>Online Gradient Descent With Expected Gradient (OGDEG)</strong></a>  <a href=\"https://www.google.de/search?q=Online Gradient Descent With Expected Gradient\" target=\"_blank\" rel=\"noopener\"><img decoding=\"async\" class=\"alignright\" src=\"https://analytixon.files.wordpress.com/2015/01/google.png?w=529\" alt=\"google\" data-recalc-dims=\"1\"/></a><BR/><span style=\"font-size:12px;font-style:normal;text-align:justify;\">Online learning with limited information feedback (bandit) tries to solve the problem where an online learner receives partial feedback information from the environment in the course of learning. Under this setting, Flaxman extends Zinkevich&#8217;s classical Online Gradient Descent (OGD) algorithm Zinkevich [2003] by proposing the Online Gradient Descent with Expected Gradient (OGDEG) algorithm. Specifically, it uses a simple trick to approximate the gradient of the loss function $f_t$ by evaluating it at a single point and bounds the expected regret as $\\mathcal{O}(T^{5/6})$ Flaxman et al. [2005]. It has been shown that compared with the first-order algorithms, second-order online learning algorithms such as Online Newton Step (ONS) Hazan et al. [2007] can significantly accelerate the convergence rate in traditional online learning. Motivated by this, this paper aims to exploit second-order information to speed up the convergence of OGDEG. In particular, we extend the ONS algorithm with the trick of expected gradient and develop a novel second-order online learning algorithm, i.e., Online Newton Step with Expected Gradient (ONSEG). Theoretically, we show that the proposed ONSEG algorithm significantly reduces the expected regret of OGDEG from $\\mathcal{O}(T^{5/6})$ to $\\mathcal{O}(T^{2/3})$ in the bandit feedback scenario. Empirically, we demonstrate the advantages of the proposed algorithm on several real-world datasets. &#8230; </span><BR/><BR/><a href=\"http://arxiv.org/abs/1802.00212v1\" target=\"top\" rel=\"noopener\"><strong>Power Linear Unit (PoLU)</strong></a>  <a href=\"https://www.google.de/search?q=Power Linear Unit\" target=\"_blank\" rel=\"noopener\"><img decoding=\"async\" class=\"alignright\" src=\"https://analytixon.files.wordpress.com/2015/01/google.png?w=529\" alt=\"google\" data-recalc-dims=\"1\"/></a><BR/><span style=\"font-size:12px;font-style:normal;text-align:justify;\">In this paper, we introduce &#8216;Power Linear Unit&#8217; (PoLU) which increases the nonlinearity capacity of a neural network and thus helps improving its performance. PoLU adopts several advantages of previously proposed activation functions. First, the output of PoLU for positive inputs is designed to be identity to avoid the gradient vanishing problem. Second, PoLU has a non-zero output for negative inputs such that the output mean of the units is close to zero, hence reducing the bias shift effect. Thirdly, there is a saturation on the negative part of PoLU, which makes it more noise-robust for negative inputs. Furthermore, we prove that PoLU is able to map more portions of every layer&#8217;s input to the same space by using the power function and thus increases the number of response regions of the neural network. We use image classification for comparing our proposed activation function with others. In the experiments, MNIST, CIFAR-10, CIFAR-100, Street View House Numbers (SVHN) and ImageNet are used as benchmark datasets. The neural networks we implemented include widely-used ELU-Network, ResNet-50, and VGG16, plus a couple of shallow networks. Experimental results show that our proposed activation function outperforms other state-of-the-art models with most networks. &#8230; </span><BR/><BR/><a href=\"http://arxiv.org/abs/1803.09017v1\" target=\"top\" rel=\"noopener\"><strong>Global Style Token (GST)</strong></a>  <a href=\"https://www.google.de/search?q=Global Style Token\" target=\"_blank\" rel=\"noopener\"><img decoding=\"async\" class=\"alignright\" src=\"https://analytixon.files.wordpress.com/2015/01/google.png?w=529\" alt=\"google\" data-recalc-dims=\"1\"/></a><BR/><span style=\"font-size:12px;font-style:normal;text-align:justify;\">In this work, we propose &#8216;global style tokens&#8217; (GSTs), a bank of embeddings that are jointly trained within Tacotron, a state-of-the-art end-to-end speech synthesis system. The embeddings are trained with no explicit labels, yet learn to model a large range of acoustic expressiveness. GSTs lead to a rich set of significant results. The soft interpretable &#8216;labels&#8217; they generate can be used to control synthesis in novel ways, such as varying speed and speaking style &#8211; independently of the text content. They can also be used for style transfer, replicating the speaking style of a single audio clip across an entire long-form text corpus. When trained on noisy, unlabeled found data, GSTs learn to factorize noise and speaker identity, providing a path towards highly scalable but robust speech synthesis. &#8230; </span><BR/></p>\n",
  "wfw:commentRss": "https://analytixon.com/2022/10/27/if-you-did-not-already-know-1869/feed/",
  "slash:comments": 0,
  "post-id": 37415
}