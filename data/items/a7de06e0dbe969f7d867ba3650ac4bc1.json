{
  "title": "Empirical Analysis of Model Selection for Heterogenous Causal Effect Estimation. (arXiv:2211.01939v1 [cs.LG])",
  "link": "http://arxiv.org/abs/2211.01939",
  "description": "<p>We study the problem of model selection in causal inference, specifically for\nthe case of conditional average treatment effect (CATE) estimation under binary\ntreatments. Unlike model selection in machine learning, we cannot use the\ntechnique of cross-validation here as we do not observe the counterfactual\npotential outcome for any data point. Hence, we need to design model selection\ntechniques that do not explicitly rely on counterfactual data. As an\nalternative to cross-validation, there have been a variety of proxy metrics\nproposed in the literature, that depend on auxiliary nuisance models also\nestimated from the data (propensity score model, outcome regression model).\nHowever, the effectiveness of these metrics has only been studied on synthetic\ndatasets as we can observe the counterfactual data for them. We conduct an\nextensive empirical analysis to judge the performance of these metrics, where\nwe utilize the latest advances in generative modeling to incorporate multiple\nrealistic datasets. We evaluate 9 metrics on 144 datasets for selecting between\n415 estimators per dataset, including datasets that closely mimic real-world\ndatasets. Further, we use the latest techniques from AutoML to ensure\nconsistent hyperparameter selection for nuisance models for a fair comparison\nacross metrics.\n</p>",
  "dc:creator": "<a href=\"http://arxiv.org/find/cs/1/au:+Mahajan_D/0/1/0/all/0/1\">Divyat Mahajan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitliagkas_I/0/1/0/all/0/1\">Ioannis Mitliagkas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neal_B/0/1/0/all/0/1\">Brady Neal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Syrgkanis_V/0/1/0/all/0/1\">Vasilis Syrgkanis</a>"
}