{
  "title": "Distributed Prototype",
  "link": "",
  "updated": "2015-10-09T00:00:00+00:00",
  "id": "https://mrocklin.github.io/blog/work/2015/10/09/Distributed",
  "content": "<p><em>This work is supported by <a href=\"http://continuum.io\">Continuum Analytics</a>\nand the <a href=\"http://www.darpa.mil/program/XDATA\">XDATA Program</a>\nas part of the <a href=\"http://blaze.pydata.org\">Blaze Project</a></em></p>\n\n<p><strong>tl;dr: We demonstrate a prototype distributed computing library and discuss\ndata locality.</strong></p>\n\n<h2 id=\"distributed-computing\">Distributed Computing</h2>\n\n<p>Here’s a new prototype library for distributed computing.\nIt could use some critical feedback.</p>\n\n<ul>\n  <li><a href=\"http://distributed.readthedocs.org/en/latest/\">distributed.readthedocs.org/en/latest/</a></li>\n  <li><a href=\"http://github.com/mrocklin/distributed/\">github.com/mrocklin/distributed/</a></li>\n</ul>\n\n<p>This blogpost uses <code class=\"language-plaintext highlighter-rouge\">distributed</code> on a toy example.  I won’t talk about the\ndesign here, but the docs should be a quick and informative read.  I recommend\nthe <a href=\"http://distributed.readthedocs.org/en/latest/quickstart.html\">quickstart</a>\nin particular.</p>\n\n<p>We’re going to do a simple computation a few different ways on a cluster of\nfour nodes.  The computation will be</p>\n\n<ol>\n  <li>Make a 1000 random numpy arrays, each of size 1 000 000</li>\n  <li>Compute the sum of each array</li>\n  <li>Compute the total sum of the sums</li>\n</ol>\n\n<p>We’ll do this directly with a distributed Pool and again with a dask graph.</p>\n\n<h2 id=\"start-up-a-cluster\">Start up a Cluster</h2>\n\n<p>I have a cluster of four <code class=\"language-plaintext highlighter-rouge\">m3.xlarge</code>s on EC2</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>$ ssh node1\n$ dcenter\n\n$ ssh node2\n$ dworkder node1:8787\n\n$ ssh node3\n$ dworkder node1:8787\n\n$ ssh node4\n$ dworkder node1:8787\n</code></pre></div></div>\n\n<p><a href=\"https://gist.github.com/mrocklin/3c1e47f403490edb9473\">Notes on how I set up my cluster.</a></p>\n\n<h2 id=\"pool\">Pool</h2>\n\n<p>On the client side we spin up a distributed <code class=\"language-plaintext highlighter-rouge\">Pool</code> and point it to the center\nnode.</p>\n\n<figure class=\"highlight\">\n  <pre><code class=\"language-python\" data-lang=\"python\"><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">distributed</span> <span class=\"kn\">import</span> <span class=\"n\">Pool</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">pool</span> <span class=\"o\">=</span> <span class=\"n\">Pool</span><span class=\"p\">(</span><span class=\"s\">'node1:8787'</span><span class=\"p\">)</span></code></pre>\n</figure>\n\n<p>Then we create a bunch of random numpy arrays:</p>\n\n<figure class=\"highlight\">\n  <pre><code class=\"language-python\" data-lang=\"python\"><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"n\">np</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">arrays</span> <span class=\"o\">=</span> <span class=\"n\">pool</span><span class=\"p\">.</span><span class=\"nb\">map</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"mi\">1000000</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"mi\">1000</span><span class=\"p\">)</span></code></pre>\n</figure>\n\n<p>Our result is a list of proxy objects that point back to individual numpy arrays\non the worker computers.  We don’t move data until we need to.  (Though we\ncould call <code class=\"language-plaintext highlighter-rouge\">.get()</code> on this to collect the numpy array from the worker.)</p>\n\n<figure class=\"highlight\">\n  <pre><code class=\"language-python\" data-lang=\"python\"><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">arrays</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n<span class=\"n\">RemoteData</span><span class=\"o\">&lt;</span><span class=\"n\">center</span><span class=\"o\">=</span><span class=\"mf\">10.141</span><span class=\"p\">.</span><span class=\"mf\">199.202</span><span class=\"p\">:</span><span class=\"mi\">8787</span><span class=\"p\">,</span> <span class=\"n\">key</span><span class=\"o\">=</span><span class=\"mf\">3e446310</span><span class=\"o\">-</span><span class=\"mf\">6.</span><span class=\"p\">..</span><span class=\"o\">&gt;</span></code></pre>\n</figure>\n\n<p>Further computations on this data happen on the cluster, on the worker nodes\nthat hold the data already.</p>\n\n<figure class=\"highlight\">\n  <pre><code class=\"language-python\" data-lang=\"python\"><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">sums</span> <span class=\"o\">=</span> <span class=\"n\">pool</span><span class=\"p\">.</span><span class=\"nb\">map</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"p\">.</span><span class=\"nb\">sum</span><span class=\"p\">,</span> <span class=\"n\">arrays</span><span class=\"p\">)</span></code></pre>\n</figure>\n\n<p>This avoids costly data transfer times.  Data transfer will happen when\nnecessary though, as when we compute the final sum.  This forces communication\nbecause all of the intermediate sums must move to one node for the final\naddition.</p>\n\n<figure class=\"highlight\">\n  <pre><code class=\"language-python\" data-lang=\"python\"><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">total</span> <span class=\"o\">=</span> <span class=\"n\">pool</span><span class=\"p\">.</span><span class=\"nb\">apply</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"p\">.</span><span class=\"nb\">sum</span><span class=\"p\">,</span> <span class=\"n\">args</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"n\">sums</span><span class=\"p\">,))</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">total</span><span class=\"p\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>  <span class=\"c1\"># finally transfer result to local machine\n</span><span class=\"mf\">499853416.82058007</span></code></pre>\n</figure>\n\n<h2 id=\"distributeddask\">distributed.dask</h2>\n\n<p>Now we do the same computation all at once by manually constructing a dask\ngraph (beware, this can get gnarly, friendlier approaches exist below.)</p>\n\n<figure class=\"highlight\">\n  <pre><code class=\"language-python\" data-lang=\"python\"><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">dsk</span> <span class=\"o\">=</span> <span class=\"nb\">dict</span><span class=\"p\">()</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">1000</span><span class=\"p\">):</span>\n<span class=\"p\">...</span>     <span class=\"n\">dsk</span><span class=\"p\">[(</span><span class=\"s\">'x'</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">)]</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">,</span> <span class=\"mi\">1000000</span><span class=\"p\">)</span>\n<span class=\"p\">...</span>     <span class=\"n\">dsk</span><span class=\"p\">[(</span><span class=\"s\">'sum'</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">)]</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">np</span><span class=\"p\">.</span><span class=\"nb\">sum</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"s\">'x'</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">))</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">dsk</span><span class=\"p\">[</span><span class=\"s\">'total'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"nb\">sum</span><span class=\"p\">,</span> <span class=\"p\">[(</span><span class=\"s\">'sum'</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">1000</span><span class=\"p\">)])</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">distributed.dask</span> <span class=\"kn\">import</span> <span class=\"n\">get</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s\">'node1'</span><span class=\"p\">,</span> <span class=\"mi\">8787</span><span class=\"p\">,</span> <span class=\"n\">dsk</span><span class=\"p\">,</span> <span class=\"s\">'total'</span><span class=\"p\">)</span>\n<span class=\"mf\">500004095.00759566</span></code></pre>\n</figure>\n\n<p>Apparently not everyone finds dask dictionaries to be pleasant to write by\nhand.  You could also use this with dask.imperative or dask.array.</p>\n\n<h3 id=\"daskimperative\">dask.imperative</h3>\n\n<figure class=\"highlight\">\n  <pre><code class=\"language-python\" data-lang=\"python\"><span class=\"k\">def</span> <span class=\"nf\">get2</span><span class=\"p\">(</span><span class=\"n\">dsk</span><span class=\"p\">,</span> <span class=\"n\">keys</span><span class=\"p\">):</span>\n    <span class=\"s\">\"\"\" Make `get` scheduler that hardcodes the IP and Port \"\"\"</span>\n    <span class=\"k\">return</span> <span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s\">'node1'</span><span class=\"p\">,</span> <span class=\"mi\">8787</span><span class=\"p\">,</span> <span class=\"n\">dsk</span><span class=\"p\">,</span> <span class=\"n\">keys</span><span class=\"p\">)</span></code></pre>\n</figure>\n\n<figure class=\"highlight\">\n  <pre><code class=\"language-python\" data-lang=\"python\"><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">dask.imperative</span> <span class=\"kn\">import</span> <span class=\"n\">do</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">arrays</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">do</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">)(</span><span class=\"mi\">1000000</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">1000</span><span class=\"p\">)]</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">sums</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">do</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"p\">.</span><span class=\"nb\">sum</span><span class=\"p\">)(</span><span class=\"n\">x</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">x</span> <span class=\"ow\">in</span> <span class=\"n\">arrays</span><span class=\"p\">]</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">total</span> <span class=\"o\">=</span> <span class=\"n\">do</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"p\">.</span><span class=\"nb\">sum</span><span class=\"p\">)(</span><span class=\"n\">sums</span><span class=\"p\">)</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">total</span><span class=\"p\">.</span><span class=\"n\">compute</span><span class=\"p\">(</span><span class=\"n\">get</span><span class=\"o\">=</span><span class=\"n\">get2</span><span class=\"p\">)</span>\n<span class=\"mf\">499993637.00844824</span></code></pre>\n</figure>\n\n<h3 id=\"daskarray\">dask.array</h3>\n\n<figure class=\"highlight\">\n  <pre><code class=\"language-python\" data-lang=\"python\"><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">import</span> <span class=\"nn\">dask.array</span> <span class=\"k\">as</span> <span class=\"n\">da</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">da</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">(</span><span class=\"mi\">1000000</span><span class=\"o\">*</span><span class=\"mi\">1000</span><span class=\"p\">,</span> <span class=\"n\">chunks</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">1000000</span><span class=\"p\">,))</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">x</span><span class=\"p\">.</span><span class=\"nb\">sum</span><span class=\"p\">().</span><span class=\"n\">compute</span><span class=\"p\">(</span><span class=\"n\">get</span><span class=\"o\">=</span><span class=\"n\">get2</span><span class=\"p\">)</span>\n<span class=\"mf\">500000250.44921482</span></code></pre>\n</figure>\n\n<p>The dask approach was smart enough to delete all of the intermediates that it\ndidn’t need.  It could have run intelligently on far more data than even our\ncluster could hold.  With the pool we manage data ourselves manually.</p>\n\n<figure class=\"highlight\">\n  <pre><code class=\"language-python\" data-lang=\"python\"><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">distributed</span> <span class=\"kn\">import</span> <span class=\"n\">delete</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">delete</span><span class=\"p\">((</span><span class=\"s\">'node0'</span><span class=\"p\">,</span> <span class=\"mi\">8787</span><span class=\"p\">),</span> <span class=\"n\">arrays</span><span class=\"p\">)</span></code></pre>\n</figure>\n\n<h2 id=\"mix-and-match\">Mix and Match</h2>\n\n<p>We can also mix these abstractions and put the results from the pool into dask\ngraphs.</p>\n\n<figure class=\"highlight\">\n  <pre><code class=\"language-python\" data-lang=\"python\"><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">arrays</span> <span class=\"o\">=</span> <span class=\"n\">pool</span><span class=\"p\">.</span><span class=\"nb\">map</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"mi\">1000000</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"mi\">1000</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">dsk</span> <span class=\"o\">=</span> <span class=\"p\">{(</span><span class=\"s\">'sum'</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">):</span> <span class=\"p\">(</span><span class=\"n\">np</span><span class=\"p\">.</span><span class=\"nb\">sum</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">x</span> <span class=\"ow\">in</span> <span class=\"nb\">enumerate</span><span class=\"p\">(</span><span class=\"n\">arrays</span><span class=\"p\">)}</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">dsk</span><span class=\"p\">[</span><span class=\"s\">'total'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"nb\">sum</span><span class=\"p\">,</span> <span class=\"p\">[(</span><span class=\"s\">'sum'</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">1000</span><span class=\"p\">)])</span></code></pre>\n</figure>\n\n<h2 id=\"discussion\">Discussion</h2>\n\n<p>The <code class=\"language-plaintext highlighter-rouge\">Pool</code> and <code class=\"language-plaintext highlighter-rouge\">get</code> user interfaces are independent from each other but both\nuse the same underlying network and both build off of the same codebase.  With\n<code class=\"language-plaintext highlighter-rouge\">distributed</code> I wanted to build a system that would allow me to experiment\neasily.  I’m mostly happy with the result so far.</p>\n\n<p>One non-trivial theme here is data-locality.  We keep intermediate results on\nthe cluster and schedule jobs on computers that already have the relevant data\nif possible.  The workers can communicate with each other if necessary so that\nany worker can do any job, but we try to arrange jobs so that workers don’t\nhave to communicate if not necessary.</p>\n\n<p>Another non-trivial aspect is that the high level <code class=\"language-plaintext highlighter-rouge\">dask.array</code> example works\nwithout any tweaking of dask.  Dask’s separation of schedulers from collections\nmeans that existing dask.array code (or dask.dataframe, dask.bag,\ndask.imperative code) gets to evolve as we experiment with new fancier\nschedulers.</p>\n\n<p>Finally, I hope that the cluster setup here feels pretty minimal.  You do need\nsome way to run a command on a bunch of machines but most people with clusters\nhave some mechanism to do that, even if its just ssh as I did above.  My hope\nis that <code class=\"language-plaintext highlighter-rouge\">distributed</code> lowers the bar for non-trivial cluster computing in\nPython.</p>\n\n<h2 id=\"disclaimer\">Disclaimer</h2>\n\n<p>Everything here is <em>very experimental</em>.  The library itself is broken\nand unstable.  It was made in the last few weeks and hasn’t been used on\nanything serious.  Please adjust expectations accordingly and\n<a href=\"https://github.com/mrocklin/distributed/pull/3\">provide critical feedback.</a></p>\n\n<ul>\n  <li><a href=\"http://distributed.readthedocs.org/en/latest/\">Distributed Documentation</a></li>\n</ul>"
}