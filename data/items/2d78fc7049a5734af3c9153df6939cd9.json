{
  "title": "Counting Efficiently with Bounter pt. 2: CountMinSketch",
  "link": "https://rare-technologies.com/counting-efficiently-with-bounter-pt-2-countminsketch/",
  "comments": "https://rare-technologies.com/counting-efficiently-with-bounter-pt-2-countminsketch/#comments",
  "pubDate": "Wed, 31 Jan 2018 10:34:34 +0000",
  "dc:creator": "Filip Štefaňák",
  "category": [
    "Machine Learning",
    "Open Source",
    "bounter",
    "cardinality estimation",
    "count-min sketch",
    "frequency estimation",
    "hyperloglog",
    "open source"
  ],
  "guid": "https://rare-technologies.com/?p=10406",
  "description": "In my previous post on the new open source Python Bounter library we discussed how we can use its HashTable to quickly count approximate item frequencies in very large item sequences. Now we turn our attention to the second algorithm in Bounter, CountMinSketch (CMS), which is also optimized in C for top performance. (Shoutout to dav009 who already ported our ... <div><a href=\"https://rare-technologies.com/counting-efficiently-with-bounter-pt-2-countminsketch/\" class=\"more-link\">Read More</a></div>",
  "content:encoded": "<p>In my <a href=\"https://rare-technologies.com/counting-efficiently-with-bounter-pt-1-hashtable/\">previous post</a> on the new open source Python <a href=\"https://github.com/RaRe-Technologies/bounter\">Bounter library</a> we discussed how we can use its <em>HashTable</em> to quickly count approximate item frequencies in very large item sequences. Now we turn our attention to the second algorithm in Bounter, <em>CountMinSketch (CMS)</em>, which is also optimized in C for top performance.\n</p>\n\n<span id=\"more-10406\"></span>\n\n<p>\n(Shoutout to dav009 who already <a href=\"https://github.com/dav009/abacus\" target=\"_blank\">ported our CountMinSketch to Golang</a> and provided some extra measurements.)\n</p>\n\n<h2>A Data Structures Refresher: <em>CountMinSketch</em></h2>\n\n<p>\nCount-min sketch is a simple yet powerful probabilistic data structure for estimating frequencies (also called counts) in very large datasets of elements (aka objects), closely related to <a href=\"https://en.wikipedia.org/wiki/Bloom_filter\">Bloom filters</a>. Wikipedia provides <a href=\"https://en.wikipedia.org/wiki/Count%E2%80%93min_sketch\" target=\"_blank\">an excellent overview of the CMS algorithm</a>. There are also several other resources out there that can help you get the idea, including <a href=\"https://sites.google.com/site/countminsketch/\" target=\"_blank\">this site</a> dedicated to the algorithm and several <a href=\"http://lkozma.net/blog/sketching-data-structures/\" target=\"_blank\">great</a> <a href=\"http://debasishg.blogspot.cz/2014/01/count-min-sketch-data-structure-for.html\" target=\"_blank\">blogs</a>.\n</p>\n\n<p>\nIn short, you can visualize <em>CMS</em> as working over a two dimensional “table” of cells called “buckets”. This table has <code>depth</code> rows and <code>width</code> columns. Each bucket in the table stores a single number. Any element to be processed by <em>CMS</em> is mapped to <code>depth</code> different buckets, one bucket per row. Which bucket gets mapped in each row is calculated using hashing: we hash the input object using a row-specific salt, to make the hash functions row-wise independent. Then to increment that object’s count, we increment the value of each of its mapped buckets. To get the object’s (approximate) count later, we find the minimum value across all its mapped buckets. That’s it!\n</p>\n\n<div id=\"attachment_10407\" style=\"width: 610px\" class=\"wp-caption aligncenter\"><img src=\"https://rare-technologies.com/wp-content/uploads/2018/01/cm-300x242.png\" alt=\"count-min sketch illustration\" width=\"300\" height=\"242\" class=\"size-full wp-image-10407\" style=\"margin: 0 auto;\" /><p class=\"wp-caption-text\"><p>\nInserting two objects, the strings \"100.120.1.34\" and \"150.100.20.56\" into a Count-Min Sketch table of <code>depth=3</code> and <code>width=8</code>. Note the collision in the bottom-left bucket. Image courtesy of <a href=\"http://lkozma.net/blog/sketching-data-structures/\">L. Kozma</a>.\n</p></p></div>\n\n<p>\nWhat about hash collisions? Clearly, two different objects can end up mapping to one or more of the same buckets. The nice approximative properties of <em>CMS</em> stem from the fact that we expect objects that collide in one row not to collide in a different row.\n</p>\n\n<p>\nGiven an object, the value in each bucket is an <em>overestimation</em> of its frequency count: it can be larger than the real count (due to a collision), or equal to it (no collision), but it can never be smaller. We can also say that there is a <em>bias</em> in one direction (up).\n</p>\n\n<p>\nThe CMS count for an object is estimated by retrieving the mapped bucket values from each row and returning the <em>smallest</em> of these numbers. This will be the one closest to the real value (though still possibly overestimated). With more rows, we have a better chance of finding a bucket that has had no collision, or at least find one where the error from overestimation is the smallest.\n</p>\n\n<p>\nTo improve on this basic idea, Bounter always uses the <em>conservative update</em> heuristic. While incrementing, after finding the appropriate bucket in each row, only those buckets that share the lowest value are updated (the remaining buckets must already have been affected by a collision and overestimated). This significantly mitigates the collision error and greatly improves the overall precision of the algorithm, compared to the basic version. \n</p>\n\n<p>\nOn top of this algorithm, for user convenience, Bounter adds a <em>HyperLogLog</em> structure to estimate the overall number of distinct elements inserted into the <em>CMS</em> table so far, and also maintains a precise tally of all these elements.\n</p>\n\n<h3>Usage</h3>\n\n<p>\nTo initialize <em>CountMinSketch</em>, use either one of these methods:\n</p>\n\n<pre class=\"brush: python; title: ; notranslate\">\nfrom bounter import bounter, CountMinSketch\n\n# if you don't need key iteration, Bounter chooses the CMS algo automatically\ncounts = bounter(need_iteration=False, size_mb=256)\n\n# or you can choose it explicitly yourself\ncounts = CountMinSketch(size_mb=256)  # specify max memory, table size calculated automatically\ncounts = CountMinSketch(width=8388608, depth=8)  # specify concrete table size\n\ncounts.size()  # print overall structure size in bytes \n268435456\ncounts.width  # buckets per table row\n8388608\ncounts.depth  # number of table rows\n8\n</pre>\n\n<p>\nCount frequencies just like with <em>HashTable</em>:\n</p>\n\n<pre class=\"brush: python; title: ; notranslate\">\ncounts.update(['a', 'b', 'c', 'a'])\ncounts.increment('b')\ncounts.increment('c', 2)   # larger increments work too!\nprint(counts['a'])\n2\n</pre>\n\n<p>\n<em>CountMinSketch</em> does not support iteration of elements. This is because the keys (the objects themselves, or their hashes) are never stored. The <code>+=</code> syntax for increment is also unsupported. This is because assignment is unsupported, and Python treats += only as shorthand for calling <code>__getitem__</code>, incrementing the result, and feeding it into  <code>__setitem__</code>.\n</p>\n\n<h3>The <code>depth</code> parameter</h3>\n\n<p>\nBy increasing the <code>depth</code> parameter, you can increase the chance of avoiding a collision in at least one row and thus improve the accuracy of the results. However, this also increases the table size and the processing time of each insert or count operation. In our experiments, we had the best results with depths between 8 to 16, meaning we used 8-16 different hashes per object. Above that, investing memory into additional <code>width</code> (as opposed to <code>depth</code>) yields a much better marginal improvement.\n</p>\n\n<h3>Logarithmic counters</h3>\n\n<p>\nEach bucket of the standard algorithm takes 32 bits, and is thus able to represent object counts between 0 and 4,294,967,295. Bounter also implements <a href=\"https://en.wikipedia.org/wiki/Approximate_counting_algorithm\" target=\"_blank\">approximate counting</a> in the buckets, reducing the size of each bucket while extending the value range. The idea of approximate counting is to represent a range of values with a single counter value, stepping to the next value only sometimes, probabilistically. For instance, to step from the bucket value 5 (representing object counts of 32-63) to 6 (representing 64-127), we need to pass a random test with a 1/32 chance of success. This means we need an average of 32 attempts to take this one step.\n</p>\n\n<p>\nThis \"base-2\" setup of doubling the range and halving the probability makes for an intuitive example, but base-2 would be too crude and imprecise for Bounter. In reality, we use the same principle but with a lower base: we take more steps between each power of 2 (8 or 1024 steps). So, as an example with 8 steps, we would step from count range 32-35 (represented by bucket value 24) to 36-39 (25) with p=1/4, then to 40-43 (26) with p=1/4, and so on with the same p until 64-71 (32), from which we would step to 72-79 (33) with p=1/8.\n</p>\n\n<pre class=\"brush: python; title: ; notranslate\">\ncounts = bounter(need_iteration=False, size_mb=254, log_counting=1024)\ncounts = bounter(need_iteration=False, size_mb=254, log_counting=8)\n</pre>\n\n<p>\nLog1024 is a 16-bit counter which is precise for values up to 2048. Larger values are off by ~2%. The maximum representable value is around 2^71.\n</p>\n\n<p>\nLog8 fits into just 8 bits and is precise for values up to 16. Larger values are off by ~30%, with the maximum representable value around 2^33.\n</p>\n\n<p>\nUsing these counters introduces a different kind of error. We call it the \"counter error\", as opposed to \"collision error\" which comes from bucket collisions. Unlike the collision error, the counter error is unbiased. Also, while collision errors affect primarily small values, the counter error only occurs for larger values. By using approximate counters, we can trade some of the collision error (freeing up to 4x more buckets in the same space) for the counter error. \n</p>\n\n<p>\nSo much for theory. Let us look at some measurements and their visualisations to better understand the trade-offs we are making.\n</p>\n\n<h3>Evaluation</h3>\n<p>\nWe use the same setup as the <a href=\"https://rare-technologies.com/counting-efficiently-with-bounter-pt-1-hashtable/\">last time</a> with HashTable: First, we count all word bigrams across all ~4 million articles from the English Wikipedia. Then, we use their counts to determine <a href=\"https://en.wikipedia.org/wiki/Collocation\">phrase collocations</a> and calculate the resulting precision, recall and F1 values for this task.\n</p>\n\n<p>\nWe include the <em>Hashtable</em> results from the last part in the visualisations, so that you can directly compare against its results.\n</p>\n\n<div id=\"attachment_10407\" style=\"width: 810px\" class=\"wp-caption aligncenter\"><a href=\"https://rare-technologies.com/wp-content/uploads/2018/01/bounter_cms_facets.html\"><img src=\"https://rare-technologies.com/wp-content/uploads/2018/01/image2-1.png\" alt=\"Click to open interactive FacetsDive in a new window\" width=\"860\" height=\"450\" class=\"alignnone size-full wp-image-10416\" /></a><p class=\"wp-caption-text\"><p>\nYou can see these accuracy charts in action and inspect individual errors (shades of blue) interactively, using Google's awesome <a href=\"https://rare-technologies.com/interactive-confusion-matrix-python/\">FacetsDive</a> tool. Click <a href=\"https://rare-technologies.com/wp-content/uploads/2018/01/bounter_cms_facets.html\" title=\"Click to open FacetsDive in a new window\" target=\"_blank\">here</a> to open the plot above in a new, interactive browser window.\n</p></p></div>\n\n<p>\nWith limited memory, each algorithm produces a characteristic error, which is best understood when looking at the Facets visualisation and inspecting the concrete examples there.\n</p>\n\n<p>\nJust as with <em>HashTable</em>, you can use the <code>quality()</code> function to get the ratio of the cardinality of the inserted items to the CMS capacity (total number of buckets). For a quality near or below 1, the results show no collision error. \n</p>\n\n<p>\nThe following table hints at the relationship of Quality (the number returned by <code>quality()</code>, the first number in the table) and F1 score (the second bold number in the table, higher is better, 1.0 is perfect) for several combinations of counter algorithms and RAM footprint. The blank cells represent combinations which were not tested.\n</p>\n\n<p>\nAs you can see, we can reach (or get very close) to the perfect F1 score of 1.0 with Quality values around 3. \n</p>\n\n<table class=\"colors\">\n<thead><tr>\n<th>Used RAM<br/><br/><br/>Algorithm</th>\n<th style=\"vertical-align: top;\">64 MB</th>\n<th style=\"vertical-align: top;\">128 MB</th>\n<th style=\"vertical-align: top;\">256 MB</th>\n<th style=\"vertical-align: top;\">512 MB</th>\n<th style=\"vertical-align: top;\">1024 MB</th>\n<th style=\"vertical-align: top;\">2048 MB</th>\n<th style=\"vertical-align: top;\">4096 MB</th>\n</tr>\n</thead>\n\n<tr>\n<td>HashTable</td>\n<td></td>\n<td>42.78 <strong>0.917</strong></td>\n<td>21.39 <strong>0.952</strong></td>\n<td>10.69 <strong>0.978</strong></td>\n<td>5.34 <strong>0.996</strong></td>\n<td>2.67 <strong>1.0</strong></td>\n<td>1.34 <strong>1.0</strong></td>\n</tr>\n\n<tr>\n<td>CMS Default</td>\n<td></td>\n<td></td>\n<td>21.76 <strong>0.821</strong></td>\n<td>10.88 <strong>0.993</strong></td>\n<td>5.44 <strong>0.998</strong></td>\n<td>2.72 <strong>1.0</strong></td>\n<td>1.36 <strong>1.0</strong></td>\n</tr>\n\n<tr>\n<td>CMS Log1024</td>\n<td></td>\n<td>21.76 <strong>0.818</strong></td>\n<td>10.88 <strong>0.987</strong></td>\n<td>5.44 <strong>0.993</strong></td>\n<td>2.72 <strong>1.0</strong></td>\n<td>1.36 <strong>0.995</strong></td>\n<td>0.68 <strong>0.998</strong></td>\n</tr>\n\n<tr>\n<td>CMS Log8</td>\n<td>21.76 <strong>0.784</strong></td>\n<td>10.88 <strong>0.960</strong></td>\n<td>5.44 <strong>0.967</strong></td>\n<td>2.72 <strong>0.969</strong></td>\n<td>1.36 <strong>0.975</strong></td>\n<td>0.68 <strong>0.974</strong></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n\n<p style=\"text-align: center;\">\n<em>\nCMS Quality score and <strong>F1 score</strong> on the task of collocation detection in the English Wikipedia, using CMS to represent the raw n-gram counts. Python's built-in Counter would occupy 17.2 GB to count all 179,413,989 distinct word pairs exactly (100% F1 score).\n</em>\n</p>\n\n<p>\nFor the specific task of determining collocation phrases, <em>HashTable</em> is a clear winner. This is because the specific type of numerical error it produces (discarding the long tail) is a good match for the task, since low-counts objects are irrelevant. As Quality climbs over 2, <em>Hashtable</em> already pins the majority of the long tail to 0.\n</p>\n\n<p>\nOn the other hand, <em>CountMinSketch</em> manages to estimate even the elements of the long tail with great precision while Quality remains in the single digits. You can see this property quite well in the visualisation. This makes the <em>CMS</em> variants more appropriate when you are interested in the long tail of element counts.\n</p>\n\n<h2>Conclusion</h2>\n\n<p>\nOur advice to \"power-users\" of Bounter is the following: use the <em>HashTable</em> or <em>CMS</em> algorithms with default settings, using the amount of memory you have available, then consult the <code>quality()</code> number. If this number is very high (over 5), using the log1024 or log8 variant of <em>CMS</em> might improve your results. If the number is less than 1.0, there should not be any error in the results at all and you can safely lower the amount of RAM in the <code>size_mb</code> parameter (if you care about memory). For example, with a Quality rating of ~0.1, you can assign 8x less RAM to Bounter.\n</p>\n\n<p>\nIf you have enough memory for now, how do you choose between <em>CountMinSketch</em> and <em>HashTable</em>? Think about the kind of estimation error that matters to your application. Is it critical to never report positive occurrences for an object you never saw (avoid <em>CountMinSketch</em>)? Or to never report 0 for objects you saw only rarely (avoid <em>HashTable</em>)? This is the primary trade-off between false positives and false negatives.\n</p>\n\n<p>\n<em>HashTable</em> has a discrete threshold given by its capacity. Until it is filled, it is guaranteed to be 100% accurate. When the capacity is used up, or even exceeded by more than 2x, it is guaranteed to misrepresent all the elements that did not fit in, cutting the long tail. On the other hand, <em>CountMinSketch</em> has a tiny probability of an overestimation error to begin with, and this continuously increases as you fill it with more values. In practice, <em>CountMinSketch</em> rate of error remains small enough even when its size is exceeded by 2-10x. Thus, it trades simplicity of its guarantees for a much better overall accuracy of the entire distribution.\n</p>\n\n<p>\nHopefully, our articles helped you understand the algorithms for approximate counting and navigate their trade-offs, letting you make the right decisions for your application.\n</p>\n\n<p>\nGood luck with your counting and let us know in the comments if you found some nice use for our library!\n</p>\n\n<h2>See also</h2>\n\n<ul>\n<li>\n<p>\nOur tutorial series on <a href=\"https://rare-technologies.com/interactive-confusion-matrix-python/\">interactive analytics in browser & confusion matrix inspection with Facets Dive</a>.\n</p>\n</li>\n\n<li>\n<p>\nTutorial on <a href=\"https://rare-technologies.com/data-streaming-in-python-generators-iterators-iterables/\">data streaming with Python</a>.\n</p>\n</li>\n\n</ul>\n",
  "wfw:commentRss": "https://rare-technologies.com/counting-efficiently-with-bounter-pt-2-countminsketch/feed/",
  "slash:comments": 2
}