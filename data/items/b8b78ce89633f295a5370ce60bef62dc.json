{
  "title": "Becoming a Bayesian, Part 1",
  "link": "",
  "published": "2015-04-19T17:30:00+01:00",
  "updated": "2015-04-19T17:30:00+01:00",
  "author": {
    "name": "Sebastian Nowozin"
  },
  "id": "tag:www.nowozin.net,2015-04-19:/sebastian/blog/becoming-a-bayesian-part-1.html",
  "summary": "<p>I have used probabilistic models for a number of years now and over this time\nI have used different paradigms to build my models, to estimate them from\ndata, and to perform inference and predictions.</p>\n<p>Overall I have slowly become â€¦</p>",
  "content": "<p>I have used probabilistic models for a number of years now and over this time\nI have used different paradigms to build my models, to estimate them from\ndata, and to perform inference and predictions.</p>\n<p>Overall I have slowly become a Bayesian; however, it has been a rough journey.\nWhen I say that \"I became a Bayesian\" I mean that my default view on problems\nnow is to think about a probabilistic model that relates observables to\nquantities of interest and of suitable prior distributions for any unknowns\nthat are present in this model.\nWhen it comes to solving the practical problem using a\ncomputer program however, I am ready to depart from the model on my whiteboard\nwhenever the advantages to do so are large enough, for example in simplicity,\nruntime speed, tractability, etc.\nSome recent work to that end:</p>\n<ul>\n<li>Our work on <a href=\"http://arxiv.org/abs/1402.0859\">informed sampling for generative computer vision\nmodels</a> with\n<a href=\"http://ps.is.tue.mpg.de/person/jampani\">Varun</a>,\n<a href=\"http://ps.is.tue.mpg.de/person/loper\">Matthew</a> and\n<a href=\"http://files.is.tue.mpg.de/pgehler/\">Peter</a>, where we argue for a generative\nand Bayesian approach to computer vision problems;</li>\n<li>Our <a href=\"http://arxiv.org/abs/1402.3580\">Bayesian NMR work</a> (and\n<a href=\"http://www.nowozin.net/sebastian/papers/wu2014porousmedia.pdf\">here</a>) with\n<a href=\"http://www.cs.cmu.edu/~andrewgw/\">Andrew Wilson</a> and collaborators from the\nCambridge university chemical department we have taken a full Bayesian\nviewpoint, with great success over conventional NMR Fourier analysis;</li>\n<li>Our work on using <a href=\"http://www.nowozin.net/sebastian/papers/bratieres2014scalablegpstruct.pdf\">GPs for structured\nprediction</a>\nwith <a href=\"http://mlg.eng.cam.ac.uk/sebastien/\">Sebastien</a>,\n<a href=\"http://www.sussex.ac.uk/Users/nq28/\">Novi</a>, and\n<a href=\"http://mlg.eng.cam.ac.uk/zoubin/\">Zoubin</a>, which was motivated by the\nstruggle to scale up a conceptually satisfying model.</li>\n<li>My work on <a href=\"http://www.nowozin.net/sebastian/papers/nowozin2014intersectionoverunion.pdf\">maximum expected utility in some structured prediction\nmodels</a>\nat CVPR 2014, which was motivated by applying basic decision theory, but ended\nup trying to cope with resulting intractabilities.</li>\n</ul>\n<p>However, I have remained skeptical of the naive and unconditional adoption of\nthe <em>subjective Bayesian viewpoint</em>.\nIn particular, I object to the viewpoint that every model and every system\nought to be Bayesian, or to the view that at the very least, if a statistical\nsystem is useful that it should have an approximate Bayesian interpretation.\nIn this post and the following two posts I will try to explain my skepticism.</p>\n<p>There is a risk of barking up the wrong tree by attacking a caricature of a\nBayesian here, which is not my intention.  In fact, to be frank, every one of\nthe researchers I have interacted with in the past few years holds a nuanced\nview of their principles and methods and more often than not is aware of their\nprinciples' limitations and willing to adjust if circumstances require it.</p>\n<p>Let me summarize the subjective Bayesian viewpoint.\nIn my experience this view of the world is arguably the most prevalent among\nBayesians in the machine learning community, for example at NIPS and at\nmachine learning summer schools.</p>\n<h3>The Subjective Bayesian Viewpoint</h3>\n<p>The subjective Bayesian viewpoint on any system under study is as\nfollows:</p>\n<ul>\n<li>Specify a probabilistic model relating what is known to what is unknown;</li>\n<li>Specify a proper prior probability distribution over unknowns based on any\ninformation that is available to you;</li>\n<li>Obtain the posterior distribution over unknowns given the known data\n(using <a href=\"http://en.wikipedia.org/wiki/Bayes%27_theorem\">Bayes\nrule</a>);</li>\n<li>Draw conclusions based on the posterior distribution; for example, solve a\ndecision problem or select a model among the alternative models.</li>\n</ul>\n<p>This approach is used exclusively for any statistical problem that may\narise.\nThis approach is strongly advocated, for example by\n<a href=\"http://www.jstor.org/discover/10.2307/2681060\">Lindley</a> and\nin a <a href=\"http://projecteuclid.org/euclid.ba/1340371036\">paper by Michael\nGoldstein</a>.</p>\n<p>Alternative Bayesian views deviate from this recipe.  For example, they may\nallow for <em>improper</em> prior distributions or instead aim to select\nuninformative prior distributions, or even select the prior as a function of\nthe inferential question at hand.</p>\n<h1>Criticism</h1>\n<p>My main criticism towards a ''naive'' subjective Bayesian viewpoint are\nrelated to the following three points:</p>\n<ol>\n<li>The consequences of model misspecification.</li>\n<li><a href=\"http://www.nowozin.net/sebastian/blog/becoming-a-bayesian-part-2.html\">The ''model first computation last'' approach</a>.</li>\n<li><a href=\"http://www.nowozin.net/sebastian/blog/becoming-a-bayesian-part-3.html\">Denial of methods of classical statistics</a>.</li>\n</ol>\n<h2>The Consequences of Model Misspecification</h2>\n<p>To model some system in the world we often use probabilistic models of the\nform\n    </p>\n<div class=\"math\">$$p(x;\\theta),\\qquad \\theta \\in \\Theta,$$</div>\n<p>\nwhere <span class=\"math\">\\(x \\in \\mathcal{X}\\)</span> is a random variable of interest and <span class=\"math\">\\(\\Theta\\)</span> is the\nset of possible parameters <span class=\"math\">\\(\\theta\\)</span>.  We are interested in <span class=\"math\">\\(p(x)\\)</span> and thus\nwould like to find a suitable parameter given some observed data <span class=\"math\">\\(x_1, x_2,\n\\dots, x_n \\in \\mathcal{X}\\)</span>.  Because we can never be entirely certain about\nour parameters we may represent our current beliefs through a posterior\ndistribution <span class=\"math\">\\(p(\\theta|x_1,\\dots,x_n)\\)</span>.</p>\n<p><em>Misspecification</em> is the case when no parameter in <span class=\"math\">\\(\\Theta\\)</span> leads to a\ndistribution <span class=\"math\">\\(p(x;\\theta)\\)</span> that behaves like the true distribution.\nThis is not exceptional, infact most models of real world systems are\nmisspecified.\nIt also is not a property of any inferential approach but rather a fundamental\nlimitation of building expressive models given our limited knowledge.  If we\ncould observe all relevant quantities and know their deterministic relationships we\nwould not need a probabilistic model.\nHence the need for a probabilistic model arises because we cannot observe\neverything and we do not know all the dependencies that exist in the real\nworld.  (Alas, as Andrew Wilson pointed out to me, the previous two sentences\nexpose my deterministic world view.)\nSo what can be said about this common case of misspecified models?</p>\n<p>Let us talk about calibration of probabilities, and what happens in case your\nmodel is wrong.\nInformally, you are <em>well-calibrated</em> if you neither overestimate nor\nunderestimate the probability of certain events.\nCrucially, this does not imply a degree of certainty, only that your\nuncertain statements (forecasted probabilities of events) are on average\ncorrect.</p>\n<p>For any probabilistic model, being well-calibrated is a desirable goal.\nThere are <a href=\"http://en.wikipedia.org/wiki/Scoring_rule\">various methods</a> to\nassess calibration and to check the forecasts of your model.\nIn 1982 <a href=\"http://www.statslab.cam.ac.uk/~apd/\">Dawid</a>, in a\n<a href=\"http://www.jstor.org/stable/2287720\">seminal paper</a>,\nestablished a general theorem whose consequence (in Section 4.3 of that paper)\nis to guarantee that a Bayesian using a parametric model will eventually be\nwell-calibrated.</p>\n<p>This is reassuring, except there is one catch:\nit does not apply in the case when the model is misspecified.\nUnfortunately, in most practical applications of probabilistic modelling,\nmisspecification is the rule rather than the exception (''All models are\nwrong'').\nWe could hope for a ''graceful degradation'', in that we are still at least\napproximately calibrated.  But this is not the case.</p>\n<h3>Calibration and Misspecification</h3>\n<p>In the misspecified case, there are <a href=\"http://delong.typepad.com/sdj/2013/01/cosma-shalizi-vs-the-fen-dwelling-bayesians.html\">simple\nexamples</a>\ndue to <a href=\"http://delong.typepad.com/sdj/\">Brad Delong</a> and <a href=\"http://www.stat.cmu.edu/~cshalizi/\">Cosma\nShalizi</a>\nwhere beliefs in a parametric model do not converge and\nbecome less-calibrated over time.\nIn their example two contradicting things happen at the same time:\nthe beliefs become very confident, yet a single new observation revises the\nbelief to the other extreme, again confident.</p>\n<h3>Improving the model?</h3>\n<p>One can object that in these examples, and more generally, one should revise\nthe model to more accurately reflect the system under study.\nBut then, in order not to end up in an infinite loop of trying to improve\na model, how to determine when to stop?\nActually, how to even determine the accuracy of the model?\n<a href=\"http://en.wikipedia.org/wiki/Marginal_likelihood\">Model evidence</a> cannot be\nused to this end, as it is conditioned on the set of possible models being\nused.  (In fact, in Delong's example the evidence would assure us that\neverything is fine.)\nThe answers to how model's can be criticised and improved are not simple, and\nquite likely not Bayesian.</p>\n<p>Andrew Gelman and Cosma Shalizi discuss this issue and others in a <a href=\"http://www.stat.columbia.edu/~gelman/research/published/philosophy_chapter.pdf\">position\npaper</a>,\nand I find myself agreeing with their assessment that there is no answer to\nwrong model assumptions within the (strictly) subjective Bayesian viewpoint:</p>\n<blockquote>\n<p>\"We fear that a philosophy of Bayesian statistics as subjective, inductive\ninference can encourage a complacency about picking or averaging over existing\nmodels rather than trying to falsify and go further.\nLikelihood and Bayesian inference are powerful, and with great power comes\ngreat responsibility.  Complex models can and should be checked and\nfalsified.\"</p>\n</blockquote>\n<h3>Non-parametric Models to the Rescue?</h3>\n<p>Another objection is that this is all well-known and hence we should use\nnon-parametric models which endow us with prior support over essentially all\nreasonable alternatives.</p>\n<p>Unfortunately, while the resulting models are richer and are practically\nuseful in real applications, we now may have other problems: even when there\nis prior support for the true model simple properties like <em>consistency</em>\n(which were guaranteed to hold in the parametric case) <a href=\"http://projecteuclid.org/euclid.aos/1176349830\">can no longer be taken\nfor granted</a>.  The current\nliterature and basic results on this topic are nicely summarized in\nSection 20.12 of <a href=\"http://www.stat.purdue.edu/~dasgupta/\">DasGupta's</a>\n<a href=\"http://www.springer.com/mathematics/probability/book/978-0-387-75970-8\">book</a>.</p>\n<h3>Conclusion</h3>\n<p>Misspecification is not a Bayesian problem, and applies equally to other\nestimation approaches, for example in the case of maximum likelihood\nestimation see the <a href=\"https://books.google.com/books?isbn=0521574463\">book by\nWhite</a>.\nHowever, a subjective Bayesian has no Bayesian means to test for the presence\nof misspecification and that makes it hard to deal with the consequences.</p>\n<p>There are some ideas for applying Bayesian inference in a\nmisspecification-aware manner, for example the <a href=\"http://homepages.cwi.nl/~pdg/ftp/alt12longer.pdf\"><em>Safe\nBayesian</em></a> approach, and an\ninteresting analysis of approximate Bayesian inference using the Bootstrap in\na relatively unknown <a href=\"http://projecteuclid.org/euclid.bj/1126126768\">paper of\nFushiki</a>.</p>\n<p>Are these alternatives practical and do they somehow overcome the\nmisspecification problem?  To be frank, I am not aware of any satisfactory\nsolution and common practice seems to be a careful model criticism using tools\nsuch as predictive model checking and graphical inspection.  But these require\nfirst acknowledging the problem.</p>\n<p>When the model is wrong ideally it would be reassuring to have,</p>\n<ul>\n<li>a reliable diagnostic and quantification on how wrong it is (say, an\n  estimate <span class=\"math\">\\(D(q\\|p^*)\\)</span> where <span class=\"math\">\\(q\\)</span> is the true distribution), and</li>\n<li>a test for whether the type of model error present will matter for making\n  certain predictions (say, an error bound on the deviation of certain\n  expectations, <span class=\"math\">\\(\\mathbb{E}_q[f(x)] - \\mathbb{E}_{p^*}[f(x)]\\)</span> for a given\n  function <span class=\"math\">\\(f\\)</span>).</li>\n</ul>\n<p>To me it appears the (pure) subjective Bayesian paradigm cannot provide the\nabove.</p>\n<h3>Addendum</h3>\n<p>Andrew Wilson pointed out to me that in most cases of statistical problems we\ncannot know the <em>true distribution</em>, even in principle.  I agree, and indeed\nif we pursue such elusive ideal then this may divert our attention away from\nthe practical issue of building a model good enough for the task at hand.\nI entirely agree with taking such pragmatic stance and this follows Francis\nBacon's ideal of assessing the worth of a model (scientific theory in his\ncase) not by an abstract ideal of truthfulness, but instead by its utility.</p>\n<p>In machine learning and most industrial applications building the model is\n<em>easy</em> because we merely focus on predictive performance which can be\nreliably assessed using holdout data.\nFor scientific discovery however, things are more subtle in that our goal is\nin establishing the truth of certain statements with sufficient confidence;\nbut this truth is only a conditional truth, conditioned on assumptions we have\nto make.</p>\n<p>A Bayesian makes all assumptions explicit and then proceeds by formally\ntreating them as truth, correctly inferring the consequences.\nA classical/frequentist approach also makes assumptions by positing a model,\nbut then may be able to make statements that hold uniformly over all\npossibilities encoded in the model.\nTherefore, in my mind the Bayesian is an optimist, believing entirely in their\nassumptions, whereas the classical approach is more pessimistic, believing\nin their model but then providing worst-case results over all possibilities.\nMisspecification affects both approaches.</p>\n<p>If you want to continue reading, <a href=\"http://www.nowozin.net/sebastian/blog/becoming-a-bayesian-part-2.html\">the second part of this\npost</a> is now available.</p>\n<p><em>Acknowledgements</em>.  I thank <a href=\"http://www.jancsary.net/\">Jeremy Jancsary</a>,\n<a href=\"http://files.is.tue.mpg.de/pgehler/\">Peter Gehler</a>,\n<a href=\"http://pub.ist.ac.at/~chl/\">Christoph Lampert</a>, and\n<a href=\"http://www.cs.cmu.edu/~andrewgw/\">Andrew Wilson</a> for feedback.</p>\n<script type=\"text/javascript\">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {\n    var align = \"center\",\n        indent = \"0em\",\n        linebreak = \"false\";\n\n    if (false) {\n        align = (screen.width < 768) ? \"left\" : align;\n        indent = (screen.width < 768) ? \"0em\" : indent;\n        linebreak = (screen.width < 768) ? 'true' : linebreak;\n    }\n\n    var mathjaxscript = document.createElement('script');\n    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';\n    mathjaxscript.type = 'text/javascript';\n    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';\n\n    var configscript = document.createElement('script');\n    configscript.type = 'text/x-mathjax-config';\n    configscript[(window.opera ? \"innerHTML\" : \"text\")] =\n        \"MathJax.Hub.Config({\" +\n        \"    config: ['MMLorHTML.js'],\" +\n        \"    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } },\" +\n        \"    jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" +\n        \"    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" +\n        \"    displayAlign: '\"+ align +\"',\" +\n        \"    displayIndent: '\"+ indent +\"',\" +\n        \"    showMathMenu: true,\" +\n        \"    messageStyle: 'normal',\" +\n        \"    tex2jax: { \" +\n        \"        inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" +\n        \"        displayMath: [ ['$$','$$'] ],\" +\n        \"        processEscapes: true,\" +\n        \"        preview: 'TeX',\" +\n        \"    }, \" +\n        \"    'HTML-CSS': { \" +\n        \"        availableFonts: ['STIX', 'TeX'],\" +\n        \"        preferredFont: 'STIX',\" +\n        \"        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" +\n        \"        linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" +\n        \"    }, \" +\n        \"}); \" +\n        \"if ('default' !== 'default') {\" +\n            \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" +\n                \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" +\n                \"VARIANT['normal'].fonts.unshift('MathJax_default');\" +\n                \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" +\n                \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" +\n                \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" +\n            \"});\" +\n            \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" +\n                \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" +\n                \"VARIANT['normal'].fonts.unshift('MathJax_default');\" +\n                \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" +\n                \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" +\n                \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" +\n            \"});\" +\n        \"}\";\n\n    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);\n    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);\n}\n</script>",
  "category": ""
}