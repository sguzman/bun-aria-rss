{
  "title": "Building advanced Beam pipelines in Scala with SCIO",
  "link": "https://cloud.google.com/blog/products/data-analytics/developing-beam-pipelines-using-scala/",
  "description": "<html><head></head><body><div class=\"block-paragraph\"><div class=\"rich-text\"><p><a href=\"https://beam.apache.org/\" target=\"_blank\">Apache Beam</a> is an open source, unified programming model with a set of language-specific SDKs for defining and executing data processing workflows. <a href=\"https://github.com/spotify/scio\" target=\"_blank\">Scio</a>, pronounced shee-o, is Scala API for Beam developed by Spotify to build both Batch and Streaming pipelines. <br/></p></div></div><div class=\"block-image_full_width\"><div class=\"article-module h-c-page\"><div class=\"h-c-grid\"><figure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"><img alt=\"1_Framework.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_Framework.max-1000x1000.jpg\"/></figure></div></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>In this blog we will uncover the need for SCIO and a few reference patterns.</p><h2>Why Scio</h2><p>SCIO provides high level abstraction for developers and is preferred for following reasons:</p><ul><li><p>Striking balance between concise and performance. Pipeline written in Scala are concise compared to java with similar performance<br/></p></li><li><p>Easier migration for Scalding/Spark developers due to similar semantics compared to Beam API thereby avoiding a steep learning curve for developers.<br/></p></li><li><p>Enables access to a large ecosystem of infrastructure libraries in Java e.g. Hadoop, Avro, Parquet and high level numerical processing libraries in Scala like <a href=\"https://github.com/twitter/algebird\" target=\"_blank\">Algebird</a>and <a href=\"https://github.com/scalanlp/breeze\" target=\"_blank\">Breeze</a>.<br/></p></li><li><p>Supports Interactive exploration of data and code snippets using <a href=\"https://spotify.github.io/scio/Scio-REPL.html\" target=\"_blank\">SCIO REPL</a></p></li></ul><h2>Reference Patterns</h2><p> Let us checkout few concepts along with examples: </p><h3>1. Graph Composition</h3><p>If you have a complex pipeline consisting of several transforms, the feasible approach is to compose the logically related transforms into blocks.  This would make it easy to manage and debug the graph rendered on dataflow UI. Let us consider an example using popular WordCount pipeline.</p></div></div><div class=\"block-image_full_width\"><div class=\"article-module h-c-page\"><div class=\"h-c-grid\"><figure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"><img alt=\"2_WordCount_NoComposition.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2_WordCount_NoComposition.max-1000x1000.jpg\"/></figure></div></div></div><div class=\"block-image_full_width\"><div class=\"article-module h-c-page\"><div class=\"h-c-grid\"><figure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"><img alt=\"2a_WordCount_NoComposition.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2a_WordCount_NoComposition.max-1000x1000.jpg\"/><figcaption class=\"article-image__caption \"><div class=\"rich-text\"><i> Fig:  Word Count Pipeline without Graph Composition</i></div></figcaption></figure></div></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p> Let us modify the code to group the related transforms into blocks:</p></div></div><div class=\"block-image_full_width\"><div class=\"article-module h-c-page\"><div class=\"h-c-grid\"><figure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"><img alt=\"3_WordCount_Composition.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/3_WordCount_Composition.max-1000x1000.jpg\"/></figure></div></div></div><div class=\"block-image_full_width\"><div class=\"article-module h-c-page\"><div class=\"h-c-grid\"><figure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"><img alt=\"3a_WordCount_Composition.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/3a_WordCount_Composition.max-1000x1000.jpg\"/><figcaption class=\"article-image__caption \"><div class=\"rich-text\"><i>Fig:  Word Count Pipeline with Graph Composition</i></div></figcaption></figure></div></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>2. Distributed Cache</h3><p>Distributed Cache allows to load the data from a given URI on workers and use the corresponding data across all tasks (DoFn’s) executing on the worker. Some of the common use cases are loading serialized machine learning model from object stores like Google Cloud Storage for running predictions,  lookup data references etc.</p><p>Let us checkout an example that loads lookup data from CSV file on worker during initialization and utilizes to count the number of matching lookups for each input element.</p></div></div><div class=\"block-image_full_width\"><div class=\"article-module h-c-page\"><div class=\"h-c-grid\"><figure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"><img alt=\"4_DistributedCache.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/4_DistributedCache.max-1000x1000.jpg\"/><figcaption class=\"article-image__caption \"><div class=\"rich-text\"><i>Fig:  Example demonstrating Distribute Cache</i></div></figcaption></figure></div></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>3. Scio Joins</h3><p>Joins in Beam are expressed using <a href=\"https://beam.apache.org/releases/javadoc/2.40.0/org/apache/beam/sdk/transforms/join/CoGroupByKey.html\" target=\"_blank\">CoGroupByKey</a>  while Scio allows to express various join types like inner, left outer and full outer joins through <a href=\"https://github.com/spotify/scio/blob/main/scio-core/src/main/scala/com/spotify/scio/util/ArtisanJoin.scala\" target=\"_blank\">flattening</a> the <a href=\"https://beam.apache.org/releases/javadoc/2.41.0/org/apache/beam/sdk/transforms/join/CoGbkResult.html\" target=\"_blank\">CoGbkResult</a>. </p><p><a href=\"https://spotify.github.io/scio/api/com/spotify/scio/values/PairHashSCollectionFunctions.html\" target=\"_blank\">Hash joins</a> (syntactic sugar over a beam side input) can be used, if one of the dataset is extremely small (max ~1GB) by representing a smaller dataset on the right hand side. Side inputs are small, in-memory data structures that are replicated to all workers and avoids shuffling. </p><p><a href=\"https://spotify.github.io/scio/api/com/spotify/scio/util/MultiJoin.html\" target=\"_blank\">MultiJoin</a> can be used to join up to 22 data sets. It is recommended that all data sets be ordered in descending size, because non-shuffle joins do require the largest data sets to be on the left of any chain of operators </p><p><a href=\"https://spotify.github.io/scio/api/com/spotify/scio/values/PairSCollectionFunctions.html#sparseJoin[W](rhs:com.spotify.scio.values.SCollection[(K,W)],rhsNumKeys:Long,fpProb:Double)(implicitfunnel:com.google.common.hash.Funnel[K]):com.spotify.scio.values.SCollection[(K,(V,W))]\" target=\"_blank\">Sparse Joins</a> can be used for cases where the left collection (LHS) is much larger than the right collection (RHS) that cannot fit in memory but contains a sparse intersection of keys matching with the left collection .  Sparse Joins are implemented by constructing a <a href=\"https://en.wikipedia.org/wiki/Bloom_filter\" target=\"_blank\">Bloom filter</a> of keys from the right collection and split the left side collection into 2 partitions. Only the partition with keys in the filter go through the join and the rest are either concatenated (i.e Outer join) or discarded (Inner join). Sparse Join is especially useful for joining historical aggregates with incremental updates.</p><p><a href=\"https://spotify.github.io/scio/api/com/spotify/scio/values/PairSkewedSCollectionFunctions.html\" target=\"_blank\">Skewed Joins</a> are a more appropriate choice for cases where the left collection (LHS) is much larger and contains hotkeys.  Skewed join uses <a href=\"https://en.wikipedia.org/wiki/Count%E2%80%93min_sketch\" target=\"_blank\">Count Mink Sketch</a> which is a probabilistic data structure to count the frequency of keys in the LHS collection.  LHS is partitioned into <i><b>Hot</b></i> and <i><b>chill</b></i> partitions.  While the Hot partition is joined with corresponding keys on RHS using a Hash join, chill partition uses a regular join and finally both the partitions are combined through union operation.</p></div></div><div class=\"block-image_full_width\"><div class=\"article-module h-c-page\"><div class=\"h-c-grid\"><figure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"><img alt=\"5_Joins.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/5_Joins.max-1000x1000.jpg\"/><figcaption class=\"article-image__caption \"><div class=\"rich-text\"><i>Fig:  Example demonstrating Scio Joins</i></div></figcaption></figure></div></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Note that while using Beam Java SDK you can also take advantage of some of the similar join abstractions using <a href=\"https://beam.apache.org/documentation/sdks/java-extensions/#join-library\" target=\"_blank\">Join Library extension</a></p><h3>4. AlgeBird Aggregators and SemiGroup</h3><p><a href=\"https://github.com/twitter/algebird\" target=\"_blank\">Algebird</a> is Twitter’s abstract algebra library containing several reusable modules for parallel aggregation and approximation. Algebird <b>Aggregator</b> or Semigroup can be used with aggregate and sum transforms on <a href=\"https://spotify.github.io/scio/api/com/spotify/scio/values/SCollection.html\" target=\"_blank\">SCollection[T]</a> or aggregateByKey and sumByKey transforms on <a href=\"https://spotify.github.io/scio/api/com/spotify/scio/values/PairSCollectionFunctions.html\" target=\"_blank\">SCollection[(K, V)]</a>.  Below example illustrates computing parallel aggregation on customer orders and composition of result into OrderMetrics class</p></div></div><div class=\"block-image_full_width\"><div class=\"article-module h-c-page\"><div class=\"h-c-grid\"><figure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"><img alt=\"6_AlgebirdAggregators.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/6_AlgebirdAggregators.max-1000x1000.jpg\"/><figcaption class=\"article-image__caption \"><div class=\"rich-text\"><i>Fig:  Example demonstrating Algebird Aggregators</i></div></figcaption></figure></div></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p> Below code snippet expands on previous example and demonstrates the <a href=\"https://en.wikipedia.org/wiki/Semigroup\" target=\"_blank\">SemiGroup</a> for aggregation of objects by combining fields.</p></div></div><div class=\"block-image_full_width\"><div class=\"article-module h-c-page\"><div class=\"h-c-grid\"><figure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"><img alt=\"7_AlgebirdSemiGroup.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/7_AlgebirdSemiGroup.max-1000x1000.jpg\"/><figcaption class=\"article-image__caption \"><div class=\"rich-text\"><i>Fig:  Example demonstrating Algebird SemiGroup</i></div></figcaption></figure></div></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>5. GroupMap and GroupMapReduce</h3><p><a href=\"https://spotify.github.io/scio/api/com/spotify/scio/values/SCollection.html#groupMap[K,U](f:T=%3EK)(g:T=%3EU)(implicitevidence$19:com.spotify.scio.coders.Coder[K],implicitevidence$20:com.spotify.scio.coders.Coder[U]):com.spotify.scio.values.SCollection[(K,Iterable[U])]\" target=\"_blank\">GroupMap</a> can be used as a replacement of <i>groupBy(key) + mapValues(_.map(func))</i> or <i>_.map(e  =&gt; kv.of(keyfunc, valuefunc)) + </i><i>groupBy(key)</i></p><p>Let us consider the below example that calculates the length of words for each type. Instead of grouping by each type and applying length function, the GroupMap allows combining these operations by applying keyfunc and valuefunc.</p></div></div><div class=\"block-image_full_width\"><div class=\"article-module h-c-page\"><div class=\"h-c-grid\"><figure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"><img alt=\"8_GroupMap.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/8_GroupMap.max-1000x1000.jpg\"/><figcaption class=\"article-image__caption \"><div class=\"rich-text\"><i> Fig:  Example demonstrating GroupMap</i></div></figcaption></figure></div></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p><a href=\"https://spotify.github.io/scio/api/com/spotify/scio/values/SCollection.html#groupMapReduce[K](f:T=%3EK)(g:(T,T)=%3ET)(implicitevidence$21:com.spotify.scio.coders.Coder[K]):com.spotify.scio.values.SCollection[(K,T)]\" target=\"_blank\">GroupMapReduce</a>  can be used to derive the key and apply the associative operation on the values associated with each key. The associative function is performed locally on each mapper similarly to a \"combiner\" in MapReduce (aka combiner lifting) before sending the results to the reducer.  This is equivalent to <i>keyBy(keyfunc) + reduceByKey(reducefunc)</i> </p><p>Let us consider the below example that calculates the cumulative sum of odd and even numbers in a given range.  In this case individual values are combined on each worker and the local results are aggregated to calculate the final result</p></div></div><div class=\"block-image_full_width\"><div class=\"article-module h-c-page\"><div class=\"h-c-grid\"><figure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"><img alt=\"9_GroupMapReduce.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/9_GroupMapReduce.max-1000x1000.jpg\"/><figcaption class=\"article-image__caption \"><div class=\"rich-text\"><i>Fig:  Example demonstrating GroupMapReduce</i></div></figcaption></figure></div></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h2>Conclusion</h2><p><i>Thanks for reading and I hope now you are motivated to learn more about SCIO.  Beyond the patterns covered above, SCIO contains several interesting features like<a href=\"https://spotify.github.io/scio/internals/Coders.html#scio-0-7-0-and-above\" target=\"_blank\">implicit coders</a> for Scala case classes,  <a href=\"https://spotify.github.io/scio/examples/TapOutputExample.scala.html\" target=\"_blank\">Chaining jobs using I/O Taps</a> , <a href=\"https://spotify.github.io/scio/extras/HyperLogLog.html\" target=\"_blank\">Distinct Count using HyperLogLog++</a> , Writing <a href=\"https://spotify.github.io/scio/extras/Sort-Merge-Bucket.html\" target=\"_blank\">sorted output</a> to files etc.  Several use case specific libraries like <a href=\"https://github.com/spotify/ratatool/tree/master/ratatool-diffy\" target=\"_blank\">BigDiffy</a> (comparison of large datasets) , <a href=\"https://github.com/spotify/featran\" target=\"_blank\">FeaTran</a> (used for ML Feature Engineering) were also built on top of SCIO. </i></p><p><i>For Beam lovers with Scala background, SCIO is the perfect recipe for building complex distributed data pipelines.</i></p></div></div></body></html>",
  "pubDate": "Wed, 02 Nov 2022 16:00:00 -0000",
  "guid": "https://cloud.google.com/blog/products/data-analytics/developing-beam-pipelines-using-scala/",
  "category": [
    "Google Cloud",
    "Data Analytics"
  ],
  "media:content": "",
  "og": {
    "type": "article",
    "title": "Building advanced Beam pipelines in Scala with SCIO",
    "description": "",
    "image": "https://storage.googleapis.com/gweb-cloudblog-publish/images/da_2022.max-600x600.jpg",
    "site_name": "Google",
    "url": "https://cloud.google.com/blog/products/data-analytics/developing-beam-pipelines-using-scala/"
  },
  "author": {
    "name": "Prathap Kumar Parvathareddy",
    "title": "Staff Data Engineer",
    "department": "",
    "company": ""
  }
}