{
  "title": "Kernel Memory Networks: A Unifying Framework for Memory Modeling. (arXiv:2208.09416v2 [cs.NE] UPDATED)",
  "link": "http://arxiv.org/abs/2208.09416",
  "description": "<p>We consider the problem of training a neural network to store a set of\npatterns with maximal noise robustness. A solution, in terms of optimal weights\nand state update rules, is derived by training each individual neuron to\nperform either kernel classification or interpolation with a minimum weight\nnorm. By applying this method to feed-forward and recurrent networks, we derive\noptimal models, termed kernel memory networks, that include, as special cases,\nmany of the hetero- and auto-associative memory models that have been proposed\nover the past years, such as modern Hopfield networks and Kanerva's sparse\ndistributed memory. We modify Kanerva's model and demonstrate a simple way to\ndesign a kernel memory network that can store an exponential number of\ncontinuous-valued patterns with a finite basin of attraction. The framework of\nkernel memory networks offers a simple and intuitive way to understand the\nstorage capacity of previous memory models, and allows for new biological\ninterpretations in terms of dendritic non-linearities and synaptic cross-talk.\n</p>",
  "dc:creator": "<a href=\"http://arxiv.org/find/cs/1/au:+Iatropoulos_G/0/1/0/all/0/1\">Georgios Iatropoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brea_J/0/1/0/all/0/1\">Johanni Brea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gerstner_W/0/1/0/all/0/1\">Wulfram Gerstner</a>"
}