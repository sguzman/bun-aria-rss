{
  "title": "Parallelizing Distance Calculations Using A GPU With CUDAnative.jl",
  "description": "<p>Hacker News discussion: <a href=\"https://news.ycombinator.com/item?id=15021244\">link</a></p>",
  "pubDate": "Mon, 14 Aug 2017 00:00:00 +0000",
  "link": "http://randyzwitch.com/cudanative-jl-julia/",
  "guid": "http://randyzwitch.com/cudanative-jl-julia/",
  "content": "<p>Hacker News discussion: <a href=\"https://news.ycombinator.com/item?id=15021244\">link</a></p>\n\n<p><a href=\"http://randyzwitch.com/notebooks/cudanative_haversine_julia_example.ipynb\">Code as Julia Jupyter Notebook</a></p>\n\n<p>Julia has the reputation as a “fast” language in that it’s possible to write high-performing code. However, what I appreciate most about Julia is not just that the code is fast, but rather that Julia makes high-performance concepts <em>accessible</em> without having to have a deep computer science or compiled language background (neither of which I possess!)</p>\n\n<p>For version 0.6 of Julia, another milestone has been reached in the “accessible” high-performance category: the ability to <a href=\"https://julialang.org/blog/2017/03/cudanative\">run Julia code natively on NVIDIA GPUs</a> through the <a href=\"https://github.com/JuliaGPU/CUDAnative.jl\">CUDAnative.jl</a> package. While CUDAnative.jl is still very much in its development stages, the package is already far-enough along that within a few hours, as a complete beginner to GPU programming, I was able to see in excess of 20x speedups for my toy example to calculate haversine distance.</p>\n\n<h2 id=\"getting-started\">Getting Started</h2>\n\n<p>The <a href=\"https://julialang.org/blog/2017/03/cudanative\">CUDAnative.jl introduction blog post</a> and <a href=\"http://juliagpu.github.io/CUDAnative.jl/stable/#Installation-1\">documentation</a> cover the installation process in-depth, so I won’t repeat the details here. I’m already a regular compile-from-source Julia user and I found the installation process pretty easy on my <a href=\"http://randyzwitch.com/building-data-science-workstation-2017/\">CUDA-enabled Ubuntu workstation</a>. If you can already do TensorFlow, Keras or other GPU tutorials on your computer, getting CUDAnative.jl to work shouldn’t take more than 10-15 minutes.</p>\n\n<h2 id=\"julia-cpu-implementation\">Julia CPU Implementation</h2>\n\n<p>To get a feel for what sort of speedup I could expect from using a GPU, I wrote a naive implementation of a distance matrix calculation in Julia:</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-julia\" data-lang=\"julia\"><table class=\"rouge-table\"><tbody><tr><td class=\"gutter gl\"><pre class=\"lineno\">1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n</pre></td><td class=\"code\"><pre><span class=\"c\">#https://github.com/quinnj/Rosetta-Julia/blob/master/src/Haversine.jl</span>\n<span class=\"n\">haversine</span><span class=\"x\">(</span><span class=\"n\">lat1</span><span class=\"o\">::</span><span class=\"kt\">Float32</span><span class=\"x\">,</span><span class=\"n\">lon1</span><span class=\"o\">::</span><span class=\"kt\">Float32</span><span class=\"x\">,</span><span class=\"n\">lat2</span><span class=\"o\">::</span><span class=\"kt\">Float32</span><span class=\"x\">,</span><span class=\"n\">lon2</span><span class=\"o\">::</span><span class=\"kt\">Float32</span><span class=\"x\">)</span> <span class=\"o\">=</span> <span class=\"mi\">2</span> <span class=\"o\">*</span> <span class=\"mf\">6372.8</span> <span class=\"o\">*</span> <span class=\"n\">asin</span><span class=\"x\">(</span><span class=\"n\">sqrt</span><span class=\"x\">(</span><span class=\"n\">sind</span><span class=\"x\">((</span><span class=\"n\">lat2</span><span class=\"o\">-</span><span class=\"n\">lat1</span><span class=\"x\">)</span><span class=\"o\">/</span><span class=\"mi\">2</span><span class=\"x\">)</span><span class=\"o\">^</span><span class=\"mi\">2</span> <span class=\"o\">+</span> <span class=\"n\">cosd</span><span class=\"x\">(</span><span class=\"n\">lat1</span><span class=\"x\">)</span> <span class=\"o\">*</span> <span class=\"n\">cosd</span><span class=\"x\">(</span><span class=\"n\">lat2</span><span class=\"x\">)</span> <span class=\"o\">*</span> <span class=\"n\">sind</span><span class=\"x\">((</span><span class=\"n\">lon2</span> <span class=\"o\">-</span> <span class=\"n\">lon1</span><span class=\"x\">)</span><span class=\"o\">/</span><span class=\"mi\">2</span><span class=\"x\">)</span><span class=\"o\">^</span><span class=\"mi\">2</span><span class=\"x\">))</span>\n\n<span class=\"k\">function</span><span class=\"nf\"> pairwise_dist</span><span class=\"x\">(</span><span class=\"n\">lat</span><span class=\"o\">::</span><span class=\"kt\">Vector</span><span class=\"x\">{</span><span class=\"kt\">Float32</span><span class=\"x\">},</span> <span class=\"n\">lon</span><span class=\"o\">::</span><span class=\"kt\">Vector</span><span class=\"x\">{</span><span class=\"kt\">Float32</span><span class=\"x\">})</span>\n\n    <span class=\"c\">#Pre-allocate, since size is known</span>\n    <span class=\"n\">n</span> <span class=\"o\">=</span> <span class=\"n\">length</span><span class=\"x\">(</span><span class=\"n\">lat</span><span class=\"x\">)</span>\n    <span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"kt\">Array</span><span class=\"x\">{</span><span class=\"kt\">Float32</span><span class=\"x\">}(</span><span class=\"n\">n</span><span class=\"x\">,</span> <span class=\"n\">n</span><span class=\"x\">)</span>\n\n    <span class=\"c\">#Brute force fill in each cell, ignore that distance [i,j] = distance [j,i]</span>\n    <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"k\">in</span> <span class=\"mi\">1</span><span class=\"o\">:</span><span class=\"n\">n</span>\n        <span class=\"k\">for</span> <span class=\"n\">j</span> <span class=\"k\">in</span> <span class=\"mi\">1</span><span class=\"o\">:</span><span class=\"n\">n</span>\n            <span class=\"nd\">@inbounds</span> <span class=\"n\">result</span><span class=\"x\">[</span><span class=\"n\">i</span><span class=\"x\">,</span> <span class=\"n\">j</span><span class=\"x\">]</span> <span class=\"o\">=</span> <span class=\"n\">haversine</span><span class=\"x\">(</span><span class=\"n\">lat</span><span class=\"x\">[</span><span class=\"n\">i</span><span class=\"x\">],</span> <span class=\"n\">lon</span><span class=\"x\">[</span><span class=\"n\">i</span><span class=\"x\">],</span> <span class=\"n\">lat</span><span class=\"x\">[</span><span class=\"n\">j</span><span class=\"x\">],</span> <span class=\"n\">lon</span><span class=\"x\">[</span><span class=\"n\">j</span><span class=\"x\">])</span>\n        <span class=\"k\">end</span>\n    <span class=\"k\">end</span>\n\n    <span class=\"k\">return</span> <span class=\"n\">result</span>\n\n<span class=\"k\">end</span>\n\n<span class=\"c\">#Example benchmark call</span>\n<span class=\"n\">lat10000</span> <span class=\"o\">=</span> <span class=\"n\">rand</span><span class=\"x\">(</span><span class=\"kt\">Float32</span><span class=\"x\">,</span> <span class=\"mi\">10000</span><span class=\"x\">)</span> <span class=\"o\">.*</span> <span class=\"mi\">45</span>\n<span class=\"n\">lon10000</span> <span class=\"o\">=</span> <span class=\"n\">rand</span><span class=\"x\">(</span><span class=\"kt\">Float32</span><span class=\"x\">,</span> <span class=\"mi\">10000</span><span class=\"x\">)</span> <span class=\"o\">.*</span> <span class=\"o\">-</span><span class=\"mi\">120</span>\n<span class=\"nd\">@time</span> <span class=\"n\">native_julia_cellwise</span> <span class=\"o\">=</span> <span class=\"n\">pairwise_dist</span><span class=\"x\">(</span><span class=\"n\">lat10000</span><span class=\"x\">,</span> <span class=\"n\">lon10000</span><span class=\"x\">)</span>\n</pre></td></tr></tbody></table></code></pre></figure>\n\n<p>The above code takes a pair of lat/lon values, then calculates the <a href=\"https://rosettacode.org/wiki/Haversine_formula\">haversine distance</a> between the two points. This algorithm is naive in that a distance matrix is symmetric (i.e. the distance between A to B is the same from B to A), so I could’ve done half the work by setting <code class=\"language-plaintext highlighter-rouge\">result[i,j]</code> and <code class=\"language-plaintext highlighter-rouge\">result[j,i]</code> to the same value, but as a measure of work for a benchmark this toy example is fine. Also note that this implementation runs on a single core, no CPU-core-level parallelization has been implemented.</p>\n\n<p>Or to put all that another way: if someone wanted to tackle this problem without thinking very hard, the implementation might look like this.</p>\n\n<h2 id=\"cudanativejl-implementation\">CUDAnative.jl Implementation</h2>\n\n<p>There are two parts to the CUDAnative.jl implementation: the kernel (i.e. the actual calculation) and the boilerplate code for coordinating the writing to/from the CPU and GPU.</p>\n\n<h4 id=\"kernel-code\">Kernel Code</h4>\n\n<p>The kernel code has similarities to the CPU implementation, with a few key differences:</p>\n\n<ul>\n  <li>Method signature is one lat/lon point vs. the lat/lon vectors, rather than a pairwise distance calculation</li>\n  <li>Boilerplate code for thread index on the GPU (0-indexed vs. normal Julia 1-indexing)</li>\n  <li>The trigonometric functions need to be prepended with <code class=\"language-plaintext highlighter-rouge\">CUDAnative.</code>, to differentiate that the GPU functions aren’t the same as the functions from Base Julia</li>\n  <li>Rather than return an array as part of the function return, we use the <code class=\"language-plaintext highlighter-rouge\">out</code> keyword argument to write directly to the GPU memory</li>\n</ul>\n\n<figure class=\"highlight\"><pre><code class=\"language-julia\" data-lang=\"julia\"><table class=\"rouge-table\"><tbody><tr><td class=\"gutter gl\"><pre class=\"lineno\">1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n</pre></td><td class=\"code\"><pre><span class=\"k\">using</span> <span class=\"n\">CUDAnative</span><span class=\"x\">,</span> <span class=\"n\">CUDAdrv</span>\n\n<span class=\"c\">#Calculate one point vs. all other points simultaneously</span>\n<span class=\"k\">function</span><span class=\"nf\"> kernel_haversine</span><span class=\"x\">(</span><span class=\"n\">latpoint</span><span class=\"o\">::</span><span class=\"kt\">Float32</span><span class=\"x\">,</span> <span class=\"n\">lonpoint</span><span class=\"o\">::</span><span class=\"kt\">Float32</span><span class=\"x\">,</span> <span class=\"n\">lat</span><span class=\"o\">::</span><span class=\"kt\">AbstractVector</span><span class=\"x\">{</span><span class=\"kt\">Float32</span><span class=\"x\">},</span> <span class=\"n\">lon</span><span class=\"o\">::</span><span class=\"kt\">AbstractVector</span><span class=\"x\">{</span><span class=\"kt\">Float32</span><span class=\"x\">},</span> <span class=\"n\">out</span><span class=\"o\">::</span><span class=\"kt\">AbstractVector</span><span class=\"x\">{</span><span class=\"kt\">Float32</span><span class=\"x\">})</span>\n\n    <span class=\"c\">#Thread index</span>\n    <span class=\"c\">#Need to do the n-1 dance, since CUDA expects 0 and Julia does 1-indexing</span>\n    <span class=\"n\">i</span> <span class=\"o\">=</span> <span class=\"x\">(</span><span class=\"n\">blockIdx</span><span class=\"x\">()</span><span class=\"o\">.</span><span class=\"n\">x</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"x\">)</span> <span class=\"o\">*</span> <span class=\"n\">blockDim</span><span class=\"x\">()</span><span class=\"o\">.</span><span class=\"n\">x</span> <span class=\"o\">+</span> <span class=\"n\">threadIdx</span><span class=\"x\">()</span><span class=\"o\">.</span><span class=\"n\">x</span>\n\n    <span class=\"n\">out</span><span class=\"x\">[</span><span class=\"n\">i</span><span class=\"x\">]</span> <span class=\"o\">=</span>  <span class=\"mi\">2</span> <span class=\"o\">*</span> <span class=\"mf\">6372.8</span> <span class=\"o\">*</span> <span class=\"n\">CUDAnative</span><span class=\"o\">.</span><span class=\"n\">asin</span><span class=\"x\">(</span><span class=\"n\">CUDAnative</span><span class=\"o\">.</span><span class=\"n\">sqrt</span><span class=\"x\">(</span><span class=\"n\">CUDAnative</span><span class=\"o\">.</span><span class=\"n\">sind</span><span class=\"x\">((</span><span class=\"n\">latpoint</span><span class=\"o\">-</span><span class=\"n\">lat</span><span class=\"x\">[</span><span class=\"n\">i</span><span class=\"x\">])</span><span class=\"o\">/</span><span class=\"mi\">2</span><span class=\"x\">)</span><span class=\"o\">^</span><span class=\"mi\">2</span> <span class=\"o\">+</span> <span class=\"n\">CUDAnative</span><span class=\"o\">.</span><span class=\"n\">cosd</span><span class=\"x\">(</span><span class=\"n\">lat</span><span class=\"x\">[</span><span class=\"n\">i</span><span class=\"x\">])</span> <span class=\"o\">*</span> <span class=\"n\">CUDAnative</span><span class=\"o\">.</span><span class=\"n\">cosd</span><span class=\"x\">(</span><span class=\"n\">latpoint</span><span class=\"x\">)</span> <span class=\"o\">*</span> <span class=\"n\">CUDAnative</span><span class=\"o\">.</span><span class=\"n\">sind</span><span class=\"x\">((</span><span class=\"n\">lonpoint</span> <span class=\"o\">-</span> <span class=\"n\">lon</span><span class=\"x\">[</span><span class=\"n\">i</span><span class=\"x\">])</span><span class=\"o\">/</span><span class=\"mi\">2</span><span class=\"x\">)</span><span class=\"o\">^</span><span class=\"mi\">2</span><span class=\"x\">))</span>\n\n    <span class=\"c\">#Return nothing, since we're writing directly to the out array allocated on GPU</span>\n    <span class=\"k\">return</span> <span class=\"nb\">nothing</span>\n<span class=\"k\">end</span>\n</pre></td></tr></tbody></table></code></pre></figure>\n\n<h4 id=\"coordination-code\">Coordination Code</h4>\n\n<p>The coordination code is similar to what you might see in a <code class=\"language-plaintext highlighter-rouge\">main()</code> function in C or Java, where the kernel is applied to the input data. I am using the <code class=\"language-plaintext highlighter-rouge\">dev</code> keyword with the default value of <code class=\"language-plaintext highlighter-rouge\">CuDevice(0)</code> to indicate that the code should be run on the first (in my case, only) GPU device.</p>\n\n<p>The remainder of the code has comments on its purpose, primarily:</p>\n\n<ul>\n  <li>Transfer Julia CPU arrays to GPU arrays (<code class=\"language-plaintext highlighter-rouge\">CuArray</code>)</li>\n  <li>Set number of threads/blocks</li>\n  <li>Calculate distance between a point and all other points in the array, write back to CPU</li>\n</ul>\n\n<figure class=\"highlight\"><pre><code class=\"language-julia\" data-lang=\"julia\"><table class=\"rouge-table\"><tbody><tr><td class=\"gutter gl\"><pre class=\"lineno\">1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n</pre></td><td class=\"code\"><pre><span class=\"c\">#validated kernel_haversine/distmat returns same answer as CPU haversine method (not shown)</span>\n<span class=\"k\">function</span><span class=\"nf\"> distmat</span><span class=\"x\">(</span><span class=\"n\">lat</span><span class=\"o\">::</span><span class=\"kt\">Vector</span><span class=\"x\">{</span><span class=\"kt\">Float32</span><span class=\"x\">},</span> <span class=\"n\">lon</span><span class=\"o\">::</span><span class=\"kt\">Vector</span><span class=\"x\">{</span><span class=\"kt\">Float32</span><span class=\"x\">};</span> <span class=\"n\">dev</span><span class=\"o\">::</span><span class=\"n\">CuDevice</span><span class=\"o\">=</span><span class=\"n\">CuDevice</span><span class=\"x\">(</span><span class=\"mi\">0</span><span class=\"x\">))</span>\n\n    <span class=\"c\">#Create a context</span>\n    <span class=\"n\">ctx</span> <span class=\"o\">=</span> <span class=\"n\">CuContext</span><span class=\"x\">(</span><span class=\"n\">dev</span><span class=\"x\">)</span>\n\n    <span class=\"c\">#Change to objects with CUDA context</span>\n    <span class=\"n\">n</span> <span class=\"o\">=</span> <span class=\"n\">length</span><span class=\"x\">(</span><span class=\"n\">lat</span><span class=\"x\">)</span>\n    <span class=\"n\">d_lat</span> <span class=\"o\">=</span> <span class=\"n\">CuArray</span><span class=\"x\">(</span><span class=\"n\">lat</span><span class=\"x\">)</span>\n    <span class=\"n\">d_lon</span> <span class=\"o\">=</span> <span class=\"n\">CuArray</span><span class=\"x\">(</span><span class=\"n\">lon</span><span class=\"x\">)</span>\n    <span class=\"n\">d_out</span> <span class=\"o\">=</span> <span class=\"n\">CuArray</span><span class=\"x\">(</span><span class=\"kt\">Vector</span><span class=\"x\">{</span><span class=\"kt\">Float32</span><span class=\"x\">}(</span><span class=\"n\">n</span><span class=\"x\">))</span>\n\n    <span class=\"c\">#Calculate number of calculations, threads, blocks</span>\n    <span class=\"n\">len</span> <span class=\"o\">=</span> <span class=\"n\">n</span>\n    <span class=\"n\">threads</span> <span class=\"o\">=</span> <span class=\"n\">min</span><span class=\"x\">(</span><span class=\"n\">len</span><span class=\"x\">,</span> <span class=\"mi\">1024</span><span class=\"x\">)</span>\n    <span class=\"n\">blocks</span> <span class=\"o\">=</span> <span class=\"kt\">Int</span><span class=\"x\">(</span><span class=\"n\">ceil</span><span class=\"x\">(</span><span class=\"n\">len</span><span class=\"o\">/</span><span class=\"n\">threads</span><span class=\"x\">))</span>\n\n    <span class=\"c\">#Julia side accumulation of results to relieve GPU memory pressure</span>\n    <span class=\"n\">accum</span> <span class=\"o\">=</span> <span class=\"kt\">Array</span><span class=\"x\">{</span><span class=\"kt\">Float32</span><span class=\"x\">}(</span><span class=\"n\">n</span><span class=\"x\">,</span> <span class=\"n\">n</span><span class=\"x\">)</span>\n\n    <span class=\"c\"># run and time the test</span>\n    <span class=\"n\">secs</span> <span class=\"o\">=</span> <span class=\"n\">CUDAdrv</span><span class=\"o\">.</span><span class=\"nd\">@elapsed</span> <span class=\"k\">begin</span>\n        <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"k\">in</span> <span class=\"mi\">1</span><span class=\"o\">:</span><span class=\"n\">n</span>\n            <span class=\"nd\">@cuda</span> <span class=\"x\">(</span><span class=\"n\">blocks</span><span class=\"x\">,</span> <span class=\"n\">threads</span><span class=\"x\">)</span> <span class=\"n\">kernel_haversine</span><span class=\"x\">(</span><span class=\"n\">lat</span><span class=\"x\">[</span><span class=\"n\">i</span><span class=\"x\">],</span> <span class=\"n\">lon</span><span class=\"x\">[</span><span class=\"n\">i</span><span class=\"x\">],</span> <span class=\"n\">d_lat</span><span class=\"x\">,</span> <span class=\"n\">d_lon</span><span class=\"x\">,</span> <span class=\"n\">d_out</span><span class=\"x\">)</span>\n            <span class=\"n\">accum</span><span class=\"x\">[</span><span class=\"o\">:</span><span class=\"x\">,</span> <span class=\"n\">i</span><span class=\"x\">]</span> <span class=\"o\">=</span> <span class=\"kt\">Vector</span><span class=\"x\">{</span><span class=\"kt\">Float32</span><span class=\"x\">}(</span><span class=\"n\">d_out</span><span class=\"x\">)</span>\n        <span class=\"k\">end</span>\n    <span class=\"k\">end</span>\n\n    <span class=\"c\">#Clean up context</span>\n    <span class=\"n\">destroy!</span><span class=\"x\">(</span><span class=\"n\">ctx</span><span class=\"x\">)</span>\n\n    <span class=\"c\">#Return timing and bring results back to Julia</span>\n    <span class=\"k\">return</span> <span class=\"x\">(</span><span class=\"n\">secs</span><span class=\"x\">,</span> <span class=\"n\">accum</span><span class=\"x\">)</span>\n\n<span class=\"k\">end</span>\n\n<span class=\"c\">#Example benchmark call</span>\n<span class=\"n\">timing</span><span class=\"x\">,</span> <span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">distmat</span><span class=\"x\">(</span><span class=\"n\">lat10000</span><span class=\"x\">,</span> <span class=\"n\">lon10000</span><span class=\"x\">)</span>\n<span class=\"n\">result</span> <span class=\"n\">≈</span> <span class=\"n\">native_julia_cellwise</span> <span class=\"c\">#validate results equivalent CPU and GPU</span>\n</pre></td></tr></tbody></table></code></pre></figure>\n\n<p>The code is written to process one row of the distance matrix at a time to minimize GPU memory usage. By writing out the results to the CPU after each loop iteration, I have <code class=\"language-plaintext highlighter-rouge\">n-1</code> extra CPU transfers, which is less performant than calculating all the distances first then transferring, but my consumer-grade GPU with 6GB of RAM would run out of GPU memory before completing the calculation otherwise.</p>\n\n<h2 id=\"performance\">Performance</h2>\n\n<p>The performance characteristics of the CPU and GPU calculations are below for various sizes of distance matrices. Having not done any GPU calculations before, I was surprised to see how much of a penalty there is writing back and forth to the GPU. As you can see from the navy-blue line, the execution time is fixed for matrices of size 1 to 1000, representing the fixed cost of moving the data from the CPU to the GPU.</p>\n\n<p>Of course, once we get above 1000x1000 matrices, the GPU really starts to shine. Due to the log scale, it’s a bit hard to see the magnitude differences, but at 100000x100000 there is a <strong>23x</strong> reduction in execution time (565.008s CPU vs. 24.32s GPU).</p>\n\n<div id=\"linep\" style=\"height:400px;width:800px;\"></div>\n<script type=\"text/javascript\">\n    // Initialize after dom ready\n    var myChart = echarts.init(document.getElementById(\"linep\"));\n\n    // Load data into the ECharts instance\n    myChart.setOption(\n{\"xAxis\":[{\"splitNumber\":5,\"axisLine\":{\"show\":false,\"onZero\":true,\"lineStyle\":{\"normal\":{},\"emphasis\":{}}},\"axisLabel\":{\"show\":true,\"interval\":\"auto\",\"rotate\":0,\"inside\":false,\"formatter\":\"{value}\",\"margin\":8},\"scale\":true,\"gridIndex\":0,\"name\":\"Matrix dimensions (square)\",\"minInterval\":0,\"zlevel\":0,\"triggerEvent\":false,\"z\":0,\"splitLine\":{\"show\":false,\"interval\":\"auto\",\"lineStyle\":{\"normal\":{},\"emphasis\":{}}},\"inverse\":false,\"nameLocation\":\"middle\",\"nameGap\":30,\"silent\":true,\"type\":\"log\"}],\"ec_charttype\":\"xy plot\",\"series\":[{\"name\":\"CPU\",\"yAxisIndex\":0,\"xAxisIndex\":0,\"smooth\":true,\"data\":[[1.0,6.0e-6],[10.0,1.7e-5],[100.0,0.001091],[1000.0,0.090409],[10000.0,5.620437],[100000.0,565.008425]],\"markLine\":{\"data\":[],\"lineStyle\":{\"normal\":{},\"emphasis\":{}}},\"large\":true,\"type\":\"line\",\"largeThreshold\":2000},{\"name\":\"GPU\",\"yAxisIndex\":0,\"xAxisIndex\":0,\"smooth\":true,\"data\":[[1.0,0.14232168],[10.0,0.15084915],[100.0,0.15897949],[1000.0,0.16998644],[10000.0,0.6376571],[100000.0,24.32015]],\"markLine\":{\"data\":[],\"lineStyle\":{\"normal\":{},\"emphasis\":{}}},\"large\":true,\"type\":\"line\",\"largeThreshold\":2000}],\"theme\":{\"geo\":{\"label\":{\"normal\":{\"textStyle\":{\"color\":\"#000000\"}},\"emphasis\":{\"textStyle\":{\"color\":\"rgb(100,0,0)\"}}},\"itemStyle\":{\"normal\":{\"borderColor\":\"#444444\",\"borderWidth\":0.5,\"areaColor\":\"#eeeeee\"},\"emphasis\":{\"borderColor\":\"#444444\",\"borderWidth\":1,\"areaColor\":\"rgba(255,215,0,0.8)\"}}},\"parallel\":{\"itemStyle\":{\"normal\":{\"borderWidth\":0,\"borderColor\":\"#ccc\"},\"emphasis\":{\"borderWidth\":0,\"borderColor\":\"#ccc\"}}},\"markPoint\":{\"label\":{\"normal\":{\"textStyle\":{\"color\":\"#eeeeee\"}},\"emphasis\":{\"textStyle\":{\"color\":\"#eeeeee\"}}}},\"visualMap\":{\"color\":[\"#e01f54\",\"#e7dbc3\"]},\"funnel\":{\"itemStyle\":{\"normal\":{\"borderWidth\":0,\"borderColor\":\"#ccc\"},\"emphasis\":{\"borderWidth\":0,\"borderColor\":\"#ccc\"}}},\"bar\":{\"itemStyle\":{\"normal\":{\"barBorderColor\":\"#ccc\",\"barBorderWidth\":0},\"emphasis\":{\"barBorderColor\":\"#ccc\",\"barBorderWidth\":0}}},\"map\":{\"label\":{\"normal\":{\"textStyle\":{\"color\":\"#000000\"}},\"emphasis\":{\"textStyle\":{\"color\":\"rgb(100,0,0)\"}}},\"itemStyle\":{\"normal\":{\"borderColor\":\"#444444\",\"borderWidth\":0.5,\"areaColor\":\"#eeeeee\"},\"emphasis\":{\"borderColor\":\"#444444\",\"borderWidth\":1,\"areaColor\":\"rgba(255,215,0,0.8)\"}}},\"scatter\":{\"itemStyle\":{\"normal\":{\"borderWidth\":0,\"borderColor\":\"#ccc\"},\"emphasis\":{\"borderWidth\":0,\"borderColor\":\"#ccc\"}}},\"pie\":{\"itemStyle\":{\"normal\":{\"borderWidth\":0,\"borderColor\":\"#ccc\"},\"emphasis\":{\"borderWidth\":0,\"borderColor\":\"#ccc\"}}},\"graph\":{\"label\":{\"normal\":{\"textStyle\":{\"color\":\"#eeeeee\"}}},\"symbolSize\":4,\"itemStyle\":{\"normal\":{\"borderWidth\":0,\"borderColor\":\"#ccc\"}},\"smooth\":false,\"symbol\":\"emptyCircle\",\"color\":[\"#e01f54\",\"#001852\",\"#f5e8c8\",\"#b8d2c7\",\"#c6b38e\",\"#a4d8c2\",\"#f3d999\",\"#d3758f\",\"#dcc392\",\"#2e4783\",\"#82b6e9\",\"#ff6347\",\"#a092f1\",\"#0a915d\",\"#eaf889\",\"#6699FF\",\"#ff6666\",\"#3cb371\",\"#d5b158\",\"#38b6b6\"],\"lineStyle\":{\"normal\":{\"color\":\"#aaaaaa\",\"width\":1}}},\"backgroundColor\":\"rgba(0,0,0,0)\",\"line\":{\"symbolSize\":4,\"itemStyle\":{\"normal\":{\"borderWidth\":1}},\"smooth\":false,\"symbol\":\"emptyCircle\",\"lineStyle\":{\"normal\":{\"width\":2}}},\"candlestick\":{\"itemStyle\":{\"normal\":{\"borderColor0\":\"#b8d2c7\",\"color\":\"#e01f54\",\"borderColor\":\"#f5e8c8\",\"borderWidth\":1,\"color0\":\"#001852\"}}},\"sankey\":{\"itemStyle\":{\"normal\":{\"borderWidth\":0,\"borderColor\":\"#ccc\"},\"emphasis\":{\"borderWidth\":0,\"borderColor\":\"#ccc\"}}},\"valueAxis\":{\"axisLine\":{\"show\":true,\"lineStyle\":{\"color\":\"#333\"}},\"axisLabel\":{\"textStyle\":{\"color\":\"#333\"},\"show\":true},\"splitLine\":{\"show\":true,\"lineStyle\":{\"color\":[\"#ccc\"]}},\"splitArea\":{\"areaStyle\":{\"color\":[\"rgba(250,250,250,0.3)\",\"rgba(200,200,200,0.3)\"]},\"show\":false},\"axisTick\":{\"show\":true,\"lineStyle\":{\"color\":\"#333\"}}},\"toolbox\":{\"iconStyle\":{\"normal\":{\"borderColor\":\"#999999\"},\"emphasis\":{\"borderColor\":\"#666666\"}}},\"categoryAxis\":{\"axisLine\":{\"show\":true,\"lineStyle\":{\"color\":\"#333\"}},\"axisLabel\":{\"textStyle\":{\"color\":\"#333\"},\"show\":true},\"splitLine\":{\"show\":false,\"lineStyle\":{\"color\":[\"#ccc\"]}},\"splitArea\":{\"areaStyle\":{\"color\":[\"rgba(250,250,250,0.3)\",\"rgba(200,200,200,0.3)\"]},\"show\":false},\"axisTick\":{\"show\":true,\"lineStyle\":{\"color\":\"#333\"}}},\"tooltip\":{\"axisPointer\":{\"crossStyle\":{\"color\":\"#cccccc\",\"width\":1},\"lineStyle\":{\"color\":\"#cccccc\",\"width\":1}}},\"timeline\":{\"label\":{\"normal\":{\"textStyle\":{\"color\":\"#293c55\"}},\"emphasis\":{\"textStyle\":{\"color\":\"#293c55\"}}},\"controlStyle\":{\"normal\":{\"color\":\"#293c55\",\"borderColor\":\"#293c55\",\"borderWidth\":0.5},\"emphasis\":{\"color\":\"#293c55\",\"borderColor\":\"#293c55\",\"borderWidth\":0.5}},\"checkpointStyle\":{\"color\":\"#e43c59\",\"borderColor\":\"rgba(194,53,49,0.5)\"},\"itemStyle\":{\"normal\":{\"color\":\"#293c55\",\"borderWidth\":1},\"emphasis\":{\"color\":\"#a9334c\"}},\"lineStyle\":{\"color\":\"#293c55\",\"width\":1}},\"radar\":{\"symbolSize\":4,\"itemStyle\":{\"normal\":{\"borderWidth\":1}},\"smooth\":false,\"symbol\":\"emptyCircle\",\"lineStyle\":{\"normal\":{\"width\":2}}},\"logAxis\":{\"axisLine\":{\"show\":true,\"lineStyle\":{\"color\":\"#333\"}},\"axisLabel\":{\"textStyle\":{\"color\":\"#333\"},\"show\":true},\"splitLine\":{\"show\":true,\"lineStyle\":{\"color\":[\"#ccc\"]}},\"splitArea\":{\"areaStyle\":{\"color\":[\"rgba(250,250,250,0.3)\",\"rgba(200,200,200,0.3)\"]},\"show\":false},\"axisTick\":{\"show\":true,\"lineStyle\":{\"color\":\"#333\"}}},\"textStyle\":{},\"gauge\":{\"itemStyle\":{\"normal\":{\"borderWidth\":0,\"borderColor\":\"#ccc\"},\"emphasis\":{\"borderWidth\":0,\"borderColor\":\"#ccc\"}}},\"boxplot\":{\"itemStyle\":{\"normal\":{\"borderWidth\":1},\"emphasis\":{\"borderWidth\":2}}},\"color\":[\"#e01f54\",\"#001852\",\"#f5e8c8\",\"#b8d2c7\",\"#c6b38e\",\"#a4d8c2\",\"#f3d999\",\"#d3758f\",\"#dcc392\",\"#2e4783\",\"#82b6e9\",\"#ff6347\",\"#a092f1\",\"#0a915d\",\"#eaf889\",\"#6699FF\",\"#ff6666\",\"#3cb371\",\"#d5b158\",\"#38b6b6\"],\"title\":{\"textStyle\":{\"color\":\"#333333\"},\"subtextStyle\":{\"color\":\"#aaaaaa\"}},\"dataZoom\":{\"dataBackgroundColor\":\"rgba(47,69,84,0.3)\",\"textStyle\":{\"color\":\"#333333\"},\"handleSize\":\"100%\",\"handleColor\":\"#a7b7cc\",\"fillerColor\":\"rgba(167,183,204,0.4)\",\"backgroundColor\":\"rgba(47,69,84,0)\"},\"timeAxis\":{\"axisLine\":{\"show\":true,\"lineStyle\":{\"color\":\"#333\"}},\"axisLabel\":{\"textStyle\":{\"color\":\"#333\"},\"show\":true},\"splitLine\":{\"show\":true,\"lineStyle\":{\"color\":[\"#ccc\"]}},\"splitArea\":{\"areaStyle\":{\"color\":[\"rgba(250,250,250,0.3)\",\"rgba(200,200,200,0.3)\"]},\"show\":false},\"axisTick\":{\"show\":true,\"lineStyle\":{\"color\":\"#333\"}}},\"legend\":{\"textStyle\":{\"color\":\"#333333\"}}},\"yAxis\":[{\"splitNumber\":5,\"axisLine\":{\"show\":false,\"onZero\":true,\"lineStyle\":{\"normal\":{},\"emphasis\":{}}},\"axisLabel\":{\"show\":true,\"interval\":\"auto\",\"rotate\":0,\"inside\":false,\"formatter\":\"{value}\",\"margin\":8},\"scale\":true,\"gridIndex\":0,\"name\":\"Time in seconds\",\"minInterval\":0,\"zlevel\":0,\"triggerEvent\":false,\"z\":0,\"inverse\":false,\"nameLocation\":\"middle\",\"nameGap\":50,\"silent\":true,\"type\":\"log\"}],\"toolbox\":{\"feature\":{},\"orient\":\"vertical\",\"itemSize\":15,\"height\":\"auto\",\"zlevel\":0,\"z\":2,\"itemGap\":20,\"right\":\"auto\",\"top\":\"center\",\"width\":\"auto\",\"show\":false,\"showTitle\":true},\"ec_width\":800,\"ec_height\":400,\"grid\":[{\"height\":\"auto\",\"show\":false,\"width\":\"auto\",\"backgroundColor\":\"transparent\"}],\"title\":[{\"left\":\"center\",\"borderColor\":\"transparent\",\"bottom\":\"auto\",\"padding\":5,\"zlevel\":0,\"borderWidth\":1,\"target\":\"blank\",\"z\":2,\"itemGap\":5,\"shadowOffsetY\":0,\"shadowOffsetX\":0,\"right\":\"auto\",\"top\":\"auto\",\"subtarget\":\"blank\",\"textStyle\":{\"fontFamily\":\"sans-serif\",\"fontStyle\":\"normal\",\"color\":\"#000\",\"fontSize\":14,\"fontWeight\":\"normal\"},\"show\":true,\"text\":\"Haversine distance: CPU vs. GPU\"}],\"legend\":{\"itemWidth\":25,\"data\":[\"CPU\",\"GPU\"],\"borderColor\":\"transparent\",\"orient\":\"horizontal\",\"bottom\":\"auto\",\"height\":\"auto\",\"zlevel\":0,\"padding\":5,\"borderWidth\":1,\"inactiveColor\":\"#ccc\",\"z\":2,\"align\":\"auto\",\"itemGap\":10,\"itemHeight\":14,\"backgroundColor\":\"transparent\",\"shadowOffsetY\":0,\"shadowOffsetX\":0,\"right\":\"right\",\"top\":\"middle\",\"width\":\"auto\",\"selectedMode\":true,\"show\":true}}\n);\n</script>\n\n<h2 id=\"what-i-learned\">What I Learned</h2>\n\n<p>There are myriad things I learned from this project, but most important is that GPGPU processing can be accessible for people like myself without a CS background. Julia isn’t the first high-level language to provide CUDA functionality, but the fact that the code is so similar to native Julia makes GPU computing something I can include in my toolbox <em>today</em>.</p>\n\n<p>Over time, I’m sure I’ll get better results as I learn more about CUDA, as CUDAnative.jl continues to smooth out the rough edges, etc. But the fact that as a beginner that I could achieve such large speedups in just an hour or two of coding and sparse CUDAnative.jl documentation bodes well for the future of GPU computing in Julia.</p>\n\n<p><a href=\"http://randyzwitch.com/notebooks/cudanative_haversine_julia_example.ipynb\">Code as Julia Jupyter Notebook</a></p>"
}