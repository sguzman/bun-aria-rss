{
  "title": "The Streaming Landscape, 2014 edition: Convergence, APIs, Data Access",
  "link": "",
  "updated": "2014-08-11T13:51:00+02:00",
  "published": "2014-08-11T13:51:00+02:00",
  "author": {
    "name": "Mikio L. Braun",
    "uri": "http://mikiobraun.de",
    "email": "mikiobraun@gmail.com"
  },
  "id": "http://blog.mikiobraun.de/2014/08/streaming-landscape-2014",
  "content": "<p><p>A year ago, I wrote a post on the <a href=\"http://blog.mikiobraun.de/2013/06/real-time-big-data-landscape.html\">real-time big data landscape</a>, identifying different approaches to deal with real-time big data. As I\nsaw it back then, there was sort of an evolution from database based\napproaches (put all your data in, run queries), up to stream processing (one\nevent at a time), and finally algorithmic approaches relying on stream mining\nalgorithsm, together with all kinds of performance “hacks” like\nparallelization, or using memory instead of disks.</p>\n\n<p>In principle, this picture is still adequate in terms of the underlying mode\nof data processing, that is, where you store your data, whether you process it\nas it comes in or in a more batch oriented fashion later on, and so on, but\nthere is always the question how to build systems around these approaches. And\ngiven the amount of money which is currently <a href=\"http://www.zdnet.com/cloudera-raises-900-million-plots-expansion-7000027879/\">infused into</a> the <a href=\"http://techcrunch.com/2014/06/30/databricks-snags-33m-in-series-b-and-debuts-cloud-platform-for-processing-big-data/\">whole Big Data company landscape</a>, quite a lot\nis happening in that area.</p>\n\n<h2 id=\"convergence\">Convergence</h2>\n\n<p>Currently, there is a lot of convergence happening. One such example is the <a href=\"http://lambda-architecture.net/\">lambda architecture</a>,\nwhich combines batch-oriented processing with stream processing to get both\nlow-latency results (potentially inaccurate and incomplete) and results on the\nfull data sets. Instead of scaling batch processing to a point where the\nlatency is small enough, a parallel stream processing layer processes events\nas they come along, with both routes piping results into a shared database to\nprovide the results for visualization or other kinds of presentation.</p>\n\n<p>Some point out that one problem with this approach is that you potentially\nneed to have all your analytics logic in two distinct, and conceptually quite\ndifferent systems. But there are systems like <a href=\"http://spark.apache.org/\">Apache Spark</a>, which can run\nthe same code in a batch fashion or near-streaming in micro-batches, or\n<a href=\"http://github.com/twitter/scalding\">Twitter’s Scalding</a>, which can take the same code to run on Hadoop\nor Storm.</p>\n\n<p>Others, like Linkedin’s Jay Kreps, ask <a href=\"http://radar.oreilly.com/2014/07/questioning-the-lambda-architecture.html\">why you can’t use stream processing\nalso to recompute stuff in batch</a>. Such systems can be implemented\nby combining a stream processing system with a system like <a href=\"http://kafka.apache.org/\">Apache Kafka</a>\nwhich is a distributed publish/subscribe event transport layer which doubles\nas a database for log data by retaining data for a predefined amount of time.</p>\n\n<h2 id=\"apis-functional-collections-vs-actors\">APIs: Functional Collections vs. Actors</h2>\n\n<p>These kinds of approaches make you wonder just how interchangable streaming\nand map-reduce style processing really is, whether it allows you to do the\nsame set of operations. If you think about it, map-reduce is already very\nstream oriented. In classical Hadoop, both the data input and output to the\nmap and reduce stage is presented via iterators and output pipes, so that you\ncould in principle also stream by the data. In fact, Scalding seems to be\ntaking advantage of exactly that.</p>\n\n<p>Generally, this “functional collection” style APIs seem to become quite\npopular, as Spark and also systems like <a href=\"http://incubator.apache.org/projects/flink.html\">Apache Flink</a> use that kind of\napproach. If you haven’t seen this before, the syntax is very close to the set\nof operations you have in functional languages like Scala. The basic data type\nis a collection of objects and you formulate your computations in terms of\noperations like map, filter, groupby, reduce, but also joins.</p>\n\n<p>This raises the question what exactly streaming analytics is. For some,\nstreaming is any kind of approach which allows you to process data in one go,\nwithout the need to go back, and also with more or less bounded resource\nrequirements. Interestingly, this seems to naturally lead to functional\ncollection style APIs, like illustrated in the <a href=\"http://matthewrocklin.com/blog/work/2014/07/04/Streaming-Analytics/\">toolz Python\nlibrary</a>,\nalthough one issue for me here is always that the functional collection style\nAPIs imply that the computation ends at some point, when in reality, it does\nnot.</p>\n\n<p>The other family of APIs uses a more actor-based approach. Stream processing\nsystems like <a href=\"https://storm.incubator.apache.org/\">Apache Storm</a>, <a href=\"http://samza.incubator.apache.org/\">Apache Samza</a>, or even <a href=\"http://akka.io\">akka</a> use that kind of approach where\nyou are basically defining worker nodes which take in a stream of data and\noutput another one, and you construct systems by explicitly sending messages\nasynchronously around between those nodes. In this setting, the on-line nature\nof the computation is much more explicit.</p>\n\n<p>I personally find actor based approaches always a bit hard to work with\nmentally, because you have to slice up operations into different actors just\nto parallelize when conceptually it’s just one step. The functional collection\nstyle approach works much better here, however, you then have to rely on the\nunderlying system being able to parallelize your computations well. Systems\nlike <a href=\"http://blog.mikiobraun.de/2014/06/future-big-data-flink-stratosphere.html\">Flink take ideas from query optimizations in databases</a> here\nto attack this problem which I think is a very promising approach.</p>\n\n<p>In general, what I personally would like to see is even more convergence\nbetween the functional collection and actor based approaches. I haven’t found\ntoo much on that but, to me, that seems like something which is bound to happen.</p>\n\n<h2 id=\"data-input-and-output\">Data Input and Output</h2>\n\n<p>Concerning data input and output, I find it interesting that all of these\napproaches don’t deal with the question of how to get at the results of your\nanalysis. One of the key features of real-time is that you need to get results\nas the data comes in, so results have to be continuously updated. This is IMHO\nalso not modelled well in the functional collection style APIs, which imply\nthat the function call returns once the result is computed. Which is never\nwhen you process data in an online fashion.</p>\n\n<p>The answer to that solution seems to be to use your highly parallelized, low-latency computation to deal with all the data, but then periodically write out\nresults to some fast, distributed storage layer like a redis database and use\nthat to query the results. It’s generally not possible to  access a running stream\nprocessing system “from the side” to get at the state which is somewhere\ndistributed in this system. While this approach is possible, it seems to me\nthat it requires you to set up yet another distributed system just to store\nresults.</p>\n\n<p>Concerning data input, there’s of course the usual coverage of all possible\nkinds of input, from REST, UDP packages, messaging frameworks, log files, and\nso on. I currently find Kafka quite interesting, because it seems like a good\nabstraction of combination of a bunch of log files and a log database. You\nget a distributed set of log data together with the ability to go back in time\nand replay data. In a way, this is exactly what we had been doing with\nTWIMPACT when analyzing Twitter data.</p>\n\n<h2 id=\"streamdrill\">Streamdrill</h2>\n\n<p>Which brings me back to <a href=\"http://streamdrill.com\">streamdrill</a> (you knew, this\nwas coming, right?), less because I need to tell you just how great it is, but\nbecause it sort of defines where I stand in this landscape myself.</p>\n\n<p>So far, we’ve mainly focussed on the core processing engine. The question of\ngetting the data out has been answered quite differently from the other\napproaches, as you can directly access the results of your computation by\nquerying the internal state via a REST interface. For getting historical data,\nyou still need to push the data to a storage backend, though. Directly exposing\nthe internal state of the computation is such a big detour from other\napproaches that I don’t see how you could easily retrofit streamdrill on top\nof Spark or akka, even though it would be great to get scaling capabilities\nthat way.</p>\n\n<p>I think the most potential for improvement with streamdrill is the part where\nyou encode the actual computation. So far, streamdrill is written and deployed\nas a more or less classical Jersey webapp, which means that everything is very\nevent-driven. We’re trying to separate functional modules from the REST\nendpoint code, but still it would need a fair understanding of Java webapps to\nwrite anything yourself (and I honestly don’t see data scientists doing that).\nHere, a more high-level, “functional collection”-style approach would definitely be\nbetter.</p>\n\n</p>\n   <p><a href=\"http://blog.mikiobraun.de/2014/08/streaming-landscape-2014.html\">Click here for the full article</a>"
}