{
  "title": "Introducing Dask distributed",
  "link": "",
  "updated": "2016-02-17T00:00:00+00:00",
  "id": "https://mrocklin.github.io/blog/work/2016/02/17/dask-distributed-part1",
  "content": "<p><em>This work is supported by <a href=\"http://continuum.io\">Continuum Analytics</a>\nand the <a href=\"http://www.darpa.mil/program/XDATA\">XDATA Program</a>\nas part of the <a href=\"http://blaze.pydata.org\">Blaze Project</a></em></p>\n\n<p><strong>tl;dr</strong>: We analyze JSON data on a cluster using pure Python projects.</p>\n\n<p>Dask, a Python library for parallel computing, now works on clusters.  During\nthe past few months I and others have extended dask with a new distributed\nmemory scheduler.  This enables dask’s existing parallel algorithms to scale\nacross 10s to 100s of nodes, and extends a subset of PyData to distributed\ncomputing.  Over the next few weeks I and others will write about this system.\nPlease note that dask+distributed is developing quickly and so the API is\nlikely to shift around a bit.</p>\n\n<p>Today we start simple with the typical cluster computing problem, parsing JSON\nrecords, filtering, and counting events using dask.bag and the new distributed\nscheduler.  We’ll dive into more advanced problems in future posts.</p>\n\n<p><em>A video version of this blogpost is available\n<a href=\"https://www.youtube.com/watch?v=W0Q0uwmYD6o\">here</a>.</em></p>\n\n<h2 id=\"github-archive-data-on-s3\">GitHub Archive Data on S3</h2>\n\n<p>GitHub releases data dumps of their public event stream as gzipped compressed,\nline-delimited, JSON.  This data is too large to fit comfortably into memory,\neven on a sizable workstation.  We could stream it from disk but, due to the\ncompression and JSON encoding this takes a while and so slogs down interactive\nuse.  For an interactive experience with data like this we need a distributed\ncluster.</p>\n\n<h3 id=\"setup-and-data\">Setup and Data</h3>\n\n<p>We provision nine <code class=\"language-plaintext highlighter-rouge\">m3.2xlarge</code> nodes on EC2.  These have eight cores and 30GB\nof RAM each.  On this cluster we provision one scheduler and nine workers (see\n<a href=\"http://distributed.readthedocs.org/en/latest/setup.html\">setup docs</a>).  (More\non launching in later posts.)  We have five months of data, from 2015-01-01 to\n2015-05-31 on the <code class=\"language-plaintext highlighter-rouge\">githubarchive-data</code> bucket in S3.  This data is publicly\navaialble if you want to play with it on EC2.  You can download the full\ndataset at https://www.githubarchive.org/ .</p>\n\n<p>The first record looks like the following:</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code> <span class=\"p\">{</span><span class=\"s\">'actor'</span><span class=\"p\">:</span> <span class=\"p\">{</span><span class=\"s\">'avatar_url'</span><span class=\"p\">:</span> <span class=\"s\">'https://avatars.githubusercontent.com/u/9152315?'</span><span class=\"p\">,</span>\n   <span class=\"s\">'gravatar_id'</span><span class=\"p\">:</span> <span class=\"s\">''</span><span class=\"p\">,</span>\n   <span class=\"s\">'id'</span><span class=\"p\">:</span> <span class=\"mi\">9152315</span><span class=\"p\">,</span>\n   <span class=\"s\">'login'</span><span class=\"p\">:</span> <span class=\"s\">'davidjhulse'</span><span class=\"p\">,</span>\n   <span class=\"s\">'url'</span><span class=\"p\">:</span> <span class=\"s\">'https://api.github.com/users/davidjhulse'</span><span class=\"p\">},</span>\n  <span class=\"s\">'created_at'</span><span class=\"p\">:</span> <span class=\"s\">'2015-01-01T00:00:00Z'</span><span class=\"p\">,</span>\n  <span class=\"s\">'id'</span><span class=\"p\">:</span> <span class=\"s\">'2489368070'</span><span class=\"p\">,</span>\n  <span class=\"s\">'payload'</span><span class=\"p\">:</span> <span class=\"p\">{</span><span class=\"s\">'before'</span><span class=\"p\">:</span> <span class=\"s\">'86ffa724b4d70fce46e760f8cc080f5ec3d7d85f'</span><span class=\"p\">,</span>\n   <span class=\"s\">'commits'</span><span class=\"p\">:</span> <span class=\"p\">[{</span><span class=\"s\">'author'</span><span class=\"p\">:</span> <span class=\"p\">{</span><span class=\"s\">'email'</span><span class=\"p\">:</span> <span class=\"s\">'david.hulse@live.com'</span><span class=\"p\">,</span>\n      <span class=\"s\">'name'</span><span class=\"p\">:</span> <span class=\"s\">'davidjhulse'</span><span class=\"p\">},</span>\n     <span class=\"s\">'distinct'</span><span class=\"p\">:</span> <span class=\"bp\">True</span><span class=\"p\">,</span>\n     <span class=\"s\">'message'</span><span class=\"p\">:</span> <span class=\"s\">'Altered BingBot.jar</span><span class=\"se\">\\n\\n</span><span class=\"s\">Fixed issue with multiple account support'</span><span class=\"p\">,</span>\n     <span class=\"s\">'sha'</span><span class=\"p\">:</span> <span class=\"s\">'a9b22a6d80c1e0bb49c1cf75a3c075b642c28f81'</span><span class=\"p\">,</span>\n     <span class=\"s\">'url'</span><span class=\"p\">:</span> <span class=\"s\">'https://api.github.com/repos/davidjhulse/davesbingrewardsbot/commits/a9b22a6d80c1e0bb49c1cf75a3c075b642c28f81'</span><span class=\"p\">}],</span>\n   <span class=\"s\">'distinct_size'</span><span class=\"p\">:</span> <span class=\"mi\">1</span><span class=\"p\">,</span>\n   <span class=\"s\">'head'</span><span class=\"p\">:</span> <span class=\"s\">'a9b22a6d80c1e0bb49c1cf75a3c075b642c28f81'</span><span class=\"p\">,</span>\n   <span class=\"s\">'push_id'</span><span class=\"p\">:</span> <span class=\"mi\">536740396</span><span class=\"p\">,</span>\n   <span class=\"s\">'ref'</span><span class=\"p\">:</span> <span class=\"s\">'refs/heads/master'</span><span class=\"p\">,</span>\n   <span class=\"s\">'size'</span><span class=\"p\">:</span> <span class=\"mi\">1</span><span class=\"p\">},</span>\n  <span class=\"s\">'public'</span><span class=\"p\">:</span> <span class=\"bp\">True</span><span class=\"p\">,</span>\n  <span class=\"s\">'repo'</span><span class=\"p\">:</span> <span class=\"p\">{</span><span class=\"s\">'id'</span><span class=\"p\">:</span> <span class=\"mi\">28635890</span><span class=\"p\">,</span>\n   <span class=\"s\">'name'</span><span class=\"p\">:</span> <span class=\"s\">'davidjhulse/davesbingrewardsbot'</span><span class=\"p\">,</span>\n   <span class=\"s\">'url'</span><span class=\"p\">:</span> <span class=\"s\">'https://api.github.com/repos/davidjhulse/davesbingrewardsbot'</span><span class=\"p\">},</span>\n  <span class=\"s\">'type'</span><span class=\"p\">:</span> <span class=\"s\">'PushEvent'</span><span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>So we have a large dataset on S3 and a moderate sized play cluster on EC2,\nwhich has access to S3 data at about  100MB/s per node.  We’re ready to play.</p>\n\n<h2 id=\"play\">Play</h2>\n\n<p>We start an <code class=\"language-plaintext highlighter-rouge\">ipython</code> interpreter on our local laptop and connect to the\ndask scheduler running on the cluster.  For the purposes of timing, the cluster\nis on the East Coast while the local machine is in California on commercial\nbroadband internet.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">distributed</span> <span class=\"kn\">import</span> <span class=\"n\">Executor</span><span class=\"p\">,</span> <span class=\"n\">s3</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">e</span> <span class=\"o\">=</span> <span class=\"n\">Executor</span><span class=\"p\">(</span><span class=\"s\">'54.173.84.107:8786'</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">e</span>\n<span class=\"o\">&lt;</span><span class=\"n\">Executor</span><span class=\"p\">:</span> <span class=\"n\">scheduler</span><span class=\"o\">=</span><span class=\"mf\">54.173</span><span class=\"p\">.</span><span class=\"mf\">84.107</span><span class=\"p\">:</span><span class=\"mi\">8786</span> <span class=\"n\">workers</span><span class=\"o\">=</span><span class=\"mi\">72</span> <span class=\"n\">threads</span><span class=\"o\">=</span><span class=\"mi\">72</span><span class=\"o\">&gt;</span>\n</code></pre></div></div>\n\n<p>Our seventy-two worker processes come from nine workers with eight processes\neach.  We chose processes rather than threads for this task because\ncomputations will be bound by the GIL.  We will change this to threads in later\nexamples.</p>\n\n<p>We start by loading a single month of data into distributed memory.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">import</span> <span class=\"nn\">json</span>\n<span class=\"n\">text</span> <span class=\"o\">=</span> <span class=\"n\">s3</span><span class=\"p\">.</span><span class=\"n\">read_text</span><span class=\"p\">(</span><span class=\"s\">'githubarchive-data'</span><span class=\"p\">,</span> <span class=\"s\">'2015-01'</span><span class=\"p\">,</span> <span class=\"n\">compression</span><span class=\"o\">=</span><span class=\"s\">'gzip'</span><span class=\"p\">)</span>\n<span class=\"n\">records</span> <span class=\"o\">=</span> <span class=\"n\">text</span><span class=\"p\">.</span><span class=\"nb\">map</span><span class=\"p\">(</span><span class=\"n\">json</span><span class=\"p\">.</span><span class=\"n\">loads</span><span class=\"p\">)</span>\n<span class=\"n\">records</span> <span class=\"o\">=</span> <span class=\"n\">e</span><span class=\"p\">.</span><span class=\"n\">persist</span><span class=\"p\">(</span><span class=\"n\">records</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p>The data lives in S3 in hourly files as gzipped encoded, line delimited JSON.\nThe <code class=\"language-plaintext highlighter-rouge\">s3.read_text</code> and <code class=\"language-plaintext highlighter-rouge\">text.map</code> functions produce\n<a href=\"http://dask.pydata.org/en/latest/bag.html\">dask.bag</a> objects which track our\noperations in a lazily built task graph.  When we ask the executor to <code class=\"language-plaintext highlighter-rouge\">persist</code>\nthis collection we ship those tasks off to the scheduler to run on all of the\nworkers in parallel.  The <code class=\"language-plaintext highlighter-rouge\">persist</code> function gives us back another <code class=\"language-plaintext highlighter-rouge\">dask.bag</code>\npointing to these remotely running results.  This persist function returns\nimmediately, and the computation happens on the cluster in the background\nasynchronously.  We gain control of our interpreter immediately while the\ncluster hums along.</p>\n\n<p>The cluster takes around 40 seconds to download, decompress, and parse this\ndata.  If you watch the video embedded above you’ll see fancy progress-bars.</p>\n\n<p>We ask for a single record.  This returns in around 200ms, which is fast enough\nthat it feels instantaneous to a human.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">records</span><span class=\"p\">.</span><span class=\"n\">take</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n<span class=\"p\">({</span><span class=\"s\">'actor'</span><span class=\"p\">:</span> <span class=\"p\">{</span><span class=\"s\">'avatar_url'</span><span class=\"p\">:</span> <span class=\"s\">'https://avatars.githubusercontent.com/u/9152315?'</span><span class=\"p\">,</span>\n   <span class=\"s\">'gravatar_id'</span><span class=\"p\">:</span> <span class=\"s\">''</span><span class=\"p\">,</span>\n   <span class=\"s\">'id'</span><span class=\"p\">:</span> <span class=\"mi\">9152315</span><span class=\"p\">,</span>\n   <span class=\"s\">'login'</span><span class=\"p\">:</span> <span class=\"s\">'davidjhulse'</span><span class=\"p\">,</span>\n   <span class=\"s\">'url'</span><span class=\"p\">:</span> <span class=\"s\">'https://api.github.com/users/davidjhulse'</span><span class=\"p\">},</span>\n  <span class=\"s\">'created_at'</span><span class=\"p\">:</span> <span class=\"s\">'2015-01-01T00:00:00Z'</span><span class=\"p\">,</span>\n  <span class=\"s\">'id'</span><span class=\"p\">:</span> <span class=\"s\">'2489368070'</span><span class=\"p\">,</span>\n  <span class=\"s\">'payload'</span><span class=\"p\">:</span> <span class=\"p\">{</span><span class=\"s\">'before'</span><span class=\"p\">:</span> <span class=\"s\">'86ffa724b4d70fce46e760f8cc080f5ec3d7d85f'</span><span class=\"p\">,</span>\n   <span class=\"s\">'commits'</span><span class=\"p\">:</span> <span class=\"p\">[{</span><span class=\"s\">'author'</span><span class=\"p\">:</span> <span class=\"p\">{</span><span class=\"s\">'email'</span><span class=\"p\">:</span> <span class=\"s\">'david.hulse@live.com'</span><span class=\"p\">,</span>\n      <span class=\"s\">'name'</span><span class=\"p\">:</span> <span class=\"s\">'davidjhulse'</span><span class=\"p\">},</span>\n     <span class=\"s\">'distinct'</span><span class=\"p\">:</span> <span class=\"bp\">True</span><span class=\"p\">,</span>\n     <span class=\"s\">'message'</span><span class=\"p\">:</span> <span class=\"s\">'Altered BingBot.jar</span><span class=\"se\">\\n\\n</span><span class=\"s\">Fixed issue with multiple account support'</span><span class=\"p\">,</span>\n     <span class=\"s\">'sha'</span><span class=\"p\">:</span> <span class=\"s\">'a9b22a6d80c1e0bb49c1cf75a3c075b642c28f81'</span><span class=\"p\">,</span>\n     <span class=\"s\">'url'</span><span class=\"p\">:</span> <span class=\"s\">'https://api.github.com/repos/davidjhulse/davesbingrewardsbot/commits/a9b22a6d80c1e0bb49c1cf75a3c075b642c28f81'</span><span class=\"p\">}],</span>\n   <span class=\"s\">'distinct_size'</span><span class=\"p\">:</span> <span class=\"mi\">1</span><span class=\"p\">,</span>\n   <span class=\"s\">'head'</span><span class=\"p\">:</span> <span class=\"s\">'a9b22a6d80c1e0bb49c1cf75a3c075b642c28f81'</span><span class=\"p\">,</span>\n   <span class=\"s\">'push_id'</span><span class=\"p\">:</span> <span class=\"mi\">536740396</span><span class=\"p\">,</span>\n   <span class=\"s\">'ref'</span><span class=\"p\">:</span> <span class=\"s\">'refs/heads/master'</span><span class=\"p\">,</span>\n   <span class=\"s\">'size'</span><span class=\"p\">:</span> <span class=\"mi\">1</span><span class=\"p\">},</span>\n  <span class=\"s\">'public'</span><span class=\"p\">:</span> <span class=\"bp\">True</span><span class=\"p\">,</span>\n  <span class=\"s\">'repo'</span><span class=\"p\">:</span> <span class=\"p\">{</span><span class=\"s\">'id'</span><span class=\"p\">:</span> <span class=\"mi\">28635890</span><span class=\"p\">,</span>\n   <span class=\"s\">'name'</span><span class=\"p\">:</span> <span class=\"s\">'davidjhulse/davesbingrewardsbot'</span><span class=\"p\">,</span>\n   <span class=\"s\">'url'</span><span class=\"p\">:</span> <span class=\"s\">'https://api.github.com/repos/davidjhulse/davesbingrewardsbot'</span><span class=\"p\">},</span>\n  <span class=\"s\">'type'</span><span class=\"p\">:</span> <span class=\"s\">'PushEvent'</span><span class=\"p\">},)</span>\n</code></pre></div></div>\n\n<p>This particular event is a <code class=\"language-plaintext highlighter-rouge\">'PushEvent'</code>.  Let’s quickly see all the kinds of\nevents.  For fun, we’ll also time the interaction:</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"o\">%</span><span class=\"n\">time</span> <span class=\"n\">records</span><span class=\"p\">.</span><span class=\"n\">pluck</span><span class=\"p\">(</span><span class=\"s\">'type'</span><span class=\"p\">).</span><span class=\"n\">frequencies</span><span class=\"p\">().</span><span class=\"n\">compute</span><span class=\"p\">()</span>\n<span class=\"n\">CPU</span> <span class=\"n\">times</span><span class=\"p\">:</span> <span class=\"n\">user</span> <span class=\"mi\">112</span> <span class=\"n\">ms</span><span class=\"p\">,</span> <span class=\"n\">sys</span><span class=\"p\">:</span> <span class=\"mi\">0</span> <span class=\"n\">ns</span><span class=\"p\">,</span> <span class=\"n\">total</span><span class=\"p\">:</span> <span class=\"mi\">112</span> <span class=\"n\">ms</span>\n<span class=\"n\">Wall</span> <span class=\"n\">time</span><span class=\"p\">:</span> <span class=\"mf\">2.41</span> <span class=\"n\">s</span>\n\n<span class=\"p\">[(</span><span class=\"s\">'ReleaseEvent'</span><span class=\"p\">,</span> <span class=\"mi\">44312</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'MemberEvent'</span><span class=\"p\">,</span> <span class=\"mi\">69757</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'IssuesEvent'</span><span class=\"p\">,</span> <span class=\"mi\">693363</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'PublicEvent'</span><span class=\"p\">,</span> <span class=\"mi\">14614</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'CreateEvent'</span><span class=\"p\">,</span> <span class=\"mi\">1651300</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'PullRequestReviewCommentEvent'</span><span class=\"p\">,</span> <span class=\"mi\">214288</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'PullRequestEvent'</span><span class=\"p\">,</span> <span class=\"mi\">680879</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'ForkEvent'</span><span class=\"p\">,</span> <span class=\"mi\">491256</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'DeleteEvent'</span><span class=\"p\">,</span> <span class=\"mi\">256987</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'PushEvent'</span><span class=\"p\">,</span> <span class=\"mi\">7028566</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'IssueCommentEvent'</span><span class=\"p\">,</span> <span class=\"mi\">1322509</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'GollumEvent'</span><span class=\"p\">,</span> <span class=\"mi\">150861</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'CommitCommentEvent'</span><span class=\"p\">,</span> <span class=\"mi\">96468</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'WatchEvent'</span><span class=\"p\">,</span> <span class=\"mi\">1321546</span><span class=\"p\">)]</span>\n</code></pre></div></div>\n\n<p>And we compute the total count of all commits for this month.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"o\">%</span><span class=\"n\">time</span> <span class=\"n\">records</span><span class=\"p\">.</span><span class=\"n\">count</span><span class=\"p\">().</span><span class=\"n\">compute</span><span class=\"p\">()</span>\n<span class=\"n\">CPU</span> <span class=\"n\">times</span><span class=\"p\">:</span> <span class=\"n\">user</span> <span class=\"mi\">134</span> <span class=\"n\">ms</span><span class=\"p\">,</span> <span class=\"n\">sys</span><span class=\"p\">:</span> <span class=\"mi\">133</span> <span class=\"n\">µs</span><span class=\"p\">,</span> <span class=\"n\">total</span><span class=\"p\">:</span> <span class=\"mi\">134</span> <span class=\"n\">ms</span>\n<span class=\"n\">Wall</span> <span class=\"n\">time</span><span class=\"p\">:</span> <span class=\"mf\">1.49</span> <span class=\"n\">s</span>\n\n<span class=\"mi\">14036706</span>\n</code></pre></div></div>\n\n<p>We see that it takes a few seconds to walk through the data (and perform all\nscheduling overhead.)  The scheduler adds about a millisecond overhead per\ntask, and there are about 1000 partitions/files here (the GitHub data is split\nby hour and there are 730 hours in a month) so most of the cost here is\noverhead.</p>\n\n<h2 id=\"investigate-jupyter\">Investigate Jupyter</h2>\n\n<p>We investigate the activities of <a href=\"http://jupyter.org/\">Project Jupyter</a>.  We\nchose this project because it’s sizable and because we understand the players\ninvolved and so can check our accuracy.  This will require us to filter our\ndata to a much smaller subset, then find popular repositories and members.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">jupyter</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">records</span><span class=\"p\">.</span><span class=\"nb\">filter</span><span class=\"p\">(</span><span class=\"k\">lambda</span> <span class=\"n\">d</span><span class=\"p\">:</span> <span class=\"n\">d</span><span class=\"p\">[</span><span class=\"s\">'repo'</span><span class=\"p\">][</span><span class=\"s\">'name'</span><span class=\"p\">].</span><span class=\"n\">startswith</span><span class=\"p\">(</span><span class=\"s\">'jupyter/'</span><span class=\"p\">))</span>\n                      <span class=\"p\">.</span><span class=\"n\">repartition</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">))</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">jupyter</span> <span class=\"o\">=</span> <span class=\"n\">e</span><span class=\"p\">.</span><span class=\"n\">persist</span><span class=\"p\">(</span><span class=\"n\">jupyter</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p>All records, regardless of event type, have a repository which has a name like\n<code class=\"language-plaintext highlighter-rouge\">'organization/repository'</code> in typical GitHub fashion.  We filter all records\nthat start with <code class=\"language-plaintext highlighter-rouge\">'jupyter/'</code>.  Additionally, because this dataset is likely\nmuch smaller, we push all of these records into just ten partitions.  This\ndramatically reduces scheduling overhead.  The <code class=\"language-plaintext highlighter-rouge\">persist</code> call hands this\ncomputation off to the scheduler and then gives us back our collection that\npoints to that computing result.  Filtering this month for Jupyter events takes\nabout 7.5 seconds.  Afterwards computations on this subset feel snappy.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"o\">%</span><span class=\"n\">time</span> <span class=\"n\">jupyter</span><span class=\"p\">.</span><span class=\"n\">count</span><span class=\"p\">().</span><span class=\"n\">compute</span><span class=\"p\">()</span>\n<span class=\"n\">CPU</span> <span class=\"n\">times</span><span class=\"p\">:</span> <span class=\"n\">user</span> <span class=\"mf\">5.19</span> <span class=\"n\">ms</span><span class=\"p\">,</span> <span class=\"n\">sys</span><span class=\"p\">:</span> <span class=\"mi\">97</span> <span class=\"n\">µs</span><span class=\"p\">,</span> <span class=\"n\">total</span><span class=\"p\">:</span> <span class=\"mf\">5.28</span> <span class=\"n\">ms</span>\n<span class=\"n\">Wall</span> <span class=\"n\">time</span><span class=\"p\">:</span> <span class=\"mi\">199</span> <span class=\"n\">ms</span>\n\n<span class=\"mi\">747</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"o\">%</span><span class=\"n\">time</span> <span class=\"n\">jupyter</span><span class=\"p\">.</span><span class=\"n\">take</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n<span class=\"n\">CPU</span> <span class=\"n\">times</span><span class=\"p\">:</span> <span class=\"n\">user</span> <span class=\"mf\">7.01</span> <span class=\"n\">ms</span><span class=\"p\">,</span> <span class=\"n\">sys</span><span class=\"p\">:</span> <span class=\"mi\">259</span> <span class=\"n\">µs</span><span class=\"p\">,</span> <span class=\"n\">total</span><span class=\"p\">:</span> <span class=\"mf\">7.27</span> <span class=\"n\">ms</span>\n<span class=\"n\">Wall</span> <span class=\"n\">time</span><span class=\"p\">:</span> <span class=\"mi\">182</span> <span class=\"n\">ms</span>\n\n<span class=\"p\">({</span><span class=\"s\">'actor'</span><span class=\"p\">:</span> <span class=\"p\">{</span><span class=\"s\">'avatar_url'</span><span class=\"p\">:</span> <span class=\"s\">'https://avatars.githubusercontent.com/u/26679?'</span><span class=\"p\">,</span>\n   <span class=\"s\">'gravatar_id'</span><span class=\"p\">:</span> <span class=\"s\">''</span><span class=\"p\">,</span>\n   <span class=\"s\">'id'</span><span class=\"p\">:</span> <span class=\"mi\">26679</span><span class=\"p\">,</span>\n   <span class=\"s\">'login'</span><span class=\"p\">:</span> <span class=\"s\">'marksteve'</span><span class=\"p\">,</span>\n   <span class=\"s\">'url'</span><span class=\"p\">:</span> <span class=\"s\">'https://api.github.com/users/marksteve'</span><span class=\"p\">},</span>\n  <span class=\"s\">'created_at'</span><span class=\"p\">:</span> <span class=\"s\">'2015-01-01T13:25:44Z'</span><span class=\"p\">,</span>\n  <span class=\"s\">'id'</span><span class=\"p\">:</span> <span class=\"s\">'2489612400'</span><span class=\"p\">,</span>\n  <span class=\"s\">'org'</span><span class=\"p\">:</span> <span class=\"p\">{</span><span class=\"s\">'avatar_url'</span><span class=\"p\">:</span> <span class=\"s\">'https://avatars.githubusercontent.com/u/7388996?'</span><span class=\"p\">,</span>\n   <span class=\"s\">'gravatar_id'</span><span class=\"p\">:</span> <span class=\"s\">''</span><span class=\"p\">,</span>\n   <span class=\"s\">'id'</span><span class=\"p\">:</span> <span class=\"mi\">7388996</span><span class=\"p\">,</span>\n   <span class=\"s\">'login'</span><span class=\"p\">:</span> <span class=\"s\">'jupyter'</span><span class=\"p\">,</span>\n   <span class=\"s\">'url'</span><span class=\"p\">:</span> <span class=\"s\">'https://api.github.com/orgs/jupyter'</span><span class=\"p\">},</span>\n  <span class=\"s\">'payload'</span><span class=\"p\">:</span> <span class=\"p\">{</span><span class=\"s\">'action'</span><span class=\"p\">:</span> <span class=\"s\">'started'</span><span class=\"p\">},</span>\n  <span class=\"s\">'public'</span><span class=\"p\">:</span> <span class=\"bp\">True</span><span class=\"p\">,</span>\n  <span class=\"s\">'repo'</span><span class=\"p\">:</span> <span class=\"p\">{</span><span class=\"s\">'id'</span><span class=\"p\">:</span> <span class=\"mi\">5303123</span><span class=\"p\">,</span>\n   <span class=\"s\">'name'</span><span class=\"p\">:</span> <span class=\"s\">'jupyter/nbviewer'</span><span class=\"p\">,</span>\n   <span class=\"s\">'url'</span><span class=\"p\">:</span> <span class=\"s\">'https://api.github.com/repos/jupyter/nbviewer'</span><span class=\"p\">},</span>\n  <span class=\"s\">'type'</span><span class=\"p\">:</span> <span class=\"s\">'WatchEvent'</span><span class=\"p\">},)</span>\n</code></pre></div></div>\n\n<p>So the first event of the year was by <code class=\"language-plaintext highlighter-rouge\">'marksteve'</code> who decided to watch the\n<code class=\"language-plaintext highlighter-rouge\">'nbviewer'</code> repository on new year’s day.</p>\n\n<p>Notice that these computations take around 200ms.  I can’t get below this from\nmy local machine, so we’re likely bound by communicating to such a remote\nlocation.  A 200ms latency is not great if you’re playing a video game, but\nit’s decent for interactive computing.</p>\n\n<p>Here are all of the Jupyter repositories touched in the month of January,</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"o\">%</span><span class=\"n\">time</span> <span class=\"n\">jupyter</span><span class=\"p\">.</span><span class=\"n\">pluck</span><span class=\"p\">(</span><span class=\"s\">'repo'</span><span class=\"p\">).</span><span class=\"n\">pluck</span><span class=\"p\">(</span><span class=\"s\">'name'</span><span class=\"p\">).</span><span class=\"n\">distinct</span><span class=\"p\">().</span><span class=\"n\">compute</span><span class=\"p\">()</span>\n<span class=\"n\">CPU</span> <span class=\"n\">times</span><span class=\"p\">:</span> <span class=\"n\">user</span> <span class=\"mf\">2.84</span> <span class=\"n\">ms</span><span class=\"p\">,</span> <span class=\"n\">sys</span><span class=\"p\">:</span> <span class=\"mf\">4.03</span> <span class=\"n\">ms</span><span class=\"p\">,</span> <span class=\"n\">total</span><span class=\"p\">:</span> <span class=\"mf\">6.86</span> <span class=\"n\">ms</span>\n<span class=\"n\">Wall</span> <span class=\"n\">time</span><span class=\"p\">:</span> <span class=\"mi\">204</span> <span class=\"n\">ms</span>\n\n<span class=\"p\">[</span><span class=\"s\">'jupyter/dockerspawner'</span><span class=\"p\">,</span>\n <span class=\"s\">'jupyter/design'</span><span class=\"p\">,</span>\n <span class=\"s\">'jupyter/docker-demo-images'</span><span class=\"p\">,</span>\n <span class=\"s\">'jupyter/jupyterhub'</span><span class=\"p\">,</span>\n <span class=\"s\">'jupyter/configurable-http-proxy'</span><span class=\"p\">,</span>\n <span class=\"s\">'jupyter/nbshot'</span><span class=\"p\">,</span>\n <span class=\"s\">'jupyter/sudospawner'</span><span class=\"p\">,</span>\n <span class=\"s\">'jupyter/colaboratory'</span><span class=\"p\">,</span>\n <span class=\"s\">'jupyter/strata-sv-2015-tutorial'</span><span class=\"p\">,</span>\n <span class=\"s\">'jupyter/tmpnb-deploy'</span><span class=\"p\">,</span>\n <span class=\"s\">'jupyter/nature-demo'</span><span class=\"p\">,</span>\n <span class=\"s\">'jupyter/nbcache'</span><span class=\"p\">,</span>\n <span class=\"s\">'jupyter/jupyter.github.io'</span><span class=\"p\">,</span>\n <span class=\"s\">'jupyter/try.jupyter.org'</span><span class=\"p\">,</span>\n <span class=\"s\">'jupyter/jupyter-drive'</span><span class=\"p\">,</span>\n <span class=\"s\">'jupyter/tmpnb'</span><span class=\"p\">,</span>\n <span class=\"s\">'jupyter/tmpnb-redirector'</span><span class=\"p\">,</span>\n <span class=\"s\">'jupyter/nbgrader'</span><span class=\"p\">,</span>\n <span class=\"s\">'jupyter/nbindex'</span><span class=\"p\">,</span>\n <span class=\"s\">'jupyter/nbviewer'</span><span class=\"p\">,</span>\n <span class=\"s\">'jupyter/oauthenticator'</span><span class=\"p\">]</span>\n</code></pre></div></div>\n\n<p>And the top ten most active people on GitHub.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"o\">%</span><span class=\"n\">time</span> <span class=\"p\">(</span><span class=\"n\">jupyter</span><span class=\"p\">.</span><span class=\"n\">pluck</span><span class=\"p\">(</span><span class=\"s\">'actor'</span><span class=\"p\">)</span>\n                  <span class=\"p\">.</span><span class=\"n\">pluck</span><span class=\"p\">(</span><span class=\"s\">'login'</span><span class=\"p\">)</span>\n                  <span class=\"p\">.</span><span class=\"n\">frequencies</span><span class=\"p\">()</span>\n                  <span class=\"p\">.</span><span class=\"n\">topk</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"k\">lambda</span> <span class=\"n\">kv</span><span class=\"p\">:</span> <span class=\"n\">kv</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">])</span>\n                  <span class=\"p\">.</span><span class=\"n\">compute</span><span class=\"p\">())</span>\n<span class=\"n\">CPU</span> <span class=\"n\">times</span><span class=\"p\">:</span> <span class=\"n\">user</span> <span class=\"mf\">8.03</span> <span class=\"n\">ms</span><span class=\"p\">,</span> <span class=\"n\">sys</span><span class=\"p\">:</span> <span class=\"mi\">90</span> <span class=\"n\">µs</span><span class=\"p\">,</span> <span class=\"n\">total</span><span class=\"p\">:</span> <span class=\"mf\">8.12</span> <span class=\"n\">ms</span>\n<span class=\"n\">Wall</span> <span class=\"n\">time</span><span class=\"p\">:</span> <span class=\"mi\">226</span> <span class=\"n\">ms</span>\n\n<span class=\"p\">[(</span><span class=\"s\">'rgbkrk'</span><span class=\"p\">,</span> <span class=\"mi\">156</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'minrk'</span><span class=\"p\">,</span> <span class=\"mi\">87</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'Carreau'</span><span class=\"p\">,</span> <span class=\"mi\">87</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'KesterTong'</span><span class=\"p\">,</span> <span class=\"mi\">74</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'jhamrick'</span><span class=\"p\">,</span> <span class=\"mi\">70</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'bollwyvl'</span><span class=\"p\">,</span> <span class=\"mi\">25</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'pkt'</span><span class=\"p\">,</span> <span class=\"mi\">18</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'ssanderson'</span><span class=\"p\">,</span> <span class=\"mi\">13</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'smashwilson'</span><span class=\"p\">,</span> <span class=\"mi\">13</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'ellisonbg'</span><span class=\"p\">,</span> <span class=\"mi\">13</span><span class=\"p\">)]</span>\n</code></pre></div></div>\n\n<p>Nothing too surprising here if you know these folks.</p>\n\n<h2 id=\"full-dataset\">Full Dataset</h2>\n\n<p>The full five months of data is too large to fit in memory, even for this\ncluster.  When we represent semi-structured data like this with dynamic data\nstructures like lists and dictionaries there is quite a bit of memory bloat.\nSome careful attention to efficient semi-structured storage here could save us\nfrom having to switch to such a large cluster, but that will have to be\nthe topic of another post.</p>\n\n<p>Instead, we operate efficiently on this dataset by flowing it through\nmemory, persisting only the records we care about.  The distributed dask\nscheduler descends from the single-machine dask scheduler, which was quite good\nat flowing through a computation and intelligently removing intermediate\nresults.</p>\n\n<p>From a user API perspective, we call <code class=\"language-plaintext highlighter-rouge\">persist</code> only on the <code class=\"language-plaintext highlighter-rouge\">jupyter</code> dataset,\nand not the full <code class=\"language-plaintext highlighter-rouge\">records</code> dataset.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">full</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">s3</span><span class=\"p\">.</span><span class=\"n\">read_text</span><span class=\"p\">(</span><span class=\"s\">'githubarchive-data'</span><span class=\"p\">,</span> <span class=\"s\">'2015'</span><span class=\"p\">,</span> <span class=\"n\">compression</span><span class=\"o\">=</span><span class=\"s\">'gzip'</span><span class=\"p\">)</span>\n              <span class=\"p\">.</span><span class=\"nb\">map</span><span class=\"p\">(</span><span class=\"n\">json</span><span class=\"p\">.</span><span class=\"n\">loads</span><span class=\"p\">)</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">jupyter</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">full</span><span class=\"p\">.</span><span class=\"nb\">filter</span><span class=\"p\">(</span><span class=\"k\">lambda</span> <span class=\"n\">d</span><span class=\"p\">:</span> <span class=\"n\">d</span><span class=\"p\">[</span><span class=\"s\">'repo'</span><span class=\"p\">][</span><span class=\"s\">'name'</span><span class=\"p\">].</span><span class=\"n\">startswith</span><span class=\"p\">(</span><span class=\"s\">'jupyter/'</span><span class=\"p\">))</span>\n                   <span class=\"p\">.</span><span class=\"n\">repartition</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">))</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">jupyter</span> <span class=\"o\">=</span> <span class=\"n\">e</span><span class=\"p\">.</span><span class=\"n\">persist</span><span class=\"p\">(</span><span class=\"n\">jupyter</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p>It takes 2m36s to download, decompress, and parse the five months of publicly\navailable GitHub events for all Jupyter events on nine <code class=\"language-plaintext highlighter-rouge\">m3.2xlarges</code>.</p>\n\n<p>There were seven thousand such events.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">jupyter</span><span class=\"p\">.</span><span class=\"n\">count</span><span class=\"p\">().</span><span class=\"n\">compute</span><span class=\"p\">()</span>\n<span class=\"mi\">7065</span>\n</code></pre></div></div>\n\n<p>We find which repositories saw the most activity during that time:</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"o\">%</span><span class=\"n\">time</span> <span class=\"p\">(</span><span class=\"n\">jupyter</span><span class=\"p\">.</span><span class=\"n\">pluck</span><span class=\"p\">(</span><span class=\"s\">'repo'</span><span class=\"p\">)</span>\n                  <span class=\"p\">.</span><span class=\"n\">pluck</span><span class=\"p\">(</span><span class=\"s\">'name'</span><span class=\"p\">)</span>\n                  <span class=\"p\">.</span><span class=\"n\">frequencies</span><span class=\"p\">()</span>\n                  <span class=\"p\">.</span><span class=\"n\">topk</span><span class=\"p\">(</span><span class=\"mi\">20</span><span class=\"p\">,</span> <span class=\"k\">lambda</span> <span class=\"n\">kv</span><span class=\"p\">:</span> <span class=\"n\">kv</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">])</span>\n                  <span class=\"p\">.</span><span class=\"n\">compute</span><span class=\"p\">())</span>\n<span class=\"n\">CPU</span> <span class=\"n\">times</span><span class=\"p\">:</span> <span class=\"n\">user</span> <span class=\"mf\">6.98</span> <span class=\"n\">ms</span><span class=\"p\">,</span> <span class=\"n\">sys</span><span class=\"p\">:</span> <span class=\"mi\">474</span> <span class=\"n\">µs</span><span class=\"p\">,</span> <span class=\"n\">total</span><span class=\"p\">:</span> <span class=\"mf\">7.46</span> <span class=\"n\">ms</span>\n<span class=\"n\">Wall</span> <span class=\"n\">time</span><span class=\"p\">:</span> <span class=\"mi\">219</span> <span class=\"n\">ms</span>\n\n<span class=\"p\">[(</span><span class=\"s\">'jupyter/jupyterhub'</span><span class=\"p\">,</span> <span class=\"mi\">1262</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'jupyter/nbgrader'</span><span class=\"p\">,</span> <span class=\"mi\">1235</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'jupyter/nbviewer'</span><span class=\"p\">,</span> <span class=\"mi\">846</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'jupyter/jupyter_notebook'</span><span class=\"p\">,</span> <span class=\"mi\">507</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'jupyter/jupyter-drive'</span><span class=\"p\">,</span> <span class=\"mi\">505</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'jupyter/notebook'</span><span class=\"p\">,</span> <span class=\"mi\">451</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'jupyter/docker-demo-images'</span><span class=\"p\">,</span> <span class=\"mi\">363</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'jupyter/tmpnb'</span><span class=\"p\">,</span> <span class=\"mi\">284</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'jupyter/jupyter_client'</span><span class=\"p\">,</span> <span class=\"mi\">162</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'jupyter/dockerspawner'</span><span class=\"p\">,</span> <span class=\"mi\">149</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'jupyter/colaboratory'</span><span class=\"p\">,</span> <span class=\"mi\">134</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'jupyter/jupyter_core'</span><span class=\"p\">,</span> <span class=\"mi\">127</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'jupyter/strata-sv-2015-tutorial'</span><span class=\"p\">,</span> <span class=\"mi\">108</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'jupyter/jupyter_nbconvert'</span><span class=\"p\">,</span> <span class=\"mi\">103</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'jupyter/configurable-http-proxy'</span><span class=\"p\">,</span> <span class=\"mi\">89</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'jupyter/hubpress.io'</span><span class=\"p\">,</span> <span class=\"mi\">85</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'jupyter/jupyter.github.io'</span><span class=\"p\">,</span> <span class=\"mi\">84</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'jupyter/tmpnb-deploy'</span><span class=\"p\">,</span> <span class=\"mi\">76</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'jupyter/nbconvert'</span><span class=\"p\">,</span> <span class=\"mi\">66</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'jupyter/jupyter_qtconsole'</span><span class=\"p\">,</span> <span class=\"mi\">59</span><span class=\"p\">)]</span>\n</code></pre></div></div>\n\n<p>We see that projects like <code class=\"language-plaintext highlighter-rouge\">jupyterhub</code> were quite active during that time\nwhile, surprisingly, <code class=\"language-plaintext highlighter-rouge\">nbconvert</code> saw relatively little action.</p>\n\n<h2 id=\"local-data\">Local Data</h2>\n\n<p>The Jupyter data is quite small and easily fits in a single machine.  Let’s\nbring the data to our local machine so that we can compare times:</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"o\">%</span><span class=\"n\">time</span> <span class=\"n\">L</span> <span class=\"o\">=</span> <span class=\"n\">jupyter</span><span class=\"p\">.</span><span class=\"n\">compute</span><span class=\"p\">()</span>\n<span class=\"n\">CPU</span> <span class=\"n\">times</span><span class=\"p\">:</span> <span class=\"n\">user</span> <span class=\"mf\">4.74</span> <span class=\"n\">s</span><span class=\"p\">,</span> <span class=\"n\">sys</span><span class=\"p\">:</span> <span class=\"mf\">10.9</span> <span class=\"n\">s</span><span class=\"p\">,</span> <span class=\"n\">total</span><span class=\"p\">:</span> <span class=\"mf\">15.7</span> <span class=\"n\">s</span>\n<span class=\"n\">Wall</span> <span class=\"n\">time</span><span class=\"p\">:</span> <span class=\"mf\">30.2</span> <span class=\"n\">s</span>\n</code></pre></div></div>\n\n<p>It takes surprisingly long to download the data, but once its here, we can\niterate far more quickly with basic Python.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">toolz.curried</span> <span class=\"kn\">import</span> <span class=\"n\">pluck</span><span class=\"p\">,</span> <span class=\"n\">frequencies</span><span class=\"p\">,</span> <span class=\"n\">topk</span><span class=\"p\">,</span> <span class=\"n\">pipe</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"o\">%</span><span class=\"n\">time</span> <span class=\"n\">pipe</span><span class=\"p\">(</span><span class=\"n\">L</span><span class=\"p\">,</span> <span class=\"n\">pluck</span><span class=\"p\">(</span><span class=\"s\">'repo'</span><span class=\"p\">),</span> <span class=\"n\">pluck</span><span class=\"p\">(</span><span class=\"s\">'name'</span><span class=\"p\">),</span> <span class=\"n\">frequencies</span><span class=\"p\">,</span>\n               <span class=\"nb\">dict</span><span class=\"p\">.</span><span class=\"n\">items</span><span class=\"p\">,</span> <span class=\"n\">topk</span><span class=\"p\">(</span><span class=\"mi\">20</span><span class=\"p\">,</span> <span class=\"n\">key</span><span class=\"o\">=</span><span class=\"k\">lambda</span> <span class=\"n\">kv</span><span class=\"p\">:</span> <span class=\"n\">kv</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]),</span> <span class=\"nb\">list</span><span class=\"p\">)</span>\n<span class=\"n\">CPU</span> <span class=\"n\">times</span><span class=\"p\">:</span> <span class=\"n\">user</span> <span class=\"mf\">11.8</span> <span class=\"n\">ms</span><span class=\"p\">,</span> <span class=\"n\">sys</span><span class=\"p\">:</span> <span class=\"mi\">0</span> <span class=\"n\">ns</span><span class=\"p\">,</span> <span class=\"n\">total</span><span class=\"p\">:</span> <span class=\"mf\">11.8</span> <span class=\"n\">ms</span>\n<span class=\"n\">Wall</span> <span class=\"n\">time</span><span class=\"p\">:</span> <span class=\"mf\">11.5</span> <span class=\"n\">ms</span>\n\n<span class=\"p\">[(</span><span class=\"s\">'jupyter/jupyterhub'</span><span class=\"p\">,</span> <span class=\"mi\">1262</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'jupyter/nbgrader'</span><span class=\"p\">,</span> <span class=\"mi\">1235</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'jupyter/nbviewer'</span><span class=\"p\">,</span> <span class=\"mi\">846</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'jupyter/jupyter_notebook'</span><span class=\"p\">,</span> <span class=\"mi\">507</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'jupyter/jupyter-drive'</span><span class=\"p\">,</span> <span class=\"mi\">505</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'jupyter/notebook'</span><span class=\"p\">,</span> <span class=\"mi\">451</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'jupyter/docker-demo-images'</span><span class=\"p\">,</span> <span class=\"mi\">363</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'jupyter/tmpnb'</span><span class=\"p\">,</span> <span class=\"mi\">284</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'jupyter/jupyter_client'</span><span class=\"p\">,</span> <span class=\"mi\">162</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'jupyter/dockerspawner'</span><span class=\"p\">,</span> <span class=\"mi\">149</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'jupyter/colaboratory'</span><span class=\"p\">,</span> <span class=\"mi\">134</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'jupyter/jupyter_core'</span><span class=\"p\">,</span> <span class=\"mi\">127</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'jupyter/strata-sv-2015-tutorial'</span><span class=\"p\">,</span> <span class=\"mi\">108</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'jupyter/jupyter_nbconvert'</span><span class=\"p\">,</span> <span class=\"mi\">103</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'jupyter/configurable-http-proxy'</span><span class=\"p\">,</span> <span class=\"mi\">89</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'jupyter/hubpress.io'</span><span class=\"p\">,</span> <span class=\"mi\">85</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'jupyter/jupyter.github.io'</span><span class=\"p\">,</span> <span class=\"mi\">84</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'jupyter/tmpnb-deploy'</span><span class=\"p\">,</span> <span class=\"mi\">76</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'jupyter/nbconvert'</span><span class=\"p\">,</span> <span class=\"mi\">66</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"s\">'jupyter/jupyter_qtconsole'</span><span class=\"p\">,</span> <span class=\"mi\">59</span><span class=\"p\">)]</span>\n</code></pre></div></div>\n\n<p>The difference here is 20x, which is a good reminder that, once you no longer\nhave a large problem you should probably eschew distributed systems and act\nlocally.</p>\n\n<h2 id=\"conclusion\">Conclusion</h2>\n\n<p>Downloading, decompressing, parsing, filtering, and counting JSON records\nis the new wordcount.  It’s the first problem anyone sees.  Fortunately it’s\nboth easy to solve and the common case.  Woo hoo!</p>\n\n<p>Here we saw that dask+distributed handle the common case decently well and with\na Pure Python stack.  Typically Python users rely on a JVM technology like\nHadoop/Spark/Storm to distribute their computations.  Here we have Python\ndistributing Python; there are some usability gains to be had here like nice\nstack traces, a bit less serialization overhead, and attention to other\nPythonic style choices.</p>\n\n<p>Over the next few posts I intend to deviate from this common case.  Most “Big\nData” technologies were designed to solve typical data munging problems found\nin web companies or with simple database operations in mind.  Python users care\nabout these things too, but they also reach out to a wide variety of fields.\nIn dask+distributed development we care about the common case, but also support\nless traditional workflows that are commonly found in the life, physical, and\nalgorithmic sciences.</p>\n\n<p>By designing to support these more extreme cases we’ve nailed some common pain\npoints in current distributed systems.  Today we’ve seen low latency and remote\ncontrol; in the future we’ll see others.</p>\n\n<h2 id=\"what-doesnt-work\">What doesn’t work</h2>\n\n<p>I’ll have an honest section like this at the end of each upcoming post\ndescribing what doesn’t work, what still feels broken, or what I would have\ndone differently with more time.</p>\n\n<ul>\n  <li>\n    <p>The imports for dask and distributed are still strange.  They’re two\nseparate codebases that play very nicely together.  Unfortunately the\nfunctionality you need is sometimes in one or in the other and it’s not\nimmediately clear to the novice user where to go.  For example dask.bag, the\ncollection we’re using for <code class=\"language-plaintext highlighter-rouge\">records</code>, <code class=\"language-plaintext highlighter-rouge\">jupyter</code>, etc. is in <code class=\"language-plaintext highlighter-rouge\">dask</code> but the\n<code class=\"language-plaintext highlighter-rouge\">s3</code> module is within the <code class=\"language-plaintext highlighter-rouge\">distributed</code> library.  We’ll have to merge things\nat some point in the near-to-moderate future.  Ditto for the API: there are\ncompute methods both on the dask collections (<code class=\"language-plaintext highlighter-rouge\">records.compute()</code>) and on\nthe distributed executor (<code class=\"language-plaintext highlighter-rouge\">e.compute(records)</code>) that behave slightly\ndifferently.</p>\n  </li>\n  <li>\n    <p>We lack an efficient distributed shuffle algorithm.  This is very important\nif you want to use operations like <code class=\"language-plaintext highlighter-rouge\">.groupby</code> (which you should avoid\nanyway).  The user API here doesn’t even cleanly warn users that this is\nmissing in the distributed case which is kind of a mess. (It works fine on a\nsingle machine.)  Efficient alternatives like <code class=\"language-plaintext highlighter-rouge\">foldby</code> <em>are</em> available.</p>\n  </li>\n  <li>\n    <p>I would have liked to run this experiment directly on the cluster to see\nhow low we could have gone below the 200ms barrier we ran into here.</p>\n  </li>\n</ul>\n\n<h2 id=\"links\">Links</h2>\n\n<ul>\n  <li><a href=\"https://dask.pydata.org/en/latest/\">dask</a>, the original project</li>\n  <li><a href=\"https://distributed.readthedocs.org/en/latest/\">dask.distributed</a>, the\ndistributed memory scheduler powering the cluster computing</li>\n  <li><a href=\"http://dask.pydata.org/en/latest/bag.html\">dask.bag</a>, the user API we’ve\nused in this post.</li>\n  <li>This post largely repeats work by <a href=\"https://github.com/cowlicks\">Blake Griffith</a> in a\n<a href=\"https://www.continuum.io/content/dask-distributed-and-anaconda-cluster\">similar post</a>\nlast year with an older iteration of the dask distributed scheduler</li>\n</ul>"
}