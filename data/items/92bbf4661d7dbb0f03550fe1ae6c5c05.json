{
  "title": "Maximum a Posteriori Estimation",
  "link": "",
  "updated": "2013-02-25T00:00:00+00:00",
  "id": "https://mrocklin.github.io/blog/work/2013/02/25/MaximumAposteriori",
  "content": "<p><em>Disclaimer:  I know relatively little about this application.  Corrections welcome.</em></p>\n\n<p>In this post we see how SymPy can simplify common numeric calculations, particularly in Bayesian inference problems.</p>\n\n<p>Imagine you are a scientist studying some <a href=\"http://en.wikipedia.org/wiki/Poisson_process\">counting process</a> (like radioactive decay or the number of page requests on a web server).  You describe this process with a <a href=\"http://en.wikipedia.org/wiki/Poisson_distribution\">Poisson random variable</a> and try to learn the rate parameter of this distribution by observing some random samples.</p>\n\n<p>If you have no preconceptions about the rate then this problem is easy.  You just divide total counts by total time and you’re done.</p>\n\n<p>A more complex problem arises when external theory provides prior information\nabout your rate parameter (for example physics might impose rules on the rate\nof radioactive decay).  Lets model this problem in SymPy.  For the sake of\nconcreteness lets arbitrarily assume that $\\lambda$, the rate parameter, follows a Beta distribution with parameters <code class=\"language-plaintext highlighter-rouge\">a</code> and <code class=\"language-plaintext highlighter-rouge\">b</code>.</p>\n\n<figure class=\"highlight\">\n  <pre><code class=\"language-python\" data-lang=\"python\"><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">b</span> <span class=\"o\">=</span> <span class=\"n\">symbols</span><span class=\"p\">(</span><span class=\"s\">'a,b'</span><span class=\"p\">,</span> <span class=\"n\">positive</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">)</span>\n<span class=\"n\">lam</span> <span class=\"o\">=</span> <span class=\"n\">Symbol</span><span class=\"p\">(</span><span class=\"s\">'lambda'</span><span class=\"p\">,</span> <span class=\"n\">positive</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">)</span>\n<span class=\"n\">rate</span> <span class=\"o\">=</span> <span class=\"n\">Beta</span><span class=\"p\">(</span><span class=\"n\">lam</span><span class=\"p\">,</span> <span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">b</span><span class=\"p\">)</span>\n<span class=\"n\">count</span> <span class=\"o\">=</span> <span class=\"n\">Poisson</span><span class=\"p\">(</span><span class=\"s\">'X'</span><span class=\"p\">,</span> <span class=\"n\">rate</span><span class=\"p\">)</span></code></pre>\n</figure>\n\n<p>In the lab we observe many samples $x_i$ taken from <code class=\"language-plaintext highlighter-rouge\">count</code>.  From these we wish to find the most likely value of <code class=\"language-plaintext highlighter-rouge\">rate</code>.  The probability of any single value of <code class=\"language-plaintext highlighter-rouge\">rate</code> given our data can be rewritten with Bayes’ rule.</p>\n\n\\[p(\\lambda \\vert x_i) \\propto \\prod_i p(x_i \\vert \\lambda) \\cdot p(\\lambda)\\]\n\n<p>In this case the distributions are given by</p>\n\n<figure class=\"highlight\">\n  <pre><code class=\"language-python\" data-lang=\"python\"><span class=\"n\">pdf</span> <span class=\"o\">=</span> <span class=\"n\">density</span><span class=\"p\">(</span><span class=\"n\">count</span><span class=\"p\">,</span> <span class=\"n\">rate</span><span class=\"p\">);</span>  <span class=\"k\">print</span> <span class=\"n\">latex</span><span class=\"p\">(</span><span class=\"n\">pdf</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">))</span>  <span class=\"c1\"># density of count, given rate\n</span><span class=\"n\">pdf</span> <span class=\"o\">=</span> <span class=\"n\">density</span><span class=\"p\">(</span><span class=\"n\">rate</span><span class=\"p\">);</span>         <span class=\"k\">print</span> <span class=\"n\">latex</span><span class=\"p\">(</span><span class=\"n\">pdf</span><span class=\"p\">(</span><span class=\"n\">lam</span><span class=\"p\">))</span></code></pre>\n</figure>\n\n\\[p(x_i \\vert \\lambda) = \\frac{\\lambda^{x}}{e^{\\lambda} x!} \\;\\;\\;\\;\np(\\lambda) = \\frac{\\lambda^{a - 1} \\left(- \\lambda + 1\\right)^{b - 1} \\Gamma\\left(a +   b\\right)}{\\Gamma\\left(a\\right) \\Gamma\\left(b\\right)}\\]\n\n<p>To find the maximizer of $p(\\lambda \\vert x_i)$ we set the derivative equal to zero.  We simplify the computation by taking the <code class=\"language-plaintext highlighter-rouge\">log</code>.  Because <code class=\"language-plaintext highlighter-rouge\">log</code> is monotonic this does not change the solution.</p>\n\n\\[0 = \\frac{d}{d\\lambda} \\log\\left( \\prod_i p(x_i \\vert \\lambda) \\cdot                 p(\\lambda)\\right) =\n\\frac{d}{d\\lambda} \\sum_i \\log(p(x_i \\vert \\lambda) \\cdot p(\\lambda))\\]\n\n<p>We can accomplish this in SymPy with the following code</p>\n\n<figure class=\"highlight\">\n  <pre><code class=\"language-python\" data-lang=\"python\"><span class=\"c1\"># Model `n` observations with a function `data` indexed by integer `i`\n</span><span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">n</span> <span class=\"o\">=</span> <span class=\"n\">symbols</span><span class=\"p\">(</span><span class=\"s\">'i,n'</span><span class=\"p\">,</span> <span class=\"n\">integer</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">)</span>\n<span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"n\">Function</span><span class=\"p\">(</span><span class=\"s\">'data'</span><span class=\"p\">)</span></code></pre>\n</figure>\n\n<figure class=\"highlight\">\n  <pre><code class=\"language-python\" data-lang=\"python\"><span class=\"c1\"># Compute log likelihood\n</span><span class=\"n\">loglikelihood</span> <span class=\"o\">=</span> <span class=\"n\">log</span><span class=\"p\">(</span><span class=\"n\">Product</span><span class=\"p\">(</span><span class=\"n\">density</span><span class=\"p\">(</span><span class=\"n\">count</span><span class=\"p\">,</span> <span class=\"n\">rate</span><span class=\"p\">)(</span><span class=\"n\">data</span><span class=\"p\">(</span><span class=\"n\">i</span><span class=\"p\">))</span> <span class=\"o\">*</span> <span class=\"n\">density</span><span class=\"p\">(</span><span class=\"n\">rate</span><span class=\"p\">)(</span><span class=\"n\">lam</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">n</span><span class=\"p\">)))</span>\n<span class=\"n\">Eq</span><span class=\"p\">(</span><span class=\"n\">simplify</span><span class=\"p\">(</span><span class=\"n\">loglikeihood</span><span class=\"p\">.</span><span class=\"n\">diff</span><span class=\"p\">(</span><span class=\"n\">lam</span><span class=\"p\">)),</span> <span class=\"mi\">0</span><span class=\"p\">)</span></code></pre>\n</figure>\n\n\\[\\sum_{i=1}^{n} \\frac{a \\left(\\lambda - 1\\right) + b \\lambda - \\lambda                \\left(\\lambda - 1\\right) - 2 \\lambda + \\left(\\lambda - 1\\right)                         \\operatorname{data}{\\left\\[i \\right\\]} + 1}{\\lambda \\left(\\lambda - 1\\right)} = 0\\]\n\n<h2 id=\"discussion\">Discussion</h2>\n\n<p>SymPy reduces this Bayesian inference problem to finding roots of the above equation.  I suspect that many prevalent numeric problems could be similarly accelerated through a symbolic preprocessing step.</p>\n\n<p>Looking at the equation above it’s clear that this problem can be simplified further.  However I like the existing solution because it does not depend on the user possessing any mathematical expertise beyond the ability to describe their mathematical model (the derivatives, log, etc… are generally applicable to this problem).  In what other automated ways can SymPy further process computations like this?  What are other ways that aren’t in SymPy but could be developed in the future?</p>\n\n<p>I suspect that the problem given here is analytically solvable.  To the extent possible SymPy should try to solve these problems.  However for the vast number of problems without analytic solutions I suspect there is still a great deal we can do, either by reducing the problem as above or through the mathematically informed selection of numeric algorithms.</p>\n\n<p>Various root finding algorithms are appropriate in different cases.  Wikipedia suggests <a href=\"http://en.wikipedia.org/wiki/Householder%27s_method\">Householder’s Method</a>, a generalization on Newton’s method for scalar systems with known derivatives.  Perhaps in cases where SymPy is unable to solve the problem analytically it could select the correct numeric algorithm.  Is this a reasonable use case for SymPy?</p>\n\n<h2 id=\"references\">References</h2>\n\n<ul>\n  <li><a href=\"http://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation\">Maximum A Posteriori Estimation</a></li>\n  <li><a href=\"http://en.wikipedia.org/wiki/Poisson_process\">Poisson process</a></li>\n  <li><a href=\"http://en.wikipedia.org/wiki/Householder%27s_method\">Householder’s Method</a></li>\n</ul>"
}