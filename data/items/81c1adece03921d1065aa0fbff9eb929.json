{
  "id": "tag:blogger.com,1999:blog-9149402429183581490.post-7242256171179291742",
  "published": "2017-04-01T21:59:00.000-07:00",
  "updated": "2018-04-10T09:50:14.276-07:00",
  "title": "Why does Kaggle use Log-loss?",
  "content": "If you're not familiar with <a href=\"https://www.kaggle.com/\" target=\"_blank\">Kaggle</a>, it's an organization dedicated to data science competitions to both provide ways for companies to potentially do analytics at less cost, as well as to identify talented data scientists.<br /><br />Competitions are scored using a variety of functions, and the most common for binary classification tasks with confidence is something called log-loss, which is essentially \\(\\sum_{i=1}^{n} \\log(p_i)\\), where \\(p_i\\) is your model's claimed confidence for test data point \\(i\\)'s correct label. Why does Kaggle use this scoring function? Here I'll follow <a href=\"https://terrytao.wordpress.com/2016/06/01/how-to-assign-partial-credit-on-an-exam-of-true-false-questions/\" target=\"_blank\">Terry Tao's argument</a>.<br /><br />Ideally what we'd like is a scoring function \\(f(x)\\) that yields the maximum expected score precisely when the claimed confidence \\(x_i\\) in the correct label for \\(i\\) is actually what the submitter believes is the true probability (or frequency) of that outcome. This means that we want \\[L(x)=p\\cdot f(x)&nbsp;+ (1-p)\\cdot f(1-x)\\] for fixed \\(p\\) to be maximized when \\(x=p\\). Differentiating, this means \\[L'(x) = p\\cdot f'(x) - (1-p)\\cdot f'(1-x) = 0\\] when \\(x=p\\), hence \\(p\\cdot f'(p) = (1-p)\\cdot f'(1-p)\\) for all \\(p\\). This will be satisfied by any admissible \\(f(x)\\) with \\(x\\cdot f'(x)\\) symmetric around \\(x=\\frac{1}{2}\\), but if we extend our analysis to multinomial outcomes we get the stronger conclusion that in fact \\(x\\cdot f'(x) = c_0\\) for some constant \\(c_0\\). This in turn implies \\(f(x)=c_0\\cdot \\log(x)+c_1\\). If we want \\(f(1/2)=0\\) and \\(f(1)=1\\), we end up with \\(f(x)={\\log}_2(2x)\\) and the expected score is \\[L(x)=x\\cdot {\\log}_2(2x) + (1-x)\\cdot {\\log}_2(2(1-x)).\\]",
  "link": [
    "",
    "",
    "",
    "",
    ""
  ],
  "author": {
    "name": "Christopher D. Long",
    "uri": "http://www.blogger.com/profile/13687149457345266350",
    "email": "noreply@blogger.com",
    "gd:image": ""
  },
  "thr:total": 0
}