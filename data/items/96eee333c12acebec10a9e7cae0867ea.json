{
  "title": "Dask Release 0.18.0",
  "link": "",
  "updated": "2018-06-14T00:00:00+00:00",
  "id": "https://mrocklin.github.io/blog/work/2018/06/14/dask-0.18.0",
  "content": "<p><em>This work is supported by <a href=\"http://anaconda.com\">Anaconda Inc.</a></em></p>\n\n<p>I’m pleased to announce the release of Dask version 0.18.0.  This is a major\nrelease with breaking changes and new features.\nThe last release was 0.17.5 on May 4th.\nThis blogpost outlines notable changes since the last release blogpost for\n0.17.2 on March 21st.</p>\n\n<p>You can conda install Dask:</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>conda install dask\n</code></pre></div></div>\n\n<p>or pip install from PyPI:</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>pip install dask[complete] --upgrade\n</code></pre></div></div>\n\n<p>Full changelogs are available here:</p>\n\n<ul>\n  <li><a href=\"https://github.com/dask/dask/blob/master/docs/source/changelog.rst\">dask/dask</a></li>\n  <li><a href=\"https://github.com/dask/distributed/blob/master/docs/source/changelog.rst\">dask/distributed</a></li>\n</ul>\n\n<p>We list some breaking changes below, followed up by changes that are less\nimportant, but still fun.</p>\n\n<h2 id=\"context\">Context</h2>\n\n<p>The Dask core library is nearing a 1.0 release.\nBefore that happens, we need to do some housecleaning.\nThis release starts that process,\nreplaces some existing interfaces,\nand builds up some needed infrastructure.\nAlmost all of the changes in this release include clean deprecation warnings,\nbut future releases will remove the old functionality, so now would be a good\ntime to check in.</p>\n\n<p>As happens with any release that starts breaking things,\nmany other smaller breaks get added on as well.\nI’m personally very happy with this release because many aspects of using Dask\nnow feel a lot cleaner, however heavy users of Dask will likely experience\nmild friction.  Hopefully this post helps explain some of the larger changes.</p>\n\n<h2 id=\"notable-breaking-changes\">Notable Breaking changes</h2>\n\n<h3 id=\"centralized-configuration\">Centralized configuration</h3>\n\n<p>Taking full advantage of Dask sometimes requires user configuration, especially\nin a distributed setting. This might be to control logging verbosity, specify\ncluster configuration, provide credentials for security, or any of several\nother options that arise in production.</p>\n\n<p>We’ve found that different computing cultures like to specify configuration in\nseveral different ways:</p>\n\n<ol>\n  <li>Configuration files</li>\n  <li>Environment variables</li>\n  <li>Directly within Python code</li>\n</ol>\n\n<p>Previously this was handled with a variety of different solutions among the\ndifferent dask subprojects.  The dask-distributed project had one system,\ndask-kubernetes had another, and so on.</p>\n\n<p>Now we centralize configuration in the <code class=\"language-plaintext highlighter-rouge\">dask.config</code> module, which collects\nconfiguration from config files, environment variables, and runtime code, and\nmakes it centrally available to all Dask subprojects.  A number of Dask\nsubprojects (dask.distributed,\n<a href=\"http://dask-kubernetes.readthedocs.io/en/latest/\">dask-kubernetes</a>, and\n<a href=\"http://dask-jobqueue.readthedocs.io/en/latest/\">dask-jobqueue</a>), are being\nco-released at the same time to take advantage of this.</p>\n\n<p>If you were actively using Dask.distributed’s configuration files some things\nhave changed:</p>\n\n<ol>\n  <li>\n    <p>The configuration is now namespaced and more heavily nested.  Here is an\nexample from the <a href=\"https://github.com/dask/distributed/blob/master/distributed/distributed.yaml\">dask.distributed default config\nfile</a>\ntoday:</p>\n\n    <div class=\"language-yaml highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"na\">distributed</span><span class=\"pi\">:</span>\n  <span class=\"na\">version</span><span class=\"pi\">:</span> <span class=\"m\">2</span>\n  <span class=\"na\">scheduler</span><span class=\"pi\">:</span>\n    <span class=\"na\">allowed-failures</span><span class=\"pi\">:</span> <span class=\"m\">3</span>     <span class=\"c1\"># number of retries before a task is considered bad</span>\n    <span class=\"na\">work-stealing</span><span class=\"pi\">:</span> <span class=\"s\">True</span>     <span class=\"c1\"># workers should steal tasks from each other</span>\n    <span class=\"na\">worker-ttl</span><span class=\"pi\">:</span> <span class=\"no\">null</span>        <span class=\"c1\"># like '60s'. Workers must heartbeat faster than this</span>\n\n  <span class=\"na\">worker</span><span class=\"pi\">:</span>\n    <span class=\"na\">multiprocessing-method</span><span class=\"pi\">:</span> <span class=\"s\">forkserver</span>\n    <span class=\"na\">use-file-locking</span><span class=\"pi\">:</span> <span class=\"s\">True</span>\n</code></pre></div>    </div>\n  </li>\n  <li>\n    <p>The default configuration location has moved from <code class=\"language-plaintext highlighter-rouge\">~/.dask/config.yaml</code> to\n<code class=\"language-plaintext highlighter-rouge\">~/.config/dask/distributed.yaml</code>, where it will live along side several\nother files like <code class=\"language-plaintext highlighter-rouge\">kubernetes.yaml</code>, <code class=\"language-plaintext highlighter-rouge\">jobqueue.yaml</code>, and so on.</p>\n  </li>\n</ol>\n\n<p>However, your old configuration files will still be found and their values\nwill be used appropriately.  We don’t make any attempt to migrate your old\nconfig values to the new location though.  You may want to delete the\nauto-generated <code class=\"language-plaintext highlighter-rouge\">~/.dask/config.yaml</code> file at some point, if you felt like being\nparticularly clean.</p>\n\n<p>You can learn more about Dask’s configuration in <a href=\"http://dask.pydata.org/en/latest/configuration.html\">Dask’s configuration\ndocumentation</a></p>\n\n<h3 id=\"replaced-the-common-get-keyword-with-scheduler\">Replaced the common get= keyword with scheduler=</h3>\n\n<p>Dask can execute code with a variety of scheduler backends based on threads,\nprocesses, single-threaded execution, or distributed clusters.</p>\n\n<p>Previously, users selected between these backends using the somewhat\ngenerically named <code class=\"language-plaintext highlighter-rouge\">get=</code> keyword:</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">x</span><span class=\"p\">.</span><span class=\"n\">compute</span><span class=\"p\">(</span><span class=\"n\">get</span><span class=\"o\">=</span><span class=\"n\">dask</span><span class=\"p\">.</span><span class=\"n\">threaded</span><span class=\"p\">.</span><span class=\"n\">get</span><span class=\"p\">)</span>\n<span class=\"n\">x</span><span class=\"p\">.</span><span class=\"n\">compute</span><span class=\"p\">(</span><span class=\"n\">get</span><span class=\"o\">=</span><span class=\"n\">dask</span><span class=\"p\">.</span><span class=\"n\">multiprocessing</span><span class=\"p\">.</span><span class=\"n\">get</span><span class=\"p\">)</span>\n<span class=\"n\">x</span><span class=\"p\">.</span><span class=\"n\">compute</span><span class=\"p\">(</span><span class=\"n\">get</span><span class=\"o\">=</span><span class=\"n\">dask</span><span class=\"p\">.</span><span class=\"n\">local</span><span class=\"p\">.</span><span class=\"n\">get_sync</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p>We’ve replaced this with a newer, and hopefully more clear, <code class=\"language-plaintext highlighter-rouge\">scheduler=</code> keyword:</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">x</span><span class=\"p\">.</span><span class=\"n\">compute</span><span class=\"p\">(</span><span class=\"n\">scheduler</span><span class=\"o\">=</span><span class=\"s\">'threads'</span><span class=\"p\">)</span>\n<span class=\"n\">x</span><span class=\"p\">.</span><span class=\"n\">compute</span><span class=\"p\">(</span><span class=\"n\">scheduler</span><span class=\"o\">=</span><span class=\"s\">'processes'</span><span class=\"p\">)</span>\n<span class=\"n\">x</span><span class=\"p\">.</span><span class=\"n\">compute</span><span class=\"p\">(</span><span class=\"n\">scheduler</span><span class=\"o\">=</span><span class=\"s\">'single-threaded'</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p>The <code class=\"language-plaintext highlighter-rouge\">get=</code> keyword has been deprecated and will raise a warning.  It will be\nremoved entirely on the next major release.</p>\n\n<p>For more information, see <a href=\"http://dask.pydata.org/en/latest/scheduling.html\">documentation on selecting different schedulers</a>.</p>\n\n<h3 id=\"replaced-daskset_options-with-daskconfigset\">Replaced dask.set_options with dask.config.set</h3>\n\n<p>Related to the configuration changes, we now include runtime state in the\nconfiguration.  Previously people used to set runtime state with the\n<code class=\"language-plaintext highlighter-rouge\">dask.set_options</code> context manager.  Now we recommend using <code class=\"language-plaintext highlighter-rouge\">dask.config.set</code>:</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">with</span> <span class=\"n\">dask</span><span class=\"p\">.</span><span class=\"n\">set_options</span><span class=\"p\">(</span><span class=\"n\">scheduler</span><span class=\"o\">=</span><span class=\"s\">'threads'</span><span class=\"p\">):</span>  <span class=\"c1\"># Before\n</span>    <span class=\"p\">...</span>\n\n<span class=\"k\">with</span> <span class=\"n\">dask</span><span class=\"p\">.</span><span class=\"n\">config</span><span class=\"p\">.</span><span class=\"nb\">set</span><span class=\"p\">(</span><span class=\"n\">scheduler</span><span class=\"o\">=</span><span class=\"s\">'threads'</span><span class=\"p\">):</span>  <span class=\"c1\"># After\n</span>    <span class=\"p\">...</span>\n</code></pre></div></div>\n\n<p>The <code class=\"language-plaintext highlighter-rouge\">dask.set_options</code> function is now an alias to <code class=\"language-plaintext highlighter-rouge\">dask.config.set</code>.</p>\n\n<h3 id=\"removed-the-daskarraylearn-subpackage\">Removed the dask.array.learn subpackage</h3>\n\n<p>This was unadvertised and saw very little use.  All functionality (and much\nmore) is now available in <a href=\"http://dask-ml.readthedocs.io/en/latest/\">Dask-ML</a>.</p>\n\n<h3 id=\"other\">Other</h3>\n\n<ul>\n  <li>We’ve removed the <code class=\"language-plaintext highlighter-rouge\">token=</code> keyword from map_blocks and moved the\nfunctionality to the <code class=\"language-plaintext highlighter-rouge\">name=</code> keyword.</li>\n  <li>The <code class=\"language-plaintext highlighter-rouge\">dask.distributed.worker_client</code> automatically rejoins the threadpool when\nyou close the context manager.</li>\n  <li>The Dask.distributed protocol now interprets msgpack arrays as tuples\nrather than lists.</li>\n</ul>\n\n<h2 id=\"fun-new-features\">Fun new features</h2>\n\n<h3 id=\"arrays\">Arrays</h3>\n\n<h4 id=\"generalized-universal-functions\">Generalized Universal Functions</h4>\n\n<p>Dask.array now supports Numpy-style\n<a href=\"https://docs.scipy.org/doc/numpy-1.13.0/reference/c-api.generalized-ufuncs.html\">Generalized Universal Functions (gufuncs)</a>\ntransparently.\nThis means that you can apply normal Numpy GUFuncs, like <code class=\"language-plaintext highlighter-rouge\">eig</code> in the example\nbelow, directly onto a Dask arrays:</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">import</span> <span class=\"nn\">dask.array</span> <span class=\"k\">as</span> <span class=\"n\">da</span>\n<span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"n\">np</span>\n\n<span class=\"c1\"># Apply a Numpy GUFunc, eig, directly onto a Dask array\n</span><span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">da</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">.</span><span class=\"n\">normal</span><span class=\"p\">(</span><span class=\"n\">size</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">),</span> <span class=\"n\">chunks</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">))</span>\n<span class=\"n\">w</span><span class=\"p\">,</span> <span class=\"n\">v</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">linalg</span><span class=\"p\">.</span><span class=\"n\">_umath_linalg</span><span class=\"p\">.</span><span class=\"n\">eig</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">output_dtypes</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"nb\">float</span><span class=\"p\">,</span> <span class=\"nb\">float</span><span class=\"p\">))</span>\n<span class=\"c1\"># w and v are dask arrays with eig applied along the latter two axes\n</span></code></pre></div></div>\n\n<p>Numpy has gufuncs of many of its internal functions, but they haven’t\nyet decided to switch these out to the public API.\nAdditionally we can define GUFuncs with other projects, like Numba:</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">import</span> <span class=\"nn\">numba</span>\n\n<span class=\"o\">@</span><span class=\"n\">numba</span><span class=\"p\">.</span><span class=\"n\">vectorize</span><span class=\"p\">([</span><span class=\"n\">float64</span><span class=\"p\">(</span><span class=\"n\">float64</span><span class=\"p\">,</span> <span class=\"n\">float64</span><span class=\"p\">)])</span>\n<span class=\"k\">def</span> <span class=\"nf\">f</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">):</span>\n    <span class=\"k\">return</span> <span class=\"n\">x</span> <span class=\"o\">+</span> <span class=\"n\">y</span>\n\n<span class=\"n\">z</span> <span class=\"o\">=</span> <span class=\"n\">f</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">)</span>  <span class=\"c1\"># if x and y are dask arrays, then z will be too\n</span></code></pre></div></div>\n\n<p>What I like about this is that Dask and Numba developers didn’t coordinate\nat all on this feature, it’s just that they both support the Numpy GUFunc\nprotocol, so you get interactions like this for free.</p>\n\n<p>For more information see <a href=\"http://dask.pydata.org/en/latest/array-gufunc.html\">Dask’s GUFunc documentation</a>.  This work was done by <a href=\"https://github.com/magonser\">Markus Gonser (@magonser)</a>.</p>\n\n<h4 id=\"new-auto-value-for-rechunking\">New “auto” value for rechunking</h4>\n\n<p>Dask arrays now accept a value, “auto”, wherever a chunk value would previously\nbe accepted.  This asks Dask to rechunk those dimensions to achieve a good\ndefault chunk size.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">x</span><span class=\"p\">.</span><span class=\"n\">rechunk</span><span class=\"p\">({</span>\n    <span class=\"mi\">0</span><span class=\"p\">:</span> <span class=\"n\">x</span><span class=\"p\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">],</span> <span class=\"c1\"># single chunk in this dimension\n</span>  <span class=\"c1\"># 1: 100e6 / x.dtype.itemsize / x.shape[0],  # before we had to calculate manually\n</span>    <span class=\"mi\">1</span><span class=\"p\">:</span> <span class=\"s\">'auto'</span>      <span class=\"c1\"># Now we allow this dimension to respond to get ideal chunk size\n</span><span class=\"p\">})</span>\n\n<span class=\"c1\"># or\n</span><span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">da</span><span class=\"p\">.</span><span class=\"n\">from_array</span><span class=\"p\">(</span><span class=\"n\">img</span><span class=\"p\">,</span> <span class=\"n\">chunks</span><span class=\"o\">=</span><span class=\"s\">'auto'</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p>This also checks the <code class=\"language-plaintext highlighter-rouge\">array.chunk-size</code> config value for optimal chunk sizes</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">dask</span><span class=\"p\">.</span><span class=\"n\">config</span><span class=\"p\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s\">'array.chunk-size'</span><span class=\"p\">)</span>\n<span class=\"s\">'128MiB'</span>\n</code></pre></div></div>\n\n<p>To be clear, this doesn’t support “automatic chunking”, which is a very hard\nproblem in general.  Users still need to be aware of their computations and how\nthey want to chunk, this just makes it marginally easier to make good\ndecisions.</p>\n\n<h4 id=\"algorithmic-improvements\">Algorithmic improvements</h4>\n\n<p>Dask.array gained a full <a href=\"http://dask.pydata.org/en/latest/array-api.html#dask.array.einsum\">einsum</a> implementation thanks to <a href=\"https://github.com/sjperkins\">Simon Perkins</a>.</p>\n\n<p>Also, Dask.array’s QR decompositions has become nicer in two ways:</p>\n\n<ol>\n  <li>They support <a href=\"http://dask.pydata.org/en/latest/array-api.html#dask.array.linalg.sfqr\">short-and-fat arrays</a></li>\n  <li>\n    <p>The <a href=\"http://dask.pydata.org/en/latest/array-api.html#dask.array.linalg.tsqr\">tall-and-skinny</a>\nvariant now operates more robustly in less memory.  Here is a friendly GIF\nof execution:</p>\n\n    <p><img src=\"https://user-images.githubusercontent.com/306380/41350133-175cac7e-6ee0-11e8-9a0e-785c6e846409.gif\" width=\"40%\" /></p>\n  </li>\n</ol>\n\n<p>This work is greatly appreciated and was done by <a href=\"https://github.com/convexset\">Jeremy Chan</a>.</p>\n\n<p>Native support for the <a href=\"http://zarr.readthedocs.io/en/stable/\">Zarr format</a> for\nchunked n-dimensional arrays landed thanks to <a href=\"https://github.com/martindurant\">Martin\nDurant</a> and <a href=\"https://github.com/jakirkham\">John A\nKirkham</a>.  Zarr has been especially useful due to\nits speed, simple spec, support of the full NetCDF style conventions, and\namenability to cloud storage.</p>\n\n<h3 id=\"dataframes-and-pandas-023\">Dataframes and Pandas 0.23</h3>\n\n<p>As usual, Dask Dataframes had many small improvements.  Of note is continued\ncompatibility with the just-released Pandas 0.23, and some new data ingestion\nformats.</p>\n\n<p>Dask.dataframe is consistent with changes in the recent Pandas 0.23 release\nthanks to <a href=\"https://github.com/TomAugspurger\">Tom Augspurger</a>.</p>\n\n<h4 id=\"orc-support\">Orc support</h4>\n\n<p>Dask.dataframe has grown a reader for the <a href=\"https://orc.apache.org/\">Apache ORC</a> format.</p>\n\n<p>Orc is a format for tabular data storage that is common in the Hadoop ecosystem.\nThe new\n<a href=\"http://dask.pydata.org/en/latest/dataframe-api.html#dask.dataframe.read_hdf\">dd.read_orc</a>\nfunction parallelizes around similarly new ORC functionality within PyArrow .\nThanks to <a href=\"https://github.com/jcrist\">Jim Crist</a> for the work on the Arrow side\nand <a href=\"https://github.com/martindurant\">Martin Durant</a> for parallelizing it with\nDask.</p>\n\n<h4 id=\"read_json-support\">Read_json support</h4>\n\n<p>Dask.dataframe now has also grown a reader for JSON files.</p>\n\n<p>The <a href=\"http://dask.pydata.org/en/latest/dataframe-api.html#dask.dataframe.read_json\">dd.read_json</a>\nfunction matches most of the <code class=\"language-plaintext highlighter-rouge\">pandas.read_json</code> API.</p>\n\n<p>This came about shortly after a recent <a href=\"https://www.youtube.com/watch?v=X4YHGKj3V5M\">PyCon 2018 talk comparing Spark and\nDask dataframe</a> where <a href=\"https://github.com/j-bennet\">Irina\nTruong</a> mentioned that it was missing.  Thanks to\n<a href=\"https://github.com/martindurant\">Martin Durant</a> and <a href=\"https://github.com/j-bennet\">Irina\nTruong</a> for this contribution.</p>\n\n<p>See the <a href=\"http://dask.pydata.org/en/latest/dataframe-create.html\">dataframe data ingestion documentation</a>\nfor more information about JSON, ORC, or any of the other formats\nsupported by Dask.dataframe.</p>\n\n<h3 id=\"joblib\">Joblib</h3>\n\n<p>The <a href=\"https://pythonhosted.org/joblib/\">Joblib</a> library for parallel computing within\nScikit-Learn has had a <a href=\"http://dask-ml.readthedocs.io/en/latest/joblib.html\">Dask backend</a>\nfor a while now.  While it has always been pretty easy to use, it’s now\nbecoming much easier to use well without much expertise.  After using this in\npractice for a while together with the Scikit-Learn developers, we’ve\nidentified and smoothed over a number of usability issues.  These changes will\nonly be fully available after the next Scikit-Learn release (hopefully soon) at\nwhich point we’ll probably release a new blogpost dedicated to the topic.</p>\n\n<h2 id=\"related-projects\">Related projects</h2>\n\n<p>This release is timed with the following packages:</p>\n\n<ol>\n  <li>dask</li>\n  <li>distributed</li>\n  <li>dask-kubernetes</li>\n</ol>\n\n<p>There is also a new repository for deploying applications on YARN (a job\nscheduler common in Hadoop environments) called\n<a href=\"https://jcrist.github.io/skein/\">skein</a>.  Early adopters welcome.</p>\n\n<h2 id=\"acknowledgements\">Acknowledgements</h2>\n\n<p>Since March 21st, the following people have contributed to the following repositories:</p>\n\n<p>The core Dask repository for parallel algorithms:</p>\n\n<ul>\n  <li>Andrethrill</li>\n  <li>Beomi</li>\n  <li>Brendan Martin</li>\n  <li>Christopher Ren</li>\n  <li>Guido Imperiale</li>\n  <li>Diane Trout</li>\n  <li>fjetter</li>\n  <li>Frederick</li>\n  <li>Henry Doupe</li>\n  <li>James Bourbeau</li>\n  <li>Jeremy Chen</li>\n  <li>Jim Crist</li>\n  <li>John A Kirkham</li>\n  <li>Jon Mease</li>\n  <li>Jörg Dietrich</li>\n  <li>Kevin Mader</li>\n  <li>Ksenia Bobrova</li>\n  <li>Larsr</li>\n  <li>Marc Pfister</li>\n  <li>Markus Gonser</li>\n  <li>Martin Durant</li>\n  <li>Matt Lee</li>\n  <li>Matthew Rocklin</li>\n  <li>Pierre-Bartet</li>\n  <li>Scott Sievert</li>\n  <li>Simon Perkins</li>\n  <li>Stefan van der Walt</li>\n  <li>Stephan Hoyer</li>\n  <li>Tom Augspurger</li>\n  <li>Uwe L. Korn</li>\n  <li>Yu Feng</li>\n</ul>\n\n<p>The dask/distributed repository for distributed computing:</p>\n\n<ul>\n  <li>Bmaisonn</li>\n  <li>Grant Jenks</li>\n  <li>Henry Doupe</li>\n  <li>Irene Rodriguez</li>\n  <li>Irina Truong</li>\n  <li>John A Kirkham</li>\n  <li>Joseph Atkins-Turkish</li>\n  <li>Kenneth Koski</li>\n  <li>Loïc Estève</li>\n  <li>Marius van Niekerk</li>\n  <li>Martin Durant</li>\n  <li>Matthew Rocklin</li>\n  <li>Olivier Grisel</li>\n  <li>Russ Bubley</li>\n  <li>Tom Augspurger</li>\n  <li>Tony Lorenzo</li>\n</ul>\n\n<p>The dask-kubernetes repository for deploying Dask on Kubernetes</p>\n\n<ul>\n  <li>Brendan Martin</li>\n  <li>J Gerard</li>\n  <li>Matthew Rocklin</li>\n  <li>Olivier Grisel</li>\n  <li>Yuvi Panda</li>\n</ul>\n\n<p>The dask-jobqueue repository for deploying Dask on HPC job schedulers</p>\n\n<ul>\n  <li>Guillaume Eynard-Bontemps</li>\n  <li>jgerardsimcock</li>\n  <li>Joseph Hamman</li>\n  <li>Loïc Estève</li>\n  <li>Matthew Rocklin</li>\n  <li>Ray Bell</li>\n  <li>Rich Signell</li>\n  <li>Shawn Taylor</li>\n  <li>Spencer Clark</li>\n</ul>\n\n<p>The dask-ml repository for scalable machine learning:</p>\n\n<ul>\n  <li>Christopher Ren</li>\n  <li>Jeremy Chen</li>\n  <li>Matthew Rocklin</li>\n  <li>Scott Sievert</li>\n  <li>Tom Augspurger</li>\n</ul>\n\n<h3 id=\"acknowledgements-1\">Acknowledgements</h3>\n\n<p>Thanks to Scott Sievert and James Bourbeau for their help editing this article.</p>"
}