{
  "title": "PromptEHR: Conditional Electronic Healthcare Records Generation with Prompt Learning. (arXiv:2211.01761v1 [cs.CL])",
  "link": "http://arxiv.org/abs/2211.01761",
  "description": "<p>Accessing longitudinal multimodal Electronic Healthcare Records (EHRs) is\nchallenging due to privacy concerns, which hinders the use of ML for healthcare\napplications. Synthetic EHRs generation bypasses the need to share sensitive\nreal patient records. However, existing methods generate single-modal EHRs by\nunconditional generation or by longitudinal inference, which falls short of low\nflexibility and makes unrealistic EHRs. In this work, we propose to formulate\nEHRs generation as a text-to-text translation task by language models (LMs),\nwhich suffices to highly flexible event imputation during generation. We also\ndesign prompt learning to control the generation conditioned by numerical and\ncategorical demographic features. We evaluate synthetic EHRs quality by two\nperplexity measures accounting for their longitudinal pattern (longitudinal\nimputation perplexity, lpl) and the connections cross modalities\n(cross-modality imputation perplexity, mpl). Moreover, we utilize two\nadversaries: membership and attribute inference attacks for privacy-preserving\nevaluation. Experiments on MIMIC-III data demonstrate the superiority of our\nmethods on realistic EHRs generation (53.1\\% decrease of lpl and 45.3\\%\ndecrease of mpl on average compared to the best baselines) with low privacy\nrisks. Software is available at https://github.com/RyanWangZf/PromptEHR.\n</p>",
  "dc:creator": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zifeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jimeng Sun</a>"
}