{
  "title": "M-SpeechCLIP: Leveraging Large-Scale, Pre-Trained Models for Multilingual Speech to Image Retrieval. (arXiv:2211.01180v1 [cs.CL] CROSS LISTED)",
  "link": "http://arxiv.org/abs/2211.01180",
  "description": "<p>This work investigates the use of large-scale, pre-trained models (CLIP and\nHuBERT) for multilingual speech-image retrieval. For non-English speech-image\nretrieval, we outperform the current state-of-the-art performance by a wide\nmargin when training separate models for each language, and show that a single\nmodel which processes speech in all three languages still achieves retrieval\nscores comparable with the prior state-of-the-art. We identify key differences\nin model behavior and performance between English and non-English settings,\npresumably attributable to the English-only pre-training of CLIP and HuBERT.\nFinally, we show that our models can be used for mono- and cross-lingual\nspeech-text retrieval and cross-lingual speech-speech retrieval, despite never\nhaving seen any parallel speech-text or speech-speech data during training.\n</p>",
  "dc:creator": "<a href=\"http://arxiv.org/find/cs/1/au:+Berry_L/0/1/0/all/0/1\">Layne Berry</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shih_Y/0/1/0/all/0/1\">Yi-Jen Shih</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hsuan-Fu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_H/0/1/0/all/0/1\">Heng-Jui Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hung-yi Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harwath_D/0/1/0/all/0/1\">David Harwath</a>"
}