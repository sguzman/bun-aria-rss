{
  "id": "tag:blogger.com,1999:blog-8474926331452026626.post-4407074621491257938",
  "published": "2022-10-22T20:30:00.004-07:00",
  "updated": "2022-10-24T08:40:18.077-07:00",
  "category": [
    "",
    "",
    ""
  ],
  "title": "Google at ECCV 2022",
  "content": "<span class=\"byline-author\">Posted by Shaina Mehta, Program Manager, Google</span> <img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhWmLScVcpCyi8puS5FYC4xNN88CWeK0-77JiMlowYPlxCPym5T4zX7iKIuzIjwtDnUubUJ0yM8Xa6Mt83N_-YoBgyrZH_dwSL6YgoxUEgGf1tNuR5fSWeRY61Ut0TOhlzUuTJlKs6fyBF3JTVzAlbEOUgtGb_5gdgFBIXWFCJ0utT8kuUh3rKIjw4L1g/s2880/about_hero.png\" style=\"display: none;\" /> <p>Google is proud to be a <a href=\"https://eccv2022.ecva.net/sponsors/\">Platinum Sponsor</a> of the <a href=\"https://eccv2022.ecva.net/\">European Conference on Computer Vision</a> (ECCV 2022), a premier forum for the dissemination of research in computer vision and machine learning (ML). This year, ECCV 2022 will be held as a hybrid event, in person in Tel Aviv, Israel with virtual attendance as an option. Google has a strong presence at this year’s conference with over 60 accepted publications and active involvement in a number of workshops and tutorials. We look forward to sharing some of our extensive research and expanding our partnership with the broader ML research community.&nbsp;</p><a name='more'></a>  <p>Registered for ECCV 2022? We hope you’ll visit our on-site or virtual booths to learn more about the research we’re presenting at ECCV 2022, including several demos and opportunities to connect with our researchers. Learn more about Google's research being presented at ECCV 2022 below (Google affiliations in <b>bold</b>). </p><div style=\"line-height: 40%;\">    <br /></div><h2>Organizing Committee</h2><p> </p><p>Program Chairs include:<b> <i>Moustapha Cissé</i></b></p> <p>Awards Paper Committee:<b> <i>Todd Zickler</i></b></p> <p>Area Chairs include:<b> <i>Ayan Chakrabarti</i></b>,<b> <i>Tali Dekel</i></b>, <b><i>Alireza Fathi</i></b>, <b><i>Vittorio Ferrari</i></b>,<b> <i>David Fleet</i>, <i>Dilip Krishnan</i></b>, <b><i>Michael Rubinstein</i></b>,<b> <i>Cordelia Schmid</i></b>,<b> <i>Deqing Sun</i></b>, <b><i>Federico Tombari</i></b>,<b> <i>Jasper Uijlings</i></b>, <b><i>Ming-Hsuan Yang</i></b>,<b> T<i>odd Zickler</i></b></p><div style=\"line-height: 40%;\">    <br /></div><h2>Accepted Publications</h2><p><a href=\"https://arxiv.org/pdf/2207.11911.pdf\">NeuMesh: Learning Disentangled Neural Mesh-Based Implicit Field for Geometry and Texture Editing</a><br />Bangbang Yang, Chong Bao, Junyi Zeng, Hujun Bao, <b><i>Yinda Zhang</i></b>, Zhaopeng Cui, Guofeng Zhang </p> <p><a href=\"https://arxiv.org/pdf/2109.09023.pdf\">Anti-Neuron Watermarking: Protecting Personal Data Against Unauthorized Neural Networks</a><br />Zihang Zou, <b><i>Boqing Gong</i></b>, Liqiang Wang </p> <p><a href=\"https://arxiv.org/pdf/2207.08954.pdf\">Exploiting Unlabeled Data with Vision and Language Models for Object Detection</a><br />Shiyu Zhao, Zhixing Zhang, Samuel Schulter, <b><i>Long Zhao</i></b>, Vijay Kumar B G, Anastasis Stathopoulos, Manmohan Chandraker, Dimitris N. Metaxas </p> <p><a href=\"https://arxiv.org/pdf/2206.07704.pdf\">Waymo Open Dataset: Panoramic Video Panoptic Segmentation</a><br />Jieru Mei, Alex Zhu, Xinchen Yan, Hang Yan, <b><i>Siyuan Qiao</i></b>, Yukun Zhu, <b><i>Liang-Chieh Chen</i></b>, Henrik Kretzschmar </p> <p><a href=\"https://arxiv.org/pdf/2208.06143.pdf\">PRIF: Primary Ray-Based Implicit Function</a><br />Brandon Yushan Feng, <b><i>Yinda Zhang</i></b>, <b><i>Danhang Tang</i></b>, <b><i>Ruofei Du</i></b>, Amitabh Varshney </p>  <p><a href=\"https://arxiv.org/pdf/2208.08622.pdf\">LoRD: Local 4D Implicit Representation for High-Fidelity Dynamic Human Modeling</a><br />Boyan Jiang, Xinlin Ren, <b><i>Mingsong Dou</i></b>, Xiangyang Xue, Yanwei Fu, <b><i>Yinda Zhang</i></b></p>  <p><a href=\"https://arxiv.org/pdf/2207.04044.pdf\">k-Means Mask Transformer</a> (see <a href=\"https://ai.googleblog.com/2022/07/revisiting-mask-transformer-from.html\">blog post</a>) <br />Qihang Yu<a href=\"#1\" name=\"top1\"><span class=\"Apple-style-span\" style=\"font-size: small;\"><sup>*</sup></span></a>, <b><i>Siyuan Qiao</i></b>, <b><i>Maxwell D Collins</i></b>, <b><i>Yukun Zhu</i></b>, <b><i>Hartwig Adam</i></b>, Alan Yuille, <b><i>Liang-Chieh Chen</i></b></p>  <p><a href=\"https://arxiv.org/pdf/2204.01697.pdf\">MaxViT: Multi-Axis Vision Transformer</a> (see <a href=\"https://ai.googleblog.com/2022/09/a-multi-axis-approach-for-vision.html\">blog post</a>) <br /><b><i>Zhengzhong Tu</i></b>, <b><i>Hossein Talebi</i></b>, <b><i>Han Zhang</i></b>, <b><i>Feng Yang</i></b>, <b><i>Peyman Milanfar</i></b>, <b><i>Alan Bovik</i></b>,<b> <i>Yinxiao Li</i></b></p>  <p><a href=\"https://arxiv.org/pdf/2207.10008.pdf\">E-Graph: Minimal Solution for Rigid Rotation with Extensibility Graphs</a><br />Yanyan Li, <b><i>Federico Tombari</i></b></p>  <p><a href=\"https://arxiv.org/pdf/2208.00237.pdf\">RBP-Pose: Residual Bounding Box Projection for Category-Level Pose Estimation</a><br />Ruida Zhang, Yan Di, Zhiqiang Lou, <b><i>Fabian Manhardt</i></b>, <b><i>Federico Tombari</i></b>, Xiangyang Ji </p>  <p><a href=\"https://arxiv.org/pdf/2207.10158.pdf\">GOCA: Guided Online Cluster Assignment for Self-Supervised Video Representation Learning</a><br />Huseyin Coskun, Alireza Zareian, Joshua L Moore, <b><i>Federico Tombari</i></b>, Chen Wang </p>  <p><a href=\"https://arxiv.org/pdf/2112.12143.pdf\">Scaling Open-Vocabulary Image Segmentation with Image-Level Labels</a><br /><b><i>Golnaz Ghiasi</i></b>, <b><i>Xiuye Gu</i></b>, <b><i>Yin Cui</i></b>, Tsung-Yi Lin<a href=\"#1\" name=\"top1\"><span class=\"Apple-style-span\" style=\"font-size: small;\"><sup>*</sup></span></a></p>  <p><a href=\"https://arxiv.org/pdf/2203.12175.pdf\">Adaptive Transformers for Robust Few-Shot Cross-Domain Face Anti-spoofing</a><br /><b><i>Hsin-Ping Huang</i></b>, <b><i>Deqing Sun</i></b>, <b><i>Yaojie Liu</i></b>, <b><i>Wen-Sheng Chu</i></b>, <b><i>Taihong Xiao</i></b>, <b><i>Jinwei Yuan</i></b>, <b><i>Hartwig Adam</i></b>, <b><i>Ming-Hsuan Yang</i></b></p>  <p><a href=\"https://arxiv.org/pdf/2204.04799.pdf\">DualPrompt: Complementary Prompting for Rehearsal-Free Continual Learning</a><br />Zifeng Wang<a href=\"#1\" name=\"top1\"><span class=\"Apple-style-span\" style=\"font-size: small;\"><sup>*</sup></span></a>, <b><i>Zizhao Zhang</i></b>, <b><i>Sayna Ebrahimi</i></b>, <b><i>Ruoxi Sun</i></b>, <b><i>Han Zhang</i></b>, <b><i>Chen-Yu Lee</i></b>, <b><i>Xiaoqi Ren</i></b>, <b><i>Guolong Su</i></b>, <b><i>Vincent Perot</i></b>, Jennifer Dy, <b><i>Tomas Pfister</i></b></p>  <p><a href=\"https://arxiv.org/pdf/2112.05112.pdf\">BLT: Bidirectional Layout Transformer for Controllable Layout Generation</a><br />Xiang Kong, <b><i>Lu Jiang</i></b>, <b><i>Huiwen Chang</i></b>, <b><i>Han Zhang</i></b>, <b><i>Yuan Hao</i></b>, <b><i>Haifeng Gong</i></b>, <b><i>Irfan Essa</i></b></p>  <p><a href=\"https://arxiv.org/pdf/2203.10638.pdf\">V2X-ViT: Vehicle-to-Everything Cooperative Perception with Vision Transformer</a><br />Runsheng Xu, Hao Xiang, Zhengzhong Tu, Xin Xia, <b><i>Ming-Hsuan Yang</i></b>, Jiaqi Ma </p>  <p><a href=\"https://arxiv.org/pdf/2208.10652.pdf\">Learning Visibility for Robust Dense Human Body Estimation</a><br />Chun-Han Yao, Jimei Yang, Duygu Ceylan, Yi Zhou, Yang Zhou, <b><i>Ming-Hsuan Yang</i></b></p>  <p><a href=\"https://arxiv.org/pdf/2111.10659.pdf\">Are Vision Transformers Robust to Patch Perturbations?</a><br />Jindong Gu, Volker Tresp, <b>Yao Qin</b></p>   <p><a href=\"https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136910542.pdf\">PseudoAugment: Learning to Use Unlabeled Data for Data Augmentation in Point Clouds</a><br />Zhaoqi Leng, Shuyang Cheng, <b><i>Ben Caine</i></b>, Weiyue Wang, Xiao Zhang, <b><i>Jonathon Shlens</i></b>, Mingxing Tan, Dragomir Anguelov </p>  <p><a href=\"https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136930020.pdf\">Structure and Motion from Casual Videos</a><br />Zhoutong Zhang, <b><i>Forrester Cole</i></b>, <b><i>Zhengqi Li</i></b>, <b><i>Noah Snavely</i></b>, <b><i>Michael Rubinstein</i></b>, <b><i>William T. Freeman</i></b></p>  <p><a href=\"https://arxiv.org/pdf/2204.10435.pdf\">PreTraM: Self-Supervised Pre-training via Connecting Trajectory and Map</a><br />Chenfeng Xu, Tian Li, Chen Tang, Lingfeng Sun, Kurt Keutzer, Masayoshi Tomizuka, <b><i>Alireza Fathi</i></b>, Wei Zhan </p>  <p><a href=\"https://arxiv.org/pdf/2207.10659.pdf\">Novel Class Discovery Without Forgetting</a><br /><b><i>Joseph K J</i></b>, <b><i>Sujoy Paul</i></b>, <b><i>Gaurav Aggarwal</i></b>, <b><i>Soma Biswas</i></b>, <b><i>Piyush Rai</i></b>, <b><i>Kai Han</i></b>, <b><i>Vineeth N Balasubramanian</i></b></p>  <p><a href=\"https://arxiv.org/pdf/2207.09644.pdf\">Hierarchically Self-Supervised Transformer for Human Skeleton Representation Learning</a><br />Yuxiao Chen, <b><i>Long Zhao</i></b>, Jianbo Yuan, Yu Tian, Zhaoyang Xia, Shijie Geng, Ligong Han, Dimitris N. Metaxas </p>  <p><a href=\"https://arxiv.org/pdf/2203.05126.pdf\">PACTran: PAC-Bayesian Metrics for Estimating the Transferability of Pretrained Models to Classification Tasks</a><br /><b><i>Nan Ding</i></b>, <b><i>Xi Chen</i></b>, <b><i>Tomer Levinboim</i></b>, <b><i>Soravit Changpinyo</i></b>, <b><i>Radu Soricut</i></b></p>  <p><a href=\"https://infinite-nature-zero.github.io/\">InfiniteNature-Zero: Learning Perpetual View Generation of Natural Scenes from Single Images</a><br /><b><i>Zhengqi Li</i></b>, Qianqian Wang<a href=\"#1\" name=\"top1\"><span class=\"Apple-style-span\" style=\"font-size: small;\"><sup>*</sup></span></a>, <b><i>Noah Snavely</i></b>, Angjoo Kanazawa<a href=\"#1\" name=\"top1\"><span class=\"Apple-style-span\" style=\"font-size: small;\"><sup>*</sup></span></a>  </p>  <p><a href=\"https://arxiv.org/pdf/2207.10662.pdf\">Generalizable Patch-Based Neural Rendering</a> (see <a href=\"https://ai.googleblog.com/2022/09/view-synthesis-with-transformers.html\">blog post</a>) <br />Mohammed Suhail<a href=\"#1\" name=\"top1\"><span class=\"Apple-style-span\" style=\"font-size: small;\"><sup>*</sup></span></a>, <b><i>Carlos Esteves</i></b>, Leonid Sigal, <b><i>Ameesh Makadia</i></b></p>  <p><a href=\"https://cseweb.ucsd.edu/~mil070/projects/ECCV2022/paper.pdf\">LESS: Label-Efficient Semantic Segmentation for LiDAR Point Clouds</a><br />Minghua Liu, Yin Zhou, Charles R. Qi, <b><i>Boqing Gong</i></b>, Hao Su, Dragomir Anguelov </p>  <p><a href=\"https://arxiv.org/pdf/2206.04453.pdf\">The Missing Link: Finding Label Relations Across Datasets</a><br /><b><i>Jasper Uijlings</i></b>, <b><i>Thomas Mensink</i></b>, <b><i>Vittorio Ferrari</i></b></p>  <p><a href=\"https://arxiv.org/pdf/2203.16530.pdf\">Learning Instance-Specific Adaptation for Cross-Domain Segmentation</a><br />Yuliang Zou, <b><i>Zizhao Zhang</i></b>, <b><i>Chun-Liang Li</i></b>, <b><i>Han Zhang</i></b>, <b><i>Tomas Pfister</i></b>, Jia-Bin Huang </p>  <p><a href=\"https://arxiv.org/pdf/2204.00679v1.pdf\">Learning Audio-Video Modalities from Image Captions</a><br /><b><i>Arsha Nagrani</i></b>, <b><i>Paul Hongsuck Seo</i></b>, <b><i>Bryan Seybold</i></b>, <b><i>Anja Hauth</i></b>,<b> <i>Santiago Manen</i></b>, <b><i>Chen Sun</i></b>, <b><i>Cordelia Schmid</i></b></p>  <p><a href=\"https://arxiv.org/pdf/2208.06773.pdf\">TL;DW? Summarizing Instructional Videos with Task Relevance &amp; Cross-Modal Saliency</a><br />Medhini Narasimhan<a href=\"#1\" name=\"top1\"><span class=\"Apple-style-span\" style=\"font-size: small;\"><sup>*</sup></span></a>, <b><i>Arsha Nagrani</i></b>, <b><i>Chen Sun</i></b>, <b><i>Michael Rubinstein</i></b>, Trevor Darrell, Anna Rohrbach, <b><i>Cordelia Schmid</i></b></p>  <p><a href=\"https://arxiv.org/pdf/2207.10225.pdf\">On Label Granularity and Object Localization</a><br />Elijah Cole, <b><i>Kimberly Wilber</i></b>, Grant Van Horn, <b><i>Xuan Yang</i></b>, <b><i>Marco Fornoni</i></b>, Pietro Perona, Serge Belongie, <b><i>Andrew Howard</i></b>, Oisin Mac Aodha </p>  <p><a href=\"https://arxiv.org/pdf/2203.10712.pdf\">Disentangling Architecture and Training for Optical Flow</a><br />  <b><i>Deqing Sun</i></b>, <b><i>Charles Herrmann</i></b>, <b><i>Fitsum Reda</i></b>, <b><i>Michael Rubinstein</i></b>,<b> <i>David J. Fleet</i></b>, <b><i>William T. Freeman</i></b></p>  <p><a href=\"https://arxiv.org/pdf/2207.13061.pdf\">NewsStories: Illustrating Articles with Visual Summaries</a><br />Reuben Tan, Bryan Plummer, Kate Saenko, <b><i>J.P. Lewis</i></b>, <b><i>Avneesh Sud</i></b>, <b><i>Thomas Leung</i></b></p>  <p><a href=\"https://arxiv.org/pdf/2208.09932.pdf\">Improving GANs for Long-Tailed Data Through Group Spectral Regularization</a><br />Harsh Rangwani, Naman Jaswani, <b><i>Tejan Karmali</i></b>, <b><i>Varun Jampani</i></b>, Venkatesh Babu Radhakrishnan </p> <p><a href=\"https://arxiv.org/pdf/2204.10235.pdf\">Planes vs. Chairs: Category-Guided 3D Shape Learning Without Any 3D Cues</a><br />Zixuan Huang, Stefan Stojanov, Anh Thai, <b><i>Varun Jampani</i></b>, James Rehg </p>  <p><a href=\"https://arxiv.org/pdf/2208.03354.pdf\">A Sketch Is Worth a Thousand Words: Image Retrieval with Text and Sketch</a><br />Patsorn Sangkloy, <b><i>Wittawat Jitkrittum</i></b>, Diyi Yang, James Hays </p>  <p><a href=\"https://arxiv.org/pdf/2204.09171.pdf\">Learned Monocular Depth Priors in Visual-Inertial Initialization</a><br /><b><i>Yunwen Zhou</i></b>, <b><i>Abhishek Kar</i></b>, <b><i>Eric L. Turner</i></b>, <b><i>Adarsh Kowdle</i></b>, <b><i>Chao Guo</i></b>, <b><i>Ryan DuToit</i></b>, <b><i>Konstantine Tsotsos</i></b></p>  <p><a href=\"https://arxiv.org/pdf/2204.01403.pdf\">How Stable are Transferability Metrics Evaluations?</a><br /><b><i>Andrea Agostinelli</i></b>, <b><i>Michal Pandy</i></b>, <b><i>Jasper Uijlings</i></b>, <b><i>Thomas Mensink</i></b>, <b><i>Vittorio Ferrari</i></b></p>  <p><a href=\"https://arxiv.org/pdf/2112.02086.pdf\">Data-Free Neural Architecture Search via Recursive Label Calibration</a><br />Zechun Liu<a href=\"#1\" name=\"top1\"><span class=\"Apple-style-span\" style=\"font-size: small;\"><sup>*</sup></span></a>, Zhiqiang Shen, <b><i>Yun Long</i></b>, Eric Xing, Kwang-Ting Cheng, <b><i>Chas H. Leichner</i></b></p>  <p><a href=\"https://arxiv.org/pdf/2201.00392.pdf\">Fast and High Quality Image Denoising via Malleable Convolution</a><br />Yifan Jiang<a href=\"#1\" name=\"top1\"><span class=\"Apple-style-span\" style=\"font-size: small;\"><sup>*</sup></span></a>, <b><i>Bartlomiej Wronski</i></b>, <b><i>Ben Mildenhall</i></b>, <b><i>Jonathan T. Barron</i></b>, Zhangyang Wang, <b><i>Tianfan Xue</i></b></p>  <p><a href=\"https://arxiv.org/pdf/2207.13247.pdf\">Concurrent Subsidiary Supervision for Unsupervised Source-Free Domain Adaptation</a><br />Jogendra Nath Kundu, Suvaansh Bhambri, Akshay R Kulkarni, Hiran Sarkar, <br /><b><i>Varun Jampani</i></b>, Venkatesh Babu Radhakrishnan </p>  <p><a href=\"https://arxiv.org/pdf/2204.03353.pdf\">Learning Online Multi-Sensor Depth Fusion</a><br />Erik Sandström, Martin R. Oswald, Suryansh Kumar, Silvan Weder, Fisher Yu, <b><i>Cristian Sminchisescu</i></b>, Luc Van Gool </p>  <p><a href=\"https://arxiv.org/pdf/2208.03764.pdf\">Hierarchical Semantic Regularization of Latent Spaces in StyleGANs</a><br /><b><i>Tejan Karmali</i></b>, Rishubh Parihar, Susmit Agrawal, Harsh Rangwani, <b><i>Varun Jampani</i></b>, Maneesh K Singh, Venkatesh Babu Radhakrishnan </p>  <p><a href=\"https://arxiv.org/pdf/2203.13296.pdf\">RayTran: 3D Pose Estimation and Shape Reconstruction of Multiple Objects from Videos with Ray-Traced Transformers</a><br />Michał J Tyszkiewicz, <b><i>Kevis-Kokitsi Maninis</i></b>, <b><i>Stefan Popov</i></b>, <b><i>Vittorio Ferrari</i></b></p>   <p><a href=\"https://arxiv.org/pdf/2107.12038.pdf\">Neural Video Compression Using GANs for Detail Synthesis and Propagation</a><br /><b><i>Fabian Mentzer</i></b>, <b><i>Eirikur Agustsson</i></b>, <b><i>Johannes Ballé</i></b>, <b><i>David Minnen</i></b>, <b><i>Nick Johnston</i></b>, <b><i>George Toderici</i></b></p>  <p><a href=\"https://arxiv.org/pdf/2207.10664.pdf\">Exploring Fine-Grained Audiovisual Categorization with the SSW60 Dataset</a><br />Grant Van Horn, Rui Qian, <b><i>Kimberly Wilber</i></b>, <b><i>Hartwig Adam</i></b>, Oisin Mac Aodha, Serge Belongie </p>  <p><a href=\"https://arxiv.org/pdf/2112.04267.pdf\">Implicit Neural Representations for Image Compression</a><br />Yannick Strümpler, Janis Postels, Ren Yang, Luc Van Gool, <b><i>Federico Tombari</i></b></p>  <p><a href=\"https://arxiv.org/pdf/2111.14673.pdf\">3D Compositional Zero-Shot Learning with DeCompositional Consensus</a><br />Muhammad Ferjad Naeem, Evin Pınar Örnek, Yongqin Xian, Luc Van Gool, <b><i>Federico Tombari</i></b></p>  <p><a href=\"https://arxiv.org/pdf/2203.17273.pdf\">FindIt: Generalized Localization with Natural Language Queries</a> (see <a href=\"https://ai.googleblog.com/2022/09/findit-generalized-object-localization.html\">blog post</a>) <br /><b><i>Weicheng Kuo</i></b>, <b><i>Fred Bertsch</i></b>, <b><i>Wei Li</i></b>, <b><i>AJ Piergiovanni</i></b>, <b><i>Mohammad Saffar</i></b>, <b><i>Anelia Angelova</i></b></p>  <p><a href=\"https://arxiv.org/pdf/2112.09747.pdf\">A Simple Single-Scale Vision Transformer for Object Detection and Instance Segmentation</a><br />Wuyang Chen<a href=\"#1\" name=\"top1\"><span class=\"Apple-style-span\" style=\"font-size: small;\"><sup>*</sup></span></a>, <b><i>Xianzhi Du</i></b>, <b><i>Fan Yang</i></b>, <b><i>Lucas Beyer</i></b>, <b><i>Xiaohua Zhai</i></b>, <b><i>Tsung-Yi Lin</i></b>, <b><i>Huizhong Chen</i></b>, <b><i>Jing Li</i></b>, <b><i>Xiaodan Song</i></b>, Zhangyang Wang, <b><i>Denny Zhou</i></b></p>   <p><a href=\"https://arxiv.org/pdf/2209.04439.pdf\">Improved Masked Image Generation with Token-Critic</a><br /><b><i>Jose Lezama</i></b>, <b><i>Huiwen Chang</i></b>, <i><b>Lu Jiang</b></i>, <b><i>Irfan Essa</i></b></p>  <p><a href=\"https://arxiv.org/pdf/2111.13876.pdf\">Learning Discriminative Shrinkage Deep Networks for Image Deconvolution</a><br />Pin-Hung Kuo, Jinshan Pan, Shao-Yi Chien, <b><i>Ming-Hsuan Yang</i></b></p>  <p><a href=\"https://arxiv.org/pdf/2207.10141.pdf\">AudioScopeV2: Audio-Visual Attention Architectures for Calibrated Open-Domain On-Screen Sound Separation</a><br />Efthymios Tzinis<a href=\"#1\" name=\"top1\"><span class=\"Apple-style-span\" style=\"font-size: small;\"><sup>*</sup></span></a>, <b><i>Scott Wisdom</i></b>, <b><i>Tal Remez</i></b>, <b><i>John Hershey</i></b></p>  <p><a href=\"https://arxiv.org/pdf/2205.06230.pdf\">Simple Open-Vocabulary Object Detection with Vision Transformers</a><br /><b><i>Matthias Minderer</i></b>, <b><i>Alexey Gritsenko</i></b>, <b><i>Austin C Stone</i></b>, <b><i>Maxim Neumann</i></b>, <b><i>Dirk Weißenborn</i></b>, <b><i>Alexey Dosovitskiy</i></b>, <b><i>Aravindh Mahendran</i></b>, <b><i>Anurag Arnab</i></b>, <b><i>Mostafa Dehghani</i></b>, <b><i>Zhuoran Shen</i></b>, <b><i>Xiao Wang</i></b>, <b><i>Xiaohua Zhai</i></b>, <b><i>Thomas Kipf</i></b>, <b><i>Neil Houlsby</i></b></p>   <p><a href=\"https://arxiv.org/pdf/2112.05892.pdf\">COMPOSER: Compositional Reasoning of Group Activity in Videos with Keypoint-Only Modality</a><br />Honglu Zhou, Asim Kadav, Aviv Shamsian, Shijie Geng, Farley Lai, <b><i>Long Zhao</i></b>, <b><i>Ting Liu</i></b>, Mubbasir Kapadia, Hans Peter Graf </p>  <p><a href=\"https://arxiv.org/pdf/2208.00934.pdf\">Video Question Answering with Iterative Video-Text Co-tokenization</a> (see <a href=\"https://ai.googleblog.com/2022/08/efficient-video-text-learning-with.html\">blog post</a>) <br /><b><i>AJ Piergiovanni</i></b>, Kairo Morton<a href=\"#1\" name=\"top1\"><span class=\"Apple-style-span\" style=\"font-size: small;\"><sup>*</sup></span></a>, <b><i>Weicheng Kuo</i></b>, <b><i>Michael S. Ryoo</i></b>, <b><i>Anelia Angelova</i></b></p>  <p><a href=\"https://arxiv.org/pdf/2111.11430.pdf\">Class-Agnostic Object Detection with Multi-modal Transformer</a><br />Muhammad Maaz, Hanoona Abdul Rasheed, Salman Khan, Fahad Shahbaz Khan, Rao Muhammad Anwer, <b><i>Ming-Hsuan Yang</i></b></p>  <p><a href=\"https://arxiv.org/pdf/2202.04901.pdf\">FILM: Frame Interpolation for Large Motion</a><b> </b>(see <a href=\"https://ai.googleblog.com/2022/10/large-motion-frame-interpolation.html\">blog post</a>) <br /><b><i>Fitsum Reda</i></b>, <b><i>Janne Kontkanen</i></b>, <b><i>Eric Tabellion</i></b>, <b><i>Deqing Sun</i></b>, <b><i>Caroline Pantofaru</i></b>, <b><i>Brian Curless</i></b></p>  <p><a href=\"https://arxiv.org/pdf/2207.12824.pdf\">Compositional Human-Scene Interaction Synthesis with Semantic Control</a><br />Kaifeng Zhao, Shaofei Wang, Yan Zhang, <b><i>Thabo Beeler,</i></b> Siyu Tang </p><div style=\"line-height: 40%;\">    <br /></div><h2>Workshops</h2><p><a href=\"https://www.latinxinai.org/eccv-2022\">LatinX in AI</a><br />Mentors include: <i><b>José Lezama</b></i><br />Keynote Speakers include: <b><i>Andre Araujo</i></b></p> <p><a href=\"https://cveu.github.io/\">AI for Creative Video Editing and Understanding</a><br />Keynote Speakers include: <b><i>Tali Dekel</i></b>, <b><i>Negar Rostamzadeh</i></b></p> <p><a href=\"https://l2id.github.io/l2id2022/\">Learning With Limited and Imperfect Data (L2ID)</a><br />Invited Speakers include: <b><i>Xiuye Gu</i></b><br />Organizing Committee includes: <b><i>Sadeep Jayasumana</i></b></p>  <p><a href=\"https://campworkshop.org/\">International Challenge on Compositional and Multimodal Perception (CAMP)</a><br />Program Committee includes: <b><i>Edward Vendrow</i></b></p>  <p><a href=\"https://sslwin.org/\">Self-Supervised Learning: What is Next?</a><br />Invited Speakers include: <b><i>Mathilde Caron</i></b>, <b><i>Arsha Nagrani</i></b><br />   Organizers include: <b><i>Andrew Zisserman</i></b></p>  <p><a href=\"https://eccv22-arow.github.io/\">3rd Workshop on Adversarial Robustness In the Real World</a><br />Invited Speakers include: <b><i>Ekin Dogus Cubuk</i></b><br />Organizers include: <b><i>Xinyun Chen</i></b>, <b><i>Alexander Robey</i></b>, <b><i>Nataniel Ruiz</i></b>, <b><i>Yutong Bai</i></b></p>       <p><a href=\"https://av4d.org/#speakers\">AV4D: Visual Learning of Sounds in Spaces</a><br />Invited Speakers include: <b><i>John Hershey</i></b></p>  <p><a href=\"http://mipi-challenge.org/index.html\">Challenge on Mobile Intelligent Photography and Imaging (MIPI)</a><br />Invited Speakers include: <b><i>Peyman Milanfar</i></b></p>  <p><a href=\"http://www.robustvision.net/\">Robust Vision Challenge 2022</a><br />Organizing Committee includes: <b><i>Alina Kuznetsova</i></b></p>  <p><a href=\"https://computer-vision-in-the-wild.github.io/eccv-2022/\">Computer Vision in the Wild</a><br />Challenge Organizers include: <b><i>Yi-Ting Chen</i></b>, <b><i>Ye Xia</i></b><br />Invited Speakers include: <b><i>Yin Cui</i></b>, <b><i>Yongqin Xian</i></b>, <b><i>Neil Houlsby</i></b></p> <p><a href=\"https://sslad2022.github.io/pages/organizers.html\">Self-Supervised Learning for Next-Generation Industry-Level Autonomous Driving (SSLAD)</a><br />Organizers include: <b><i>Fisher Yu</i></b></p>  <p><a href=\"https://sites.google.com/corp/view/rcv-at-eccv-2022/home\">Responsible Computer Vision</a><br />Organizing Committee includes: <b><i>Been Kim</i></b><br />Invited Speakers include: <b><i>Emily Denton</i></b></p>  <p><a href=\"https://cross-modal-human-robot-interaction.github.io/\">Cross-Modal Human-Robot Interaction</a><br />Invited Speakers include: <b><i>Peter Anderson</i></b></p> <p><a href=\"https://workshop2022.isic-archive.com/#invited_speakers\">ISIC Skin Image Analysis</a><br />Organizing Committee includes: <b><i>Yuan Liu</i></b><br />Steering Committee includes: <b><i>Yuan Liu</i></b>, <b><i>Dale Webster</i></b><br />Invited Speakers include: <b><i>Yuan Liu</i></b></p> <p><a href=\"https://sites.google.com/corp/view/hands2022/home\">Observing and Understanding Hands in Action</a><br />Sponsored by Google </p> <p><a href=\"https://avvision.xyz/eccv22/\">Autonomous Vehicle Vision (AVVision)</a><br />Speakers include: <b><i>Fisher Yu</i></b></p> <p><a href=\"https://jrdb.erc.monash.edu/workshops/eccv2022\">Visual Perception for Navigation in Human Environments: The JackRabbot Human Body Pose Dataset and Benchmark</a><br />Organizers include: <i><b>Edward Vendrow</b></i></p> <p><a href=\"https://languagefor3dscenes.github.io/ECCV2022/\">Language for 3D Scenes</a><br />Invited Speakers include: <b><i>Jason Baldridge</i></b><br />Organizers include: <b><i>Leonidas Guibas</i></b></p>  <p><a href=\"https://computerperception.github.io/\">Designing and Evaluating Computer Perception Systems (CoPe)</a><br />Organizers include: <b><i>Andrew Zisserman</i></b></p> <p><a href=\"https://learn3dg.github.io/\">Learning To Generate 3D Shapes and Scenes</a><br />Panelists include: <b><i>Pete Florence</i></b></p>  <p><a href=\"https://data.vision.ee.ethz.ch/cvl/aim22/\">Advances in Image Manipulation</a><br />Program Committee includes: <b><i>George Toderici</i></b>, <b><i>Ming-Hsuan Yang</i></b></p>  <p><a href=\"https://sites.google.com/corp/view/tie-eccv2022\">TiE: Text in Everything</a><br />Challenge Organizers include: <b><i>Shangbang Long</i></b>, <b><i>Siyang Qin</i></b><br />Invited Speakers include: <b><i>Tali Dekel</i></b>, <b><i>Aishwarya Agrawal</i></b></p> <p><a href=\"https://ilr-workshop.github.io/ECCVW2022/\">Instance-Level Recognition</a><br />Organizing Committee: <b><i>Andre Araujo</i></b>, <b><i>Bingyi Cao</i></b>, <b><i>Tobias Weyand</i></b><br />Invited Speakers include: <b><i>Mathilde Caron</i></b></p> <p><a href=\"https://what-is-motion-for.github.io/\">What Is Motion For?</a><br />Organizing Committee: <b><i>Deqing Sun</i></b>, <b><i>Fitsum Reda</i></b>, <b><i>Charles Herrmann</i></b><br />Invited Speakers include: <b><i>Tali Dekel</i></b></p>  <p><a href=\"https://ngr-co3d.github.io/\">Neural Geometry and Rendering: Advances and the Common Objects in 3D Challenge</a><br />Invited Speakers include: <b><i>Ben Mildenhall</i></b></p>  <p><a href=\"https://geometry.stanford.edu/voli/\">Visual Object-Oriented Learning Meets Interaction: Discovery, Representations, and Applications</a><br />Invited Speakers include: <b><i>Klaus Greff</i></b>, <b><i>Thomas Kipf</i></b><br />Organizing Committee includes: <b><i>Leonidas Guibas</i></b></p>  <p><a href=\"https://wvbsd.github.io/2022/index.html\">Vision with Biased or Scarce Data (VBSD)</a><br />Program Committee includes: <b><i>Yizhou Wang</i></b></p>  <p><a href=\"https://motcomplex.github.io/\">Multiple Object Tracking and Segmentation in Complex Environments</a><br />Invited Speakers include: <b><i>Xingyi Zhou</i></b>, <b><i>Fisher Yu</i></b></p>  <p><a href=\"https://vipriors.github.io/\">3rd Visual Inductive Priors for Data-Efficient Deep Learning Workshop</a><br />Organizing Committee includes: <b><i>Ekin Dogus Cubuk</i></b></p>  <p><a href=\"https://deeperaction.github.io/\">DeeperAction: Detailed Video Action Understanding and Anomaly Recognition</a><br />Advisors include: <b><i>Rahul Sukthankar</i></b></p>  <p><a href=\"https://signlanguageworkshop.github.io/\">Sign Language Understanding Workshop and Sign Language Recognition, Translation &amp; Production Challenge</a><br />Organizing Committee includes: <b><i>Andrew Zisserman</i></b><br />Speakers include: <b><i>Andrew Zisserman</i></b></p>  <p><a href=\"https://ego4d-data.org/workshops/eccv22/\">Ego4D: First-Person Multi-Modal Video Understanding</a><br />Invited Speakers include: <b><i>Michal Irani</i></b></p>  <p><a href=\"https://vcmi.inesctec.pt/aimia_eccv/\">AI-Enabled Medical Image Analysis: Digital Pathology &amp; Radiology/COVID19</a><br />Program Chairs include: <b><i>Po-Hsuan Cameron Chen</i></b><br />Workshop Partner: <b><i>Google Health</i></b></p>  <p><a href=\"https://www.votchallenge.net/vot2022/index.html\">Visual Object Tracking Challenge (VOT 2022)</a><br />Technical Committee includes: <b><i>Christoph Mayer</i></b></p> <p><a href=\"https://iplab.dmi.unict.it/acvr2022/\">Assistive Computer Vision and Robotics</a><br />Technical Committee includes: <b><i>Maja Mataric</i></b></p>  <p><a href=\"https://sites.google.com/corp/view/egocentric-hand-body-activity\">Human Body, Hands, and Activities from Egocentric and Multi-View Cameras</a><br />Organizers include: <b><i>Francis Engelmann</i></b></p>  <p><a href=\"https://sites.google.com/corp/view/mono3d-eccv-workshop\">Frontiers of Monocular 3D Perception: Implicit x Explicit</a><br />Panelists include: <b><i>Pete Florence</i></b></p><div style=\"line-height: 40%;\">    <br /></div><h2>Tutorials</h2><p><a href=\"https://feichtenhofer.github.io/eccv2022-ssl-tutorial/\">Self-Supervised Representation Learning in Computer Vision</a><br />Invited Speakers include: <b><i>Ting Chen</i></b></p>  <p><a href=\"https://sites.google.com/corp/berkeley.edu/nerf-tutorial/home\">Neural Volumetric Rendering for Computer Vision</a><br />Organizers include: <b><i>Ben Mildenhall</i></b>, <b><i>Pratul Srinivasan</i></b>, <b><i>Jon Barron</i></b><br />Presenters include: <b><i>Ben Mildenhall</i></b>, <b><i>Pratul Srinivasan</i></b></p>  <p><a href=\"https://sites.google.com/corp/g.ucla.edu/eccv2022-nas/home\">New Frontiers in Efficient Neural Architecture Search!</a><br />Speakers include: <b><i>Ruochen Wang</i></b></p><!--Footnotes themselves at the bottom.--><hr width=\"80%\" /><span class=\"Apple-style-span\" style=\"font-size: x-small;\"><br />  <a name=\"1\"><sup>*</sup></a>Work done while at Google.<a href=\"#top1\"> &nbsp;<sup>↩</sup></a></span><p></p>",
  "link": [
    "",
    "",
    "",
    "",
    ""
  ],
  "author": {
    "name": "Google AI",
    "uri": "http://www.blogger.com/profile/12098626514775266161",
    "email": "noreply@blogger.com",
    "gd:image": ""
  },
  "media:thumbnail": "",
  "thr:total": 0
}