{
  "title": "Dynamic Causal Effects Evaluation in A/B Testing with a Reinforcement Learning Framework. (arXiv:2002.01711v6 [cs.LG] UPDATED)",
  "link": "http://arxiv.org/abs/2002.01711",
  "description": "<p>A/B testing, or online experiment is a standard business strategy to compare\na new product with an old one in pharmaceutical, technological, and traditional\nindustries. Major challenges arise in online experiments of two-sided\nmarketplace platforms (e.g., Uber) where there is only one unit that receives a\nsequence of treatments over time. In those experiments, the treatment at a\ngiven time impacts current outcome as well as future outcomes. The aim of this\npaper is to introduce a reinforcement learning framework for carrying A/B\ntesting in these experiments, while characterizing the long-term treatment\neffects. Our proposed testing procedure allows for sequential monitoring and\nonline updating. It is generally applicable to a variety of treatment designs\nin different industries. In addition, we systematically investigate the\ntheoretical properties (e.g., size and power) of our testing procedure.\nFinally, we apply our framework to both simulated data and a real-world data\nexample obtained from a technological company to illustrate its advantage over\nthe current practice. A Python implementation of our test is available at\nhttps://github.com/callmespring/CausalRL.\n</p>",
  "dc:creator": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_C/0/1/0/all/0/1\">Chengchun Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaoyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_S/0/1/0/all/0/1\">Shikai Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1\">Hongtu Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Jieping Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_R/0/1/0/all/0/1\">Rui Song</a>"
}