{
  "title": "Streaming Columnar Data with Apache Arrow",
  "link": "",
  "published": "2017-01-27T09:00:00-08:00",
  "updated": "2017-01-27T09:00:00-08:00",
  "author": {
    "name": "Wes McKinney"
  },
  "id": "tag:wesmckinney.com,2017-01-27:/blog/arrow-streaming-columnar/",
  "summary": "<p>Over the past couple weeks, <a href=\"http://github.com/nongli\">Nong Li</a> and I added a streaming binary format\nto <a href=\"http://arrow.apache.org\">Apache Arrow</a>, accompanying the existing random access / IPC file\nformat. We have implementations in Java and C++, plus Python bindings. In this\npost, I explain how the format works and show how you can achieve very high\ndata throughput to pandas DataFrames.</p>",
  "content": "<p>Over the past couple weeks, <a href=\"http://github.com/nongli\">Nong Li</a> and I added a streaming binary format\nto <a href=\"http://arrow.apache.org\">Apache Arrow</a>, accompanying the existing random access / IPC file\nformat. We have implementations in Java and C++, plus Python bindings. In this\npost, I explain how the format works and show how you can achieve very high\ndata throughput to pandas DataFrames.</p>\n\n\n<h2>Columnar streaming data</h2>\n<p>A common question I get about using Arrow is the high cost of transposing large\ntabular datasets from record- or row-oriented format to column-oriented\nformat. For a multi-gigabyte dataset, transposing in memory or on disk may be\nprohibitive.</p>\n<p>For streaming data, whether the source data is row-oriented or column-oriented\nmemory layout, one option is to send small batches of rows, each internally\nhaving a columnar memory layout.</p>\n<p>In Apache Arrow, an in-memory columnar array collection representing a chunk of\na table is called a <strong>record batch</strong>. Multiple record batches can be collected\nto represent a single logical table data structure.</p>\n<p>In the existing \"random access\" file format, we write metadata containing the\ntable schema and block locations at the end of the file, enabling you to select\nany record batch or any column in the dataset very cheaply. In the streaming\nformat, we send a series of messages: the schema followed by one or more record\nbatches.</p>\n<p>The different formats look roughly like this diagram:</p>\n<p><center>\n<img src=\"../../images/arrow_file_formats.png\" alt=\"Arrow file formats\" width=\"60%\"/>\n</center></p>\n<h2>Streaming data in PyArrow: Usage</h2>\n<p>To show you how this works, I generate an example dataset representing a single\nstreaming chunk:</p>\n<div class=\"github\"><pre><span></span><code><span class=\"kn\">import</span> <span class=\"nn\">time</span>\n<span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n<span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n<span class=\"kn\">import</span> <span class=\"nn\">pyarrow</span> <span class=\"k\">as</span> <span class=\"nn\">pa</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">generate_data</span><span class=\"p\">(</span><span class=\"n\">total_size</span><span class=\"p\">,</span> <span class=\"n\">ncols</span><span class=\"p\">):</span>\n    <span class=\"n\">nrows</span> <span class=\"o\">=</span> <span class=\"nb\">int</span><span class=\"p\">(</span><span class=\"n\">total_size</span> <span class=\"o\">/</span> <span class=\"n\">ncols</span> <span class=\"o\">/</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">dtype</span><span class=\"p\">(</span><span class=\"s1\">&#39;float64&#39;</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">itemsize</span><span class=\"p\">)</span>\n    <span class=\"k\">return</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">({</span>\n        <span class=\"s1\">&#39;c&#39;</span> <span class=\"o\">+</span> <span class=\"nb\">str</span><span class=\"p\">(</span><span class=\"n\">i</span><span class=\"p\">):</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"n\">nrows</span><span class=\"p\">)</span>\n        <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">ncols</span><span class=\"p\">)</span>\n    <span class=\"p\">})</span>\n</code></pre></div>\n\n<p>Now, suppose we want to write 1 gigabyte of data composed of chunks that are 1\nmegabyte each, so 1024 chunks. First, let's create 1MB DataFrame with 16 columns:</p>\n<div class=\"github\"><pre><span></span><code><span class=\"n\">KILOBYTE</span> <span class=\"o\">=</span> <span class=\"mi\">1</span> <span class=\"o\">&lt;&lt;</span> <span class=\"mi\">10</span>\n<span class=\"n\">MEGABYTE</span> <span class=\"o\">=</span> <span class=\"n\">KILOBYTE</span> <span class=\"o\">*</span> <span class=\"n\">KILOBYTE</span>\n<span class=\"n\">DATA_SIZE</span> <span class=\"o\">=</span> <span class=\"mi\">1024</span> <span class=\"o\">*</span> <span class=\"n\">MEGABYTE</span>\n<span class=\"n\">NCOLS</span> <span class=\"o\">=</span> <span class=\"mi\">16</span>\n\n<span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">generate_data</span><span class=\"p\">(</span><span class=\"n\">MEGABYTE</span><span class=\"p\">,</span> <span class=\"n\">NCOLS</span><span class=\"p\">)</span>\n</code></pre></div>\n\n<p>Then, I convert this to a <code>pyarrow.RecordBatch</code>:</p>\n<div class=\"github\"><pre><span></span><code>batch = pa.RecordBatch.from_pandas(df)\n</code></pre></div>\n\n<p>Now, I create an output stream that writes to RAM and create a <code>StreamWriter</code>:</p>\n<div class=\"github\"><pre><span></span><code><span class=\"n\">sink</span> <span class=\"o\">=</span> <span class=\"n\">pa</span><span class=\"o\">.</span><span class=\"n\">InMemoryOutputStream</span><span class=\"p\">()</span>\n<span class=\"n\">stream_writer</span> <span class=\"o\">=</span> <span class=\"n\">pa</span><span class=\"o\">.</span><span class=\"n\">StreamWriter</span><span class=\"p\">(</span><span class=\"n\">sink</span><span class=\"p\">,</span> <span class=\"n\">batch</span><span class=\"o\">.</span><span class=\"n\">schema</span><span class=\"p\">)</span>\n</code></pre></div>\n\n<p>Then, we write the 1024 chunks composing the 1 GB dataset:</p>\n<div class=\"github\"><pre><span></span><code><span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">DATA_SIZE</span> <span class=\"o\">//</span> <span class=\"n\">MEGABYTE</span><span class=\"p\">):</span>\n    <span class=\"n\">stream_writer</span><span class=\"o\">.</span><span class=\"n\">write_batch</span><span class=\"p\">(</span><span class=\"n\">batch</span><span class=\"p\">)</span>\n</code></pre></div>\n\n<p>Since we wrote to RAM, we can get the entire stream as a single buffer:</p>\n<div class=\"github\"><pre><span></span><code><span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">13</span><span class=\"p\">]:</span> <span class=\"n\">source</span> <span class=\"o\">=</span> <span class=\"n\">sink</span><span class=\"o\">.</span><span class=\"n\">get_result</span><span class=\"p\">()</span>\n\n<span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">14</span><span class=\"p\">]:</span> <span class=\"n\">source</span>\n<span class=\"n\">Out</span><span class=\"p\">[</span><span class=\"mi\">14</span><span class=\"p\">]:</span> <span class=\"o\">&lt;</span><span class=\"n\">pyarrow</span><span class=\"o\">.</span><span class=\"n\">io</span><span class=\"o\">.</span><span class=\"n\">Buffer</span> <span class=\"n\">at</span> <span class=\"mh\">0x7f2df7118f80</span><span class=\"o\">&gt;</span>\n\n<span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">15</span><span class=\"p\">]:</span> <span class=\"n\">source</span><span class=\"o\">.</span><span class=\"n\">size</span>\n<span class=\"n\">Out</span><span class=\"p\">[</span><span class=\"mi\">15</span><span class=\"p\">]:</span> <span class=\"mi\">1074750744</span>\n</code></pre></div>\n\n<p>Since this data is in memory, reading back Arrow record batches is a zero-copy\noperation. I open a <code>StreamReader</code>, read back the data as a <code>pyarrow.Table</code>,\nand then convert to a pandas DataFrame:</p>\n<div class=\"github\"><pre><span></span><code><span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">16</span><span class=\"p\">]:</span> <span class=\"n\">reader</span> <span class=\"o\">=</span> <span class=\"n\">pa</span><span class=\"o\">.</span><span class=\"n\">StreamReader</span><span class=\"p\">(</span><span class=\"n\">source</span><span class=\"p\">)</span>\n\n<span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">17</span><span class=\"p\">]:</span> <span class=\"n\">table</span> <span class=\"o\">=</span> <span class=\"n\">reader</span><span class=\"o\">.</span><span class=\"n\">read_all</span><span class=\"p\">()</span>\n\n<span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">18</span><span class=\"p\">]:</span> <span class=\"n\">table</span>\n<span class=\"n\">Out</span><span class=\"p\">[</span><span class=\"mi\">18</span><span class=\"p\">]:</span> <span class=\"o\">&lt;</span><span class=\"n\">pyarrow</span><span class=\"o\">.</span><span class=\"n\">table</span><span class=\"o\">.</span><span class=\"n\">Table</span> <span class=\"n\">at</span> <span class=\"mh\">0x7fae8281f6f0</span><span class=\"o\">&gt;</span>\n\n<span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">19</span><span class=\"p\">]:</span> <span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">table</span><span class=\"o\">.</span><span class=\"n\">to_pandas</span><span class=\"p\">()</span>\n\n<span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">20</span><span class=\"p\">]:</span> <span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">memory_usage</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">sum</span><span class=\"p\">()</span>\n<span class=\"n\">Out</span><span class=\"p\">[</span><span class=\"mi\">20</span><span class=\"p\">]:</span> <span class=\"mi\">1073741904</span>\n</code></pre></div>\n\n<p>This is all very nice, but you may have some questions. How fast is it? How\ndoes the stream chunk size affect the absolute performance to obtain the pandas\nDataFrame?</p>\n<h2>Streaming data performance</h2>\n<p>As the streaming chunksize grows smaller, the cost to reconstruct a contiguous\ncolumnar pandas DataFrame increases because of cache-inefficient memory access\npatterns. There is also some overhead from manipulating the C++ container data\nstructures around the arrays and their memory buffers.</p>\n<p>With a 1 MB as above, on my laptop (Quad-core Xeon E3-1505M) I have:</p>\n<div class=\"github\"><pre><span></span><code><span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">20</span><span class=\"p\">]:</span> <span class=\"o\">%</span><span class=\"n\">timeit</span> <span class=\"n\">pa</span><span class=\"o\">.</span><span class=\"n\">StreamReader</span><span class=\"p\">(</span><span class=\"n\">source</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">read_all</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">to_pandas</span><span class=\"p\">()</span>\n<span class=\"mi\">10</span> <span class=\"n\">loops</span><span class=\"p\">,</span> <span class=\"n\">best</span> <span class=\"n\">of</span> <span class=\"mi\">3</span><span class=\"p\">:</span> <span class=\"mi\">129</span> <span class=\"n\">ms</span> <span class=\"n\">per</span> <span class=\"n\">loop</span>\n</code></pre></div>\n\n<p>This is an effective throughput of <strong>7.75 GB/s</strong> to reconstruct a 1GB DataFrame\nfrom 1024 1MB chunks. What happens when we use larger and smaller chunks? Here\nare the results</p>\n<p><center>\n<img src=\"../../images/arrow_streaming_benchmarks.png\"\n     alt=\"Arrow streaming performance\"\n     width=\"1000%\"/>\n</center></p>\n<p>The performance degrades significantly from 256K to 64K chunks. I was surprised\nto see that 1MB chunks were faster than 16MB ones; it would be worth a more\nthorough investigation to understand whether that is normal variance or\nsomething else going on.</p>\n<p>In the current iteration of the format, the data is not being compressed at\nall, so the in-memory and on-the-wire size are about the same. Compression may\nbe added to the format as an option in the future.</p>\n<h2>Summary</h2>\n<p>Streaming columnar data can be an efficient way to transmit large datasets to\ncolumnar analytics tools like pandas using small chunks. Data services using\nrow-oriented storage can transpose and stream small data chunks that are more\nfriendly to your CPU's L2 and L3 caches.</p>\n<h2>Full benchmarking code</h2>\n<div class=\"github\"><pre><span></span><code><span class=\"kn\">import</span> <span class=\"nn\">time</span>\n<span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n<span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n<span class=\"kn\">import</span> <span class=\"nn\">pyarrow</span> <span class=\"k\">as</span> <span class=\"nn\">pa</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">generate_data</span><span class=\"p\">(</span><span class=\"n\">total_size</span><span class=\"p\">,</span> <span class=\"n\">ncols</span><span class=\"p\">):</span>\n    <span class=\"n\">nrows</span> <span class=\"o\">=</span> <span class=\"n\">total_size</span> <span class=\"o\">/</span> <span class=\"n\">ncols</span> <span class=\"o\">/</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">dtype</span><span class=\"p\">(</span><span class=\"s1\">&#39;float64&#39;</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">itemsize</span>\n    <span class=\"k\">return</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">({</span>\n        <span class=\"s1\">&#39;c&#39;</span> <span class=\"o\">+</span> <span class=\"nb\">str</span><span class=\"p\">(</span><span class=\"n\">i</span><span class=\"p\">):</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"n\">nrows</span><span class=\"p\">)</span>\n        <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">ncols</span><span class=\"p\">)</span>\n    <span class=\"p\">})</span>\n\n<span class=\"n\">KILOBYTE</span> <span class=\"o\">=</span> <span class=\"mi\">1</span> <span class=\"o\">&lt;&lt;</span> <span class=\"mi\">10</span>\n<span class=\"n\">MEGABYTE</span> <span class=\"o\">=</span> <span class=\"n\">KILOBYTE</span> <span class=\"o\">*</span> <span class=\"n\">KILOBYTE</span>\n<span class=\"n\">DATA_SIZE</span> <span class=\"o\">=</span> <span class=\"mi\">1024</span> <span class=\"o\">*</span> <span class=\"n\">MEGABYTE</span>\n<span class=\"n\">NCOLS</span> <span class=\"o\">=</span> <span class=\"mi\">16</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">get_timing</span><span class=\"p\">(</span><span class=\"n\">f</span><span class=\"p\">,</span> <span class=\"n\">niter</span><span class=\"p\">):</span>\n    <span class=\"n\">start</span> <span class=\"o\">=</span> <span class=\"n\">time</span><span class=\"o\">.</span><span class=\"n\">clock_gettime</span><span class=\"p\">(</span><span class=\"n\">time</span><span class=\"o\">.</span><span class=\"n\">CLOCK_REALTIME</span><span class=\"p\">)</span>\n    <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">niter</span><span class=\"p\">):</span>\n        <span class=\"n\">f</span><span class=\"p\">()</span>\n    <span class=\"k\">return</span> <span class=\"p\">(</span><span class=\"n\">time</span><span class=\"o\">.</span><span class=\"n\">clock_gettime</span><span class=\"p\">(</span><span class=\"n\">time</span><span class=\"o\">.</span><span class=\"n\">CLOCK_REALTIME</span><span class=\"p\">)</span> <span class=\"o\">-</span> <span class=\"n\">start</span><span class=\"p\">)</span> <span class=\"o\">/</span> <span class=\"n\">NITER</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">read_as_dataframe</span><span class=\"p\">(</span><span class=\"n\">klass</span><span class=\"p\">,</span> <span class=\"n\">source</span><span class=\"p\">):</span>\n    <span class=\"n\">reader</span> <span class=\"o\">=</span> <span class=\"n\">klass</span><span class=\"p\">(</span><span class=\"n\">source</span><span class=\"p\">)</span>\n    <span class=\"n\">table</span> <span class=\"o\">=</span> <span class=\"n\">reader</span><span class=\"o\">.</span><span class=\"n\">read_all</span><span class=\"p\">()</span>\n    <span class=\"k\">return</span> <span class=\"n\">table</span><span class=\"o\">.</span><span class=\"n\">to_pandas</span><span class=\"p\">()</span>\n<span class=\"n\">NITER</span> <span class=\"o\">=</span> <span class=\"mi\">5</span>\n<span class=\"n\">results</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n\n<span class=\"n\">CHUNKSIZES</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"mi\">16</span> <span class=\"o\">*</span> <span class=\"n\">KILOBYTE</span><span class=\"p\">,</span> <span class=\"mi\">64</span> <span class=\"o\">*</span> <span class=\"n\">KILOBYTE</span><span class=\"p\">,</span> <span class=\"mi\">256</span> <span class=\"o\">*</span> <span class=\"n\">KILOBYTE</span><span class=\"p\">,</span> <span class=\"n\">MEGABYTE</span><span class=\"p\">,</span> <span class=\"mi\">16</span> <span class=\"o\">*</span> <span class=\"n\">MEGABYTE</span><span class=\"p\">]</span>\n\n<span class=\"k\">for</span> <span class=\"n\">chunksize</span> <span class=\"ow\">in</span> <span class=\"n\">CHUNKSIZES</span><span class=\"p\">:</span>\n    <span class=\"n\">nchunks</span> <span class=\"o\">=</span> <span class=\"n\">DATA_SIZE</span> <span class=\"o\">//</span> <span class=\"n\">chunksize</span>\n    <span class=\"n\">batch</span> <span class=\"o\">=</span> <span class=\"n\">pa</span><span class=\"o\">.</span><span class=\"n\">RecordBatch</span><span class=\"o\">.</span><span class=\"n\">from_pandas</span><span class=\"p\">(</span><span class=\"n\">generate_data</span><span class=\"p\">(</span><span class=\"n\">chunksize</span><span class=\"p\">,</span> <span class=\"n\">NCOLS</span><span class=\"p\">))</span>\n\n    <span class=\"n\">sink</span> <span class=\"o\">=</span> <span class=\"n\">pa</span><span class=\"o\">.</span><span class=\"n\">InMemoryOutputStream</span><span class=\"p\">()</span>\n    <span class=\"n\">stream_writer</span> <span class=\"o\">=</span> <span class=\"n\">pa</span><span class=\"o\">.</span><span class=\"n\">StreamWriter</span><span class=\"p\">(</span><span class=\"n\">sink</span><span class=\"p\">,</span> <span class=\"n\">batch</span><span class=\"o\">.</span><span class=\"n\">schema</span><span class=\"p\">)</span>\n\n    <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">nchunks</span><span class=\"p\">):</span>\n        <span class=\"n\">stream_writer</span><span class=\"o\">.</span><span class=\"n\">write_batch</span><span class=\"p\">(</span><span class=\"n\">batch</span><span class=\"p\">)</span>\n\n    <span class=\"n\">source</span> <span class=\"o\">=</span> <span class=\"n\">sink</span><span class=\"o\">.</span><span class=\"n\">get_result</span><span class=\"p\">()</span>\n\n    <span class=\"n\">elapsed</span> <span class=\"o\">=</span> <span class=\"n\">get_timing</span><span class=\"p\">(</span><span class=\"k\">lambda</span><span class=\"p\">:</span> <span class=\"n\">read_as_dataframe</span><span class=\"p\">(</span><span class=\"n\">pa</span><span class=\"o\">.</span><span class=\"n\">StreamReader</span><span class=\"p\">,</span> <span class=\"n\">source</span><span class=\"p\">),</span> <span class=\"n\">NITER</span><span class=\"p\">)</span>\n\n    <span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">chunksize</span><span class=\"p\">,</span> <span class=\"n\">elapsed</span><span class=\"p\">)</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">result</span><span class=\"p\">)</span>\n    <span class=\"n\">results</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">result</span><span class=\"p\">)</span>\n</code></pre></div>"
}