{
  "title": "An Even Dozen &#8211; Denoising Dirty Documents: Part 12",
  "link": "https://colinpriest.com/2015/11/15/an-even-dozen-denoising-dirty-documents-part-12/",
  "comments": "https://colinpriest.com/2015/11/15/an-even-dozen-denoising-dirty-documents-part-12/#comments",
  "dc:creator": "Colin Priest",
  "pubDate": "Sun, 15 Nov 2015 03:52:38 +0000",
  "category": [
    "Image Processing",
    "Kaggle",
    "Machine Learning",
    "R",
    "Stacking",
    "XGBoost"
  ],
  "guid": "http://colinpriest.com/?p=593",
  "description": "Over the past 11 blogs in this series, I have discussed how to build machine learning models for Kaggle&#8217;s Denoising &#8230;<p><a href=\"https://colinpriest.com/2015/11/15/an-even-dozen-denoising-dirty-documents-part-12/\">Continue reading <span class=\"meta-nav\">&#8594;</span></a></p>",
  "content:encoded": "<p>Over the past 11 blogs in this series, I have discussed how to build machine learning models for Kaggle&#8217;s <a href=\"https://www.kaggle.com/c/denoising-dirty-documents\" target=\"_blank\">Denoising Dirty Documents competition</a>.</p>\n<p><a href=\"https://colinpriestdotcom.files.wordpress.com/2015/11/dozeneggs.jpg\"><img loading=\"lazy\" data-attachment-id=\"595\" data-permalink=\"https://colinpriest.com/2015/11/15/an-even-dozen-denoising-dirty-documents-part-12/dozeneggs/\" data-orig-file=\"https://colinpriestdotcom.files.wordpress.com/2015/11/dozeneggs.jpg\" data-orig-size=\"1200,829\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"dozeneggs\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://colinpriestdotcom.files.wordpress.com/2015/11/dozeneggs.jpg?w=300\" data-large-file=\"https://colinpriestdotcom.files.wordpress.com/2015/11/dozeneggs.jpg?w=529\" class=\"alignnone size-medium wp-image-595\" src=\"https://colinpriestdotcom.files.wordpress.com/2015/11/dozeneggs.jpg?w=300\" alt=\"dozeneggs\" width=\"300\" height=\"207\" srcset=\"https://colinpriestdotcom.files.wordpress.com/2015/11/dozeneggs.jpg?w=300 300w, https://colinpriestdotcom.files.wordpress.com/2015/11/dozeneggs.jpg?w=600 600w, https://colinpriestdotcom.files.wordpress.com/2015/11/dozeneggs.jpg?w=150 150w\" sizes=\"(max-width: 300px) 100vw, 300px\" /></a></p>\n<p>The final blog in this series brings the count to an even dozen, and will achieve two aims:</p>\n<ol>\n<li>ensemble the models that we have built</li>\n<li>take advantage of the second information leakage in the competition</li>\n</ol>\n<p>Ensembling, the combining of individual models into a single model, performs best when the individual models have errors that are not strongly correlated. For example, if each model has statistically independent errors, and each model performs with similar accuracy, then the average prediction across the 4 models will have half the RMSE score of the individual models. One way to increase the statistical independence of the models is to use different feature sets and / or types of models on each. I therefore chose the following combination of models:</p>\n<ol>\n<li>deep learning &#8211; thresholding based features</li>\n<li>deep learning &#8211; edge based features</li>\n<li>deep learning &#8211; median based features</li>\n<li>images with backgrounds removed using information leakage</li>\n<li>xgboost &#8211; wide selection of features</li>\n<li>convolutional neural network &#8211; using raw images without background removal pre-processing</li>\n<li>convolutional neural network &#8211; using images with backgrounds removed using information leakage</li>\n<li>deep convolutional neural network &#8211; using raw images without background removal pre-processing</li>\n<li>deep convolutional neural network &#8211; using images with backgrounds removed using information leakage</li>\n</ol>\n<p><a href=\"https://colinpriestdotcom.files.wordpress.com/2015/11/20151115-ensemble-structure.png\"><img loading=\"lazy\" data-attachment-id=\"599\" data-permalink=\"https://colinpriest.com/2015/11/15/an-even-dozen-denoising-dirty-documents-part-12/20151115-ensemble-structure/\" data-orig-file=\"https://colinpriestdotcom.files.wordpress.com/2015/11/20151115-ensemble-structure.png\" data-orig-size=\"805,445\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"20151115 ensemble structure\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://colinpriestdotcom.files.wordpress.com/2015/11/20151115-ensemble-structure.png?w=300\" data-large-file=\"https://colinpriestdotcom.files.wordpress.com/2015/11/20151115-ensemble-structure.png?w=529\" class=\"alignnone size-medium wp-image-599\" src=\"https://colinpriestdotcom.files.wordpress.com/2015/11/20151115-ensemble-structure.png?w=300\" alt=\"20151115 ensemble structure\" width=\"300\" height=\"166\" srcset=\"https://colinpriestdotcom.files.wordpress.com/2015/11/20151115-ensemble-structure.png?w=300 300w, https://colinpriestdotcom.files.wordpress.com/2015/11/20151115-ensemble-structure.png?w=600 600w, https://colinpriestdotcom.files.wordpress.com/2015/11/20151115-ensemble-structure.png?w=150 150w\" sizes=\"(max-width: 300px) 100vw, 300px\" /></a></p>\n<p>It turned out that some of these models had errors that weren&#8217;t strongly independent to other models. But I was rushing to improve my leaderboard score in the final 48 hours of the competition, so I didn&#8217;t have time to experiment.</p>\n<p>I didn&#8217;t experiment much with different ensemble models. However I did test xgboost versus a simple average or a least square linear regression, and it outperformed both. Maybe an <a href=\"http://web.stanford.edu/~hastie/TALKS/enet_talk.pdf\" target=\"_blank\">elastic net</a> could have done a good job.</p>\n<p>Here is the R code for my ensemble:</p>\n<pre class=\"brush: r; title: ; notranslate\">\n\n.libPaths(c(.libPaths(), \"./rlibs\"))\nlibrary(png)\nlibrary(data.table)\nlibrary(xgboost)\n\n# a function to turn a matrix image into a vector\nimg2vec = function(img)\n{\nreturn (matrix(img, nrow(img) * ncol(img), 1))\n}\n\ncleanFolder = \"./data/train_cleaned\"\ninFolder1 = \"./threshold based model/training data\"\ninFolder2 = \"./edge based model/training data\"\ninFolder3 = \"./median based model/training data\"\ninFolder4 = \"./foreground/train foreground\"\ninFolder5 = \"./submission 11/train_postprocessed\"\ninFolder6 = \"./convnet/train_predicted\"\ninFolder7 = \"./cnn_leakage/train_predicted\"\ninFolder8 = \"./CNN based model/training\"\ninFolder9 = \"./deep CNN/train_predicted\"\n\noutPath = \"./stacked/stacking.csv\"\n\nfilenames = list.files(cleanFolder)\nfor (f in filenames)\n{\nprint(f)\nimgX1 = readPNG(file.path(inFolder1, f))\nimgX2 = readPNG(file.path(inFolder2, f))\nimgX3 = readPNG(file.path(inFolder3, f))\nimgX4 = readPNG(file.path(inFolder4, f))\nimgX5 = readPNG(file.path(inFolder5, f))\nimgX6 = readPNG(file.path(inFolder6, f))\nimgX7 = readPNG(file.path(inFolder7, f))\nimgX8 = readPNG(file.path(inFolder8, f))\nimgX9 = readPNG(file.path(inFolder9, f))\nimgY = readPNG(file.path(cleanFolder, f))\n\n# turn the images into vectors\ny = img2vec(imgY)\nx1 = img2vec(imgX1)\nx2 = img2vec(imgX2)\nx3 = img2vec(imgX3)\nx4 = img2vec(imgX4)\nx5 = img2vec(imgX5)\nx6 = img2vec(imgX6)\nx7 = img2vec(imgX7)\nx8 = img2vec(imgX8)\nx9 = img2vec(imgX9)\n\ndat = data.table(cbind(y, x1, x2, x3, x4, x5, x6, x7, x8, x9))\nsetnames(dat,c(\"y\", \"threshold\", \"edge\", \"median\", \"foreground\", \"submission11\", \"convnet\", \"cnn_leakage\", \"CNN\", \"deepCNN\"))\nwrite.table(dat, file=outPath, append=(f != filenames[1]), sep=\",\", row.names=FALSE, col.names=(f == filenames[1]), quote=FALSE)\n}\n\n# read in the full data table\ndat = read.csv(outPath)\n\n# fit an xgboost model to a subset of the data\nset.seed(1)\n#rows = sample(nrow(dat), 15000000)\ndat[is.na(dat)] = 0\n#dtrain <- xgb.DMatrix(as.matrix(dat[rows,-1]), label = as.matrix(dat[rows,1]))\ndtrain <- xgb.DMatrix(as.matrix(dat[,-1]), label = as.matrix(dat[,1]))\n#\nnThreads = 30\n# do cross validation first\n#xgb.tab = xgb.cv(data = dtrain, nthread = nThreads, eval_metric = \"rmse\", nrounds = 1000, early.stop.round = 15, nfold = 4, print.every.n = 10)\n# what is the best number of rounds?\n#min.error.idx = which.min(xgb.tab[, test.rmse.mean])\n# now fit an xgboost model\nmin.error.idx = 300 # was 268\nxgb.mod = xgboost(data = dtrain, nthread = nThreads, eval_metric = \"rmse\", nrounds = min.error.idx, print.every.n = 10)\n\ndat_predicted = predict(xgb.mod, newdata=as.matrix(dat[,-1]))\nsqrt( mean( (dat$y - dat_predicted) ^ 2 )) # 0.00759027\n\nsave (xgb.mod, file = \"./model/xgb.rData\")\n\n#####################################################################################################################################\n\nimgFolder = \"./data/test\"\ninFolder1 = \"./threshold based model/test data\"\ninFolder2 = \"./edge based model/test data\"\ninFolder3 = \"./median based model/test data\"\ninFolder4 = \"./foreground/test foreground\"\ninFolder5 = \"./submission 11/test_postprocessed\"\ninFolder6 = \"./convnet/test_predicted\"\ninFolder7 = \"./cnn_leakage/test_predicted\"\ninFolder8 = \"./CNN based model/test\"\ninFolder9 = \"./deep CNN/test_predicted\"\n\noutFolder = \"./stacked/test data\"\noutFolder2 = \"./stacked/test images\"\n\nfilenames = list.files(imgFolder)\nfor (f in filenames)\n{\nprint(f)\nimgX1 = readPNG(file.path(inFolder1, f))\nimgX2 = readPNG(file.path(inFolder2, f))\nimgX3 = readPNG(file.path(inFolder3, f))\nimgX4 = readPNG(file.path(inFolder4, f))\nimgX5 = readPNG(file.path(inFolder5, f))\nimgX6 = readPNG(file.path(inFolder6, f))\nimgX7 = readPNG(file.path(inFolder7, f))\nimgX8 = readPNG(file.path(inFolder8, f))\nimgX9 = readPNG(file.path(inFolder9, f))\n\n# turn the images into vectors\nx1 = img2vec(imgX1)\nx2 = img2vec(imgX2)\nx3 = img2vec(imgX3)\nx4 = img2vec(imgX4)\nx5 = img2vec(imgX5)\nx6 = img2vec(imgX6)\nx7 = img2vec(imgX7)\nx8 = img2vec(imgX8)\nx9 = img2vec(imgX9)\n\ndat = data.table(cbind(x1, x2, x3, x4, x5, x6, x7, x8, x9))\nsetnames(dat,c(\"threshold\", \"edge\", \"median\", \"foreground\", \"submission11\", \"convnet\", \"cnn_leakage\", \"CNN\", \"deepCNN\"))\nyHat = predict(xgb.mod, newdata=as.matrix(dat))\nyHat[yHat < 0] = 0\nyHat[yHat > 1] = 1\nimgY = matrix(yHat, nrow(imgX1), ncol(imgX1))\nwritePNG(imgY, file.path(outFolder2, f))\nsave(imgY, file = file.path(outFolder, gsub(\".png\", \".rData\", f)))\n}\n\n</pre>\n<p>Ensembling materially improved my leaderboard score versus any of the individual models. I feel that was due to the use of different features across my 3 deep learning models. So now I had a set of images that looked quite good:</p>\n<p><a href=\"https://colinpriestdotcom.files.wordpress.com/2015/11/20151115-output-1.png\"><img loading=\"lazy\" data-attachment-id=\"606\" data-permalink=\"https://colinpriest.com/2015/11/15/an-even-dozen-denoising-dirty-documents-part-12/20151115-output-1/\" data-orig-file=\"https://colinpriestdotcom.files.wordpress.com/2015/11/20151115-output-1.png\" data-orig-size=\"1302,684\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"20151115 output 1\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://colinpriestdotcom.files.wordpress.com/2015/11/20151115-output-1.png?w=300\" data-large-file=\"https://colinpriestdotcom.files.wordpress.com/2015/11/20151115-output-1.png?w=529\" class=\"alignnone size-medium wp-image-606\" src=\"https://colinpriestdotcom.files.wordpress.com/2015/11/20151115-output-1.png?w=300\" alt=\"20151115 output 1\" width=\"300\" height=\"158\" srcset=\"https://colinpriestdotcom.files.wordpress.com/2015/11/20151115-output-1.png?w=300 300w, https://colinpriestdotcom.files.wordpress.com/2015/11/20151115-output-1.png?w=600 600w, https://colinpriestdotcom.files.wordpress.com/2015/11/20151115-output-1.png?w=150 150w\" sizes=\"(max-width: 300px) 100vw, 300px\" /></a></p>\n<p><a href=\"https://colinpriestdotcom.files.wordpress.com/2015/11/20151115-output-2.png\"><img loading=\"lazy\" data-attachment-id=\"607\" data-permalink=\"https://colinpriest.com/2015/11/15/an-even-dozen-denoising-dirty-documents-part-12/20151115-output-2/\" data-orig-file=\"https://colinpriestdotcom.files.wordpress.com/2015/11/20151115-output-2.png\" data-orig-size=\"540,420\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"20151115 output 2\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://colinpriestdotcom.files.wordpress.com/2015/11/20151115-output-2.png?w=300\" data-large-file=\"https://colinpriestdotcom.files.wordpress.com/2015/11/20151115-output-2.png?w=529\" class=\"alignnone size-medium wp-image-607\" src=\"https://colinpriestdotcom.files.wordpress.com/2015/11/20151115-output-2.png?w=300\" alt=\"20151115 output 2\" width=\"300\" height=\"233\" srcset=\"https://colinpriestdotcom.files.wordpress.com/2015/11/20151115-output-2.png?w=300 300w, https://colinpriestdotcom.files.wordpress.com/2015/11/20151115-output-2.png?w=150 150w, https://colinpriestdotcom.files.wordpress.com/2015/11/20151115-output-2.png 540w\" sizes=\"(max-width: 300px) 100vw, 300px\" /></a></p>\n<p>To my eyes, my predicted images were indistinguishable from the clean images in the training data. In a real world situation I would have stopped model development here, because the image quality exceeds the minimum requirements for OCR. However, since this was a competition, I wanted the best score I could get.</p>\n<p>So I took advantage of the second data leakage in the competition &#8211; the fact that the cleaned images were repeated across the dataset. This meant that I could compare a cleaned images to other cleaned images that appeared to have the same text and the same font, and clean up any pixels that were different across the set of images. I experimented with using the mean of the pixel brightness across the images, but using the median performed better.</p>\n<pre class=\"brush: r; title: ; notranslate\">\n\nlibrary(png)\nlibrary(data.table)\n\ninFolder = \"./stacked/test data\"\noutFolder = \"./information leakage/data\"\noutFolder2 = \"./information leakage/images\"\n\n# a function to turn a matrix image into a vector\nimg2vec = function(img)\n{\nreturn (matrix(img, nrow(img) * ncol(img), 1))\n}\n\nfilenames = list.files(inFolder, pattern = \"\\\\.rData$\")\nfor (f in filenames)\n{\nprint(f)\n\nload(file.path(inFolder, f))\nimgX = imgY\n\n# look for the closest matched images\nscores = matrix(1, length(filenames))\nfor (i in 1:length(filenames))\n{\nload(file.path(inFolder, filenames[i]))\nrmse = 1\nif (nrow(imgY) >= nrow(imgX) && ncol(imgY) >= ncol(imgX))\n{\nimgY = imgY[1:nrow(imgX), 1:ncol(imgX)]\nrmse = sqrt(mean( (imgX - imgY)^2 ))\n}\nscores[i] = rmse\n}\n\ndat = matrix(1, ncol(imgX) * nrow(imgX), 4)\nfor (i in 1:4)\n{\nf2 = filenames[order(scores)][i]\nload(file.path(inFolder, f2))\ndat[,i] = img2vec(imgY)\n}\n\ndat2 = apply(dat, 1, median)\n#dat2 = apply(dat, 1, mean)\n\nimgOut = matrix(dat2, nrow(imgX), ncol(imgX))\nwritePNG(imgOut, file.path(outFolder2, gsub(\".rData\", \".png\", f)))\nsave(imgOut, file = file.path(outFolder, f))\n}\n\n</pre>\n<p>This information leakage halved the RMSE, and I suspect that it was what allowed the top two competitors to obtain RMSE scores less than 1%.</p>\n<p>So that&#8217;s it for this series of blogs. I learned a lot from my first Kaggle competition. Competing against others, and sharing ideas is a fun way to learn.</p>\n",
  "wfw:commentRss": "https://colinpriest.com/2015/11/15/an-even-dozen-denoising-dirty-documents-part-12/feed/",
  "slash:comments": 3,
  "media:thumbnail": "",
  "media:content": [
    {
      "media:title": "dozeneggs"
    },
    {
      "media:title": "colinpriest1966"
    },
    {
      "media:title": "dozeneggs"
    },
    {
      "media:title": "20151115 ensemble structure"
    },
    {
      "media:title": "20151115 output 1"
    },
    {
      "media:title": "20151115 output 2"
    }
  ]
}