{
  "title": "Classifying the Iris Data Set with PyTorch",
  "link": "",
  "published": "2020-09-27T00:00:00-05:00",
  "updated": "2020-09-27T00:00:00-05:00",
  "id": "http://janakiev.com/blog/pytorch-iris",
  "content": "<p>In this short article we will have a look on how to use <a href=\"https://pytorch.org/\">PyTorch</a> with the Iris data set. We will create and train a neural network with <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.Linear.html\">Linear</a> layers and we will employ a <a href=\"https://en.wikipedia.org/wiki/Softmax_function\">Softmax</a> activation function and the <a href=\"https://arxiv.org/abs/1412.6980\">Adam</a> optimizer.</p>\n\n<h1 id=\"data-preperation\">Data Preperation</h1>\n\n<p>To prepare the data, we will use a <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\">StandardScaler</a> to remove the mean and scale the features to unit variance. Finally we want to perform a <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split\">train test split</a> to compare our results later on.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"n\">np</span>\n<span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"n\">pd</span>\n<span class=\"kn\">import</span> <span class=\"nn\">matplotlib.pyplot</span> <span class=\"k\">as</span> <span class=\"n\">plt</span>\n\n<span class=\"n\">plt</span><span class=\"p\">.</span><span class=\"n\">style</span><span class=\"p\">.</span><span class=\"n\">use</span><span class=\"p\">(</span><span class=\"s\">'ggplot'</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">from</span> <span class=\"nn\">sklearn.datasets</span> <span class=\"kn\">import</span> <span class=\"n\">load_iris</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sklearn.model_selection</span> <span class=\"kn\">import</span> <span class=\"n\">train_test_split</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sklearn.preprocessing</span> <span class=\"kn\">import</span> <span class=\"n\">StandardScaler</span>\n\n<span class=\"n\">iris</span> <span class=\"o\">=</span> <span class=\"n\">load_iris</span><span class=\"p\">()</span>\n<span class=\"n\">X</span> <span class=\"o\">=</span> <span class=\"n\">iris</span><span class=\"p\">[</span><span class=\"s\">'data'</span><span class=\"p\">]</span>\n<span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">iris</span><span class=\"p\">[</span><span class=\"s\">'target'</span><span class=\"p\">]</span>\n<span class=\"n\">names</span> <span class=\"o\">=</span> <span class=\"n\">iris</span><span class=\"p\">[</span><span class=\"s\">'target_names'</span><span class=\"p\">]</span>\n<span class=\"n\">feature_names</span> <span class=\"o\">=</span> <span class=\"n\">iris</span><span class=\"p\">[</span><span class=\"s\">'feature_names'</span><span class=\"p\">]</span>\n\n<span class=\"c1\"># Scale data to have mean 0 and variance 1 \n# which is importance for convergence of the neural network\n</span><span class=\"n\">scaler</span> <span class=\"o\">=</span> <span class=\"n\">StandardScaler</span><span class=\"p\">()</span>\n<span class=\"n\">X_scaled</span> <span class=\"o\">=</span> <span class=\"n\">scaler</span><span class=\"p\">.</span><span class=\"n\">fit_transform</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Split the data set into training and testing\n</span><span class=\"n\">X_train</span><span class=\"p\">,</span> <span class=\"n\">X_test</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">,</span> <span class=\"n\">y_test</span> <span class=\"o\">=</span> <span class=\"n\">train_test_split</span><span class=\"p\">(</span>\n    <span class=\"n\">X_scaled</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">test_size</span><span class=\"o\">=</span><span class=\"mf\">0.2</span><span class=\"p\">,</span> <span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<h1 id=\"visualize-the-data\">Visualize the Data</h1>\n\n<p>Let’s take a look at our data to see what we are dealing with.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">fig</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">ax1</span><span class=\"p\">,</span> <span class=\"n\">ax2</span><span class=\"p\">)</span> <span class=\"o\">=</span> <span class=\"n\">plt</span><span class=\"p\">.</span><span class=\"n\">subplots</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">figsize</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">6</span><span class=\"p\">))</span>\n<span class=\"k\">for</span> <span class=\"n\">target</span><span class=\"p\">,</span> <span class=\"n\">target_name</span> <span class=\"ow\">in</span> <span class=\"nb\">enumerate</span><span class=\"p\">(</span><span class=\"n\">names</span><span class=\"p\">):</span>\n    <span class=\"n\">X_plot</span> <span class=\"o\">=</span> <span class=\"n\">X</span><span class=\"p\">[</span><span class=\"n\">y</span> <span class=\"o\">==</span> <span class=\"n\">target</span><span class=\"p\">]</span>\n    <span class=\"n\">ax1</span><span class=\"p\">.</span><span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">X_plot</span><span class=\"p\">[:,</span> <span class=\"mi\">0</span><span class=\"p\">],</span> <span class=\"n\">X_plot</span><span class=\"p\">[:,</span> <span class=\"mi\">1</span><span class=\"p\">],</span> \n             <span class=\"n\">linestyle</span><span class=\"o\">=</span><span class=\"s\">'none'</span><span class=\"p\">,</span> \n             <span class=\"n\">marker</span><span class=\"o\">=</span><span class=\"s\">'o'</span><span class=\"p\">,</span> \n             <span class=\"n\">label</span><span class=\"o\">=</span><span class=\"n\">target_name</span><span class=\"p\">)</span>\n<span class=\"n\">ax1</span><span class=\"p\">.</span><span class=\"n\">set_xlabel</span><span class=\"p\">(</span><span class=\"n\">feature_names</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">])</span>\n<span class=\"n\">ax1</span><span class=\"p\">.</span><span class=\"n\">set_ylabel</span><span class=\"p\">(</span><span class=\"n\">feature_names</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">])</span>\n<span class=\"n\">ax1</span><span class=\"p\">.</span><span class=\"n\">axis</span><span class=\"p\">(</span><span class=\"s\">'equal'</span><span class=\"p\">)</span>\n<span class=\"n\">ax1</span><span class=\"p\">.</span><span class=\"n\">legend</span><span class=\"p\">();</span>\n\n<span class=\"k\">for</span> <span class=\"n\">target</span><span class=\"p\">,</span> <span class=\"n\">target_name</span> <span class=\"ow\">in</span> <span class=\"nb\">enumerate</span><span class=\"p\">(</span><span class=\"n\">names</span><span class=\"p\">):</span>\n    <span class=\"n\">X_plot</span> <span class=\"o\">=</span> <span class=\"n\">X</span><span class=\"p\">[</span><span class=\"n\">y</span> <span class=\"o\">==</span> <span class=\"n\">target</span><span class=\"p\">]</span>\n    <span class=\"n\">ax2</span><span class=\"p\">.</span><span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">X_plot</span><span class=\"p\">[:,</span> <span class=\"mi\">2</span><span class=\"p\">],</span> <span class=\"n\">X_plot</span><span class=\"p\">[:,</span> <span class=\"mi\">3</span><span class=\"p\">],</span> \n             <span class=\"n\">linestyle</span><span class=\"o\">=</span><span class=\"s\">'none'</span><span class=\"p\">,</span> \n             <span class=\"n\">marker</span><span class=\"o\">=</span><span class=\"s\">'o'</span><span class=\"p\">,</span> \n             <span class=\"n\">label</span><span class=\"o\">=</span><span class=\"n\">target_name</span><span class=\"p\">)</span>\n<span class=\"n\">ax2</span><span class=\"p\">.</span><span class=\"n\">set_xlabel</span><span class=\"p\">(</span><span class=\"n\">feature_names</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">])</span>\n<span class=\"n\">ax2</span><span class=\"p\">.</span><span class=\"n\">set_ylabel</span><span class=\"p\">(</span><span class=\"n\">feature_names</span><span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">])</span>\n<span class=\"n\">ax2</span><span class=\"p\">.</span><span class=\"n\">axis</span><span class=\"p\">(</span><span class=\"s\">'equal'</span><span class=\"p\">)</span>\n<span class=\"n\">ax2</span><span class=\"p\">.</span><span class=\"n\">legend</span><span class=\"p\">();</span>\n</code></pre></div></div>\n\n<p><img src=\"/assets/pytorch_iris_files/output_5_0.png\" alt=\"png\" /></p>\n\n<h1 id=\"configure-neural-network-models\">Configure Neural Network Models</h1>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torch.nn.functional</span> <span class=\"k\">as</span> <span class=\"n\">F</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torch.nn</span> <span class=\"k\">as</span> <span class=\"n\">nn</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torch.autograd</span> <span class=\"kn\">import</span> <span class=\"n\">Variable</span>\n</code></pre></div></div>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">class</span> <span class=\"nc\">Model</span><span class=\"p\">(</span><span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">Module</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"nf\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">input_dim</span><span class=\"p\">):</span>\n        <span class=\"nb\">super</span><span class=\"p\">(</span><span class=\"n\">Model</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"p\">).</span><span class=\"n\">__init__</span><span class=\"p\">()</span>\n        <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">layer1</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"n\">input_dim</span><span class=\"p\">,</span> <span class=\"mi\">50</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">layer2</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">50</span><span class=\"p\">,</span> <span class=\"mi\">50</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">layer3</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">50</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">)</span>\n        \n    <span class=\"k\">def</span> <span class=\"nf\">forward</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">):</span>\n        <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">F</span><span class=\"p\">.</span><span class=\"n\">relu</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">layer1</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">))</span>\n        <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">F</span><span class=\"p\">.</span><span class=\"n\">relu</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">layer2</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">))</span>\n        <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">F</span><span class=\"p\">.</span><span class=\"n\">softmax</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">layer3</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">),</span> <span class=\"n\">dim</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"n\">x</span>\n</code></pre></div></div>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">model</span>     <span class=\"o\">=</span> <span class=\"n\">Model</span><span class=\"p\">(</span><span class=\"n\">X_train</span><span class=\"p\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">])</span>\n<span class=\"n\">optimizer</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">optim</span><span class=\"p\">.</span><span class=\"n\">Adam</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">.</span><span class=\"n\">parameters</span><span class=\"p\">(),</span> <span class=\"n\">lr</span><span class=\"o\">=</span><span class=\"mf\">0.001</span><span class=\"p\">)</span>\n<span class=\"n\">loss_fn</span>   <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">CrossEntropyLoss</span><span class=\"p\">()</span>\n<span class=\"n\">model</span>\n</code></pre></div></div>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>Model(\n  (layer1): Linear(in_features=4, out_features=50, bias=True)\n  (layer2): Linear(in_features=50, out_features=50, bias=True)\n  (layer3): Linear(in_features=50, out_features=3, bias=True)\n)\n</code></pre></div></div>\n\n<h1 id=\"train-the-model\">Train the Model</h1>\n\n<p>Now its time to run the training. In order to track progress more efficiently, we can use <a href=\"https://github.com/tqdm/tqdm\">tqdm</a>, which is a great and easy to use progress bar for our training epochs.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">import</span> <span class=\"nn\">tqdm</span>\n\n<span class=\"n\">EPOCHS</span>  <span class=\"o\">=</span> <span class=\"mi\">100</span>\n<span class=\"n\">X_train</span> <span class=\"o\">=</span> <span class=\"n\">Variable</span><span class=\"p\">(</span><span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">from_numpy</span><span class=\"p\">(</span><span class=\"n\">X_train</span><span class=\"p\">)).</span><span class=\"nb\">float</span><span class=\"p\">()</span>\n<span class=\"n\">y_train</span> <span class=\"o\">=</span> <span class=\"n\">Variable</span><span class=\"p\">(</span><span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">from_numpy</span><span class=\"p\">(</span><span class=\"n\">y_train</span><span class=\"p\">)).</span><span class=\"nb\">long</span><span class=\"p\">()</span>\n<span class=\"n\">X_test</span>  <span class=\"o\">=</span> <span class=\"n\">Variable</span><span class=\"p\">(</span><span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">from_numpy</span><span class=\"p\">(</span><span class=\"n\">X_test</span><span class=\"p\">)).</span><span class=\"nb\">float</span><span class=\"p\">()</span>\n<span class=\"n\">y_test</span>  <span class=\"o\">=</span> <span class=\"n\">Variable</span><span class=\"p\">(</span><span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">from_numpy</span><span class=\"p\">(</span><span class=\"n\">y_test</span><span class=\"p\">)).</span><span class=\"nb\">long</span><span class=\"p\">()</span>\n\n<span class=\"n\">loss_list</span>     <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">zeros</span><span class=\"p\">((</span><span class=\"n\">EPOCHS</span><span class=\"p\">,))</span>\n<span class=\"n\">accuracy_list</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">zeros</span><span class=\"p\">((</span><span class=\"n\">EPOCHS</span><span class=\"p\">,))</span>\n\n<span class=\"k\">for</span> <span class=\"n\">epoch</span> <span class=\"ow\">in</span> <span class=\"n\">tqdm</span><span class=\"p\">.</span><span class=\"n\">trange</span><span class=\"p\">(</span><span class=\"n\">EPOCHS</span><span class=\"p\">):</span>\n    <span class=\"n\">y_pred</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"p\">(</span><span class=\"n\">X_train</span><span class=\"p\">)</span>\n    <span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"n\">loss_fn</span><span class=\"p\">(</span><span class=\"n\">y_pred</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">)</span>\n    <span class=\"n\">loss_list</span><span class=\"p\">[</span><span class=\"n\">epoch</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">loss</span><span class=\"p\">.</span><span class=\"n\">item</span><span class=\"p\">()</span>\n    \n    <span class=\"c1\"># Zero gradients\n</span>    <span class=\"n\">optimizer</span><span class=\"p\">.</span><span class=\"n\">zero_grad</span><span class=\"p\">()</span>\n    <span class=\"n\">loss</span><span class=\"p\">.</span><span class=\"n\">backward</span><span class=\"p\">()</span>\n    <span class=\"n\">optimizer</span><span class=\"p\">.</span><span class=\"n\">step</span><span class=\"p\">()</span>\n    \n    <span class=\"k\">with</span> <span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">no_grad</span><span class=\"p\">():</span>\n        <span class=\"n\">y_pred</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"p\">(</span><span class=\"n\">X_test</span><span class=\"p\">)</span>\n        <span class=\"n\">correct</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">argmax</span><span class=\"p\">(</span><span class=\"n\">y_pred</span><span class=\"p\">,</span> <span class=\"n\">dim</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span> <span class=\"o\">==</span> <span class=\"n\">y_test</span><span class=\"p\">).</span><span class=\"nb\">type</span><span class=\"p\">(</span><span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">FloatTensor</span><span class=\"p\">)</span>\n        <span class=\"n\">accuracy_list</span><span class=\"p\">[</span><span class=\"n\">epoch</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">correct</span><span class=\"p\">.</span><span class=\"n\">mean</span><span class=\"p\">()</span>\n</code></pre></div></div>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>100%|██████████| 100/100 [00:00&lt;00:00, 407.99it/s]\n</code></pre></div></div>\n\n<h1 id=\"plot-accuracy-and-loss-from-training\">Plot Accuracy and Loss from Training</h1>\n\n<p>Let’s have a look how our models perform. We can clearly see that adding more nodes makes the training perform better.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">fig</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">ax1</span><span class=\"p\">,</span> <span class=\"n\">ax2</span><span class=\"p\">)</span> <span class=\"o\">=</span> <span class=\"n\">plt</span><span class=\"p\">.</span><span class=\"n\">subplots</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">figsize</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">12</span><span class=\"p\">,</span> <span class=\"mi\">6</span><span class=\"p\">),</span> <span class=\"n\">sharex</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">)</span>\n\n<span class=\"n\">ax1</span><span class=\"p\">.</span><span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">accuracy_list</span><span class=\"p\">)</span>\n<span class=\"n\">ax1</span><span class=\"p\">.</span><span class=\"n\">set_ylabel</span><span class=\"p\">(</span><span class=\"s\">\"validation accuracy\"</span><span class=\"p\">)</span>\n<span class=\"n\">ax2</span><span class=\"p\">.</span><span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">loss_list</span><span class=\"p\">)</span>\n<span class=\"n\">ax2</span><span class=\"p\">.</span><span class=\"n\">set_ylabel</span><span class=\"p\">(</span><span class=\"s\">\"validation loss\"</span><span class=\"p\">)</span>\n<span class=\"n\">ax2</span><span class=\"p\">.</span><span class=\"n\">set_xlabel</span><span class=\"p\">(</span><span class=\"s\">\"epochs\"</span><span class=\"p\">);</span>\n</code></pre></div></div>\n\n<p><img src=\"/assets/pytorch_iris_files/output_13_0.png\" alt=\"png\" /></p>\n\n<h1 id=\"show-roc-curve\">Show ROC Curve</h1>\n\n<p>We have previously split the data and we can compare now with the <a href=\"https://en.wikipedia.org/wiki/Receiver_operating_characteristic\">Receiver Operating Characteristic (ROC)</a> how well the models perform. The ROC plot compares the false positive rate with the true positive rate. We additionally compute for each model the <a href=\"https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve\">Area under the curve (AUC)</a>, where <code class=\"language-plaintext highlighter-rouge\">auc = 1</code> is perfect classification and <code class=\"language-plaintext highlighter-rouge\">auc = 0.5</code> is random guessing (for a two class problem). To prepare the test data, we need to use the <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">OneHotEncoder</a> to encode the integer features into a <a href=\"https://en.wikipedia.org/wiki/One-hot\">One-hot</a> vector which we then flatten with <a href=\"https://numpy.org/doc/stable/reference/generated/numpy.ravel.html\">numpy.ravel()</a> for <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html\">sklearn.metrics.roc_curve()</a>.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">from</span> <span class=\"nn\">sklearn.metrics</span> <span class=\"kn\">import</span> <span class=\"n\">roc_curve</span><span class=\"p\">,</span> <span class=\"n\">auc</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sklearn.preprocessing</span> <span class=\"kn\">import</span> <span class=\"n\">OneHotEncoder</span>\n\n<span class=\"n\">plt</span><span class=\"p\">.</span><span class=\"n\">figure</span><span class=\"p\">(</span><span class=\"n\">figsize</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">))</span>\n<span class=\"n\">plt</span><span class=\"p\">.</span><span class=\"n\">plot</span><span class=\"p\">([</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"s\">'k--'</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># One hot encoding\n</span><span class=\"n\">enc</span> <span class=\"o\">=</span> <span class=\"n\">OneHotEncoder</span><span class=\"p\">()</span>\n<span class=\"n\">Y_onehot</span> <span class=\"o\">=</span> <span class=\"n\">enc</span><span class=\"p\">.</span><span class=\"n\">fit_transform</span><span class=\"p\">(</span><span class=\"n\">y_test</span><span class=\"p\">[:,</span> <span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">newaxis</span><span class=\"p\">]).</span><span class=\"n\">toarray</span><span class=\"p\">()</span>\n\n<span class=\"k\">with</span> <span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">no_grad</span><span class=\"p\">():</span>\n    <span class=\"n\">y_pred</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"p\">(</span><span class=\"n\">X_test</span><span class=\"p\">).</span><span class=\"n\">numpy</span><span class=\"p\">()</span>\n    <span class=\"n\">fpr</span><span class=\"p\">,</span> <span class=\"n\">tpr</span><span class=\"p\">,</span> <span class=\"n\">threshold</span> <span class=\"o\">=</span> <span class=\"n\">roc_curve</span><span class=\"p\">(</span><span class=\"n\">Y_onehot</span><span class=\"p\">.</span><span class=\"n\">ravel</span><span class=\"p\">(),</span> <span class=\"n\">y_pred</span><span class=\"p\">.</span><span class=\"n\">ravel</span><span class=\"p\">())</span>\n    \n<span class=\"n\">plt</span><span class=\"p\">.</span><span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">fpr</span><span class=\"p\">,</span> <span class=\"n\">tpr</span><span class=\"p\">,</span> <span class=\"n\">label</span><span class=\"o\">=</span><span class=\"s\">'AUC = {:.3f}'</span><span class=\"p\">.</span><span class=\"nb\">format</span><span class=\"p\">(</span><span class=\"n\">auc</span><span class=\"p\">(</span><span class=\"n\">fpr</span><span class=\"p\">,</span> <span class=\"n\">tpr</span><span class=\"p\">)))</span>\n<span class=\"n\">plt</span><span class=\"p\">.</span><span class=\"n\">xlabel</span><span class=\"p\">(</span><span class=\"s\">'False positive rate'</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"p\">.</span><span class=\"n\">ylabel</span><span class=\"p\">(</span><span class=\"s\">'True positive rate'</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"p\">.</span><span class=\"n\">title</span><span class=\"p\">(</span><span class=\"s\">'ROC curve'</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"p\">.</span><span class=\"n\">legend</span><span class=\"p\">();</span>\n</code></pre></div></div>\n\n<p><img src=\"/assets/pytorch_iris_files/output_15_0.png\" alt=\"png\" /></p>",
  "author": {
    "name": "Nikolai Janakiev"
  },
  "category": [
    "",
    "",
    "",
    ""
  ],
  "summary": "In this short article we will have a look on how to use PyTorch with the Iris data set. We will create and train a neural network with Linear layers and we will employ a Softmax activation function and the Adam optimizer.",
  "media:thumbnail": "",
  "media:content": ""
}