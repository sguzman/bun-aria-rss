{
  "title": "Beyond Numpy Arrays in Python",
  "link": "",
  "updated": "2018-05-27T00:00:00+00:00",
  "id": "https://mrocklin.github.io/blog/work/2018/05/27/beyond-numpy",
  "content": "<h2 id=\"executive-summary\">Executive Summary</h2>\n\n<p>In recent years Python’s array computing ecosystem has grown organically to support\nGPUs, sparse, and distributed arrays.\nThis is wonderful and a great example of the growth that can occur in decentralized open source development.</p>\n\n<p>However to solidify this growth and apply it across the ecosystem we now need to do some central planning\nto move from a pair-wise model where packages need to know about each other\nto an ecosystem model where packages can negotiate by developing and adhering to community-standard protocols.</p>\n\n<p>With moderate effort we can define a subset of the Numpy API that works well across all of them,\nallowing the ecosystem to more smoothly transition between hardware.\nThis post describes the opportunities and challenges to accomplish this.</p>\n\n<p>We start by discussing two kinds of libraries:</p>\n\n<ol>\n  <li>Libraries that <em>implement</em> the Numpy API</li>\n  <li>Libraries that <em>consume</em> the Numpy API and build new functionality on top\nof it</li>\n</ol>\n\n<h2 id=\"libraries-that-implement-the-numpy-api\">Libraries that Implement the Numpy API</h2>\n\n<p>The Numpy array is one of the foundations of the numeric Python ecosystem,\nand serves as the standard model for similar libraries in other languages.\nToday it is used to analyze satellite and biomedical imagery, financial models,\ngenomes, oceans and the atmosphere, super-computer simulations,\nand data from thousands of other domains.</p>\n\n<p>However, Numpy was designed several years ago,\nand its implementation is no longer optimal for some modern hardware,\nparticularly multi-core workstations, many-core GPUs, and distributed clusters.</p>\n\n<p>Fortunately other libraries implement the Numpy array API on these other architectures:</p>\n\n<ul>\n  <li><a href=\"https://cupy.chainer.org/\">CuPy</a>: implements the Numpy API on GPUs with CUDA</li>\n  <li><a href=\"https://sparse.pydata.org/\">Sparse</a>: implements the Numpy API for sparse arrays that are mostly zeros</li>\n  <li><a href=\"https://dask.pydata.org/\">Dask array</a>: implements the Numpy API in parallel for multi-core workstations or distributed clusters</li>\n</ul>\n\n<p>So even when the Numpy implementation is no longer ideal,\nthe <em>Numpy API</em> lives on in successor projects.</p>\n\n<p><em>Note: the Numpy implementation remains ideal most of the time.\nDense in-memory arrays are still the common case.\nThis blogpost is about the minority of cases where Numpy is not ideal</em></p>\n\n<p>So today we can write code similar code between all of\nNumpy, GPU, sparse, and parallel arrays:</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"n\">np</span>\n<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">(...)</span>  <span class=\"c1\"># Runs on a single CPU\n</span><span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">x</span><span class=\"p\">.</span><span class=\"n\">T</span><span class=\"p\">.</span><span class=\"n\">dot</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">log</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span> <span class=\"o\">+</span> <span class=\"mi\">1</span><span class=\"p\">)</span>\n<span class=\"n\">z</span> <span class=\"o\">=</span> <span class=\"n\">y</span> <span class=\"o\">-</span> <span class=\"n\">y</span><span class=\"p\">.</span><span class=\"n\">mean</span><span class=\"p\">(</span><span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">z</span><span class=\"p\">[:</span><span class=\"mi\">5</span><span class=\"p\">])</span>\n\n<span class=\"kn\">import</span> <span class=\"nn\">cupy</span> <span class=\"k\">as</span> <span class=\"n\">cp</span>\n<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">cp</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">(...)</span>  <span class=\"c1\"># Runs on a GPU\n</span><span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">x</span><span class=\"p\">.</span><span class=\"n\">T</span><span class=\"p\">.</span><span class=\"n\">dot</span><span class=\"p\">(</span><span class=\"n\">cp</span><span class=\"p\">.</span><span class=\"n\">log</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span> <span class=\"o\">+</span> <span class=\"mi\">1</span><span class=\"p\">)</span>\n<span class=\"n\">z</span> <span class=\"o\">=</span> <span class=\"n\">y</span> <span class=\"o\">-</span> <span class=\"n\">y</span><span class=\"p\">.</span><span class=\"n\">mean</span><span class=\"p\">(</span><span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">z</span><span class=\"p\">[:</span><span class=\"mi\">5</span><span class=\"p\">].</span><span class=\"n\">get</span><span class=\"p\">())</span>\n\n<span class=\"kn\">import</span> <span class=\"nn\">dask.array</span> <span class=\"k\">as</span> <span class=\"n\">da</span>\n<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">da</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">(...)</span>  <span class=\"c1\"># Runs on many CPUs\n</span><span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">x</span><span class=\"p\">.</span><span class=\"n\">T</span><span class=\"p\">.</span><span class=\"n\">dot</span><span class=\"p\">(</span><span class=\"n\">da</span><span class=\"p\">.</span><span class=\"n\">log</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span> <span class=\"o\">+</span> <span class=\"mi\">1</span><span class=\"p\">)</span>\n<span class=\"n\">z</span> <span class=\"o\">=</span> <span class=\"n\">y</span> <span class=\"o\">-</span> <span class=\"n\">y</span><span class=\"p\">.</span><span class=\"n\">mean</span><span class=\"p\">(</span><span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">z</span><span class=\"p\">[:</span><span class=\"mi\">5</span><span class=\"p\">].</span><span class=\"n\">compute</span><span class=\"p\">())</span>\n\n<span class=\"p\">...</span>\n</code></pre></div></div>\n\n<p>Additionally, each of the deep learning frameworks\n(TensorFlow, PyTorch, MXNet)\nhas a Numpy-like thing that is <em>similar-ish</em> to Numpy’s API,\nbut definitely not trying to be an exact match.</p>\n\n<h2 id=\"libraries-that-consume-and-extend-the-numpy-api\">Libraries that consume and extend the Numpy API</h2>\n\n<p>At the same time as the development of Numpy APIs for different hardware,\nmany libraries today build algorithmic functionality on top of the Numpy API:</p>\n\n<ol>\n  <li><a href=\"http://xarray.pydata.org/en/stable/\">XArray</a>\nfor labeled and indexed collections of arrays</li>\n  <li><a href=\"https://github.com/hips/autograd\">Autograd</a> and\n<a href=\"https://github.com/google/tangent/\">Tangent</a>:\nfor automatic differentiation</li>\n  <li><a href=\"http://tensorly.org/stable/index.html\">TensorLy</a>\nfor higher order array factorizations</li>\n  <li>\n    <p><a href=\"https://dask.pydata.org\">Dask array</a>\nwhich coordinates many Numpy-like arrays into a logical parallel array</p>\n\n    <p>(dask array both <em>consumes</em> and <em>implements</em> the Numpy API)</p>\n  </li>\n  <li><a href=\"http://optimized-einsum.readthedocs.io/en/latest/\">Opt Einsum</a>\nfor more efficient einstein summation operations</li>\n  <li>…</li>\n</ol>\n\n<p>These projects and more enhance array computing in Python,\nbuilding on new features beyond what Numpy itself provides.</p>\n\n<p>There are also projects like Pandas, Scikit-Learn, and SciPy,\nthat use Numpy’s in-memory internal representation.\nWe’re going to ignore these libraries for this blogpost\nand focus on those libraries that only use the high-level Numpy API\nand not the low-level representation.</p>\n\n<h2 id=\"opportunities-and-challenges\">Opportunities and Challenges</h2>\n\n<p>Given the two groups of projects:</p>\n\n<ol>\n  <li>New libraries that <em>implement</em> the Numpy API\n(CuPy, Sparse, Dask array)</li>\n  <li>New libraries that <em>consume</em> and <em>extend</em> the Numpy API\n(XArray, Autograd/tangent, TensorLy, Einsum)</li>\n</ol>\n\n<p>We want to use them together, applying Autograd to CuPy, TensorLy to Sparse,\nand so on, including all future implementations that might follow.\nThis is challenging.</p>\n\n<p>Unfortunately,\nwhile all of the array implementations APIs are <em>very similar</em> to Numpy’s API,\nthey use different functions.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">numpy</span><span class=\"p\">.</span><span class=\"n\">sin</span> <span class=\"ow\">is</span> <span class=\"n\">cupy</span><span class=\"p\">.</span><span class=\"n\">sin</span>\n<span class=\"bp\">False</span>\n</code></pre></div></div>\n\n<p>This creates problems for the consumer libraries,\nbecause now they need to switch out which functions they use\ndepending on which array-like objects they’ve been given.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">def</span> <span class=\"nf\">f</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">):</span>\n    <span class=\"k\">if</span> <span class=\"nb\">isinstance</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"p\">.</span><span class=\"n\">ndarray</span><span class=\"p\">):</span>\n        <span class=\"k\">return</span> <span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">sin</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n    <span class=\"k\">elif</span> <span class=\"nb\">isinstance</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">cupy</span><span class=\"p\">.</span><span class=\"n\">ndarray</span><span class=\"p\">):</span>\n        <span class=\"k\">return</span> <span class=\"n\">cupy</span><span class=\"p\">.</span><span class=\"n\">sin</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n    <span class=\"k\">elif</span> <span class=\"p\">...</span>\n\n</code></pre></div></div>\n\n<p>Today each array project implements a custom plugin system\nthat they use to switch between some of the array options.\nLinks to these plugin mechanisms are below if you’re interested:</p>\n\n<ul>\n  <li><a href=\"https://github.com/pydata/xarray/blob/c346d3b7bcdbd6073cf96fdeb0710467a284a611/xarray/core/duck_array_ops.py\">xarray/core/duck_array_ops.py</a></li>\n  <li><a href=\"https://github.com/tensorly/tensorly/tree/af0700af61ca2cd104e90755d5e5033e23fd4ec4/tensorly/backend\">tensorly/backend</a></li>\n  <li><a href=\"https://github.com/HIPS/autograd/blob/bd3f92fcd4d66424be5fb6b6d3a7f9195c98eebf/autograd/numpy/numpy_vspaces.py\">autograd/numpy/numpy_vspaces.py</a></li>\n  <li><a href=\"https://github.com/google/tangent/blob/bc64848bba964c632a6da4965fb91f2f61a3cdd4/tangent/template.py\">tangent/template.py</a></li>\n  <li><a href=\"https://github.com/dask/dask/blob/8f164773cb3717b3c5ad856341205f605b8404cf/dask/array/core.py#L59-L62\">dask/array/core.py#L59-L62</a></li>\n  <li><a href=\"https://github.com/dgasmith/opt_einsum/blob/32c1b0adb50511da1b86dc98bcf169d79b44efce/opt_einsum/backends.py\">opt_einsum/backends.py</a></li>\n</ul>\n\n<p>For example XArray can use either Numpy arrays or Dask arrays.\nThis has been hugely beneficial to users of that project,\nwhich today seamlessly transition from small in-memory datasets on their laptops\nto 100TB datasets on clusters,\nall using the same programming model.\nHowever when considering adding sparse or GPU arrays to XArray’s plugin system,\nit quickly became clear that this would be expensive today.</p>\n\n<p>Building, maintaining, and extending these plugin mechanisms is <em>costly</em>.\nThe plugin systems in each project are not alike,\nso any new array implementation has to go to each library and build the same code several times.\nSimilarly, any new algorithmic library must build plugins to every ndarray implementation.\nEach library has to explicitly import and understand each other library,\nand has to adapt as those libraries change over time.\nThis coverage is not complete,\nand so users lack confidence that their applications are portable between hardware.</p>\n\n<p>Pair-wise plugin mechanisms make sense for a single project,\nbut are not an efficient choice for the full ecosystem.</p>\n\n<h2 id=\"solutions\">Solutions</h2>\n\n<p>I see two solutions today:</p>\n\n<ol>\n  <li>\n    <p>Build a new library that holds dispatch-able versions of all of the relevant Numpy functions\nand convince everyone to use it instead of Numpy internally</p>\n  </li>\n  <li>\n    <p>Build this dispatch mechanism into Numpy itself</p>\n  </li>\n</ol>\n\n<p>Each has challenges.</p>\n\n<h3 id=\"build-a-new-centralized-plugin-library\">Build a new centralized plugin library</h3>\n\n<p>We can build a new library,\nhere called <code class=\"language-plaintext highlighter-rouge\">arrayish</code>,\nthat holds dispatch-able versions of all of the relevant Numpy functions.\nWe then convince everyone to use it instead of Numpy internally.</p>\n\n<p>So in each array-like library’s codebase we write code like the following:</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\"># inside numpy's codebase\n</span><span class=\"kn\">import</span> <span class=\"nn\">arrayish</span>\n<span class=\"kn\">import</span> <span class=\"nn\">numpy</span>\n<span class=\"o\">@</span><span class=\"n\">arrayish</span><span class=\"p\">.</span><span class=\"n\">sin</span><span class=\"p\">.</span><span class=\"n\">register</span><span class=\"p\">(</span><span class=\"n\">numpy</span><span class=\"p\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"p\">.</span><span class=\"n\">sin</span><span class=\"p\">)</span>\n<span class=\"o\">@</span><span class=\"n\">arrayish</span><span class=\"p\">.</span><span class=\"n\">cos</span><span class=\"p\">.</span><span class=\"n\">register</span><span class=\"p\">(</span><span class=\"n\">numpy</span><span class=\"p\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"p\">.</span><span class=\"n\">cos</span><span class=\"p\">)</span>\n<span class=\"o\">@</span><span class=\"n\">arrayish</span><span class=\"p\">.</span><span class=\"n\">dot</span><span class=\"p\">.</span><span class=\"n\">register</span><span class=\"p\">(</span><span class=\"n\">numpy</span><span class=\"p\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"p\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"p\">.</span><span class=\"n\">dot</span><span class=\"p\">)</span>\n<span class=\"p\">...</span>\n</code></pre></div></div>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\"># inside cupy's codebase\n</span><span class=\"kn\">import</span> <span class=\"nn\">arrayish</span>\n<span class=\"kn\">import</span> <span class=\"nn\">cupy</span>\n<span class=\"o\">@</span><span class=\"n\">arrayish</span><span class=\"p\">.</span><span class=\"n\">sin</span><span class=\"p\">.</span><span class=\"n\">register</span><span class=\"p\">(</span><span class=\"n\">cupy</span><span class=\"p\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">cupy</span><span class=\"p\">.</span><span class=\"n\">sin</span><span class=\"p\">)</span>\n<span class=\"o\">@</span><span class=\"n\">arrayish</span><span class=\"p\">.</span><span class=\"n\">cos</span><span class=\"p\">.</span><span class=\"n\">register</span><span class=\"p\">(</span><span class=\"n\">cupy</span><span class=\"p\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">cupy</span><span class=\"p\">.</span><span class=\"n\">cos</span><span class=\"p\">)</span>\n<span class=\"o\">@</span><span class=\"n\">arrayish</span><span class=\"p\">.</span><span class=\"n\">dot</span><span class=\"p\">.</span><span class=\"n\">register</span><span class=\"p\">(</span><span class=\"n\">cupy</span><span class=\"p\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">cupy</span><span class=\"p\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">cupy</span><span class=\"p\">.</span><span class=\"n\">dot</span><span class=\"p\">)</span>\n<span class=\"p\">...</span>\n</code></pre></div></div>\n\n<p>and so on for Dask, Sparse, and any other Numpy-like libraries.</p>\n\n<p>In all of the algorithm libraries (like XArray, autograd, TensorLy, …)\nwe use arrayish instead of Numpy</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\"># inside XArray's codebase\n# import numpy\n</span><span class=\"kn\">import</span> <span class=\"nn\">arrayish</span> <span class=\"k\">as</span> <span class=\"n\">numpy</span>\n</code></pre></div></div>\n\n<p>This is the same plugin solution as before,\nbut now we build a community standard plugin system\nthat hopefully all of the projects can agree to use.</p>\n\n<p>This reduces the big <code class=\"language-plaintext highlighter-rouge\">n by m</code> cost of maintaining several plugin systems,\nto a more manageable <code class=\"language-plaintext highlighter-rouge\">n plus m</code> cost of using a single plugin system in each library.\nThis centralized project would also benefit, perhaps,\nfrom being better maintained than any individual project is likely to do on its own.</p>\n\n<p>However this has costs:</p>\n\n<ol>\n  <li>Getting many different projects to agree on a new standard is hard</li>\n  <li>\n    <p>Algorithmic projects will need to start using arrayish internally,\nadding new imports like the following:</p>\n\n    <div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">import</span> <span class=\"nn\">arrayish</span> <span class=\"k\">as</span> <span class=\"n\">numpy</span>\n</code></pre></div>    </div>\n\n    <p>And this wll certainly cause some complications interally</p>\n  </li>\n  <li>Someone needs to build an maintain the central infrastructure</li>\n</ol>\n\n<p><a href=\"https://github.com/hameerabbasi\">Hameer Abbasi</a>\nput together a rudimentary prototype for arrayish here:\n<a href=\"https://github.com/hameerabbasi/arrayish\">github.com/hameerabbasi/arrayish</a>.\nThere has been some discussion about this topic, using XArray+Sparse as an example, in\n<a href=\"https://github.com/pydata/sparse/issues/1\">pydata/sparse #1</a></p>\n\n<h3 id=\"dispatch-from-within-numpy\">Dispatch from within Numpy</h3>\n\n<p>Alternatively, the central dispatching mechanism could live within Numpy itself.</p>\n\n<p>Numpy functions could learn to hand control over to their arguments,\nallowing the array implementations to take over when possible.\nThis would allow existing Numpy code to work on externally developed array implementations.</p>\n\n<p>There is precedent for this.\nThe <a href=\"https://docs.scipy.org/doc/numpy/reference/arrays.classes.html#numpy.class.__array_ufunc__\"><strong>array_ufunc</strong></a> protocol\nallows any class that defines the <code class=\"language-plaintext highlighter-rouge\">__array_ufunc__</code> method\nto take control of any Numpy ufunc like <code class=\"language-plaintext highlighter-rouge\">np.sin</code> or <code class=\"language-plaintext highlighter-rouge\">np.exp</code>.\nNumpy reductions like <code class=\"language-plaintext highlighter-rouge\">np.sum</code> already look for <code class=\"language-plaintext highlighter-rouge\">.sum</code> methods on their arguments and defer to them if possible.</p>\n\n<p>Some array projects, like Dask and Sparse, already implement the <code class=\"language-plaintext highlighter-rouge\">__array_ufunc__</code> protocol.\nThere is also <a href=\"https://github.com/cupy/cupy/pull/1247\">an open PR for CuPy</a>.\nHere is an example showing Numpy functions on Dask arrays cleanly.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"n\">np</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">import</span> <span class=\"nn\">dask.array</span> <span class=\"k\">as</span> <span class=\"n\">da</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">da</span><span class=\"p\">.</span><span class=\"n\">ones</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"n\">chunks</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">5</span><span class=\"p\">,))</span>  <span class=\"c1\"># A Dask array\n</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">np</span><span class=\"p\">.</span><span class=\"nb\">sum</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">exp</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">))</span>             <span class=\"c1\"># Apply Numpy function to a Dask array\n</span><span class=\"n\">dask</span><span class=\"p\">.</span><span class=\"n\">array</span><span class=\"o\">&lt;</span><span class=\"nb\">sum</span><span class=\"o\">-</span><span class=\"n\">aggregate</span><span class=\"p\">,</span> <span class=\"n\">shape</span><span class=\"o\">=</span><span class=\"p\">(),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">float64</span><span class=\"p\">,</span> <span class=\"n\">chunksize</span><span class=\"o\">=</span><span class=\"p\">()</span><span class=\"o\">&gt;</span>  <span class=\"c1\"># get a Dask array\n</span></code></pre></div></div>\n\n<p><em>I recommend that all Numpy-API compatible array projects implement the <code class=\"language-plaintext highlighter-rouge\">__array_ufunc__</code> protocol.</em></p>\n\n<p>This works for many functions, but not all.\nOther operations like <code class=\"language-plaintext highlighter-rouge\">tensordot</code>, <code class=\"language-plaintext highlighter-rouge\">concatenate</code>, and <code class=\"language-plaintext highlighter-rouge\">stack</code>\noccur frequently in algorithmic code but are not covered here.</p>\n\n<p>This solution avoids the community challenges of the <code class=\"language-plaintext highlighter-rouge\">arrayish</code> solution above.\nEveryone is accustomed to aligning themselves to Numpy’s decisions,\nand relatively little code would need to be rewritten.</p>\n\n<p>The challenge with this approach is that historically\nNumpy has moved more slowly than the rest of the ecosystem.\nFor example the <code class=\"language-plaintext highlighter-rouge\">__array_ufunc__</code> protocol mentioned above\nwas discussed for several years before it was merged.\nFortunately Numpy has recently\n<a href=\"https://www.numfocus.org/blog/numpy-receives-first-ever-funding-thanks-to-moore-foundation\">received</a>\n<a href=\"https://bids.berkeley.edu/news/bids-receives-sloan-foundation-grant-contribute-numpy-development\">funding</a>\nto help it make changes like this more rapidly.\nThe full time developers hired under this funding have just started though,\nand it’s not clear how much of a priority this work is for them at first.</p>\n\n<p>For what it’s worth I’d prefer to see this Numpy protocol solution take hold.</p>\n\n<h2 id=\"final-thoughts\">Final Thoughts</h2>\n\n<p>In recent years Python’s array computing ecosystem has grown organically to support\nGPUs, sparse, and distributed arrays.\nThis is wonderful and a great example of the growth that can occur in decentralized open source development.</p>\n\n<p>However to solidify this growth and apply it across the ecosystem we now need to do some central planning\nto move from a pair-wise model where packages need to know about each other\nto an ecosystem model where packages can negotiate by developing and adhering to community-standard protocols.</p>\n\n<p>The community has done this transition before\n(Numeric + Numarray -&gt; Numpy, the Scikit-Learn fit/predict API, etc..)\nusually with surprisingly positive results.</p>\n\n<p>The open questions I have today are the following:</p>\n\n<ol>\n  <li>How quickly can Numpy adapt to this demand for protocols\nwhile still remaining stable for its existing role as foundation of the ecosystem</li>\n  <li>What algorithmic domains can be written in a cross-hardware way\nthat depends only on the high-level Numpy API,\nand doesn’t require specialization at the data structure level.\nClearly some domains exist (XArray, automatic differentiation),\nbut how common are these?</li>\n  <li>Once a standard protocol is in place,\nwhat other array-like implementations might arise?\nIn-memory compression?  Probabilistic?  Symbolic?</li>\n</ol>\n\n<h2 id=\"update\">Update</h2>\n\n<p>After discussing this topic at the\n<a href=\"https://scisprints.github.io/#may-numpy-developer-sprint\">May NumPy Developer Sprint</a>\nat <a href=\"https://bids.berkeley.edu/\">BIDS</a>\na few of us have drafted a Numpy Enhancement Proposal (NEP)\n<a href=\"https://github.com/numpy/numpy/pull/11189\">available here</a>.</p>"
}