{
  "title": "Convolution channel separation and frequency sub-bands aggregation for music genre classification. (arXiv:2211.01599v1 [eess.AS])",
  "link": "http://arxiv.org/abs/2211.01599",
  "description": "<p>In music, short-term features such as pitch and tempo constitute long-term\nsemantic features such as melody and narrative. A music genre classification\n(MGC) system should be able to analyze these features. In this research, we\npropose a novel framework that can extract and aggregate both short- and\nlong-term features hierarchically. Our framework is based on ECAPA-TDNN, where\nall the layers that extract short-term features are affected by the layers that\nextract long-term features because of the back-propagation training. To prevent\nthe distortion of short-term features, we devised the convolution channel\nseparation technique that separates short-term features from long-term feature\nextraction paths. To extract more diverse features from our framework, we\nincorporated the frequency sub-bands aggregation method, which divides the\ninput spectrogram along frequency bandwidths and processes each segment. We\nevaluated our framework using the Melon Playlist dataset which is a large-scale\ndataset containing 600 times more data than GTZAN which is a widely used\ndataset in MGC studies. As the result, our framework achieved 70.4% accuracy,\nwhich was improved by 16.9% compared to a conventional framework.\n</p>",
  "dc:creator": "<a href=\"http://arxiv.org/find/eess/1/au:+Heo_J/0/1/0/all/0/1\">Jungwoo Heo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shin_H/0/1/0/all/0/1\">Hyun-seo Shin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kim_J/0/1/0/all/0/1\">Ju-ho Kim</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lim_C/0/1/0/all/0/1\">Chan-yeong Lim</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yu_H/0/1/0/all/0/1\">Ha-Jin Yu</a>"
}