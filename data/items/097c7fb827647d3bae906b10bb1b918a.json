{
  "title": "A Tutorial on Multi-Armed Bandits: To Explore or Exploit?",
  "description": "<p>The Multi-Armed Bandit problem is a classical Reinforcement Learning that shows the exploration-exploitation trade-off. In this tutorial, we will look at the problem of advertorial design and we will answer the following question: what advertorials will lead to the highest gains?</p><p>Suppose we have an advertorial with a few parameters:</p>",
  "link": "https://www.data-blogger.com/a-tutorial-on-multi-armed-bandits-to-explore-or-exploit/",
  "guid": "622d004a092f120001a24e34",
  "category": [
    "Mathematics",
    "Machine Learning"
  ],
  "dc:creator": "Kevin Jacobs",
  "pubDate": "Thu, 18 Nov 2021 00:00:00 GMT",
  "media:content": "",
  "content:encoded": "<img src=\"https://images.unsplash.com/photo-1525018667593-176858caed6a?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDN8fHNsb3QlMjBtYWNoaW5lc3xlbnwwfHx8fDE2NDcxMTYzOTc&ixlib=rb-1.2.1&q=80&w=2000\" alt=\"A Tutorial on Multi-Armed Bandits: To Explore or Exploit?\"><p>The Multi-Armed Bandit problem is a classical Reinforcement Learning that shows the exploration-exploitation trade-off. In this tutorial, we will look at the problem of advertorial design and we will answer the following question: what advertorials will lead to the highest gains?</p><p>Suppose we have an advertorial with a few parameters:</p><ul><li>The color of the button (green, red or blue)</li><li>The font size (small or large)</li><li>The font style (bold, underlined or normal)</li></ul><p>What design will work the best? Notice that it is not efficient to randomly choose values for our design. In that case, we can observe a lot of information (explore), but we will not be able to exploit the best performing designs (exploit). On the other extreme, we can only exploit the best working solution, but then we won&#x2019;t be able to test out new designs and the performance of our advertorial might drop. What is the best trade-off between exploring and exploiting?</p><p>Now, we will create an agent which will click the advertorial in some cases but won&#x2019;t click the advertorial in other cases. The agent has a preference for certain advertorials:</p><pre><code class=\"language-python\">import numpy as np\nimport json\n\n# All the options we can choose from\noptions = {\n    'button': ['red', 'green', 'blue'],\n    'size': ['small', 'large'],\n    'style': ['bold', 'underline', 'normal']\n}\n\nclass SimpleAgent:\n    \"\"\"This agent has a preference for large, red buttons with either a bold or normal style.\"\"\"\n    \n    def __init__(self):\n        self.parameters = {\n            'button': {\n                'red': 0.8,       # The agent will click on red buttons with a probability of 80%\n                'green': 0.1,     # The agent will click on green buttons with a probability of 10%\n                'blue': 0.0       # The agent will never click on blue buttons\n            },\n            'size': {\n                'small': 0.1,     # The agent will click when the advertorial has a small font with a probability of 10%\n                'large': 0.9      # The agent will click when the advertorial has a large font with a probability of 90%\n            },\n            'style': {\n                'bold': 0.8,      # The agent will click when there is a bold font with a probability of 80%\n                'underline': 0.1, # The agent will click when there is an underlined font with a probability of 10%\n                'normal': 0.9     # The agent will click when there is a normal font with a probability of 90%\n            }\n        }\n    \n    def does_click(self, design):\n        \"\"\"This function returns True if the agent does click on the advertorial, otherwise False.\"\"\"\n        for param in design:\n            random_number = np.random.random()\n            design_value = self.parameters[param][design[param]]\n            # Determine whether the agent has clicked for this particular parameter\n            # The agent has not clicked when the random number is less than the probability for the given parameter\n            if random_number < 1. - design_value:\n                return False\n        # The agent will click when this statement is reached!\n        return True\n    \ndef compute_ctr(agent, design, n=100):\n    \"\"\"Compute the Click Through Rate (CTR) for a given agent and a given design and for a number of runs.\"\"\"\n    clicks = 0\n    for _ in range(n):\n        clicks += int(agent.does_click(design))\n    return float(clicks) / float(n)\n\n# Setup the agent\nagent = SimpleAgent()\n\n# Create a design\ndesign = {\n    'button': 'red',\n    'size': 'large',\n    'style': 'bold'\n}\n\n# Now we will test the design\n# We now that our agent \n# Compute the CTR (Click Through Rate)\nprint(f'The design got a CTR of {compute_ctr(agent, design) * 100:.0f}% for design {json.dumps(design)}')\n\n# Create a second design with a small font - such that the agent will click less often\ndesign_small_font = {\n    'button': 'red',\n    'size': 'small',\n    'style': 'bold'\n}\n\n# Now we will test this design\nprint(f'The design got a CTR of {compute_ctr(agent, design_small_font) * 100:.0f}% for design {json.dumps(design_small_font)}')</code></pre><p>This code has the following output (and it will slightly differ at every run since it is probabilistic):</p><pre><code>The design got a CTR of 58% for design {\"button\": \"red\", \"size\": \"large\", \"style\": \"bold\"}\nThe design got a CTR of 10% for design {\"button\": \"red\", \"size\": \"small\", \"style\": \"bold\"}</code></pre><p>You can see that the agent prefers the first design more than the second design since the font size differs. Can our algorithm also spot this pattern?</p><h2 id=\"the-algorithm-thompson-sampling\">The algorithm: Thompson Sampling</h2><p>Now we will take a look at Thompson Sampling: an algorithm that is a solution to the Multi-Armed Bandit problem. The algorithm will start with a prior (Beta) distribution in which it will select each design option with the same probability. A red button will appear as often as a green button and a blue button. Then, the algorithm will observe clicks and will update the probability distribution accordingly. If there are more clicks while there is a red button, then the red button will be shown more often. The following code implements the sampling method:</p><pre><code class=\"language-python\">class ThompsonSampler:\n    \n    def __init__(self, options):\n        self.params = {\n            option: {\n                value: {\n                    False: 1.,\n                    True: 1.\n                }\n                for value in options[option]\n            }\n            for option in options\n        }\n        \n    def observe(self, design, has_clicked):\n        for option in design:\n            self.params[option][design[option]][has_clicked] += 1\n        \n    def __str__(self):\n        return json.dumps(self.params, indent=4)\n    \nsampler = ThompsonSampler(options)\ndesign = {\n    'button': 'red',\n    'size': 'large',\n    'style': 'bold'\n}\nsampler.observe(design=design, has_clicked=True)\nprint(sampler)</code></pre><p>This code produces the following output:</p><pre><code>{\n    \"button\": {\n        \"red\": {\n            \"false\": 1.0,\n            \"true\": 2.0\n        },\n        \"green\": {\n            \"false\": 1.0,\n            \"true\": 1.0\n        },\n        \"blue\": {\n            \"false\": 1.0,\n            \"true\": 1.0\n        }\n    },\n    \"size\": {\n        \"small\": {\n            \"false\": 1.0,\n            \"true\": 1.0\n        },\n        \"large\": {\n            \"false\": 1.0,\n            \"true\": 2.0\n        }\n    },\n    \"style\": {\n        \"bold\": {\n            \"false\": 1.0,\n            \"true\": 2.0\n        },\n        \"underline\": {\n            \"false\": 1.0,\n            \"true\": 1.0\n        },\n        \"normal\": {\n            \"false\": 1.0,\n            \"true\": 1.0\n        }\n    }\n}</code></pre><p>It started with a prior distribution where all values were set to &#x201C;1&#x201D;. After observing a click for the specified design, the counts were adjusted accordingly.</p><h2 id=\"design-generator\">Design generator</h2><p>Now, we will create a design generator that uses the sampler as input and generates a design based on the output of the sampler:</p><pre><code class=\"language-python\">class DesignGenerator:\n    \n    def __init__(self, sampler):\n        self.sampler = sampler\n        \n    def get_scores(self, option):\n        scores = []\n        for value in self.sampler.params[option]:\n            a = self.sampler.params[option][value][True]\n            b = self.sampler.params[option][value][False]\n            scores.append(np.random.beta(a, b))\n        scores = np.array(scores)\n        scores /= scores.sum()\n        return scores\n        \n    def generate(self):\n        design = {}\n        for option in self.sampler.params:\n            items = list(self.sampler.params[option].keys())\n            scores = self.get_scores(option)\n            design[option] = np.random.choice(items, p=scores)\n        return design\n    \nsampler = ThompsonSampler(options)\ndesign_generator = DesignGenerator(sampler)\ndesign_generator.generate()</code></pre><p>As you can see, it will generate a random design for us. But, the designs will become more tailored after observing more clicks. The following design was generated after running the code:</p><pre><code>{'button': 'green', 'size': 'small', 'style': 'normal'}</code></pre><h2 id=\"the-results\">The results</h2><p>Will Thompson sampling be able to figure out the preferences of the agent? With the following code, we can observe the statistics for the button colour:</p><pre><code class=\"language-python\">import pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n    \nsampler = ThompsonSampler(options)\nadvertorial_maker = DesignGenerator(sampler)\nbutton_scores = []\nfor i in range(300):\n    button_scores.append(dict(zip(options['button'], advertorial_maker.get_scores('button').tolist())))\n    design = advertorial_maker.generate()\n    does_click = agent.does_click(design)\n    sampler.observe(design, does_click)\n\ndf_button = pd.DataFrame.from_records(button_scores)\ndf_button.plot(style='.', color=['red', 'green', 'blue'], ms=20, alpha=0.5)\nplt.title('Button color')\nplt.xlabel('Number of observations')\nplt.ylabel('Sampling probability')\nplt.savefig('button_color.png')\nplt.show()</code></pre><p>This code observes the agent 300 times. And yes, it seems that the algorithm correctly predicts that a red button should be more important than a green button or a blue button. Also, notice that the algorithm still explores: it will still be able to produce a green button in some cases:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://www.data-blogger.com/wp-content/uploads/2021/11/button_color.png.webp\" class=\"kg-image\" alt=\"A Tutorial on Multi-Armed Bandits: To Explore or Exploit?\" loading=\"lazy\"><figcaption>The statistics for the button color.</figcaption></figure><p>Also, the font size statistics can be found:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://www.data-blogger.com/wp-content/uploads/2021/11/font_size.png\" class=\"kg-image\" alt=\"A Tutorial on Multi-Armed Bandits: To Explore or Exploit?\" loading=\"lazy\"><figcaption>Font size statistics.</figcaption></figure><p>Notice that the algorithm has found a preference for large font sizes after 300 observations. And lastly, we can also see the statistics for the font style:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://www.data-blogger.com/wp-content/uploads/2021/11/font_style.png.webp\" class=\"kg-image\" alt=\"A Tutorial on Multi-Armed Bandits: To Explore or Exploit?\" loading=\"lazy\"><figcaption>Statistics for the font style.</figcaption></figure><p>This indeed matches the preference of our agent! The agent liked the normal style and the bold style but dislikes underlined fonts.</p><h2 id=\"conclusion\">Conclusion</h2><p>Thank you for following this tutorial! In this tutorial, we have seen a solution for the Multi-Armed Bandit problem and applied it for advertorial optimisation. If you liked this blog post, please share it or leave a comment below.</p>"
}