{
  "title": "Notes on Kafka in Python",
  "link": "",
  "updated": "2017-10-10T00:00:00+00:00",
  "id": "https://mrocklin.github.io/blog/work/2017/10/10/kafka-python",
  "content": "<h2 id=\"summary\">Summary</h2>\n\n<p><img src=\"https://kafka.apache.org/images/logo.png\" align=\"right\" width=\"40%\" /></p>\n\n<p>I recently investigated the state of Python libraries for Kafka.  This blogpost\ncontains my findings.</p>\n\n<p>Both <a href=\"http://pykafka.readthedocs.io/en/latest/\">PyKafka</a> and\n<a href=\"https://github.com/confluentinc/confluent-kafka-python\">confluent-kafka</a> have\nmature implementations and are maintained by invested companies.\nConfluent-kafka is generally faster while PyKafka is arguably better designed\nand documented for Python usability.</p>\n\n<p>Conda packages are now available for both.  I hope to extend one or both to\nsupport asynchronous workloads with Tornado.</p>\n\n<p><em>Disclaimer: I am not an expert in this space.  I have no strong affiliation\nwith any of these projects.  This is a report based on my experience of the\npast few weeks.  I don’t encourage anyone to draw conclusions from this work.\nI encourage people to investigate on their own.</em></p>\n\n<h2 id=\"introduction\">Introduction</h2>\n\n<p><a href=\"https://kafka.apache.org/\">Apache Kafka</a> is a common data system for streaming\narchitectures.  It manages rolling buffers of byte messages and provides a\nscalable mechanism to publish or subscribe to those buffers in real time.\nWhile Kafka was originally designed within the JVM space the fact that it only\nmanages bytes makes it easy to access from native code systems like C/C++ and\nPython.</p>\n\n<h2 id=\"python-options\">Python Options</h2>\n\n<p>Today there are three independent Kafka implementations in Python, two of which\nare optionally backed by a C implementation,\n<a href=\"https://github.com/edenhill/librdkafka\">librdkafka</a>, for speed:</p>\n\n<ul>\n  <li>\n    <p><a href=\"https://kafka-python.readthedocs.io/en/master/\">kafka-python</a>: The first on\nthe scene, a Pure Python Kafka client with robust documentation and an API\nthat is fairly faithful to the original Java API.  This implementation has\nthe most stars on GitHub, the most active development team (by number of\ncommitters) but also lacks a connection to the fast C library.  I’ll admit\nthat I didn’t spend enough time on this project to judge it well because of\nthis.</p>\n  </li>\n  <li>\n    <p><a href=\"http://pykafka.readthedocs.io/en/latest/\">PyKafka</a>: The second\nimplementation chronologically.  This library is maintained by\n<a href=\"https://www.parse.ly/\">Parse.ly</a> a web analytics company that heavily uses\nboth streaming systems and Python.  PyKafka’s API is more creative and\ndesigned to follow common Python idioms rather than the Java API.  PyKafka\nhas both a pure Python implementation and connections to the low-level\n<code class=\"language-plaintext highlighter-rouge\">librdkafka</code> C library for increased performance.</p>\n  </li>\n  <li>\n    <p><a href=\"https://github.com/confluentinc/confluent-kafka-python\">Confluent-kafka</a>:\nIs the final implementation chronologically.  It is maintained by\n<a href=\"https://www.confluent.io/home\">Confluent</a>, the primary for-profit company\nthat supports and maintains Kafka.  This library is the fastest, but also\nthe least accessible from a Python perspective.  This implementation is\nwritten in CPython extensions, and the documentation is minimal.  However,\nif you are coming from the Java API then this is entirely consistent with\nthat experience, so that documentation probably suffices.</p>\n  </li>\n</ul>\n\n<h2 id=\"performance\">Performance</h2>\n\n<p>Confluent-kafka message-consumption bandwidths are around 50% higher and\nmessage-production bandwidths are around 3x higher than PyKafka, both of which\nare significantly higher than kafka-python.  I’m taking these numbers from\n<a href=\"http://activisiongamescience.github.io/2016/06/15/Kafka-Client-Benchmarking/\">this\nblogpost</a>\nwhich gives benchmarks comparing the three libraries.  The primary numeric\nresults follow below:</p>\n\n<p><em>Note: It’s worth noting that this blogpost was moving smallish 100 byte messages\naround.  I would hope that Kafka would perform better (closer to network\nbandwidths) when messages are of a decent size.</em></p>\n\n<h3 id=\"producer-throughput\">Producer Throughput</h3>\n\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time_in_seconds</th>\n      <th>MBs/s</th>\n      <th>Msgs/s</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>confluent_kafka_producer</th>\n      <td>5.4</td>\n      <td>17</td>\n      <td>183000</td>\n    </tr>\n    <tr>\n      <th>pykafka_producer_rdkafka</th>\n      <td>16</td>\n      <td>6.1</td>\n      <td>64000</td>\n    </tr>\n    <tr>\n      <th>pykafka_producer</th>\n      <td>57</td>\n      <td>1.7</td>\n      <td>17000</td>\n    </tr>\n    <tr>\n      <th>python_kafka_producer</th>\n      <td>68</td>\n      <td>1.4</td>\n      <td>15000</td>\n    </tr>\n  </tbody>\n</table>\n\n<h3 id=\"consumer-throughput\">Consumer Throughput</h3>\n\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time_in_seconds</th>\n      <th>MBs/s</th>\n      <th>Msgs/s</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>confluent_kafka_consumer</th>\n      <td>3.8</td>\n      <td>25</td>\n      <td>261000</td>\n    </tr>\n    <tr>\n      <th>pykafka_consumer_rdkafka</th>\n      <td>6.1</td>\n      <td>17</td>\n      <td>164000</td>\n    </tr>\n    <tr>\n      <th>pykafka_consumer</th>\n      <td>29</td>\n      <td>3.2</td>\n      <td>34000</td>\n    </tr>\n    <tr>\n      <th>python_kafka_consumer</th>\n      <td>26</td>\n      <td>3.6</td>\n      <td>38000</td>\n    </tr>\n  </tbody>\n</table>\n\n<p><em>Note: I discovered this article on <a href=\"https://github.com/Parsely/pykafka/issues/559\">parsely/pykafka #559</a>, which has good conversation about the three libraries.</em></p>\n\n<p>I profiled PyKafka in these cases and it doesn’t appear that these code paths\nhave yet been optimized.  I expect that modest effort could close that gap\nconsiderably.  This difference seems to be more from lack of interest than any\nhard design constraint.</p>\n\n<p>It’s not clear how critical these speeds are.  According to the PyKafka\nmaintainers at Parse.ly they haven’t actually turned on the librdkafka\noptimizations in their internal pipelines, and are instead using the slow\nPure Python implementation, which is apparently more than fast enough for\ncommon use.  Getting messages out of Kafka just isn’t their bottleneck.  It may\nbe that these 250,000 messages/sec limits are not significant in most\napplications.  I suspect that this matters more in bulk analysis workloads than\nin online applications.</p>\n\n<h2 id=\"pythonic-vs-java-apis\">Pythonic vs Java APIs</h2>\n\n<p>It took me a few times to get confluent-kafka to work.  It wasn’t clear what\ninformation I needed to pass to the constructor to connect to Kafka and when I\ngave the wrong information I received no message that I had done anything\nincorrectly.  Docstrings and documentation were both minimal.  In contrast,\nPyKafka’s API and error messages quickly led me to correct behavior and I was\nup and running within a minute.</p>\n\n<p>However, I persisted with confluent-kafka, found the right <a href=\"https://kafka.apache.org/documentation/#api\">Java\ndocumentation</a>, and eventually did\nget things up and running.  Once this happened everything fell into place and I\nwas able to easily build applications with Confluent-kafka that were both\nsimple and fast.</p>\n\n<h2 id=\"development-experience\">Development experience</h2>\n\n<p>I would like to add asynchronous support to one or both of these libraries so\nthat they can read or write data in a non-blocking fashion and play nicely with\nother asynchronous systems like Tornado or Asyncio.  I started investigating\nthis with both libraries on GitHub.</p>\n\n<h3 id=\"developers\">Developers</h3>\n\n<p>Both libraries have a maintainer who is somewhat responsive and whose time is\nfunded by the parent company.  Both maintainers seem active on a day-to-day\nbasis and handle contributions from external developers.</p>\n\n<p>Both libraries are fully active with a common pattern of a single main dev\nmerging work from a number of less active developers.  Distributions of commits\nover the last six months look similar:</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>confluent-kafka-python$ git shortlog -ns --since \"six months ago\"\n38  Magnus Edenhill\n5  Christos Trochalakis\n4  Ewen Cheslack-Postava\n1  Simon Wahlgren\n\npykafka$ git shortlog -ns --since \"six months ago\"\n52  Emmett Butler\n23  Emmett J. Butler\n20  Marc-Antoine Parent\n18  Tanay Soni\n5  messense\n1  Erik Stephens\n1  Jeff Widman\n1  Prateek Shrivastava\n1  aleatha\n1  zpcui\n</code></pre></div></div>\n\n<h3 id=\"codebase\">Codebase</h3>\n\n<p>In regards to the codebases I found that PyKafka was easier to hack on for a\nfew reasons:</p>\n\n<ol>\n  <li>Most of PyKafka is written in Python rather than C extensions, and so it is\nmore accessible to a broader development base.  I find that Python C\nextensions are not pleasant to work with, even if you are comfortable with\nC.</li>\n  <li>PyKafka appears to be much more extensively tested.  PyKafka actually spins\nup a local Kafka instance to do comprehensive integration tests while\nConfluent-kafka seems to only test API without actually running against a\nreal Kakfa instance.</li>\n  <li>For what it’s worth, PyKafka maintainers <a href=\"https://github.com/Parsely/pykafka/issues/731\">responded\nquickly</a> to an issue on\nTornado.  Confluent-kafka maintainers still have not responded to a\n<a href=\"https://github.com/confluentinc/confluent-kafka-python/issues/100#issuecomment-334152182\">comment on an existing Tornado\nissue</a>,\neven though that comment had signfiicnatly more content (a working\nprototype).</li>\n</ol>\n\n<p><em>To be clear, no maintainer has any responsibility to answer my questions on\ngithub.  They are likely busy with other things that are of more relevance to\ntheir particular mandate.</em></p>\n\n<h2 id=\"conda-packages\">Conda packages</h2>\n\n<p>I’ve pushed/updated recipes for both packages on conda-forge.  You can install\nthem as follows:</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>conda install -c conda-forge pykafka                 # Linux, Mac, Windows\nconda install -c conda-forge python-confluent-kafka  # Linux, Mac\n</code></pre></div></div>\n\n<p>In both cases this these are built against the fast <code class=\"language-plaintext highlighter-rouge\">librdkafka</code> C library\n(except on Windows) and install that library as well.</p>\n\n<h2 id=\"future-plans\">Future plans</h2>\n\n<p>I’ve recently started work on streaming systems and pipelines for\n<a href=\"http://dask.pydata.org/en/latest/\">Dask</a>, so I’ll probably continue to\ninvestigate this space.  I’m still torn between the two implementations.  There\nare strong reasons to use either of them.</p>\n\n<p>Culturally I am drawn to Parse.ly’s PyKafka library.  They’re clearly Python\ndevelopers writing for Python users.  However the costs of using a non-Pythonic\nsystem here just aren’t that large (Kafka’s API is small), and Confluent’s\ninterests are more aligned with investing in Kafka long term than are\nParse.ly’s.</p>"
}