{
  "title": "Dask Scaling Limits",
  "link": "",
  "updated": "2018-06-26T00:00:00+00:00",
  "id": "https://mrocklin.github.io/blog/work/2018/06/26/dask-scaling-limits",
  "content": "<p><em>This work is supported by <a href=\"http://anaconda.com\">Anaconda Inc.</a></em></p>\n\n<h2 id=\"history\">History</h2>\n\n<p>For the first year of Dask’s life it focused exclusively on single node\nparallelism.  We felt then that efficiently supporting 100+GB datasets on\npersonal laptops or 1TB datasets on large workstations was a sweet spot for\nproductivity, especially when avoiding the pain of deploying and configuring\ndistributed systems.  We still believe in the efficiency of single-node\nparallelism, but in the years since, Dask has extended itself to support larger\ndistributed systems.</p>\n\n<p>After that first year, Dask focused equally on both single-node and distributed\nparallelism.  We maintain <a href=\"http://dask.pydata.org/en/latest/scheduling.html\">two entirely separate\nschedulers</a>, one optimized for\neach case.  This allows Dask to be very simple to use on single machines, but\nalso scale up to thousand-node clusters and 100+TB datasets when needed with\nthe same API.</p>\n\n<p>Dask’s distributed system has a single central scheduler and many distributed\nworkers.  This is a common architecture today that scales out to a few thousand\nnodes.  Roughly speaking Dask scales about the same as a system like Apache\nSpark, but less well than a high-performance system like MPI.</p>\n\n<h2 id=\"an-example\">An Example</h2>\n\n<p>Most Dask examples in blogposts or talks are on modestly sized datasets,\nusually in the 10-50GB range.  This, combined with Dask’s history with\nmedium-data on single-nodes may have given people a more humble impression of\nDask than is appropriate.</p>\n\n<p>As a small nudge, here is an example using Dask to interact with 50 36-core\nnodes on an artificial terabyte dataset.</p>\n\n<iframe width=\"700\" height=\"394\" src=\"https://www.youtube.com/embed/nH_AQo8WdKw\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen=\"\"></iframe>\n\n<p>This is a common size for a typical modestly sized Dask cluster.  We usually\nsee Dask deployment sizes either in the tens of machines (usually with Hadoop\nstyle or ad-hoc enterprise clusters), or in the few-thousand range (usually\nwith high performance computers or cloud deployments).  We’re showing the\nmodest case here just due to lack of resources.  Everything in that example\nshould work fine scaling out a couple extra orders of magnitude.</p>\n\n<h2 id=\"challenges-to-scaling-out\">Challenges to Scaling Out</h2>\n\n<p>For the rest of the article we’ll talk about common causes that we see today\nthat get in the way of scaling out.  These are collected from experience\nworking both with people in the open source community, as well as private\ncontracts.</p>\n\n<h3 id=\"simple-map-reduce-style\">Simple Map-Reduce style</h3>\n\n<p>If you’re doing simple map-reduce style parallelism then things will be pretty\nsmooth out to a large number of nodes.  However, there are still some\nlimitations to keep in mind:</p>\n\n<ol>\n  <li>\n    <p>The scheduler will have at least one, and possibly a few connections open\nto each worker.  You’ll want to ensure that your machines can have many\nopen file handles at once.  Some Linux distributions cap this at 1024 by\ndefault, but it is easy to change.</p>\n  </li>\n  <li>\n    <p>The scheduler has an overhead of around 200 microseconds per task.\nSo if each task takes one second then your scheduler can saturate 5000\ncores, but if each task takes only 100ms then your scheduler can only\nsaturate around 500 cores, and so on.  Task duration imposes an inversely\nproportional constraint on scaling.</p>\n\n    <p>If you want to scale larger than this then your tasks will need to\nstart doing more work in each task to avoid overhead.  Often this involves\nmoving inner for loops within tasks rather than spreading them out to many\ntasks.</p>\n  </li>\n</ol>\n\n<h3 id=\"more-complex-algorithms\">More complex algorithms</h3>\n\n<p>If you’re doing more complex algorithms (which is common among Dask users) then\nmany more things can break along the way.  High performance computing isn’t\nabout doing any one thing well, it’s about doing <em>nothing badly</em>.  This section\nlists a few issues that arise for larger deployments:</p>\n\n<ol>\n  <li>\n    <p>Dask collection algorithms may be suboptimal.</p>\n\n    <p>The parallel algorithms in Dask-array/bag/dataframe/ml are <em>pretty</em> good,\nbut as Dask scales out to larger clusters and its algorithms are used by\nmore domains we invariably find that small corners of the API fail beyond a\ncertain point.  Luckily these are usually pretty easy to fix after they are\nreported.</p>\n  </li>\n  <li>\n    <p>The graph size may grow too large for the scheduler</p>\n\n    <p>The metadata describing your computation has to all fit on a single\nmachine, the Dask scheduler.  This metadata, the task graph, can grow big\nif you’re not careful.  It’s nice to have a scheduler process with at least\na few gigabytes of memory if you’re going to be processing million-node\ntask graphs.  A task takes up around 1kB of memory <em>if</em> you’re careful to\navoid closing over any unnecessary local data.</p>\n  </li>\n  <li>\n    <p>The graph serialization time may become annoying for interactive use</p>\n\n    <p>Again, if you have million node task graphs you’re going to be serializaing\nthem up and passing them from the client to the scheduler.  This is <em>fine</em>,\nassuming they fit at both ends, but can take up some time and limit\ninteractivity.  If you press <code class=\"language-plaintext highlighter-rouge\">compute</code> and nothing shows up on the\ndashboard for a minute or two, this is what’s happening.</p>\n  </li>\n  <li>\n    <p>The interactive dashboard plots stop being as useful</p>\n\n    <p>Those beautiful plots on the dashboard were mostly designed for deployments\nwith 1-100 nodes, but not 1000s.  Seeing the start and stop time of every\ntask of a million-task computation just isn’t something that our brains can\nfully understand.</p>\n\n    <p>This is something that we would like to improve.  If anyone out there is\ninterested in scalable performance diagnostics, please get involved.</p>\n  </li>\n  <li>\n    <p>Other components that you rely on, like distributed storage, may also start\nto break</p>\n\n    <p>Dask provides users more power than they’re accustomed to.\nIt’s easy for them to accidentally clobber some other component of their\nsystems, like distributed storage, a local database, the network, and so\non, with too many requests.</p>\n\n    <p>Many of these systems provide abstractions that are very well tested and\nstable for normal single-machine use, but that quickly become brittle when\nyou have a thousand machines acting on them with the full creativity of a\nnovice user.  Dask provies some primitives like distributed locks and\nqueues to help control access to these resources, but it’s on the user to\nuse them well and not break things.</p>\n  </li>\n</ol>\n\n<h2 id=\"conclusion\">Conclusion</h2>\n\n<p>Dask scales happily out to tens of nodes, like in the example above, or to\nthousands of nodes, which I’m not showing here simply due to lack of resources.</p>\n\n<p>Dask provides this scalability while still maintaining the flexibility and\nfreedom to build custom systems that has defined the project since it began.\nHowever, the combination of scalability and freedom makes it hard for Dask to\nfully protect users from breaking things.  It’s much easier to protect users\nwhen you can constrain what they can do.  When users stick to standard\nworkflows like Dask dataframe or Dask array they’ll probably be ok, but when\noperating with full creativity at the thousand-node scale some expertise will\ninvariably be necessary.  We try hard to provide the diagnostics and tools\nnecessary to investigate issues and control operation.  The project is getting\nbetter at this every day, in large part due to some expert users out there.</p>\n\n<h2 id=\"a-call-for-examples\">A Call for Examples</h2>\n\n<p>Do you use Dask on more than one machine to do interesting work?\nWe’d love to hear about it either in the comments below, or in this <a href=\"https://goo.gl/forms/ueIMoGl6ZPl529203\">online\nform</a>.</p>"
}