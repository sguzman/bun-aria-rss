{
  "title": "Beyond the Best: Estimating Distribution Functionals in Infinite-Armed Bandits. (arXiv:2211.01743v1 [cs.LG])",
  "link": "http://arxiv.org/abs/2211.01743",
  "description": "<p>In the infinite-armed bandit problem, each arm's average reward is sampled\nfrom an unknown distribution, and each arm can be sampled further to obtain\nnoisy estimates of the average reward of that arm. Prior work focuses on\nidentifying the best arm, i.e., estimating the maximum of the average reward\ndistribution. We consider a general class of distribution functionals beyond\nthe maximum, and propose unified meta algorithms for both the offline and\nonline settings, achieving optimal sample complexities. We show that online\nestimation, where the learner can sequentially choose whether to sample a new\nor existing arm, offers no advantage over the offline setting for estimating\nthe mean functional, but significantly reduces the sample complexity for other\nfunctionals such as the median, maximum, and trimmed mean. The matching lower\nbounds utilize several different Wasserstein distances. For the special case of\nmedian estimation, we identify a curious thresholding phenomenon on the\nindistinguishability between Gaussian convolutions with respect to the noise\nlevel, which may be of independent interest.\n</p>",
  "dc:creator": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yifei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baharav_T/0/1/0/all/0/1\">Tavor Baharav</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1\">Yanjun Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiao_J/0/1/0/all/0/1\">Jiantao Jiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tse_D/0/1/0/all/0/1\">David Tse</a>"
}