{
  "title": "Partition and Shuffle",
  "link": "",
  "updated": "2015-03-25T00:00:00+00:00",
  "id": "https://mrocklin.github.io/blog/work/2015/03/25/Partition-and-Shuffle",
  "content": "<p><em>This work is supported by <a href=\"http://continuum.io\">Continuum Analytics</a>\nand the <a href=\"http://www.darpa.mil/program/XDATA\">XDATA Program</a>\nas part of the <a href=\"http://blaze.pydata.org\">Blaze Project</a></em></p>\n\n<p><em>This post primarily targets developers.</em></p>\n\n<p><strong>tl;dr</strong> We partition out-of-core dataframes efficiently.</p>\n\n<h2 id=\"partition-data\">Partition Data</h2>\n\n<p>Many efficient parallel algorithms require intelligently partitioned data.</p>\n\n<p>For time-series data we might partition into month-long blocks.\nFor text-indexed data we might have all of the “A”s in one group and\nall of the “B”s in another.  These divisions let us arrange work with\nforesight.</p>\n\n<p>To extend Pandas operations to larger-than-memory data efficient partition\nalgorithms are critical.  This is tricky when data doesn’t fit in memory.</p>\n\n<h2 id=\"partitioning-is-fundamentally-hard\">Partitioning is fundamentally hard</h2>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>Data locality is the root of all performance\n    -- A Good Programmer\n</code></pre></div></div>\n\n<p>Partitioning/shuffling is inherently non-local.  Every block of input data\nneeds to separate and send bits to every block of output data.  If we have a\nthousand partitions then that’s a million little partition shards to\ncommunicate.  Ouch.</p>\n\n<p><img src=\"https://mrocklin.github.io/blog/images/partition-transfer.png\" alt=\"Shuffling data between partitions\" width=\"30%\" align=\"right\" /></p>\n\n<p>Consider the following setup</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>  100GB dataset\n/ 100MB partitions\n= 1,000 input partitions\n</code></pre></div></div>\n\n<p>To partition we need shuffle data in the input partitions to a similar number of\noutput partitions</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>  1,000 input partitions\n* 1,000 output partitions\n= 1,000,000 partition shards\n</code></pre></div></div>\n\n<p>If our communication/storage of those shards has even a millisecond of latency\nthen we run into problems.</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>  1,000,000 partition shards\nx 1ms\n= 18 minutes\n</code></pre></div></div>\n\n<p>Previously I stored the partition-shards individually on the filesystem using\ncPickle.  This was a mistake.  It was very slow because it treated each of the\nmillion shards independently.  Now we aggregate shards headed for the same\nout-block and write out many at a time, bundling overhead.  We balance this\nagainst memory constraints.  This stresses both Python latencies and memory\nuse.</p>\n\n<h2 id=\"bcolz-now-for-very-small-data\">BColz, now for very small data</h2>\n\n<p>Fortunately we have a nice on-disk chunked array container that\nsupports append in Cython.  <a href=\"http://bcolz.blosc.org/\">BColz</a> (formerly BLZ,\nformerly CArray) does this for us.  It wasn’t originally designed for this\nuse case but performs admirably.</p>\n\n<p>Briefly, BColz is…</p>\n\n<ul>\n  <li>A binary store (like HDF5)</li>\n  <li>With columnar access (useful for tabular computations)</li>\n  <li>That stores data in cache-friendly sized blocks</li>\n  <li>With a focus on compression</li>\n  <li>Written mostly by Francesc Alted (PyTables) and Valentin Haenel</li>\n</ul>\n\n<p>It includes two main objects:</p>\n\n<ul>\n  <li><code class=\"language-plaintext highlighter-rouge\">carray</code>: An on-disk numpy array</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">ctable</code>: A named collection of <code class=\"language-plaintext highlighter-rouge\">carrays</code> to represent a table/dataframe</li>\n</ul>\n\n<h2 id=\"partitioned-frame\">Partitioned Frame</h2>\n\n<p>We use <code class=\"language-plaintext highlighter-rouge\">carray</code> to make a new data structure <code class=\"language-plaintext highlighter-rouge\">pframe</code> with the following\noperations:</p>\n\n<ul>\n  <li><em>Append</em> DataFrame to collection, and partition it along the index on\nknown block divisions <code class=\"language-plaintext highlighter-rouge\">blockdivs</code></li>\n  <li><em>Extract</em> DataFrame corresponding to a particular partition</li>\n</ul>\n\n<p>Internally we invent two new data structures:</p>\n\n<ul>\n  <li><code class=\"language-plaintext highlighter-rouge\">cframe</code>: Like <code class=\"language-plaintext highlighter-rouge\">ctable</code> this stores column information in a collection of\n<code class=\"language-plaintext highlighter-rouge\">carrays</code>.  Unlike <code class=\"language-plaintext highlighter-rouge\">ctable</code> this maps perfectly onto the custom\nblock structure used internally by Pandas.  For internal use only.</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">pframe</code>: A collection of <code class=\"language-plaintext highlighter-rouge\">cframes</code>, one for each partition.</li>\n</ul>\n\n<p><img src=\"https://mrocklin.github.io/blog/images/pframe-design.png\" width=\"100%\" alt=\"Partitioned Frame design\" /></p>\n\n<p>Through <code class=\"language-plaintext highlighter-rouge\">bcolz.carray</code>, <code class=\"language-plaintext highlighter-rouge\">cframe</code> manages efficient incremental storage to disk.\nPFrame partitions incoming data and feeds it to the appropriate <code class=\"language-plaintext highlighter-rouge\">cframe</code>.</p>\n\n<h2 id=\"example\">Example</h2>\n\n<p>Create test dataset</p>\n\n<figure class=\"highlight\">\n  <pre><code class=\"language-python\" data-lang=\"python\"><span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]:</span> <span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"n\">pd</span>\n<span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">]:</span> <span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"p\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">({</span><span class=\"s\">'a'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">],</span>\n<span class=\"p\">...</span>                        <span class=\"s\">'b'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"mf\">1.</span><span class=\"p\">,</span> <span class=\"mf\">2.</span><span class=\"p\">,</span> <span class=\"mf\">3.</span><span class=\"p\">,</span> <span class=\"mf\">4.</span><span class=\"p\">]},</span>\n<span class=\"p\">...</span>                       <span class=\"n\">index</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"mi\">20</span><span class=\"p\">])</span></code></pre>\n</figure>\n\n<p>Create <code class=\"language-plaintext highlighter-rouge\">pframe</code> like our test dataset, partitioning on divisions 5, 15.  Append\nthe single test dataframe.</p>\n\n<figure class=\"highlight\">\n  <pre><code class=\"language-python\" data-lang=\"python\"><span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">]:</span> <span class=\"kn\">from</span> <span class=\"nn\">pframe</span> <span class=\"kn\">import</span> <span class=\"n\">pframe</span>\n<span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">4</span><span class=\"p\">]:</span> <span class=\"n\">pf</span> <span class=\"o\">=</span> <span class=\"n\">pframe</span><span class=\"p\">(</span><span class=\"n\">like</span><span class=\"o\">=</span><span class=\"n\">df</span><span class=\"p\">,</span> <span class=\"n\">blockdivs</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"mi\">15</span><span class=\"p\">])</span>\n<span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">5</span><span class=\"p\">]:</span> <span class=\"n\">pf</span><span class=\"p\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">)</span></code></pre>\n</figure>\n\n<p>Pull out partitions</p>\n\n<figure class=\"highlight\">\n  <pre><code class=\"language-python\" data-lang=\"python\"><span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">6</span><span class=\"p\">]:</span> <span class=\"n\">pf</span><span class=\"p\">.</span><span class=\"n\">get_partition</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n<span class=\"n\">Out</span><span class=\"p\">[</span><span class=\"mi\">6</span><span class=\"p\">]:</span>\n   <span class=\"n\">a</span>  <span class=\"n\">b</span>\n<span class=\"mi\">1</span>  <span class=\"mi\">1</span>  <span class=\"mi\">1</span>\n<span class=\"mi\">4</span>  <span class=\"mi\">2</span>  <span class=\"mi\">2</span>\n\n<span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">7</span><span class=\"p\">]:</span> <span class=\"n\">pf</span><span class=\"p\">.</span><span class=\"n\">get_partition</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n<span class=\"n\">Out</span><span class=\"p\">[</span><span class=\"mi\">7</span><span class=\"p\">]:</span>\n    <span class=\"n\">a</span>  <span class=\"n\">b</span>\n<span class=\"mi\">10</span>  <span class=\"mi\">3</span>  <span class=\"mi\">3</span>\n\n<span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">8</span><span class=\"p\">]:</span> <span class=\"n\">pf</span><span class=\"p\">.</span><span class=\"n\">get_partition</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">)</span>\n<span class=\"n\">Out</span><span class=\"p\">[</span><span class=\"mi\">8</span><span class=\"p\">]:</span>\n    <span class=\"n\">a</span>  <span class=\"n\">b</span>\n<span class=\"mi\">20</span>  <span class=\"mi\">4</span>  <span class=\"mi\">4</span></code></pre>\n</figure>\n\n<p>Continue to append data…</p>\n\n<figure class=\"highlight\">\n  <pre><code class=\"language-python\" data-lang=\"python\"><span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">9</span><span class=\"p\">]:</span> <span class=\"n\">df2</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"p\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">({</span><span class=\"s\">'a'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"mi\">20</span><span class=\"p\">,</span> <span class=\"mi\">30</span><span class=\"p\">,</span> <span class=\"mi\">40</span><span class=\"p\">],</span>\n<span class=\"p\">...</span>                         <span class=\"s\">'b'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"mf\">10.</span><span class=\"p\">,</span> <span class=\"mf\">20.</span><span class=\"p\">,</span> <span class=\"mf\">30.</span><span class=\"p\">,</span> <span class=\"mf\">40.</span><span class=\"p\">]},</span>\n<span class=\"p\">...</span>                        <span class=\"n\">index</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"mi\">20</span><span class=\"p\">])</span>\n<span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">10</span><span class=\"p\">]:</span> <span class=\"n\">pf</span><span class=\"p\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">df2</span><span class=\"p\">)</span></code></pre>\n</figure>\n\n<p>… and partitions grow accordingly.</p>\n\n<figure class=\"highlight\">\n  <pre><code class=\"language-python\" data-lang=\"python\"><span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">12</span><span class=\"p\">]:</span> <span class=\"n\">pf</span><span class=\"p\">.</span><span class=\"n\">get_partition</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n<span class=\"n\">Out</span><span class=\"p\">[</span><span class=\"mi\">12</span><span class=\"p\">]:</span>\n    <span class=\"n\">a</span>   <span class=\"n\">b</span>\n<span class=\"mi\">1</span>   <span class=\"mi\">1</span>   <span class=\"mi\">1</span>\n<span class=\"mi\">4</span>   <span class=\"mi\">2</span>   <span class=\"mi\">2</span>\n<span class=\"mi\">1</span>  <span class=\"mi\">10</span>  <span class=\"mi\">10</span>\n<span class=\"mi\">4</span>  <span class=\"mi\">20</span>  <span class=\"mi\">20</span></code></pre>\n</figure>\n\n<p>We can continue this until our disk fills up.  This runs near peak I/O speeds\n(on my low-power laptop with admittedly poor I/O.)</p>\n\n<h2 id=\"performance\">Performance</h2>\n\n<p>I’ve partitioned the NYCTaxi trip dataset a lot this week and posting my\nresults to the Continuum chat with messages like the following</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>I think I've got it to work, though it took all night and my hard drive filled up.\nDown to six hours and it actually works.\nThree hours!\nBy removing object dtypes we're down to 30 minutes\n20!  This is actually usable.\nOK, I've got this to six minutes.  Thank goodness for Pandas categoricals.\nFive.\nDown to about three and a half with multithreading, but only if we stop blosc from segfaulting.\n</code></pre></div></div>\n\n<p>And thats where I am now.  It’s been a fun week.  Here is a tiny benchmark.</p>\n\n<figure class=\"highlight\">\n  <pre><code class=\"language-python\" data-lang=\"python\"><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"n\">pd</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"n\">np</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">pframe</span> <span class=\"kn\">import</span> <span class=\"n\">pframe</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"p\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">({</span><span class=\"s\">'a'</span><span class=\"p\">:</span> <span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">(</span><span class=\"mi\">1000000</span><span class=\"p\">),</span>\n                       <span class=\"s\">'b'</span><span class=\"p\">:</span> <span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">.</span><span class=\"n\">poisson</span><span class=\"p\">(</span><span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"n\">size</span><span class=\"o\">=</span><span class=\"mi\">1000000</span><span class=\"p\">),</span>\n                       <span class=\"s\">'c'</span><span class=\"p\">:</span> <span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">(</span><span class=\"mi\">1000000</span><span class=\"p\">),</span>\n                       <span class=\"s\">'d'</span><span class=\"p\">:</span> <span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">(</span><span class=\"mi\">1000000</span><span class=\"p\">).</span><span class=\"n\">astype</span><span class=\"p\">(</span><span class=\"s\">'f4'</span><span class=\"p\">)}).</span><span class=\"n\">set_index</span><span class=\"p\">(</span><span class=\"s\">'a'</span><span class=\"p\">)</span></code></pre>\n</figure>\n\n<p>Set up a pframe to match the structure of this DataFrame\nPartition index into divisions of size 0.1</p>\n\n<figure class=\"highlight\">\n  <pre><code class=\"language-python\" data-lang=\"python\"><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">pf</span> <span class=\"o\">=</span> <span class=\"n\">pframe</span><span class=\"p\">(</span><span class=\"n\">like</span><span class=\"o\">=</span><span class=\"n\">df</span><span class=\"p\">,</span>\n<span class=\"p\">...</span>             <span class=\"n\">blockdivs</span><span class=\"o\">=</span><span class=\"p\">[.</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"p\">.</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"p\">.</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"p\">.</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"p\">.</span><span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"p\">.</span><span class=\"mi\">6</span><span class=\"p\">,</span> <span class=\"p\">.</span><span class=\"mi\">7</span><span class=\"p\">,</span> <span class=\"p\">.</span><span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"p\">.</span><span class=\"mi\">9</span><span class=\"p\">],</span>\n<span class=\"p\">...</span>             <span class=\"n\">chunklen</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"o\">**</span><span class=\"mi\">15</span><span class=\"p\">)</span></code></pre>\n</figure>\n\n<p>Dump the random data into the Partition Frame one hundred times and compute\neffective bandwidths.</p>\n\n<figure class=\"highlight\">\n  <pre><code class=\"language-python\" data-lang=\"python\"><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">100</span><span class=\"p\">):</span>\n<span class=\"p\">...</span>     <span class=\"n\">pf</span><span class=\"p\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">)</span>\n\n<span class=\"n\">CPU</span> <span class=\"n\">times</span><span class=\"p\">:</span> <span class=\"n\">user</span> <span class=\"mf\">39.4</span> <span class=\"n\">s</span><span class=\"p\">,</span> <span class=\"n\">sys</span><span class=\"p\">:</span> <span class=\"mf\">3.01</span> <span class=\"n\">s</span><span class=\"p\">,</span> <span class=\"n\">total</span><span class=\"p\">:</span> <span class=\"mf\">42.4</span> <span class=\"n\">s</span>\n<span class=\"n\">Wall</span> <span class=\"n\">time</span><span class=\"p\">:</span> <span class=\"mf\">40.6</span> <span class=\"n\">s</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">pf</span><span class=\"p\">.</span><span class=\"n\">nbytes</span>\n<span class=\"mi\">2800000000</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">pf</span><span class=\"p\">.</span><span class=\"n\">nbytes</span> <span class=\"o\">/</span> <span class=\"mf\">40.6</span> <span class=\"o\">/</span> <span class=\"mf\">1e6</span>  <span class=\"c1\"># MB/s\n</span><span class=\"mf\">68.9655172413793</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">pf</span><span class=\"p\">.</span><span class=\"n\">cbytes</span> <span class=\"o\">/</span> <span class=\"mf\">40.6</span> <span class=\"o\">/</span> <span class=\"mf\">1e6</span>  <span class=\"c1\"># Actual compressed bytes on disk\n</span><span class=\"mf\">41.5172952955665</span></code></pre>\n</figure>\n\n<p>We partition and store on disk random-ish data at 68MB/s (cheating with\ncompression).  This is on my old small notebook computer with a weak processor\nand hard drive I/O bandwidth at around 100 MB/s.</p>\n\n<h2 id=\"theoretical-comparison-to-external-sort\">Theoretical Comparison to External Sort</h2>\n\n<p>There isn’t much literature to back up my approach.  That concerns me.\nThere is a lot of literature however on external sorting and they often site\nour partitioning problem as a use case.  Perhaps we should do an external sort?</p>\n\n<p>I thought I’d quickly give some reasons why I think the current approach is\ntheoretically better than an out-of-core sort; hopefully someone smarter can\ncome by and tell me why I’m wrong.</p>\n\n<p>We don’t need a full sort, we need something far weaker.   External sort\nrequires at least two passes over the data while the method above requires one\nfull pass through the data as well as one additional pass through the index\ncolumn to determine good block divisions.  These divisions should be of\n<em>approximately</em> equal size.  The <em>approximate size</em> can be pretty rough.  I\ndon’t think we would notice a variation of a factor of five in block sizes.\nTask scheduling lets us be pretty sloppy with load imbalance as long as we have\nmany tasks.</p>\n\n<p>I haven’t implemented a good external sort though so I’m only able to argue\ntheory here.  I’m likely missing important implementation details.</p>\n\n<h2 id=\"links\">Links</h2>\n\n<ul>\n  <li><a href=\"https://github.com/mrocklin/dask/tree/pframe/pframe\">PFrame code</a> lives in a dask branch at the moment.  It depends on a couple of BColz PRs (<a href=\"https://github.com/Blosc/bcolz/pull/163\">#163</a>, <a href=\"https://github.com/Blosc/bcolz/pull/166\">#164</a>)</li>\n</ul>"
}