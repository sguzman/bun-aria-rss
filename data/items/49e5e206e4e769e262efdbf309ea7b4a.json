{
  "guid": "http://blog.districtdatalabs.com/basics-of-entity-resolution#30219",
  "pubDate": "Sat, 11 Mar 2017 13:55:00 -0500",
  "link": "http://blog.districtdatalabs.com/basics-of-entity-resolution",
  "title": "Basics of Entity Resolution",
  "description": "with Python and Dedupe",
  "content:encoded": "<p>Entity resolution (ER) is the task of disambiguating records that correspond to real world entities across and within datasets. The applications of entity resolution are tremendous, particularly for public sector and federal datasets related to health, transportation, finance, law enforcement, and antiterrorism.  </p>\n\n<p>Unfortunately, the problems associated with entity resolution are equally big &mdash; as the volume and velocity of data grow, inference across networks and semantic relationships between entities becomes increasingly difficult. Data quality issues, schema variations, and idiosyncratic data collection traditions can all complicate these problems even further. When combined, such challenges amount to a substantial barrier to organizationsâ€™ ability to fully understand their data, let alone make effective use of predictive analytics to optimize targeting, thresholding, and resource management.  </p>\n\n<h3 id=\"naming-your-problem\">Naming Your Problem</h3>\n\n<p>Let us first consider what an entity is. Much as the key step in machine learning is to determine what an instance is, the key step in entity resolution is to determine what an entity is. Let's define an entity as a unique thing (a person, a business, a product) with a set of attributes that describe it (a name, an address, a shape, a title, a price, etc.). That single entity may have multiple references across data sources, such as a person with two different email addresses, a company with two different phone numbers, or a product listed on two different websites. If we want to ask questions about all the unique people, or businesses, or products in a dataset, we must find a method for producing an annotated version of that dataset that contains unique entities.</p>\n\n<p>How can we tell that these multiple references point to the same entity? What if the attributes for each entity aren't the same across references? What happens when there are more than two or three or ten references to the same entity? Which one is the main (canonical) version? Do we just throw the duplicates away?</p>\n\n<p>Each question points to a single problem, albeit one that frequently goes unnamed. Ironically, one of the problems in entity resolution is that even though it goes by a lot of different names, many people who struggle with entity resolution do not know the name of their problem.</p>\n\n<p>The three primary tasks involved in entity resolution are deduplication, record linkage, and canonicalization:    </p>\n\n<ol>\n<li><strong>Deduplication:</strong> eliminating duplicate (exact) copies of repeated data.</li>\n<li><strong>Record linkage:</strong> identifying records that reference the same entity across different sources.</li>\n<li><strong>Canonicalization:</strong> converting data with more than one possible representation into a standard form.</li>\n</ol>\n\n<p>Entity resolution is not a new problem, but thanks to Python and new machine learning libraries, it is an increasingly achievable objective. This post will explore some basic approaches to entity resolution using one of those tools, the Python Dedupe library. In this post, we will explore the basic functionalities of Dedupe, walk through how the library works under the hood, and perform a demonstration on two different datasets.</p>\n\n<h2 id=\"about-dedupe\">About Dedupe</h2>\n\n<p><a href=\"https://pypi.python.org/pypi/dedupe/1.6.5\">Dedupe</a> is a library that uses machine learning to perform deduplication and entity resolution quickly on structured data. It isn't the only tool available in Python for doing entity resolution tasks, but it is the only one (as far as we know) that conceives of entity resolution as it's primary task. In addition to removing duplicate entries from within a single dataset, Dedupe can also do record linkage across disparate datasets. Dedupe also scales fairly well &mdash; in this post we demonstrate using the library with a relatively small dataset of a few thousand records and a very large dataset of several million.</p>\n\n<h3 id=\"how-dedupe-works\">How Dedupe Works</h3>\n\n<p>Effective deduplication relies largely on domain expertise. This is for two main reasons: first, because domain experts develop a set of heuristics that enable them to conceptualize what a canonical version of a record <em>should</em> look like, even if they've never seen it in practice. Second, domain experts instinctively recognize which record subfields are most likely to uniquely identify a record; they just know where to look. As such, Dedupe works by engaging the user in labeling the data via a command line interface, and using machine learning on the resulting training data to predict similar or matching records within unseen data.    </p>\n\n<h3 id=\"testing-out-dedupe\">Testing Out Dedupe</h3>\n\n<p>Getting started with Dedupe is easy, and the developers have provided a <a href=\"https://github.com/datamade/dedupe-examples\">convenient repo</a> with examples that you can use and iterate on. Let's start by walking through the <em>csv_example.py</em> from the <em>dedupe-examples</em>. To get Dedupe running, we'll need to install <code>unidecode</code>, <code>future</code>, and <code>dedupe</code>.    </p>\n\n<p>In your terminal (we recommend doing so inside a <a href=\"https://districtdatalabs.silvrback.com/how-to-develop-quality-python-code\">virtual environment</a>):    </p>\n<div class=\"highlight\"><pre><span></span>git clone https://github.com/DistrictDataLabs/dedupe-examples.git\n<span class=\"nb\">cd</span> dedupe-examples\n\npip install unidecode\npip install future\npip install dedupe\n</pre></div>\n<p>Then we'll run the csv_example.py file to see what dedupe can do:    </p>\n<div class=\"highlight\"><pre><span></span>python csv_example.py\n</pre></div>\n<h3 id=\"blocking-and-affine-gap-distance\">Blocking and Affine Gap Distance</h3>\n\n<p>Let's imagine we own an online retail business, and we are developing a new recommendation engine that mines our existing customer data to come up with good recommendations for products that our existing and new customers might like to buy. Our dataset is a purchase history log where customer information is represented by attributes like name, telephone number, address, and order history. The database we've been using to log purchases assigns a new unique ID for every customer interaction.</p>\n\n<p>But it turns out we're a great business, so we have a lot of repeat customers! We'd like to be able to aggregate the order history information by customer so that we can build a good recommender system with the data we have. That aggregation is easy if every customer's information is duplicated exactly in every purchase log. But what if it looks something like the table below?   </p>\n\n<p><img alt=\"Silvrback blog image\" class=\"sb_float_center\" src=\"https://silvrback.s3.amazonaws.com/uploads/a7c655cb-7d2e-4439-8338-348f90b19145/er_bizcase.png\" /></p>\n\n<p>How can we aggregate the data so that it is unique to the customer rather than the purchase? Features in the data set like names, phone numbers, and addresses will probably be useful. What is notable is that there are numerous variations for those attributes, particularly in how names appear &mdash; sometimes as nicknames, sometimes even misspellings. What we need is an intelligent and mostly automated way to create a new dataset for our recommender system.  Enter Dedupe.</p>\n\n<p>When comparing records, rather than treating each record as a single long string, Dedupe cleverly exploits the structure of the input data to instead compare the records <em>field by field</em>. The advantage of this approach is more pronounced when certain feature vectors of records are much more likely to assist in identifying matches than other attributes. Dedupe lets the user nominate the features they believe will be most useful:   </p>\n<div class=\"highlight\"><pre><span></span><span class=\"n\">fields</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n    <span class=\"p\">{</span><span class=\"s1\">'field'</span> <span class=\"p\">:</span> <span class=\"s1\">'Name'</span><span class=\"p\">,</span> <span class=\"s1\">'type'</span><span class=\"p\">:</span> <span class=\"s1\">'String'</span><span class=\"p\">},</span>\n    <span class=\"p\">{</span><span class=\"s1\">'field'</span> <span class=\"p\">:</span> <span class=\"s1\">'Phone'</span><span class=\"p\">,</span> <span class=\"s1\">'type'</span><span class=\"p\">:</span> <span class=\"s1\">'Exact'</span><span class=\"p\">,</span> <span class=\"s1\">'has missing'</span> <span class=\"p\">:</span> <span class=\"bp\">True</span><span class=\"p\">},</span>\n    <span class=\"p\">{</span><span class=\"s1\">'field'</span> <span class=\"p\">:</span> <span class=\"s1\">'Address'</span><span class=\"p\">,</span> <span class=\"s1\">'type'</span><span class=\"p\">:</span> <span class=\"s1\">'String'</span><span class=\"p\">,</span> <span class=\"s1\">'has missing'</span> <span class=\"p\">:</span> <span class=\"bp\">True</span><span class=\"p\">},</span>\n    <span class=\"p\">{</span><span class=\"s1\">'field'</span> <span class=\"p\">:</span> <span class=\"s1\">'Purchases'</span><span class=\"p\">,</span> <span class=\"s1\">'type'</span><span class=\"p\">:</span> <span class=\"s1\">'String'</span><span class=\"p\">},</span>\n    <span class=\"p\">]</span>\n</pre></div>\n<p>Dedupe scans the data to create tuples of records that it will propose to the user to label as being either matches, not matches, or possible matches. These <code>uncertainPairs</code> are identified using a combination of <strong>blocking</strong> , <strong>affine gap distance</strong>, and <strong>active learning</strong>.</p>\n\n<p>Blocking is used to reduce the number of overall record comparisons that need to be made. Dedupe's method of blocking involves engineering subsets of feature vectors (these are called 'predicates') that can be compared across records. In the case of our people dataset above, the predicates might be things like:</p>\n\n<ul>\n<li>the first three digits of the phone number<br></li>\n<li>the full name<br></li>\n<li>the first five characters of the name<br></li>\n<li>a random 4-gram within the city name<br></li>\n</ul>\n\n<p>Records are then grouped, or blocked, by matching predicates so that only records with matching predicates will be compared to each other during the active learning phase. The blocks are developed by computing the edit distance between predicates across records. Dedupe uses a distance metric called <strong>affine gap distance</strong>, which is a variation on Hamming distance that makes subsequent consecutive deletions or insertions cheaper.</p>\n\n<p><img alt=\"Silvrback blog image\" src=\"https://silvrback.s3.amazonaws.com/uploads/a7c655cb-7d2e-4439-8338-348f90b19145/AGSlide1.png\" /></p>\n\n<p><img alt=\"Silvrback blog image \" src=\"https://silvrback.s3.amazonaws.com/uploads/a7c655cb-7d2e-4439-8338-348f90b19145/AGSlide2.png\" /></p>\n\n<p><img alt=\"Silvrback blog image \" src=\"https://silvrback.s3.amazonaws.com/uploads/a7c655cb-7d2e-4439-8338-348f90b19145/AGSlide3.png\" /></p>\n\n<p>Therefore, we might have one blocking method that groups all of the records that have the same area code of the phone number. This would result in three predicate blocks: one with a 202 area code, one with a 334, and one with NULL. There would be two records in the 202 block (IDs 452 and 821), two records in the 334 block (IDs 233 and 699), and one record in the NULL area code block (ID 720).</p>\n\n<p><img alt=\"Silvrback blog image \" src=\"https://silvrback.s3.amazonaws.com/uploads/a7c655cb-7d2e-4439-8338-348f90b19145/BlockingSlide4.png\" /></p>\n\n<p>The relative weight of these different feature vectors can be learned during the active learning process and expressed numerically to ensure that features that will be most predictive of matches will be heavier in the overall matching schema. As the user labels more and more tuples, Dedupe gradually relearns the weights, recalculates the edit distances between records, and updates its list of the most uncertain pairs to propose to the user for labeling.</p>\n\n<p>Once the user has generated enough labels, the learned weights are used to calculate the probability that each pair of records within a block is a duplicate or not.  In order to scale the pairwise matching up to larger tuples of matched records (in the case that entities may appear more than twice within a document), Dedupe uses hierarchical clustering with centroidal linkage. Records within some threshold distance of a centroid will be grouped together. The final result is an annotated version of the original dataset that now includes a centroid label for each record.    </p>\n\n<h2 id=\"active-learning\">Active Learning</h2>\n\n<p>You can see that <code>dedupe</code> is a command line application that will prompt the user to engage in active learning by showing pairs of entities and asking if they are the same or different.</p>\n<div class=\"highlight\"><pre><span></span>Do these records refer to the same thing?\n<span class=\"o\">(</span>y<span class=\"o\">)</span>es / <span class=\"o\">(</span>n<span class=\"o\">)</span>o / <span class=\"o\">(</span>u<span class=\"o\">)</span>nsure / <span class=\"o\">(</span>f<span class=\"o\">)</span>inished\n</pre></div>\n<p>Active learning is the so-called <em>special sauce</em> behind Dedupe. As in most supervised machine learning tasks, the challenge is to get labeled data that the model can learn from. The active learning phase in Dedupe is essentially an extended user-labeling session, which can be short if you have a small dataset and can take longer if your dataset is large. You are presented with four options:</p>\n\n<p><img alt=\"Silvrback blog image \" src=\"https://silvrback.s3.amazonaws.com/uploads/a7c655cb-7d2e-4439-8338-348f90b19145/dedupeEX.png\" /></p>\n\n<p>You can experiment with typing the <em>y</em>, <em>n</em>, and <em>u</em> keys to flag duplicates for active learning. When you are finished, enter <em>f</em> to quit.</p>\n\n<ul>\n<li>(y)es:    confirms that the two references are to the same entity<br></li>\n<li>(n)o:     labels the two references as not the same entity<br></li>\n<li>(u)nsure: does not label the two references as the same entity or as different entities<br></li>\n<li>(f)inished: ends the active learning session and triggers the supervised learning phase<br></li>\n</ul>\n\n<p><img alt=\"Silvrback blog image \" src=\"https://silvrback.s3.amazonaws.com/uploads/a7c655cb-7d2e-4439-8338-348f90b19145/dedupeEX2.png\" /></p>\n\n<p>As you can see in the example above, some comparisons decisions are very easy. The first contains zero for zero hits on all four attributes being examined, so the verdict is most certainly a non-match. On the second, we have a 3/4 exact match, with the fourth being fuzzy in that one entity contains a piece of the matched entity; Ryerson vs. Chicago Public Schools Ryerson. A human would be able to discern these as two references to the same entity, and we can label it as such to enable the supervised learning that comes after the active learning.</p>\n\n<p>The <em>csv_example</em> also includes an <a href=\"https://github.com/datamade/dedupe-examples/blob/master/csv_example/csv_evaluation.py\">evaluation script</a> that will enable you to determine how successfully you were able to resolve the entities. It's important to note that the blocking, active learning and supervised learning portions of the deduplication process are very dependent on the dataset attributes that the user nominates for selection. In the <em>csv_example</em>, the script nominates the following four attributes:</p>\n<div class=\"highlight\"><pre><span></span><span class=\"n\">fields</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n    <span class=\"p\">{</span><span class=\"s1\">'field'</span> <span class=\"p\">:</span> <span class=\"s1\">'Site name'</span><span class=\"p\">,</span> <span class=\"s1\">'type'</span><span class=\"p\">:</span> <span class=\"s1\">'String'</span><span class=\"p\">},</span>\n    <span class=\"p\">{</span><span class=\"s1\">'field'</span> <span class=\"p\">:</span> <span class=\"s1\">'Address'</span><span class=\"p\">,</span> <span class=\"s1\">'type'</span><span class=\"p\">:</span> <span class=\"s1\">'String'</span><span class=\"p\">},</span>\n    <span class=\"p\">{</span><span class=\"s1\">'field'</span> <span class=\"p\">:</span> <span class=\"s1\">'Zip'</span><span class=\"p\">,</span> <span class=\"s1\">'type'</span><span class=\"p\">:</span> <span class=\"s1\">'Exact'</span><span class=\"p\">,</span> <span class=\"s1\">'has missing'</span> <span class=\"p\">:</span> <span class=\"bp\">True</span><span class=\"p\">},</span>\n    <span class=\"p\">{</span><span class=\"s1\">'field'</span> <span class=\"p\">:</span> <span class=\"s1\">'Phone'</span><span class=\"p\">,</span> <span class=\"s1\">'type'</span><span class=\"p\">:</span> <span class=\"s1\">'String'</span><span class=\"p\">,</span> <span class=\"s1\">'has missing'</span> <span class=\"p\">:</span> <span class=\"bp\">True</span><span class=\"p\">},</span>\n    <span class=\"p\">]</span>\n</pre></div>\n<p>A different combination of attributes would result in a different blocking, a different set of <code>uncertainPairs</code>, a different set of features to use in the active learning phase, and almost certainly a different result. In other words, user experience and domain knowledge factor in heavily at multiple phases of the deduplication process.</p>\n\n<h2 id=\"something-a-bit-more-challenging\">Something a Bit More Challenging</h2>\n\n<p>In order to try out Dedupe with a more challenging project, we decided to try out deduplicating the White House visitors' log. Our hypothesis was that it would be interesting to be able to answer questions such as \"How many times has person X visited the White House during administration Y?\" However, in order to do that, it would be necessary to generate a version of the list that contained unique entities. We guessed that there would be many cases where there were multiple references to a single entity, potentially with slight variations in how they appeared in the dataset. We also expected to find a lot of names that seemed similar but in fact referenced different entities.  In other words, a good challenge!</p>\n\n<p>The data set we used was pulled from the <a href=\"https://open.whitehouse.gov/dataset/White-House-Visitor-Records-Requests/p86s-ychb\">WhiteHouse.gov</a> website, a part of the executive initiative to make federal data more open to the public. This particular set of data is a list of White House visitor record requests from 2006 through 2010. Here's a snapshot of what the data looks like via the White House API.  </p>\n\n<p><img alt=\"Silvrback blog image \" src=\"https://silvrback.s3.amazonaws.com/uploads/a7c655cb-7d2e-4439-8338-348f90b19145/visitors.png\" /></p>\n\n<p>The dataset includes a lot of columns, and for most of the entries, the majority of these fields are blank:</p>\n\n<table><thead>\n<tr>\n<th>Database Field</th>\n<th>Field Description</th>\n</tr>\n</thead><tbody>\n<tr>\n<td>NAMELAST</td>\n<td>Last name of entity</td>\n</tr>\n<tr>\n<td>NAMEFIRST</td>\n<td>First name of entity</td>\n</tr>\n<tr>\n<td>NAMEMID</td>\n<td>Middle name of entity</td>\n</tr>\n<tr>\n<td>UIN</td>\n<td>Unique Identification Number</td>\n</tr>\n<tr>\n<td>BDGNBR</td>\n<td>Badge Number</td>\n</tr>\n<tr>\n<td>Type of Access</td>\n<td>Access type to White House</td>\n</tr>\n<tr>\n<td>TOA</td>\n<td>Time of arrival</td>\n</tr>\n<tr>\n<td>POA</td>\n<td>Post on arrival</td>\n</tr>\n<tr>\n<td>TOD</td>\n<td>Time of departure</td>\n</tr>\n<tr>\n<td>POD</td>\n<td>Post on departure</td>\n</tr>\n<tr>\n<td>APPT_MADE_DATE</td>\n<td>When the appointment date was made</td>\n</tr>\n<tr>\n<td>APPT_START_DATE</td>\n<td>When the appointment date is scheduled to start</td>\n</tr>\n<tr>\n<td>APPT_END_DATE</td>\n<td>When the appointment date is scheduled to end</td>\n</tr>\n<tr>\n<td>APPT_CANCEL_DATE</td>\n<td>When the appointment date was canceled</td>\n</tr>\n<tr>\n<td>Total_People</td>\n<td>Total number of people scheduled to attend</td>\n</tr>\n<tr>\n<td>LAST_UPDATEDBY</td>\n<td>Who was the last person to update this event</td>\n</tr>\n<tr>\n<td>POST</td>\n<td>Classified as 'WIN'</td>\n</tr>\n<tr>\n<td>LastEntryDate</td>\n<td>When the last update to this instance</td>\n</tr>\n<tr>\n<td>TERMINAL_SUFFIX</td>\n<td>ID for terminal used to process visitor</td>\n</tr>\n<tr>\n<td>visitee_namelast</td>\n<td>The visitee's last name</td>\n</tr>\n<tr>\n<td>visitee_namefirst</td>\n<td>The visitee's first name</td>\n</tr>\n<tr>\n<td>MEETING_LOC</td>\n<td>The location of the meeting</td>\n</tr>\n<tr>\n<td>MEETING_ROOM</td>\n<td>The room number of the meeting</td>\n</tr>\n<tr>\n<td>CALLER_NAME_LAST</td>\n<td>The authorizing person for the visitor's last name</td>\n</tr>\n<tr>\n<td>CALLER_NAME_FIRST</td>\n<td>The authorizing person for the visitor's first name</td>\n</tr>\n<tr>\n<td>CALLER_ROOM</td>\n<td>The authorizing person's room for the visitor</td>\n</tr>\n<tr>\n<td>Description</td>\n<td>Description of the event or visit</td>\n</tr>\n<tr>\n<td>RELEASE_DATE</td>\n<td>The date this set of logs were released to the public</td>\n</tr>\n</tbody></table>\n\n<h3 id=\"loading-the-data\">Loading the Data</h3>\n\n<p>Using the API, the <em>White House Visitor Log Requests</em> can be exported in a variety of formats to include, .json, .csv, and .xlsx, .pdf, .xlm, and RSS. However, it's important to keep in mind that the dataset contains over 5 million rows. For this reason, we decided to use .csv and grabbed the data using <code>requests</code>:</p>\n<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">requests</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">getData</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"p\">,</span><span class=\"n\">fname</span><span class=\"p\">):</span>\n    <span class=\"sd\">\"\"\"</span>\n<span class=\"sd\">    Download the dataset from the webpage.</span>\n<span class=\"sd\">    \"\"\"</span>\n    <span class=\"n\">response</span> <span class=\"o\">=</span> <span class=\"n\">requests</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"p\">)</span>\n    <span class=\"k\">with</span> <span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"n\">fname</span><span class=\"p\">,</span> <span class=\"s1\">'w'</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">f</span><span class=\"p\">:</span>\n        <span class=\"n\">f</span><span class=\"o\">.</span><span class=\"n\">write</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">content</span><span class=\"p\">)</span>\n\n<span class=\"n\">DATAURL</span> <span class=\"o\">=</span> <span class=\"s2\">\"https://open.whitehouse.gov/api/views/p86s-ychb/rows.csv?accessType=DOWNLOAD\"</span>\n<span class=\"n\">ORIGFILE</span> <span class=\"o\">=</span> <span class=\"s2\">\"fixtures/whitehouse-visitors.csv\"</span>\n\n<span class=\"n\">getData</span><span class=\"p\">(</span><span class=\"n\">DATAURL</span><span class=\"p\">,</span><span class=\"n\">ORIGFILE</span><span class=\"p\">)</span>\n</pre></div>\n<p>Once downloaded, we can clean it up and load it into a database for more secure and stable storage.</p>\n\n<h2 id=\"tailoring-the-code\">Tailoring the Code</h2>\n\n<p>Next, we'll discuss what is needed to tailor a <code>dedupe</code> example to get the code to work for the White House visitors log dataset. The main challenge with this dataset is its sheer size. First, we'll need to import a few modules and connect to our database:    </p>\n<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">csv</span>\n<span class=\"kn\">import</span> <span class=\"nn\">psycopg2</span>\n<span class=\"kn\">from</span> <span class=\"nn\">dateutil</span> <span class=\"kn\">import</span> <span class=\"n\">parser</span>\n<span class=\"kn\">from</span> <span class=\"nn\">datetime</span> <span class=\"kn\">import</span> <span class=\"n\">datetime</span>\n\n<span class=\"n\">conn</span> <span class=\"o\">=</span> <span class=\"bp\">None</span>\n\n<span class=\"n\">DATABASE</span> <span class=\"o\">=</span> <span class=\"n\">your_db_name</span>\n<span class=\"n\">USER</span> <span class=\"o\">=</span> <span class=\"n\">your_user_name</span>\n<span class=\"n\">HOST</span> <span class=\"o\">=</span> <span class=\"n\">your_hostname</span>\n<span class=\"n\">PASSWORD</span> <span class=\"o\">=</span> <span class=\"n\">your_password</span>\n\n<span class=\"k\">try</span><span class=\"p\">:</span>\n    <span class=\"n\">conn</span> <span class=\"o\">=</span> <span class=\"n\">psycopg2</span><span class=\"o\">.</span><span class=\"n\">connect</span><span class=\"p\">(</span><span class=\"n\">database</span><span class=\"o\">=</span><span class=\"n\">DATABASE</span><span class=\"p\">,</span> <span class=\"n\">user</span><span class=\"o\">=</span><span class=\"n\">USER</span><span class=\"p\">,</span> <span class=\"n\">host</span><span class=\"o\">=</span><span class=\"n\">HOST</span><span class=\"p\">,</span> <span class=\"n\">password</span><span class=\"o\">=</span><span class=\"n\">PASSWORD</span><span class=\"p\">)</span>\n    <span class=\"k\">print</span> <span class=\"p\">(</span><span class=\"s2\">\"I've connected\"</span><span class=\"p\">)</span>\n<span class=\"k\">except</span><span class=\"p\">:</span>\n    <span class=\"k\">print</span> <span class=\"p\">(</span><span class=\"s2\">\"I am unable to connect to the database\"</span><span class=\"p\">)</span>\n<span class=\"n\">cur</span> <span class=\"o\">=</span> <span class=\"n\">conn</span><span class=\"o\">.</span><span class=\"n\">cursor</span><span class=\"p\">()</span>\n</pre></div>\n<p>The other challenge with our dataset are the numerous missing values and <em>datetime</em> formatting irregularities. We wanted to be able to use the <em>datetime</em> strings to help with entity resolution, so we wanted to get the formatting to be as consistent as possible. The following script handles both the <em>datetime</em> parsing and the missing values by combining Python's <code>dateutil</code> module and PostgreSQL's fairly forgiving 'varchar' type.</p>\n\n<p>This function takes the csv data in as input, parses the <em>datetime</em> fields we're interested in ('lastname','firstname','uin','apptmade','apptstart','apptend', 'meeting_loc'.), and outputs a database table that retains the desired columns. Keep in mind this will take a while to run.        </p>\n<div class=\"highlight\"><pre><span></span><span class=\"k\">def</span> <span class=\"nf\">dateParseSQL</span><span class=\"p\">(</span><span class=\"n\">nfile</span><span class=\"p\">):</span>\n    <span class=\"n\">cur</span><span class=\"o\">.</span><span class=\"n\">execute</span><span class=\"p\">(</span><span class=\"s1\">'''CREATE TABLE IF NOT EXISTS visitors_er</span>\n<span class=\"s1\">                  (visitor_id SERIAL PRIMARY KEY,</span>\n<span class=\"s1\">                  lastname    varchar,</span>\n<span class=\"s1\">                  firstname   varchar,</span>\n<span class=\"s1\">                  uin         varchar,</span>\n<span class=\"s1\">                  apptmade    varchar,</span>\n<span class=\"s1\">                  apptstart   varchar,</span>\n<span class=\"s1\">                  apptend     varchar,</span>\n<span class=\"s1\">                  meeting_loc varchar);'''</span><span class=\"p\">)</span>\n    <span class=\"n\">conn</span><span class=\"o\">.</span><span class=\"n\">commit</span><span class=\"p\">()</span>\n    <span class=\"k\">with</span> <span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"n\">nfile</span><span class=\"p\">,</span> <span class=\"s1\">'rU'</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">infile</span><span class=\"p\">:</span>\n        <span class=\"n\">reader</span> <span class=\"o\">=</span> <span class=\"n\">csv</span><span class=\"o\">.</span><span class=\"n\">reader</span><span class=\"p\">(</span><span class=\"n\">infile</span><span class=\"p\">,</span> <span class=\"n\">delimiter</span><span class=\"o\">=</span><span class=\"s1\">','</span><span class=\"p\">)</span>\n        <span class=\"nb\">next</span><span class=\"p\">(</span><span class=\"n\">reader</span><span class=\"p\">,</span> <span class=\"bp\">None</span><span class=\"p\">)</span>\n        <span class=\"k\">for</span> <span class=\"n\">row</span> <span class=\"ow\">in</span> <span class=\"n\">reader</span><span class=\"p\">:</span>\n            <span class=\"k\">for</span> <span class=\"n\">field</span> <span class=\"ow\">in</span> <span class=\"n\">DATEFIELDS</span><span class=\"p\">:</span>\n                <span class=\"k\">if</span> <span class=\"n\">row</span><span class=\"p\">[</span><span class=\"n\">field</span><span class=\"p\">]</span> <span class=\"o\">!=</span> <span class=\"s1\">''</span><span class=\"p\">:</span>\n                    <span class=\"k\">try</span><span class=\"p\">:</span>\n                        <span class=\"n\">dt</span> <span class=\"o\">=</span> <span class=\"n\">parser</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">(</span><span class=\"n\">row</span><span class=\"p\">[</span><span class=\"n\">field</span><span class=\"p\">])</span>\n                        <span class=\"n\">row</span><span class=\"p\">[</span><span class=\"n\">field</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">dt</span><span class=\"o\">.</span><span class=\"n\">toordinal</span><span class=\"p\">()</span>  <span class=\"c1\"># We also tried dt.isoformat()</span>\n                    <span class=\"k\">except</span><span class=\"p\">:</span>\n                        <span class=\"k\">continue</span>\n            <span class=\"n\">sql</span> <span class=\"o\">=</span> <span class=\"s2\">\"INSERT INTO visitors_er(lastname,firstname,uin,apptmade,apptstart,apptend,meeting_loc) </span><span class=\"se\">\\</span>\n<span class=\"s2\">                   VALUES (</span><span class=\"si\">%s</span><span class=\"s2\">,</span><span class=\"si\">%s</span><span class=\"s2\">,</span><span class=\"si\">%s</span><span class=\"s2\">,</span><span class=\"si\">%s</span><span class=\"s2\">,</span><span class=\"si\">%s</span><span class=\"s2\">,</span><span class=\"si\">%s</span><span class=\"s2\">,</span><span class=\"si\">%s</span><span class=\"s2\">)\"</span>\n            <span class=\"n\">cur</span><span class=\"o\">.</span><span class=\"n\">execute</span><span class=\"p\">(</span><span class=\"n\">sql</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">row</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">],</span><span class=\"n\">row</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">],</span><span class=\"n\">row</span><span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">],</span><span class=\"n\">row</span><span class=\"p\">[</span><span class=\"mi\">10</span><span class=\"p\">],</span><span class=\"n\">row</span><span class=\"p\">[</span><span class=\"mi\">11</span><span class=\"p\">],</span><span class=\"n\">row</span><span class=\"p\">[</span><span class=\"mi\">12</span><span class=\"p\">],</span><span class=\"n\">row</span><span class=\"p\">[</span><span class=\"mi\">21</span><span class=\"p\">],))</span>\n            <span class=\"n\">conn</span><span class=\"o\">.</span><span class=\"n\">commit</span><span class=\"p\">()</span>\n    <span class=\"k\">print</span> <span class=\"p\">(</span><span class=\"s2\">\"All done!\"</span><span class=\"p\">)</span>\n\n\n<span class=\"n\">dateParseSQL</span><span class=\"p\">(</span><span class=\"n\">ORIGFILE</span><span class=\"p\">)</span>\n</pre></div>\n<p>About 60 of our rows had ASCII characters, which we dropped using this SQL command:</p>\n<div class=\"highlight\"><pre><span></span><span class=\"k\">delete</span> <span class=\"k\">from</span> <span class=\"n\">visitors</span> <span class=\"k\">where</span> <span class=\"n\">firstname</span> <span class=\"o\">~</span> <span class=\"s1\">'[^[:ascii:]]'</span> <span class=\"k\">OR</span> <span class=\"n\">lastname</span> <span class=\"o\">~</span> <span class=\"s1\">'[^[:ascii:]]'</span><span class=\"p\">;</span>\n</pre></div>\n<p>For our deduplication script, we modified the <a href=\"https://github.com/datamade/dedupe-examples/blob/master/pgsql_example/pgsql_example.py\">PostgreSQL example</a> as well as <a href=\"https://twitter.com/dchud\">Dan Chudnov</a>'s <a href=\"https://github.com/dchud/osha-dedupe/blob/master/pgdedupe.py\">adaptation of the script</a> for the OSHA dataset.</p>\n<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">tempfile</span>\n<span class=\"kn\">import</span> <span class=\"nn\">argparse</span>\n<span class=\"kn\">import</span> <span class=\"nn\">csv</span>\n<span class=\"kn\">import</span> <span class=\"nn\">os</span>\n\n<span class=\"kn\">import</span> <span class=\"nn\">dedupe</span>\n<span class=\"kn\">import</span> <span class=\"nn\">psycopg2</span>\n<span class=\"kn\">from</span> <span class=\"nn\">psycopg2.extras</span> <span class=\"kn\">import</span> <span class=\"n\">DictCursor</span>\n</pre></div>\n<p>Initially, we wanted to try to use the datetime fields to deduplicate the entities, but <code>dedupe</code> was not a big fan of the <em>datetime</em> fields, whether in isoformat or ordinal, so we ended up nominating the following fields:    </p>\n<div class=\"highlight\"><pre><span></span><span class=\"n\">KEY_FIELD</span> <span class=\"o\">=</span> <span class=\"s1\">'visitor_id'</span>\n<span class=\"n\">SOURCE_TABLE</span> <span class=\"o\">=</span> <span class=\"s1\">'visitors'</span>\n\n<span class=\"n\">FIELDS</span> <span class=\"o\">=</span>  <span class=\"p\">[{</span><span class=\"s1\">'field'</span><span class=\"p\">:</span> <span class=\"s1\">'firstname'</span><span class=\"p\">,</span> <span class=\"s1\">'variable name'</span><span class=\"p\">:</span> <span class=\"s1\">'firstname'</span><span class=\"p\">,</span>\n               <span class=\"s1\">'type'</span><span class=\"p\">:</span> <span class=\"s1\">'String'</span><span class=\"p\">,</span><span class=\"s1\">'has missing'</span><span class=\"p\">:</span> <span class=\"bp\">True</span><span class=\"p\">},</span>\n              <span class=\"p\">{</span><span class=\"s1\">'field'</span><span class=\"p\">:</span> <span class=\"s1\">'lastname'</span><span class=\"p\">,</span> <span class=\"s1\">'variable name'</span><span class=\"p\">:</span> <span class=\"s1\">'lastname'</span><span class=\"p\">,</span>\n               <span class=\"s1\">'type'</span><span class=\"p\">:</span> <span class=\"s1\">'String'</span><span class=\"p\">,</span><span class=\"s1\">'has missing'</span><span class=\"p\">:</span> <span class=\"bp\">True</span><span class=\"p\">},</span>\n              <span class=\"p\">{</span><span class=\"s1\">'field'</span><span class=\"p\">:</span> <span class=\"s1\">'uin'</span><span class=\"p\">,</span> <span class=\"s1\">'variable name'</span><span class=\"p\">:</span> <span class=\"s1\">'uin'</span><span class=\"p\">,</span>\n               <span class=\"s1\">'type'</span><span class=\"p\">:</span> <span class=\"s1\">'String'</span><span class=\"p\">,</span><span class=\"s1\">'has missing'</span><span class=\"p\">:</span> <span class=\"bp\">True</span><span class=\"p\">},</span>\n              <span class=\"p\">{</span><span class=\"s1\">'field'</span><span class=\"p\">:</span> <span class=\"s1\">'meeting_loc'</span><span class=\"p\">,</span> <span class=\"s1\">'variable name'</span><span class=\"p\">:</span> <span class=\"s1\">'meeting_loc'</span><span class=\"p\">,</span>\n               <span class=\"s1\">'type'</span><span class=\"p\">:</span> <span class=\"s1\">'String'</span><span class=\"p\">,</span><span class=\"s1\">'has missing'</span><span class=\"p\">:</span> <span class=\"bp\">True</span><span class=\"p\">}</span>\n              <span class=\"p\">]</span>\n</pre></div>\n<p>We modified a function Dan wrote to generate the predicate blocks:    </p>\n<div class=\"highlight\"><pre><span></span><span class=\"k\">def</span> <span class=\"nf\">candidates_gen</span><span class=\"p\">(</span><span class=\"n\">result_set</span><span class=\"p\">):</span>\n    <span class=\"n\">lset</span> <span class=\"o\">=</span> <span class=\"nb\">set</span>\n    <span class=\"n\">block_id</span> <span class=\"o\">=</span> <span class=\"bp\">None</span>\n    <span class=\"n\">records</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n    <span class=\"n\">i</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>\n    <span class=\"k\">for</span> <span class=\"n\">row</span> <span class=\"ow\">in</span> <span class=\"n\">result_set</span><span class=\"p\">:</span>\n        <span class=\"k\">if</span> <span class=\"n\">row</span><span class=\"p\">[</span><span class=\"s1\">'block_id'</span><span class=\"p\">]</span> <span class=\"o\">!=</span> <span class=\"n\">block_id</span><span class=\"p\">:</span>\n            <span class=\"k\">if</span> <span class=\"n\">records</span><span class=\"p\">:</span>\n                <span class=\"k\">yield</span> <span class=\"n\">records</span>\n\n            <span class=\"n\">block_id</span> <span class=\"o\">=</span> <span class=\"n\">row</span><span class=\"p\">[</span><span class=\"s1\">'block_id'</span><span class=\"p\">]</span>\n            <span class=\"n\">records</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n            <span class=\"n\">i</span> <span class=\"o\">+=</span> <span class=\"mi\">1</span>\n\n            <span class=\"k\">if</span> <span class=\"n\">i</span> <span class=\"o\">%</span> <span class=\"mi\">10000</span> <span class=\"o\">==</span> <span class=\"mi\">0</span><span class=\"p\">:</span>\n                <span class=\"k\">print</span> <span class=\"p\">(</span><span class=\"s1\">'{} blocks'</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"n\">i</span><span class=\"p\">))</span>\n\n        <span class=\"n\">smaller_ids</span> <span class=\"o\">=</span> <span class=\"n\">row</span><span class=\"p\">[</span><span class=\"s1\">'smaller_ids'</span><span class=\"p\">]</span>\n        <span class=\"k\">if</span> <span class=\"n\">smaller_ids</span><span class=\"p\">:</span>\n            <span class=\"n\">smaller_ids</span> <span class=\"o\">=</span> <span class=\"n\">lset</span><span class=\"p\">(</span><span class=\"n\">smaller_ids</span><span class=\"o\">.</span><span class=\"n\">split</span><span class=\"p\">(</span><span class=\"s1\">','</span><span class=\"p\">))</span>\n        <span class=\"k\">else</span><span class=\"p\">:</span>\n            <span class=\"n\">smaller_ids</span> <span class=\"o\">=</span> <span class=\"n\">lset</span><span class=\"p\">([])</span>\n\n        <span class=\"n\">records</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">((</span><span class=\"n\">row</span><span class=\"p\">[</span><span class=\"n\">KEY_FIELD</span><span class=\"p\">],</span> <span class=\"n\">row</span><span class=\"p\">,</span> <span class=\"n\">smaller_ids</span><span class=\"p\">))</span>\n\n    <span class=\"k\">if</span> <span class=\"n\">records</span><span class=\"p\">:</span>\n        <span class=\"k\">yield</span> <span class=\"n\">records</span>\n</pre></div>\n<p>And we adapted the method from the dedupe-examples repo to handle the active learning, supervised learning, and clustering steps:    </p>\n<div class=\"highlight\"><pre><span></span><span class=\"k\">def</span> <span class=\"nf\">find_dupes</span><span class=\"p\">(</span><span class=\"n\">args</span><span class=\"p\">):</span>\n    <span class=\"n\">deduper</span> <span class=\"o\">=</span> <span class=\"n\">dedupe</span><span class=\"o\">.</span><span class=\"n\">Dedupe</span><span class=\"p\">(</span><span class=\"n\">FIELDS</span><span class=\"p\">)</span>\n\n    <span class=\"k\">with</span> <span class=\"n\">psycopg2</span><span class=\"o\">.</span><span class=\"n\">connect</span><span class=\"p\">(</span><span class=\"n\">database</span><span class=\"o\">=</span><span class=\"n\">args</span><span class=\"o\">.</span><span class=\"n\">dbname</span><span class=\"p\">,</span>\n                          <span class=\"n\">host</span><span class=\"o\">=</span><span class=\"s1\">'localhost'</span><span class=\"p\">,</span>\n                          <span class=\"n\">cursor_factory</span><span class=\"o\">=</span><span class=\"n\">DictCursor</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">con</span><span class=\"p\">:</span>\n        <span class=\"k\">with</span> <span class=\"n\">con</span><span class=\"o\">.</span><span class=\"n\">cursor</span><span class=\"p\">()</span> <span class=\"k\">as</span> <span class=\"n\">c</span><span class=\"p\">:</span>\n            <span class=\"n\">c</span><span class=\"o\">.</span><span class=\"n\">execute</span><span class=\"p\">(</span><span class=\"s1\">'SELECT COUNT(*) AS count FROM </span><span class=\"si\">%s</span><span class=\"s1\">'</span> <span class=\"o\">%</span> <span class=\"n\">SOURCE_TABLE</span><span class=\"p\">)</span>\n            <span class=\"n\">row</span> <span class=\"o\">=</span> <span class=\"n\">c</span><span class=\"o\">.</span><span class=\"n\">fetchone</span><span class=\"p\">()</span>\n            <span class=\"n\">count</span> <span class=\"o\">=</span> <span class=\"n\">row</span><span class=\"p\">[</span><span class=\"s1\">'count'</span><span class=\"p\">]</span>\n            <span class=\"n\">sample_size</span> <span class=\"o\">=</span> <span class=\"nb\">int</span><span class=\"p\">(</span><span class=\"n\">count</span> <span class=\"o\">*</span> <span class=\"n\">args</span><span class=\"o\">.</span><span class=\"n\">sample</span><span class=\"p\">)</span>\n\n            <span class=\"k\">print</span> <span class=\"p\">(</span><span class=\"s1\">'Generating sample of {} records'</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"n\">sample_size</span><span class=\"p\">))</span>\n            <span class=\"k\">with</span> <span class=\"n\">con</span><span class=\"o\">.</span><span class=\"n\">cursor</span><span class=\"p\">(</span><span class=\"s1\">'deduper'</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">c_deduper</span><span class=\"p\">:</span>\n                <span class=\"n\">c_deduper</span><span class=\"o\">.</span><span class=\"n\">execute</span><span class=\"p\">(</span><span class=\"s1\">'SELECT visitor_id,lastname,firstname,uin,meeting_loc FROM </span><span class=\"si\">%s</span><span class=\"s1\">'</span> <span class=\"o\">%</span> <span class=\"n\">SOURCE_TABLE</span><span class=\"p\">)</span>\n                <span class=\"n\">temp_d</span> <span class=\"o\">=</span> <span class=\"nb\">dict</span><span class=\"p\">((</span><span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">row</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">row</span> <span class=\"ow\">in</span> <span class=\"nb\">enumerate</span><span class=\"p\">(</span><span class=\"n\">c_deduper</span><span class=\"p\">))</span>\n                <span class=\"n\">deduper</span><span class=\"o\">.</span><span class=\"n\">sample</span><span class=\"p\">(</span><span class=\"n\">temp_d</span><span class=\"p\">,</span> <span class=\"n\">sample_size</span><span class=\"p\">)</span>\n                <span class=\"k\">del</span><span class=\"p\">(</span><span class=\"n\">temp_d</span><span class=\"p\">)</span>\n\n            <span class=\"k\">if</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">exists</span><span class=\"p\">(</span><span class=\"n\">args</span><span class=\"o\">.</span><span class=\"n\">training</span><span class=\"p\">):</span>\n                <span class=\"k\">print</span> <span class=\"p\">(</span><span class=\"s1\">'Loading training file from {}'</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"n\">args</span><span class=\"o\">.</span><span class=\"n\">training</span><span class=\"p\">))</span>\n                <span class=\"k\">with</span> <span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"n\">args</span><span class=\"o\">.</span><span class=\"n\">training</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">tf</span><span class=\"p\">:</span>\n                    <span class=\"n\">deduper</span><span class=\"o\">.</span><span class=\"n\">readTraining</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"p\">)</span>\n\n            <span class=\"k\">print</span> <span class=\"p\">(</span><span class=\"s1\">'Starting active learning'</span><span class=\"p\">)</span>\n            <span class=\"n\">dedupe</span><span class=\"o\">.</span><span class=\"n\">convenience</span><span class=\"o\">.</span><span class=\"n\">consoleLabel</span><span class=\"p\">(</span><span class=\"n\">deduper</span><span class=\"p\">)</span>\n\n            <span class=\"k\">print</span> <span class=\"p\">(</span><span class=\"s1\">'Starting training'</span><span class=\"p\">)</span>\n            <span class=\"n\">deduper</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"p\">(</span><span class=\"n\">ppc</span><span class=\"o\">=</span><span class=\"mf\">0.001</span><span class=\"p\">,</span> <span class=\"n\">uncovered_dupes</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">)</span>\n\n            <span class=\"k\">print</span> <span class=\"p\">(</span><span class=\"s1\">'Saving new training file to {}'</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"n\">args</span><span class=\"o\">.</span><span class=\"n\">training</span><span class=\"p\">))</span>\n            <span class=\"k\">with</span> <span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"n\">args</span><span class=\"o\">.</span><span class=\"n\">training</span><span class=\"p\">,</span> <span class=\"s1\">'w'</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">training_file</span><span class=\"p\">:</span>\n                <span class=\"n\">deduper</span><span class=\"o\">.</span><span class=\"n\">writeTraining</span><span class=\"p\">(</span><span class=\"n\">training_file</span><span class=\"p\">)</span>\n\n            <span class=\"n\">deduper</span><span class=\"o\">.</span><span class=\"n\">cleanupTraining</span><span class=\"p\">()</span>\n\n            <span class=\"k\">print</span> <span class=\"p\">(</span><span class=\"s1\">'Creating blocking_map table'</span><span class=\"p\">)</span>\n            <span class=\"n\">c</span><span class=\"o\">.</span><span class=\"n\">execute</span><span class=\"p\">(</span><span class=\"s2\">\"\"\"</span>\n<span class=\"s2\">                DROP TABLE IF EXISTS blocking_map</span>\n<span class=\"s2\">                \"\"\"</span><span class=\"p\">)</span>\n            <span class=\"n\">c</span><span class=\"o\">.</span><span class=\"n\">execute</span><span class=\"p\">(</span><span class=\"s2\">\"\"\"</span>\n<span class=\"s2\">                CREATE TABLE blocking_map</span>\n<span class=\"s2\">                (block_key VARCHAR(200), </span><span class=\"si\">%s</span><span class=\"s2\"> INTEGER)</span>\n<span class=\"s2\">                \"\"\"</span> <span class=\"o\">%</span> <span class=\"n\">KEY_FIELD</span><span class=\"p\">)</span>\n\n            <span class=\"k\">for</span> <span class=\"n\">field</span> <span class=\"ow\">in</span> <span class=\"n\">deduper</span><span class=\"o\">.</span><span class=\"n\">blocker</span><span class=\"o\">.</span><span class=\"n\">index_fields</span><span class=\"p\">:</span>\n                <span class=\"k\">print</span> <span class=\"p\">(</span><span class=\"s1\">'Selecting distinct values for \"{}\"'</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"n\">field</span><span class=\"p\">))</span>\n                <span class=\"n\">c_index</span> <span class=\"o\">=</span> <span class=\"n\">con</span><span class=\"o\">.</span><span class=\"n\">cursor</span><span class=\"p\">(</span><span class=\"s1\">'index'</span><span class=\"p\">)</span>\n                <span class=\"n\">c_index</span><span class=\"o\">.</span><span class=\"n\">execute</span><span class=\"p\">(</span><span class=\"s2\">\"\"\"</span>\n<span class=\"s2\">                    SELECT DISTINCT </span><span class=\"si\">%s</span><span class=\"s2\"> FROM </span><span class=\"si\">%s</span><span class=\"s2\"></span>\n<span class=\"s2\">                    \"\"\"</span> <span class=\"o\">%</span> <span class=\"p\">(</span><span class=\"n\">field</span><span class=\"p\">,</span> <span class=\"n\">SOURCE_TABLE</span><span class=\"p\">))</span>\n                <span class=\"n\">field_data</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">row</span><span class=\"p\">[</span><span class=\"n\">field</span><span class=\"p\">]</span> <span class=\"k\">for</span> <span class=\"n\">row</span> <span class=\"ow\">in</span> <span class=\"n\">c_index</span><span class=\"p\">)</span>\n                <span class=\"n\">deduper</span><span class=\"o\">.</span><span class=\"n\">blocker</span><span class=\"o\">.</span><span class=\"n\">index</span><span class=\"p\">(</span><span class=\"n\">field_data</span><span class=\"p\">,</span> <span class=\"n\">field</span><span class=\"p\">)</span>\n                <span class=\"n\">c_index</span><span class=\"o\">.</span><span class=\"n\">close</span><span class=\"p\">()</span>\n\n            <span class=\"k\">print</span> <span class=\"p\">(</span><span class=\"s1\">'Generating blocking map'</span><span class=\"p\">)</span>\n            <span class=\"n\">c_block</span> <span class=\"o\">=</span> <span class=\"n\">con</span><span class=\"o\">.</span><span class=\"n\">cursor</span><span class=\"p\">(</span><span class=\"s1\">'block'</span><span class=\"p\">)</span>\n            <span class=\"n\">c_block</span><span class=\"o\">.</span><span class=\"n\">execute</span><span class=\"p\">(</span><span class=\"s2\">\"\"\"</span>\n<span class=\"s2\">                SELECT * FROM </span><span class=\"si\">%s</span><span class=\"s2\"></span>\n<span class=\"s2\">                \"\"\"</span> <span class=\"o\">%</span> <span class=\"n\">SOURCE_TABLE</span><span class=\"p\">)</span>\n            <span class=\"n\">full_data</span> <span class=\"o\">=</span> <span class=\"p\">((</span><span class=\"n\">row</span><span class=\"p\">[</span><span class=\"n\">KEY_FIELD</span><span class=\"p\">],</span> <span class=\"n\">row</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">row</span> <span class=\"ow\">in</span> <span class=\"n\">c_block</span><span class=\"p\">)</span>\n            <span class=\"n\">b_data</span> <span class=\"o\">=</span> <span class=\"n\">deduper</span><span class=\"o\">.</span><span class=\"n\">blocker</span><span class=\"p\">(</span><span class=\"n\">full_data</span><span class=\"p\">)</span>\n\n            <span class=\"k\">print</span> <span class=\"p\">(</span><span class=\"s1\">'Inserting blocks into blocking_map'</span><span class=\"p\">)</span>\n            <span class=\"n\">csv_file</span> <span class=\"o\">=</span> <span class=\"n\">tempfile</span><span class=\"o\">.</span><span class=\"n\">NamedTemporaryFile</span><span class=\"p\">(</span><span class=\"n\">prefix</span><span class=\"o\">=</span><span class=\"s1\">'blocks_'</span><span class=\"p\">,</span> <span class=\"n\">delete</span><span class=\"o\">=</span><span class=\"bp\">False</span><span class=\"p\">)</span>\n            <span class=\"n\">csv_writer</span> <span class=\"o\">=</span> <span class=\"n\">csv</span><span class=\"o\">.</span><span class=\"n\">writer</span><span class=\"p\">(</span><span class=\"n\">csv_file</span><span class=\"p\">)</span>\n            <span class=\"n\">csv_writer</span><span class=\"o\">.</span><span class=\"n\">writerows</span><span class=\"p\">(</span><span class=\"n\">b_data</span><span class=\"p\">)</span>\n            <span class=\"n\">csv_file</span><span class=\"o\">.</span><span class=\"n\">close</span><span class=\"p\">()</span>\n\n            <span class=\"n\">f</span> <span class=\"o\">=</span> <span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"n\">csv_file</span><span class=\"o\">.</span><span class=\"n\">name</span><span class=\"p\">,</span> <span class=\"s1\">'r'</span><span class=\"p\">)</span>\n            <span class=\"n\">c</span><span class=\"o\">.</span><span class=\"n\">copy_expert</span><span class=\"p\">(</span><span class=\"s2\">\"COPY blocking_map FROM STDIN CSV\"</span><span class=\"p\">,</span> <span class=\"n\">f</span><span class=\"p\">)</span>\n            <span class=\"n\">f</span><span class=\"o\">.</span><span class=\"n\">close</span><span class=\"p\">()</span>\n\n            <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">remove</span><span class=\"p\">(</span><span class=\"n\">csv_file</span><span class=\"o\">.</span><span class=\"n\">name</span><span class=\"p\">)</span>\n\n            <span class=\"n\">con</span><span class=\"o\">.</span><span class=\"n\">commit</span><span class=\"p\">()</span>\n\n            <span class=\"k\">print</span> <span class=\"p\">(</span><span class=\"s1\">'Indexing blocks'</span><span class=\"p\">)</span>\n            <span class=\"n\">c</span><span class=\"o\">.</span><span class=\"n\">execute</span><span class=\"p\">(</span><span class=\"s2\">\"\"\"</span>\n<span class=\"s2\">                CREATE INDEX blocking_map_key_idx ON blocking_map (block_key)</span>\n<span class=\"s2\">                \"\"\"</span><span class=\"p\">)</span>\n            <span class=\"n\">c</span><span class=\"o\">.</span><span class=\"n\">execute</span><span class=\"p\">(</span><span class=\"s2\">\"DROP TABLE IF EXISTS plural_key\"</span><span class=\"p\">)</span>\n            <span class=\"n\">c</span><span class=\"o\">.</span><span class=\"n\">execute</span><span class=\"p\">(</span><span class=\"s2\">\"DROP TABLE IF EXISTS plural_block\"</span><span class=\"p\">)</span>\n            <span class=\"n\">c</span><span class=\"o\">.</span><span class=\"n\">execute</span><span class=\"p\">(</span><span class=\"s2\">\"DROP TABLE IF EXISTS covered_blocks\"</span><span class=\"p\">)</span>\n            <span class=\"n\">c</span><span class=\"o\">.</span><span class=\"n\">execute</span><span class=\"p\">(</span><span class=\"s2\">\"DROP TABLE IF EXISTS smaller_coverage\"</span><span class=\"p\">)</span>\n\n            <span class=\"k\">print</span> <span class=\"p\">(</span><span class=\"s1\">'Calculating plural_key'</span><span class=\"p\">)</span>\n            <span class=\"n\">c</span><span class=\"o\">.</span><span class=\"n\">execute</span><span class=\"p\">(</span><span class=\"s2\">\"\"\"</span>\n<span class=\"s2\">                CREATE TABLE plural_key</span>\n<span class=\"s2\">                (block_key VARCHAR(200),</span>\n<span class=\"s2\">                block_id SERIAL PRIMARY KEY)</span>\n<span class=\"s2\">                \"\"\"</span><span class=\"p\">)</span>\n            <span class=\"n\">c</span><span class=\"o\">.</span><span class=\"n\">execute</span><span class=\"p\">(</span><span class=\"s2\">\"\"\"</span>\n<span class=\"s2\">                INSERT INTO plural_key (block_key)</span>\n<span class=\"s2\">                SELECT block_key FROM blocking_map</span>\n<span class=\"s2\">                GROUP BY block_key HAVING COUNT(*) > 1</span>\n<span class=\"s2\">                \"\"\"</span><span class=\"p\">)</span>\n\n            <span class=\"k\">print</span> <span class=\"p\">(</span><span class=\"s1\">'Indexing block_key'</span><span class=\"p\">)</span>\n            <span class=\"n\">c</span><span class=\"o\">.</span><span class=\"n\">execute</span><span class=\"p\">(</span><span class=\"s2\">\"\"\"</span>\n<span class=\"s2\">                CREATE UNIQUE INDEX block_key_idx ON plural_key (block_key)</span>\n<span class=\"s2\">                \"\"\"</span><span class=\"p\">)</span>\n\n            <span class=\"k\">print</span> <span class=\"p\">(</span><span class=\"s1\">'Calculating plural_block'</span><span class=\"p\">)</span>\n            <span class=\"n\">c</span><span class=\"o\">.</span><span class=\"n\">execute</span><span class=\"p\">(</span><span class=\"s2\">\"\"\"</span>\n<span class=\"s2\">                CREATE TABLE plural_block</span>\n<span class=\"s2\">                AS (SELECT block_id, </span><span class=\"si\">%s</span><span class=\"s2\"></span>\n<span class=\"s2\">                FROM blocking_map INNER JOIN plural_key</span>\n<span class=\"s2\">                USING (block_key))</span>\n<span class=\"s2\">                \"\"\"</span> <span class=\"o\">%</span> <span class=\"n\">KEY_FIELD</span><span class=\"p\">)</span>\n\n            <span class=\"k\">print</span> <span class=\"p\">(</span><span class=\"s1\">'Adding {} index'</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"n\">KEY_FIELD</span><span class=\"p\">))</span>\n            <span class=\"n\">c</span><span class=\"o\">.</span><span class=\"n\">execute</span><span class=\"p\">(</span><span class=\"s2\">\"\"\"</span>\n<span class=\"s2\">                CREATE INDEX plural_block_</span><span class=\"si\">%s</span><span class=\"s2\">_idx</span>\n<span class=\"s2\">                    ON plural_block (</span><span class=\"si\">%s</span><span class=\"s2\">)</span>\n<span class=\"s2\">                \"\"\"</span> <span class=\"o\">%</span> <span class=\"p\">(</span><span class=\"n\">KEY_FIELD</span><span class=\"p\">,</span> <span class=\"n\">KEY_FIELD</span><span class=\"p\">))</span>\n            <span class=\"n\">c</span><span class=\"o\">.</span><span class=\"n\">execute</span><span class=\"p\">(</span><span class=\"s2\">\"\"\"</span>\n<span class=\"s2\">                CREATE UNIQUE INDEX plural_block_block_id_</span><span class=\"si\">%s</span><span class=\"s2\">_uniq</span>\n<span class=\"s2\">                ON plural_block (block_id, </span><span class=\"si\">%s</span><span class=\"s2\">)</span>\n<span class=\"s2\">                \"\"\"</span> <span class=\"o\">%</span> <span class=\"p\">(</span><span class=\"n\">KEY_FIELD</span><span class=\"p\">,</span> <span class=\"n\">KEY_FIELD</span><span class=\"p\">))</span>\n\n            <span class=\"k\">print</span> <span class=\"p\">(</span><span class=\"s1\">'Creating covered_blocks'</span><span class=\"p\">)</span>\n            <span class=\"n\">c</span><span class=\"o\">.</span><span class=\"n\">execute</span><span class=\"p\">(</span><span class=\"s2\">\"\"\"</span>\n<span class=\"s2\">                CREATE TABLE covered_blocks AS</span>\n<span class=\"s2\">                    (SELECT </span><span class=\"si\">%s</span><span class=\"s2\">,</span>\n<span class=\"s2\">                            string_agg(CAST(block_id AS TEXT), ','</span>\n<span class=\"s2\">                            ORDER BY block_id) AS sorted_ids</span>\n<span class=\"s2\">                     FROM plural_block</span>\n<span class=\"s2\">                     GROUP BY </span><span class=\"si\">%s</span><span class=\"s2\">)</span>\n<span class=\"s2\">                 \"\"\"</span> <span class=\"o\">%</span> <span class=\"p\">(</span><span class=\"n\">KEY_FIELD</span><span class=\"p\">,</span> <span class=\"n\">KEY_FIELD</span><span class=\"p\">))</span>\n\n            <span class=\"k\">print</span> <span class=\"p\">(</span><span class=\"s1\">'Indexing covered_blocks'</span><span class=\"p\">)</span>\n            <span class=\"n\">c</span><span class=\"o\">.</span><span class=\"n\">execute</span><span class=\"p\">(</span><span class=\"s2\">\"\"\"</span>\n<span class=\"s2\">                CREATE UNIQUE INDEX covered_blocks_</span><span class=\"si\">%s</span><span class=\"s2\">_idx</span>\n<span class=\"s2\">                    ON covered_blocks (</span><span class=\"si\">%s</span><span class=\"s2\">)</span>\n<span class=\"s2\">                \"\"\"</span> <span class=\"o\">%</span> <span class=\"p\">(</span><span class=\"n\">KEY_FIELD</span><span class=\"p\">,</span> <span class=\"n\">KEY_FIELD</span><span class=\"p\">))</span>\n            <span class=\"k\">print</span> <span class=\"p\">(</span><span class=\"s1\">'Committing'</span><span class=\"p\">)</span>\n\n            <span class=\"k\">print</span> <span class=\"p\">(</span><span class=\"s1\">'Creating smaller_coverage'</span><span class=\"p\">)</span>\n            <span class=\"n\">c</span><span class=\"o\">.</span><span class=\"n\">execute</span><span class=\"p\">(</span><span class=\"s2\">\"\"\"</span>\n<span class=\"s2\">                CREATE TABLE smaller_coverage AS</span>\n<span class=\"s2\">                    (SELECT </span><span class=\"si\">%s</span><span class=\"s2\">, block_id,</span>\n<span class=\"s2\">                        TRIM(',' FROM split_part(sorted_ids,</span>\n<span class=\"s2\">                        CAST(block_id AS TEXT), 1))</span>\n<span class=\"s2\">                        AS smaller_ids</span>\n<span class=\"s2\">                     FROM plural_block</span>\n<span class=\"s2\">                     INNER JOIN covered_blocks</span>\n<span class=\"s2\">                     USING (</span><span class=\"si\">%s</span><span class=\"s2\">))</span>\n<span class=\"s2\">                \"\"\"</span> <span class=\"o\">%</span> <span class=\"p\">(</span><span class=\"n\">KEY_FIELD</span><span class=\"p\">,</span> <span class=\"n\">KEY_FIELD</span><span class=\"p\">))</span>\n            <span class=\"n\">con</span><span class=\"o\">.</span><span class=\"n\">commit</span><span class=\"p\">()</span>\n\n            <span class=\"k\">print</span> <span class=\"p\">(</span><span class=\"s1\">'Clustering...'</span><span class=\"p\">)</span>\n            <span class=\"n\">c_cluster</span> <span class=\"o\">=</span> <span class=\"n\">con</span><span class=\"o\">.</span><span class=\"n\">cursor</span><span class=\"p\">(</span><span class=\"s1\">'cluster'</span><span class=\"p\">)</span>\n            <span class=\"n\">c_cluster</span><span class=\"o\">.</span><span class=\"n\">execute</span><span class=\"p\">(</span><span class=\"s2\">\"\"\"</span>\n<span class=\"s2\">                SELECT *</span>\n<span class=\"s2\">                FROM smaller_coverage</span>\n<span class=\"s2\">                INNER JOIN </span><span class=\"si\">%s</span><span class=\"s2\"></span>\n<span class=\"s2\">                    USING (</span><span class=\"si\">%s</span><span class=\"s2\">)</span>\n<span class=\"s2\">                ORDER BY (block_id)</span>\n<span class=\"s2\">                \"\"\"</span> <span class=\"o\">%</span> <span class=\"p\">(</span><span class=\"n\">SOURCE_TABLE</span><span class=\"p\">,</span> <span class=\"n\">KEY_FIELD</span><span class=\"p\">))</span>\n            <span class=\"n\">clustered_dupes</span> <span class=\"o\">=</span> <span class=\"n\">deduper</span><span class=\"o\">.</span><span class=\"n\">matchBlocks</span><span class=\"p\">(</span>\n                    <span class=\"n\">candidates_gen</span><span class=\"p\">(</span><span class=\"n\">c_cluster</span><span class=\"p\">),</span> <span class=\"n\">threshold</span><span class=\"o\">=</span><span class=\"mf\">0.5</span><span class=\"p\">)</span>\n\n            <span class=\"k\">print</span> <span class=\"p\">(</span><span class=\"s1\">'Creating entity_map table'</span><span class=\"p\">)</span>\n            <span class=\"n\">c</span><span class=\"o\">.</span><span class=\"n\">execute</span><span class=\"p\">(</span><span class=\"s2\">\"DROP TABLE IF EXISTS entity_map\"</span><span class=\"p\">)</span>\n            <span class=\"n\">c</span><span class=\"o\">.</span><span class=\"n\">execute</span><span class=\"p\">(</span><span class=\"s2\">\"\"\"</span>\n<span class=\"s2\">                CREATE TABLE entity_map (</span>\n<span class=\"s2\">                    </span><span class=\"si\">%s</span><span class=\"s2\"> INTEGER,</span>\n<span class=\"s2\">                    canon_id INTEGER,</span>\n<span class=\"s2\">                    cluster_score FLOAT,</span>\n<span class=\"s2\">                    PRIMARY KEY(</span><span class=\"si\">%s</span><span class=\"s2\">)</span>\n<span class=\"s2\">                )\"\"\"</span> <span class=\"o\">%</span> <span class=\"p\">(</span><span class=\"n\">KEY_FIELD</span><span class=\"p\">,</span> <span class=\"n\">KEY_FIELD</span><span class=\"p\">))</span>\n\n            <span class=\"k\">print</span> <span class=\"p\">(</span><span class=\"s1\">'Inserting entities into entity_map'</span><span class=\"p\">)</span>\n            <span class=\"k\">for</span> <span class=\"n\">cluster</span><span class=\"p\">,</span> <span class=\"n\">scores</span> <span class=\"ow\">in</span> <span class=\"n\">clustered_dupes</span><span class=\"p\">:</span>\n                <span class=\"n\">cluster_id</span> <span class=\"o\">=</span> <span class=\"n\">cluster</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n                <span class=\"k\">for</span> <span class=\"n\">key_field</span><span class=\"p\">,</span> <span class=\"n\">score</span> <span class=\"ow\">in</span> <span class=\"nb\">zip</span><span class=\"p\">(</span><span class=\"n\">cluster</span><span class=\"p\">,</span> <span class=\"n\">scores</span><span class=\"p\">):</span>\n                    <span class=\"n\">c</span><span class=\"o\">.</span><span class=\"n\">execute</span><span class=\"p\">(</span><span class=\"s2\">\"\"\"</span>\n<span class=\"s2\">                        INSERT INTO entity_map</span>\n<span class=\"s2\">                            (</span><span class=\"si\">%s</span><span class=\"s2\">, canon_id, cluster_score)</span>\n<span class=\"s2\">                        VALUES (</span><span class=\"si\">%s</span><span class=\"s2\">, </span><span class=\"si\">%s</span><span class=\"s2\">, </span><span class=\"si\">%s</span><span class=\"s2\">)</span>\n<span class=\"s2\">                        \"\"\"</span> <span class=\"o\">%</span> <span class=\"p\">(</span><span class=\"n\">KEY_FIELD</span><span class=\"p\">,</span> <span class=\"n\">key_field</span><span class=\"p\">,</span> <span class=\"n\">cluster_id</span><span class=\"p\">,</span> <span class=\"n\">score</span><span class=\"p\">))</span>\n\n            <span class=\"k\">print</span> <span class=\"p\">(</span><span class=\"s1\">'Indexing head_index'</span><span class=\"p\">)</span>\n            <span class=\"n\">c_cluster</span><span class=\"o\">.</span><span class=\"n\">close</span><span class=\"p\">()</span>\n            <span class=\"n\">c</span><span class=\"o\">.</span><span class=\"n\">execute</span><span class=\"p\">(</span><span class=\"s2\">\"CREATE INDEX head_index ON entity_map (canon_id)\"</span><span class=\"p\">)</span>\n            <span class=\"n\">con</span><span class=\"o\">.</span><span class=\"n\">commit</span><span class=\"p\">()</span>\n\n<span class=\"k\">if</span> <span class=\"vm\">__name__</span> <span class=\"o\">==</span> <span class=\"s1\">'__main__'</span><span class=\"p\">:</span>\n    <span class=\"n\">parser</span> <span class=\"o\">=</span> <span class=\"n\">argparse</span><span class=\"o\">.</span><span class=\"n\">ArgumentParser</span><span class=\"p\">()</span>\n    <span class=\"n\">parser</span><span class=\"o\">.</span><span class=\"n\">add_argument</span><span class=\"p\">(</span><span class=\"s1\">'--dbname'</span><span class=\"p\">,</span> <span class=\"n\">dest</span><span class=\"o\">=</span><span class=\"s1\">'dbname'</span><span class=\"p\">,</span> <span class=\"n\">default</span><span class=\"o\">=</span><span class=\"s1\">'whitehouse'</span><span class=\"p\">,</span> <span class=\"n\">help</span><span class=\"o\">=</span><span class=\"s1\">'database name'</span><span class=\"p\">)</span>\n    <span class=\"n\">parser</span><span class=\"o\">.</span><span class=\"n\">add_argument</span><span class=\"p\">(</span><span class=\"s1\">'-s'</span><span class=\"p\">,</span> <span class=\"s1\">'--sample'</span><span class=\"p\">,</span> <span class=\"n\">default</span><span class=\"o\">=</span><span class=\"mf\">0.10</span><span class=\"p\">,</span> <span class=\"nb\">type</span><span class=\"o\">=</span><span class=\"nb\">float</span><span class=\"p\">,</span> <span class=\"n\">help</span><span class=\"o\">=</span><span class=\"s1\">'sample size (percentage, default 0.10)'</span><span class=\"p\">)</span>\n    <span class=\"n\">parser</span><span class=\"o\">.</span><span class=\"n\">add_argument</span><span class=\"p\">(</span><span class=\"s1\">'-t'</span><span class=\"p\">,</span> <span class=\"s1\">'--training'</span><span class=\"p\">,</span> <span class=\"n\">default</span><span class=\"o\">=</span><span class=\"s1\">'training.json'</span><span class=\"p\">,</span> <span class=\"n\">help</span><span class=\"o\">=</span><span class=\"s1\">'name of training file'</span><span class=\"p\">)</span>\n    <span class=\"n\">args</span> <span class=\"o\">=</span> <span class=\"n\">parser</span><span class=\"o\">.</span><span class=\"n\">parse_args</span><span class=\"p\">()</span>\n    <span class=\"n\">find_dupes</span><span class=\"p\">(</span><span class=\"n\">args</span><span class=\"p\">)</span>\n</pre></div>\n<h2 id=\"active-learning-observations\">Active Learning Observations</h2>\n\n<p>We ran multiple experiments:</p>\n\n<ul>\n<li>Test 1: lastname, firstname, meeting_loc => 447 (15 minutes of training)</li>\n<li>Test 2: lastname, firstname, uin, meeting_loc => 3385 (5 minutes of training) - one instance that had 168 duplicates</li>\n</ul>\n\n<p>We observed a lot of uncertainty during the active learning phase, mostly because of how enormous the dataset is.  This was particularly pronounced with names that seemed more common to us and that sounded more domestic since those are much more commonly occurring in this dataset. For example, are two records containing the name Michael Grant the same entity?</p>\n\n<p>Additionally, we noticed that there were a lot of variations in the way that middle names were captured. Sometimes they were concatenated with the first name, other times with the last name. We also observed what seemed to be many nicknames or that could have been references to separate entities: <em>KIM ASKEW</em> vs. <em>KIMBERLEY ASKEW</em> and <em>Kathy Edwards</em> vs. <em>Katherine Edwards</em> (and yes, <code>dedupe</code> does preserve variations in case). On the other hand, since nicknames generally appear only in people's first names, when we did see a short version of a first name paired with an unusual or rare last name, we were more confident in labeling those as a match.</p>\n\n<p>Other things that made the labeling easier were clearly gendered names (e.g. <em>Brian Murphy</em> vs. <em>Briana Murphy</em>), which helped us to identify separate entities in spite of very small differences in the strings. Some names appeared to be clear misspellings, which also made us more confident in our labeling two references as matches for a single entity  (<em>Davifd Culp</em> vs. <em>David Culp</em>). There were also a few potential easter eggs in the dataset, which we suspect might actually be aliases (<em>Jon Doe</em> and <em>Ben Jealous</em>).</p>\n\n<p>One of the things we discovered upon multiple runs of the active learning process is that the number of fields the user nominates to Dedupe for use has a great impact on the kinds of predicate blocks that are generated during the initial blocking phase. Thus, the comparisons that are presented to the trainer during the active learning phase. In one of our runs, we used only the last name, first name, and meeting location fields. Some of the comparisons were easy:      </p>\n<div class=\"highlight\"><pre><span></span>lastname : KUZIEMKO\nfirstname : ILYANA\nmeeting_loc : WH\n\nlastname : KUZIEMKO\nfirstname : ILYANA\nmeeting_loc : WH\n\nDo these records refer to the same thing?\n<span class=\"o\">(</span>y<span class=\"o\">)</span>es / <span class=\"o\">(</span>n<span class=\"o\">)</span>o / <span class=\"o\">(</span>u<span class=\"o\">)</span>nsure / <span class=\"o\">(</span>f<span class=\"o\">)</span>inished\n</pre></div>\n<p>Some were hard:    </p>\n<div class=\"highlight\"><pre><span></span>lastname : Desimone\nfirstname : Daniel\nmeeting_loc : OEOB\n\nlastname : DeSimone\nfirstname : Daniel\nmeeting_loc : WH\n\nDo these records refer to the same thing?\n<span class=\"o\">(</span>y<span class=\"o\">)</span>es / <span class=\"o\">(</span>n<span class=\"o\">)</span>o / <span class=\"o\">(</span>u<span class=\"o\">)</span>nsure / <span class=\"o\">(</span>f<span class=\"o\">)</span>inished\n</pre></div>\n<h2 id=\"results\">Results</h2>\n\n<p>What we realized from this is that there are two different kinds of duplicates that appear in our dataset. The first kind of duplicate is one that generated via (likely mistaken) duplicate visitor request forms. We noticed that these duplicate entries tended to be proximal to each other in terms of <em>visitor_id</em> number, have the same meeting location and the same <em>uin</em> (which confusingly, is not a unique guest identifier but appears to be assigned to every visitor within a unique tour group). The second kind of duplicate is what we think of as the <em>frequent flier</em> &mdash; people who seem to spend a lot of time at the White House like staffers and other political appointees.</p>\n\n<p>During the dedupe process, we computed there were 332,606 potential duplicates within the data set of 1,048,576 entities. For this particular data, we would expect these kinds of figures, knowing that people visit for repeat business or social functions.</p>\n\n<h3 id=\"within-visit-duplicates\">Within-Visit Duplicates</h3>\n<div class=\"highlight\"><pre><span></span><span class=\"n\">lastname</span> <span class=\"o\">:</span> <span class=\"n\">Ryan</span>\n<span class=\"n\">meeting_loc</span> <span class=\"o\">:</span> <span class=\"n\">OEOB</span>\n<span class=\"n\">firstname</span> <span class=\"o\">:</span> <span class=\"n\">Patrick</span>\n<span class=\"n\">uin</span> <span class=\"o\">:</span> <span class=\"n\">U62671</span>\n\n<span class=\"n\">lastname</span> <span class=\"o\">:</span> <span class=\"n\">Ryan</span>\n<span class=\"n\">meeting_loc</span> <span class=\"o\">:</span> <span class=\"n\">OEOB</span>\n<span class=\"n\">firstname</span> <span class=\"o\">:</span> <span class=\"n\">Patrick</span>\n<span class=\"n\">uin</span> <span class=\"o\">:</span> <span class=\"n\">U62671</span>\n</pre></div>\n<h3 id=\"across-visit-duplicates-frequent-fliers\">Across-Visit Duplicates (Frequent Fliers)</h3>\n<div class=\"highlight\"><pre><span></span><span class=\"n\">lastname</span> <span class=\"o\">:</span> <span class=\"n\">TANGHERLINI</span>\n<span class=\"n\">meeting_loc</span> <span class=\"o\">:</span> <span class=\"n\">OEOB</span>\n<span class=\"n\">firstname</span> <span class=\"o\">:</span> <span class=\"n\">DANIEL</span>\n<span class=\"n\">uin</span> <span class=\"o\">:</span> <span class=\"n\">U02692</span>\n\n<span class=\"n\">lastname</span> <span class=\"o\">:</span> <span class=\"n\">TANGHERLINI</span>\n<span class=\"n\">meeting_loc</span> <span class=\"o\">:</span> <span class=\"n\">NEOB</span>\n<span class=\"n\">firstname</span> <span class=\"o\">:</span> <span class=\"n\">DANIEL</span>\n<span class=\"n\">uin</span> <span class=\"o\">:</span> <span class=\"n\">U73085</span>\n</pre></div><div class=\"highlight\"><pre><span></span><span class=\"n\">lastname</span> <span class=\"o\">:</span> <span class=\"n\">ARCHULETA</span>\n<span class=\"n\">meeting_loc</span> <span class=\"o\">:</span> <span class=\"n\">WH</span>\n<span class=\"n\">firstname</span> <span class=\"o\">:</span> <span class=\"n\">KATHERINE</span>\n<span class=\"n\">uin</span> <span class=\"o\">:</span> <span class=\"n\">U68121</span>\n\n<span class=\"n\">lastname</span> <span class=\"o\">:</span> <span class=\"n\">ARCHULETA</span>\n<span class=\"n\">meeting_loc</span> <span class=\"o\">:</span> <span class=\"n\">OEOB</span>\n<span class=\"n\">firstname</span> <span class=\"o\">:</span> <span class=\"n\">KATHERINE</span>\n<span class=\"n\">uin</span> <span class=\"o\">:</span> <span class=\"n\">U76331</span>\n</pre></div>\n<p><img alt=\"Silvrback blog image \" src=\"https://silvrback.s3.amazonaws.com/uploads/a7c655cb-7d2e-4439-8338-348f90b19145/dedupe_errors.png\" /></p>\n\n<h2 id=\"conclusion\">Conclusion</h2>\n\n<p>In this beginners guide to Entity Resolution, we learned what it means to identify entities and their possible duplicates within and across records. To further examine this data beyond the scope of this blog post, we would like to determine which records are true duplicates. This would require additional information to canonicalize these entities, thus allowing for potential indexing of entities for future assessments. Ultimately we discovered the importance of entity resolution across a variety of domains, such as counter-terrorism, customer databases, and voter registration.</p>\n\n<p>Please return to the District Data Labs blog for upcoming posts on entity resolution and discussion about a number of other important topics to the data science community.  Upcoming post topics from our research group include string matching algorithms, data preparation, and entity identification!</p>\n\n<h2 id=\"recommended-reading\">Recommended Reading</h2>\n\n<ul>\n<li><a href=\"http://www.slideshare.net/BenjaminBengfort/a-primer-on-entity-resolution\">A Primer on Entity Resolution by Benjamin Bengfort</a><br></li>\n<li><a href=\"http://www.datacommunitydc.org/blog/2013/08/entity-resolution-for-big-data\">Entity Resolution for Big Data: A Summary of the KDD 2013 Tutorial Taught by Dr. Lise Getoor and Dr. Ashwin Machanavajjhala</a><br></li>\n<li><a href=\"http://courses.cs.washington.edu/courses/cse590q/04au/papers/Felligi69.pdf\">A Theory for Record Linkage by Ivan P. Fellegi and Alan B. Sunter</a><br></li>\n</ul>\n\n<p><em>District Data Labs provides data science <a href=\"http://www.districtdatalabs.com/consulting/\">consulting</a> and <a href=\"http://www.districtdatalabs.com/training/\">corporate training</a> services. We work with companies and teams of all sizes, helping them make their operations more data-driven and enhancing the analytical abilities of their employees. Interested in working with us? <a href=\"mailto:contact@districtdatalabs.com?subject=Consulting%20and%20Corporate%20Training%20Services&body=Hello!%20I'm%20interested%20in%20learning%20more%20about%20your%20data%20science%20consulting%20and%20corporate%20training%20offerings.\">Let us know</a>!</em></p>\n"
}