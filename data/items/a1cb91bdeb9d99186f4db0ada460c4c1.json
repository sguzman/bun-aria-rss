{
  "title": "Thunderbolting Your Video Card",
  "description": "<!--kg-card-begin: markdown--><p>When I wrote about <a href=\"https://blog.codinghorror.com/the-golden-age-of-x86-gaming/\">The Golden Age of x86 Gaming</a>, I <em>implied</em> that, in the future, it might be an interesting, albeit expensive, idea to upgrade your video card via an external Thunderbolt 3 enclosure.</p>\n<p><img src=\"https://blog.codinghorror.com/content/images/2017/03/skull-canyon-nuc-with-razer-core.jpg\" alt loading=\"lazy\"></p>\n<p>I'm here to report that <strong>the future is now</strong>.</p>\n<p>Yes, that's</p>",
  "link": "https://blog.codinghorror.com/thunderbolting-your-video-card/",
  "guid": "5988f60721f57d0019a2e129",
  "dc:creator": "Jeff Atwood",
  "pubDate": "Fri, 24 Mar 2017 09:08:37 GMT",
  "content:encoded": "<!--kg-card-begin: markdown--><p>When I wrote about <a href=\"https://blog.codinghorror.com/the-golden-age-of-x86-gaming/\">The Golden Age of x86 Gaming</a>, I <em>implied</em> that, in the future, it might be an interesting, albeit expensive, idea to upgrade your video card via an external Thunderbolt 3 enclosure.</p>\n<p><img src=\"https://blog.codinghorror.com/content/images/2017/03/skull-canyon-nuc-with-razer-core.jpg\" alt loading=\"lazy\"></p>\n<p>I'm here to report that <strong>the future is now</strong>.</p>\n<p>Yes, that's right, I paid $500 for <a href=\"https://www.razerzone.com/store/razer-core\">an external Thunderbolt 3 enclosure</a> to fit a $600 video card, all to enable a plug-in upgrade of a GPU on a <a href=\"https://blog.codinghorror.com/the-golden-age-of-x86-gaming/\">Skull Canyon NUC</a> that itself cost around $1000 fully built. I know, it sounds crazy, and &#x2026; OK fine, I won't argue with you. It's crazy.</p>\n<p>This matters mostly because of 4k, aka 2160p, aka 3840 &#xD7; 2160, aka <strong>Ultra HD</strong>.</p>\n<p><img src=\"https://blog.codinghorror.com/content/images/2015/08/common-hd-resolutions-compared.png\" alt=\"4k compared to 1080p\" loading=\"lazy\"></p>\n<p>Plain old regular HD, aka 1080p, aka 1920 &#xD7; 1080, is one quarter the size of 4k, and &#xBC; the work. By today's GPU standards HD is pretty much <em>easy mode</em> these days. It's not even interesting. No offense to console fans, or anything.</p>\n<p>Late in 2016, I got a <a href=\"https://www.amazon.com/gp/product/B01CDD4J58/?tag=codihorr-20\">4k OLED display</a> and it &#x2026; kind of blew my mind. I have never seen blacks so black, colors so vivid, on a display so thin. It made my previous 2008 era Panasonic plasma set look lame. It's so good that I'm now a little angry that every display that my eyes touch isn't OLED already. I even got into nerd fights over it, and to be honest, I'd still throw down for OLED. It is legitimately <em>that good</em>. Come at me, bro.</p>\n<p>Don't believe me? Well, guess which display in the below picture is OLED? Go on, guess:</p>\n<p><a href=\"http://www.consumerreports.org/lcd-led-oled-tvs/2016-LG-4K-oled-tvs/\"><img src=\"https://blog.codinghorror.com/content/images/2017/03/CptX7RCVYAAKNOP.jpg\" alt=\"Guess which screen is OLED?\" loading=\"lazy\"></a></p>\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\"><a href=\"https://twitter.com/andrewbstiles\">@andrewbstiles</a> if it was physically possible to have sex with this TV I.. uh.. I'd take it on long, romantic walks</p>&#x2014; Jeff Atwood (@codinghorror) <a href=\"https://twitter.com/codinghorror/status/764304493483663361\">August 13, 2016</a></blockquote>\n<script async src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n<p>There's a reason every site that reviews TVs had to recalibrate their results when <a href=\"http://thewirecutter.com/reviews/best-tv/\">they reviewed the 2016 OLED sets</a>.</p>\n<blockquote>\n<p>In my extended review at Reference Home Theater, I call it &#x201C;the best looking TV I&#x2019;ve ever reviewed.&#x201D; But we aren&#x2019;t alone in loving the E6. Vincent Teoh at HDTVtest writes, &#x201C;We&#x2019;re not even going to qualify the following endorsement: if you can afford it, this is the TV to buy.&#x201D; Rtings.com gave <a href=\"https://www.amazon.com/gp/product/B01CDD4J58/?tag=codihorr-20\">the E6 OLED</a> the highest score of any TV the site has ever tested. Reviewed.com awarded it a 9.9 out of 10, with only the LG G6 OLED (which offers the same image but better styling and sound for $2,000 more) coming out ahead.</p>\n</blockquote>\n<p>But I digress.</p>\n<p>Playing games at 1080p in my living room was already possible. But now that I have an incredible 4k display in the living room, it's a whole other level of difficulty. Not just twice as hard &#x2013; and remember current consoles <em>barely</em> manage to eke out 1080p at 30fps in most games &#x2013; but <strong>four times as hard</strong>. That's where external GPU power comes in.</p>\n<p><img src=\"https://blog.codinghorror.com/content/images/2017/03/razer-core-with-gpu.jpg\" alt loading=\"lazy\"></p>\n<p>The cool technology underpinning all of this is <strong>Thunderbolt 3</strong>. The thunderbolt cable bundled with the Razer Core is rather &#x2026; diminutive. There's <a href=\"https://blog.startech.com/post/thunderbolt-3-the-basics/\">a reason for this</a>.</p>\n<blockquote>\n<p><strong>Is there a maximum cable length for Thunderbolt 3 technology?</strong></p>\n<p>Thunderbolt 3 passive cables have maximum lengths.</p>\n<ul>\n<li>0.5m TB 3 (40Gbps)</li>\n<li>1.0m TB 3 (20Gbps)</li>\n<li>2.0m TB 3 (20Gbps)</li>\n</ul>\n<p>In the future we will offer active cables which will provide 40Gbps of bandwidth at longer lengths.</p>\n</blockquote>\n<p>40Gbps is, for the record, an <em>insane</em> amount of bandwidth. Let's use our rule of thumb based on ultra common gigabit ethernet, that 1 gigabit = 120 megabytes/second, and we arrive at <strong>4.8 gigabytes/second</strong>. Zow.</p>\n<p>That's more than enough bandwidth to run even the highest of high end video cards, but it is not without overhead. There's <a href=\"http://www.ultrabookreview.com/10761-razer-core-review/\">a mild performance hit</a> for running the card externally, on the order of <strong>15%</strong>. There's also a further performance hit of 10% if you are in \"loopback\" mode on a laptop where you don't <em>have</em> an external display, so the video frames have to be shuttled back from the GPU to the internal laptop display.</p>\n<p>This may look like a gamer-only thing, but surprisingly, it isn't. What you get is the general purpose ability to attach <strong>any PCI express card</strong> to any computer with a <strong>Thunderbolt 3</strong> port and, for the most part, it just works!</p>\n<p>Linus breaks it down and answers all your most difficult questions:</p>\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/2D79GsrEqe4\" frameborder=\"0\" allowfullscreen></iframe>\n<p>Please watch the above video closely if you're actually interested in this stuff; it is essential. I'll add some caveats of my own after working with the Razer Core for a while:</p>\n<ul>\n<li>\n<p>Make sure the video card you plan to put into the Razer Core is not too tall, or too wide. You can tell if a card is going to be too tall by looking at pictures of the mounting rear bracket. If the card extends significantly above the standard rear mounting bracket, it won't fit. If the card takes more than 2 slots in width, it also won't fit, but this is more rare. Depth (length) is rarely an issue.</p>\n</li>\n<li>\n<p>There are four fans in the Razer Core and although it is <em>reasonably</em> quiet, it's not super silent or anything. You may want to <a href=\"http://forum.notebookreview.com/threads/razer-core-disassembly-fan-location-guide.802000/\">mod the fans</a>. The Razer Core is a remarkably simple device, internally, it's really just a power supply, some Thunderbolt 3 bridge logic, and a PCI express slot. I agree with Linus that the #1 area Razer could improve in the future, beyond generally getting the price down, is to use fewer and larger fans that run quieter.</p>\n</li>\n<li>\n<p>If you're putting a heavy hitter GPU in the Razer Core, I'd try to avoid blower style cards (the ones that exhaust heat from the rear) in favor of those that cool with large fans blowing down and around the card. Dissipating 150w+ is no mean feat and you'll definitely need to keep the enclosure in open air &#x2026; and of course within 0.5 meters of the computer it's connected to.</p>\n</li>\n<li>\n<p>There is no visible external power switch on the Razer Core. It doesn't power on until you connect a TB3 cable to it. I was totally not expecting that. But once connected, it powers up and the Windows 10 Thunderbolt 3 drivers kick in and ask you to authorize the device, which I did (always authorize). Then it spun a bit, detected the new GPU, and suddenly I had multiple graphics card active on the same computer. I also installed the latest Nvidia drivers just to make sure everything was ship shape.</p>\n</li>\n<li>\n<p>It's kinda ... <em>weird</em> having multiple GPUs simultaneously active. I wanted to make the Razer Core display the only display, but you can't really turn off the built in GPU &#x2013; you can select \"only use display 2\", that's all. I got into several weird states where windows were opening on the other display and I had to mess around a fair bit to get things locked down to just one display. You may want to consider whether you have both \"displays\" connected for troubleshooting, or not.</p>\n</li>\n</ul>\n<p>And then, there I am, playing Lego Marvel in splitscreen co-op at glorious 3840 &#xD7; 2160 UltraHD resolution on an amazing OLED display with my son. It is <em>incredible</em>.</p>\n<p><img src=\"https://blog.codinghorror.com/content/images/2017/03/lego-marvel-4k.jpg\" alt loading=\"lazy\"></p>\n<p>Beyond the technical \"because I could\", I am <strong>wildly optimistic about the future of external Thunderbolt 3 expansion boxes</strong>, and here's why:</p>\n<ul>\n<li>\n<p>The main expense and bottleneck in any stonking gaming rig is, by <em>far</em>, the GPU. It's also the item you are most likely to need to replace a year or two from now.</p>\n</li>\n<li>\n<p>The CPU and memory speeds available today are so comically fast that any device with a low-end i3-7100 for $120 will make zero difference in real world gaming at 1080p or higher &#x2026; if you're OK with 30fps minimum. If you bump up to $200, you can get a quad-core i5-7500 that guarantees you 60fps minimum everywhere.</p>\n</li>\n<li>\n<p>If you prefer a small system or a laptop, an external GPU makes it so much more flexible. Because CPU and memory speeds are already so fast, 99.9% of the time your bottleneck is the GPU, and almost <strong>any small device you can buy with a Thunderbolt 3 port can now magically transform into a potent gaming rig with a single plug</strong>. Thunderbolt 3 may be a bit cutting edge today, but more and more devices are shipping with Thunderbolt 3. Within a few years, I predict TB3 ports will be as common as USB3 ports.</p>\n</li>\n<li>\n<p>A general purpose external PCI express enclosure will be usable for a very long time. My last <em>seven</em> video card upgrades were plug and play PCI Express cards that would have worked fine in any computer I've built in the last ten years.</p>\n</li>\n<li>\n<p>External GPUs are not meaningfully bottlenecked by Thunderbolt 3 bandwidth; the impact is 15%  to 25%, and perhaps even less over time as drivers and implementations mature. While Thunderbolt 3 has \"only\" PCI Express x4 bandwidth, many benchmarkers have noted that GPUs moving from PCI Express x16 to x8 has <a href=\"https://www.pugetsystems.com/labs/articles/Impact-of-PCI-E-Speed-on-Gaming-Performance-518/\">almost no effect on performance</a>. And there's always Thunderbolt 4 on the horizon.</p>\n</li>\n</ul>\n<p>The future, as they say, is already here &#x2013; it's just not evenly distributed.</p>\n<p>I am painfully aware that <strong>costs need to come down</strong>. Way, <em>way</em> down. The <a href=\"https://www.razerzone.com/store/razer-core\">$499 Razer Core</a> is well made, on the vanguard of what's possible, a harbinger of the future, and fantastically enough, it does <em>even more</em> than what it says on the tin. But it's not exactly <em>affordable</em>.</p>\n<p>I would absolutely love to see a modest, dedicated $200 external Thunderbolt 3 box that included an inexpensive current-gen GPU. This would <em>clobber</em> any onboard GPU on the planet. Let's compare my Skull Canyon NUC, which has Intel's <a href=\"http://www.notebookcheck.net/Intel-Iris-Pro-Graphics-580.160664.0.html\">fastest ever, PS4 class embedded GPU</a>, with the modest $150 <a href=\"http://www.notebookcheck.com/NVIDIA-GeForce-GTX-1050-Ti-Desktop.181030.0.html\">GeForce GTX 1050 Ti</a>:</p>\n<table width=\"300px\">\n<tr>\n<td colspan=\"2\"><b>1920 &#xD7; 1080 high detail</b></td>\n</tr>\n<tr>\n<td>Bioshock Infinite</td><td>15 &#x2192; 79 fps</td>\n</tr>\n<tr>\n<td>Rise of the Tomb Raider</td><td>12 &#x2192; 49 fps</td>\n</tr>\n<tr>\n<td>Overwatch</td><td>43 &#x2192; 114 fps</td>\n</tr>\n</table>\n<p>As predicted, that's a 3x-5x stompdown. Mac users lamenting their general lack of upgradeability, hear me: <em>this sort of box is exactly what you want and need</em>. Imagine if Apple was to embrace upgrading their laptops and all-in-one systems via Thunderbolt 3.</p>\n<p><img src=\"https://blog.codinghorror.com/content/images/2017/03/razer-core-and-razer-laptop.jpg\" alt loading=\"lazy\"></p>\n<p>I know, I know. It's a stretch. But a man can dream &#x2026; of externally upgradeable GPUs. That are too expensive, sure, but they are here, right now, today. They'll only get cheaper over time.</p>\n<table>  \n<tr><td class=\"welovecodinghorror\">  \n[advertisement] <a href=\"http://careers.stackoverflow.com\" rel=\"nofollow\">Find a better job the Stack Overflow way</a> - what you need when you need it, no spam, and no scams.\n</td></tr>  \n</table>  <!--kg-card-end: markdown-->"
}