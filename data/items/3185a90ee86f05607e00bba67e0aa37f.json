{
  "title": "Latent Prompt Tuning for Text Summarization. (arXiv:2211.01837v1 [cs.CL])",
  "link": "http://arxiv.org/abs/2211.01837",
  "description": "<p>Prompts with different control signals (e.g., length, keywords, etc.) can be\nused to control text summarization. When control signals are available, they\ncan control the properties of generated summaries and potentially improve\nsummarization quality (since more information are given). Unfortunately,\ncontrol signals are not already available during inference time. In this paper,\nwe propose Lotus (shorthand for Latent Prompt Tuning for Summarization), which\nis a single model that can be applied in both controlled and uncontrolled\n(without control signals) modes. During training, Lotus learns latent prompt\nrepresentations from prompts with gold control signals using a contrastive\nlearning objective. Experiments show Lotus in uncontrolled mode consistently\nimproves upon strong (uncontrollable) summarization models across four\ndifferent summarization datasets. We also demonstrate generated summaries can\nbe controlled using prompts with user specified control tokens.\n</p>",
  "dc:creator": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yubo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xingxing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Si-qing Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>"
}