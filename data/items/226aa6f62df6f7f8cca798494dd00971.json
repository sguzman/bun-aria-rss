{
  "title": "Artificial Intelligence",
  "itunes:title": "Artificial Intelligence",
  "description": "<p>An artificial intelligence capable of improving itself runs the risk of growing intelligent beyond any human capacity and outside of our control. Josh explains why a superintelligent AI that we haven’t planned for would be extremely bad for humankind. (Original score by <a href=\"https://www.pointlobo.com/\">Point Lobo</a>.) </p><p>Interviewees: Nick Bostrom, Oxford University philosopher and founder of the Future of Humanity Institute; David Pearce, philosopher and co-founder of the World Transhumanist Association (Humanity+); Sebastian Farquahar, Oxford University philosopher.<em></em></p><p></p><p> </p> Learn more about your ad-choices at <a href=\"https://www.iheartpodcastnetwork.com\">https://www.iheartpodcastnetwork.com</a><p>See <a href=\"https://omnystudio.com/listener\">omnystudio.com/listener</a> for privacy information.</p>",
  "content:encoded": "<p>An artificial intelligence capable of improving itself runs the risk of growing intelligent beyond any human capacity and outside of our control. Josh explains why a superintelligent AI that we haven’t planned for would be extremely bad for humankind. (Original score by <a href=\"https://www.pointlobo.com/\">Point Lobo</a>.) </p><p>Interviewees: Nick Bostrom, Oxford University philosopher and founder of the Future of Humanity Institute; David Pearce, philosopher and co-founder of the World Transhumanist Association (Humanity+); Sebastian Farquahar, Oxford University philosopher.<em></em></p><p></p><p> </p> Learn more about your ad-choices at <a href=\"https://www.iheartpodcastnetwork.com\">https://www.iheartpodcastnetwork.com</a><p>See <a href=\"https://omnystudio.com/listener\">omnystudio.com/listener</a> for privacy information.</p>",
  "itunes:summary": "An artificial intelligence capable of improving itself runs the risk of growing intelligent beyond any human capacity and outside of our control. Josh explains why a superintelligent AI that we haven’t planned for would be extremely bad for humankind.",
  "itunes:episodeType": "full",
  "itunes:season": 1,
  "itunes:episode": 5,
  "itunes:author": "iHeartPodcasts",
  "itunes:image": "",
  "media:content": [
    {
      "media:player": ""
    },
    ""
  ],
  "guid": "803d5ee0-e696-11e8-af15-832c0f346c70",
  "omny:clipId": "1bdc98e9-549d-4ebf-abb4-ae32006e745c",
  "pubDate": "Fri, 16 Nov 2018 05:01:00 +0000",
  "itunes:duration": 2512,
  "enclosure": "",
  "link": "https://omny.fm/shows/the-end-of-the-world-with-josh-clark/artificial-intelligence"
}