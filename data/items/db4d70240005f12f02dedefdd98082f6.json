{
  "title": "Recurrent Neural Networks in Tensorflow I",
  "link": "",
  "published": "2016-07-11T00:00:00-04:00",
  "updated": "2016-07-11T00:00:00-04:00",
  "author": {
    "name": "Silviu Pitis"
  },
  "id": "tag:r2rt.com,2016-07-11:/recurrent-neural-networks-in-tensorflow-i.html",
  "summary": "This is the first in a series of posts about recurrent neural networks in Tensorflow. In this post, we will build a vanilla recurrent neural network (RNN) from the ground up in Tensorflow, and then translate the model into Tensorflow's RNN API.",
  "content": "<!DOCTYPE html>\n<html>\n<head>\n  <meta charset=\"utf-8\">\n  <meta name=\"generator\" content=\"pandoc\">\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, user-scalable=yes\">\n  <title></title>\n  <style type=\"text/css\">code{white-space: pre;}</style>\n  <style type=\"text/css\">\ndiv.sourceCode { overflow-x: auto; }\ntable.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {\n  margin: 0; padding: 0; vertical-align: baseline; border: none; }\ntable.sourceCode { width: 100%; line-height: 100%; }\ntd.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }\ntd.sourceCode { padding-left: 5px; }\ncode > span.kw { color: #007020; font-weight: bold; } /* Keyword */\ncode > span.dt { color: #902000; } /* DataType */\ncode > span.dv { color: #40a070; } /* DecVal */\ncode > span.bn { color: #40a070; } /* BaseN */\ncode > span.fl { color: #40a070; } /* Float */\ncode > span.ch { color: #4070a0; } /* Char */\ncode > span.st { color: #4070a0; } /* String */\ncode > span.co { color: #60a0b0; font-style: italic; } /* Comment */\ncode > span.ot { color: #007020; } /* Other */\ncode > span.al { color: #ff0000; font-weight: bold; } /* Alert */\ncode > span.fu { color: #06287e; } /* Function */\ncode > span.er { color: #ff0000; font-weight: bold; } /* Error */\ncode > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */\ncode > span.cn { color: #880000; } /* Constant */\ncode > span.sc { color: #4070a0; } /* SpecialChar */\ncode > span.vs { color: #4070a0; } /* VerbatimString */\ncode > span.ss { color: #bb6688; } /* SpecialString */\ncode > span.im { } /* Import */\ncode > span.va { color: #19177c; } /* Variable */\ncode > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */\ncode > span.op { color: #666666; } /* Operator */\ncode > span.bu { } /* BuiltIn */\ncode > span.ex { } /* Extension */\ncode > span.pp { color: #bc7a00; } /* Preprocessor */\ncode > span.at { color: #7d9029; } /* Attribute */\ncode > span.do { color: #ba2121; font-style: italic; } /* Documentation */\ncode > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */\ncode > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */\ncode > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */\n  </style>\n  <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML\" type=\"text/javascript\"></script>\n  <!--[if lt IE 9]>\n    <script src=\"//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js\"></script>\n  <![endif]-->\n</head>\n<body>\n<p>This is the first in a series of posts about recurrent neural networks in Tensorflow. In this post, we will build a vanilla recurrent neural network (RNN) from the ground up in Tensorflow, and then translate the model into Tensorflow’s RNN API.</p>\n<p><strong>Edit 2017/03/07</strong>: Updated to work with Tensorflow 1.0.</p>\n<h3 id=\"introduction-to-rnns\">Introduction to RNNs</h3>\n<p>RNNs are neural networks that accept their own outputs as inputs. So as to not reinvent the wheel, here are a few blog posts to introduce you to RNNs:</p>\n<ol type=\"1\">\n<li><a href=\"https://r2rt.com/written-memories-understanding-deriving-and-extending-the-lstm.html\">Written Memories: Understanding, Deriving and Extending the LSTM</a>, on this blog</li>\n<li><a href=\"http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/\">Recurrent Neural Networks Tutorial</a>, by Denny Britz</li>\n<li><a href=\"http://karpathy.github.io/2015/05/21/rnn-effectiveness/\">The Unreasonable Effectiveness of Recurrent Neural Networks</a>, by Andrej Karpathy</li>\n<li><a href=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/\">Understanding LSTM Networks</a>, by Christopher Olah</li>\n</ol>\n<h3 id=\"outline-of-the-data\">Outline of the data</h3>\n<p>In this post, we’ll be building a no frills RNN that accepts a binary sequence X and uses it to predict a binary sequence Y. The sequences are constructed as follows:</p>\n<ul>\n<li><strong>Input sequence (X)</strong>: At time step <em>t</em>, <span class=\"math inline\">\\(X_t\\)</span> has a 50% chance of being 1 (and a 50% chance of being 0). E.g., X might be [1, 0, 0, 1, 1, 1 … ].</li>\n<li><strong>Output sequence (Y)</strong>: At time step <em>t</em>, <span class=\"math inline\">\\(Y_t\\)</span> has a base 50% chance of being 1 (and a 50% base chance to be 0). The chance of <span class=\"math inline\">\\(Y_t\\)</span> being 1 is increased by 50% (i.e., to 100%) if <span class=\"math inline\">\\(X_{t-3}\\)</span> is 1, and decreased by 25% (i.e., to 25%) if <span class=\"math inline\">\\(X_{t-8}\\)</span> is 1. If both <span class=\"math inline\">\\(X_{t-3}\\)</span> and <span class=\"math inline\">\\(X_{t-8}\\)</span> are 1, the chance of <span class=\"math inline\">\\(Y_{t}\\)</span> being 1 is 50% + 50% - 25% = 75%.</li>\n</ul>\n<p>Thus, there are two dependencies in the data: one at <em>t</em>-3 (3 steps back) and one at <em>t</em>-8 (8 steps back).</p>\n<p>This data is simple enough that we can calculate the expected cross-entropy loss for a trained RNN depending on whether or not it learns the dependencies:</p>\n<ul>\n<li>If the network learns no dependencies, it will correctly assign a probability of 62.5% to 1, for an expected cross-entropy loss of about <strong>0.66</strong>.</li>\n<li>If the network learns only the first dependency (3 steps back) but not the second dependency, it will correctly assign a probability of 87.5%, 50% of the time, and correctly assign a probability of 62.5% the other 50% of the time, for an expected cross entropy loss of about <strong>0.52</strong>.</li>\n<li>If the network learns both dependencies, it will be 100% accurate 25% of the time, correctly assign a probability of 50%, 25% of the time, and correctly assign a probability of 75%, 50% of the time, for an expected cross extropy loss of about <strong>0.45</strong>.</li>\n</ul>\n<p>Here are the calculations:</p>\n<div class=\"sourceCode\"><pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"im\">import</span> numpy <span class=\"im\">as</span> np\n\n<span class=\"bu\">print</span>(<span class=\"st\">&quot;Expected cross entropy loss if the model:&quot;</span>)\n<span class=\"bu\">print</span>(<span class=\"st\">&quot;- learns neither dependency:&quot;</span>, <span class=\"op\">-</span>(<span class=\"fl\">0.625</span> <span class=\"op\">*</span> np.log(<span class=\"fl\">0.625</span>) <span class=\"op\">+</span>\n                                      <span class=\"fl\">0.375</span> <span class=\"op\">*</span> np.log(<span class=\"fl\">0.375</span>)))\n<span class=\"co\"># Learns first dependency only ==&gt; 0.51916669970720941</span>\n<span class=\"bu\">print</span>(<span class=\"st\">&quot;- learns first dependency:  &quot;</span>,\n      <span class=\"fl\">-0.5</span> <span class=\"op\">*</span> (<span class=\"fl\">0.875</span> <span class=\"op\">*</span> np.log(<span class=\"fl\">0.875</span>) <span class=\"op\">+</span> <span class=\"fl\">0.125</span> <span class=\"op\">*</span> np.log(<span class=\"fl\">0.125</span>))\n      <span class=\"fl\">-0.5</span> <span class=\"op\">*</span> (<span class=\"fl\">0.625</span> <span class=\"op\">*</span> np.log(<span class=\"fl\">0.625</span>) <span class=\"op\">+</span> <span class=\"fl\">0.375</span> <span class=\"op\">*</span> np.log(<span class=\"fl\">0.375</span>)))\n<span class=\"bu\">print</span>(<span class=\"st\">&quot;- learns both dependencies: &quot;</span>, <span class=\"fl\">-0.50</span> <span class=\"op\">*</span> (<span class=\"fl\">0.75</span> <span class=\"op\">*</span> np.log(<span class=\"fl\">0.75</span>) <span class=\"op\">+</span> <span class=\"fl\">0.25</span> <span class=\"op\">*</span> np.log(<span class=\"fl\">0.25</span>))\n      <span class=\"op\">-</span> <span class=\"fl\">0.25</span> <span class=\"op\">*</span> (<span class=\"dv\">2</span> <span class=\"op\">*</span> <span class=\"fl\">0.50</span> <span class=\"op\">*</span> np.log (<span class=\"fl\">0.50</span>)) <span class=\"op\">-</span> <span class=\"fl\">0.25</span> <span class=\"op\">*</span> (<span class=\"dv\">0</span>))</code></pre></div>\n<pre><code>Expected cross entropy loss if the model:\n- learns neither dependency: 0.661563238158\n- learns first dependency:   0.519166699707\n- learns both dependencies:  0.454454367449</code></pre>\n<h3 id=\"model-architecture\">Model architecture</h3>\n<p>The model will be as simple as possible: at time step <em>t</em>, for <span class=\"math inline\">\\(t \\in \\{0, 1, \\dots n\\}\\)</span> the model accepts a (one-hot) binary <span class=\"math inline\">\\(X_t\\)</span> vector and a previous state vector, <span class=\"math inline\">\\(S_{t-1}\\)</span>, as inputs and produces a state vector, <span class=\"math inline\">\\(S_t\\)</span>, and a predicted probability distribution vector, <span class=\"math inline\">\\(P_t\\)</span>, for the (one-hot) binary vector <span class=\"math inline\">\\(Y_t\\)</span>.</p>\n<p>Formally, the model is:</p>\n<p><span class=\"math inline\">\\(S_t = \\text{tanh}(W(X_t \\ @ \\ S_{t-1}) + b_s)\\)</span></p>\n<p><span class=\"math inline\">\\(P_t = \\text{softmax}(US_t + b_p)\\)</span></p>\n<p>where <span class=\"math inline\">\\(@\\)</span> represents vector concatenation, <span class=\"math inline\">\\(X_t \\in R^2\\)</span> is a one-hot binary vector, <span class=\"math inline\">\\(W \\in R^{d \\times (2 + d)}, \\  b_s \\in R^d, \\ U \\in R^{2 \\times d}\\)</span>, <span class=\"math inline\">\\(b_p \\in R^2\\)</span> and d is the size of the state vector (I use <span class=\"math inline\">\\(d = 4\\)</span> below). At time step 0, <span class=\"math inline\">\\(S_{-1}\\)</span> (the initial state) is initialized as a vector of zeros.</p>\n<p>Here is a diagram of the model:</p>\n<figure>\n<img src=\"https://r2rt.com/static/images/BasicRNN.png\" alt=\"Diagram of Basic RNN\" /><figcaption>Diagram of Basic RNN</figcaption>\n</figure>\n<h3 id=\"how-wide-should-our-tensorflow-graph-be\">How wide should our Tensorflow graph be?</h3>\n<p>To build models in Tensorflow generally, you first represent the model as a graph, and then execute the graph. A critical question we must answer when deciding how to represent our model is: how wide should our graph be? How many time steps of input should our graph accept at once?</p>\n<p>Each time step is a duplicate, so it might make sense to have our graph, G, represent a single time step: <span class=\"math inline\">\\(G(X_t, S_{t-1}) \\mapsto (P_t, S_t)\\)</span>. We can then execute our graph for each time step, feeding in the state returned from the previous execution into the current execution. This would work for a model that was already trained, but there’s a problem with using this approach for training: the gradients computed during backpropagation are graph-bound. We would only be able to backpropagate errors to the current timestep; we could not backpropagate the error to time step <em>t-1</em>. This means our network will not be able to learn how to store long-term dependencies (such as the two in our data) in its state.</p>\n<p>Alternatively, we might make our graph as wide as our data sequence. This often works, except that in this case, we have an arbitrarily long input sequence, so we have to stop somewhere. Let’s say we make our graph accept sequences of length 10,000. This solves the problem of graph-bound gradients, and the errors from time step 9999 are propagated all the way back to time step 0. Unfortunately, such backpropagation is not only (often prohibitively) expensive, but also ineffective, due to the vanishing / exploding gradient problem: it turns out that backpropagating errors over too many time steps often causes them to vanish (become insignificantly small) or explode (become overwhelmingly large). To understand why this is the case, we apply the chain rule repeatedly to <span class=\"math inline\">\\(\\frac{\\partial E_t}{\\partial S_{t-k}}\\)</span> and observe that there is a product of <span class=\"math inline\">\\(k\\)</span> factors (Jacobian matrices) linking the gradient at <span class=\"math inline\">\\(S_t\\)</span> and the gradient as <span class=\"math inline\">\\(S_{t-k}\\)</span>:</p>\n<p><span class=\"math display\">\\[\\frac{\\partial E_t}{\\partial S_{t-k}} =\n\\frac{\\partial E_t}{\\partial S_t}\n\\frac{\\partial S_t}{\\partial S_{t-k}} =\n\\frac{\\partial E_t}{\\partial S_t}\n\\left(\\frac{\\partial S_t}{\\partial S_{t-1}}\n\\frac{\\partial S_{t-1}}{\\partial S_{t-2}} \\dots\n\\frac{\\partial S_{t-k+1}}{\\partial S_{t-k}}\\right) =\n\\frac{\\partial E_t}{\\partial S_t}\n\\prod_{i=1}^{k}\\frac{\\partial S_{t-i+1}}{\\partial S_{t-i}}\\]</span></p>\n<p>In the words of Pascanu et al., “<em>in the same way a product of [k] real numbers can shrink to zero or explode to infinity, so does this product of matrices …</em>” See <a href=\"http://arxiv.org/pdf/1211.5063v2.pdf\">On the difficulty of training RNNs</a>, by Pascanu et al. or my post <a href=\"https://r2rt.com/written-memories-understanding-deriving-and-extending-the-lstm.html\">Written Memories: Understanding, Deriving and Extending the LSTM</a> for more detailed explanations and references.</p>\n<p>The usual pattern for dealing with very long sequences is therefore to “truncate” our backpropagation by backpropagating errors a maximum of <span class=\"math inline\">\\(n\\)</span> steps. We choose <span class=\"math inline\">\\(n\\)</span> as a hyperparameter to our model, keeping in mind the trade-off: higher <span class=\"math inline\">\\(n\\)</span> lets us capture longer term dependencies, but is more expensive computationally and memory-wise.</p>\n<p>A natural interpretation of backpropagating errors a maximum of <span class=\"math inline\">\\(n\\)</span> steps means that we backpropagate every possible error <span class=\"math inline\">\\(n\\)</span> steps. That is, if we have a sequence of length 49, and choose <span class=\"math inline\">\\(n = 7\\)</span>, we would backpropagate 42 of the errors the full 7 steps. <em>This is not the approach we take in Tensorflow.</em> Tensorflow’s approach is to limit the graph to being <span class=\"math inline\">\\(n\\)</span> units wide. See <a href=\"https://www.tensorflow.org/versions/r0.9/tutorials/recurrent/index.html#truncated-backpropagation\">Tensorflow’s writeup on Truncated Backpropagation</a> (“[Truncated backpropagation] is easy to implement by feeding inputs of length [<span class=\"math inline\">\\(n\\)</span>] at a time and doing backward pass after each iteration.”). This means that we would take our sequence of length 49, break it up into 7 sub-sequences of length 7 that we feed into the graph in 7 separate computations, and that only the errors from the 7th input in each graph are backpropagated the full 7 steps. Therefore, even if you think there are no dependencies longer than 7 steps in your data, it may still be worthwhile to use <span class=\"math inline\">\\(n &gt; 7\\)</span> so as to increase the proportion of errors that are backpropagated by 7 steps. For an empirical investigation of the difference between backpropagating every error <span class=\"math inline\">\\(n\\)</span> steps and Tensorflow-style backpropagation, see my post on <a href=\"https://r2rt.com/styles-of-truncated-backpropagation.html\">Styles of Truncated Backpropagation</a>.</p>\n<h3 id=\"using-lists-of-tensors-to-represent-the-width\">Using lists of tensors to represent the width</h3>\n<p>Our graph will be <span class=\"math inline\">\\(n\\)</span> units (time steps) wide where each unit is a perfect duplicate, sharing the same variables. The easiest way to build a graph containing these duplicate units is to build each duplicate part in parallel. This is a key point, so I’m bolding it: <strong>the easiest way to represent each type of duplicate tensor (the rnn inputs, the rnn outputs (hidden state), the predictions, and the loss) is as a <em>list</em> of tensors.</strong> Here is a diagram with references to the variables used in the code below:</p>\n<figure>\n<img src=\"https://r2rt.com/static/images/BasicRNNLabeled.png\" alt=\"Diagram of Basic RNN - Labeled\" /><figcaption>Diagram of Basic RNN - Labeled</figcaption>\n</figure>\n<p>We will run a training step after each execution of the graph, simultaneously grabbing the final state produced by that execution to pass on to the next execution.</p>\n<p>Without further ado, here is the code:</p>\n<h4 id=\"imports-config-variables-and-data-generators\">Imports, config variables, and data generators</h4>\n<div class=\"sourceCode\"><pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"im\">import</span> numpy <span class=\"im\">as</span> np\n<span class=\"im\">import</span> tensorflow <span class=\"im\">as</span> tf\n<span class=\"op\">%</span>matplotlib inline\n<span class=\"im\">import</span> matplotlib.pyplot <span class=\"im\">as</span> plt</code></pre></div>\n<div class=\"sourceCode\"><pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"co\"># Global config variables</span>\nnum_steps <span class=\"op\">=</span> <span class=\"dv\">5</span> <span class=\"co\"># number of truncated backprop steps (&#39;n&#39; in the discussion above)</span>\nbatch_size <span class=\"op\">=</span> <span class=\"dv\">200</span>\nnum_classes <span class=\"op\">=</span> <span class=\"dv\">2</span>\nstate_size <span class=\"op\">=</span> <span class=\"dv\">4</span>\nlearning_rate <span class=\"op\">=</span> <span class=\"fl\">0.1</span></code></pre></div>\n<div class=\"sourceCode\"><pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> gen_data(size<span class=\"op\">=</span><span class=\"dv\">1000000</span>):\n    X <span class=\"op\">=</span> np.array(np.random.choice(<span class=\"dv\">2</span>, size<span class=\"op\">=</span>(size,)))\n    Y <span class=\"op\">=</span> []\n    <span class=\"cf\">for</span> i <span class=\"kw\">in</span> <span class=\"bu\">range</span>(size):\n        threshold <span class=\"op\">=</span> <span class=\"fl\">0.5</span>\n        <span class=\"cf\">if</span> X[i<span class=\"dv\">-3</span>] <span class=\"op\">==</span> <span class=\"dv\">1</span>:\n            threshold <span class=\"op\">+=</span> <span class=\"fl\">0.5</span>\n        <span class=\"cf\">if</span> X[i<span class=\"dv\">-8</span>] <span class=\"op\">==</span> <span class=\"dv\">1</span>:\n            threshold <span class=\"op\">-=</span> <span class=\"fl\">0.25</span>\n        <span class=\"cf\">if</span> np.random.rand() <span class=\"op\">&gt;</span> threshold:\n            Y.append(<span class=\"dv\">0</span>)\n        <span class=\"cf\">else</span>:\n            Y.append(<span class=\"dv\">1</span>)\n    <span class=\"cf\">return</span> X, np.array(Y)\n\n<span class=\"co\"># adapted from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/ptb/reader.py</span>\n<span class=\"kw\">def</span> gen_batch(raw_data, batch_size, num_steps):\n    raw_x, raw_y <span class=\"op\">=</span> raw_data\n    data_length <span class=\"op\">=</span> <span class=\"bu\">len</span>(raw_x)\n\n    <span class=\"co\"># partition raw data into batches and stack them vertically in a data matrix</span>\n    batch_partition_length <span class=\"op\">=</span> data_length <span class=\"op\">//</span> batch_size\n    data_x <span class=\"op\">=</span> np.zeros([batch_size, batch_partition_length], dtype<span class=\"op\">=</span>np.int32)\n    data_y <span class=\"op\">=</span> np.zeros([batch_size, batch_partition_length], dtype<span class=\"op\">=</span>np.int32)\n    <span class=\"cf\">for</span> i <span class=\"kw\">in</span> <span class=\"bu\">range</span>(batch_size):\n        data_x[i] <span class=\"op\">=</span> raw_x[batch_partition_length <span class=\"op\">*</span> i:batch_partition_length <span class=\"op\">*</span> (i <span class=\"op\">+</span> <span class=\"dv\">1</span>)]\n        data_y[i] <span class=\"op\">=</span> raw_y[batch_partition_length <span class=\"op\">*</span> i:batch_partition_length <span class=\"op\">*</span> (i <span class=\"op\">+</span> <span class=\"dv\">1</span>)]\n    <span class=\"co\"># further divide batch partitions into num_steps for truncated backprop</span>\n    epoch_size <span class=\"op\">=</span> batch_partition_length <span class=\"op\">//</span> num_steps\n\n    <span class=\"cf\">for</span> i <span class=\"kw\">in</span> <span class=\"bu\">range</span>(epoch_size):\n        x <span class=\"op\">=</span> data_x[:, i <span class=\"op\">*</span> num_steps:(i <span class=\"op\">+</span> <span class=\"dv\">1</span>) <span class=\"op\">*</span> num_steps]\n        y <span class=\"op\">=</span> data_y[:, i <span class=\"op\">*</span> num_steps:(i <span class=\"op\">+</span> <span class=\"dv\">1</span>) <span class=\"op\">*</span> num_steps]\n        <span class=\"cf\">yield</span> (x, y)\n\n<span class=\"kw\">def</span> gen_epochs(n, num_steps):\n    <span class=\"cf\">for</span> i <span class=\"kw\">in</span> <span class=\"bu\">range</span>(n):\n        <span class=\"cf\">yield</span> gen_batch(gen_data(), batch_size, num_steps)</code></pre></div>\n<h4 id=\"model\">Model</h4>\n<div class=\"sourceCode\"><pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"co\">&quot;&quot;&quot;</span>\n<span class=\"co\">Placeholders</span>\n<span class=\"co\">&quot;&quot;&quot;</span>\n\nx <span class=\"op\">=</span> tf.placeholder(tf.int32, [batch_size, num_steps], name<span class=\"op\">=</span><span class=\"st\">&#39;input_placeholder&#39;</span>)\ny <span class=\"op\">=</span> tf.placeholder(tf.int32, [batch_size, num_steps], name<span class=\"op\">=</span><span class=\"st\">&#39;labels_placeholder&#39;</span>)\ninit_state <span class=\"op\">=</span> tf.zeros([batch_size, state_size])\n\n<span class=\"co\">&quot;&quot;&quot;</span>\n<span class=\"co\">RNN Inputs</span>\n<span class=\"co\">&quot;&quot;&quot;</span>\n\n<span class=\"co\"># Turn our x placeholder into a list of one-hot tensors:</span>\n<span class=\"co\"># rnn_inputs is a list of num_steps tensors with shape [batch_size, num_classes]</span>\nx_one_hot <span class=\"op\">=</span> tf.one_hot(x, num_classes)\nrnn_inputs <span class=\"op\">=</span> tf.unstack(x_one_hot, axis<span class=\"op\">=</span><span class=\"dv\">1</span>)</code></pre></div>\n<div class=\"sourceCode\"><pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"co\">&quot;&quot;&quot;</span>\n<span class=\"co\">Definition of rnn_cell</span>\n\n<span class=\"co\">This is very similar to the __call__ method on Tensorflow&#39;s BasicRNNCell. See:</span>\n<span class=\"co\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py#L95</span>\n<span class=\"co\">&quot;&quot;&quot;</span>\n<span class=\"cf\">with</span> tf.variable_scope(<span class=\"st\">&#39;rnn_cell&#39;</span>):\n    W <span class=\"op\">=</span> tf.get_variable(<span class=\"st\">&#39;W&#39;</span>, [num_classes <span class=\"op\">+</span> state_size, state_size])\n    b <span class=\"op\">=</span> tf.get_variable(<span class=\"st\">&#39;b&#39;</span>, [state_size], initializer<span class=\"op\">=</span>tf.constant_initializer(<span class=\"fl\">0.0</span>))\n\n<span class=\"kw\">def</span> rnn_cell(rnn_input, state):\n    <span class=\"cf\">with</span> tf.variable_scope(<span class=\"st\">&#39;rnn_cell&#39;</span>, reuse<span class=\"op\">=</span><span class=\"va\">True</span>):\n        W <span class=\"op\">=</span> tf.get_variable(<span class=\"st\">&#39;W&#39;</span>, [num_classes <span class=\"op\">+</span> state_size, state_size])\n        b <span class=\"op\">=</span> tf.get_variable(<span class=\"st\">&#39;b&#39;</span>, [state_size], initializer<span class=\"op\">=</span>tf.constant_initializer(<span class=\"fl\">0.0</span>))\n    <span class=\"cf\">return</span> tf.tanh(tf.matmul(tf.concat([rnn_input, state], <span class=\"dv\">1</span>), W) <span class=\"op\">+</span> b)</code></pre></div>\n<div class=\"sourceCode\"><pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"co\">&quot;&quot;&quot;</span>\n<span class=\"co\">Adding rnn_cells to graph</span>\n\n<span class=\"co\">This is a simplified version of the &quot;static_rnn&quot; function from Tensorflow&#39;s api. See:</span>\n<span class=\"co\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/rnn/python/ops/core_rnn.py#L41</span>\n<span class=\"co\">Note: In practice, using &quot;dynamic_rnn&quot; is a better choice that the &quot;static_rnn&quot;:</span>\n<span class=\"co\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn.py#L390</span>\n<span class=\"co\">&quot;&quot;&quot;</span>\nstate <span class=\"op\">=</span> init_state\nrnn_outputs <span class=\"op\">=</span> []\n<span class=\"cf\">for</span> rnn_input <span class=\"kw\">in</span> rnn_inputs:\n    state <span class=\"op\">=</span> rnn_cell(rnn_input, state)\n    rnn_outputs.append(state)\nfinal_state <span class=\"op\">=</span> rnn_outputs[<span class=\"op\">-</span><span class=\"dv\">1</span>]</code></pre></div>\n<div class=\"sourceCode\"><pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"co\">&quot;&quot;&quot;</span>\n<span class=\"co\">Predictions, loss, training step</span>\n\n<span class=\"co\">Losses is similar to the &quot;sequence_loss&quot;</span>\n<span class=\"co\">function from Tensorflow&#39;s API, except that here we are using a list of 2D tensors, instead of a 3D tensor. See:</span>\n<span class=\"co\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/seq2seq/python/ops/loss.py#L30</span>\n<span class=\"co\">&quot;&quot;&quot;</span>\n\n<span class=\"co\">#logits and predictions</span>\n<span class=\"cf\">with</span> tf.variable_scope(<span class=\"st\">&#39;softmax&#39;</span>):\n    W <span class=\"op\">=</span> tf.get_variable(<span class=\"st\">&#39;W&#39;</span>, [state_size, num_classes])\n    b <span class=\"op\">=</span> tf.get_variable(<span class=\"st\">&#39;b&#39;</span>, [num_classes], initializer<span class=\"op\">=</span>tf.constant_initializer(<span class=\"fl\">0.0</span>))\nlogits <span class=\"op\">=</span> [tf.matmul(rnn_output, W) <span class=\"op\">+</span> b <span class=\"cf\">for</span> rnn_output <span class=\"kw\">in</span> rnn_outputs]\npredictions <span class=\"op\">=</span> [tf.nn.softmax(logit) <span class=\"cf\">for</span> logit <span class=\"kw\">in</span> logits]\n\n<span class=\"co\"># Turn our y placeholder into a list of labels</span>\ny_as_list <span class=\"op\">=</span> tf.unstack(y, num<span class=\"op\">=</span>num_steps, axis<span class=\"op\">=</span><span class=\"dv\">1</span>)\n\n<span class=\"co\">#losses and train_step</span>\nlosses <span class=\"op\">=</span> [tf.nn.sparse_softmax_cross_entropy_with_logits(labels<span class=\"op\">=</span>label, logits<span class=\"op\">=</span>logit) <span class=\"cf\">for</span> <span class=\"op\">\\</span>\n          logit, label <span class=\"kw\">in</span> <span class=\"bu\">zip</span>(logits, y_as_list)]\ntotal_loss <span class=\"op\">=</span> tf.reduce_mean(losses)\ntrain_step <span class=\"op\">=</span> tf.train.AdagradOptimizer(learning_rate).minimize(total_loss)</code></pre></div>\n<div class=\"sourceCode\"><pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"co\">&quot;&quot;&quot;</span>\n<span class=\"co\">Train the network</span>\n<span class=\"co\">&quot;&quot;&quot;</span>\n\n<span class=\"kw\">def</span> train_network(num_epochs, num_steps, state_size<span class=\"op\">=</span><span class=\"dv\">4</span>, verbose<span class=\"op\">=</span><span class=\"va\">True</span>):\n    <span class=\"cf\">with</span> tf.Session() <span class=\"im\">as</span> sess:\n        sess.run(tf.global_variables_initializer())\n        training_losses <span class=\"op\">=</span> []\n        <span class=\"cf\">for</span> idx, epoch <span class=\"kw\">in</span> <span class=\"bu\">enumerate</span>(gen_epochs(num_epochs, num_steps)):\n            training_loss <span class=\"op\">=</span> <span class=\"dv\">0</span>\n            training_state <span class=\"op\">=</span> np.zeros((batch_size, state_size))\n            <span class=\"cf\">if</span> verbose:\n                <span class=\"bu\">print</span>(<span class=\"st\">&quot;</span><span class=\"ch\">\\n</span><span class=\"st\">EPOCH&quot;</span>, idx)\n            <span class=\"cf\">for</span> step, (X, Y) <span class=\"kw\">in</span> <span class=\"bu\">enumerate</span>(epoch):\n                tr_losses, training_loss_, training_state, _ <span class=\"op\">=</span> <span class=\"op\">\\</span>\n                    sess.run([losses,\n                              total_loss,\n                              final_state,\n                              train_step],\n                                  feed_dict<span class=\"op\">=</span>{x:X, y:Y, init_state:training_state})\n                training_loss <span class=\"op\">+=</span> training_loss_\n                <span class=\"cf\">if</span> step <span class=\"op\">%</span> <span class=\"dv\">100</span> <span class=\"op\">==</span> <span class=\"dv\">0</span> <span class=\"kw\">and</span> step <span class=\"op\">&gt;</span> <span class=\"dv\">0</span>:\n                    <span class=\"cf\">if</span> verbose:\n                        <span class=\"bu\">print</span>(<span class=\"st\">&quot;Average loss at step&quot;</span>, step,\n                              <span class=\"st\">&quot;for last 250 steps:&quot;</span>, training_loss<span class=\"op\">/</span><span class=\"dv\">100</span>)\n                    training_losses.append(training_loss<span class=\"op\">/</span><span class=\"dv\">100</span>)\n                    training_loss <span class=\"op\">=</span> <span class=\"dv\">0</span>\n\n    <span class=\"cf\">return</span> training_losses</code></pre></div>\n<div class=\"sourceCode\"><pre class=\"sourceCode python\"><code class=\"sourceCode python\">training_losses <span class=\"op\">=</span> train_network(<span class=\"dv\">1</span>,num_steps)\nplt.plot(training_losses)</code></pre></div>\n<pre><code>EPOCH 0\nAverage loss at step 100 for last 250 steps: 0.6559883219\nAverage loss at step 200 for last 250 steps: 0.617185292244\nAverage loss at step 300 for last 250 steps: 0.595771013498\nAverage loss at step 400 for last 250 steps: 0.568864737153\nAverage loss at step 500 for last 250 steps: 0.524139249921\nAverage loss at step 600 for last 250 steps: 0.522666031122\nAverage loss at step 700 for last 250 steps: 0.522012578249\nAverage loss at step 800 for last 250 steps: 0.519179680347\nAverage loss at step 900 for last 250 steps: 0.519965928495</code></pre>\n<figure>\n<img src=\"https://r2rt.com/static/images/RNN_output_21_2.png\" alt=\"RNN Output, num_steps = 5\" /><figcaption>RNN Output, num_steps = 5</figcaption>\n</figure>\n<p>As you can see, the network very quickly learns to capture the first dependency (but not the second), and converges to the expected cross-entropy loss of 0.52.</p>\n<p>Exporting our model to a separate file in order to play with hyperparameters, we can see what happens when we use <code>num_steps = 1</code> and <code>num_steps = 10</code> (for this latter case, we also increase the state_size so as to maintain the the information about the second dependency for the required 8 steps):</p>\n<div class=\"sourceCode\"><pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"im\">import</span> basic_rnn\n<span class=\"kw\">def</span> plot_learning_curve(num_steps, state_size<span class=\"op\">=</span><span class=\"dv\">4</span>, epochs<span class=\"op\">=</span><span class=\"dv\">1</span>):\n    <span class=\"kw\">global</span> losses, total_loss, final_state, train_step, x, y, init_state\n    tf.reset_default_graph()\n    g <span class=\"op\">=</span> tf.get_default_graph()\n    losses, total_loss, final_state, train_step, x, y, init_state <span class=\"op\">=</span> <span class=\"op\">\\</span>\n        basic_rnn.setup_graph(g,\n            basic_rnn.RNN_config(num_steps<span class=\"op\">=</span>num_steps, state_size<span class=\"op\">=</span>state_size))\n    res <span class=\"op\">=</span> train_network(epochs, num_steps, state_size<span class=\"op\">=</span>state_size, verbose<span class=\"op\">=</span><span class=\"va\">False</span>)\n    plt.plot(res)</code></pre></div>\n<div class=\"sourceCode\"><pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"co\">&quot;&quot;&quot;</span>\n<span class=\"co\">NUM_STEPS = 1</span>\n<span class=\"co\">&quot;&quot;&quot;</span>\nplot_learning_curve(num_steps<span class=\"op\">=</span><span class=\"dv\">1</span>, state_size<span class=\"op\">=</span><span class=\"dv\">4</span>, epochs<span class=\"op\">=</span><span class=\"dv\">2</span>)</code></pre></div>\n<figure>\n<img src=\"https://r2rt.com/static/images/RNN_output_25_0.png\" alt=\"RNN Output, num_steps = 1\" /><figcaption>RNN Output, num_steps = 1</figcaption>\n</figure>\n<div class=\"sourceCode\"><pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"co\">&quot;&quot;&quot;</span>\n<span class=\"co\">NUM_STEPS = 10</span>\n<span class=\"co\">&quot;&quot;&quot;</span>\nplot_learning_curve(num_steps<span class=\"op\">=</span><span class=\"dv\">10</span>, state_size<span class=\"op\">=</span><span class=\"dv\">16</span>, epochs<span class=\"op\">=</span><span class=\"dv\">10</span>)</code></pre></div>\n<figure>\n<img src=\"https://r2rt.com/static/images/RNN_output_26_0.png\" alt=\"RNN Output, num_steps = 10\" /><figcaption>RNN Output, num_steps = 10</figcaption>\n</figure>\n<p>As expected, using <code>num_steps = 10</code> comes close to our expected cross-entropy for knowing both dependencies (0.454). However, using <code>num_steps = 1</code> hovers around something slightly better than the expected cross-entropy for knowing neither dependency (0.66), and doesn’t seem to converge. What’s going on?</p>\n<p>The answer is that some information about the first dependency is making its way into the incoming state by pure chance. Although the model can’t learn weights that will maintain information about the first dependency (due to the backpropagation being graph-bound), it can learn to take advantage of whatever information about <span class=\"math inline\">\\(X_{t-3}\\)</span> is left over in <span class=\"math inline\">\\(S_{t-1}\\)</span>. In doing so, the model changes the way information about <span class=\"math inline\">\\(X_{t-3}\\)</span> is stored in <span class=\"math inline\">\\(S_{t-1}\\)</span>, which explains why the loss goes up and down, rather than settling at a local minima.</p>\n<h3 id=\"translating-our-model-to-tensorflow\">Translating our model to Tensorflow</h3>\n<p>Translating our model to Tensorflow’s API is easy. We simply replace these two sections:</p>\n<div class=\"sourceCode\"><pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"co\">&quot;&quot;&quot;</span>\n<span class=\"co\">Definition of rnn_cell</span>\n\n<span class=\"co\">This is very similar to the __call__ method on Tensorflow&#39;s BasicRNNCell. See:</span>\n<span class=\"co\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py#L95</span>\n<span class=\"co\">&quot;&quot;&quot;</span>\n<span class=\"cf\">with</span> tf.variable_scope(<span class=\"st\">&#39;rnn_cell&#39;</span>):\n    W <span class=\"op\">=</span> tf.get_variable(<span class=\"st\">&#39;W&#39;</span>, [num_classes <span class=\"op\">+</span> state_size, state_size])\n    b <span class=\"op\">=</span> tf.get_variable(<span class=\"st\">&#39;b&#39;</span>, [state_size], initializer<span class=\"op\">=</span>tf.constant_initializer(<span class=\"fl\">0.0</span>))\n\n<span class=\"kw\">def</span> rnn_cell(rnn_input, state):\n    <span class=\"cf\">with</span> tf.variable_scope(<span class=\"st\">&#39;rnn_cell&#39;</span>, reuse<span class=\"op\">=</span><span class=\"va\">True</span>):\n        W <span class=\"op\">=</span> tf.get_variable(<span class=\"st\">&#39;W&#39;</span>, [num_classes <span class=\"op\">+</span> state_size, state_size])\n        b <span class=\"op\">=</span> tf.get_variable(<span class=\"st\">&#39;b&#39;</span>, [state_size], initializer<span class=\"op\">=</span>tf.constant_initializer(<span class=\"fl\">0.0</span>))\n    <span class=\"cf\">return</span> tf.tanh(tf.matmul(tf.concat([rnn_input, state], <span class=\"dv\">1</span>), W) <span class=\"op\">+</span> b)\n\n<span class=\"co\">&quot;&quot;&quot;</span>\n<span class=\"co\">Adding rnn_cells to graph</span>\n\n<span class=\"co\">This is a simplified version of the &quot;static_rnn&quot; function from Tensorflow&#39;s api. See:</span>\n<span class=\"co\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/rnn/python/ops/core_rnn.py#L41</span>\n<span class=\"co\">Note: In practice, using &quot;dynamic_rnn&quot; is a better choice that the &quot;static_rnn&quot;:</span>\n<span class=\"co\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn.py#L390</span>\n<span class=\"co\">&quot;&quot;&quot;</span>\nstate <span class=\"op\">=</span> init_state\nrnn_outputs <span class=\"op\">=</span> []\n<span class=\"cf\">for</span> rnn_input <span class=\"kw\">in</span> rnn_inputs:\n    state <span class=\"op\">=</span> rnn_cell(rnn_input, state)\n    rnn_outputs.append(state)\nfinal_state <span class=\"op\">=</span> rnn_outputs[<span class=\"op\">-</span><span class=\"dv\">1</span>]</code></pre></div>\n<p>With these two lines:</p>\n<div class=\"sourceCode\"><pre class=\"sourceCode python\"><code class=\"sourceCode python\">cell <span class=\"op\">=</span> tf.contrib.rnn.BasicRNNCell(state_size)\nrnn_outputs, final_state <span class=\"op\">=</span> tf.contrib.rnn.static_rnn(cell, rnn_inputs, initial_state<span class=\"op\">=</span>init_state)</code></pre></div>\n<h3 id=\"using-a-dynamic-rnn\">Using a dynamic RNN</h3>\n<p>Above, we added every node for every timestep to the graph before execution. This is called “static” construction. We could also let Tensorflow dynamically create the graph at execution time, which can be more efficient. To do this, instead of using a list of tensors (of length <code>num_steps</code> and shape <code>[batch_size, features]</code>), we keep everything in a single 3-dimnesional tensor of shape <code>[batch_size, num_steps, features]</code>, and use Tensorflow’s <code>dynamic_rnn</code> function. This is shown below.</p>\n<h3 id=\"final-model-static\">Final model — static</h3>\n<p>To recap, here’s the entire static model, as modified to use Tensorflow’s API:</p>\n<div class=\"sourceCode\"><pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"co\">&quot;&quot;&quot;</span>\n<span class=\"co\">Placeholders</span>\n<span class=\"co\">&quot;&quot;&quot;</span>\n\nx <span class=\"op\">=</span> tf.placeholder(tf.int32, [batch_size, num_steps], name<span class=\"op\">=</span><span class=\"st\">&#39;input_placeholder&#39;</span>)\ny <span class=\"op\">=</span> tf.placeholder(tf.int32, [batch_size, num_steps], name<span class=\"op\">=</span><span class=\"st\">&#39;labels_placeholder&#39;</span>)\ninit_state <span class=\"op\">=</span> tf.zeros([batch_size, state_size])\n\n<span class=\"co\">&quot;&quot;&quot;</span>\n<span class=\"co\">Inputs</span>\n<span class=\"co\">&quot;&quot;&quot;</span>\n\nx_one_hot <span class=\"op\">=</span> tf.one_hot(x, num_classes)\nrnn_inputs <span class=\"op\">=</span> tf.unstack(x_one_hot, axis<span class=\"op\">=</span><span class=\"dv\">1</span>)\n\n<span class=\"co\">&quot;&quot;&quot;</span>\n<span class=\"co\">RNN</span>\n<span class=\"co\">&quot;&quot;&quot;</span>\n\ncell <span class=\"op\">=</span> tf.contrib.rnn.BasicRNNCell(state_size)\nrnn_outputs, final_state <span class=\"op\">=</span> tf.contrib.rnn.static_rnn(cell, rnn_inputs, initial_state<span class=\"op\">=</span>init_state)\n\n<span class=\"co\">&quot;&quot;&quot;</span>\n<span class=\"co\">Predictions, loss, training step</span>\n<span class=\"co\">&quot;&quot;&quot;</span>\n\n<span class=\"cf\">with</span> tf.variable_scope(<span class=\"st\">&#39;softmax&#39;</span>):\n    W <span class=\"op\">=</span> tf.get_variable(<span class=\"st\">&#39;W&#39;</span>, [state_size, num_classes])\n    b <span class=\"op\">=</span> tf.get_variable(<span class=\"st\">&#39;b&#39;</span>, [num_classes], initializer<span class=\"op\">=</span>tf.constant_initializer(<span class=\"fl\">0.0</span>))\nlogits <span class=\"op\">=</span> [tf.matmul(rnn_output, W) <span class=\"op\">+</span> b <span class=\"cf\">for</span> rnn_output <span class=\"kw\">in</span> rnn_outputs]\npredictions <span class=\"op\">=</span> [tf.nn.softmax(logit) <span class=\"cf\">for</span> logit <span class=\"kw\">in</span> logits]\n\ny_as_list <span class=\"op\">=</span> tf.unstack(y, num<span class=\"op\">=</span>num_steps, axis<span class=\"op\">=</span><span class=\"dv\">1</span>)\n\nlosses <span class=\"op\">=</span> [tf.nn.sparse_softmax_cross_entropy_with_logits(labels<span class=\"op\">=</span>label, logits<span class=\"op\">=</span>logit) <span class=\"cf\">for</span> <span class=\"op\">\\</span>\n          logit, label <span class=\"kw\">in</span> <span class=\"bu\">zip</span>(logits, y_as_list)]\ntotal_loss <span class=\"op\">=</span> tf.reduce_mean(losses)\ntrain_step <span class=\"op\">=</span> tf.train.AdagradOptimizer(learning_rate).minimize(total_loss)</code></pre></div>\n<h3 id=\"final-model-dynamic\">Final model — dynamic</h3>\n<p>And here it is with the <code>dynamic_rnn</code> API, which should be preferred over the static API:</p>\n<div class=\"sourceCode\"><pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"co\">&quot;&quot;&quot;</span>\n<span class=\"co\">Placeholders</span>\n<span class=\"co\">&quot;&quot;&quot;</span>\n\nx <span class=\"op\">=</span> tf.placeholder(tf.int32, [batch_size, num_steps], name<span class=\"op\">=</span><span class=\"st\">&#39;input_placeholder&#39;</span>)\ny <span class=\"op\">=</span> tf.placeholder(tf.int32, [batch_size, num_steps], name<span class=\"op\">=</span><span class=\"st\">&#39;labels_placeholder&#39;</span>)\ninit_state <span class=\"op\">=</span> tf.zeros([batch_size, state_size])\n\n<span class=\"co\">&quot;&quot;&quot;</span>\n<span class=\"co\">Inputs</span>\n<span class=\"co\">&quot;&quot;&quot;</span>\n\nrnn_inputs <span class=\"op\">=</span> tf.one_hot(x, num_classes)\n\n<span class=\"co\">&quot;&quot;&quot;</span>\n<span class=\"co\">RNN</span>\n<span class=\"co\">&quot;&quot;&quot;</span>\n\ncell <span class=\"op\">=</span> tf.contrib.rnn.BasicRNNCell(state_size)\nrnn_outputs, final_state <span class=\"op\">=</span> tf.nn.dynamic_rnn(cell, rnn_inputs, initial_state<span class=\"op\">=</span>init_state)\n\n<span class=\"co\">&quot;&quot;&quot;</span>\n<span class=\"co\">Predictions, loss, training step</span>\n<span class=\"co\">&quot;&quot;&quot;</span>\n\n<span class=\"cf\">with</span> tf.variable_scope(<span class=\"st\">&#39;softmax&#39;</span>):\n    W <span class=\"op\">=</span> tf.get_variable(<span class=\"st\">&#39;W&#39;</span>, [state_size, num_classes])\n    b <span class=\"op\">=</span> tf.get_variable(<span class=\"st\">&#39;b&#39;</span>, [num_classes], initializer<span class=\"op\">=</span>tf.constant_initializer(<span class=\"fl\">0.0</span>))\nlogits <span class=\"op\">=</span> tf.reshape(\n            tf.matmul(tf.reshape(rnn_outputs, [<span class=\"op\">-</span><span class=\"dv\">1</span>, state_size]), W) <span class=\"op\">+</span> b,\n            [batch_size, num_steps, num_classes])\npredictions <span class=\"op\">=</span> tf.nn.softmax(logits)\n\nlosses <span class=\"op\">=</span> tf.nn.sparse_softmax_cross_entropy_with_logits(labels<span class=\"op\">=</span>y, logits<span class=\"op\">=</span>logits)\ntotal_loss <span class=\"op\">=</span> tf.reduce_mean(losses)\ntrain_step <span class=\"op\">=</span> tf.train.AdagradOptimizer(learning_rate).minimize(total_loss)</code></pre></div>\n<h3 id=\"conclusion\">Conclusion</h3>\n<p>And there you have it, a basic RNN In Tensorflow. In the <a href=\"https://r2rt.com/recurrent-neural-networks-in-tensorflow-ii.html\">next post</a> of this series, we’ll look at how to improve our base implementation, how to upgrade to a GRU/LSTM or other custom RNN cell and use multiple layers, how to add features like dropout and layer normalization, and how to use our RNN to generate sequences.</p>\n</body>\n</html>"
}