{
  "title": "Convergence Rates for Learning Linear Operators from Noisy Data. (arXiv:2108.12515v3 [math.ST] UPDATED)",
  "link": "http://arxiv.org/abs/2108.12515",
  "description": "<p>This paper studies the learning of linear operators between\ninfinite-dimensional Hilbert spaces. The training data comprises pairs of\nrandom input vectors in a Hilbert space and their noisy images under an unknown\nself-adjoint linear operator. Assuming that the operator is diagonalizable in a\nknown basis, this work solves the equivalent inverse problem of estimating the\noperator's eigenvalues given the data. Adopting a Bayesian approach, the\ntheoretical analysis establishes posterior contraction rates in the infinite\ndata limit with Gaussian priors that are not directly linked to the forward map\nof the inverse problem. The main results also include learning-theoretic\ngeneralization error guarantees for a wide range of distribution shifts. These\nconvergence rates quantify the effects of data smoothness and true eigenvalue\ndecay or growth, for compact or unbounded operators, respectively, on sample\ncomplexity. Numerical evidence supports the theory in diagonal and non-diagonal\nsettings.\n</p>",
  "dc:creator": "<a href=\"http://arxiv.org/find/math/1/au:+Hoop_M/0/1/0/all/0/1\">Maarten V. de Hoop</a>, <a href=\"http://arxiv.org/find/math/1/au:+Kovachki_N/0/1/0/all/0/1\">Nikola B. Kovachki</a>, <a href=\"http://arxiv.org/find/math/1/au:+Nelsen_N/0/1/0/all/0/1\">Nicholas H. Nelsen</a>, <a href=\"http://arxiv.org/find/math/1/au:+Stuart_A/0/1/0/all/0/1\">Andrew M. Stuart</a>"
}