{
  "title": "Top 10 Data Innovation Trends During 2020",
  "link": "http://rocketdatascience.org/?p=1589",
  "comments": "http://rocketdatascience.org/?p=1589#respond",
  "dc:creator": "Kirk Borne",
  "pubDate": "Tue, 06 Jul 2021 17:42:37 +0000",
  "category": [
    "Analytics",
    "Artificial Intelligence",
    "Big Data",
    "Internet of Things",
    "Machine Learning",
    "Strategy"
  ],
  "guid": "http://rocketdatascience.org/?p=1589",
  "description": "The year 2020 was remarkably different in many ways from previous years. In at least one way, it was not different, and that was in the continued development of innovations that are inspired by data. This steady march of data-driven innovation has been a consistent characteristic of each year for at least the past decade. [&#8230;]",
  "content:encoded": "\n<p>The year 2020 was remarkably different in many\nways from previous years. In at least one way, it was not different, and that was\nin the continued development of innovations that are inspired by data. This\nsteady march of data-driven innovation has been a consistent characteristic of\neach year for at least the past decade. These data-fueled innovations come in\nthe form of new algorithms, new technologies, new applications, new concepts,\nand even some “old things made new again”.</p>\n\n\n\n<p>I provide below my perspective on what was\ninteresting, innovative, and influential in my watch list of the Top 10 data\ninnovation trends during 2020. </p>\n\n\n\n<p>1)&nbsp;Automated Narrative Text Generation\ntools became incredibly good in 2020, being able to create scary good “deep\nfake” articles. The GPT-3 (Generative Pretrained Transformer, 3rd generation\ntext autocomplete) algorithm made headlines since it demonstrated that it can\nstart with a very thin amount of input (a short topic description, or a question),\nfrom which it can then generate several paragraphs of narrative that are very\nhard (perhaps impossible) to distinguish from human-generated text. However, it\nis far from perfect, since it certainly does not have reasoning skills, and it\nalso loses its “train of thought” after several paragraphs (e.g., by making\ncontradictory statements at different places in the narrative, even though the\nstatements are nicely formed sentences).</p>\n\n\n\n<p>2) MLOps became the expected norm\nin&nbsp;machine&nbsp;learning&nbsp;and data science projects. MLOps takes the\nmodeling, algorithms, and data wrangling out of the experimental “one off”\nphase and moves the best models into deployment and sustained operational&nbsp;phase.\nMLOps &#8220;done right&#8221; addresses sustainable model operations, explainability,\ntrust, versioning, reproducibility, training updates, and governance (i.e., the\nmonitoring of very important operational ML characteristics: data drift,\nconcept drift, and model security).</p>\n\n\n\n<p>3) Concept drift by COVID – as mentioned above, concept drift is being addressed in machine learning and data science projects by MLOps, but concept drift is so much bigger than MLOps. Specifically, it feels to many of us like a decade of business transformation was compressed into the one year 2020. How and why businesses make decisions, customers make decisions, and anybody else makes decisions became conceptually and contextually different in 2020. Customer purchase patterns, supply chain, inventory, and logistics represent just a few domains where we saw new and emergent behaviors, responses, and outcomes represented in our data and in our predictive models. The old models were not able to predict very well based on the previous year’s data since the previous year seemed like 100 years ago in “data years”. Another example was in new data-driven cybersecurity practices introduced by the COVID pandemic, including behavior biometrics (or biometric analytics), which were driven strongly by the global “work from home” transition, where many insecurities in networks, data-sharing, and collaboration / communication tools were exposed. Behavior biometrics may possibly become the essential cyber requirement for unique user identification, finally putting weak passwords out of commission. Data and network access controls have similar user-based permissions when working from home as when working behind the firewall at your place of business, but the security checks and usage tracking can be more verifiable and certified with biometric analytics. This is critical in our massively data-sharing world and enterprises.</p>\n\n\n\n<p>4) AIOps increasingly became a focus in AI\nstrategy conversations. While it is similar to MLOps, AIOps is less focused on\nthe ML algorithms and more focused on automation and AI applications in the\nenterprise IT environment – i.e., focused on operationalizing AI, including\ndata orchestration, the AI platform, AI outcomes monitoring, and cybersecurity\nrequirements. AIOps appears in discussions related to ITIM (IT infrastructure\nmonitoring), SIEM (security information and event management), APM (application\nperformance monitoring), UEBA (user and entity behavior analytics), DevSecOps,\nAnomaly Detection, Rout Cause Analysis, Alert Generation, and related\nenterprise IT applications.</p>\n\n\n\n<p>5) The emergence of Edge-to-Cloud\narchitectures clearly began pushing Industry 4.0 forward (with some folks now starting\nto envision what Industry 5.0 will look like). The Edge-to-Cloud architectures are\nresponding to the growth of IoT sensors and devices everywhere, whose\ndeployments are boosted by 5G capabilities that are now helping to\nsignificantly reduce data-to-action latency. In some cases, the analytics and\nintelligence must be computed and acted upon at the edge (Edge Computing, at\nthe point of data collection), as in autonomous vehicles. In other cases, the\nanalytics and insights may have more significant computation requirements and\nless strict latency requirements, thus allowing the data to be moved to larger\ncomputational resources in the cloud. The almost forgotten &#8220;orphan&#8221;\nin these architectures, Fog Computing (living between edge and cloud), is now moving\nto a more significant status in data and analytics architecture design. </p>\n\n\n\n<p>6)&nbsp;Federated&nbsp;Machine&nbsp;Learning&nbsp;(FML)\nis another &#8220;orphan&#8221; concept (formerly called Distributed Data Mining\na decade ago) that found new life in modeling requirements, algorithms, and\napplications in 2020. To some extent, the pandemic contributed to this\nbecause&nbsp;FML&nbsp;enforces data privacy by essentially removing\ndata-sharing as a requirement for model-building across multiple datasets,\nmultiple organizations, and multiple applications. FML model training is done incrementally\nand locally on the local dataset, with the meta-parameters of the local models\nthen being shared with a centralized model-inference engine (which does not see\nany of the private data). The centralized ML engine then builds a global model,\nwhich is communicated back to the local nodes. Multiple iterations in\nparameter-updating and hyperparameter-tuning can occur between local nodes and\nthe central inference engine, until satisfactory model performance is achieved.\nAll through these training stages, data privacy is preserved, while allowing\nfor the generation of globally useful, distributable, and accurate models.</p>\n\n\n\n<p>7) Deep learning (DL) may not be “the one\nalgorithm to dominate all others” after all. There was some research published\nearlier in 2020 that found that traditional, less complex algorithms can be\nnearly as good or better than deep learning on some tasks. This could be yet\nanother demonstration of the “no free lunch theorem”, which basically states\nthat there is no single universal algorithm that is the best for all problems.\nConsequently, the results of the new DL research may not be so surprising, but\nthey certainly prompt us with necessary reminders that sometimes simple is\nbetter than complexity, and that the old saying is often still true: <em>“perfect\nis the enemy of good enough.”</em></p>\n\n\n\n<p>8) RPA (Robotic Process Automation) and\nintelligent automation&nbsp;were not new in 2020, but the surge in their use\nand in the number of providers was remarkable. While RPA is more rule-based\n(informed by business process mining, to automate work tasks that have very\nlittle variation), intelligent automation is more data-driven, adaptable, and\nself-learning in real-time. RPA mimics human actions, by repetition of routine\ntasks based on a set of rules. Intelligent automation simulates human\nintelligence, which responds and adapts to emergent patterns in new data, and\nwhich is capable of learning to automate non-routine tasks. Keep an eye on the\nintelligent automation space for new and exciting developments to come in the\nnear future around hyperautomation and enterprise intelligence, such as the\nemergence of learning business systems that learn and adapt their processes\nbased on signals in enterprise data across numerous business functions:\nfinance, marketing, HR, customer service, production, operations, sales, and\nmanagement.</p>\n\n\n\n<p>9) The Rise of Data Literacy initiatives,\nimperatives, instructional programs, and institutional awareness in 2020 was\none of the two most exciting things that I witnessed during the year. (The\nother one of the two is next on my list.) I have said for nearly 20 years that\ndata literacy must become a key component of education at all levels and an\naptitude of nearly all employees in all organizations. The world is data,\nrevolves around data, produces and consumes massive quantities of data, and\ndrives innovative emerging technologies that are inspired by, informed by, and\nfueled by data: augmented reality (AR), virtual reality (VR), autonomous\nvehicles, computer vision, digital twins, drones, robotics, AI, IoT, hyperautomation,\nvirtual assistants, conversational AI, chatbots, natural language understanding\nand generation (NLU, NLG), automatic language translation, 4D-printing, cyber\nresilience, and more. Data literacy is essential for future of work, future\ninnovation, work from home, and everyone that touches digital information.\nStudies have shown that organizations that are not adopting data literacy\nprograms are not only falling behind, but they may stay behind, their\ncompetition. Get on board with data literacy! Now!</p>\n\n\n\n<p>10) Observability emerged as one of the hottest and (for me) most exciting developments of the year. Do not confuse observability with monitoring (specifically, with IT monitoring). The key difference is this: monitoring is what you do, and observability is why you do it. Observability is a business strategy: what you monitor, why you monitor it, what you intend to learn from it, how it will be used, and how it will contribute to business objectives and mission success. But the power, value, and imperative of observability does not stop there. Observability meets AI – it is part of the complete AIOps package: “keeping an eye on the AI.” Observability delivers actionable insights, context-enriched data sets, early warning alert generation, root cause visibility, active performance monitoring, predictive and prescriptive incident management, real-time operational deviation detection (6-Sigma never had it so good!), tight coupling of cyber-physical systems, digital twinning of almost anything in the enterprise, and more. And the goodness doesn’t stop there. The emergence of standards, like OpenTelemetry, can unify all aspects of your enterprise observability strategy: process instrumentation, sensing, metrics specification, context generation, data collection, data export, and data analysis of business process performance and behavior monitoring in the cloud. This plethora of benefits is a real game-changer for open-source self-service intelligent data-driven business process monitoring (BPM) and application performance monitoring (APM), feedback, and improvement. As mentioned above, monitoring is “what you are doing”, and observability is “why you are doing it.” If your organization is not having “the talk” about observability, now is the time to start – to understand why and how to produce business value through observability into the multitude of data-rich digital business applications and processes all across the modern enterprise. Don&#8217;t drown in those deep seas of data. Instead, develop an Observability Strategy to help your organization ride the waves of data, to help your business innovation and transformation practices move at the speed of data.</p>\n\n\n\n<p>In summary, my top 10 data innovation trends from 2020 are:</p>\n\n\n\n<ul><li>GPT-3</li><li>MLOps</li><li>Concept Drift by COVID</li><li>AIOps</li><li>Edge-to-Cloud and Fog\nComputing</li><li>Federated Machine\nLearning</li><li>Deep Learning meets\nthe “no free lunch theorem”</li><li>RPA and Intelligent\nAutomation</li><li>Rise of Data Literacy</li><li>Observability</li></ul>\n\n\n\n<p>If\nI were to choose what was hottest trend in 2020, it would not be a single item in\nthis top 10 list. The hottest trend would be a hybrid (convergence) of several of\nthese items. That hybrid would include: Observability, coupled with Edge and\nthe ever-rising ubiquitous IoT (sensors on everything), boosted by 5G and cloud\ntechnologies, fueling ever-improving ML and DL algorithms, all of which are\nenabling “just-in-time” intelligence and intelligent automation (for\ndata-driven decisions and action, at the point of data collection), deployed with\na data-literate workforce, in a sustainable and trusted MLOps environment,\nwhere algorithms, data, and applications work harmoniously and are governed and\nsecured by AIOps. </p>\n\n\n\n<p>If we\nlearned anything from the year 2020, it should be that trendy technologies do not\ncomprise a menu of digital transformation solutions to choose from, but there really\nis only one combined solution, which is the hybrid convergence of data\ninnovation technologies. From my perspective, that was the single most\nsignificant data innovation trend of the year 2020. </p>\n",
  "wfw:commentRss": "http://rocketdatascience.org/?feed=rss2&#038;p=1589",
  "slash:comments": 0
}