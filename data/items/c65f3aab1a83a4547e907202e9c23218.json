{
  "title": "Dask and Celery",
  "link": "",
  "updated": "2016-09-13T00:00:00+00:00",
  "id": "https://mrocklin.github.io/blog/work/2016/09/13/dask-and-celery",
  "content": "<p>This post compares two Python distributed task processing systems,\nDask.distributed and Celery.</p>\n\n<p><em>Disclaimer: technical comparisons are hard to do well.  I am biased towards\nDask and ignorant of correct Celery practices.  Please keep this in mind.\nCritical feedback by Celery experts is welcome.</em></p>\n\n<p><a href=\"http://www.celeryproject.org/\">Celery</a> is a distributed task queue built in\nPython and heavily used by the Python community for task-based workloads.</p>\n\n<p><a href=\"http://dask.pydata.org/en/latest/\">Dask</a> is a parallel computing library\npopular within the PyData community that has grown a fairly sophisticated\n<a href=\"http://distributed.readthedocs.io/en/latest/\">distributed task scheduler</a>.\nThis post explores if Dask.distributed can be useful for Celery-style problems.</p>\n\n<p>Comparing technical projects is hard both because authors have bias, and also\nbecause the scope of each project can be quite large.  This allows authors to\ngravitate towards the features that show off our strengths.  Fortunately <a href=\"https://github.com/dask/dask/issues/1537\">a\nCelery user asked how Dask compares on\nGithub</a> and they listed a few\nconcrete features:</p>\n\n<ol>\n  <li>Handling multiple queues</li>\n  <li>Canvas (celery’s workflow)</li>\n  <li>Rate limiting</li>\n  <li>Retrying</li>\n</ol>\n\n<p>These provide an opportunity to explore the Dask/Celery comparision from the\nbias of a Celery user rather than from the bias of a Dask developer.</p>\n\n<p>In this post I’ll point out a couple of large differences, then go through the\nCelery hello world in both projects, and then address how these requested\nfeatures are implemented or not within Dask.  This anecdotal comparison over a\nfew features should give us a general comparison.</p>\n\n<h2 id=\"biggest-difference-worker-state-and-communication\">Biggest difference: Worker state and communication</h2>\n\n<p>First, the biggest difference (from my perspective) is that Dask workers hold\nonto intermediate results and communicate data between each other while in\nCelery all results flow back to a central authority.  This difference was\ncritical when building out large parallel arrays and dataframes (Dask’s\noriginal purpose) where we needed to engage our worker processes’ memory and\ninter-worker communication bandwidths.  Computational systems like Dask do\nthis, more data-engineering systems like Celery/Airflow/Luigi don’t.  This is\nthe main reason why Dask wasn’t built on top of Celery/Airflow/Luigi originally.</p>\n\n<p>That’s not a knock against Celery/Airflow/Luigi by any means.  Typically\nthey’re used in settings where this doesn’t matter and they’ve focused their\nenergies on several features that Dask similarly doesn’t care about or do well.\nTasks usually read data from some globally accessible store like a database or\nS3 and either return very small results, or place larger results back in the\nglobal store.</p>\n\n<p>The question on my mind is now is <em>Can Dask be a useful solution in more\ntraditional loose task scheduling problems where projects like Celery are\ntypically used?  What are the benefits and drawbacks?</em></p>\n\n<h2 id=\"hello-world\">Hello World</h2>\n\n<p>To start we do the <a href=\"http://docs.celeryproject.org/en/latest/getting-started/first-steps-with-celery.html\">First steps with\nCelery</a>\nwalk-through both in Celery and Dask and compare the two:</p>\n\n<h3 id=\"celery\">Celery</h3>\n\n<p>I follow the Celery quickstart, using Redis instead of RabbitMQ because it’s\nwhat I happen to have handy.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\"># tasks.py\n</span>\n<span class=\"kn\">from</span> <span class=\"nn\">celery</span> <span class=\"kn\">import</span> <span class=\"n\">Celery</span>\n\n<span class=\"n\">app</span> <span class=\"o\">=</span> <span class=\"n\">Celery</span><span class=\"p\">(</span><span class=\"s\">'tasks'</span><span class=\"p\">,</span> <span class=\"n\">broker</span><span class=\"o\">=</span><span class=\"s\">'redis://localhost'</span><span class=\"p\">,</span> <span class=\"n\">backend</span><span class=\"o\">=</span><span class=\"s\">'redis'</span><span class=\"p\">)</span>\n\n<span class=\"o\">@</span><span class=\"n\">app</span><span class=\"p\">.</span><span class=\"n\">task</span>\n<span class=\"k\">def</span> <span class=\"nf\">add</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">):</span>\n    <span class=\"k\">return</span> <span class=\"n\">x</span> <span class=\"o\">+</span> <span class=\"n\">y</span>\n</code></pre></div></div>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>$ redis-server\n$ celery -A tasks worker --loglevel=info\n</code></pre></div></div>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]:</span> <span class=\"kn\">from</span> <span class=\"nn\">tasks</span> <span class=\"kn\">import</span> <span class=\"n\">add</span>\n\n<span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">]:</span> <span class=\"o\">%</span><span class=\"n\">time</span> <span class=\"n\">add</span><span class=\"p\">.</span><span class=\"n\">delay</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">).</span><span class=\"n\">get</span><span class=\"p\">()</span>  <span class=\"c1\"># submit and retrieve roundtrip\n</span><span class=\"n\">CPU</span> <span class=\"n\">times</span><span class=\"p\">:</span> <span class=\"n\">user</span> <span class=\"mi\">60</span> <span class=\"n\">ms</span><span class=\"p\">,</span> <span class=\"n\">sys</span><span class=\"p\">:</span> <span class=\"mi\">8</span> <span class=\"n\">ms</span><span class=\"p\">,</span> <span class=\"n\">total</span><span class=\"p\">:</span> <span class=\"mi\">68</span> <span class=\"n\">ms</span>\n<span class=\"n\">Wall</span> <span class=\"n\">time</span><span class=\"p\">:</span> <span class=\"mi\">567</span> <span class=\"n\">ms</span>\n<span class=\"n\">Out</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">]:</span> <span class=\"mi\">2</span>\n\n<span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">]:</span> <span class=\"o\">%%</span><span class=\"n\">time</span>\n<span class=\"p\">...:</span> <span class=\"n\">futures</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">add</span><span class=\"p\">.</span><span class=\"n\">delay</span><span class=\"p\">(</span><span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">1000</span><span class=\"p\">)]</span>\n<span class=\"p\">...:</span> <span class=\"n\">results</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">f</span><span class=\"p\">.</span><span class=\"n\">get</span><span class=\"p\">()</span> <span class=\"k\">for</span> <span class=\"n\">f</span> <span class=\"ow\">in</span> <span class=\"n\">futures</span><span class=\"p\">]</span>\n<span class=\"p\">...:</span>\n<span class=\"n\">CPU</span> <span class=\"n\">times</span><span class=\"p\">:</span> <span class=\"n\">user</span> <span class=\"mi\">888</span> <span class=\"n\">ms</span><span class=\"p\">,</span> <span class=\"n\">sys</span><span class=\"p\">:</span> <span class=\"mi\">72</span> <span class=\"n\">ms</span><span class=\"p\">,</span> <span class=\"n\">total</span><span class=\"p\">:</span> <span class=\"mi\">960</span> <span class=\"n\">ms</span>\n<span class=\"n\">Wall</span> <span class=\"n\">time</span><span class=\"p\">:</span> <span class=\"mf\">1.7</span> <span class=\"n\">s</span>\n</code></pre></div></div>\n\n<h3 id=\"dask\">Dask</h3>\n\n<p>We do the same workload with dask.distributed’s concurrent.futures interface,\nusing the default single-machine deployment.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]:</span> <span class=\"kn\">from</span> <span class=\"nn\">distributed</span> <span class=\"kn\">import</span> <span class=\"n\">Client</span>\n\n<span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">]:</span> <span class=\"n\">c</span> <span class=\"o\">=</span> <span class=\"n\">Client</span><span class=\"p\">()</span>\n\n<span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">]:</span> <span class=\"kn\">from</span> <span class=\"nn\">operator</span> <span class=\"kn\">import</span> <span class=\"n\">add</span>\n\n<span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">4</span><span class=\"p\">]:</span> <span class=\"o\">%</span><span class=\"n\">time</span> <span class=\"n\">c</span><span class=\"p\">.</span><span class=\"n\">submit</span><span class=\"p\">(</span><span class=\"n\">add</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">).</span><span class=\"n\">result</span><span class=\"p\">()</span>\n<span class=\"n\">CPU</span> <span class=\"n\">times</span><span class=\"p\">:</span> <span class=\"n\">user</span> <span class=\"mi\">20</span> <span class=\"n\">ms</span><span class=\"p\">,</span> <span class=\"n\">sys</span><span class=\"p\">:</span> <span class=\"mi\">0</span> <span class=\"n\">ns</span><span class=\"p\">,</span> <span class=\"n\">total</span><span class=\"p\">:</span> <span class=\"mi\">20</span> <span class=\"n\">ms</span>\n<span class=\"n\">Wall</span> <span class=\"n\">time</span><span class=\"p\">:</span> <span class=\"mf\">20.7</span> <span class=\"n\">ms</span>\n<span class=\"n\">Out</span><span class=\"p\">[</span><span class=\"mi\">4</span><span class=\"p\">]:</span> <span class=\"mi\">2</span>\n\n<span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">5</span><span class=\"p\">]:</span> <span class=\"o\">%%</span><span class=\"n\">time</span>\n<span class=\"p\">...:</span> <span class=\"n\">futures</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">c</span><span class=\"p\">.</span><span class=\"n\">submit</span><span class=\"p\">(</span><span class=\"n\">add</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">1000</span><span class=\"p\">)]</span>\n<span class=\"p\">...:</span> <span class=\"n\">results</span> <span class=\"o\">=</span> <span class=\"n\">c</span><span class=\"p\">.</span><span class=\"n\">gather</span><span class=\"p\">(</span><span class=\"n\">futures</span><span class=\"p\">)</span>\n<span class=\"p\">...:</span>\n<span class=\"n\">CPU</span> <span class=\"n\">times</span><span class=\"p\">:</span> <span class=\"n\">user</span> <span class=\"mi\">328</span> <span class=\"n\">ms</span><span class=\"p\">,</span> <span class=\"n\">sys</span><span class=\"p\">:</span> <span class=\"mi\">12</span> <span class=\"n\">ms</span><span class=\"p\">,</span> <span class=\"n\">total</span><span class=\"p\">:</span> <span class=\"mi\">340</span> <span class=\"n\">ms</span>\n<span class=\"n\">Wall</span> <span class=\"n\">time</span><span class=\"p\">:</span> <span class=\"mi\">369</span> <span class=\"n\">ms</span>\n</code></pre></div></div>\n\n<h3 id=\"comparison\">Comparison</h3>\n\n<ul>\n  <li><strong>Functions</strong>: In Celery you register computations ahead of time on the\nserver.  This is good if you know what you want to run ahead of time (such\nas is often the case in data engineering workloads) and don’t want the\nsecurity risk of allowing users to run arbitrary code on your cluster.  It’s\nless pleasant on users who want to experiment.  In Dask we choose the\nfunctions to run on the user side, not on the server side.  This ends up\nbeing pretty critical in data exploration but may be a hinderance in more\nconservative/secure compute settings.</li>\n  <li><strong>Setup</strong>: In Celery we depend on other widely deployed systems like\nRabbitMQ or Redis.  Dask depends on lower-level Torando TCP IOStreams and\nDask’s own custom routing logic.  This makes Dask trivial to set up, but\nalso probably less durable.  Redis and RabbitMQ have both solved lots of\nproblems that come up in the wild and leaning on them inspires confidence.</li>\n  <li><strong>Performance</strong>:  They both operate with sub-second latencies and\nmillisecond-ish overheads.  Dask is marginally lower-overhead but for data\nengineering workloads differences at this level are rarely significant.\nDask is an order of magnitude lower-latency, which might be a big deal\ndepending on your application.  For example if you’re firing off tasks from\na user clicking a button on a website 20ms is generally within interactive\nbudget while 500ms feels a bit slower.</li>\n</ul>\n\n<h2 id=\"simple-dependencies\">Simple Dependencies</h2>\n\n<p>The question asked about\n<a href=\"http://docs.celeryproject.org/en/master/userguide/canvas.html\">Canvas</a>,\nCelery’s dependency management system.</p>\n\n<p>Often tasks depend on the results of other tasks.  Both systems have ways to\nhelp users express these dependencies.</p>\n\n<h3 id=\"celery-1\">Celery</h3>\n\n<p>The <code class=\"language-plaintext highlighter-rouge\">apply_async</code> method has a <code class=\"language-plaintext highlighter-rouge\">link=</code> parameter that can be used to call tasks\nafter other tasks have run.  For example we can compute <code class=\"language-plaintext highlighter-rouge\">(1 + 2) + 3</code> in Celery\nas follows:</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">add</span><span class=\"p\">.</span><span class=\"n\">apply_async</span><span class=\"p\">((</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">),</span> <span class=\"n\">link</span><span class=\"o\">=</span><span class=\"n\">add</span><span class=\"p\">.</span><span class=\"n\">s</span><span class=\"p\">(</span><span class=\"mi\">3</span><span class=\"p\">))</span>\n</code></pre></div></div>\n\n<h3 id=\"daskdistributed\">Dask.distributed</h3>\n\n<p>With the Dask concurrent.futures API, futures can be used within submit calls\nand dependencies are implicit.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">c</span><span class=\"p\">.</span><span class=\"n\">submit</span><span class=\"p\">(</span><span class=\"n\">add</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">)</span>\n<span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">c</span><span class=\"p\">.</span><span class=\"n\">submit</span><span class=\"p\">(</span><span class=\"n\">add</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p>We could also use the <a href=\"http://dask.pydata.org/en/latest/delayed.html\">dask.delayed</a> decorator to annotate arbitrary functions and then use normal-ish Python.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">@</span><span class=\"n\">dask</span><span class=\"p\">.</span><span class=\"n\">delayed</span>\n<span class=\"k\">def</span> <span class=\"nf\">add</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">):</span>\n    <span class=\"k\">return</span> <span class=\"n\">x</span> <span class=\"o\">+</span> <span class=\"n\">y</span>\n\n<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">add</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">)</span>\n<span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">)</span>\n<span class=\"n\">y</span><span class=\"p\">.</span><span class=\"n\">compute</span><span class=\"p\">()</span>\n</code></pre></div></div>\n\n<h3 id=\"comparison-1\">Comparison</h3>\n\n<p>I prefer the Dask solution, but that’s subjective.</p>\n\n<h2 id=\"complex-dependencies\">Complex Dependencies</h2>\n\n<h3 id=\"celery-2\">Celery</h3>\n\n<p>Celery includes a rich vocabulary of terms to connect tasks in more complex\nways including <code class=\"language-plaintext highlighter-rouge\">groups</code>, <code class=\"language-plaintext highlighter-rouge\">chains</code>, <code class=\"language-plaintext highlighter-rouge\">chords</code>, <code class=\"language-plaintext highlighter-rouge\">maps</code>, <code class=\"language-plaintext highlighter-rouge\">starmaps</code>, etc..  More\ndetail here in their docs for Canvas, the system they use to construct complex\nworkflows: http://docs.celeryproject.org/en/master/userguide/canvas.html</p>\n\n<p>For example here we chord many adds and then follow them with a sum.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]:</span> <span class=\"kn\">from</span> <span class=\"nn\">tasks</span> <span class=\"kn\">import</span> <span class=\"n\">add</span><span class=\"p\">,</span> <span class=\"n\">tsum</span>  <span class=\"c1\"># I had to add a sum method to tasks.py\n</span>\n<span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">]:</span> <span class=\"kn\">from</span> <span class=\"nn\">celery</span> <span class=\"kn\">import</span> <span class=\"n\">chord</span>\n\n<span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">]:</span> <span class=\"o\">%</span><span class=\"n\">time</span> <span class=\"n\">chord</span><span class=\"p\">(</span><span class=\"n\">add</span><span class=\"p\">.</span><span class=\"n\">s</span><span class=\"p\">(</span><span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">100</span><span class=\"p\">))(</span><span class=\"n\">tsum</span><span class=\"p\">.</span><span class=\"n\">s</span><span class=\"p\">()).</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"n\">CPU</span> <span class=\"n\">times</span><span class=\"p\">:</span> <span class=\"n\">user</span> <span class=\"mi\">172</span> <span class=\"n\">ms</span><span class=\"p\">,</span> <span class=\"n\">sys</span><span class=\"p\">:</span> <span class=\"mi\">12</span> <span class=\"n\">ms</span><span class=\"p\">,</span> <span class=\"n\">total</span><span class=\"p\">:</span> <span class=\"mi\">184</span> <span class=\"n\">ms</span>\n<span class=\"n\">Wall</span> <span class=\"n\">time</span><span class=\"p\">:</span> <span class=\"mf\">1.21</span> <span class=\"n\">s</span>\n<span class=\"n\">Out</span><span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">]:</span> <span class=\"mi\">9900</span>\n</code></pre></div></div>\n\n<h3 id=\"dask-1\">Dask</h3>\n\n<p>Dask’s trick of allowing futures in submit calls actually goes pretty far.\nDask doesn’t really need any additional primitives.  It can do all of the\npatterns expressed in Canvas fairly naturally with normal submit calls.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">4</span><span class=\"p\">]:</span> <span class=\"o\">%%</span><span class=\"n\">time</span>\n<span class=\"p\">...:</span> <span class=\"n\">futures</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">c</span><span class=\"p\">.</span><span class=\"n\">submit</span><span class=\"p\">(</span><span class=\"n\">add</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">100</span><span class=\"p\">)]</span>\n<span class=\"p\">...:</span> <span class=\"n\">total</span> <span class=\"o\">=</span> <span class=\"n\">c</span><span class=\"p\">.</span><span class=\"n\">submit</span><span class=\"p\">(</span><span class=\"nb\">sum</span><span class=\"p\">,</span> <span class=\"n\">futures</span><span class=\"p\">)</span>\n<span class=\"p\">...:</span> <span class=\"n\">total</span><span class=\"p\">.</span><span class=\"n\">result</span><span class=\"p\">()</span>\n<span class=\"p\">...:</span>\n<span class=\"n\">CPU</span> <span class=\"n\">times</span><span class=\"p\">:</span> <span class=\"n\">user</span> <span class=\"mi\">52</span> <span class=\"n\">ms</span><span class=\"p\">,</span> <span class=\"n\">sys</span><span class=\"p\">:</span> <span class=\"mi\">0</span> <span class=\"n\">ns</span><span class=\"p\">,</span> <span class=\"n\">total</span><span class=\"p\">:</span> <span class=\"mi\">52</span> <span class=\"n\">ms</span>\n<span class=\"n\">Wall</span> <span class=\"n\">time</span><span class=\"p\">:</span> <span class=\"mf\">60.8</span> <span class=\"n\">ms</span>\n</code></pre></div></div>\n\n<p>Or with <a href=\"http://dask.pydata.org/en/latest/delayed.html\">Dask.delayed</a></p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">futures</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">100</span><span class=\"p\">)]</span>\n<span class=\"n\">total</span> <span class=\"o\">=</span> <span class=\"n\">dask</span><span class=\"p\">.</span><span class=\"n\">delayed</span><span class=\"p\">(</span><span class=\"nb\">sum</span><span class=\"p\">)(</span><span class=\"n\">futures</span><span class=\"p\">)</span>\n<span class=\"n\">total</span><span class=\"p\">.</span><span class=\"n\">result</span><span class=\"p\">()</span>\n</code></pre></div></div>\n\n<h2 id=\"multiple-queues\">Multiple Queues</h2>\n\n<p>In Celery there is a notion of queues to which tasks can be submitted and that\nworkers can subscribe.  An example use case is having “high priority” workers\nthat only process “high priority” tasks.  Every worker can subscribe to\nthe high-priority queue but certain workers will subscribe to that queue\nexclusively:</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>celery -A my-project worker -Q high-priority  # only subscribe to high priority\ncelery -A my-project worker -Q celery,high-priority  # subscribe to both\ncelery -A my-project worker -Q celery,high-priority\ncelery -A my-project worker -Q celery,high-priority\n</code></pre></div></div>\n\n<p>This is like the TSA pre-check line or the express lane in the grocery store.</p>\n\n<p>Dask has a couple of topics that are similar or could fit this need in a pinch, but nothing that is strictly analogous.</p>\n\n<p>First, for the common case above, tasks have priorities.  These are typically\nset by the scheduler to minimize memory use but can be overridden directly by\nusers to give certain tasks precedence over others.</p>\n\n<p>Second, you can restrict tasks to run on subsets of workers.  This was\noriginally designed for data-local storage systems like the Hadoop FileSystem\n(HDFS) or clusters with special hardware like GPUs but can be used in the\nqueues case as well.  It’s not quite the same abstraction but could be used to\nachieve the same results in a pinch.  For each task you can <em>restrict</em> the pool\nof workers on which it can run.</p>\n\n<p>The relevant docs for this are here:\n<a href=\"http://distributed.readthedocs.io/en/latest/locality.html#user-control\">http://distributed.readthedocs.io/en/latest/locality.html#user-control</a></p>\n\n<h2 id=\"retrying-tasks\">Retrying Tasks</h2>\n\n<p>Celery allows tasks to retry themselves on a failure.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">@</span><span class=\"n\">app</span><span class=\"p\">.</span><span class=\"n\">task</span><span class=\"p\">(</span><span class=\"n\">bind</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">)</span>\n<span class=\"k\">def</span> <span class=\"nf\">send_twitter_status</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">oauth</span><span class=\"p\">,</span> <span class=\"n\">tweet</span><span class=\"p\">):</span>\n    <span class=\"k\">try</span><span class=\"p\">:</span>\n        <span class=\"n\">twitter</span> <span class=\"o\">=</span> <span class=\"n\">Twitter</span><span class=\"p\">(</span><span class=\"n\">oauth</span><span class=\"p\">)</span>\n        <span class=\"n\">twitter</span><span class=\"p\">.</span><span class=\"n\">update_status</span><span class=\"p\">(</span><span class=\"n\">tweet</span><span class=\"p\">)</span>\n    <span class=\"k\">except</span> <span class=\"p\">(</span><span class=\"n\">Twitter</span><span class=\"p\">.</span><span class=\"n\">FailWhaleError</span><span class=\"p\">,</span> <span class=\"n\">Twitter</span><span class=\"p\">.</span><span class=\"n\">LoginError</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">exc</span><span class=\"p\">:</span>\n        <span class=\"k\">raise</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">retry</span><span class=\"p\">(</span><span class=\"n\">exc</span><span class=\"o\">=</span><span class=\"n\">exc</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Example from http://docs.celeryproject.org/en/latest/userguide/tasks.html#retrying\n</span></code></pre></div></div>\n\n<p>Sadly Dask currently has no support for this (see <a href=\"https://github.com/dask/distributed/issues/391\">open\nissue</a>).  All functions are\nconsidered pure and final.  If a task errs the exception is considered to be\nthe true result.  This could change though; it has been requested a couple of\ntimes now.</p>\n\n<p>Until then users need to implement retry logic within the function (which isn’t\na terrible idea regardless).</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">@</span><span class=\"n\">app</span><span class=\"p\">.</span><span class=\"n\">task</span><span class=\"p\">(</span><span class=\"n\">bind</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">)</span>\n<span class=\"k\">def</span> <span class=\"nf\">send_twitter_status</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">oauth</span><span class=\"p\">,</span> <span class=\"n\">tweet</span><span class=\"p\">,</span> <span class=\"n\">n_retries</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">):</span>\n    <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">n_retries</span><span class=\"p\">):</span>\n        <span class=\"k\">try</span><span class=\"p\">:</span>\n            <span class=\"n\">twitter</span> <span class=\"o\">=</span> <span class=\"n\">Twitter</span><span class=\"p\">(</span><span class=\"n\">oauth</span><span class=\"p\">)</span>\n            <span class=\"n\">twitter</span><span class=\"p\">.</span><span class=\"n\">update_status</span><span class=\"p\">(</span><span class=\"n\">tweet</span><span class=\"p\">)</span>\n            <span class=\"k\">return</span>\n        <span class=\"k\">except</span> <span class=\"p\">(</span><span class=\"n\">Twitter</span><span class=\"p\">.</span><span class=\"n\">FailWhaleError</span><span class=\"p\">,</span> <span class=\"n\">Twitter</span><span class=\"p\">.</span><span class=\"n\">LoginError</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">exc</span><span class=\"p\">:</span>\n            <span class=\"k\">pass</span>\n</code></pre></div></div>\n\n<h2 id=\"rate-limiting\">Rate Limiting</h2>\n\n<p>Celery lets you specify rate limits on tasks, presumably to help you avoid\ngetting blocked from hammering external APIs</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">@</span><span class=\"n\">app</span><span class=\"p\">.</span><span class=\"n\">task</span><span class=\"p\">(</span><span class=\"n\">rate_limit</span><span class=\"o\">=</span><span class=\"s\">'1000/h'</span><span class=\"p\">)</span>\n<span class=\"k\">def</span> <span class=\"nf\">query_external_api</span><span class=\"p\">(...):</span>\n    <span class=\"p\">...</span>\n</code></pre></div></div>\n\n<p>Dask definitely has nothing built in for this, nor is it planned.  However,\nthis could be done externally to Dask fairly easily.  For example, Dask\nsupports mapping functions over arbitrary Python Queues.  If you send in a\nqueue then all current and future elements in that queue will be mapped over.\nYou could easily handle rate limiting in Pure Python on the client side by\nrate limiting your input queues.  The low latency and overhead of Dask makes it\nfairly easy to manage logic like this on the client-side.  It’s not as\nconvenient, but it’s still straightforward.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">queue</span> <span class=\"kn\">import</span> <span class=\"n\">Queue</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">q</span> <span class=\"o\">=</span> <span class=\"n\">Queue</span><span class=\"p\">()</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">out</span> <span class=\"o\">=</span> <span class=\"n\">c</span><span class=\"p\">.</span><span class=\"nb\">map</span><span class=\"p\">(</span><span class=\"n\">query_external_api</span><span class=\"p\">,</span> <span class=\"n\">q</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"nb\">type</span><span class=\"p\">(</span><span class=\"n\">out</span><span class=\"p\">)</span>\n<span class=\"n\">Queue</span>\n</code></pre></div></div>\n\n<h2 id=\"final-thoughts\">Final Thoughts</h2>\n\n<p>Based on this very shallow exploration of Celery, I’ll foolishly claim that\nDask can handle Celery workloads, <em>if you’re not diving into deep API</em>.\nHowever all of that deep API is actually really important.  Celery evolved in\nthis domain and developed tons of features that solve problems that arise over\nand over again.  This history saves users an enormous amount of time.  Dask\nevolved in a very different space and has developed a very different set of\ntricks.  Many of Dask’s tricks are general enough that they can solve Celery\nproblems with a small bit of effort, but there’s still that extra step.  I’m\nseeing people applying that effort to problems now and I think it’ll be\ninteresting to see what comes out of it.</p>\n\n<p>Going through the Celery API was a good experience for me personally.  I think\nthat there are some good concepts from Celery that can inform future Dask\ndevelopment.</p>"
}