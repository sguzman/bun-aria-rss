{
  "title": "Towards Realistic Low-resource Relation Extraction: A Benchmark with Empirical Baseline Study. (arXiv:2210.10678v2 [cs.CL] UPDATED)",
  "link": "http://arxiv.org/abs/2210.10678",
  "description": "<p>This paper presents an empirical study to build relation extraction systems\nin low-resource settings. Based upon recent pre-trained language models, we\ncomprehensively investigate three schemes to evaluate the performance in\nlow-resource settings: (i) different types of prompt-based methods with\nfew-shot labeled data; (ii) diverse balancing methods to address the\nlong-tailed distribution issue; (iii) data augmentation technologies and\nself-training to generate more labeled in-domain data. We create a benchmark\nwith 8 relation extraction (RE) datasets covering different languages, domains\nand contexts and perform extensive comparisons over the proposed schemes with\ncombinations. Our experiments illustrate: (i) Though prompt-based tuning is\nbeneficial in low-resource RE, there is still much potential for improvement,\nespecially in extracting relations from cross-sentence contexts with multiple\nrelational triples; (ii) Balancing methods are not always helpful for RE with\nlong-tailed distribution; (iii) Data augmentation complements existing\nbaselines and can bring much performance gain, while self-training may not\nconsistently achieve advancement to low-resource RE. Code and datasets are in\nhttps://github.com/zjunlp/LREBench.\n</p>",
  "dc:creator": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xin Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huajun Chen</a>"
}