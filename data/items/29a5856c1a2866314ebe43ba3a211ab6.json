{
  "title": "Pandas on HDFS with Dask Dataframes",
  "link": "",
  "updated": "2016-02-22T00:00:00+00:00",
  "id": "https://mrocklin.github.io/blog/work/2016/02/22/dask-distributed-part-2",
  "content": "<p><em>This work is supported by <a href=\"http://continuum.io\">Continuum Analytics</a>\nand the <a href=\"http://www.darpa.mil/program/XDATA\">XDATA Program</a>\nas part of the <a href=\"http://blaze.pydata.org\">Blaze Project</a></em></p>\n\n<p>In this post we use Pandas in parallel across an HDFS cluster to read CSV data.\nWe coordinate these computations with dask.dataframe.  A screencast version of\nthis blogpost is available <a href=\"https://www.youtube.com/watch?v=LioaeHsZDBQ\">here</a>\nand the previous post in this series is available\n<a href=\"http://matthewrocklin.com/blog/work/2016/02/17/dask-distributed-part1\">here</a>.</p>\n\n<p>To start, we connect to our scheduler, import the <code class=\"language-plaintext highlighter-rouge\">hdfs</code> module from the\n<code class=\"language-plaintext highlighter-rouge\">distributed</code> library, and read our CSV data from HDFS.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">distributed</span> <span class=\"kn\">import</span> <span class=\"n\">Executor</span><span class=\"p\">,</span> <span class=\"n\">hdfs</span><span class=\"p\">,</span> <span class=\"n\">progress</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">e</span> <span class=\"o\">=</span> <span class=\"n\">Executor</span><span class=\"p\">(</span><span class=\"s\">'127.0.0.1:8786'</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">e</span>\n<span class=\"o\">&lt;</span><span class=\"n\">Executor</span><span class=\"p\">:</span> <span class=\"n\">scheduler</span><span class=\"o\">=</span><span class=\"mf\">127.0</span><span class=\"p\">.</span><span class=\"mf\">0.1</span><span class=\"p\">:</span><span class=\"mi\">8786</span> <span class=\"n\">workers</span><span class=\"o\">=</span><span class=\"mi\">64</span> <span class=\"n\">threads</span><span class=\"o\">=</span><span class=\"mi\">64</span><span class=\"o\">&gt;</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">nyc2014</span> <span class=\"o\">=</span> <span class=\"n\">hdfs</span><span class=\"p\">.</span><span class=\"n\">read_csv</span><span class=\"p\">(</span><span class=\"s\">'/nyctaxi/2014/*.csv'</span><span class=\"p\">,</span>\n<span class=\"p\">...</span>               <span class=\"n\">parse_dates</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s\">'pickup_datetime'</span><span class=\"p\">,</span> <span class=\"s\">'dropoff_datetime'</span><span class=\"p\">],</span>\n<span class=\"p\">...</span>               <span class=\"n\">skipinitialspace</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">)</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">nyc2015</span> <span class=\"o\">=</span> <span class=\"n\">hdfs</span><span class=\"p\">.</span><span class=\"n\">read_csv</span><span class=\"p\">(</span><span class=\"s\">'/nyctaxi/2015/*.csv'</span><span class=\"p\">,</span>\n<span class=\"p\">...</span>               <span class=\"n\">parse_dates</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s\">'tpep_pickup_datetime'</span><span class=\"p\">,</span> <span class=\"s\">'tpep_dropoff_datetime'</span><span class=\"p\">])</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">nyc2014</span><span class=\"p\">,</span> <span class=\"n\">nyc2015</span> <span class=\"o\">=</span> <span class=\"n\">e</span><span class=\"p\">.</span><span class=\"n\">persist</span><span class=\"p\">([</span><span class=\"n\">nyc2014</span><span class=\"p\">,</span> <span class=\"n\">nyc2015</span><span class=\"p\">])</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">progress</span><span class=\"p\">(</span><span class=\"n\">nyc2014</span><span class=\"p\">,</span> <span class=\"n\">nyc2015</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p><img src=\"https://mrocklin.github.io/blog/images/distributed-hdfs-read-csv.gif\" /></p>\n\n<p>Our data comes from the New York City Taxi and Limousine Commission which\npublishes <a href=\"http://www.nyc.gov/html/tlc/html/about/trip_record_data.shtml\">all yellow cab taxi rides in\nNYC</a> for various\nyears.  This is a nice model dataset for computational tabular data because\nit’s large enough to be annoying while also deep enough to be broadly\nappealing.  Each year is about 25GB on disk and about 60GB in memory as a\nPandas DataFrame.</p>\n\n<p>HDFS breaks up our CSV files into 128MB chunks on various hard drives spread\nthroughout the cluster.  The dask.distributed workers each read the chunks of\nbytes local to them and call the <code class=\"language-plaintext highlighter-rouge\">pandas.read_csv</code> function on these bytes,\nproducing 391 separate Pandas DataFrame objects spread throughout the memory of\nour eight worker nodes.  The returned objects, <code class=\"language-plaintext highlighter-rouge\">nyc2014</code> and <code class=\"language-plaintext highlighter-rouge\">nyc2015</code>, are\n<a href=\"http://dask.pydata.org/en/latest/dataframe.html\">dask.dataframe</a> objects which\npresent a subset of the Pandas API to the user, but farm out all of the work to\nthe many Pandas dataframes they control across the network.</p>\n\n<h2 id=\"play-with-distributed-data\">Play with Distributed Data</h2>\n\n<p>If we wait for the data to load fully into memory then we can perform\npandas-style analysis at interactive speeds.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">nyc2015</span><span class=\"p\">.</span><span class=\"n\">head</span><span class=\"p\">()</span>\n</code></pre></div></div>\n\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>VendorID</th>\n      <th>tpep_pickup_datetime</th>\n      <th>tpep_dropoff_datetime</th>\n      <th>passenger_count</th>\n      <th>trip_distance</th>\n      <th>pickup_longitude</th>\n      <th>pickup_latitude</th>\n      <th>RateCodeID</th>\n      <th>store_and_fwd_flag</th>\n      <th>dropoff_longitude</th>\n      <th>dropoff_latitude</th>\n      <th>payment_type</th>\n      <th>fare_amount</th>\n      <th>extra</th>\n      <th>mta_tax</th>\n      <th>tip_amount</th>\n      <th>tolls_amount</th>\n      <th>improvement_surcharge</th>\n      <th>total_amount</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>2015-01-15 19:05:39</td>\n      <td>2015-01-15 19:23:42</td>\n      <td>1</td>\n      <td>1.59</td>\n      <td>-73.993896</td>\n      <td>40.750111</td>\n      <td>1</td>\n      <td>N</td>\n      <td>-73.974785</td>\n      <td>40.750618</td>\n      <td>1</td>\n      <td>12.0</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>3.25</td>\n      <td>0</td>\n      <td>0.3</td>\n      <td>17.05</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2015-01-10 20:33:38</td>\n      <td>2015-01-10 20:53:28</td>\n      <td>1</td>\n      <td>3.30</td>\n      <td>-74.001648</td>\n      <td>40.724243</td>\n      <td>1</td>\n      <td>N</td>\n      <td>-73.994415</td>\n      <td>40.759109</td>\n      <td>1</td>\n      <td>14.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>2.00</td>\n      <td>0</td>\n      <td>0.3</td>\n      <td>17.80</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>2015-01-10 20:33:38</td>\n      <td>2015-01-10 20:43:41</td>\n      <td>1</td>\n      <td>1.80</td>\n      <td>-73.963341</td>\n      <td>40.802788</td>\n      <td>1</td>\n      <td>N</td>\n      <td>-73.951820</td>\n      <td>40.824413</td>\n      <td>2</td>\n      <td>9.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.00</td>\n      <td>0</td>\n      <td>0.3</td>\n      <td>10.80</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>2015-01-10 20:33:39</td>\n      <td>2015-01-10 20:35:31</td>\n      <td>1</td>\n      <td>0.50</td>\n      <td>-74.009087</td>\n      <td>40.713818</td>\n      <td>1</td>\n      <td>N</td>\n      <td>-74.004326</td>\n      <td>40.719986</td>\n      <td>2</td>\n      <td>3.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.00</td>\n      <td>0</td>\n      <td>0.3</td>\n      <td>4.80</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>2015-01-10 20:33:39</td>\n      <td>2015-01-10 20:52:58</td>\n      <td>1</td>\n      <td>3.00</td>\n      <td>-73.971176</td>\n      <td>40.762428</td>\n      <td>1</td>\n      <td>N</td>\n      <td>-74.004181</td>\n      <td>40.742653</td>\n      <td>2</td>\n      <td>15.0</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.00</td>\n      <td>0</td>\n      <td>0.3</td>\n      <td>16.30</td>\n    </tr>\n  </tbody>\n</table>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">nyc2014</span><span class=\"p\">)</span>\n<span class=\"mi\">165114373</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">nyc2015</span><span class=\"p\">)</span>\n<span class=\"mi\">146112989</span>\n</code></pre></div></div>\n\n<p>Interestingly it appears that the NYC cab industry has contracted a bit in the\nlast year.  There are <em>fewer</em> cab rides in 2015 than in 2014.</p>\n\n<p>When we ask for something like the length of the full dask.dataframe we\nactually ask for the length of all of the hundreds of Pandas dataframes and\nthen sum them up.  This process of reaching out to all of the workers completes\nin around 200-300 ms, which is generally fast enough to feel snappy in an\ninteractive session.</p>\n\n<p>The dask.dataframe API looks just like the Pandas API, except that we call\n<code class=\"language-plaintext highlighter-rouge\">.compute()</code> when we want an actual result.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">nyc2014</span><span class=\"p\">.</span><span class=\"n\">passenger_count</span><span class=\"p\">.</span><span class=\"nb\">sum</span><span class=\"p\">().</span><span class=\"n\">compute</span><span class=\"p\">()</span>\n<span class=\"mf\">279997507.0</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">nyc2015</span><span class=\"p\">.</span><span class=\"n\">passenger_count</span><span class=\"p\">.</span><span class=\"nb\">sum</span><span class=\"p\">().</span><span class=\"n\">compute</span><span class=\"p\">()</span>\n<span class=\"mi\">245566747</span>\n</code></pre></div></div>\n\n<p>Dask.dataframes build a plan to get your result and the distributed scheduler\ncoordinates that plan on all of the little Pandas dataframes on the workers\nthat make up our dataset.</p>\n\n<h2 id=\"pandas-for-metadata\">Pandas for Metadata</h2>\n\n<p>Let’s appreciate for a moment all the work we didn’t have to do around CSV\nhandling because Pandas magically handled it for us.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">nyc2015</span><span class=\"p\">.</span><span class=\"n\">dtypes</span>\n<span class=\"n\">VendorID</span>                          <span class=\"n\">int64</span>\n<span class=\"n\">tpep_pickup_datetime</span>     <span class=\"n\">datetime64</span><span class=\"p\">[</span><span class=\"n\">ns</span><span class=\"p\">]</span>\n<span class=\"n\">tpep_dropoff_datetime</span>    <span class=\"n\">datetime64</span><span class=\"p\">[</span><span class=\"n\">ns</span><span class=\"p\">]</span>\n<span class=\"n\">passenger_count</span>                   <span class=\"n\">int64</span>\n<span class=\"n\">trip_distance</span>                   <span class=\"n\">float64</span>\n<span class=\"n\">pickup_longitude</span>                <span class=\"n\">float64</span>\n<span class=\"n\">pickup_latitude</span>                 <span class=\"n\">float64</span>\n<span class=\"n\">RateCodeID</span>                        <span class=\"n\">int64</span>\n<span class=\"n\">store_and_fwd_flag</span>               <span class=\"nb\">object</span>\n<span class=\"n\">dropoff_longitude</span>               <span class=\"n\">float64</span>\n<span class=\"n\">dropoff_latitude</span>                <span class=\"n\">float64</span>\n<span class=\"n\">payment_type</span>                      <span class=\"n\">int64</span>\n<span class=\"n\">fare_amount</span>                     <span class=\"n\">float64</span>\n<span class=\"n\">extra</span>                           <span class=\"n\">float64</span>\n<span class=\"n\">mta_tax</span>                         <span class=\"n\">float64</span>\n<span class=\"n\">tip_amount</span>                      <span class=\"n\">float64</span>\n<span class=\"n\">tolls_amount</span>                    <span class=\"n\">float64</span>\n<span class=\"n\">improvement_surcharge</span>           <span class=\"n\">float64</span>\n<span class=\"n\">total_amount</span>\\<span class=\"n\">r</span>                  <span class=\"n\">float64</span>\n<span class=\"n\">dtype</span><span class=\"p\">:</span> <span class=\"nb\">object</span>\n</code></pre></div></div>\n\n<p>We didn’t have to find columns or specify data-types.  We didn’t have to parse\neach value with an <code class=\"language-plaintext highlighter-rouge\">int</code> or <code class=\"language-plaintext highlighter-rouge\">float</code> function as appropriate.  We didn’t have to\nparse the datetimes, but instead just specified a <code class=\"language-plaintext highlighter-rouge\">parse_datetimes=</code> keyword.\nThe CSV parsing happened about as quickly as can be expected for this format,\nclocking in at a network total of a bit under 1 GB/s.</p>\n\n<p>Pandas is well loved because it removes all of these little hurdles from the\nlife of the analyst.  If we tried to reinvent a new\n“Big-Data-Frame” we would have to reimplement all of the work already well done\ninside of Pandas.  Instead, dask.dataframe just coordinates and reuses the code\nwithin the Pandas library.  It is successful largely due to work from core\nPandas developers, notably Masaaki Horikoshi\n(<a href=\"https://github.com/sinhrks/\">@sinhrks</a>), who have done tremendous work to\nalign the API precisely with the Pandas core library.</p>\n\n<h2 id=\"analyze-tips-and-payment-types\">Analyze Tips and Payment Types</h2>\n\n<p>In an effort to demonstrate the abilities of dask.dataframe we ask a simple\nquestion of our data, <em>“how do New Yorkers tip?”</em>.  The 2015 NYCTaxi data is\nquite good about breaking down the total cost of each ride into the fare\namount, tip amount, and various taxes and fees.  In particular this lets us\nmeasure the percentage that each rider decided to pay in tip.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">nyc2015</span><span class=\"p\">[[</span><span class=\"s\">'fare_amount'</span><span class=\"p\">,</span> <span class=\"s\">'tip_amount'</span><span class=\"p\">,</span> <span class=\"s\">'payment_type'</span><span class=\"p\">]].</span><span class=\"n\">head</span><span class=\"p\">()</span>\n</code></pre></div></div>\n\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fare_amount</th>\n      <th>tip_amount</th>\n      <th>payment_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>12.0</td>\n      <td>3.25</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>14.5</td>\n      <td>2.00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9.5</td>\n      <td>0.00</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.5</td>\n      <td>0.00</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>15.0</td>\n      <td>0.00</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n\n<p>In the first two lines we see evidence supporting the 15-20% tip standard\ncommon in the US.  The following three lines interestingly show zero tip.\nJudging only by these first five lines (a very small sample) we see a strong\ncorrelation here with the payment type.  We analyze this a bit more by counting\noccurrences in the <code class=\"language-plaintext highlighter-rouge\">payment_type</code> column both for the full dataset, and\nfiltered by zero tip:</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"o\">%</span><span class=\"n\">time</span> <span class=\"n\">nyc2015</span><span class=\"p\">.</span><span class=\"n\">payment_type</span><span class=\"p\">.</span><span class=\"n\">value_counts</span><span class=\"p\">().</span><span class=\"n\">compute</span><span class=\"p\">()</span>\n<span class=\"n\">CPU</span> <span class=\"n\">times</span><span class=\"p\">:</span> <span class=\"n\">user</span> <span class=\"mi\">132</span> <span class=\"n\">ms</span><span class=\"p\">,</span> <span class=\"n\">sys</span><span class=\"p\">:</span> <span class=\"mi\">0</span> <span class=\"n\">ns</span><span class=\"p\">,</span> <span class=\"n\">total</span><span class=\"p\">:</span> <span class=\"mi\">132</span> <span class=\"n\">ms</span>\n<span class=\"n\">Wall</span> <span class=\"n\">time</span><span class=\"p\">:</span> <span class=\"mi\">558</span> <span class=\"n\">ms</span>\n\n<span class=\"mi\">1</span>    <span class=\"mi\">91574644</span>\n<span class=\"mi\">2</span>    <span class=\"mi\">53864648</span>\n<span class=\"mi\">3</span>      <span class=\"mi\">503070</span>\n<span class=\"mi\">4</span>      <span class=\"mi\">170599</span>\n<span class=\"mi\">5</span>          <span class=\"mi\">28</span>\n<span class=\"n\">Name</span><span class=\"p\">:</span> <span class=\"n\">payment_type</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"p\">:</span> <span class=\"n\">int64</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"o\">%</span><span class=\"n\">time</span> <span class=\"n\">nyc2015</span><span class=\"p\">[</span><span class=\"n\">nyc2015</span><span class=\"p\">.</span><span class=\"n\">tip_amount</span> <span class=\"o\">==</span> <span class=\"mi\">0</span><span class=\"p\">].</span><span class=\"n\">payment_type</span><span class=\"p\">.</span><span class=\"n\">value_counts</span><span class=\"p\">().</span><span class=\"n\">compute</span><span class=\"p\">()</span>\n<span class=\"n\">CPU</span> <span class=\"n\">times</span><span class=\"p\">:</span> <span class=\"n\">user</span> <span class=\"mi\">212</span> <span class=\"n\">ms</span><span class=\"p\">,</span> <span class=\"n\">sys</span><span class=\"p\">:</span> <span class=\"mi\">4</span> <span class=\"n\">ms</span><span class=\"p\">,</span> <span class=\"n\">total</span><span class=\"p\">:</span> <span class=\"mi\">216</span> <span class=\"n\">ms</span>\n<span class=\"n\">Wall</span> <span class=\"n\">time</span><span class=\"p\">:</span> <span class=\"mf\">1.69</span> <span class=\"n\">s</span>\n\n<span class=\"mi\">2</span>    <span class=\"mi\">53862557</span>\n<span class=\"mi\">1</span>     <span class=\"mi\">3365668</span>\n<span class=\"mi\">3</span>      <span class=\"mi\">502025</span>\n<span class=\"mi\">4</span>      <span class=\"mi\">170234</span>\n<span class=\"mi\">5</span>          <span class=\"mi\">26</span>\n<span class=\"n\">Name</span><span class=\"p\">:</span> <span class=\"n\">payment_type</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"p\">:</span> <span class=\"n\">int64</span>\n</code></pre></div></div>\n\n<p>We find that almost all zero-tip rides correspond to payment type 2, and that\nalmost all payment type 2 rides don’t tip.  My un-scientific hypothesis here is\npayment type 2 corresponds to cash fares and that we’re observing a tendancy of\ndrivers not to record cash tips.  However we would need more domain knowledge\nabout our data to actually make this claim with any degree of authority.</p>\n\n<h2 id=\"analyze-tips-fractions\">Analyze Tips Fractions</h2>\n\n<p>Lets make a new column, <code class=\"language-plaintext highlighter-rouge\">tip_fraction</code>, and then look at the average of this\ncolumn grouped by day of week and grouped by hour of day.</p>\n\n<p>First, we need to filter out bad rows, both rows with this odd payment type,\nand rows with zero fare (there are a surprising number of free cab rides in\nNYC.)  Second we create a new column equal to the ratio of <code class=\"language-plaintext highlighter-rouge\">tip_amount /\nfare_amount</code>.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">nyc2015</span><span class=\"p\">[(</span><span class=\"n\">nyc2015</span><span class=\"p\">.</span><span class=\"n\">fare_amount</span> <span class=\"o\">&gt;</span> <span class=\"mi\">0</span><span class=\"p\">)</span> <span class=\"o\">&amp;</span> <span class=\"p\">(</span><span class=\"n\">nyc2015</span><span class=\"p\">.</span><span class=\"n\">payment_type</span> <span class=\"o\">!=</span> <span class=\"mi\">2</span><span class=\"p\">)]</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">.</span><span class=\"n\">assign</span><span class=\"p\">(</span><span class=\"n\">tip_fraction</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">.</span><span class=\"n\">tip_amount</span> <span class=\"o\">/</span> <span class=\"n\">df</span><span class=\"p\">.</span><span class=\"n\">fare_amount</span><span class=\"p\">))</span>\n</code></pre></div></div>\n\n<p>Next we choose to groupby the pickup datetime column in order to see how the\naverage tip fraction changes by day of week and by hour.  The groupby and\ndatetime handling of Pandas makes these operations trivial.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">dayofweek</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">.</span><span class=\"n\">groupby</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">.</span><span class=\"n\">tpep_pickup_datetime</span><span class=\"p\">.</span><span class=\"n\">dt</span><span class=\"p\">.</span><span class=\"n\">dayofweek</span><span class=\"p\">).</span><span class=\"n\">tip_fraction</span><span class=\"p\">.</span><span class=\"n\">mean</span><span class=\"p\">()</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">hour</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">.</span><span class=\"n\">groupby</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">.</span><span class=\"n\">tpep_pickup_datetime</span><span class=\"p\">.</span><span class=\"n\">dt</span><span class=\"p\">.</span><span class=\"n\">hour</span><span class=\"p\">).</span><span class=\"n\">tip_fraction</span><span class=\"p\">.</span><span class=\"n\">mean</span><span class=\"p\">()</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">dayofweek</span><span class=\"p\">,</span> <span class=\"n\">hour</span> <span class=\"o\">=</span> <span class=\"n\">e</span><span class=\"p\">.</span><span class=\"n\">persist</span><span class=\"p\">([</span><span class=\"n\">dayofweek</span><span class=\"p\">,</span> <span class=\"n\">hour</span><span class=\"p\">])</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">progress</span><span class=\"p\">(</span><span class=\"n\">dayofweek</span><span class=\"p\">,</span> <span class=\"n\">hour</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p><img src=\"https://mrocklin.github.io/blog/images/distributed-hdfs-groupby-tip-fraction.gif\" /></p>\n\n<p>Grouping by day-of-week doesn’t show anything too striking to my eye.  However\nI would like to note at how generous NYC cab riders seem to be.  A 23-25% tip\ncan be quite nice:</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">dayofweek</span><span class=\"p\">.</span><span class=\"n\">compute</span><span class=\"p\">()</span>\n<span class=\"n\">tpep_pickup_datetime</span>\n<span class=\"mi\">0</span>    <span class=\"mf\">0.237510</span>\n<span class=\"mi\">1</span>    <span class=\"mf\">0.236494</span>\n<span class=\"mi\">2</span>    <span class=\"mf\">0.236073</span>\n<span class=\"mi\">3</span>    <span class=\"mf\">0.246007</span>\n<span class=\"mi\">4</span>    <span class=\"mf\">0.242081</span>\n<span class=\"mi\">5</span>    <span class=\"mf\">0.232415</span>\n<span class=\"mi\">6</span>    <span class=\"mf\">0.259974</span>\n<span class=\"n\">Name</span><span class=\"p\">:</span> <span class=\"n\">tip_fraction</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"p\">:</span> <span class=\"n\">float64</span>\n</code></pre></div></div>\n\n<p>But grouping by hour shows that late night and early morning riders are more\nlikely to tip extravagantly:</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">hour</span><span class=\"p\">.</span><span class=\"n\">compute</span><span class=\"p\">()</span>\n<span class=\"n\">tpep_pickup_datetime</span>\n<span class=\"mi\">0</span>     <span class=\"mf\">0.263602</span>\n<span class=\"mi\">1</span>     <span class=\"mf\">0.278828</span>\n<span class=\"mi\">2</span>     <span class=\"mf\">0.293536</span>\n<span class=\"mi\">3</span>     <span class=\"mf\">0.276784</span>\n<span class=\"mi\">4</span>     <span class=\"mf\">0.348649</span>\n<span class=\"mi\">5</span>     <span class=\"mf\">0.248618</span>\n<span class=\"mi\">6</span>     <span class=\"mf\">0.233257</span>\n<span class=\"mi\">7</span>     <span class=\"mf\">0.216003</span>\n<span class=\"mi\">8</span>     <span class=\"mf\">0.221508</span>\n<span class=\"mi\">9</span>     <span class=\"mf\">0.217018</span>\n<span class=\"mi\">10</span>    <span class=\"mf\">0.225618</span>\n<span class=\"mi\">11</span>    <span class=\"mf\">0.231396</span>\n<span class=\"mi\">12</span>    <span class=\"mf\">0.225186</span>\n<span class=\"mi\">13</span>    <span class=\"mf\">0.235662</span>\n<span class=\"mi\">14</span>    <span class=\"mf\">0.237636</span>\n<span class=\"mi\">15</span>    <span class=\"mf\">0.228832</span>\n<span class=\"mi\">16</span>    <span class=\"mf\">0.234086</span>\n<span class=\"mi\">17</span>    <span class=\"mf\">0.240635</span>\n<span class=\"mi\">18</span>    <span class=\"mf\">0.237488</span>\n<span class=\"mi\">19</span>    <span class=\"mf\">0.272792</span>\n<span class=\"mi\">20</span>    <span class=\"mf\">0.235866</span>\n<span class=\"mi\">21</span>    <span class=\"mf\">0.242157</span>\n<span class=\"mi\">22</span>    <span class=\"mf\">0.243244</span>\n<span class=\"mi\">23</span>    <span class=\"mf\">0.244586</span>\n<span class=\"n\">Name</span><span class=\"p\">:</span> <span class=\"n\">tip_fraction</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"p\">:</span> <span class=\"n\">float64</span>\n<span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">24</span><span class=\"p\">]:</span>\n</code></pre></div></div>\n\n<p>We plot this with matplotlib and see a nice trough during business hours with a\nsurge in the early morning with an astonishing peak of 34% at 4am:</p>\n\n<p><img src=\"https://mrocklin.github.io/blog/images/nyctaxi-2015-hourly-tips.png\" /></p>\n\n<h2 id=\"performance\">Performance</h2>\n\n<p>Lets dive into a few operations that run at different time scales.  This gives\na good understanding of the strengths and limits of the scheduler.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"o\">%</span><span class=\"n\">time</span> <span class=\"n\">nyc2015</span><span class=\"p\">.</span><span class=\"n\">head</span><span class=\"p\">()</span>\n<span class=\"n\">CPU</span> <span class=\"n\">times</span><span class=\"p\">:</span> <span class=\"n\">user</span> <span class=\"mi\">4</span> <span class=\"n\">ms</span><span class=\"p\">,</span> <span class=\"n\">sys</span><span class=\"p\">:</span> <span class=\"mi\">0</span> <span class=\"n\">ns</span><span class=\"p\">,</span> <span class=\"n\">total</span><span class=\"p\">:</span> <span class=\"mi\">4</span> <span class=\"n\">ms</span>\n<span class=\"n\">Wall</span> <span class=\"n\">time</span><span class=\"p\">:</span> <span class=\"mf\">20.9</span> <span class=\"n\">ms</span>\n</code></pre></div></div>\n\n<p>This head computation is about as fast as a film projector.  You could perform\nthis roundtrip computation between every consecutive frame of a movie; to a\nhuman eye this appears fluid.  In the <a href=\"http://matthewrocklin.com/blog/work/2016/02/17/dask-distributed-part1\">last post</a>\nwe asked about how low we could bring latency.  In that post we were running\ncomputations from my laptop in California and so were bound by transcontinental\nlatencies of 200ms.  This time, because we’re operating from the cluster, we\ncan get down to 20ms.  We’re only able to be this fast because we touch only a\nsingle data element, the first partition.  Things change when we need to touch\nthe entire dataset.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"o\">%</span><span class=\"n\">time</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">nyc2015</span><span class=\"p\">)</span>\n<span class=\"n\">CPU</span> <span class=\"n\">times</span><span class=\"p\">:</span> <span class=\"n\">user</span> <span class=\"mi\">48</span> <span class=\"n\">ms</span><span class=\"p\">,</span> <span class=\"n\">sys</span><span class=\"p\">:</span> <span class=\"mi\">0</span> <span class=\"n\">ns</span><span class=\"p\">,</span> <span class=\"n\">total</span><span class=\"p\">:</span> <span class=\"mi\">48</span> <span class=\"n\">ms</span>\n<span class=\"n\">Wall</span> <span class=\"n\">time</span><span class=\"p\">:</span> <span class=\"mi\">271</span> <span class=\"n\">ms</span>\n</code></pre></div></div>\n\n<p>The length computation takes 200-300 ms.  This computation takes longer because we\ntouch every individual partition of the data, of which there are 178.  The\nscheduler incurs about 1ms of overhead per task, add a bit of latency\nand you get the ~200ms total.  This means that the scheduler will likely be the\nbottleneck whenever computations are very fast, such as is the case for\ncomputing <code class=\"language-plaintext highlighter-rouge\">len</code>.  Really, this is good news; it means that by improving the\nscheduler we can reduce these durations even further.</p>\n\n<p>If you look at the groupby computations above you can add the numbers in the\nprogress bars to show that we computed around 3000 tasks in around 7s.  It\nlooks like this computation is about half scheduler overhead and about half\nbound by actual computation.</p>\n\n<h2 id=\"conclusion\">Conclusion</h2>\n\n<p>We used dask+distributed on a cluster to read CSV data from HDFS\ninto a dask dataframe.  We then used dask.dataframe, which looks identical to\nthe Pandas dataframe, to manipulate our distributed dataset intuitively and\nefficiently.</p>\n\n<p>We looked a bit at the performance characteristics of simple computations.</p>\n\n<h2 id=\"what-doesnt-work\">What doesn’t work</h2>\n\n<p>As always I’ll have a section like this that honestly says what doesn’t work\nwell and what I would have done with more time.</p>\n\n<ul>\n  <li>\n    <p>Dask dataframe implements a commonly used <em>subset</em> of Pandas functionality,\nnot all of it.  It’s surprisingly hard to communicate the exact bounds of\nthis subset to users.  Notably, in the distributed setting we don’t have a\nshuffle algorithm, so <code class=\"language-plaintext highlighter-rouge\">groupby(...).apply(...)</code> and some joins are not\nyet possible.</p>\n  </li>\n  <li>\n    <p>If you want to use threads, you’ll need Pandas 0.18.0 which, at the time of\nthis writing, was still in release candidate stage.  This Pandas release\nfixes some important GIL related issues.</p>\n  </li>\n  <li>\n    <p>The 1ms overhead per task limit is significant.  While we can still scale\nout to clusters far larger than what we have here, we probably won’t be\nable to strongly accelerate very quick operations until we reduce this\nnumber.</p>\n  </li>\n  <li>\n    <p>We use the <a href=\"http://hdfs3.readthedocs.org/en/latest/\">hdfs3 library</a> to read\ndata from HDFS.  This library seems to work great but is new and could use\nmore active users to flush out bug reports.</p>\n  </li>\n</ul>\n\n<h2 id=\"links\">Links</h2>\n\n<ul>\n  <li><a href=\"https://dask.pydata.org/en/latest/\">dask</a>, the original project</li>\n  <li><a href=\"https://distributed.readthedocs.org/en/latest/\">dask.distributed</a>, the\ndistributed memory scheduler powering the cluster computing</li>\n  <li><a href=\"http://dask.pydata.org/en/latest/dataframe.html\">dask.dataframe</a>, the user\nAPI we’ve used in this post.</li>\n  <li><a href=\"http://www.nyc.gov/html/tlc/html/about/trip_record_data.shtml\">NYC Taxi Data Downloads</a></li>\n  <li><a href=\"https://hdfs3.readthedocs.org/en/latest\">hdfs3</a>: Python library we use for\nHDFS interations.</li>\n  <li>The <a href=\"http://matthewrocklin.com/blog/work/2016/02/17/dask-distributed-part1\">previous post</a> in this blog series.</li>\n</ul>\n\n<h2 id=\"setup-and-data\">Setup and Data</h2>\n\n<p>You can obtain public data from the New York City Taxi and Limousine Commission\n<a href=\"http://www.nyc.gov/html/tlc/html/about/trip_record_data.shtml\">here</a>.  I\ndownloaded this onto the head node and dumped it into HDFS with commands like\nthe following:</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>$ wget https://storage.googleapis.com/tlc-trip-data/2015/yellow_tripdata_2015-{01..12}.csv\n$ hdfs dfs -mkdir /nyctaxi\n$ hdfs dfs -mkdir /nyctaxi/2015\n$ hdfs dfs -put yellow*.csv /nyctaxi/2015/\n</code></pre></div></div>\n\n<p>The cluster was hosted on EC2 and was comprised of nine <code class=\"language-plaintext highlighter-rouge\">m3.2xlarges</code> with 8\ncores and 30GB of RAM each.  Eight of these nodes were used as workers; they\nused processes for parallelism, not threads.</p>"
}