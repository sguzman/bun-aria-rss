{
  "title": "DynLight: Realize dynamic phase duration with multi-level traffic signal control. (arXiv:2204.03471v3 [cs.AI] UPDATED)",
  "link": "http://arxiv.org/abs/2204.03471",
  "description": "<p>Adopting reinforcement learning (RL) for traffic signal control (TSC) is\nincreasingly popular, and RL has become a promising solution for traffic signal\ncontrol. However, several challenges still need to be overcome. Firstly, most\nRL methods use fixed action duration and select the green phase for the next\nstate, which makes the phase duration less dynamic and flexible. Secondly, the\nphase sequence of RL methods can be arbitrary, affecting the real-world\ndeployment which may require a cyclical phase structure. Lastly, the average\ntravel time and throughput are not fair metrics to evaluate TSC performance. To\naddress these challenges, we propose a multi-level traffic signal control\nframework, DynLight, which uses an optimization method Max-QueueLength (M-QL)\nto determine the phase and uses a deep Q-network to determine the duration of\nthe corresponding phase. Based on DynLight, we further propose DynLight-C which\nadopts a well-trained deep Q-network of DynLight and replace M-QL with a\ncyclical control policy that actuates a set of phases in fixed cyclical order\nto realize cyclical phase structure. Comprehensive experiments on multiple\nreal-world datasets demonstrate that DynLight achieves a new state-of-the-art.\nFurthermore, the deep Q-network of DynLight can learn well on determining the\nphase duration and DynLight-C demonstrates high performance for deployment.\n</p>",
  "dc:creator": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Liang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1\">Shubin Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1\">Jianming Deng</a>"
}