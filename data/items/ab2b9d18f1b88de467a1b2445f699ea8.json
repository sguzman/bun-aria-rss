{
  "id": "tag:blogger.com,1999:blog-15418143.post-5552908452350401895",
  "published": "2015-03-26T02:25:00.001-05:00",
  "updated": "2016-06-13T07:44:19.948-05:00",
  "category": [
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    ""
  ],
  "title": "Mobileye's quest to put Deep Learning inside every new car",
  "content": "<div class=\"p1\"><span class=\"s2\">In Amnon Shashua's vision of the future, every car can see</span>. &nbsp;He's convinced that the key technology behind the imminent driving revolution is going to be <b>computer vision</b>, and to experience this technology,&nbsp;<b>we won't have to wait for fully autonomous cars to become mainstream</b>.<b>&nbsp;&nbsp;</b>I had the chance to hear Shashua's vision of the future this past Monday, and from what I'm about to tell you, it looks like there's going to be <b>a whole lot of Deep Learning inside tomorrow's car<i>.&nbsp;</i></b>Cars equipped with Deep Learning-based pedestrian avoidance systems (See Figure 1) can sense people and dangerous situations while you're behind the wheel. From winning large-scale object recognition competitions like ImageNet, to heavy internal use by Google, Deep Learning is now at the foundation of many hi-tech startups and giants. And when it comes to cars, Deep Learning promises to give us both safer roads&nbsp;and the highly-anticipated hands-free driving experience.&nbsp;</div><div class=\"p1\"><br /><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://4.bp.blogspot.com/-99sL1hGWDbY/VRI9gcyf1bI/AAAAAAAAN2c/ViA3bMwa4hs/s1600/mobileye_technology.png\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" height=\"168\" src=\"https://4.bp.blogspot.com/-99sL1hGWDbY/VRI9gcyf1bI/AAAAAAAAN2c/ViA3bMwa4hs/s1600/mobileye_technology.png\" width=\"320\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://www.mobileye.com/technology/\">Mobileye's&nbsp;</a>Deep Learning-based Pedestrian Detector</div></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><br /></div><div class=\"p4\"><span class=\"s2\"><b>Mobileye Co-founder Amnon Shashua shares his vision during an invited lecture at MIT</b></span></div><div class=\"p4\"><span class=\"s2\">       </span></div><div class=\"p1\"><span class=\"s1\"><a href=\"http://en.wikipedia.org/wiki/Amnon_Shashua\">Amnon Shashua</a>&nbsp;is the&nbsp;</span><span class=\"s2\">Co-founder &amp; CTO of <a href=\"http://www.mobileye.com/\">Mobileye</a>&nbsp;and&nbsp;</span>this past Monday (March 23, 2015) he&nbsp;<span class=\"s2\">gave a compelling talk at</span><span class=\"s1\"> MIT’s <a href=\"https://cbmm.mit.edu/news-events/events/brains-minds-machines-seminar-series-computer-vision-changing-our-lives\">Brains, Minds &amp; Machines Seminar&nbsp;Series</a> titled “</span><span class=\"s2\">Computer Vision that is Changing Our Lives”.&nbsp;Shashua discussed Mobileye’s Deep Learning chips, robots, autonomous driving, as well as introduced his most recent project, a wearable computer vision unit called <a href=\"http://www.orcam.com/\">OrCam</a>.&nbsp;</span><br /><span class=\"s2\"><br /></span><br /><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://4.bp.blogspot.com/-cK3SV7jfZ3U/VRI8yeCk_zI/AAAAAAAAN2U/f3bhiQk1KUA/s1600/mobileye.jpg\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" height=\"212\" src=\"https://4.bp.blogspot.com/-cK3SV7jfZ3U/VRI8yeCk_zI/AAAAAAAAN2U/f3bhiQk1KUA/s1600/mobileye.jpg\" width=\"320\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\">Fig 2. Prof Amnon Shashua, CTO of Mobileye</div><span class=\"s2\"><br /></span><span class=\"s2\">Let's take a deeper look at the man behind Mobileye and his vision. Below is my summary of Shashua's talk as well as some personal insights regarding Mobileye's&nbsp;embedded computer vision technology and how it relates to cloud-based computer vision.</span><br /><br /><b>Mobileye's academic roots</b><br /><span class=\"s2\">You might have heard stories of bold entrepreneurs dropping out of college to form million dollar startups, but this isn't one of them. &nbsp;This is the story of a professor who turned his ideas into a publicly traded company, Mobileye (NYSE:MBLY). Amnon Shashua is a Professor at Hebrew University, and his lifetime achievements suggest that <b>for high-tech entrepreneurship, it is pretty cool to stay in school</b>. And while Shashua and I never overlapped academically (he is 23 years older than me), both of us spent some time at MIT as postdoctoral researchers.</span><br /><span class=\"s2\"><br /></span></div><div class=\"p3\"><span class=\"s2\"></span></div><div class=\"p1\"><span class=\"s2\"><b>Deep Learning's impact on Mobileye</b></span></div><div class=\"p1\"><span class=\"s2\">During his presentation at MIT, Amnon Shashua showcased a wide array of of computer vision problems that are currently being solved by Mobileye real-time computer vision systems. These systems are image-based and do not require expensive 3D sensors such as the ones commonly found on top of self-driving cars. &nbsp;He showed videos of real-time lane detection, pedestrian detection, animal detection, and road surface detection. I have seen many similar visualizations during my academic career; however, Shashua emphasized that <b>deep learning is now used to power most of Mobileye's computer vision systems</b>.&nbsp;</span><br /><span class=\"s2\"><br /></span><span class=\"s2\"><b>Question:</b> I genuinely wonder how much the shift to Deep methods improved Mobileye's algorithms, or if the move is a strategic technology upgrade to stay relevant in the era where Google and and competition is feverishly pouncing on the landscape of deep learning. There's a lot of competition on the hardware front, and it <b>seems like the chase for ASIC-like Deep Learning Miners/Trainers is on</b>.</span><br /><span class=\"s2\"><br /></span><br /><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://1.bp.blogspot.com/-TE9BUs2F8XA/VRMo02YyWcI/AAAAAAAAN3Y/5v8-Zc8cFy4/s1600/alexnet.png\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" height=\"212\" src=\"https://1.bp.blogspot.com/-TE9BUs2F8XA/VRMo02YyWcI/AAAAAAAAN3Y/5v8-Zc8cFy4/s1600/alexnet.png\" width=\"640\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\">The AlexNet CNN diagram from the <a href=\"http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf\">popular&nbsp;Krizhevsky/Sutskever/Hinton paper</a>. Shashua explicitly mentioned the AlexNet model during his MIT talk, and it appears that Mobileye has done their Deep Learning homework.</div><span class=\"s2\"><br /></span><span class=\"s2\"><b>The early Mobileye:&nbsp;</b></span>Mobileye didn’t wait for the deep learning revolution to happen. They started shipping computer vision technology for vehicles using traditional techniques more than a decade ago. In fact, I attended a Mobileye presentation at CMU almost a full decade ago -- it was given by Andras Ferencz at the&nbsp;<a href=\"http://vasc.ri.cmu.edu/seminar/old/F05.html\">2005 CMU VASC Seminar</a>. &nbsp;This week's talk by Shashua suggests that <b>Mobileye was able to successfully modernize their algorithms to use deep learning.</b><br /><br /><b>Further reading:</b>&nbsp;To learn about object recognition methods in computer vision which were popular before Deep Learning, see my January blog post, titled&nbsp;<a href=\"http://www.computervisionblog.com/2015/01/from-feature-descriptors-to-deep.html\">From feature descriptors to deep learning: 20 years of computer vision</a>.<br /><br /></div><div class=\"p1\"><span class=\"s2\"><br /></span></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://1.bp.blogspot.com/-DVxBJt9hNJI/VRJBOmQux0I/AAAAAAAAN2w/5-d9P81DH70/s1600/amnon%2Bdeep_learning.png\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" height=\"272\" src=\"https://1.bp.blogspot.com/-DVxBJt9hNJI/VRJBOmQux0I/AAAAAAAAN2w/5-d9P81DH70/s1600/amnon%2Bdeep_learning.png\" width=\"640\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\">Fig 3. \"Deep Learning at Mobileye\" presentation at the 2015 Deutsche Bank Global&nbsp;</div><div class=\"separator\" style=\"clear: both; text-align: center;\">Auto Industry Conference.</div><div class=\"p1\"><span class=\"s2\"><br /></span></div><div class=\"p3\"><b><span class=\"s2\"></span>Mobileye's custom Computer Vision hardware</b></div><div class=\"p1\"><span class=\"s2\">Mobileye is not a software computer vision company -- they bake their algorithms into custom computer vision chips. Shashua reported some<b> impressive computation speeds on what appears to be tiny vision chips</b>. Their custom hardware is more specific than GPUs (which are quite common for deep learning, scientific computations, computer graphics, and actually affordable). But Mobileye chips do not need to perform the computationally expensive big-data training stage onboard, so their devices can be much leaner than GPUs. Mobileye has lots of hardware experience, and regarding machine learning, Shashua mentioned that Mobileye has more vehicle-related training data than they know what to do with. &nbsp;</span><br /><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://4.bp.blogspot.com/-SjGNQxZMyMw/VRJARTrOJtI/AAAAAAAAN2o/o_uTMoySXl4/s1600/Lane_Guidance_Camera_PCB.jpg\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" height=\"241\" src=\"https://4.bp.blogspot.com/-SjGNQxZMyMw/VRJARTrOJtI/AAAAAAAAN2o/o_uTMoySXl4/s1600/Lane_Guidance_Camera_PCB.jpg\" width=\"320\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\">Fig 4. The Mobileye Q2 lane detection chip.</div><div class=\"p3\"><br /></div><div class=\"p3\"><br /><b>Embedded vs. Cloud-based computer vision</b><br />While Mobileye makes a strong case for embedded computer vision, there are many scenarios today where the alternative cloud-based computer vision approach triumphs. &nbsp;<b>Cloud-based computer vision is about delivering powerful algorithms as a service, over the web.</b> &nbsp;In a cloud-based architecture, the algorithms live in a data center and applications talk to the vision backend via an API layer. &nbsp;And while certain mission-critical applications cannot have a cloud-component (e.g., a drones flying over the desert), cloud-based vision system promise to turn laptops and smartphones into smart devices, without the need to bake algorithms into chips. In-home surveillance apps, home-automation apps, exploratory robotics projects, and even scientific research can benefit from cloud-based computer vision. &nbsp;Most importantly, cloud-based deployment means that startups can innovate faster, and entire products can evolve much faster.<br /><br />Unlike Mobileye's decade-long journey, I suspect&nbsp;<b>cloud-based computer vision platforms are going to make computer vision development much faster, </b>giving developers a Heroku-like button for visual AI. &nbsp;Choosing diverse compilation targets such as a custom chip or Javascript will be handled by the computer vision platform, allowing computer vision developers to work smarter and deploy to more devices.<br /><br /></div><div class=\"p3\"><span class=\"s2\"></span></div><div class=\"p1\"><span class=\"s2\"><b>Conclusion and Predictions</b></span></div><div class=\"p1\">Even if you don't believe that today's computer vision-based safety features make cars smart enough to call them robots, driving tomorrow's car is sure going to <i>feel</i> different. &nbsp;I will leave you with one final note: Mobileye's CTO hinted that if you are going to design a car in 2015 on top of computer vision tech, you <b>might reconsider traditional safety features such as airbags, and create a leaner, less-expensive AI-enabled vehicle</b>.<br /><span style=\"font-size: xx-small; text-align: center;\"><br /></span><br /><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://safety.trw.com/wp-content/uploads/2013/08/photo-sae-Data-Fusion-jpg.jpg\" imageanchor=\"1\" style=\"display: inline !important; margin-left: 1em; margin-right: 1em; text-align: center;\"><img border=\"0\" src=\"http://safety.trw.com/wp-content/uploads/2013/08/photo-sae-Data-Fusion-jpg.jpg\" height=\"284\" width=\"640\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\">Fig 5. Mobileye technology illustration [<a href=\"http://safety.trw.com/trws-new-video-camera-supports-global-safety-trends-2/0910/\">safety.trw.com</a>].</div><br /><div style=\"text-align: left;\"><br /></div></div><div class=\"p1\"><b>Watch the Mobileye presentation on YouTube:</b> If you are interested in embedded deep learning, autonomous vehicles, or want to get a taste of how the industry veterans compile their deep networks into chips, you can watch the full 38-minute presentation from Amnon's January 2015 Mobileye presentation.&nbsp;</div><div class=\"p1\"><br /></div><center><iframe allowfullscreen=\"\" frameborder=\"0\" height=\"315\" src=\"https://www.youtube.com/embed/kp3ik5f3-2c\" width=\"560\"></iframe></center><div class=\"p1\"><br /></div><div class=\"p1\"><br />I hope you learned a little bit about vehicle computer vision systems, embedded Deep Learning, and got a glimpse of the visual intelligence revolution that is happening today. Feel free to comment below, follow me on Twitter (<a href=\"https://twitter.com/quantombone\">@quantombone</a>), or sign-up to the <a href=\"http://vision.ai/\">vision.ai</a> mailing list if you are a developer interested in taking vision.ai's cloud-based computer vision platform for a spin.<br /><br /></div><a class=\"twitter-follow-button\" data-show-count=\"false\" href=\"https://twitter.com/quantombone\">Follow @quantombone</a><script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>",
  "link": [
    "",
    "",
    "",
    "",
    ""
  ],
  "author": {
    "name": "Tomasz Malisiewicz",
    "uri": "http://www.blogger.com/profile/17507234774392358321",
    "email": "noreply@blogger.com",
    "gd:image": ""
  },
  "media:thumbnail": "",
  "thr:total": 2
}