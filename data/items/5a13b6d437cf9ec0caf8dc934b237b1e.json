{
  "title": "Demosaicing",
  "link": "",
  "published": "2015-05-29T23:00:00+01:00",
  "updated": "2015-05-29T23:00:00+01:00",
  "author": {
    "name": "Sebastian Nowozin"
  },
  "id": "tag:www.nowozin.net,2015-05-29:/sebastian/blog/demosaicing.html",
  "summary": "<p>This article describes the basic problem of image demosaicing and a recent work\nof mine providing a research dataset for demosaicing research.</p>\n<p><a href=\"http://en.wikipedia.org/wiki/Demosaicing\">Image demosaicing</a> is a procedure\nused in almost all digital cameras.\nFrom your smartphone camera to the top-of-the-line â€¦</p>",
  "content": "<p>This article describes the basic problem of image demosaicing and a recent work\nof mine providing a research dataset for demosaicing research.</p>\n<p><a href=\"http://en.wikipedia.org/wiki/Demosaicing\">Image demosaicing</a> is a procedure\nused in almost all digital cameras.\nFrom your smartphone camera to the top-of-the-line digital SLR cameras, they\nall use a demosaicing algorithm to convert the captured sensor information into\na color image.\nSo what is this algorithm doing and why is it needed?</p>\n<h2>Why do we need Demosaicing?</h2>\n<p>Modern imaging sensors are based on semiconductors which have a large number of\nphoto-sensitive sensor elements, called <em>sensels</em>.\nWhen a quantum of light hits a sensel it creates an electric charge.\nThe amount of the charge created depends on the energy of the photon which\ndepends on the wavelength of the incident light.\nUnfortunately, in current imaging sensors, once the electric charge is created\nit is no longer possible to deduce the color of the light.\n(The exception is the <a href=\"http://www.foveon.com/\">Foveon sensor</a> which uses a\nlayered silicon design in which photons of higher energy levels (green and\nblue) penetrate into lower silicon layers than photons of lower energy levels\n(red)).</p>\n<p>To produce color images current sensors therefore do not record all wavelengths\nequally at each sensor element.\nInstead, each element has it's own color filter.\nA typical modern sensor uses three distinct filter types, each most sensitive\nto a particular range of wavelengths.\nThe three types are abbreviated red (R), green (G), and blue (B), although in\nreality they are remain sensitive to all wavelengths.\nFor a detailed plot of the wavelength sensitivities, <a href=\"http://www.dxomark.com/About/In-depth-measurements/Measurements/Color-sensitivity\">this\npage</a>\nhas a nice graph.</p>\n<p>Each sensor element therefore records only one measurement: the charge related\nto a certain range of wavelengths.\nIt does not record the full color information.\nTo reproduce an image suitable for human consumption we require three\nmeasurements, such as red/green/blue values.  (This is a simplification, and in\nreal systems the concept of a color space is used; a camera records in a\ncamera-specific color space which is then transformed into a perceptual color\nspace such as Adobe sRGB.)</p>\n<p>The most popular arrangement of color filters is the so called Bayer filter\nand has a layout as shown below.</p>\n<p><img alt=\"Bayer RGGB color filter array\" src=\"http://www.nowozin.net/sebastian/blog/images/demosaicing-bayer.png\"></p>\n<p><em>Image demosaicing</em> is the process of recovering the missing colors at each\nsensor element.\nFor example, in the top left sensel of the above figure only the blue response\nis measured and we need to recover the value of the green and red responses at\nthis spatial location.</p>\n<p>In principle, why should this even be possible?\nBecause images of the natural world are slowly changing across the sensor,\nwe can use color information from adjacent sensels (but different filter types)\nto provide the missing information.</p>\n<h2>Challenges for Demosaicing Algorithms</h2>\n<p>The above description is correct in that all demosaicing algorithms use\ncorrelations among spatially close sensels to restore the missing information.\nHowever, there are around three dozen publically available demosaicing\nalgorithms and probably many more proprietary ones.\nBeside differences in resource requirements and complexity, these algorithms\nalso differ widely in their demosaicing performance.</p>\n<p>Without considering implementation concerns for a moment, what makes a good\ndemosaicing algorithm?\nA good demosaicing method has the following desirable properties:</p>\n<ul>\n<li>Visually pleasing demosaiced output images;</li>\n<li>No visible high-frequency artifacts (<em>zippering</em>), no visible color artifacts;</li>\n<li>Robustness to noise present in the input;</li>\n<li>Applicable to different color filter array layouts (not just <a href=\"http://en.wikipedia.org/wiki/Bayer_filter\">Bayer</a>);</li>\n</ul>\n<p>To achieve this, a demosaicing algorithm has to be highly adapted to the\nstatistics of natural images.\nThat is, it has to have an understanding of typical image components such as\ntextures, edges, smooth surfaces, etcetera.</p>\n<h2>Research Dataset</h2>\n<p>One approach to image demosaicing is to treat it is a statistical regression\nproblem.\nBy learning about natural image statistics from ground truth data, one should\nbe able -- given sufficient data -- to approach the optimal demosaicing\nperformance possible.</p>\n<p>The problem is, perhaps surprisingly, that there are no suitable datasets.\nCurrent comparisons of demosaicing algorithms in the literature resort to two\napproaches to provide results for their algorithms:</p>\n<ol>\n<li>Use a small set of Kodak images that were scanned onto Photo-CD's (remember\nthose?) in the mid-1990'ies from analogue films.  To me it is unclear whether\nthis scanning involved demosaicing, and whether the properties of the analogue\nfilms are an adequate proxy for digital imaging sensors.</li>\n<li>Download sRGB images from the Internet and remove color channels to obtain a\nmosaiced image.  But all these images have been demosaiced already, so we\nmerely measure the closeness of one demosaicing algorithm to another one.</li>\n</ol>\n<p>This is appalling on the one hand, but it is certainly challenging to improve\non it, if only for the reason that currently no sensor can capture ground truth\neasily.\nThere have been ideas to obtain ground truth using a Foveon sensor or by using\na global switchable color filter and multiple captures.\nThe first idea (using a Foveon camera) sounds feasible but the noise and\nsensitivity characteristics of a Foveon sensor are quite different from popular\nCFA-CMOS sensors.\nThe second idea sounds ideal but would only work in a static lab setup.</p>\n<p>We introduce the <a href=\"http://research.microsoft.com/en-us/um/cambridge/projects/msrdemosaic/\">Microsoft Research Demosaicing\nDataset</a>,\nour attempt at providing a suitable dataset.\nOur dataset is described in detail in an <a href=\"http://www.nowozin.net/sebastian/papers/khashabi2014demosaicing.pdf\">IEEE TIP\npaper</a>.\nThe dataset contains 500 images captured by ourselves containing both indoor\nand outdoor imagery.  Here are some example images.</p>\n<p><img alt=\"MSR Demosaicing dataset example images\" src=\"http://www.nowozin.net/sebastian/blog/images/msr-demosaicing-images.jpg\"></p>\n<p>How did we overcome the problem of creating suitable ground truth images?\nThe basic idea is as follows: it is difficult to capture ground truth for\ndemosaicing for a full image sensor, but if we group multiple sensels into one\nvirtual sensel then we can interpret this group as possessing all necessary\ncolor information.\nThat is, we simultaneously reduce the image resolution and perform demosaicing.\nThere are multiple proposals in the paper how to do this technically in a\nsound manner, but to see it visually, here is an example of downsampling using\n3-by-3 sensel blocks on a Bayer filter.</p>\n<p><img alt=\"Bayer RGGB 3-by-3 downsampling\" src=\"http://www.nowozin.net/sebastian/blog/images/demosaicing-oddblock.png\"></p>\n<p>As you can see, within each 3-by-3 sensel block we may have an unequal number\nof measurements of each color, but the spatial distribution of sensels of\ndifferent types is uniform in the sense that their center of gravity is the\ncenter of the 3-by-3 block.\nThis is not the case in general, for example when averaging 4-by-4 blocks of\nBayer measurements, then the red channels will have a higher density in the\nupper left corner of each block.</p>\n<h2>Algorithm Comparison</h2>\n<p>So how do common algorithms (and our novel algorithm) fare on our benchmark\ndata set?\nPerformance is typically measured as a function of the mean-squared-error of\nthe predicted image intensities.  The most common measurement is the <a href=\"http://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio\">peak\nsignal to noise\nratio</a> measured in\ndecibels (dB), where higher is better.\nWe also report another performance measure based on a perceptual similarity\nmetric, the structural similarity index (SSIM) which measures mean and\nvariance statistics in image blocks, and again a higher score means a better\ndemosaiced image.</p>\n<p>The top algorithms achieve the following performance.  I also include bilinear\ninterpolation as a baseline method.</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Method</th>\n<th align=\"center\">PSNR (dB)</th>\n<th align=\"center\">SSIM</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"left\">Bilinear interpolation</td>\n<td align=\"center\">30.86</td>\n<td align=\"center\">0.882</td>\n</tr>\n<tr>\n<td align=\"left\">Non-Local means</td>\n<td align=\"center\">38.42</td>\n<td align=\"center\">0.978</td>\n</tr>\n<tr>\n<td align=\"left\">Contour stencils</td>\n<td align=\"center\"><strong>39.41</strong></td>\n<td align=\"center\"><strong>0.980</strong></td>\n</tr>\n<tr>\n<td align=\"left\">RTF (our method)</td>\n<td align=\"center\">39.39</td>\n<td align=\"center\"><strong>0.980</strong></td>\n</tr>\n</tbody>\n</table>\n<p>Hence we achieve a result comparable to the state of the art.\nThe experiments become interesting when we perform simultaneous denoising and\ndemosaicing.\nPerforming both operations simultaneously is desirable in a real imaging\npipeline because both they happen at the same stage in the processing.\nFor the task of simultaneous denoising and demosaicing the results tell a\ndifferent story.</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Method</th>\n<th align=\"center\">PSNR (dB)</th>\n<th align=\"center\">SSIM</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"left\">Bilinear interpolation</td>\n<td align=\"center\">30.40</td>\n<td align=\"center\">0.859</td>\n</tr>\n<tr>\n<td align=\"left\">Non-Local means</td>\n<td align=\"center\">36.46</td>\n<td align=\"center\">0.949</td>\n</tr>\n<tr>\n<td align=\"left\">Contour stencils</td>\n<td align=\"center\">37.17</td>\n<td align=\"center\">0.953</td>\n</tr>\n<tr>\n<td align=\"left\">RTF (our method)</td>\n<td align=\"center\"><strong>37.78</strong></td>\n<td align=\"center\"><strong>0.961</strong></td>\n</tr>\n</tbody>\n</table>\n<p>In the paper we compare more than a dozen methods.\nThe proposed method achieves an improved demosaicing performance of over 0.5dB\nin realistic conditions which is visually significant.\nOur method is based on the non-parametric <a href=\"http://www.nowozin.net/sebastian/papers/jancsary2012rtf.pdf\">regression tree field model\n(RTF)</a>\nwhich we have published earlier; essentially this is a Gaussian conditional\nrandom field (CRF) with very rich potential functions defined by regression\ntrees.  Due to its high capacity it can learn a lot about image statistics\nrelevant to demosaicing.</p>\n<p>The next best method is the <a href=\"http://www.ipol.im/pub/art/2012/g-dwcs/\">contour stencils method of\nGetreuer</a>.\nThis method performs smoothing and completion of values along a graph defined\non the sensor positions.  While the method works well it is manually defined\nfor the Bayer pattern and may not be easily generalized to arbitrary color\nfilter arrays.</p>\n<h2>Outlook</h2>\n<p>Demosaicing for the Bayer layout is largely solved, but for novel color filter\narray layouts there currently is no all-around best method.  While our\nmachine learning approach is feasible and leads to high quality demosaicing\nresults, the current loss functions used (such as peak signal to noise ratio\n(PSNR) and structural similarity (SSIM)) are not sufficiently aligned with\nhuman perception to accurately measure image quality, in particular for\nzippering artifacts along edge structures.\nWhatever demosaicing method is adopted, it is beneficial to simultaneously\nperform demosaicing and denoising, because either task becomes more difficult\nif performed in isolation.</p>",
  "category": ""
}