{
  "title": "WeightWatcher:  Empirical Quality Metrics for Deep Neural Networks",
  "link": "https://calculatedcontent.com/2020/02/16/weightwatcher-empirical-quality-metrics-for-deep-neural-networks/",
  "comments": "https://calculatedcontent.com/2020/02/16/weightwatcher-empirical-quality-metrics-for-deep-neural-networks/#respond",
  "dc:creator": "Charles H Martin, PhD",
  "pubDate": "Mon, 17 Feb 2020 00:58:14 +0000",
  "category": [
    "Uncategorized",
    "AI",
    "DATA SCIENCE",
    "Deep Learning",
    "KERAS",
    "machine learning",
    "NLP",
    "PYTORCH",
    "TENSORFLOW"
  ],
  "guid": "http://calculatedcontent.com/?p=13287",
  "description": "We introduce the weightwatcher (ww) , a python tool for a python tool for computing quality metrics of trained, and &#8230; <a class=\"more-link\" href=\"https://calculatedcontent.com/2020/02/16/weightwatcher-empirical-quality-metrics-for-deep-neural-networks/\">More</a>",
  "content:encoded": "\n<p></p>\n\n\n\n<p>We introduce the <a href=\"https://github.com/CalculatedContent/WeightWatcher\">weightwatcher</a> (ww) , a python tool for a python tool for computing quality metrics of trained, and pretrained, Deep Neural Netwworks.</p>\n\n\n\n<p class=\"has-text-align-center\">pip install weightwatcher</p>\n\n\n\n<p>This blog describes how to use the tool in practice; <a href=\"https://arxiv.org/pdf/2002.06716.pdf\">see our most recent paper for even more details.</a>  </p>\n\n\n\n<p>Here is an example with pretrained VGG11 from pytorch (ww works with keras models also):</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: python; title: ; notranslate\">\n<code>import weightwatcher as ww\nimport torchvision.models as models\n\nmodel = models.vgg11(pretrained=True)\nwatcher = ww.WeightWatcher(model=model)\nresults = watcher.analyze()\n\nsummary = watcher.get_summary()\ndetails = watcher.get_details()</code>\n</pre></div>\n\n\n<p>WeightWatcher generates a dict that summarizes the empirical quality metrics for the model (with the most useful metrics)</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: python; title: ; notranslate\">\n<strong>summary:</strong> = { ...\n  alpha: 2.572493\n  alpha_weighted: 3.418571\n  lognorm: 1.252417   \n  logspectralnorm: 1.377540 \n  logpnorm: 3.878202\n... }<strong>\n</strong>\n</pre></div>\n\n\n<p>The tool also generates a <strong>details</strong> pandas dataframe, with a layer-by-layer analysis (shown below)</p>\n\n\n\n<p>The summary contains the Power Law exponent (<img src=\"https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;alpha\" class=\"latex\" />), as well as several log norm metrics, as explained in our papers, and below.  Each value represents an empirical quality metric that can be used to gauge the gross effectiveness of the model, as compared to similar models. </p>\n\n\n\n<p>(<a href=\"https://github.com/CalculatedContent/WeightWatcher/blob/master/WeightWatcher.ipynb\">The main weightwatcher notebook</a> demonstrates more features )</p>\n\n\n\n<p>For example, <strong>lognorm</strong> is the average over all layers L of the log of the Frobenius norm of each layer weight matrix <img src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;mathbf{W}\" class=\"latex\" /> :</p>\n\n\n\n<p class=\"has-text-align-left\"><strong>lognorm</strong>: average log Frobenius Norm := <img src=\"https://s0.wp.com/latex.php?latex=%5Cdfrac%7B1%7D%7BL%7D%5Csum_%7Bl%7D%5Clog%5CVert%5Cmathbf%7BW_%7Bl%7D%7D%5CVert_%7BF%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Cdfrac%7B1%7D%7BL%7D%5Csum_%7Bl%7D%5Clog%5CVert%5Cmathbf%7BW_%7Bl%7D%7D%5CVert_%7BF%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdfrac%7B1%7D%7BL%7D%5Csum_%7Bl%7D%5Clog%5CVert%5Cmathbf%7BW_%7Bl%7D%7D%5CVert_%7BF%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;dfrac{1}{L}&#92;sum_{l}&#92;log&#92;Vert&#92;mathbf{W_{l}}&#92;Vert_{F} \" class=\"latex\" /></p>\n\n\n\n<p>Where the individual layer Frobenius norm, for say a Fully Connected (FC layer,  may be computed as</p>\n\n\n\n<p class=\"has-text-align-center\"><img src=\"https://s0.wp.com/latex.php?latex=%5C%5Clog%5CVert%5Cmathbf%7BW%7D%5CVert_%7BF%7D%3D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5C%5Clog%5CVert%5Cmathbf%7BW%7D%5CVert_%7BF%7D%3D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5C%5Clog%5CVert%5Cmathbf%7BW%7D%5CVert_%7BF%7D%3D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;&#92;log&#92;Vert&#92;mathbf{W}&#92;Vert_{F}=\" class=\"latex\" /><code>np.log10(np.linalg.norm(W))</code></p>\n\n\n\n<h3>Comparing Metrics Across Models:</h3>\n\n\n\n<p>We can use these metrics to compare models across a common architecture series, such as the VGG series, the ResNet series, etc.  These can be applied to trained models, pretrained models, and/or even fine-tuned models.</p>\n\n\n\n<p>Consider the series of models VGG11, VGG11_BN, &#8230; VGG19, VGG_19, available in pytorch. We can plot the reported the various log norm metrics <img src=\"https://s0.wp.com/latex.php?latex=%5Clangle%5CVert%5Ccdot%5CVert%5Crangle&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Clangle%5CVert%5Ccdot%5CVert%5Crangle&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clangle%5CVert%5Ccdot%5CVert%5Crangle&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;langle&#92;Vert&#92;cdot&#92;Vert&#92;rangle\" class=\"latex\" /> vs the reported test accuracies.  </p>\n\n\n\n<figure class=\"wp-block-image size-large\"><img data-attachment-id=\"13647\" data-permalink=\"https://calculatedcontent.com/2020/02/16/weightwatcher-empirical-quality-metrics-for-deep-neural-networks/screen-shot-2020-02-14-at-10-06-20-pm/\" data-orig-file=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-14-at-10.06.20-pm.png\" data-orig-size=\"1604,1664\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"Screen Shot 2020-02-14 at 10.06.20 PM\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-14-at-10.06.20-pm.png?w=289\" data-large-file=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-14-at-10.06.20-pm.png?w=987\" src=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-14-at-10.06.20-pm.png?w=987\" alt=\"\" class=\"wp-image-13647\" srcset=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-14-at-10.06.20-pm.png?w=987 987w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-14-at-10.06.20-pm.png?w=145 145w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-14-at-10.06.20-pm.png?w=289 289w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-14-at-10.06.20-pm.png?w=768 768w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-14-at-10.06.20-pm.png 1604w\" sizes=\"(max-width: 987px) 100vw, 987px\" /></figure>\n\n\n\n<p>For a series of similar, well-trained models, all of the empirical log norm metrics correlate well with the reported test accuracies! Moreover, the Weighted Alpha and Log <img src=\"https://s0.wp.com/latex.php?latex=%5Calpha-&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Calpha-&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha-&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;alpha-\" class=\"latex\" />Norm metrics work best. </p>\n\n\n\n<p><em><strong>Smaller is better</strong></em>.</p>\n\n\n\n<p>We also run a ordinary linear regression (OLS) and the root mean squared error (RMSE) , and for several other CV models that are available in the pytorch <a href=\"https://pytorch.org/docs/stable/torchvision/models.html\">torchvision.models package.</a></p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" data-attachment-id=\"13679\" data-permalink=\"https://calculatedcontent.com/2020/02/16/weightwatcher-empirical-quality-metrics-for-deep-neural-networks/screen-shot-2020-02-15-at-10-32-36-am/\" data-orig-file=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-15-at-10.32.36-am.png\" data-orig-size=\"942,416\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"Screen Shot 2020-02-15 at 10.32.36 AM\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-15-at-10.32.36-am.png?w=300\" data-large-file=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-15-at-10.32.36-am.png?w=942\" src=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-15-at-10.32.36-am.png?w=840\" alt=\"\" class=\"wp-image-13679\" width=\"464\" height=\"205\" srcset=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-15-at-10.32.36-am.png?w=464 464w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-15-at-10.32.36-am.png?w=928 928w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-15-at-10.32.36-am.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-15-at-10.32.36-am.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-15-at-10.32.36-am.png?w=768 768w\" sizes=\"(max-width: 464px) 100vw, 464px\" /></figure></div>\n\n\n<p>We have tested this on over <a href=\"https://github.com/osmr/imgclsmob\">100 well trained computer vision (CV) pre-trained models on multiple data sets</a> (such as the ImageNet-1K subset of ImageNet).  These trends how for nearly every case of well-trained models.</p>\n\n\n\n<p>Notice that the RMSE for ResNet, trained on ImageNet1K, is larger than for ResNet trained on the full ImageNet, even though ResNet-1K has more models in the regression. that (19 vs  5).   For the exact same model, the larger and better data set shows a better OLS fit!  </p>\n\n\n\n<h4>How can you use this ?  </h4>\n\n\n\n<p>We have several ideas where we hope this would be useful.  These include:</p>\n\n\n\n<ul>\n<li>comparing different models trained using Auto-ML (in addition to standard cross-validation)</li>\n\n\n\n<li>judging the quality of NLP models for generating fake text (in addition to, say, the perplexity)</li>\n\n\n\n<li>evaluating different unsupervised clustering models, to determine which (presumably) gives the best clusters</li>\n\n\n\n<li>deciding if you have enough data, or need to add more, for your specific model or series of models.</li>\n</ul>\n\n\n\n<h3>Detailed quality metrics: layer-by-layer</h3>\n\n\n\n<p>We can learn even more about a model by looking at the empirical metrics, layer by layer.  The <strong>results</strong> is a dataframe that contains empirical quality metrics for each layer of the model.   An example output, for VGG11, is:</p>\n\n\n\n<figure class=\"wp-block-image size-large\"><img data-attachment-id=\"13633\" data-permalink=\"https://calculatedcontent.com/2020/02/16/weightwatcher-empirical-quality-metrics-for-deep-neural-networks/screen-shot-2020-02-14-at-9-50-36-pm/\" data-orig-file=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-14-at-9.50.36-pm.png\" data-orig-size=\"1534,536\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"Screen Shot 2020-02-14 at 9.50.36 PM\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-14-at-9.50.36-pm.png?w=300\" data-large-file=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-14-at-9.50.36-pm.png?w=1024\" src=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-14-at-9.50.36-pm.png?w=1024\" alt=\"\" class=\"wp-image-13633\" srcset=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-14-at-9.50.36-pm.png?w=1024 1024w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-14-at-9.50.36-pm.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-14-at-9.50.36-pm.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-14-at-9.50.36-pm.png?w=768 768w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-14-at-9.50.36-pm.png 1534w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" /></figure>\n\n\n\n<p>The columns contain both metadata for each layer (id, type, shape, etc), and the values of the empirical quality metrics for that layer matrix.  </p>\n\n\n\n<p>These metrics depend on the spectral properties&#8211;singular values <img src=\"https://s0.wp.com/latex.php?latex=%5Csigma&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Csigma&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Csigma&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;sigma\" class=\"latex\" /> of <img src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;mathbf{W}\" class=\"latex\" /> , or, equivalently, the eigenvalues  <img src=\"https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;lambda\" class=\"latex\" /> of the correlation matrix  of <img src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D%3D%5Cmathbf%7BW%7D%5E%7BT%7D%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D%3D%5Cmathbf%7BW%7D%5E%7BT%7D%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D%3D%5Cmathbf%7BW%7D%5E%7BT%7D%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;mathbf{X}=&#92;mathbf{W}^{T}&#92;mathbf{W}\" class=\"latex\" />.</p>\n\n\n\n<h4>The Power Law Exponent <img src=\"https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;alpha\" class=\"latex\" /></h4>\n\n\n\n<p>WeightWatcher is unique in that it can measure the amount of correlation, or information, that a model contains&#8211;without peeking at the training or test data.  Data Correlation is measured by the Power Law (PL) exponents <img src=\"https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;alpha\" class=\"latex\" />.</p>\n\n\n\n<p>WeightWatcher computes the eigenvalues (by SVD) for each layer weight matrix <img src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;mathbf{W}\" class=\"latex\" />, and fits the eigenvalue density (i.e. histogram <img src=\"https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;rho(&#92;lambda))\" class=\"latex\" /> to a truncated Power Law (PL), with PL exponent  <img src=\"https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;alpha\" class=\"latex\" /></p>\n\n\n\n<p class=\"has-text-align-center\"><img src=\"https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29%5Csim%5Clambda%5E%7B-%5Calpha%7D%2C%5C%3B%5C%3B%5Clambda%5Cle%5Clambda%5E%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29%5Csim%5Clambda%5E%7B-%5Calpha%7D%2C%5C%3B%5C%3B%5Clambda%5Cle%5Clambda%5E%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29%5Csim%5Clambda%5E%7B-%5Calpha%7D%2C%5C%3B%5C%3B%5Clambda%5Cle%5Clambda%5E%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;rho(&#92;lambda)&#92;sim&#92;lambda^{-&#92;alpha},&#92;;&#92;;&#92;lambda&#92;le&#92;lambda^{max}\" class=\"latex\" /> </p>\n\n\n\n<p>In nearly every pretrained model we have examined, the Empirical Spectral Density can be fit to a truncated PL.    And the PL exponent usually is in the range <img src=\"https://s0.wp.com/latex.php?latex=%5Calpha%5Cin%5B2%2C5-6%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Calpha%5Cin%5B2%2C5-6%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha%5Cin%5B2%2C5-6%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;alpha&#92;in[2,5-6]\" class=\"latex\" />, where smaller is better.</p>\n\n\n\n<p>Here is an example of the output of <code>weightwatcher</code> of the second Fully Connected layer (FC2) in VGG11.  These results can be reproduced using the WeightWatcher-VGG.ipynb notebook in the <a href=\"https://github.com/CalculatedContent/ww-trends-2020\">ww-trends-2020 github repo</a>., using the options:</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: python; title: ; notranslate\">\nresults = watcher.analyze(alphas=True, plot=True)\n</pre></div>\n\n\n<p>The plot below shows the ESD (Empirical Spectral Density <img src=\"https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;rho(&#92;lambda)\" class=\"latex\" />,), of the weight matrix <img src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;mathbf{W}\" class=\"latex\" />, in layer FC2.  Again, this is a (normalized) histogram of the eigenvalues <img src=\"https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;lambda\" class=\"latex\" /> of the correlation matrix <img src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D%3D%5Cmathbf%7BW%7D%5E%7BT%7D%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D%3D%5Cmathbf%7BW%7D%5E%7BT%7D%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D%3D%5Cmathbf%7BW%7D%5E%7BT%7D%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;mathbf{X}=&#92;mathbf{W}^{T}&#92;mathbf{W}\" class=\"latex\" />. </p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"alignleft size-large is-resized\"><img loading=\"lazy\" data-attachment-id=\"13731\" data-permalink=\"https://calculatedcontent.com/2020/02/16/weightwatcher-empirical-quality-metrics-for-deep-neural-networks/screen-shot-2020-02-16-at-11-06-38-am/\" data-orig-file=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-11.06.38-am.png\" data-orig-size=\"1406,1114\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"Screen Shot 2020-02-16 at 11.06.38 AM\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-11.06.38-am.png?w=300\" data-large-file=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-11.06.38-am.png?w=1024\" src=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-11.06.38-am.png?w=840\" alt=\"\" class=\"wp-image-13731\" width=\"340\" height=\"269\" srcset=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-11.06.38-am.png?w=340 340w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-11.06.38-am.png?w=680 680w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-11.06.38-am.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-11.06.38-am.png?w=300 300w\" sizes=\"(max-width: 340px) 100vw, 340px\" /></figure></div>\n\n\n<p class=\"has-text-align-left\">The FC2 matrix is square, 512&#215;512, and has an aspect ratio of Q=N/M=1 . The maximum eigenvalue is about 45, which is typical for many heavy tailed ESDs.  And there is a large peak at 0, which is normal for  Q=1.  Because Q= 1, the ESD might look  heavy tailed, but this can be deceiving because a random matrix with Q=1 would look similar.  Still, as with nearly all <em>well-trained</em> DNNS, we expect the FC2 ESD  <img src=\"https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;rho(&#92;lambda)\" class=\"latex\" /> to be well fit by a Power Law model, with an exponent  <img src=\"https://s0.wp.com/latex.php?latex=%5Calpha%5Cin%5B2%2C4%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Calpha%5Cin%5B2%2C4%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha%5Cin%5B2%2C4%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;alpha&#92;in[2,4]\" class=\"latex\" /> (i.e. <a href=\"https://arxiv.org/abs/1810.01075\">in the Fat Tailed Universality class</a>), or at least,  for a model that is not &#8216;flawed&#8217; in some way, <img src=\"https://s0.wp.com/latex.php?latex=%5Calpha%5Cle+6&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Calpha%5Cle+6&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha%5Cle+6&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;alpha&#92;le 6\" class=\"latex\" />.</p>\n\n\n\n<p class=\"has-text-align-center\"><strong>alpha</strong> . PL exponent for <img src=\"https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;alpha\" class=\"latex\" /> for <strong>W</strong>: <img src=\"https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29%5Csim%5Clambda%5E%7B-%5Calpha%7D%2C%5C%3B%5C%3B%5Clambda%5Cle%5Clambda%5E%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29%5Csim%5Clambda%5E%7B-%5Calpha%7D%2C%5C%3B%5C%3B%5Clambda%5Cle%5Clambda%5E%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29%5Csim%5Clambda%5E%7B-%5Calpha%7D%2C%5C%3B%5C%3B%5Clambda%5Cle%5Clambda%5E%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;rho(&#92;lambda)&#92;sim&#92;lambda^{-&#92;alpha},&#92;;&#92;;&#92;lambda&#92;le&#92;lambda^{max}\" class=\"latex\" /></p>\n\n\n\n<p>The smaller <strong>alpha</strong> <img src=\"https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;alpha\" class=\"latex\" /> is , for each layer, the more correlation that layer describes. Indeed, in the best performing models, all of the layer <strong>alphas</strong> approach 2 <img src=\"https://s0.wp.com/latex.php?latex=%28%5Calpha%5Crightarrow+2%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%28%5Calpha%5Crightarrow+2%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28%5Calpha%5Crightarrow+2%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"(&#92;alpha&#92;rightarrow 2)\" class=\"latex\" />.</p>\n\n\n\n<p>To check that the ESD is really heavy tailed, we need to check the Power Law (PL) fit.  This is done by inspecting the weightwatcher plots.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"alignright size-large is-resized\"><img loading=\"lazy\" data-attachment-id=\"13730\" data-permalink=\"https://calculatedcontent.com/2020/02/16/weightwatcher-empirical-quality-metrics-for-deep-neural-networks/screen-shot-2020-02-16-at-11-06-44-am/\" data-orig-file=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-11.06.44-am.png\" data-orig-size=\"1454,1130\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"Screen Shot 2020-02-16 at 11.06.44 AM\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-11.06.44-am.png?w=300\" data-large-file=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-11.06.44-am.png?w=1024\" src=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-11.06.44-am.png?w=840\" alt=\"\" class=\"wp-image-13730\" width=\"376\" height=\"292\" srcset=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-11.06.44-am.png?w=376 376w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-11.06.44-am.png?w=752 752w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-11.06.44-am.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-11.06.44-am.png?w=300 300w\" sizes=\"(max-width: 376px) 100vw, 376px\" /></figure></div>\n\n\n<p>The plot on the right shows the output of the <a href=\"https://arxiv.org/abs/1305.0215\">powerlaw</a> package, which is used to do the PL fit of the ESD.  The PL exponent <img src=\"https://s0.wp.com/latex.php?latex=%5Calpha%3D3.41&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Calpha%3D3.41&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha%3D3.41&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;alpha=3.41\" class=\"latex\" />, which is a typical value for (moderately, i.e. Fat) Heavy Tailed ESDs.   Also, the KS distance is small <img src=\"https://s0.wp.com/latex.php?latex=%28%5Cle+0.1%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%28%5Cle+0.1%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28%5Cle+0.1%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"(&#92;le 0.1)\" class=\"latex\" />, which is good.  We can also see this visually.  The dots are the actual data, and the lines are the fits.  If the lines are reasonably straight, and match the dots, and in the range <img src=\"https://s0.wp.com/latex.php?latex=0%3C%5Clambda%5Cle%5Clambda%5E%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=0%3C%5Clambda%5Cle%5Clambda%5E%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0%3C%5Clambda%5Cle%5Clambda%5E%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"0<&#92;lambda&#92;le&#92;lambda^{max}\" class=\"latex\" /> the fit is good.  <em>And they are.</em> This is a good PL fit.</p>\n\n\n\n<p></p>\n\n\n\n<h4>Good Model, Bad Data ?</h4>\n\n\n\n<p>As shown above, with  ResNet vs ResNet-1K, the <code>weightwatcher</code> tool can help you decide if you have enough data, or your model/architecture would benefit from more data.  Indeed, poorly trained models, with very bad data sets, show strange behavior that you can detect using <code>weightwatcher</code></p>\n\n\n\n<p>Here is an example of the infamous <strong>OpenAI GPT</strong> model, originally released as a poorly-trained model &#8211;so it would not be misused.  <a href=\"https://techcrunch.com/2019/02/17/openai-text-generator-dangerous/\">It was too dangerous to release <img src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f61b.png\" alt=\"😛\" class=\"wp-smiley\" style=\"height: 1em; max-height: 1em;\" /></a> We can compare this deficient GPT with the new and improved <strong>GPT2-small</strong> model, which has basically the same architecture, but has been trained as well as possible.  <a href=\"https://www.theverge.com/2019/11/7/20953040/openai-text-generation-ai-gpt-2-full-model-release-1-5b-parameters\">Yes, they gave in an released it! </a>  (Both are in the popular <code>huggingface</code> package, and <code>weightwatcher</code> can read and analyze these models)  Below, we plot a histogram of the PL exponents <img src=\"https://s0.wp.com/latex.php?latex=%28%5Calpha%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%28%5Calpha%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28%5Calpha%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"(&#92;alpha)\" class=\"latex\" />, as well as histogram of the log Spectral Norms <img src=\"https://s0.wp.com/latex.php?latex=%28%5Clog%5CVert%5Cmathbf%7BW%7D%5CVert_%7Binfty%7D+%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%28%5Clog%5CVert%5Cmathbf%7BW%7D%5CVert_%7Binfty%7D+%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28%5Clog%5CVert%5Cmathbf%7BW%7D%5CVert_%7Binfty%7D+%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"(&#92;log&#92;Vert&#92;mathbf{W}&#92;Vert_{infty} )\" class=\"latex\" /> for each layer in GPT (blue) and GPT2 (red)</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" data-attachment-id=\"13683\" data-permalink=\"https://calculatedcontent.com/2020/02/16/weightwatcher-empirical-quality-metrics-for-deep-neural-networks/screen-shot-2020-02-15-at-10-50-16-am/\" data-orig-file=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-15-at-10.50.16-am.png\" data-orig-size=\"1934,1140\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"Screen Shot 2020-02-15 at 10.50.16 AM\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-15-at-10.50.16-am.png?w=300\" data-large-file=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-15-at-10.50.16-am.png?w=1024\" src=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-15-at-10.50.16-am.png?w=840\" alt=\"\" class=\"wp-image-13683\" width=\"521\" height=\"306\" srcset=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-15-at-10.50.16-am.png?w=519 519w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-15-at-10.50.16-am.png?w=1038 1038w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-15-at-10.50.16-am.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-15-at-10.50.16-am.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-15-at-10.50.16-am.png?w=768 768w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-15-at-10.50.16-am.png?w=1024 1024w\" sizes=\"(max-width: 521px) 100vw, 521px\" /></figure></div>\n\n\n<p>These results can be reproduced using the WeightWatcher-OpenAI-GPT.ipynb notebook in the <a href=\"https://github.com/CalculatedContent/ww-trends-2020\">ww-trends-2020 github repo</a>.</p>\n\n\n\n<p>Notice that the poorly-trained GPT model has many unusually high values of <strong>alpha</strong> <img src=\"https://s0.wp.com/latex.php?latex=%28%5Calpha%5Cgg+6%29+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%28%5Calpha%5Cgg+6%29+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28%5Calpha%5Cgg+6%29+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"(&#92;alpha&#92;gg 6) \" class=\"latex\" />. Many are be above 6, and even range upto 10 or 12 ! This is typical of poorly trained and/or overparameterized models.</p>\n\n\n\n<p>Notice that the new and improved GPT2-small does not have the unusually high PL exponents any more, and, also, the peak of the histogram distribtion is farther to the left (smaller).<strong>  </strong></p>\n\n\n\n<p class=\"has-text-align-center\"><strong>Smaller <strong>alpha</strong> <img src=\"https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;alpha\" class=\"latex\" />  is always better.</strong></p>\n\n\n\n<p>If you have a poorly trained model. and  you fix your model by adding more and better data, the <strong>alphas</strong> will generally settle down to below 6. Note: this can not be seen in a total average because the large values will throw the average off&#8211;to see this, make a histogram plot of <strong>alpha</strong></p>\n\n\n\n<p>What about the log Spectral Norm <img src=\"https://s0.wp.com/latex.php?latex=%5Clog%5CVert%5Cmathbf%7BW%7D%5CVert_%7B%5Cinfty%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Clog%5CVert%5Cmathbf%7BW%7D%5CVert_%7B%5Cinfty%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clog%5CVert%5Cmathbf%7BW%7D%5CVert_%7B%5Cinfty%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;log&#92;Vert&#92;mathbf{W}&#92;Vert_{&#92;infty}\" class=\"latex\" /> ?  It seems to show inconsistent behavior. Above, we saw that smaller <img src=\"https://s0.wp.com/latex.php?latex=%5Clog%5CVert%5Cmathbf%7BW%7D%5CVert_%7B%5Cinfty%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Clog%5CVert%5Cmathbf%7BW%7D%5CVert_%7B%5Cinfty%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clog%5CVert%5Cmathbf%7BW%7D%5CVert_%7B%5Cinfty%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;log&#92;Vert&#92;mathbf{W}&#92;Vert_{&#92;infty}\" class=\"latex\" /> is better.  But now it looks as if smaller <img src=\"https://s0.wp.com/latex.php?latex=%5Clog%5CVert%5Cmathbf%7BW%7D%5CVert_%7B%5Cinfty%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Clog%5CVert%5Cmathbf%7BW%7D%5CVert_%7B%5Cinfty%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clog%5CVert%5Cmathbf%7BW%7D%5CVert_%7B%5Cinfty%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;log&#92;Vert&#92;mathbf{W}&#92;Vert_{&#92;infty}\" class=\"latex\" /> is worse ?  What is going on with this&#8230;and the other empirical Norm metrics ?  </p>\n\n\n\n<p>Now let&#8217;s take a deeper look at how to use the empirical log Norm metrics:</p>\n\n\n\n<h4>Norm Metrics:  <img src=\"https://s0.wp.com/latex.php?latex=%5CVert%5Cmathbf%7BW%7D%5CVert_%7BF%7D%2C+%5CVert%5Cmathbf%7BW%7D%5CVert_%7B%5Cinfty%7D%2C%5CVert%5Cmathbf%7BX%7D%5CVert%5E%7B%5Calpha%7D_%7B%5Calpha%7D%2C+...+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5CVert%5Cmathbf%7BW%7D%5CVert_%7BF%7D%2C+%5CVert%5Cmathbf%7BW%7D%5CVert_%7B%5Cinfty%7D%2C%5CVert%5Cmathbf%7BX%7D%5CVert%5E%7B%5Calpha%7D_%7B%5Calpha%7D%2C+...+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5CVert%5Cmathbf%7BW%7D%5CVert_%7BF%7D%2C+%5CVert%5Cmathbf%7BW%7D%5CVert_%7B%5Cinfty%7D%2C%5CVert%5Cmathbf%7BX%7D%5CVert%5E%7B%5Calpha%7D_%7B%5Calpha%7D%2C+...+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;Vert&#92;mathbf{W}&#92;Vert_{F}, &#92;Vert&#92;mathbf{W}&#92;Vert_{&#92;infty},&#92;Vert&#92;mathbf{X}&#92;Vert^{&#92;alpha}_{&#92;alpha}, ... \" class=\"latex\" /></h4>\n\n\n\n<p>Unlike the PL exponent <strong>alpha</strong>, the empirical Norm metrics depend strongly on the <em>scale of the weight matrix</em> <strong>W</strong>.  As such, they are highly sensitive to problems like <em>Scale Collapse</em>&#8211;and examining these metrics can tell us when something is potentially very wrong with our models.</p>\n\n\n\n<p>First, what are we looking at ?  These empirical (log) Norm metrics reported are defined using the raw eigenvalues. We can compute the eigenvalues of <strong>X</strong> pretty easily (although actually in the code we compute the singular values of <strong>W</strong> using the sklearn TruncatedSVD&nbsp;method.)</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: python; title: ; notranslate\">\nM = np.min(W.shape)\nsvd = TruncatedSVD(n_components=M-1)\nsvd.fit(W)\nsv = svd.singular_values_\neigen_values = sv*sv\n</pre></div>\n\n\n<p>Recall that the Frobenius norm (squared) for matrix <strong>W</strong> is also the  sum of the eigenvalues of <strong>X</strong>.  The Spectral Norm (squared) is just the maximum eigenvalue <img src=\"https://s0.wp.com/latex.php?latex=%5Clambda%5E%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Clambda%5E%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda%5E%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;lambda^{max}\" class=\"latex\" /> of <strong>X</strong>.   The weighted alpha <img src=\"https://s0.wp.com/latex.php?latex=%5Chat%7B%5Calpha%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Chat%7B%5Calpha%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Chat%7B%5Calpha%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;hat{&#92;alpha}\" class=\"latex\" /> and  the log <img src=\"https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;alpha\" class=\"latex\" /> (or Shatten) Norm  are computed after fitting the PL exponent <img src=\"https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;alpha\" class=\"latex\" /> for the layer.  In math, these are:</p>\n\n\n\n<div class=\"is-layout-flow wp-block-group\"><div class=\"wp-block-group__inner-container\">\n<ul>\n<li><strong>lognorm</strong>: <img src=\"https://s0.wp.com/latex.php?latex=%5Clog%5CVert%5Cmathbf%7BW%7D%5CVert_%7BF%7D%3D%5Cfrac%7B1%7D%7B2%7D%5Clog%5Csum_%7Bl%7D%5Clambda_%7Bl%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Clog%5CVert%5Cmathbf%7BW%7D%5CVert_%7BF%7D%3D%5Cfrac%7B1%7D%7B2%7D%5Clog%5Csum_%7Bl%7D%5Clambda_%7Bl%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clog%5CVert%5Cmathbf%7BW%7D%5CVert_%7BF%7D%3D%5Cfrac%7B1%7D%7B2%7D%5Clog%5Csum_%7Bl%7D%5Clambda_%7Bl%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;log&#92;Vert&#92;mathbf{W}&#92;Vert_{F}=&#92;frac{1}{2}&#92;log&#92;sum_{l}&#92;lambda_{l}\" class=\"latex\" /></li>\n\n\n\n<li><strong>logspectralnorm</strong>: <img src=\"https://s0.wp.com/latex.php?latex=%5Clog%5CVert%5Cmathbf%7BW%7D%5CVert_%7B%5Cinfty%7D%3D%5Cfrac%7B1%7D%7B2%7D%5Clog%5Clambda%5E%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Clog%5CVert%5Cmathbf%7BW%7D%5CVert_%7B%5Cinfty%7D%3D%5Cfrac%7B1%7D%7B2%7D%5Clog%5Clambda%5E%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clog%5CVert%5Cmathbf%7BW%7D%5CVert_%7B%5Cinfty%7D%3D%5Cfrac%7B1%7D%7B2%7D%5Clog%5Clambda%5E%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;log&#92;Vert&#92;mathbf{W}&#92;Vert_{&#92;infty}=&#92;frac{1}{2}&#92;log&#92;lambda^{max}\" class=\"latex\" /></li>\n\n\n\n<li><strong>alpha_weighted:</strong>    <img src=\"https://s0.wp.com/latex.php?latex=%5Chat%7B%5Calpha%7D%3D%5Calpha%5Clog%5Clambda%5E%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Chat%7B%5Calpha%7D%3D%5Calpha%5Clog%5Clambda%5E%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Chat%7B%5Calpha%7D%3D%5Calpha%5Clog%5Clambda%5E%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;hat{&#92;alpha}=&#92;alpha&#92;log&#92;lambda^{max}\" class=\"latex\" /></li>\n\n\n\n<li><strong>logpnorm:</strong> <img src=\"https://s0.wp.com/latex.php?latex=%5Clog%5CVert%5Cmathbf%7BX%7D%5CVert%5E%7B%5Calpha%7D_%7B%5Calpha%7D%3D%5Clog%5Csum_%7Bl%7D%5Clambda_%7Bl%7D%5E%7B%5Calpha%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Clog%5CVert%5Cmathbf%7BX%7D%5CVert%5E%7B%5Calpha%7D_%7B%5Calpha%7D%3D%5Clog%5Csum_%7Bl%7D%5Clambda_%7Bl%7D%5E%7B%5Calpha%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clog%5CVert%5Cmathbf%7BX%7D%5CVert%5E%7B%5Calpha%7D_%7B%5Calpha%7D%3D%5Clog%5Csum_%7Bl%7D%5Clambda_%7Bl%7D%5E%7B%5Calpha%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;log&#92;Vert&#92;mathbf{X}&#92;Vert^{&#92;alpha}_{&#92;alpha}=&#92;log&#92;sum_{l}&#92;lambda_{l}^{&#92;alpha}\" class=\"latex\" /></li>\n</ul>\n</div></div>\n\n\n\n<p>The <code>weightwatcher</code> code computes the necessary eigenvalues, does the PowerLaw (PL) fits, and reports these, and other, empirical quality metrics, for you, both for the average (summary) and layer-by-layer (details) of each.  The details dataframe has many more metrics as well, but, for now we will focus on these four.   </p>\n\n\n\n<p> Now,  what can we do with them?  We are going to look at 3 ways to identify potential problems in a DNN, which can not be seen by just looking at the test accuracy</p>\n\n\n\n<div class=\"is-layout-flow wp-block-group\"><div class=\"wp-block-group__inner-container\">\n<ul>\n<li><strong>Correlation Flow</strong> : comparing different architectures</li>\n\n\n\n<li><strong>Alpha Spikes</strong> : Identifying overparameterized models</li>\n\n\n\n<li><strong>Scale Collapse</strong> : potential problems when distilling models</li>\n</ul>\n</div></div>\n\n\n\n<h4>Correlation Flow :  comparing different architectures</h4>\n\n\n\n<p>Using the <code>weighwatcher details dataframe</code>, we can plot the PL exponent <strong>alpha</strong> vs. the layer Id to get what is called a<em> Correlation Flow</em> plot:</p>\n\n\n\n<p>Let us do this, by comparing 3 common (pretrained) computer vision models: VGG, ResNet, and DenseNet.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" data-attachment-id=\"13755\" data-permalink=\"https://calculatedcontent.com/2020/02/16/weightwatcher-empirical-quality-metrics-for-deep-neural-networks/screen-shot-2020-02-16-at-1-06-12-pm/\" data-orig-file=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.06.12-pm.png\" data-orig-size=\"1818,1722\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"Screen Shot 2020-02-16 at 1.06.12 PM\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.06.12-pm.png?w=300\" data-large-file=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.06.12-pm.png?w=1024\" src=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.06.12-pm.png?w=840\" alt=\"\" class=\"wp-image-13755\" width=\"520\" height=\"491\" srcset=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.06.12-pm.png?w=1037 1037w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.06.12-pm.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.06.12-pm.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.06.12-pm.png?w=768 768w\" sizes=\"(max-width: 520px) 100vw, 520px\" /></figure></div>\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" data-attachment-id=\"13752\" data-permalink=\"https://calculatedcontent.com/2020/02/16/weightwatcher-empirical-quality-metrics-for-deep-neural-networks/screen-shot-2020-02-16-at-12-00-03-pm/\" data-orig-file=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-12.00.03-pm.png\" data-orig-size=\"2304,572\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"Screen Shot 2020-02-16 at 12.00.03 PM\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-12.00.03-pm.png?w=300\" data-large-file=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-12.00.03-pm.png?w=1024\" src=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-12.00.03-pm.png?w=840\" alt=\"\" class=\"wp-image-13752\" width=\"635\" height=\"157\" srcset=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-12.00.03-pm.png?w=632 632w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-12.00.03-pm.png?w=1265 1265w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-12.00.03-pm.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-12.00.03-pm.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-12.00.03-pm.png?w=768 768w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-12.00.03-pm.png?w=1024 1024w\" sizes=\"(max-width: 635px) 100vw, 635px\" /></figure></div>\n\n\n<p>These results can be reproduced using the following notebooks:</p>\n\n\n\n<ul>\n<li><a href=\"https://github.com/CalculatedContent/ww-trends-2020/blob/master/WeightWatcher-VGG.ipynb\">WeightWatcher-VGG.ipynb</a></li>\n\n\n\n<li><a href=\"https://github.com/CalculatedContent/ww-trends-2020/blob/master/WeightWatcher-ResNet.ipynb\">WeightWatcher-ResNet.ipynb</a></li>\n\n\n\n<li><a href=\"https://github.com/CalculatedContent/ww-trends-2020/blob/master/WeightWatcher-DenseNet.ipynb\">WeightWatcher-DenseNet.ipynb</a></li>\n</ul>\n\n\n\n<p>Recall that good models have  average PL exponents <img src=\"https://s0.wp.com/latex.php?latex=%5Calpha%5Cin%5B2%2C4%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Calpha%5Cin%5B2%2C4%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha%5Cin%5B2%2C4%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;alpha&#92;in[2,4]\" class=\"latex\" />, in the Fat Tailed Universality class.  Likewise, we find  that, if we plot <strong>alpha</strong> vs layer_id, then good models also have stable <strong>alphas</strong>, in this range.  </p>\n\n\n\n<p>The VGG11 and 19 models have good <strong>alphas</strong>, all within the Fat Tailed Universality class, or smaller.  And both the smaller and larger models show similar behavior.  Also, noitce that the last 3 and FC layers in the VGG models all have final smaller <strong>alphas</strong>, <img src=\"https://s0.wp.com/latex.php?latex=%5Calpha%5Cin%5B2%2C3%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Calpha%5Cin%5B2%2C3%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha%5Cin%5B2%2C3%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;alpha&#92;in[2,3]\" class=\"latex\" />.  So while the <strong>alphas</strong> are increasing as we move down the model, the final FC layers seem to capture and concentrate the information, leading to more correlated layer weight matrices at the end.</p>\n\n\n\n<p>ResNet152 is an even better example of good Correlation Flow.   It has a large number of <strong>alphas</strong> near 2, contiguously, for over 200 layers.  Indeed, ResNet models have been trained with over 1000 layers; clearly the ResNet architecture supports a good flow of information.</p>\n\n\n\n<p>Good <em>Correlation Flow </em> shows that the DNN architecture is learning the correlations in the data at every layer, and implies (*informally) that  information is flowing smoothly through the network.</p>\n\n\n\n<p class=\"has-text-align-center\"><strong>Good DNNs show good Correlation Flow</strong></p>\n\n\n\n<p>We also find that models in an architecture series (VGG, ResNet, DenseNet, etc) all have similar Correlation Flow patterns, when adjusting for the model depth.</p>\n\n\n\n<p>Bad models, however, have <strong>alphas</strong> that increase with layer_id,  or behave erratically.  This means that the information is not flowing well through the network, and the final layers are not fully correlated.  For example, the older VGG models have <strong>alphas</strong> in a good range, <em><strong>but</strong></em>, as we go down the network, the <strong>alphas</strong> are systematically increasing.  The final FC layers fix the problem, although, maybe a few residual connections, like in ResNet, might improve these old models even more.</p>\n\n\n\n<p>You might think adding a lot of residual connections would improve  Correlation Flow&#8211;but too many connections is also bad.  The DenseNet series is an example of an architecture with too many residual connections.  Here, both with the pretrained DenseNet126 and 161 we see the many <img src=\"https://s0.wp.com/latex.php?latex=%5Calpha%5Cgg&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Calpha%5Cgg&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha%5Cgg&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;alpha&#92;gg\" class=\"latex\" />, and, looking down the network layers,  the are scattered all over.  The Correlation Flow is poor and even chaotic, and, we conjecture,  less than optimal.  </p>\n\n\n\n<p class=\"has-text-align-left\">Curiously, the ResNet models show good flow internally, as shown when we zoom-in, in (d) above. But the last few layers have unusually large <strong>alphas</strong>; we will discuss this phenomena now.</p>\n\n\n\n<p><strong>Advice</strong>: If you are training or finetuning a DNN model for production use, use <code>weightwatcher</code> to plot the Correlation Flow.  If you see alphas increasing with depth, behaving chaotically, or there are just a lot of alphas >> 6, revisit your architecture and training procedures.  </p>\n\n\n\n<h4> Alpha Spikes : Identifying overparameterized models</h4>\n\n\n\n<p class=\"has-text-align-center\"><em>When is a DNN is over-parameterized, once trained on some data ?</em></p>\n\n\n\n<p>Easy&#8230;just look at <strong>alphas</strong>.  We have found that well-trained, or perhaps fully-trained, models, should have <img src=\"https://s0.wp.com/latex.php?latex=%5Calpha%5Cin%5B2%2C4%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Calpha%5Cin%5B2%2C4%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha%5Cin%5B2%2C4%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;alpha&#92;in[2,4]\" class=\"latex\" />.  And the best CV models have most of their <strong>alphas</strong> just above 2.0.  However, some models, such as NLP OpenAI GPT2 and BERT models, have a wider <img src=\"https://s0.wp.com/latex.php?latex=%5Calpha%5Cin%5B2%2C6%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Calpha%5Cin%5B2%2C6%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha%5Cin%5B2%2C6%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;alpha&#92;in[2,6]\" class=\"latex\" />.  And many models have several unusually large <strong>alphas</strong>, with latex \\alpha\\gg 6$.  What is going on ?  And how is it useful ?</p>\n\n\n\n<p>The current batch of NLP Transformer models are great examples. We suspect that many models, like BERT and GPT-xl,  are over-parameterized, and that to fully use them in production, they need to be fine-tuned.  Indeed, that is the whole point of these models; NLP transfer learning.</p>\n\n\n\n<p>Let&#8217;s take a look the current crop of pretrained OpenAI GPT-2 models, provided by the <code>huggingface</code> package.   We call these &#8220;good-better-best&#8221; series.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" data-attachment-id=\"13760\" data-permalink=\"https://calculatedcontent.com/2020/02/16/weightwatcher-empirical-quality-metrics-for-deep-neural-networks/screen-shot-2020-02-16-at-1-53-23-pm/\" data-orig-file=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.53.23-pm.png\" data-orig-size=\"1752,720\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"Screen Shot 2020-02-16 at 1.53.23 PM\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.53.23-pm.png?w=300\" data-large-file=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.53.23-pm.png?w=1024\" src=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.53.23-pm.png?w=840\" alt=\"\" class=\"wp-image-13760\" width=\"587\" height=\"241\" srcset=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.53.23-pm.png?w=587 587w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.53.23-pm.png?w=1174 1174w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.53.23-pm.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.53.23-pm.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.53.23-pm.png?w=768 768w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.53.23-pm.png?w=1024 1024w\" sizes=\"(max-width: 587px) 100vw, 587px\" /></figure></div>\n\n\n<figure class=\"wp-block-image size-large is-resized\"><img loading=\"lazy\" data-attachment-id=\"13759\" data-permalink=\"https://calculatedcontent.com/2020/02/16/weightwatcher-empirical-quality-metrics-for-deep-neural-networks/screen-shot-2020-02-16-at-1-53-26-pm/\" data-orig-file=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.53.26-pm.png\" data-orig-size=\"2502,262\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"Screen Shot 2020-02-16 at 1.53.26 PM\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.53.26-pm.png?w=300\" data-large-file=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.53.26-pm.png?w=1024\" src=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.53.26-pm.png?w=840\" alt=\"\" class=\"wp-image-13759\" width=\"681\" height=\"70\" srcset=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.53.26-pm.png?w=668 668w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.53.26-pm.png?w=1337 1337w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.53.26-pm.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.53.26-pm.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.53.26-pm.png?w=768 768w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.53.26-pm.png?w=1024 1024w\" sizes=\"(max-width: 681px) 100vw, 681px\" /></figure>\n\n\n\n<p>These results can be reproduced using the <a href=\"https://github.com/CalculatedContent/ww-trends-2020/blob/master/WeightWatcher-OpenAI-GPT2.ipynb\">WeightWatcher-OpenAI-GPT2.ipynb</a> notebook.</p>\n\n\n\n<p>For both the PL exponent (a) and our Log Alpha Norm (b) , <em>Smaller is Better.  </em>The latest and greatest <a href=\"https://openai.com/blog/gpt-2-1-5b-release/\">OpenAI GPT2-xl </a>model (in red) has both smaller <strong>alphas</strong> and smaller empirical log norm metrics, compared to the earlier GP2-large (orange) and GPT2-medium (green) models.  </p>\n\n\n\n<p>But the GPT2-xl model also has more outlier <strong>alphas</strong>: <img src=\"https://s0.wp.com/latex.php?latex=%5Calpha%5Cgg+6&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Calpha%5Cgg+6&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha%5Cgg+6&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;alpha&#92;gg 6\" class=\"latex\" /></p>\n\n\n\n<p>We have seen similar behavior in other NLP models, such as comparing OpenAI GPT to GPT2-small, and the original BERT, as compared to the Distilled Bert (as discussed in <a href=\"https://www.youtube.com/watch?v=PQUItQi-B-I\">my recent Stanford Lecture</a>).  We suspect that when these large NLP Trasnformer models are fine-tuned or distilled, the <strong>alphas</strong> will get smaller, and performance will improve.    </p>\n\n\n\n<p><strong>Advice</strong>: So when you fine-tune your models, monitor the <strong>alphas</strong> with <code>weightwatcher</code>.    If they do not decrease enough, add more data, and/or try to improve the training protocols.</p>\n\n\n\n<p>But you also have to be careful not to break your model, as have found that some distillation methods may do this.</p>\n\n\n\n<h4>Scale Collapse : When Models Go Bad</h4>\n\n\n\n<p>Frequently one may finetune a model, for transfer learning, distillation, or just to add more data.  </p>\n\n\n\n<p class=\"has-text-align-center\"><em>How can we know if we broke the model ?</em></p>\n\n\n\n<p>We have found that poorly trained models frequently exhibit Scale Collapse, in which 1 or more layers have unusually small Spectral and/or Frobenius Norms.    </p>\n\n\n\n<p>This can be seen in your models by running plotting a histogram of the <strong>logspectralnorm</strong> column from the <code>details dataframe</code></p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"alignleft size-large is-resized\"><img loading=\"lazy\" data-attachment-id=\"13775\" data-permalink=\"https://calculatedcontent.com/scale-collapse-1/\" data-orig-file=\"https://charlesmartin14.files.wordpress.com/2020/02/scale-collapse-1.png\" data-orig-size=\"960,720\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"scale-collapse-1\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://charlesmartin14.files.wordpress.com/2020/02/scale-collapse-1.png?w=300\" data-large-file=\"https://charlesmartin14.files.wordpress.com/2020/02/scale-collapse-1.png?w=960\" src=\"https://charlesmartin14.files.wordpress.com/2020/02/scale-collapse-1.png?w=960\" alt=\"\" class=\"wp-image-13775\" width=\"373\" height=\"280\" srcset=\"https://charlesmartin14.files.wordpress.com/2020/02/scale-collapse-1.png?w=373 373w, https://charlesmartin14.files.wordpress.com/2020/02/scale-collapse-1.png?w=746 746w, https://charlesmartin14.files.wordpress.com/2020/02/scale-collapse-1.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2020/02/scale-collapse-1.png?w=300 300w\" sizes=\"(max-width: 373px) 100vw, 373px\" /></figure></div>\n\n\n<p class=\"has-text-align-left\">Recall earlier we noted the poorly-trained in the OpenAI GPT model. This is typical of many porly-trained models.  Because of this, log norm metrics can not be reliable used to predict trends in accuracies on poorly-trained models. </p>\n\n\n\n<p class=\"has-text-align-left\">However, we can use the empirical log Norm metrics to detect problems that can not be seen by simply looking at the training and test accuracies.</p>\n\n\n\n<h4>Distillation may break models: be careful out there</h4>\n\n\n\n<p>We have also observed this in some distilled models.  Below we look at the ResNet20 model, before and after distillation using the Group Regularization method (as described in the <a href=\"https://github.com/NervanaSystems/distiller\">Intel distiller package</a> and provided in the <a href=\"https://nervanasystems.github.io/distiller/model_zoo.html\">model zoo</a>).  We plot the Spectral Norm (maximum eigenvalue) and PL exponent alpha vs. the layer_id (depth) for both the baseline (green) and finetuned /distiller (red) ResNet20 models.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-large\"><img data-attachment-id=\"13777\" data-permalink=\"https://calculatedcontent.com/screen-shot-2020-02-16-at-4-33-46-pm/\" data-orig-file=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-4.33.46-pm.png\" data-orig-size=\"1678,888\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"screen-shot-2020-02-16-at-4.33.46-pm\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-4.33.46-pm.png?w=300\" data-large-file=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-4.33.46-pm.png?w=1024\" src=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-4.33.46-pm.png?w=1024\" alt=\"\" class=\"wp-image-13777\" srcset=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-4.33.46-pm.png?w=1024 1024w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-4.33.46-pm.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-4.33.46-pm.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-4.33.46-pm.png?w=768 768w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-4.33.46-pm.png 1678w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" /></figure></div>\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" data-attachment-id=\"13778\" data-permalink=\"https://calculatedcontent.com/screen-shot-2020-02-16-at-4-33-50-pm/\" data-orig-file=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-4.33.50-pm.png\" data-orig-size=\"2482,368\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"screen-shot-2020-02-16-at-4.33.50-pm\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-4.33.50-pm.png?w=300\" data-large-file=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-4.33.50-pm.png?w=1024\" src=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-4.33.50-pm.png?w=1024\" alt=\"\" class=\"wp-image-13778\" width=\"644\" height=\"96\" srcset=\"https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-4.33.50-pm.png?w=1024 1024w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-4.33.50-pm.png?w=644 644w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-4.33.50-pm.png?w=1288 1288w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-4.33.50-pm.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-4.33.50-pm.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-4.33.50-pm.png?w=768 768w\" sizes=\"(max-width: 644px) 100vw, 644px\" /></figure></div>\n\n\n<p>These results can be reproduced by installing the distiller package, downloading the model zoo pretrained models, and running the <a href=\"https://github.com/CalculatedContent/ww-trends-2020/blob/master/distiller/WeightWatcher-Intel-Distiller-ResNet20.ipynb\">WeightWatcher-Intel-Distiller-ResNet20.ipynb</a> notebook in the distiller folder. <small>(We do note that these are older results, and we used older versions of both <code>distiller</code> and <code>weighwatcher</code>, which used a different normalization on the Conv2D layers.  Current results may differ although we expect to see similar trends.)</small></p>\n\n\n\n<p>Notice that the baseline and finetuned ResNet20 have similar PL exponents (b) for all layers, but for several layers in (a), the Spectral Norm (maximum eigenvalue) collapses in value. That is, the <em>Scale Collapse</em>s.  This is bad, and characteristic of a poorly trained model like the original GPT.  </p>\n\n\n\n<p><strong>Advice</strong>: if you finetune a model, use <code>weighwatcher</code> to monitor the <strong>log Spectral Norms</strong>.  If you see unusually small values, something is wrong.</p>\n\n\n\n<h2>Learn More about the WeightWatcher tool</h2>\n\n\n\n<p><a href=\"https://arxiv.org/pdf/2002.06716.pdf\">Our latest paper</a> is now on archive.</p>\n\n\n\n<p>Please check out the <a href=\"https://github.com/CalculatedContent/WeightWatcher\">github webpage for WeightWatcher </a>and the associated papers and online talks at Stanford, UC Berkeley, and the wonderful podcasts that have invited us on to speak about the work.</p>\n\n\n\n<p></p>\n\n\n\n<p>If you want to get more involved, reach out to me directly at <em>charles@calculationconsulting.com</em></p>\n\n\n\n<p>And remember&#8211;if you need help at your company with AI, Deep learning, and Machine Learning, please reach out.    <a href=\"https://calculationconsulting.com/\">Calculation Consulting</a></p>\n\n\n\n<p></p>\n",
  "wfw:commentRss": "https://calculatedcontent.com/2020/02/16/weightwatcher-empirical-quality-metrics-for-deep-neural-networks/feed/",
  "slash:comments": 0,
  "media:thumbnail": "",
  "media:content": [
    {
      "media:title": "WeightWatcher Metrics"
    },
    {
      "media:title": "charlesmartin14"
    },
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    ""
  ]
}