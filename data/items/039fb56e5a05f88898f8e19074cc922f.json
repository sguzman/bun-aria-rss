{
  "title": "Leveraging Domain Features for Detecting Adversarial Attacks Against Deep Speech Recognition in Noise. (arXiv:2211.01621v1 [eess.AS])",
  "link": "http://arxiv.org/abs/2211.01621",
  "description": "<p>In recent years, significant progress has been made in deep model-based\nautomatic speech recognition (ASR), leading to its widespread deployment in the\nreal world. At the same time, adversarial attacks against deep ASR systems are\nhighly successful. Various methods have been proposed to defend ASR systems\nfrom these attacks. However, existing classification based methods focus on the\ndesign of deep learning models while lacking exploration of domain specific\nfeatures. This work leverages filter bank-based features to better capture the\ncharacteristics of attacks for improved detection. Furthermore, the paper\nanalyses the potentials of using speech and non-speech parts separately in\ndetecting adversarial attacks. In the end, considering adverse environments\nwhere ASR systems may be deployed, we study the impact of acoustic noise of\nvarious types and signal-to-noise ratios. Extensive experiments show that the\ninverse filter bank features generally perform better in both clean and noisy\nenvironments, the detection is effective using either speech or non-speech\npart, and the acoustic noise can largely degrade the detection performance.\n</p>",
  "dc:creator": "<a href=\"http://arxiv.org/find/eess/1/au:+Nielsen_C/0/1/0/all/0/1\">Christian Heider Nielsen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tan_Z/0/1/0/all/0/1\">Zheng-Hua Tan</a>"
}