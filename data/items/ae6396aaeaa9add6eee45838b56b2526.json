{
  "title": "Getting Started With OmniSci, Part 1: Docker Install and Loading Data",
  "description": "<p>It’s been nearly five years since I wrote about <a href=\"http://localhost:4000/big-data-hadoop-amazon-ec2-cloudera-part-1/\">Getting Started with Hadoop</a> for big data. In those years, there have been incremental improvements in columnar file formats and dramatic computation speed improvements with Apache Spark, but I still wouldn’t call the Hadoop ecosystem convenient for actual data <em>analysis</em>.  During this same time period, thanks to <a href=\"https://developer.nvidia.com/\">NVIDIA</a> and their <a href=\"https://devblogs.nvidia.com/even-easier-introduction-cuda/\">CUDA library</a> for general-purpose calculations on GPUs, graphics cards went from enabling visuals on a computer to enabling massively-parallel calculations as well.</p>",
  "pubDate": "Thu, 01 Feb 2018 00:00:00 +0000",
  "link": "http://randyzwitch.com/mapd-install-load-data/",
  "guid": "http://randyzwitch.com/mapd-install-load-data/",
  "content": "<p>It’s been nearly five years since I wrote about <a href=\"http://localhost:4000/big-data-hadoop-amazon-ec2-cloudera-part-1/\">Getting Started with Hadoop</a> for big data. In those years, there have been incremental improvements in columnar file formats and dramatic computation speed improvements with Apache Spark, but I still wouldn’t call the Hadoop ecosystem convenient for actual data <em>analysis</em>.  During this same time period, thanks to <a href=\"https://developer.nvidia.com/\">NVIDIA</a> and their <a href=\"https://devblogs.nvidia.com/even-easier-introduction-cuda/\">CUDA library</a> for general-purpose calculations on GPUs, graphics cards went from enabling visuals on a computer to enabling massively-parallel calculations as well.</p>\n\n<p>Building upon CUDA is <a href=\"https://www.omnisci.com/\">MapD</a>, an analytics platform that allows for super-fast SQL queries and interactive visualizations. In this blog post, I’ll show how to use Docker to install <a href=\"https://www.omnisci.com/blog/2017/05/08/mapd-open-sources-gpu-powered-database/\">MapD Community Edition</a> and load <a href=\"http://www.pjm.com/markets-and-operations/ops-analysis/historical-load-data.aspx\">hourly electricity demand</a> data to analyze.</p>\n\n<h2 id=\"installing-mapd-ce-using-dockernvidia-docker\">Installing MapD CE using Docker/nvidia-docker</h2>\n\n<p>While CUDA makes it <em>possible</em> to do calculations on GPUs, I wouldn’t go as far as to say it is easy, including just getting everything installed! Luckily, there is Docker and <a href=\"https://devblogs.nvidia.com/nvidia-docker-gpu-server-application-deployment-made-easy/\">nvidia-docker</a>, which provide all-in-one <em>containers</em> with all necessary drivers and libraries installed to build upon. MapD provides instructions for installing <a href=\"https://www.mapd.com/docs/latest/getting-started/docker-gpu-ce-recipe/\">MapD CE using nvidia-docker</a>, with the main installation command as follows:</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-bash\" data-lang=\"bash\"><table class=\"rouge-table\"><tbody><tr><td class=\"gutter gl\"><pre class=\"lineno\">1\n2\n3\n4\n5\n</pre></td><td class=\"code\"><pre><span class=\"c\">##nvidia-docker version 2</span>\ndocker run <span class=\"nt\">--runtime</span><span class=\"o\">=</span>nvidia <span class=\"se\">\\</span>\n<span class=\"nt\">-v</span> <span class=\"nv\">$HOME</span>/mapd-docker-storage:/mapd-storage <span class=\"se\">\\</span>\n<span class=\"nt\">-p</span> 9090-9092:9090-9092 <span class=\"se\">\\</span>\nmapd/mapd-ce-cuda\n</pre></td></tr></tbody></table></code></pre></figure>\n\n<p>When you kickoff this command (I’m using a ssh terminal into a <a href=\"http://randyzwitch.com/building-data-science-workstation-2017/\">remote Ubuntu desktop</a>), Docker will download all the required images from the <code class=\"language-plaintext highlighter-rouge\">mapd/mapd-ce-cuda</code>repository and start a background process for the MapD database and the Immerse visualization interface/web server:</p>\n\n<p><img src=\"/assets/img/docker-dl-images.png\" alt=\"docker images\" /></p>\n\n<p>Once all of the images are downloaded, you can find the container that was created using <code class=\"language-plaintext highlighter-rouge\">docker container ls</code>, then run <code class=\"language-plaintext highlighter-rouge\">docker exec -it &lt;container id&gt; bash</code> to start the container and drop you into a Bash shell (on the container). From this point, MapD Community Edition will be running!</p>\n\n<p><img src=\"/assets/img/docker-container-ls.png\" alt=\"docker ls\" /></p>\n\n<h2 id=\"loading-data-using-the-immerse-interface\">Loading Data Using the Immerse Interface</h2>\n\n<p>Once the Bash shell opens in the terminal, you can now interact with MapD via the Docker container. However, for beginning exploration, it’s much simpler to use the Immerse Web Interface at <code class=\"language-plaintext highlighter-rouge\">localhost:9092</code>:</p>\n\n<p><img src=\"/assets/img/mapd-immerse.png\" alt=\"mapd immerse\" /></p>\n\n<p>Uploading data via the Data Manager interface is reasonably performant for smaller files; a test file with four columns and million or so rows loaded in a few seconds (dependent on your upload speed, obviously):</p>\n\n<p><img src=\"/assets/img/mapd-import-table.png\" alt=\"mapd data manager\" /></p>\n\n<p>Edit the column names and types if you want (the CSV reader gets it right for me most of the time). Then, once the ‘Save Table’ button is clicked, MapD will import the CSV data into a columnar binary format, so that the GPU can operate directly on the data rather than reading from the CSV each query.</p>\n\n<h2 id=\"loading-data-using-the-command-line\">Loading Data Using the Command Line</h2>\n\n<p>While browser GUIs are great for some things, I’m still very much a command-line guy, at least for things like loading data. MapD provides the <code class=\"language-plaintext highlighter-rouge\">mapdql</code> interface to load data and query, very much like psql for Postgres and other databases. To load my 4.9 million * 4 column dataset, I used the following commands:</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-bash\" data-lang=\"bash\"><table class=\"rouge-table\"><tbody><tr><td class=\"gutter gl\"><pre class=\"lineno\">1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n</pre></td><td class=\"code\"><pre><span class=\"nv\">$ </span>docker container <span class=\"nb\">ls\n</span>CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                              NAMES\n51be4b888448        mapd/mapd-ce-cuda   <span class=\"s2\">\"/bin/sh -c '/mapd/s…\"</span>   44 hours ago        Up 44 hours         0.0.0.0:9090-9092-&gt;9090-9092/tcp   nifty_heisenberg\n\n<span class=\"nv\">$ </span>docker <span class=\"nb\">exec</span> <span class=\"nt\">-it</span> 51be4b888448 bash\nroot@1f64b2dcc316:/mapd# bin/mapdql\nPassword: &lt;default is <span class=\"s2\">\"HyperInteractive\"</span><span class=\"o\">&gt;</span>\nUser mapd connected to database mapd\n\nmapdql&gt; create table hourly_loads<span class=\"o\">(</span>\n..&gt; ACTUAL_DATE DATE,\n..&gt; ZONE_NAME TEXT,\n..&gt; HOUR_ENDING SMALLINT,\n..&gt; MW FLOAT<span class=\"o\">)</span><span class=\"p\">;</span>\n\nmapdql&gt; copy hourly_loads from <span class=\"s1\">'hourly_loads.csv'</span><span class=\"p\">;</span>\nResult\nLoaded: 4898472 recs, Rejected: 0 recs <span class=\"k\">in </span>0.923000 secs\n</pre></td></tr></tbody></table></code></pre></figure>\n\n<p>The <a href=\"https://www.mapd.com/docs/latest/mapd-core-guide/data-definition/\">DDL</a> for MapD seems pretty much the same as every other database language. First you define a table’s columns and their types, then you can use the <code class=\"language-plaintext highlighter-rouge\">copy</code> command to load data from a CSV. The statement that prints upon success begins to give an indication of the speed MapD provides, loading nearly 5 million records in less than a second.</p>\n\n<h2 id=\"simplistic-query-performance\">Simplistic Query Performance</h2>\n\n<p>Up this point, I’ve intentionally not described the data I uploaded into MapD; in my next post, I’ll cover the dataset I’m using and how I converted the data from Excel spreadsheets into a CSV. But before ending this post, I wanted to show a brief summary of the performance of MapD:</p>\n\n<p><img src=\"/assets/img/mapd-query-speed.png\" alt=\"mapd query speed\" /></p>\n\n<p>The first query shows a simple record count by the <code class=\"language-plaintext highlighter-rouge\">hour_ending</code> dimension in my table, something you might run if you weren’t too familiar with the table. You’ll notice that running this <code class=\"language-plaintext highlighter-rouge\">group by</code> across the 5 million row dataset took 5143ms, which isn’t so fast. What’s going on?</p>\n\n<p>Because this is the first query from a cold start, MapD needs to load data into GPU RAM. So while the first query takes a few seconds, the second query displays a <em>warmed-up</em> level of performance: 212ms to scan 5 million rows, filter by a few values of the <code class=\"language-plaintext highlighter-rouge\">zone_name</code> column, then grouping by <code class=\"language-plaintext highlighter-rouge\">hour_ending</code>. For reference, a <a href=\"https://sciencing.com/fast-blink-eye-5199669.html\">human blink takes 100-400 ms</a>, so this second query quite literally finished in the blink of an eye…</p>\n\n<h2 id=\"dashboards-streaming-data-and-more\">Dashboards, Streaming Data and more…</h2>\n\n<p>This first blog post just scratched the surface on what is possible using just the Community Edition of MapD. In future blog posts, I will provide the code to create the dataset, do some basic descriptive statistics, and even do some analysis and dashboarding of historical electricity demand.</p>\n\n<p><strong>Update, 2/1/2018 4:49 p.m.</strong></p>\n\n<p>Per Todd Mostak from MapD, the second query would likely even run faster than 212ms, had I run it again:</p>\n\n<blockquote class=\"twitter-tweet\" data-conversation=\"none\" data-cards=\"hidden\" data-partner=\"tweetdeck\"><p lang=\"en\" dir=\"ltr\">Also fyi that 212ms query will likely run faster if you run it again (even changing the literals). MapD compiles queries the first time it sees a new query plan but then can reuse the same compiled code if you change literals (like for zone_name).</p>&mdash; Todd Mostak (@ToddMostak) <a href=\"https://twitter.com/ToddMostak/status/959181487848525824?ref_src=twsrc%5Etfw\">February 1, 2018</a></blockquote>\n<script async=\"\" src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>"
}