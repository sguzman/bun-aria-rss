{
  "title": "Configuration Driven Machine Learning Pipelines",
  "description": "<style>\nfigure figcaption {\n    text-align: center;\n}\n</style>\n\n<p>At Stitch Fix, data scientists have great autonomy to iterate on and improve \nour customer’s experience. They do this by regularly training, retraining, \nand deploying a diverse fleet of machine learning models that each play a \nvital role in Stitch Fix’s business. As a core component of the algorithms platform, \nthe Model Lifecycle team is responsible for enabling data science teams to scale, \nby streamlining the process of getting these models into production. \nIn <a href=\"https://multithreaded.stitchfix.com/blog/2022/07/14/deployment-for-free/\">our last post</a>, \nwe discussed the tooling we built that enables Data Scientists to deploy and monitor models with the push of a button. \nIn this post, we’re going to dive into how we improved the model training experience.</p>\n\n<h2 id=\"motivation\">Motivation</h2>\n\n<p>As we researched how data scientists built their models at Stitch Fix, a typical pattern emerged. We observed three distinct phases of model development:</p>\n\n<ol>\n  <li><em>Ideation</em>: The data scientist models a problem and iterates on potential solutions.</li>\n  <li><em>Workflow development</em>: The data scientist compiles the chosen solution into a production-ready framework. They:\n    <ol>\n      <li>Write modules that handle training, data loading, and training orchestration</li>\n      <li>Write a DAG in our abstraction on top of airflow to call these modules from within tasks and send data between them</li>\n      <li>Publish this workflow to production</li>\n    </ol>\n  </li>\n  <li><em>Workflow iteration</em>: Issues regularly occur in production pipelines. To debug and fix, the data scientist will try to:\n    <ol>\n      <li>Execute the workflow in staging</li>\n      <li>Diagnose task failures from run logs</li>\n      <li>Fix and republish the workflow</li>\n      <li>Execute the workflow to demonstrate that the fix works by examining the production state</li>\n    </ol>\n  </li>\n</ol>\n\n<p><img src=\"/assets/posts/2022-08-02-config-driven-ml-pipelines/ds_workflow.png\" alt=\"Data Scientist Workflow\" /></p>\n\n<p>While analyzing these workflows, we found that the standard approach was <em>lacking</em> the following best practices:</p>\n\n<ol>\n  <li><strong>Configurability</strong>: Nothing in the above workflow guarantees that the code is configurable for further iteration.</li>\n  <li><strong>Separation of concerns</strong>: All the code (orchestration, infrastructure, data) in this approach is bundled together, making surgical changes messy and complicated.</li>\n  <li><strong><a href=\"https://en.wikipedia.org/wiki/Don%27t_repeat_yourself\">DRY</a> code</strong>: The logic to orchestrate training, building, and publishing workflows is repetitive in nature – \na lot of it can be factored out.</li>\n  <li><strong>Easy migrations</strong>: Good luck migrating an entirely custom codebase without any of the above properties!</li>\n</ol>\n\n<p>The system we built alleviates the concerns above, by providing a common framework for data scientists at Stitch Fix to develop and execute training pipelines.</p>\n\n<h2 id=\"design-goals\">Design goals</h2>\n\n<p>Keeping the above criterion in mind, we came up with the following design goals:</p>\n\n<ul>\n  <li><strong>Higher-level abstractions</strong>: When the data scientist is ideating, they should be able to build their workflow out of simple high-level abstractions\nsuch as <em>datasets</em>, <em>trainers</em> and <em>models</em>.</li>\n  <li><strong>Faster iteration</strong>: Developing models should be fast.</li>\n  <li><strong>Principled code organization</strong>: The code should be organized with a separation of concerns in mind. \nFor example, the code to train a model and the code to run inference over a dataset should be stored \nseparately (but be easy to reference).</li>\n  <li><strong>Operational simplicity</strong>: When underlying infrastructure or dependencies change, the data scientist should be able to migrate with little to no effort.</li>\n  <li><strong>Unified environments</strong>: A data scientist should be able to use the same code in production as they do when developing a model.</li>\n</ul>\n\n<h3 id=\"designing-for-stitch-fix\">Designing for Stitch Fix</h3>\n\n<p>Using our framework, data scientists at Stitch Fix have access to two high-level building blocks:</p>\n\n<ul>\n  <li><strong>Extracts</strong>: For generating features a model needs to train</li>\n  <li><strong>Trainer</strong>: For building the final trained model</li>\n</ul>\n\n<p>To train their models, data scientists need to simply implement the interfaces above and glue them together with some configuration files \n(details to come shortly). The framework we built takes care of the rest – orchestration, workflow compilation, and managing compute/scalability.</p>\n\n<h2 id=\"a-regression-example\">A regression example</h2>\n\n<p>To illustrate how the framework works, let’s walk through an example of a fairly simple workflow – training a linear regression model using <em>sklearn</em>. All these configurations reside in <code class=\"language-plaintext highlighter-rouge\">.yaml</code> files within a GitHub repository managed by the data scientist.</p>\n\n<h3 id=\"extract-configuration\">Extract configuration</h3>\n\n<p>Here we specify an extract by executing a <code class=\"language-plaintext highlighter-rouge\">SQL</code> script, located in a file templated with <a href=\"https://jinja.palletsprojects.com/en/3.1.x/\">jinja</a>. \nThe framework executes the query and stores the data in our internal data warehouse. \nThis is one of a variety of methods the framework provides to specify an extract.</p>\n\n<p>We name the below file <em>extract_inputs.yaml</em>:</p>\n\n<div class=\"language-yaml highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\"># to reference what this represents in another configuration,</span>\n<span class=\"c1\"># we need to point to this file and specify `training_data`.</span>\n<span class=\"na\">training_data</span><span class=\"pi\">:</span>\n  <span class=\"na\">operator</span><span class=\"pi\">:</span> <span class=\"s\">sql</span>\n  <span class=\"na\">sql_file</span><span class=\"pi\">:</span> <span class=\"s\">training_data.sql</span>\n  <span class=\"na\">kwargs</span><span class=\"pi\">:</span>\n    <span class=\"na\">limit</span><span class=\"pi\">:</span> <span class=\"m\">10000</span> <span class=\"c1\"># A parameter that gets injected into the .sql file</span>\n</code></pre></div></div>\n\n<h3 id=\"model-configuration\">Model configuration</h3>\n\n<p>Here, <code class=\"language-plaintext highlighter-rouge\">SKLearnLinearRegressionTrainer</code> is the trainer module that we want to orchestrate. The <code class=\"language-plaintext highlighter-rouge\">contructor_args</code> \nfor the trainer accept feature column names and hyperparameters (such as <code class=\"language-plaintext highlighter-rouge\">fit_intercept</code>) which are required for training the model.</p>\n\n<p>Finally, the dependencies section specifies the mapping between the extracted data and the trainer’s <code class=\"language-plaintext highlighter-rouge\">train</code> method.</p>\n\n<div class=\"language-yaml highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\"># required -- these end up as indexes in model envelope</span>\n<span class=\"na\">model_name</span><span class=\"pi\">:</span> <span class=\"s\">A regression model</span>\n<span class=\"na\">model_description</span><span class=\"pi\">:</span> <span class=\"s\">This is a sample linear regression model.</span>\n<span class=\"na\">tags</span><span class=\"pi\">:</span> <span class=\"c1\"># for integrating with model envelope indexing (see prior post)</span>\n  <span class=\"na\">canonical_name</span><span class=\"pi\">:</span> <span class=\"s\">sample_regression_model_v1</span>\n<span class=\"c1\"># model trainer to use</span>\n<span class=\"na\">model_trainer</span><span class=\"pi\">:</span> <span class=\"s\">sklearn.sklearn_linear.SKLearnLinearRegressionTrainer</span>\n<span class=\"na\">constructor_args</span><span class=\"pi\">:</span>\n  <span class=\"na\">fit_intercept</span><span class=\"pi\">:</span> <span class=\"s\">False</span>\n  <span class=\"na\">feature_columns</span><span class=\"pi\">:</span>\n    <span class=\"pi\">-</span> <span class=\"s\">x_0</span>\n    <span class=\"pi\">-</span> <span class=\"s\">x_1</span>\n    <span class=\"pi\">-</span> <span class=\"s\">x_2</span>\n  <span class=\"na\">target_label</span><span class=\"pi\">:</span> <span class=\"s\">y</span>\n\n<span class=\"c1\"># things that we want to happen before this model is trained</span>\n<span class=\"na\">dependencies</span><span class=\"pi\">:</span>\n  <span class=\"na\">data</span><span class=\"pi\">:</span>\n    <span class=\"pi\">-</span> <span class=\"na\">train_param_name</span><span class=\"pi\">:</span> <span class=\"s\">df</span>  <span class=\"c1\"># maps to the parameter in train()</span>\n      <span class=\"na\">file</span><span class=\"pi\">:</span> <span class=\"s\">extract_inputs.yaml</span>  <span class=\"c1\"># points to extract defined above</span>\n      <span class=\"na\">file_param_name</span><span class=\"pi\">:</span> <span class=\"s\">training_data</span>   <span class=\"c1\"># the variable within the extract file</span>\n</code></pre></div></div>\n\n<h3 id=\"the-trainer\">The trainer</h3>\n\n<p>The trainer implements the <code class=\"language-plaintext highlighter-rouge\">AbstractTrainer</code> interface. The <code class=\"language-plaintext highlighter-rouge\">train</code> method returns an object that encapsulates a model as a pure function, as well as \nother lifecycle methods such as <code class=\"language-plaintext highlighter-rouge\">evaluate</code>, which enables computation of metrics on the trained model.</p>\n\n<p>The beauty of using configurations here is that you can introduce new datasets and modify training hyperparameters without touching the trainer code.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">@</span><span class=\"n\">dataclass</span>\n<span class=\"k\">class</span> <span class=\"nc\">SKLearnLinearRegressionTrainer</span><span class=\"p\">(</span>\n    <span class=\"n\">AbstractTrainer</span><span class=\"p\">[</span><span class=\"n\">SKLearnLinearRegressionModel</span><span class=\"p\">]</span>\n<span class=\"p\">):</span>\n    <span class=\"c1\"># Note that these constructor parameters correspond to those passed in the file above\n</span>    <span class=\"n\">fit_intercept</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> \n    <span class=\"n\">feature_columns</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span>\n    <span class=\"n\">target_label</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s\">\"target\"</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">train</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">df</span><span class=\"p\">:</span> <span class=\"n\">pd</span><span class=\"p\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">TrainedObject</span><span class=\"p\">:</span>\n        <span class=\"c1\"># df maps to train_param_name in model configuration\n</span>        <span class=\"n\">regression_model</span> <span class=\"o\">=</span> <span class=\"n\">linear_model</span><span class=\"p\">.</span><span class=\"n\">LinearRegression</span><span class=\"p\">(</span>\n            <span class=\"n\">fit_intercept</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">fit_intercept</span><span class=\"p\">,</span>\n            <span class=\"n\">normalize</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">normalize</span><span class=\"p\">,</span>\n            <span class=\"n\">n_jobs</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">n_jobs</span><span class=\"p\">,</span>\n        <span class=\"p\">)</span>\n        <span class=\"n\">features</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">feature_columns</span><span class=\"p\">]</span>\n        <span class=\"n\">regression_model</span><span class=\"p\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">features</span><span class=\"p\">,</span> <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">target_label</span><span class=\"p\">])</span>\n        <span class=\"c1\"># the wrapper model containing the state\n</span>        <span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">SKLearnLinearRegressionModel</span><span class=\"p\">(</span>\n            <span class=\"n\">model</span><span class=\"o\">=</span><span class=\"n\">regression_model</span><span class=\"p\">,</span>\n            <span class=\"n\">feature_columns</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">feature_columns</span><span class=\"p\">,</span>\n            <span class=\"n\">target_label</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">target_label</span><span class=\"p\">,</span>\n        <span class=\"p\">)</span>\n        <span class=\"c1\"># return the wrapper model that will be stored to the model store\n</span>        <span class=\"k\">return</span> <span class=\"n\">TrainedObject</span><span class=\"p\">(</span>\n            <span class=\"n\">model</span><span class=\"p\">,</span>\n            <span class=\"c1\"># We use the following parameters to derive the model's signature\n</span>            <span class=\"n\">sample_input_data</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s\">\"x\"</span><span class=\"p\">:</span> <span class=\"n\">features</span><span class=\"p\">},</span>\n            <span class=\"n\">sample_output_data</span><span class=\"o\">=</span><span class=\"n\">model</span><span class=\"p\">.</span><span class=\"n\">predict</span><span class=\"p\">(</span><span class=\"n\">features</span><span class=\"p\">),</span>\n            <span class=\"n\">method</span><span class=\"o\">=</span><span class=\"s\">\"predict\"</span><span class=\"p\">,</span>\n        <span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">evaluate</span><span class=\"p\">(</span>\n        <span class=\"bp\">self</span><span class=\"p\">,</span>\n        <span class=\"n\">model</span><span class=\"p\">:</span> <span class=\"n\">SKLearnLinearRegressionModel</span><span class=\"p\">,</span>\n        <span class=\"n\">df</span><span class=\"p\">:</span> <span class=\"n\">pd</span><span class=\"p\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">,</span>\n        <span class=\"c1\"># Evaluate is passed the trained model from the previous step\n</span>    <span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Any</span><span class=\"p\">]:</span>\n        <span class=\"n\">df_predicted</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"p\">.</span><span class=\"n\">predict</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">[</span><span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">feature_columns</span><span class=\"p\">])</span>\n        <span class=\"n\">mean_squared_error</span> <span class=\"o\">=</span> <span class=\"n\">metrics</span><span class=\"p\">.</span><span class=\"n\">mean_squared_error</span><span class=\"p\">(</span>\n            <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">target_label</span><span class=\"p\">],</span> <span class=\"n\">df_predicted</span>\n        <span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"p\">{</span><span class=\"s\">'mean_squared_error'</span> <span class=\"p\">:</span> <span class=\"n\">mean_squared_error</span><span class=\"p\">}</span>\n</code></pre></div></div>\n\n<h3 id=\"the-model\">The model</h3>\n\n<p>The model is a simple wrapper over a model’s functionality. \nIt is the only component that gets saved to the model store.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">@</span><span class=\"n\">dataclass</span>\n<span class=\"k\">class</span> <span class=\"nc\">SKLearnLinearRegressionModel</span><span class=\"p\">:</span>\n    <span class=\"n\">model</span><span class=\"p\">:</span> <span class=\"n\">linear_model</span><span class=\"p\">.</span><span class=\"n\">LinearRegression</span>\n    <span class=\"n\">feature_columns</span><span class=\"p\">:</span> <span class=\"n\">typing</span><span class=\"p\">.</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span>\n    <span class=\"n\">target_label</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s\">\"target\"</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">predict</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">pd</span><span class=\"p\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">pd</span><span class=\"p\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">:</span>\n        <span class=\"n\">predicted</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">model</span><span class=\"p\">.</span><span class=\"n\">predict</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"n\">pd</span><span class=\"p\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">(</span><span class=\"n\">predicted</span><span class=\"p\">,</span> <span class=\"n\">columns</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">target_label</span><span class=\"p\">])</span>\n\n</code></pre></div></div>\n\n<h2 id=\"iterating-locally\">Iterating locally</h2>\n\n<p>The pipelines can be iterated on locally using a <a href=\"https://dash.plotly.com/\">dash</a> application that launches and renders the execution graph. The datasets are cached to allow for sampling and exploration. Changes to the trainer’s implementation can be made on the fly and tested by stepping through trainer execution.</p>\n\n<p><br /></p>\n<figure>\n<img src=\"/assets/posts/2022-08-02-config-driven-ml-pipelines/local_iteration_ui.png\" alt=\"local iteration ui\" width=\"100%\" />\n<figcaption>The first version of the local iteration UI</figcaption>\n</figure>\n\n<h2 id=\"behind-the-scenes\">Behind the scenes</h2>\n\n<p>We transform the <code class=\"language-plaintext highlighter-rouge\">YAML</code> files the user provides into an intermediate representation as a <a href=\"https://en.wikipedia.org/wiki/Directed_acyclic_graph\">directed acyclic graph</a>, which we then compile \nto Stitch Fix’s internal airflow-based orchestration system. \nThis provides an additional layer of abstraction, while enabling us to leverage the \nawesome set of operators that other platform teams build.</p>\n\n<p>The intermediate layer of abstraction gives us the ability to do the following without a data scientist’s involvement.</p>\n\n<ol>\n  <li><strong>Migrate seamlessly</strong>: Since we control the translation layer, we can make necessary changes to the underlying infrastructure. A simple republish will migrate the code base for the data scientist.</li>\n  <li><strong>Switch backends</strong>: If we find a better orchestration solution than airflow, we can easily switch to it.</li>\n  <li><strong>Swap orchestration strategies</strong>: Since data scientists conform to the trainer interface and we control orchestration, we can implement a variety of orchestration strategies for training (see below).</li>\n</ol>\n\n<h2 id=\"the-goodies\">The goodies</h2>\n\n<p>With the <em>trainer</em> and <em>extract</em> abstractions, we can enable different orchestration strategies without touching the trainer code.</p>\n\n<p>We provide the following orchestration strategies out of the box:</p>\n\n<ol>\n  <li><strong>Tuning</strong>: By adding a configuration with the parameter space to explore, the framework will conduct a search through hyperparameter space to tune the model. \nWe support <code class=\"language-plaintext highlighter-rouge\">Guassian Process</code> and <code class=\"language-plaintext highlighter-rouge\">Grid Search</code> tuning strategies.\n    <div class=\"language-yaml highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code> <span class=\"na\">model</span><span class=\"pi\">:</span> <span class=\"s\">model_linear_regression.yaml</span>\n <span class=\"na\">environment</span><span class=\"pi\">:</span>\n   <span class=\"na\">memory</span><span class=\"pi\">:</span> <span class=\"m\">2000</span>\n   <span class=\"na\">cpu</span><span class=\"pi\">:</span> <span class=\"m\">2000</span>\n <span class=\"na\">n_function_compute_workers</span><span class=\"pi\">:</span> <span class=\"m\">4</span>\n <span class=\"na\">tuning_type</span><span class=\"pi\">:</span> <span class=\"s\">grid</span>\n <span class=\"na\">param_boundaries</span><span class=\"pi\">:</span>\n   <span class=\"na\">alpha</span><span class=\"pi\">:</span>\n     <span class=\"pi\">-</span> <span class=\"m\">0.1</span>\n     <span class=\"pi\">-</span> <span class=\"m\">0.8</span>\n     <span class=\"pi\">-</span> <span class=\"m\">0.1</span> <span class=\"c1\">#step size only valid for tuning_type grid </span>\n   <span class=\"na\">max_iter</span><span class=\"pi\">:</span>\n     <span class=\"pi\">-</span> <span class=\"m\">10</span>\n     <span class=\"pi\">-</span> <span class=\"m\">50</span>\n     <span class=\"pi\">-</span> <span class=\"m\">10</span> <span class=\"c1\">#step size only valid for tuning_type grid</span>\n</code></pre></div>    </div>\n    <p><br /></p>\n\n    <figure>\n<img src=\"/assets/posts/2022-08-02-config-driven-ml-pipelines/tuning_regression.png\" alt=\"Effect of hyperparameter values on loss\" style=\"width:100%\" />\n<figcaption>The effect of changing hyperparameters on the loss value of a model. <em>max_iter</em> has no impact on model performance, \nwhereas <em>alpha</em> is correlated.</figcaption>   </figure>\n  </li>\n  <li><strong>Backtesting</strong>: By choosing a data splitting strategy, a user can see how their model performs on unseen data.<br />\n In the snippet below in the <em>model.yaml</em> file:\n    <ul>\n      <li>You pick the strategy as <em>sliding_time_window</em> .</li>\n      <li><em>days_backward</em> represents the length of data to look at.</li>\n      <li>The data splits will slide over the window above by 2 days.</li>\n      <li><em>train_size</em> represents the size of each training window.</li>\n      <li><em>test_size</em> represents the size of testing window.</li>\n    </ul>\n\n    <div class=\"language-yaml highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code> <span class=\"na\">split_config</span><span class=\"pi\">:</span>\n   <span class=\"na\">train_param_name</span><span class=\"pi\">:</span> <span class=\"s\">df</span>\n   <span class=\"na\">strategy</span><span class=\"pi\">:</span> <span class=\"s\">sliding_time_window</span>\n   <span class=\"na\">days_backward</span><span class=\"pi\">:</span> <span class=\"m\">60</span>\n   <span class=\"na\">train_size</span><span class=\"pi\">:</span>\n     <span class=\"na\">days</span><span class=\"pi\">:</span> <span class=\"m\">10</span>\n   <span class=\"na\">test_size</span><span class=\"pi\">:</span>\n     <span class=\"na\">days</span><span class=\"pi\">:</span> <span class=\"m\">5</span>\n   <span class=\"na\">slide_by</span><span class=\"pi\">:</span>\n     <span class=\"na\">days</span><span class=\"pi\">:</span> <span class=\"m\">2</span>\n</code></pre></div>    </div>\n\n    <p>Training models at various time periods allows you to measure how accurate your model is at different points of time.\nAnd one can examine the performance of these strategies on a per metric basis.</p>\n\n    <p><br /></p>\n    <figure>\n<img src=\"/assets/posts/2022-08-02-config-driven-ml-pipelines/backtest.png\" alt=\"training window splits vs loss values\" style=\"width:100%\" />\n<figcaption>Window size for training/testing (left) juxtaposed with corresponding evaluation metrics (right)\n</figcaption>\n</figure>\n  </li>\n</ol>\n\n<h2 id=\"looking-onward\">Looking onward</h2>\n\n<p>We’ve made a lot of progress, but still have a ways to go. We’re currently working on:</p>\n\n<ul>\n  <li><strong>Model and dataset observability</strong>: Dataset and model performance monitoring, both at training and at inference time</li>\n  <li><strong>Pytorch lightning support</strong>: Auto-logging of metrics along with custom PyTorch data loaders</li>\n</ul>\n\n<h2 id=\"adoption\">Adoption</h2>\n\n<p>With configuration-driven pipelines, we have unencumbered the data scientists by enabling them to focus on doing what they do best; training models. The reception within Stitch Fix tells the story for itself – we have over 68 workflows running using our system. These were created by 30 data scientists and regularly train and retrain 200+ distinct production models, including those powering Stitch Fix’s core recommendation stack.</p>\n\n<h2 id=\"some-parting-thoughts\">Some parting thoughts</h2>\n\n<p>As the machine learning platform team, we measure success in our ability to boost data scientist productivity. \nBy building higher-level abstractions that reduce the cognitive surface area for data scientists, \nwe have managed to improve the onboarding experience while simultaneously empowering platform teams to run a tighter ship on deployed models.</p>\n\n<p>We discussed our training framework here – this is but one of the tools that streamline model development. We have also written about:</p>\n\n<ul>\n  <li><a href=\"https://multithreaded.stitchfix.com/blog/2022/02/22/scaling-hamilton/\">Hamilton</a> (open source!): For managing dataflows</li>\n  <li><a href=\"https://multithreaded.stitchfix.com/blog/2022/07/14/deployment-for-free/\">Model Envelope</a>: For getting the models we train into production</li>\n</ul>\n\n<p>These tools would be impossible without the incredible set of platform tooling Stitch fix has already built – we would be remiss if we did not acknowledge the giants,\non whose shoulders we stand. For more details, check out articles on our home-built \n<a href=\"https://multithreaded.stitchfix.com/blog/2019/07/30/building-centralized-experimental-platform/\">experimentation platform</a>, \n<a href=\"https://multithreaded.stitchfix.com/blog/2020/05/06/metametastore/\">data warehouse</a>, \nand <a href=\"https://multithreaded.stitchfix.com/blog/2018/09/05/datahighway/\">kafka tooling</a>.</p>",
  "pubDate": "Tue, 02 Aug 2022 09:00:00 +0000",
  "link": "https://multithreaded.stitchfix.com/blog/2022/08/02/configuration-driven-ml-pipelines/",
  "guid": "https://multithreaded.stitchfix.com/blog/2022/08/02/configuration-driven-ml-pipelines/"
}