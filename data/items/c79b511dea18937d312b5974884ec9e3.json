{
  "title": "Analyzing Sharpness along GD Trajectory: Progressive Sharpening and Edge of Stability. (arXiv:2207.12678v2 [cs.LG] UPDATED)",
  "link": "http://arxiv.org/abs/2207.12678",
  "description": "<p>Recent findings (e.g., <a href=\"/abs/2103.00065\">arXiv:2103.00065</a>) demonstrate that modern neural\nnetworks trained by full-batch gradient descent typically enter a regime called\nEdge of Stability (EOS). In this regime, the sharpness, i.e., the maximum\nHessian eigenvalue, first increases to the value 2/(step size) (the progressive\nsharpening phase) and then oscillates around this value (the EOS phase). This\npaper aims to analyze the GD dynamics and the sharpness along the optimization\ntrajectory. Our analysis naturally divides the GD trajectory into four phases\ndepending on the change of the sharpness. We empirically identify the norm of\noutput layer weight as an interesting indicator of sharpness dynamics. Based on\nthis empirical observation, we attempt to theoretically and empirically explain\nthe dynamics of various key quantities that lead to the change of sharpness in\neach phase of EOS. Moreover, based on certain assumptions, we provide a\ntheoretical proof of the sharpness behavior in EOS regime in two-layer\nfully-connected linear neural networks. We also discuss some other empirical\nfindings and the limitation of our theoretical results.\n</p>",
  "dc:creator": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhouzi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zixuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jian Li</a>"
}