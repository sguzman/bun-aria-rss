{
  "title": "MXNet baseline model for iNaturalist Challenge at FGVC 2017 competition",
  "link": "https://no2147483647.wordpress.com/2017/06/16/mxnet-baseline-model-for-inaturalist-challenge-at-fgvc-2017-competition/",
  "comments": "https://no2147483647.wordpress.com/2017/06/16/mxnet-baseline-model-for-inaturalist-challenge-at-fgvc-2017-competition/#respond",
  "dc:creator": "phunterlau",
  "pubDate": "Fri, 16 Jun 2017 01:44:42 +0000",
  "category": [
    "Machine Learning",
    "deep learning",
    "mxnet"
  ],
  "guid": "http://no2147483647.wordpress.com/?p=304",
  "description": "I have prepared for a baseline model using MXNet for iNaturalist Challenge at FGVC 2017 competition on Kaggle. Github link is https://github.com/phunterlau/iNaturalist the public LB score is 0.117. Please follow this discussion thread https://www.kaggle.com/c/inaturalist-challenge-at-fgvc-2017/discussion/34514 if any questions. How to use Install MXNet Run pip install mxnet-cu80 after installing CUDA driver or go to https://github.com/dmlc/mxnet/ for the latest version from [&#8230;]",
  "content:encoded": "<p>I have prepared for a baseline model using MXNet for iNaturalist Challenge at FGVC 2017 competition on Kaggle. Github link is <a href=\"https://github.com/phunterlau/iNaturalist\">https://github.com/phunterlau/iNaturalist</a> the public LB score is 0.117. Please follow this discussion thread <a href=\"https://www.kaggle.com/c/inaturalist-challenge-at-fgvc-2017/discussion/34514\">https://www.kaggle.com/c/inaturalist-challenge-at-fgvc-2017/discussion/34514</a> if any questions.</p>\n<h2>How to use</h2>\n<h3><a id=\"user-content-install-mxnet\" class=\"anchor\" href=\"https://github.com/phunterlau/iNaturalist#install-mxnet\"></a>Install MXNet</h3>\n<p>Run <code>pip install mxnet-cu80</code> after installing CUDA driver or go to <a href=\"https://github.com/dmlc/mxnet/\">https://github.com/dmlc/mxnet/</a> for the latest version from Github.</p>\n<p>Windows users? no CUDA 8.0? no GPU? Please run <code>pip search mxnet</code> and find the good package for your platform.</p>\n<h3><a id=\"user-content-generate-lists\" class=\"anchor\" href=\"https://github.com/phunterlau/iNaturalist#generate-lists\"></a>Generate lists</h3>\n<p>After downloading and unzipping the train and test set in to <code>data</code>, along with the necessary <code>.json</code> annotation files, run <code>python mx_list.py</code> under <code>data</code> and generate <code>train.lst</code> <code>val.lst</code> <code>test.lst</code></p>\n<h3><a id=\"user-content-generate-rec-files\" class=\"anchor\" href=\"https://github.com/phunterlau/iNaturalist#generate-rec-files\"></a>Generate rec files</h3>\n<p>A good way to speed up training is maximizing the IO by using <code>.rec</code> format, which also provides convenience of data augmentation. In the <code>data/</code> directory, <code>gen_rec.sh</code> can generate <code>train.rec</code> and <code>val.rec</code> for the train and validate datasets, and <code>im2rec.py</code> can be obtained from MXNet repo <a href=\"https://github.com/dmlc/mxnet/tree/master/tools\">https://github.com/dmlc/mxnet/tree/master/tools</a> . One can adjust <code>--quality 95</code> parameter to lower quality for saving disk space, but it may take risk of loosing training precision.</p>\n<h3><a id=\"user-content-train\" class=\"anchor\" href=\"https://github.com/phunterlau/iNaturalist#train\"></a>Train</h3>\n<p>Run <code>sh run.sh</code> which looks like (a 4 GTX 1080 machine for example):</p>\n<pre><code>python fine-tune.py --pretrained-model model/resnet-152 \\\n    --load-epoch 0 --gpus 0,1,2,3 \\\n    --model-prefix model/iNat-resnet-152 \\\n\t--data-nthreads 48 \\\n    --batch-size 48 --num-classes 5089 --num-examples 579184\n</code></pre>\n<p>please adjust <code>--gpus</code> and <code>--batch-size</code> according to the machine configuration. A sample calculation: <code>batch-size = 12</code> can use 8 GB memory on a GTX 1080, so <code>--batch-size 48</code> is good for a 4-GPU machine.</p>\n<p>Please have internet connection for the first time run because needs to download the pretrained model from <a href=\"http://data.mxnet.io/models/imagenet-11k/resnet-152/\">http://data.mxnet.io/models/imagenet-11k/resnet-152/</a>. If the machine has no internet connection, please download the corresponding model files from other machines, and ship to <code>model/</code> directory.</p>\n<h3><a id=\"user-content-generate-submission-file\" class=\"anchor\" href=\"https://github.com/phunterlau/iNaturalist#generate-submission-file\"></a>Generate submission file</h3>\n<p>After a long run of some epochs, e.g. 30 epochs, we can select some epochs for the submission file. Run <code>sub.py</code>which two parameters : <code>num of epoch</code> and <code>gpu id</code> like:</p>\n<pre><code>python sub.py 21 0\n</code></pre>\n<p>selects the 21st epoch and infer on GPU <code>#0</code>. One can merge multiple epoch results on different GPUs and ensemble for a good submission file.</p>\n<h2><a id=\"user-content-how-fine-tune-works\" class=\"anchor\" href=\"https://github.com/phunterlau/iNaturalist#how-fine-tune-works\"></a>How &#8216;fine-tune&#8217; works</h2>\n<p>Fine-tune method starts with loading a pretrained ResNet 152 layers (Imagenet 11k classes) from MXNet model zoo, where the model has gained some prediction power, and applies the new data by learning from provided data.</p>\n<p>The key technique is from <code>lr_step_epochs</code> where we assign a small learning rate and less regularizations when approach to certain epochs. In this example, we give <code>lr_step_epochs='10,20'</code> which means the learning rate changes slower when approach to 10th and 20th epoch, so the fine-tune procedure can converge the network and learn from the provided new samples. A similar thought is applied to the data augmentations where fine tune is given less augmentation. This technique is described in Mu&#8217;s thesis <a href=\"http://www.cs.cmu.edu/~muli/file/mu-thesis.pdf\">http://www.cs.cmu.edu/~muli/file/mu-thesis.pdf</a></p>\n<p>This pipeline is not limited to ResNet-152 pretrained model. Please experiment the fine tune method with other models, like ResNet 101, Inception, from MXNet&#8217;s model zoo <a href=\"http://data.mxnet.io/models/\">http://data.mxnet.io/models/</a> by following this tutorial <a href=\"http://mxnet.io/how_to/finetune.html\">http://mxnet.io/how_to/finetune.html</a> and this sample code <a href=\"https://github.com/dmlc/mxnet/blob/master/example/image-classification/fine-tune.py\">https://github.com/dmlc/mxnet/blob/master/example/image-classification/fine-tune.py</a> . Please feel free submit issues and/or pull requests and/or discuss on the Kaggle forum if have better results.</p>\n<h2><a id=\"user-content-reference\" class=\"anchor\" href=\"https://github.com/phunterlau/iNaturalist#reference\"></a>Reference</h2>\n<ul>\n<li>MXNet&#8217;s model zoo <a href=\"http://data.mxnet.io/models/\">http://data.mxnet.io/models/</a></li>\n<li>MXNet fine tune <a href=\"http://mxnet.io/how_to/finetune.html\">http://mxnet.io/how_to/finetune.html</a><a href=\"https://github.com/dmlc/mxnet/blob/master/example/image-classification/fine-tune.py\">https://github.com/dmlc/mxnet/blob/master/example/image-classification/fine-tune.py</a></li>\n<li>Mu Li&#8217;s thesis <a href=\"http://www.cs.cmu.edu/~muli/file/mu-thesis.pdf\">http://www.cs.cmu.edu/~muli/file/mu-thesis.pdf</a></li>\n<li>iNaturalist Challenge at FGVC 2017 <a href=\"https://www.kaggle.com/c/inaturalist-challenge-at-fgvc-2017/\">https://www.kaggle.com/c/inaturalist-challenge-at-fgvc-2017/</a></li>\n</ul>\n",
  "wfw:commentRss": "https://no2147483647.wordpress.com/2017/06/16/mxnet-baseline-model-for-inaturalist-challenge-at-fgvc-2017-competition/feed/",
  "slash:comments": 0,
  "media:content": {
    "media:title": "phunterlau"
  }
}