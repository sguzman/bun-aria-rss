{
  "title": "On the Adversarial Robustness of Vision Transformers. (arXiv:2103.15670v3 [cs.CV] UPDATED)",
  "link": "http://arxiv.org/abs/2103.15670",
  "description": "<p>Following the success in advancing natural language processing and\nunderstanding, transformers are expected to bring revolutionary changes to\ncomputer vision. This work provides a comprehensive study on the robustness of\nvision transformers (ViTs) against adversarial perturbations. Tested on various\nwhite-box and transfer attack settings, we find that ViTs possess better\nadversarial robustness when compared with MLP-Mixer and convolutional neural\nnetworks (CNNs) including ConvNeXt, and this observation also holds for\ncertified robustness. Through frequency analysis and feature visualization, we\nsummarize the following main observations contributing to the improved\nrobustness of ViTs: 1) Features learned by ViTs contain less high-frequency\npatterns that have spurious correlation, which helps explain why ViTs are less\nsensitive to high-frequency perturbations than CNNs and MLP-Mixer, and there is\na high correlation between how much the model learns high-frequency features\nand its robustness against different frequency-based perturbations. 2)\nIntroducing convolutional or tokens-to-token blocks for learning high-frequency\nfeatures in ViTs can improve classification accuracy but at the cost of\nadversarial robustness. 3) Modern CNN designs that borrow techniques from ViTs\nincluding activation function, layer norm, larger kernel size to imitate the\nglobal attention, and patchify the images as inputs, etc., could help bridge\nthe performance gap between ViTs and CNNs not only in terms of performance, but\nalso certified and empirical adversarial robustness. Moreover, we show\nadversarial training is also applicable to ViT for training robust models, and\nsharpness-aware minimization can also help improve robustness, while\npre-training with clean images on larger datasets does not significantly\nimprove adversarial robustness.\n</p>",
  "dc:creator": "<a href=\"http://arxiv.org/find/cs/1/au:+Shao_R/0/1/0/all/0/1\">Rulin Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1\">Zhouxing Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_J/0/1/0/all/0/1\">Jinfeng Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1\">Pin-Yu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1\">Cho-Jui Hsieh</a>"
}