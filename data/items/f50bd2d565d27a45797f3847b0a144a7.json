{
  "id": "tag:blogger.com,1999:blog-15418143.post-1716021431567432061",
  "published": "2015-05-06T12:16:00.000-05:00",
  "updated": "2016-06-13T07:42:56.512-05:00",
  "category": [
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    ""
  ],
  "title": "Dyson 360 Eye and Baidu Deep Learning at the Embedded Vision Summit in Santa Clara",
  "content": "<h3><b>Bringing Computer Vision to the Consumer</b></h3><div><span style=\"font-size: x-small;\">Mike Aldred</span></div><div><span style=\"font-size: x-small;\">Electronics Lead, Dyson Ltd</span></div><div><br /></div><div>While vision has been a research priority for decades, the results have often remained out of reach of the consumer. Huge strides have been made, but the final, and perhaps toughest, hurdle is how to integrate vision into real world products. It’s a long road from concept to finished machine, and to succeed, companies need clear objectives, a robust test plan, and the ability to adapt when those fail.&nbsp;</div><div class=\"separator\" style=\"clear: both; text-align: center;\"><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://2.bp.blogspot.com/-xKfSvJf2BOY/VUo6zsl2WKI/AAAAAAAAOGk/97yv4YuXzdk/s1600/dyson-360-eye-front1.jpg\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" height=\"197\" src=\"https://2.bp.blogspot.com/-xKfSvJf2BOY/VUo6zsl2WKI/AAAAAAAAOGk/97yv4YuXzdk/s320/dyson-360-eye-front1.jpg\" width=\"320\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\">Image from ExtremeTech:&nbsp;<a href=\"http://www.extremetech.com/extreme/189240-dyson-360-eye-dysons-truly-intelligent-robotic-vacuum-cleaner-is-finally-here\">Dyson 360 Eye: Dyson’s ‘truly intelligent’ robotic vacuum cleaner is finally here</a></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><br /></div><div><br /></div><div>The <a href=\"https://www.dyson360eye.com/\">Dyson 360 Eye robot vacuum cleaner</a> uses computer vision as its primary localization technology. 10 years in the making, it was taken from bleeding edge academic research to a robust, reliable and manufacturable solution by Mike Aldred and his team at Dyson.&nbsp;</div><div><br /></div><div>Mike Aldred’s keynote at next week's <a href=\"http://www.embedded-vision.com/summit/highlights/speakers\">Embedded Vision Summit</a> (May 12th in Santa Clara) will chart some of the high and lows of the project, the challenges of bridging between academia and business, and how to use a diverse team to take an idea from the lab into real homes.</div><div><br /></div><h3><b>Enabling Ubiquitous Visual Intelligence Through Deep Learning</b></h3><div><span style=\"font-size: x-small;\">Ren Wu&nbsp;</span></div><div><span style=\"font-size: x-small;\">Distinguished Scientist, Baidu Institute of Deep Learning</span></div><div><br /></div><div>Deep learning techniques have been making headlines lately in computer vision research. Using techniques inspired by the human brain, deep learning employs massive replication of simple algorithms which learn to distinguish objects through training on vast numbers of examples. Neural networks trained in this way are gaining the ability to recognize objects as accurately as humans. Some experts believe that deep learning will transform the field of vision, enabling the widespread deployment of visual intelligence in many types of systems and applications. But there are many practical problems to be solved before this goal can be reached. For example, how can we create the massive sets of real-world images required to train neural networks? And given their massive computational requirements, how can we deploy neural networks into applications like mobile and wearable devices with tight cost and power consumption constraints?&nbsp;</div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://2.bp.blogspot.com/-XxXCP2Vf_D8/VUpKAEqx4II/AAAAAAAAOHU/UOJVjMV-b3w/s1600/baidu-phone-image.png\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" height=\"319\" src=\"https://2.bp.blogspot.com/-XxXCP2Vf_D8/VUpKAEqx4II/AAAAAAAAOHU/UOJVjMV-b3w/s320/baidu-phone-image.png\" width=\"320\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><br /></div><div><br /></div><div>Ren Wu’s morning keynote at next week's&nbsp;<a href=\"http://www.embedded-vision.com/summit/highlights/speakers\">Embedded Vision Summit</a>&nbsp;(May 12th in Santa Clara)&nbsp;will share an insider’s perspective on these and other critical questions related to the practical use of neural networks for vision, based on the pioneering work being conducted by his team at Baidu.</div><div><br /></div><h3><b>Vision-as-a-Service: Democratization of Vision for Consumers and Businesses</b></h3><div><span style=\"font-size: x-small;\">Herman Yau</span></div><div><span style=\"font-size: x-small;\">Co-founder and CEO, Tend</span></div><div><br /></div><div>Hundreds of millions of video cameras are installed around the world—in businesses, homes, and public spaces—but most of them provide limited insights. Installing new, more intelligent cameras requires massive deployments with long time-to-market cycles. Computer vision enables us to extract meaning from video streams generated by existing cameras, creating value for consumers, businesses, and communities in the form of improved safety, quality, security, and health. But how can we bring computer vision to millions of deployed cameras? The answer is through “Vision-as-a-Service” (VaaS), a new business model that leverages the cloud to apply state-of-the-art computer vision techniques to video streams captured by inexpensive cameras. Centralizing vision processing in the cloud offers some compelling advantages, such as the ability to quickly deploy sophisticated new features without requiring upgrades of installed camera hardware. It also brings some tough challenges, such as scaling to bring intelligence to millions of cameras.&nbsp;</div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://3.bp.blogspot.com/-3-JR8IYNxM4/VUpKVAhXtDI/AAAAAAAAOHc/wax8UnHDVT0/s1600/300x300_TPO_February_PRM844_Distributed_Computing.jpg\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" src=\"https://3.bp.blogspot.com/-3-JR8IYNxM4/VUpKVAhXtDI/AAAAAAAAOHc/wax8UnHDVT0/s1600/300x300_TPO_February_PRM844_Distributed_Computing.jpg\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\">Image From&nbsp;<a href=\"http://www.techpageone.co.uk/en/technology/distributed-computing-three-best-use-cases/#.VUpKO9pViko\">Distributed Computing: Three Best-Use Cases</a></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><br /></div><div><br /></div><div><br /></div><div>Herman Yau's talk at next week's&nbsp;<a href=\"http://www.embedded-vision.com/summit/highlights/speakers\">Embedded Vision Summit</a>&nbsp;(May 12th in Santa Clara)&nbsp;will explain the architecture and business model behind VaaS, show how it is being deployed in a wide range of real-world use cases, and highlight some of the key challenges and how they can be overcome.</div><div><br /></div><div><b>Embedded Vision Summit on May 12th, 2015</b></div><div><br /></div><div>There will be many more great presentations at the upcoming Embedded Vision Summit. &nbsp;From the range of topics, it looks like any startup with interest in computer vision will be able to benefit from attending. The entire day is filled with talks by great presenters (Gary Bradski will talk about the latest developments in OpenCV). You can see the list of speakers:&nbsp;<a href=\"http://www.embedded-vision.com/summit/highlights/speakers\">Embedded Vision Summit 2015 List of speakers</a>&nbsp;or the day's agenda <a href=\"http://www.embedded-vision.com/summit/attend/agenda\">Embedded Vision Summit 2015 Agenda</a>.</div><div><br /></div><div><a href=\"http://www.embedded-vision.com/summit/attend/register\">Embedded Vision Summit 2015 Registration </a>(249$ for the one day event&nbsp;+ food)</div><div><br /></div><div><b>Demos during lunch:&nbsp;</b>The Technology Showcase at the Embedded Vision Summit will highlight demonstrations of technology for computer vision-based applications and systems from the following companies.</div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://3.bp.blogspot.com/-HOuzwOMkz-A/VUpC8QdxplI/AAAAAAAAOHE/QKZKvKS5Hb0/s1600/tech.png\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" height=\"315\" src=\"https://3.bp.blogspot.com/-HOuzwOMkz-A/VUpC8QdxplI/AAAAAAAAOHE/QKZKvKS5Hb0/s400/tech.png\" width=\"400\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><br /></div><div><br /></div><div>The vision topics covered will be: Deep Learning, CNNs, Business, Markets, Libraries, Standards, APIs, 3D Vision, and Processors. I will be there with my <a href=\"http://vision.ai/\">vision.ai</a> team, together with some computer vision guys from&nbsp;<a href=\"http://www.knithealth.com/\">KnitHealth, Inc</a>, a new SF-based Health Vision Company. If you're interested in meeting with us, let's chat at the Vision Summit.</div><div><br /></div><div>What kind of startups and companies should attend? Definitely robotics. Definitely vision sensors. Definitely those interested in deep learning hardware implementations. Seems like even half of the software engineers at Google could benefit from learning about their favorite deep learning algorithms being optimized for hardware.&nbsp;</div><div><br /><br /></div>",
  "link": [
    "",
    "",
    "",
    "",
    ""
  ],
  "author": {
    "name": "Tomasz Malisiewicz",
    "uri": "http://www.blogger.com/profile/17507234774392358321",
    "email": "noreply@blogger.com",
    "gd:image": ""
  },
  "media:thumbnail": "",
  "thr:total": 1
}