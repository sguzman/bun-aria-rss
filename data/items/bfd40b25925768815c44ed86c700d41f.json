{
  "title": "Fighting Deep Fakes",
  "itunes:title": "Fighting Deep Fakes",
  "pubDate": "Sat, 04 Aug 2018 03:25:50 GMT",
  "itunes:duration": "44:41",
  "enclosure": "",
  "guid": "f8731e6024c9498684070d8e3da0685e",
  "itunes:explicit": "no",
  "link": "https://shows.acast.com/lawfare/episodes/60518a63bd84d92f9a7e5768",
  "acast:episodeId": "60518a63bd84d92f9a7e5768",
  "acast:settings": "ozu8rXK33NzX6c6CybB5UOF04GhvlOgDa40P9ZFPAybvfyg0UxkGS28ZOgnOo+59hYWZ43P8iM2gznOgM5mBpsMAKCMa/C1B7LRWhJHIObkB4A9FVaPrr4xBHxLTFpyyb4hpsKc1k488zHrp4SG1XFK9UhJYayKi5nJ8nkehwGI=",
  "itunes:subtitle": "Episode 335",
  "itunes:episodeType": "full",
  "itunes:episode": 335,
  "description": "<p>Technologies that distort representations of reality, like audio, photo, and video editing software, are nothing new, but what happens when these technologies are paired with artificial intelligence to produce hyper-realistic media of things that never happened? This new phenomenon, called \"deep fakes,\" poses significant problems for lawyers, policymakers, and technologists. On July 19, Klon Kitchen, senior fellow for technology and national security at the Heritage Foundation, moderated a panel with Bobby Chesney of the University of Texas at Austin Law School, Danielle Citron of the University of Maryland Carey School of Law, and Chris Bregler, a senior computer scientist and AI manager at Google. They talked about how deep fakes work, why they don't fit into the current legal and policy thinking, and about how policy, technology, and the law can begin to combat them.</p><p>Support this show <a target=\"_blank\" rel=\"payment\" href=\"http://supporter.acast.com/lawfare\">http://supporter.acast.com/lawfare</a>.</p><br /><hr><p style='color:grey; font-size:0.75em;'> Hosted on Acast. See <a style='color:grey;' target='_blank' rel='noopener noreferrer' href='https://acast.com/privacy'>acast.com/privacy</a> for more information.</p>",
  "itunes:summary": "<p>Technologies that distort representations of reality, like audio, photo, and video editing software, are nothing new, but what happens when these technologies are paired with artificial intelligence to produce hyper-realistic media of things that never happened? This new phenomenon, called \"deep fakes,\" poses significant problems for lawyers, policymakers, and technologists. On July 19, Klon Kitchen, senior fellow for technology and national security at the Heritage Foundation, moderated a panel with Bobby Chesney of the University of Texas at Austin Law School, Danielle Citron of the University of Maryland Carey School of Law, and Chris Bregler, a senior computer scientist and AI manager at Google. They talked about how deep fakes work, why they don't fit into the current legal and policy thinking, and about how policy, technology, and the law can begin to combat them.</p><p>Support this show <a target=\"_blank\" rel=\"payment\" href=\"http://supporter.acast.com/lawfare\">http://supporter.acast.com/lawfare</a>.</p><br /><hr><p style='color:grey; font-size:0.75em;'> Hosted on Acast. See <a style='color:grey;' target='_blank' rel='noopener noreferrer' href='https://acast.com/privacy'>acast.com/privacy</a> for more information.</p>"
}