{
  "title": "Getting Started Using Hadoop, Part 2: Building a Cluster",
  "description": "<p>In <a title=\"Getting Started With Hadoop, Part 1\" href=\"http://randyzwitch.com/big-data-hadoop-amazon-ec2-cloudera-part-1/\" target=\"_blank\">Part 1 of this series</a>, I discussed some of the basic concepts around Hadoop, specifically when it’s appropriate to use Hadoop to solve your data engineering problems and the terminology of the Hadoop eco-system. This post will cover how to install your own Hadoop cluster on Amazon EC2 using Cloudera Manager.</p>",
  "pubDate": "Thu, 25 Apr 2013 17:33:48 +0000",
  "link": "http://randyzwitch.com/big-data-hadoop-amazon-ec2-cloudera-part-2/",
  "guid": "http://randyzwitch.com/big-data-hadoop-amazon-ec2-cloudera-part-2/",
  "content": "<p>In <a title=\"Getting Started With Hadoop, Part 1\" href=\"http://randyzwitch.com/big-data-hadoop-amazon-ec2-cloudera-part-1/\" target=\"_blank\">Part 1 of this series</a>, I discussed some of the basic concepts around Hadoop, specifically when it’s appropriate to use Hadoop to solve your data engineering problems and the terminology of the Hadoop eco-system. This post will cover how to install your own Hadoop cluster on Amazon EC2 using Cloudera Manager.</p>\n\n<p>Like prior posts talking about <a title=\"Amazon EC2 posts\" href=\"http://randyzwitch.com/tags/#amazon_ec2\" target=\"_blank\">Amazon EC2</a>, this post assumes you have some basic facility with Linux, submitting instructions via the command line, etc. Because really, if you’re interested in Hadoop, using the command line probably isn’t a limiting factor!</p>\n\n<h2 id=\"building-a-18-node-hadoop-cluster\">Building a 18-node Hadoop Cluster</h2>\n\n<p>The SlideShare presentation below shows the steps to building a 18-node Hadoop cluster, using a single <em>m1.large</em> EC2 instance as the ‘Name Node’ and 18 <em>m1.medium</em> EC2 instances as the ‘Data Nodes’.  I chose 18 nodes because according to <a title=\"Cloudera Manager Example\" href=\"http://blog.cloudera.com/blog/2013/03/how-to-create-a-cdh-cluster-on-amazon-ec2-via-cloudera-manager/\" target=\"_blank\">Cloudera</a>, 20 is the maximum that can be activated at one time through the Amazon API, so let’s stay under the max to avoid any errors. It’s possible to add more instances later through the Cloudera Manager (up to 50 total), if so desired.</p>\n\n<p>Note that going through this tutorial will cost $2.40/hr at current prices ($0.24/hr per <em>m1.large</em> instance and $0.12/hr per <em>m1.medium</em> instance).</p>\n\n<iframe style=\"border: 1px solid #CCC; border-width: 1px 1px 0; margin-bottom: 5px;\" src=\"http://www.slideshare.net/slideshow/embed_code/19982722\" height=\"421\" width=\"512\" allowfullscreen=\"\" frameborder=\"0\" marginwidth=\"0\" marginheight=\"0\" scrolling=\"no\"></iframe>\n\n<p>Since the SlideShare presentation is potentially not so friendly on the eyes, I’ve also created a <a title=\"Cloudera Amazon EC2 instructions\" href=\"http://randyzwitch.com/wp-content/uploads/2013/04/cloudera-amazon-ec2.pdf\" target=\"_blank\">PDF download</a> that’s full resolution.</p>\n\n<h2 id=\"next-steps\">Next Steps</h2>\n\n<p>Once you make it through all these steps to set up a Hadoop cluster, you are ready to do some analysis. <a href=\"http://randyzwitch.com/uploading-data-hadoop-amazon-ec2-cloudera-part-3/\" title=\"Upload data into HDFS using Hue\">Part 3 of this tutorial</a> will cover how to upload data into HDFS using Hue.</p>\n\n<p><em>Update, 7/13/13:</em> As is the case with any open-source project, there have been several changes to the Cloudera Manager that makes setup easier. When getting started, on the screen where it asks “Which Cloudera do you want to deploy?”, choose ‘Cloudera Standard’. Also, once you get to slides 13-14 where you click on the link to get started with Hue, the link now works correctly (you don’t need to search for the Amazon DNS any more!)</p>"
}