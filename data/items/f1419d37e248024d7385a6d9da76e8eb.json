{
  "title": "Towards Out-of-core DataFrames",
  "link": "",
  "updated": "2015-03-11T00:00:00+00:00",
  "id": "https://mrocklin.github.io/blog/work/2015/03/11/Towards-OOC-Frame",
  "content": "<p><em>This work is supported by <a href=\"http://continuum.io\">Continuum Analytics</a>\nand the <a href=\"http://www.darpa.mil/program/XDATA\">XDATA Program</a>\nas part of the <a href=\"http://blaze.pydata.org\">Blaze Project</a></em></p>\n\n<p><em>This post primarily targets developers.  It is on experimental code that is\nnot ready for users.</em></p>\n\n<p><strong>tl;dr</strong> Can we build <code class=\"language-plaintext highlighter-rouge\">dask.frame</code>?  One approach involves indexes and a lot\nof shuffling.</p>\n\n<h2 id=\"dask-arrays-work\">Dask arrays work</h2>\n\n<p>Over the last two months we’ve watched the creation of\n<a href=\"http://dask.pydata.org\"><code class=\"language-plaintext highlighter-rouge\">dask</code></a>, a task scheduling specification, and\n<a href=\"http://dask.pydata.org/en/latest/array.html\"><code class=\"language-plaintext highlighter-rouge\">dask.array</code></a> a project to\nimplement the out-of-core nd-arrays using blocked algorithms.\n(blogposts:\n<a href=\"http://matthewrocklin.com/blog/work/2014/12/27/Towards-OOC/\">1</a>,\n<a href=\"http://matthewrocklin.com/blog/work/2014/12/30/Towards-OOC-Frontend/\">2</a>,\n<a href=\"http://matthewrocklin.com/blog/work/2015/01/06/Towards-OOC-Scheduling/\">3</a>,\n<a href=\"http://matthewrocklin.com/blog/work/2015/01/14/Towards-OOC-MatMul/\">4</a>,\n<a href=\"http://matthewrocklin.com/blog/work/2015/01/16/Towards-OOC-SpillToDisk/\">5</a>,\n<a href=\"http://matthewrocklin.com/blog/work/2015/02/13/Towards-OOC-Slicing-and-Stacking/\">6</a>).\nThis worked pretty well.  Dask.array is available on the main conda channel and on PyPI\nand, for the most part, is a pleasant drop-in replacement for a subset of NumPy\noperations.  I’m really happy with it.</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>conda install dask\nor\npip install dask\n</code></pre></div></div>\n\n<p>There is still work to do, in particular I’d like to interact with people who\nhave real-world problems, but for the most part <code class=\"language-plaintext highlighter-rouge\">dask.array</code> feels ready.</p>\n\n<h2 id=\"on-to-dask-frames\">On to dask frames</h2>\n\n<p>Can we do for Pandas what we’ve just done for NumPy?</p>\n\n<p>Question: <em>Can we represent a large DataFrame as a sequence of in-memory DataFrames and\nperform most Pandas operations using task scheduling?</em></p>\n\n<p>Answer: <em>I don’t know.  Lets try.</em></p>\n\n<h2 id=\"naive-approach\">Naive Approach</h2>\n\n<p>If represent a dask.array as an N-d grid of NumPy ndarrays, then maybe we should\nrepresent a dask.frame as a 1-d grid of Pandas DataFrames; they’re kind of like arrays.</p>\n\n<table>\n<th>\n<td><b>dask.array</b></td>\n<td><b>Naive dask.frame</b></td>\n</th>\n<tr>\n<td></td>\n<td><img src=\"https://mrocklin.github.io/blog/images/array.png\" /></td>\n<td><img src=\"https://mrocklin.github.io/blog/images/naive-frame.png\" /></td>\n</tr>\n</table>\n\n<p>This approach supports the following operations:</p>\n\n<ul>\n  <li>Elementwise operations   <code class=\"language-plaintext highlighter-rouge\">df.a + df.b</code></li>\n  <li>Row-wise filtering   <code class=\"language-plaintext highlighter-rouge\">df[df.a &gt; 0]</code></li>\n  <li>Reductions <code class=\"language-plaintext highlighter-rouge\">df.a.mean()</code></li>\n  <li>Some split-apply-combine operations that combine with a standard reduction\nlike <code class=\"language-plaintext highlighter-rouge\">df.groupby('a').b.mean()</code>.  Essentially anything you can do with\n<code class=\"language-plaintext highlighter-rouge\">df.groupby(...).agg(...)</code></li>\n</ul>\n\n<p>The reductions and split-apply-combine operations require some cleverness.\nThis is how Blaze works now and how it does the does out-of-core operations in\nthese notebooks:\n<a href=\"http://nbviewer.ipython.org/github/ContinuumIO/blaze/blob/gh-pages/notebooks/timings-csv.ipynb\">Blaze and CSVs</a>,\n<a href=\"http://nbviewer.ipython.org/github/ContinuumIO/blaze/blob/gh-pages/notebooks/timings-bcolz.ipynb\">Blaze and Binary Storage</a>.</p>\n\n<p>However this approach does not support the following operations:</p>\n\n<ul>\n  <li>Joins</li>\n  <li>Split-apply-combine with more complex <code class=\"language-plaintext highlighter-rouge\">transform</code> or <code class=\"language-plaintext highlighter-rouge\">apply</code> combine steps</li>\n  <li>Sliding window or resampling operations</li>\n  <li>Anything involving multiple datasets</li>\n</ul>\n\n<h2 id=\"partition-on-the-index-values\">Partition on the Index values</h2>\n\n<p>Instead of partitioning based on the size of blocks we instead partition on\nvalue ranges of the index.</p>\n\n<table>\n<th>\n<td><b>Partition on block size</b></td>\n<td><b>Partition on index value</b></td>\n</th>\n<tr>\n<td></td>\n<td><img src=\"https://mrocklin.github.io/blog/images/naive-frame.png\" /></td>\n<td><img src=\"https://mrocklin.github.io/blog/images/frame.png\" /></td>\n</tr>\n</table>\n\n<p>This opens up a few more operations</p>\n\n<ul>\n  <li>Joins are possible when both tables share the same index.  Because we have\ninformation about index values we we know which blocks from one side need to\ncommunicate to which blocks from the other.</li>\n  <li>Split-apply-combine with transform/apply steps are possible when the grouper\nis the index.  In this case we’re guaranteed that each group is in the same\nblock.  This opens up general <code class=\"language-plaintext highlighter-rouge\">df.gropuby(...).apply(...)</code></li>\n  <li>Rolling or resampling operations are easy on the index if we share a small\namount of information between blocks as we do in <code class=\"language-plaintext highlighter-rouge\">dask.array</code> for <a href=\"http://dask.pydata.org/en/latest/ghost.html\">ghosting\noperations</a>.</li>\n</ul>\n\n<p>We note the following theme:</p>\n\n<p><em>Complex operations are easy if the logic aligns with the index</em></p>\n\n<p>And so a recipe for many complex operations becomes:</p>\n\n<ol>\n  <li>Re-index your data along the proper column</li>\n  <li>Perform easy computation</li>\n</ol>\n\n<h2 id=\"re-indexing-out-of-core-data\">Re-indexing out-of-core data</h2>\n\n<p>To be explicit imagine we have a large time-series of transactions indexed by\ntime and partitioned by day.  The data for every day is in a separate DataFrame.</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>Block 1\n-------\n                     credit    name\ntime\n2014-01-01 00:00:00     100     Bob\n2014-01-01 01:00:00     200   Edith\n2014-01-01 02:00:00    -300   Alice\n2014-01-01 03:00:00     400     Bob\n2014-01-01 04:00:00    -500  Dennis\n...\n\nBlock 2\n-------\n                     credit    name\ntime\n2014-01-02 00:00:00     300    Andy\n2014-01-02 01:00:00     200   Edith\n...\n</code></pre></div></div>\n\n<p>We want to reindex this data and shuffle all of the entries so that now we\npartiion on the name of the person.  Perhaps all of the A’s are in one block\nwhile all of the B’s are in another.</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>Block 1\n-------\n                       time  credit\nname\nAlice   2014-04-30 00:00:00     400\nAlice   2014-01-01 00:00:00     100\nAndy    2014-11-12 00:00:00    -200\nAndy    2014-01-18 00:00:00     400\nAndy    2014-02-01 00:00:00    -800\n...\n\nBlock 2\n-------\n                       time  credit\nname\nBob     2014-02-11 00:00:00     300\nBob     2014-01-05 00:00:00     100\n...\n</code></pre></div></div>\n\n<p>Re-indexing and shuffling large data is difficult and expensive.  We need to\nfind good values on which to partition our data so that we get regularly sized\nblocks that fit nicely into memory.  We also need to shuffle entries from all\nof the original blocks to all of the new ones.  In principle every old block\nhas something to contribute to every new one.</p>\n\n<p>We can’t just call <code class=\"language-plaintext highlighter-rouge\">DataFrame.sort</code> because the entire data might not fit in\nmemory and most of our sorting algorithms assume random access.</p>\n\n<p>We do this in two steps</p>\n\n<ol>\n  <li>Find good division values to partition our data.  These should partition\nthe data into blocks of roughly equal size.</li>\n  <li>Shuffle our old blocks into new blocks along the new partitions found in\nstep one.</li>\n</ol>\n\n<p><img src=\"https://mrocklin.github.io/blog/images/frame-sort.png\" align=\"right\" width=\"30%\" /></p>\n\n<h2 id=\"find-divisions-by-external-sorting\">Find divisions by external sorting</h2>\n\n<p>One approach to find new partition values is to pull out the new index\nfrom each block, perform an out-of-core sort, and then take regularly spaced\nvalues from that array.</p>\n\n<ol>\n  <li>\n    <p>Pull out new index column from each block</p>\n\n    <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>indexes = [block['new-column-index'] for block in blocks]\n</code></pre></div>    </div>\n  </li>\n  <li>\n    <p>Perform <a href=\"en.wikipedia.org/wiki/External_sorting\">out-of-core sort</a> on that\ncolumn</p>\n\n    <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>sorted_index = fancy_out_of_core_sort(indexes)\n</code></pre></div>    </div>\n  </li>\n  <li>\n    <p>Take values at regularly spaced intervals, e.g.</p>\n\n    <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>partition_values = sorted_index[::1000000]\n</code></pre></div>    </div>\n  </li>\n</ol>\n\n<p>We implement this using parallel in-block sorts, followed by a streaming merge\nprocess using the <code class=\"language-plaintext highlighter-rouge\">heapq</code> module.  It works but is slow.</p>\n\n<h3 id=\"possible-improvements\">Possible Improvements</h3>\n\n<p>This could be accelerated through one of the following options:</p>\n\n<ol>\n  <li>A streaming numeric solution that works directly on iterators of NumPy\narrays (<code class=\"language-plaintext highlighter-rouge\">numtoolz</code> anyone?)</li>\n  <li>Not sorting at all.  We only actually need approximate regularly spaced\nquantiles.  A brief literature search hints that there might be some good\nsolutions.</li>\n</ol>\n\n<p><img src=\"https://mrocklin.github.io/blog/images/frame-shuffle.png\" align=\"right\" width=\"30%\" /></p>\n\n<h2 id=\"shuffle\">Shuffle</h2>\n\n<p>Now that we know the values on which we want to partition we ask each block to\nshard itself into appropriate pieces and shove all of those pieces into a\nspill-to-disk dictionary.  Another process then picks up these pieces and calls\n<code class=\"language-plaintext highlighter-rouge\">pd.concat</code> to merge them in to the new blocks.</p>\n\n<p>For the out-of-core dict we’re currently using\n<a href=\"https://github.com/ContinuumIO/chest\">Chest</a>.  Turns out that serializing\nDataFrames and writing them to disk can be tricky.  There are several good\nmethods with about an order of magnitude performance difference between them.</p>\n\n<h2 id=\"this-works-but-my-implementation-is-slow\">This works but my implementation is slow</h2>\n\n<p>Here is an example with snippet of the NYCTaxi data (this is small)</p>\n\n<figure class=\"highlight\">\n  <pre><code class=\"language-python\" data-lang=\"python\"><span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]:</span> <span class=\"kn\">import</span> <span class=\"nn\">dask.frame</span> <span class=\"k\">as</span> <span class=\"n\">dfr</span>\n\n<span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">]:</span> <span class=\"n\">d</span> <span class=\"o\">=</span> <span class=\"n\">dfr</span><span class=\"p\">.</span><span class=\"n\">read_csv</span><span class=\"p\">(</span><span class=\"s\">'/home/mrocklin/data/trip-small.csv'</span><span class=\"p\">,</span> <span class=\"n\">chunksize</span><span class=\"o\">=</span><span class=\"mi\">10000</span><span class=\"p\">)</span>\n\n<span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">]:</span> <span class=\"n\">d</span><span class=\"p\">.</span><span class=\"n\">head</span><span class=\"p\">(</span><span class=\"mi\">3</span><span class=\"p\">)</span>   <span class=\"c1\"># This is fast\n</span><span class=\"n\">Out</span><span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">]:</span>\n                          <span class=\"n\">medallion</span>                      <span class=\"n\">hack_license</span>  \\\n<span class=\"mi\">0</span>  <span class=\"mi\">89</span><span class=\"n\">D227B655E5C82AECF13C3F540D4CF4</span>  <span class=\"n\">BA96DE419E711691B9445D6A6307C170</span>\n<span class=\"mi\">1</span>  <span class=\"mi\">0</span><span class=\"n\">BD7C8F5BA12B88E0B67BED28BEA73D8</span>  <span class=\"mi\">9</span><span class=\"n\">FD8F69F0804BDB5549F40E9DA1BE472</span>\n<span class=\"mi\">2</span>  <span class=\"mi\">0</span><span class=\"n\">BD7C8F5BA12B88E0B67BED28BEA73D8</span>  <span class=\"mi\">9</span><span class=\"n\">FD8F69F0804BDB5549F40E9DA1BE472</span>\n\n  <span class=\"n\">vendor_id</span>  <span class=\"n\">rate_code</span> <span class=\"n\">store_and_fwd_flag</span>      <span class=\"n\">pickup_datetime</span>  \\\n<span class=\"mi\">0</span>       <span class=\"n\">CMT</span>          <span class=\"mi\">1</span>                  <span class=\"n\">N</span>  <span class=\"mi\">2013</span><span class=\"o\">-</span><span class=\"mi\">01</span><span class=\"o\">-</span><span class=\"mi\">01</span> <span class=\"mi\">15</span><span class=\"p\">:</span><span class=\"mi\">11</span><span class=\"p\">:</span><span class=\"mi\">48</span>\n<span class=\"mi\">1</span>       <span class=\"n\">CMT</span>          <span class=\"mi\">1</span>                  <span class=\"n\">N</span>  <span class=\"mi\">2013</span><span class=\"o\">-</span><span class=\"mi\">01</span><span class=\"o\">-</span><span class=\"mi\">06</span> <span class=\"mi\">00</span><span class=\"p\">:</span><span class=\"mi\">18</span><span class=\"p\">:</span><span class=\"mi\">35</span>\n<span class=\"mi\">2</span>       <span class=\"n\">CMT</span>          <span class=\"mi\">1</span>                  <span class=\"n\">N</span>  <span class=\"mi\">2013</span><span class=\"o\">-</span><span class=\"mi\">01</span><span class=\"o\">-</span><span class=\"mi\">05</span> <span class=\"mi\">18</span><span class=\"p\">:</span><span class=\"mi\">49</span><span class=\"p\">:</span><span class=\"mi\">41</span>\n\n      <span class=\"n\">dropoff_datetime</span>  <span class=\"n\">passenger_count</span>  <span class=\"n\">trip_time_in_secs</span>  <span class=\"n\">trip_distance</span>  \\\n<span class=\"mi\">0</span>  <span class=\"mi\">2013</span><span class=\"o\">-</span><span class=\"mi\">01</span><span class=\"o\">-</span><span class=\"mi\">01</span> <span class=\"mi\">15</span><span class=\"p\">:</span><span class=\"mi\">18</span><span class=\"p\">:</span><span class=\"mi\">10</span>                <span class=\"mi\">4</span>                <span class=\"mi\">382</span>            <span class=\"mf\">1.0</span>\n<span class=\"mi\">1</span>  <span class=\"mi\">2013</span><span class=\"o\">-</span><span class=\"mi\">01</span><span class=\"o\">-</span><span class=\"mi\">06</span> <span class=\"mi\">00</span><span class=\"p\">:</span><span class=\"mi\">22</span><span class=\"p\">:</span><span class=\"mi\">54</span>                <span class=\"mi\">1</span>                <span class=\"mi\">259</span>            <span class=\"mf\">1.5</span>\n<span class=\"mi\">2</span>  <span class=\"mi\">2013</span><span class=\"o\">-</span><span class=\"mi\">01</span><span class=\"o\">-</span><span class=\"mi\">05</span> <span class=\"mi\">18</span><span class=\"p\">:</span><span class=\"mi\">54</span><span class=\"p\">:</span><span class=\"mi\">23</span>                <span class=\"mi\">1</span>                <span class=\"mi\">282</span>            <span class=\"mf\">1.1</span>\n\n   <span class=\"n\">pickup_longitude</span>  <span class=\"n\">pickup_latitude</span>  <span class=\"n\">dropoff_longitude</span>  <span class=\"n\">dropoff_latitude</span>\n<span class=\"mi\">0</span>        <span class=\"o\">-</span><span class=\"mf\">73.978165</span>        <span class=\"mf\">40.757977</span>         <span class=\"o\">-</span><span class=\"mf\">73.989838</span>         <span class=\"mf\">40.751171</span>\n<span class=\"mi\">1</span>        <span class=\"o\">-</span><span class=\"mf\">74.006683</span>        <span class=\"mf\">40.731781</span>         <span class=\"o\">-</span><span class=\"mf\">73.994499</span>         <span class=\"mf\">40.750660</span>\n<span class=\"mi\">2</span>        <span class=\"o\">-</span><span class=\"mf\">74.004707</span>        <span class=\"mf\">40.737770</span>         <span class=\"o\">-</span><span class=\"mf\">74.009834</span>         <span class=\"mf\">40.726002</span>\n\n<span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">4</span><span class=\"p\">]:</span> <span class=\"n\">d2</span> <span class=\"o\">=</span> <span class=\"n\">d</span><span class=\"p\">.</span><span class=\"n\">set_index</span><span class=\"p\">(</span><span class=\"n\">d</span><span class=\"p\">.</span><span class=\"n\">passenger_count</span><span class=\"p\">,</span> <span class=\"n\">out_chunksize</span><span class=\"o\">=</span><span class=\"mi\">10000</span><span class=\"p\">)</span>   <span class=\"c1\"># This takes some time\n</span>\n<span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">5</span><span class=\"p\">]:</span> <span class=\"n\">d2</span><span class=\"p\">.</span><span class=\"n\">head</span><span class=\"p\">(</span><span class=\"mi\">3</span><span class=\"p\">)</span>\n<span class=\"n\">Out</span><span class=\"p\">[</span><span class=\"mi\">5</span><span class=\"p\">]:</span>\n                                        <span class=\"n\">medallion</span>  \\\n<span class=\"n\">passenger_count</span>\n<span class=\"mi\">0</span>                <span class=\"mi\">3</span><span class=\"n\">F3AC054811F8B1F095580C50FF16090</span>\n<span class=\"mi\">1</span>                <span class=\"mi\">4</span><span class=\"n\">C52E48F9E05AA1A8E2F073BB932E9AA</span>\n<span class=\"mi\">1</span>                <span class=\"n\">FF00E5D4B15B6E896270DDB8E0697BF7</span>\n\n                                     <span class=\"n\">hack_license</span> <span class=\"n\">vendor_id</span>  <span class=\"n\">rate_code</span>  \\\n<span class=\"n\">passenger_count</span>\n<span class=\"mi\">0</span>                <span class=\"n\">E00BD74D8ADB81183F9F5295DC619515</span>       <span class=\"n\">VTS</span>          <span class=\"mi\">5</span>\n<span class=\"mi\">1</span>                <span class=\"mi\">307</span><span class=\"n\">D1A2524E526EE08499973A4F832CF</span>       <span class=\"n\">VTS</span>          <span class=\"mi\">1</span>\n<span class=\"mi\">1</span>                <span class=\"mf\">0E8</span><span class=\"n\">CCD187F56B3696422278EBB620EFA</span>       <span class=\"n\">VTS</span>          <span class=\"mi\">1</span>\n\n                <span class=\"n\">store_and_fwd_flag</span>      <span class=\"n\">pickup_datetime</span>     <span class=\"n\">dropoff_datetime</span>  \\\n<span class=\"n\">passenger_count</span>\n<span class=\"mi\">0</span>                              <span class=\"n\">NaN</span>  <span class=\"mi\">2013</span><span class=\"o\">-</span><span class=\"mi\">01</span><span class=\"o\">-</span><span class=\"mi\">13</span> <span class=\"mi\">03</span><span class=\"p\">:</span><span class=\"mi\">25</span><span class=\"p\">:</span><span class=\"mi\">00</span>  <span class=\"mi\">2013</span><span class=\"o\">-</span><span class=\"mi\">01</span><span class=\"o\">-</span><span class=\"mi\">13</span> <span class=\"mi\">03</span><span class=\"p\">:</span><span class=\"mi\">42</span><span class=\"p\">:</span><span class=\"mi\">00</span>\n<span class=\"mi\">1</span>                              <span class=\"n\">NaN</span>  <span class=\"mi\">2013</span><span class=\"o\">-</span><span class=\"mi\">01</span><span class=\"o\">-</span><span class=\"mi\">13</span> <span class=\"mi\">16</span><span class=\"p\">:</span><span class=\"mi\">12</span><span class=\"p\">:</span><span class=\"mi\">00</span>  <span class=\"mi\">2013</span><span class=\"o\">-</span><span class=\"mi\">01</span><span class=\"o\">-</span><span class=\"mi\">13</span> <span class=\"mi\">16</span><span class=\"p\">:</span><span class=\"mi\">23</span><span class=\"p\">:</span><span class=\"mi\">00</span>\n<span class=\"mi\">1</span>                              <span class=\"n\">NaN</span>  <span class=\"mi\">2013</span><span class=\"o\">-</span><span class=\"mi\">01</span><span class=\"o\">-</span><span class=\"mi\">13</span> <span class=\"mi\">15</span><span class=\"p\">:</span><span class=\"mi\">05</span><span class=\"p\">:</span><span class=\"mi\">00</span>  <span class=\"mi\">2013</span><span class=\"o\">-</span><span class=\"mi\">01</span><span class=\"o\">-</span><span class=\"mi\">13</span> <span class=\"mi\">15</span><span class=\"p\">:</span><span class=\"mi\">15</span><span class=\"p\">:</span><span class=\"mi\">00</span>\n\n                 <span class=\"n\">passenger_count</span>  <span class=\"n\">trip_time_in_secs</span>  <span class=\"n\">trip_distance</span>  \\\n<span class=\"n\">passenger_count</span>\n<span class=\"mi\">0</span>                              <span class=\"mi\">0</span>               <span class=\"mi\">1020</span>           <span class=\"mf\">5.21</span>\n<span class=\"mi\">1</span>                              <span class=\"mi\">1</span>                <span class=\"mi\">660</span>           <span class=\"mf\">2.94</span>\n<span class=\"mi\">1</span>                              <span class=\"mi\">1</span>                <span class=\"mi\">600</span>           <span class=\"mf\">2.18</span>\n\n                 <span class=\"n\">pickup_longitude</span>  <span class=\"n\">pickup_latitude</span>  <span class=\"n\">dropoff_longitude</span>  \\\n<span class=\"n\">passenger_count</span>\n<span class=\"mi\">0</span>                      <span class=\"o\">-</span><span class=\"mf\">73.986900</span>        <span class=\"mf\">40.743736</span>         <span class=\"o\">-</span><span class=\"mf\">74.029747</span>\n<span class=\"mi\">1</span>                      <span class=\"o\">-</span><span class=\"mf\">73.976753</span>        <span class=\"mf\">40.790123</span>         <span class=\"o\">-</span><span class=\"mf\">73.984802</span>\n<span class=\"mi\">1</span>                      <span class=\"o\">-</span><span class=\"mf\">73.982719</span>        <span class=\"mf\">40.767147</span>         <span class=\"o\">-</span><span class=\"mf\">73.982170</span>\n\n                 <span class=\"n\">dropoff_latitude</span>\n<span class=\"n\">passenger_count</span>\n<span class=\"mi\">0</span>                       <span class=\"mf\">40.741348</span>\n<span class=\"mi\">1</span>                       <span class=\"mf\">40.758518</span>\n<span class=\"mi\">1</span>                       <span class=\"mf\">40.746170</span>\n\n<span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">6</span><span class=\"p\">]:</span> <span class=\"n\">d2</span><span class=\"p\">.</span><span class=\"n\">blockdivs</span>  <span class=\"c1\"># our new partition values\n</span><span class=\"n\">Out</span><span class=\"p\">[</span><span class=\"mi\">6</span><span class=\"p\">]:</span> <span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">6</span><span class=\"p\">)</span>\n\n<span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">7</span><span class=\"p\">]:</span> <span class=\"n\">d</span><span class=\"p\">.</span><span class=\"n\">blockdivs</span>   <span class=\"c1\"># our original partition values\n</span><span class=\"n\">Out</span><span class=\"p\">[</span><span class=\"mi\">7</span><span class=\"p\">]:</span> <span class=\"p\">(</span><span class=\"mi\">10000</span><span class=\"p\">,</span> <span class=\"mi\">20000</span><span class=\"p\">,</span> <span class=\"mi\">30000</span><span class=\"p\">,</span> <span class=\"mi\">40000</span><span class=\"p\">,</span> <span class=\"mi\">50000</span><span class=\"p\">,</span> <span class=\"mi\">60000</span><span class=\"p\">,</span> <span class=\"mi\">70000</span><span class=\"p\">,</span> <span class=\"mi\">80000</span><span class=\"p\">,</span> <span class=\"mi\">90000</span><span class=\"p\">)</span></code></pre>\n</figure>\n\n<h2 id=\"some-problems\">Some Problems</h2>\n\n<ul>\n  <li>\n    <p>First, we have to evaluate the dask as we go.  Every <code class=\"language-plaintext highlighter-rouge\">set_index</code> operation (and\nhence many groupbys and joins) forces an evaluation.  We can no longer, as in\nthe dask.array case, endlessly compound high-level operations to form more and\nmore complex graphs and then only evaluate at the end.  We need to evaluate as\nwe go.</p>\n  </li>\n  <li>\n    <p>Sorting/shuffling is slow.  This is for a few reasons including the\nserialization of DataFrames and sorting being hard.</p>\n  </li>\n  <li>\n    <p>How feasible is it to frequently re-index a large amount of data?  When do we\nreach the stage of “just use a database”?</p>\n  </li>\n  <li>\n    <p>Pandas doesn’t yet release the GIL, so this is all single-core.  See post on\n<a href=\"https://mrocklin.github.io/blog/work/2015/03/10/PyData-GIL/\">PyData and the GIL</a>.</p>\n  </li>\n  <li>\n    <p>My current solution lacks basic functionality.  I’ve skipped\nthe easy things to first ensure sure that the hard stuff is doable.</p>\n  </li>\n</ul>\n\n<h2 id=\"help\">Help!</h2>\n\n<p>I know less about tables than about arrays.  I’m ignorant of the literature and\ncommon solutions in this field.  If anything here looks suspicious then <em>please\nspeak up</em>.  I could really use your help.</p>\n\n<p>Additionally the Pandas API is much more complex than NumPy’s.  If any\nexperienced devs out there feel like jumping in and implementing fairly\nstraightforward Pandas features in a blocked way I’d be obliged.</p>"
}