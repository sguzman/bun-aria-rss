{
  "title": "StereoSpike: Depth Learning with a Spiking Neural Network. (arXiv:2109.13751v3 [cs.CV] UPDATED)",
  "link": "http://arxiv.org/abs/2109.13751",
  "description": "<p>Depth estimation is an important computer vision task, useful in particular\nfor navigation in autonomous vehicles, or for object manipulation in robotics.\nHere we solved it using an end-to-end neuromorphic approach, combining two\nevent-based cameras and a Spiking Neural Network (SNN) with a slightly modified\nU-Net-like encoder-decoder architecture, that we named StereoSpike. More\nspecifically, we used the Multi Vehicle Stereo Event Camera Dataset (MVSEC). It\nprovides a depth ground-truth, which was used to train StereoSpike in a\nsupervised manner, using surrogate gradient descent. We propose a novel readout\nparadigm to obtain a dense analog prediction -- the depth of each pixel -- from\nthe spikes of the decoder. We demonstrate that this architecture generalizes\nvery well, even better than its non-spiking counterparts, leading to\nstate-of-the-art test accuracy. To the best of our knowledge, it is the first\ntime that such a large-scale regression problem is solved by a fully spiking\nnetwork. Finally, we show that low firing rates (&lt;10%) can be obtained via\nregularization, with a minimal cost in accuracy. This means that StereoSpike\ncould be efficiently implemented on neuromorphic chips, opening the door for\nlow power and real time embedded systems.\n</p>",
  "dc:creator": "<a href=\"http://arxiv.org/find/cs/1/au:+Rancon_U/0/1/0/all/0/1\">Ulysse Ran&#xe7;on</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cuadrado_Anibarro_J/0/1/0/all/0/1\">Javier Cuadrado-Anibarro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cottereau_B/0/1/0/all/0/1\">Benoit R. Cottereau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Masquelier_T/0/1/0/all/0/1\">Timoth&#xe9;e Masquelier</a>"
}