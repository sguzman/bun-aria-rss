{
  "id": "tag:blogger.com,1999:blog-19803222.post-7186481362605520438",
  "published": "2016-08-14T11:36:00.000-06:00",
  "updated": "2016-08-14T12:42:22.083-06:00",
  "title": "Some papers I liked at ACL 2016",
  "content": "A conference just ended, so it's that time of year! Here are some papers I liked with the usual caveats about recall.<br /><br />Before I go to the list, let me say that I really really enjoyed ACL this year. I was completely on the fence about going, and basically decided to go only because of giving a talk at <a href=\"https://sites.google.com/site/repl4nlp2016/\">Repl4NLP</a>, and wanted to attend the business meeting for the discussion of diversity in the ACL community, led by Joakim Nivre with an <i>amazing</i> report that he, Lyn Walker, Yejin Choi and Min-Yen Kan put together. (Likely I'll post more, separately, about both of these; for the latter, I tried to <a href=\"https://twitter.com/haldaume3/status/763351580821291008\">transcribe much of Joakim's presentation</a>.)<br /><br />All in all, I'm supremely glad I decided to go: it was probably my favorite conference in recent memory. This was not just because there were lots of great papers (there were!) but also because somehow it felt more like a large community conference than others I've attended recently. I'm not sure what made it like this, but I noticed it felt a lot less clique-y than NAACL, a lot more broad and interesting than ICML/NIPS (though that's probably because of my personal taste in research) and in general a lot friendlier. I don't know what the organizers did that managed this great combination, but it was great!<br /><br />Okay, so on to the papers, sorted by ACL id.<br /><br /><a href=\"http://www.aclweb.org/anthology/P/P16/P16-1009.pdf\">P16-1009</a>: <b>Rico Sennrich; Barry Haddow; Alexandra Birch</b><br /><i>Improving Neural Machine Translation Models with Monolingual Data</i><br /><blockquote class=\"tr_bq\">I like this paper because it has a nice solution to a problem I spent a year thinking about on-and-off and never came up with. The problem is: suppose that you're training a discriminative MT system (they're doing neural; that's essentially irrelevant). You usually have far more monolingual data than parallel data, which typically gets thrown away in neural systems because we have no idea how to incorporate it (other than as a feature, but that's blech). What they do here is, assuming you have translation systems in both directions, back translate your monolingual target-side data, and then use that faux-parallel-data to train your MT system on. Obvious question is: how much of the improvement in performance is due to language modeling versus due to some weird kind of reverse-self-training, but regardless the answer, this is a really cool (if somewhat computationally expensive) answer to a question that's been around for at least five years. Oh and it also works <i>really</i> well.<br /><i></i></blockquote><br /><a href=\"http://www.aclweb.org/anthology/P/P16/P16-1018.pdf\">P16-1018</a>: <b>E.Dario Gutierrez; Ekaterina Shutova; Tyler Marghetis; Benjamin Bergen</b><br /><i>Literal and Metaphorical Senses in Compositional Distributional Semantic Models</i><br /><blockquote class=\"tr_bq\">I didn't see this paper presented, but it was suggested to me at Monday's poster session. Suppose we're trying to learn representations of adjective/noun pairs, by modeling nouns as vectors and adjectives as matrices, evaluating on unseen pairs only. (Personally I don't love this style, but that's incidental to the main ideas in this paper.) This paper adjusts the adjective matrices depending on whether they're being used literally (\"sweet candy\") or metaphorically (\"sweet dreams\"). But then you can go further and posit that there's another matrix that can transform literal metaphors into metaphorical metaphors automatically, essentially implementing the Lakoff-style notion that there is great consistency in how metaphors are created.</blockquote><br /><a href=\"http://www.aclweb.org/anthology/P/P16/P16-1030.pdf\">P16-1030</a> [<a href=\"http://www.aclweb.org/anthology/attachments/P/P16/P16-1030.Datasets.zip\">dataset</a>]: <b>Hannah Rashkin; Sameer Singh; Yejin Choi</b><br /><i>Connotation Frames: A Data-Driven Investigation</i><br /><blockquote class=\"tr_bq\">This paper should win some sort of award for thoroughness. The idea is that in many frames (\"The walrus pummelled the sea squirt\") there is implied connotation/polarity/etc. on not only the agent (walrus) and theme (sea squirt) of the frame but also tells us something about the relationship between the writer/speaker and the agent/theme (the writer might be closer to the sea squirt in this example, versus s/pummelled/fought/). The connotation frame for pummelled collects all this information. This paper also describes an approach to prediction of these complex frames using nice structured models. Totally want to try this stuff on our old <a href=\"http://hal3.name/docs/daume10plotunits-emnlp.pdf\">plotunits</a> data, where we had a hard time getting even a much simpler type of representation (patient polarity verbs) to work!</blockquote><br /><a href=\"http://www.aclweb.org/anthology/P/P16/P16-1152.pdf\">P16-1152</a>: <b>Artem Sokolov; Julia Kreutzer; Christopher Lo; Stefan Riezler</b><br /><i>Learning Structured Predictors from Bandit Feedback for Interactive NLP</i><br /><blockquote class=\"tr_bq\">This was perhaps my favorite paper of the conference because it's trying to do something new and hard and takes a nice approach. At a high level, suppose you're Facebook and you're trying to improve your translation system so you ask users to give 1 star to 5 star ratings. How can you use this to do better translation? This is basically the (structured) contextual bandit feedback learning problem. This paper approaches this from a dueling bandits perspective where I show you two translations and ask which is better. (Some of the authors had an earlier <a href=\"http://www.cl.uni-heidelberg.de/~riezler/publications/papers/MTSUMMIT2015.pdf\">MT-Summit paper</a> on the non-dueling problem which I imagine many people didn't see, but you should read it anyway.) The technical approach is basically probabilitic latent-variable models, optimized with gradient descent, with promising results. (I also like this because I've been thinking about similar <a href=\"https://arxiv.org/abs/1502.02206\">structured bandit problems</a> recently too :P.)</blockquote><br /><a href=\"http://www.aclweb.org/anthology/P/P16/P16-1231.pdf\">P16-1231</a>: <b>Daniel Andor; Chris Alberti; David Weiss; Aliaksei Severyn; Alessandro Presta; Kuzman Ganchev; Slav Petrov; Michael Collins</b><br /><i>Globally Normalized Transition-Based Neural Networks</i><br /><blockquote class=\"tr_bq\">[EDIT 14 Aug 2:40p: I misunderstood from the talk and therefore the following is basically inaccurate. I'm leaving this description and paper here on the list because Yoav's comment will make no sense otherwise, but please understand that it's wrong and, I hate to say this, it does make the paper less exciting to me. The part that's wrong is struck-out below.] There's a theme in the past two years of basically repeating all the structured prediction stuff we did ten years ago on our new neural network technology. This paper is about using Collins &amp; Roark-style incremental perceptron for transition-based dependency parsing on top of neural networks. The idea is that label-bias is perhaps still a problem for neural network dependency parsers, like their linear grandparents. <strike>Why do I like this? Because I think a lot of neural nets people would argue that this shouldn't be necessary: the network can do arbitrarily far lookahead into the future and therefore should be able to learn to avoid the label-bias problem. This paper shows that current techniques don't achieve that: there's a consistent win to be had by doing global normalization.</strike></blockquote><br /><a href=\"http://www.aclweb.org/anthology/P/P16/P16-2013.pdf\">P16-2013</a>: <b>Marina Fomicheva; Lucia Specia</b><br /><i>Reference Bias in Monolingual Machine Translation Evaluation</i><br /><blockquote class=\"tr_bq\">This paper shows pretty definitively that human evaluations against a reference translation are super biased toward the particular reference used (probably because evaluators are lazy and are basically doing ngram matching anyway -- a story I heard from MSR friends a while back). The paper also shows that this gets worse over time, presumably as evaluators get tireder.</blockquote><a href=\"http://www.aclweb.org/anthology/P/P16/P16-2096.pdf\">P16-2096</a>: <b>Dirk Hovy; Shannon L. Spruit</b><br /><i>The Social Impact of Natural Language Processing</i><br /><blockquote class=\"tr_bq\">This is a nice paper summarizing four issues that come up in ethics that also come up in NLP. I mostly liked this paper because it gave names to things I've thought about off and on, but didn't have a name for. In particular, they consider <i>exclusion</i> (hey my ASR system doesn't work on people with an accent, I guess they don't get a voice), <i>overgeneralization</i> (to what degree are our models effectively stereotyping more than they should), <i>over-</i> and <i>under-exposure</i> (hey lets all work on parsing because that's what everyone else is working on, which then makes parsing seem more important...just to pick a random example :P), and <i>dual-use</i> (I made something for good but XYZ organization used it for evil!). This is a position/discussion-starting paper, and I thought quite engaging.</blockquote><br />Feel free to post papers you like in the comments! <br /><br /><br /><br /><br /><br /><i>&nbsp;</i>",
  "link": [
    "",
    "",
    "",
    "",
    ""
  ],
  "author": {
    "name": "hal",
    "uri": "http://www.blogger.com/profile/02162908373916390369",
    "email": "noreply@blogger.com",
    "gd:image": ""
  },
  "thr:total": 13
}