{
  "title": "Inferring data loss (and correcting for it) from fundamental relationships",
  "author": {
    "name": "Chris Stucchio"
  },
  "link": "",
  "updated": "2017-09-01T09:45:00+02:00Z",
  "published": "2017-09-01T09:45:00+02:00Z",
  "id": "https://www.chrisstucchio.com/blog/2017/sequential_conversion_rates.html",
  "content": "\n                (If mathematical formulas are not showing up here, <a href=\"https://www.chrisstucchio.com/blog/2017/sequential_conversion_rates.html?utm_medium=rss&utm_source=rss&utm_campaign=rss\">please read this on the web.</a>.)\n                <p>I recently analyzed a somewhat puzzling data set. I was sending HTTP POST requests to a system. The system's would then acknowledge receipt of these requests (returning a 200 status code), and some time later (it was a slow asynchronous process) send a web hook to a specified URL <em>if the request was successful</em>. However, successful was far from certain; most requests actually failed. My job was to measure the success rate.</p>\n<p>Concretely, event <code>A</code> would trigger at some time <code>t0</code>. If <code>A</code> was successful, then event <code>B</code> might occur at time <code>t1</code>. <code>B</code> can only occur if <code>A</code> occurred.</p>\n<p>Similar systems like this happen in a variety of contexts:</p>\n<ul>\n<li>Ad delivery. The ad must first be displayed (event <code>A</code>), and only after it's displayed can the viewer click a link (event <code>B</code>).</li>\n<li>Email. The email must first be opened (event <code>A</code>), and only after it's opened can the reader click a link (event <code>B</code>).</li>\n<li>Web forms. A user must first enter their credit card, and only after that can they click submit.</li>\n</ul>\n<p>What I wanted to compute was <code>alpha = P(A)</code> and <code>beta = P(B | A)</code>.</p>\n<p>When analyzing the data I had, I noticed a curious pattern.</p>\n<div class=\"highlight\"><pre><span></span>request ID| time of A | time of B\n----------+-----------+----------\nabc       | 12:00     | 1:00\ndef       | 12:01     | null\nghi       | null      | null\njkl       | null      | 1:03  <--- WTF is this?\n</pre></div>\n\n\n<p>That last row (for request ID <code>jkl</code>) indicates something really weird happening. It suggests that event <code>B</code> has occurred even though event <code>A</code> has not!</p>\n<p>According to my model, which I have a high degree of confidence in, this isn't possible. Yet it's in the data; the responding system could not post a web hook with ID <code>jkl</code> if they hadn't received the request; they couldn't possibly know this ID.</p>\n<p>The conclusion I drew is that our measurements of <code>A</code> and <code>B</code> are unreliable. <code>A</code> and <code>B</code> may actually occur without being observed. So the real problem at hand is to infer the true rates at which <code>A</code> and <code>B</code> occur from the complete data set.</p>\n<h2>Some simplified calculations</h2>\n<p>I'll begin with some simple calculations - using nothing but arithmetic - to give the flavor of this analysis. To make things concrete, suppose we have the following data set:</p>\n<p>Suppose we have the following counts:</p>\n<ul>\n<li>100k requests were made</li>\n<li>In 40k cases, event <code>A</code> was reported and <code>B</code> did was not reported</li>\n<li>In 10k cases, event <code>A</code> was reported and then <code>B</code> was reported</li>\n<li>In 5k cases, event <code>B</code> was reported but <code>A</code> was never reported</li>\n</ul>\n<p>The most naive possible approach is to simply treat the cases where <code>B</code> occurred to be <em>bad data</em> and discard them. Then we can estimate:</p>\n<div class=\"highlight\"><pre><span></span>alpha = 50k / 95k = 0.526\nbeta = 10k / 50k = 0.200\n</pre></div>\n\n\n<p>But we can do better than this. We can use logical inference to deduce that in every case where <code>B</code> occurred, <code>A</code> also occurred. So we actually know that <code>A</code> occurred 55k times, and <code>A</code> then <code>B</code> occurred 15k times. So we can then estimate:</p>\n<div class=\"highlight\"><pre><span></span>alpha = 55k / 100k = 0.550\nbeta = 15k / 55k = 0.273\n</pre></div>\n\n\n<p>Finally, there's a third approach we can take. Lets define the parameters <code>gamma_A = P(A reported | A occurred)</code> and <code>gamma_B = P(B reported | B occurred)</code>. Lets assume that <code>gamma_A = gamma_B = gamma</code>; this is reasonable in the event that events <code>A</code> and <code>B</code> are measured by the same mechanism (e.g., a tracking pixel).</p>\n<p>Then we can infer, based on the fact that <code>B</code> occurred at least 500 times without <code>A</code> being reported, that approximately 10% (5k A occurrences without reports/ 50k A reports) of the time, data is lost. This suggests <code>gamma ~= 0.9</code>.</p>\n<p>We can then estimate that there were 50k / 0.9 = 55.56k occurrences of <code>A</code> and 15k / 0.9 = 16.67k occurrences of <code>B</code>, yielding:</p>\n<div class=\"highlight\"><pre><span></span>alpha = 55.56k / 100k = 0.556\nbeta = 16.67k / 55.56k = 0.300\n</pre></div>\n\n\n<h3>Small errors result in big differences!</h3>\n<p>Based on the data we have, we've guesstimated that approximately 10% of the events which occur are not reported. However, this effect cascades and results in an overall success rate of <code>alpha * beta</code> being reported as 10.5% (= 1,000 / 9,500) rather than 16.7% (= 1667 / 10,000). That's a huge difference!</p>\n<h2>Statistical method</h2>\n<p>These calculations are all great, but we also need to deal with uncertainty. It's possible that actually <code>gamma=0.95</code> but we simply got unlucky, or <code>gamma=0.85</code> and we got very lucky. How can we quantify this?</p>\n<p>This can be done relatively straightforwardly with <a href=\"https://pymc-devs.github.io/pymc3/notebooks/getting_started.html\">pymc3</a>.</p>\n<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">pylab</span> <span class=\"kn\">as</span> <span class=\"nn\">pl</span>\n<span class=\"kn\">import</span> <span class=\"nn\">pymc3</span> <span class=\"kn\">as</span> <span class=\"nn\">pymc</span>\n<span class=\"kn\">import</span> <span class=\"nn\">numpy</span>\n\n<span class=\"n\">N</span> <span class=\"o\">=</span> <span class=\"mi\">100000</span>\n<span class=\"n\">ao</span> <span class=\"o\">=</span> <span class=\"mi\">40000</span>\n<span class=\"n\">bo_and_ao</span> <span class=\"o\">=</span> <span class=\"mi\">10000</span>\n<span class=\"n\">bo_no_ao</span> <span class=\"o\">=</span> <span class=\"mi\">5000</span>\n\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">pymc</span><span class=\"o\">.</span><span class=\"n\">Model</span><span class=\"p\">()</span>\n\n<span class=\"k\">with</span> <span class=\"n\">model</span><span class=\"p\">:</span>\n    <span class=\"n\">alpha</span> <span class=\"o\">=</span> <span class=\"n\">pymc</span><span class=\"o\">.</span><span class=\"n\">Uniform</span><span class=\"p\">(</span><span class=\"s1\">'alpha'</span><span class=\"p\">,</span> <span class=\"n\">lower</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">upper</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n    <span class=\"n\">beta</span>  <span class=\"o\">=</span> <span class=\"n\">pymc</span><span class=\"o\">.</span><span class=\"n\">Uniform</span><span class=\"p\">(</span><span class=\"s1\">'beta'</span><span class=\"p\">,</span> <span class=\"n\">lower</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">upper</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n    <span class=\"n\">gamma</span> <span class=\"o\">=</span> <span class=\"n\">pymc</span><span class=\"o\">.</span><span class=\"n\">Uniform</span><span class=\"p\">(</span><span class=\"s1\">'gamma'</span><span class=\"p\">,</span> <span class=\"n\">lower</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">upper</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n\n    <span class=\"n\">a_occurred</span> <span class=\"o\">=</span> <span class=\"n\">pymc</span><span class=\"o\">.</span><span class=\"n\">Binomial</span><span class=\"p\">(</span><span class=\"s1\">'a_occurred'</span><span class=\"p\">,</span> <span class=\"n\">n</span><span class=\"o\">=</span><span class=\"n\">N</span><span class=\"p\">,</span> <span class=\"n\">p</span><span class=\"o\">=</span><span class=\"n\">alpha</span><span class=\"p\">)</span>\n    <span class=\"n\">a_observed</span> <span class=\"o\">=</span> <span class=\"n\">pymc</span><span class=\"o\">.</span><span class=\"n\">Binomial</span><span class=\"p\">(</span><span class=\"s1\">'a_observed'</span><span class=\"p\">,</span> <span class=\"n\">n</span><span class=\"o\">=</span><span class=\"n\">a_occurred</span><span class=\"p\">,</span> <span class=\"n\">p</span><span class=\"o\">=</span><span class=\"n\">gamma</span><span class=\"p\">,</span> <span class=\"n\">observed</span><span class=\"o\">=</span><span class=\"n\">ao</span><span class=\"o\">+</span><span class=\"n\">bo_and_ao</span><span class=\"p\">)</span>\n\n    <span class=\"n\">b_occurred</span> <span class=\"o\">=</span> <span class=\"n\">pymc</span><span class=\"o\">.</span><span class=\"n\">Binomial</span><span class=\"p\">(</span><span class=\"s1\">'b_occurred'</span><span class=\"p\">,</span> <span class=\"n\">n</span><span class=\"o\">=</span><span class=\"n\">a_occurred</span><span class=\"p\">,</span> <span class=\"n\">p</span><span class=\"o\">=</span><span class=\"n\">beta</span><span class=\"p\">)</span>\n    <span class=\"n\">b_observed</span> <span class=\"o\">=</span> <span class=\"n\">pymc</span><span class=\"o\">.</span><span class=\"n\">Binomial</span><span class=\"p\">(</span><span class=\"s1\">'b_observed'</span><span class=\"p\">,</span> <span class=\"n\">n</span><span class=\"o\">=</span><span class=\"n\">b_occurred</span><span class=\"p\">,</span> <span class=\"n\">p</span><span class=\"o\">=</span><span class=\"n\">gamma</span><span class=\"p\">,</span> <span class=\"n\">observed</span><span class=\"o\">=</span><span class=\"n\">bo_and_ao</span><span class=\"o\">+</span><span class=\"n\">bo_no_ao</span><span class=\"p\">)</span>\n</pre></div>\n\n\n<p>The results can then be plotted:</p>\n<p><img alt=\"Graph of uncertainty in number of conversions\" src=\"/blog_media/2017/sequential_conversion_rates/observation_probability.png\"></p>\n<p>As is expected, we have sharp lower bounds; the true number of events could not be lower than our observed number of events.</p>\n<p>These numbers are in rough accordance with our heuristic calculations above.</p>\n<h2>Extracting fundamental parameters</h2>\n<p>In the above data, we've done two important things.</p>\n<p><em>First</em>, we've built a <a href=\"https://en.wikipedia.org/wiki/Nowcasting_(economics)\">nowcast</a> of our underlying data. That is to say, while the number of times events <code>A</code> and <code>B</code> occur is nominally directly observable (albeit noisily), the actual number of times are not. So we can construct better estimates (as well as credible intervals) of the event occurrent counts.</p>\n<p><em>Second</em>, we've built a direct probabilistic way of computing the fundamental parameters of the problem, namely <code>alpha</code> and <code>beta</code>. In our pymc code, just as we can plot a histogram of <code>a_occurrences</code> (via <code>pl.hist(trace['a_occurred'][::20], bins=50)</code>), we can similarly plot a histogram of <code>alpha</code> itself. In many instances - e.g. <a href=\"https://cdn2.hubspot.net/hubfs/310840/VWO_SmartStats_technical_whitepaper.pdf\">A/B testing</a> or <a href=\"https://www.chrisstucchio.com/blog/2013/bayesian_bandit.html\">bandit algorithms</a> - the underlying probabilities are the parameter of direct interest. The actual counts are only incidental.</p>\n<p>The conclusion here is that missing data is not a fundamentally limiting factor in running many analysis. Provided you have a more complete generative model of data collection, and adequate data to fit the model, you can actually correct for missing data when running such analysis.</p>\n              "
}