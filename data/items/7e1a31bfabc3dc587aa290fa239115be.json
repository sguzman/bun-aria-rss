{
  "title": "Kvfrans Thoughts: A Mathematical Definition of Interestingness",
  "description": "<h2 id=\"a-mathematical-definition-of-interestingness\">A Mathematical Definition of Interestingness</h2><p>In open-endedness research, we care about building systems that continously generate interesting designs. So what makes something interesting? Previously, <a href=\"https://kvfrans.com/thoughts-oct-29/\">I argued</a> that interestestness depends on a viewer's perspective. But this answer isn't very satisfying.</p><p>Ideally, we would want some mathematically-definable way to measure how interesting</p>",
  "link": "https://kvfrans.com/kvfrans-thoughts-nov-15/",
  "guid": "6192dc0c4365cb5561d981dc",
  "category": "thoughts",
  "dc:creator": "Kevin Frans",
  "pubDate": "Mon, 06 Dec 2021 22:28:59 GMT",
  "content:encoded": "<h2 id=\"a-mathematical-definition-of-interestingness\">A Mathematical Definition of Interestingness</h2><p>In open-endedness research, we care about building systems that continously generate interesting designs. So what makes something interesting? Previously, <a href=\"https://kvfrans.com/thoughts-oct-29/\">I argued</a> that interestestness depends on a viewer's perspective. But this answer isn't very satisfying.</p><p>Ideally, we would want some mathematically-definable way to measure how interesting something is. A naive approach would to be to define interestingness as variation or entropy, but we run into the following problem:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://kvfrans.com/content/images/2021/11/image-2.png\" class=\"kg-image\" alt></figure><p>In this example, you get the highest entropy by mixing milk and coffee, since at the molecular level the particles are the most widely distributed. But somehow the middle cup is the most interesting to us as humans, since the half-mixed milk forms all sorts of cool swirls and twists.</p><p>An analogy I like to draw here is the <a href=\"https://galaxykate0.tumblr.com/post/139774965871/so-you-want-to-build-a-generator\">10,000 oatmeal problem</a>, which states:</p><blockquote>I can easily generate 10,000 bowls of plain oatmeal, with each oat being in a different position and different orientation, and <em>mathematically speaking</em> they will all be completely unique. But the user will likely just see <em>a lot of oatmeal</em>.</blockquote><p>Entropy is not all that great! Sure, we get a lot of unique designs, but at some level they all look like the same design. Something is missing in our interestingness formulation.</p><p>The best definition of interestingness I've come across so far is the idea of <em>sophistication</em>, which is mentioned in <a href=\"https://scottaaronson.blog/?p=762\">this blog post by Scott Aaronson</a>:</p><blockquote>Sophistication(x) is the length of the shortest computer program that describes, not necessarily x itself, but a set S of which x is a “random” or “generic” member.</blockquote><p>Sophistication solves our milk-coffee problem and our oatmeal problem. In both cases, the high-entropy examples can be described by very short programs – just sample random positions for each particle. Something like the swirls in the half-mixed cup has higher sophistication, since you'd need a more complicated program to generate those artifacts.</p><p>How can we apply sophistication in the context of open-endedness and machine learning? Let's say we're trying to generate a lot of interesting image. One formulation is to do something like:</p><ol><li>An image gets less reward the more times it is generated.</li><li>Continously search for high-reward images.</li></ol><p>Obviously, this formulation kind of sucks, since the space of images is really big, and we will basically end up with a lot of images of noise. Ideally, we want to eliminate all images that look like 'static noise' in one swoop, and move on to more interesting kinds of variation.</p><p>Here's a sophistication-like formulation that makes use of smarter learning:</p><ol><li>A generative adversarial network is trained to model all past images that have been generated.</li><li>An image gets less reward if the GAN's discriminator thinks it looks in-distribution.</li><li>Continuously search for high-reward images and re-train the GAN.</li></ol><p>In theory, this GAN-based formulation should explore the image space in a more efficient manner. Once a few static-noise images have been generated, the GAN can model all types of static-noise, so high-reward images need to display other kinds of variation. </p><p>The GAN-based formulation kind of resembles sophistication, where we assume that Soph(x) is just -Disc(x), i.e. an image is sophisticated if it the GAN struggles to model it correctly. As long as we're continously re-training our GAN, this approximation shouldn't be too bad.</p><p>======</p><!--kg-card-begin: html--><!---\n\nmeta-thoughts on sophistication\nit's just the same as curiosity\nwhat we get is a function of \"what states are harder to get to\"\n* because modeling by neural net is hard\n* because finding the action seq that gets here is hard\n* because creating an design that is seen as this object is hard\nhere's another option – can we just optimize directly for how hard something is to do. the interesting part is how to measure 'hard'\ndifficulty = new, but also hard to learn to do (N number of grads to imitate me)\ndifficulty = novel (tabular?)\ndifficulty = unstable\ndifficulty = shortest program to \nwhat are we trying to achieve?\nemergent behavior that is interesting, to us as humans\ntechnical: ground what it means to interesting\nat some point, we do need to tie these things back into what humans call interesting\nother definition = interesting if it can be used for downstream task\nquality-diversity -> quality-[] difficulty? diversity?\n\nagent parkour = agents in a world, and they try to mimic each other, and they get reward if they can't mimic each other, we can have a reward function to bootstrap off of. Maybe there is a cheaper way to measure 'hard to mimic' than imitation? Heuristics such as: less contact with ground, more instability, center of mass is not supported,\n(other idea = mimic)\ninnovator: trained with RL, reward = inverse of fakabilityfaker: given state sequence, output action sequence that matchesgoal-proposer: come up with a imagegoal-achiever: make imagegoal-proposer: come up with a imagegoal-achiever: autoencode this image\ngoal-proposer: come up with a clip pointgoal-achiever: make image that matches that point\nnetork input: CLIPoutput: pixelsnetwork in: CLIPOUtput: VQGAN zoutput 2: pixelsStarting point: use translator as a jump, then optimize a little bit aftergoal-proposer: uniformly sample pointsgoal-achiever: make image that matches that point\none definition that leads to inequality in clip space: some images are harder to generate sequentially\nInterestnegness is at some point philosophically a means to acheving quality.\n\n--><!--kg-card-end: html-->"
}