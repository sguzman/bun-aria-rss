{
  "title": "evolved channel selection",
  "link": "http://matpalm.com/blog/evolved_channel_selection",
  "category": [
    "projects",
    "ga",
    "jax"
  ],
  "guid": "http://matpalm.com/blog/evolved_channel_selection",
  "description": "evolved channel selection",
  "content:encoded": "<h1>multi spectral channel data</h1>\n<p><a href=\"https://github.com/phelber/eurosat\">eurosat/all</a> is a dataset\n   of 27,000 64x64 satellite images taken with 13 spectral bands.\n   each image is labelled one of ten classes.\n</p>\n<p>for the purpose of classification these 13 aren't equally useful, and the\n   information in them varies across resolutions. if we were designing a sensor\n   we might choose to use different channels in different resolutions.\n</p>\n<p>how can we explore the trade off between mixed resolutions and whether to use\n   a channel at all?\n</p>\n\n<h1>a simple baseline model</h1>\n<p>let's start with a simple baseline to see what performance we get. we won't\n   spend too much time on this model, we just want something that we can\n   iterate on quickly.\n</p>\n<p>the simple model shown below trained on a 'training' split with adam hits 0.942\n   top 1 accuracy on a 2nd 'validation' split in 5 epochs. that'll do for a start.\n</p>\n<img src=\"/blog/imgs/2021/ecs/single.svg.png\"/>\n\n\n<h1>what is the benefit of each channel?</h1>\n<p>let's check the effect of including different combos of input channels. we'll do so by\n   introducing a channel mask.\n</p>\n<p>a mask of all ones denotes using all channels and gives our baseline performance\n</p>\n<table class='data'>\n<tr><td>mask</td><td>validation accuracy</td></tr>\n<tr><td>[1,1,1,1,1,1,1,1,1,1,1,1,1]</td><td>0.942</td></tr>\n</table>\n\n<p>a mask of all zeros denotes using <em>no</em> channels and acts as a sanity check; it\n   gives the performance of random chance which is in line with what we expect\n   give the balanced training set. (note: we standardise the input data so that\n   it has zero mean per channel (with the mean, standard deviation parameters\n   fit against training data only) so we can get this effect)\n</p>\n<table class='data'>\n<tr><td>mask</td><td>validation accuracy</td></tr>\n<tr><td>[1,1,1,1,1,1,1,1,1,1,1,1,1]</td><td>0.942</td></tr>\n<tr><td>[0,0,0,0,0,0,0,0,0,0,0,0,0]</td><td>0.113</td></tr>\n</table>\n\n<p>but what about if we drop just one channel? i.e. a mask of all ones except for a single zero.\n</p>\n<table class='data'>\n<tr><td>channel to drop</td><td>validation accuracy</td></tr>\n<tr><td>0</td><td>0.735</td></tr>\n<tr><td>1</td><td>0.528</td></tr>\n<tr><td>2</td><td>0.661</td></tr>\n<tr><td>3</td><td>0.675</td></tr>\n<tr><td>4</td><td>0.809</td></tr>\n<tr><td>5</td><td>0.724</td></tr>\n<tr><td>6</td><td>0.749</td></tr>\n<tr><td>7</td><td>0.634</td></tr>\n<tr><td>8</td><td>0.874</td></tr>\n<tr><td>9</td><td>0.934</td></tr>\n<tr><td>10</td><td>0.593</td></tr>\n<tr><td>11</td><td>0.339</td></tr>\n<tr><td>12</td><td>0.896</td></tr>\n</table>\n\n<p>from this we can see that the performance hit we get from losing a single channel\n   is not always the same. in particular consider channel 11; if we drop that channel we\n   get a huge hit! does that mean that if we keep <em>only</em> 11 that should give reasonable\n   performance?\n</p>\n<table class='data'>\n<tr><td>mask</td><td>validation accuracy</td></tr>\n<tr><td>[1,1,1,1,1,1,1,1,1,1,1,1,1]</td><td>0.942</td></tr>\n<tr><td>[0,0,0,0,0,0,0,0,0,0,0,0,0]</td><td>0.113</td></tr>\n<tr><td>[0,0,0,0,0,0,0,0,0,0,0,1,0] (keep just 11)</td><td>0.260</td></tr>\n</table>\n\n<p>bbbzzzttt (or other appropriate annoying buzzer noise). channel 11\n   is contributing to the classification but it's not being used independently.\n   in general this is exactly the behaviour we want from a neural network\n   but what should we do to explore the effect of not having this dependence?\n</p>\n\n<h1>dropping out channels</h1>\n<p>consider using a dropout idea, just with input channels instead of intermediate nodes.\n</p>\n<p>what behaviour do we get if we drop channels out during\n   training? i.e. with 50% probability we replace an entire input channel with 0s?\n</p>\n<p>things take longer to train and we get a slight hit in accuracy...\n</p>\n<table class='data'>\n<tr><td>dropout?</td><td>validation accuracy</td></tr>\n<tr><td>no</td><td>0.942</td></tr>\n<tr><td>yes</td><td>0.934</td></tr>\n</table>\n\n<p>...but now when we mask out one channel at a time we don't get a big hit for losing any\n   particular one.\n</p>\n<table class='data'>\n<tr><td>channel to drop</td><td colspan=2>validation accuracy</td></tr>\n<tr><td></td><td>no dropout</td><td>with dropout</td></tr>\n<tr><td>0</td><td>0.735</td><td>0.931</td></tr>\n<tr><td>1</td><td>0.528</td><td>0.931</td></tr>\n<tr><td>2</td><td>0.661</td><td>0.936</td></tr>\n<tr><td>3</td><td>0.675</td><td>0.935</td></tr>\n<tr><td>4</td><td>0.809</td><td>0.937</td></tr>\n<tr><td>5</td><td>0.724</td><td>0.934</td></tr>\n<tr><td>6</td><td>0.749</td><td>0.931</td></tr>\n<tr><td>7</td><td>0.634</td><td>0.927</td></tr>\n<tr><td>8</td><td>0.874</td><td>0.927</td></tr>\n<tr><td>9</td><td>0.934</td><td>0.927</td></tr>\n<tr><td>10</td><td>0.593</td><td>0.927</td></tr>\n<tr><td>11</td><td>0.339</td><td>0.933</td></tr>\n<tr><td>12</td><td>0.896</td><td>0.937</td></tr>\n</table>\n\n\n<h1>evolving the channel selection</h1>\n<p>now that we have a model that is robust to any combo of channels what do we see\n   if we use a simple genetic algorithm (GA) to evolve the channel mask to use\n   with this pre trained network?\n   a mask that represents using all channels will be the best right? right?\n</p>\n<p>we'll evolve the GA using the network trained above but based on it's performance\n   on a 3rd \"ga_train\" split using the inverse loss as a fitness function.\n</p>\n<p>amusingly the GA finds that a mask of <code>[1,1,0,1,0,0,0,1,1,0,1,0,1]</code>\n   does better marginally better than all channels, but only uses 1/2 of them!\n</p>\n<table class='data'>\n<tr><td>mask</td><td>split</td><td>accuracy</td></tr>\n<tr><td>[1,1,1,1,1,1,1,1,1,1,1,1,1] (all)</td><td>ga_validate</td><td>0.934</td></tr>\n<tr><td>[1,1,0,1,0,0,0,1,1,0,1,0,1] (ga)</td><td>ga_validate</td><td>0.936</td></tr>\n</table>\n\n<p>important note: we can imagine the best performance overall would be to have the GA\n   evolve not the channels to use from this model, but the channels to use when training <em>from\nscratch</em>. this would though require a lot more model training, basically a full training\n   cycle per fitness evaluation :( in the approach we describe here\n   we only have to train a single model and then have the GA just run inference.\n</p>\n\n<h1>what about different resolutions?</h1>\n<p>taking the idea of channel selection a step further, what if we got the GA to not\n   only decide whether to use a channel or not, but also <em>what resolution</em> it should be\n   in?\n</p>\n<p>consider some example images across resolutions....\n</p>\n<table class='data'>\n<tr><td colspan=4>example images (just RGB channels shown)</td></tr>\n<tr><td>orig x64</td><td>x32</td><td>x16</td><td>x8</td>\n<tr>\n<td><img src=\"/blog/imgs/2021/ecs/i05_x64.png\" width='128'/></td>\n<td><img src=\"/blog/imgs/2021/ecs/i05_x32.png\" width='128'/></td>\n<td><img src=\"/blog/imgs/2021/ecs/i05_x16.png\" width='128'/></td>\n<td><img src=\"/blog/imgs/2021/ecs/i05_x08.png\" width='128'/></td>\n</tr>\n<tr>\n<td><img src=\"/blog/imgs/2021/ecs/i06_x64.png\" width='128'/></td>\n<td><img src=\"/blog/imgs/2021/ecs/i06_x32.png\" width='128'/></td>\n<td><img src=\"/blog/imgs/2021/ecs/i06_x16.png\" width='128'/></td>\n<td><img src=\"/blog/imgs/2021/ecs/i06_x08.png\" width='128'/></td>\n</tr>\n<tr>\n<td><img src=\"/blog/imgs/2021/ecs/i08_x64.png\" width='128'/></td>\n<td><img src=\"/blog/imgs/2021/ecs/i08_x32.png\" width='128'/></td>\n<td><img src=\"/blog/imgs/2021/ecs/i08_x16.png\" width='128'/></td>\n<td><img src=\"/blog/imgs/2021/ecs/i08_x08.png\" width='128'/></td>\n</tr>\n</table>\n\n<p>we could then weight the use of a channel based on resolution; the higher the resolution\n   the more the channel \"costs\" to use, with not using the channel at all being \"free\".\n</p>\n<p>to support this we can change the GA to represent members not as a string of {0, 1}s\n   but instead a sequence of {0, x8, x16, x32, x64} values per channel where these represent...\n</p>\n<table class='data'>\n<tr><td><b>resolution</b></td><td><b>description</b></td><td><b>channel cost<b/></td></tr>\n<tr><td>x64</td><td>use original (64, 64) version of input</td><td>0.8</td></tr>\n<tr><td>x32</td><td>use a 1/2 res (32, 32) version of input</td><td>0.4</td></tr>\n<tr><td>x16</td><td>use a 1/4 res (16, 16) version of input</td><td>0.2</td></tr>\n<tr><td>x8</td><td>use a 1/8 res (8, 8) version of input</td><td>0.1</td></tr>\n<tr><td>0</td><td>don't use channel</td><td>0</td></tr>\n</table>\n\n<p>the change in the encoding of our GA is trivial, just 5 values per channel instead of 2,\n   but before we look at that; how do we change our network?\n</p>\n<p>we can do it without having to add too many extra parameters by using the magic of fully\n   convolutional networks :)\n</p>\n<p>notice how the main trunk of our first network was a series of 2d convolutions\n   with a global spatial mean. this network will simply take as input all the\n   resolutions we need! we can simply reuse it multiple times!\n</p>\n<p>so we can have our network...\n</p>\n<ol>\n <li>\n     take the original x64 input\n </li>\n\n <li>\n     downsample it multiple times to x32, x16 and x8\n </li>\n\n <li>\n     mask out the channels so that each channel is only represented in one of the resolutions (or not\n     represented at all if we want to ignore that channel)\n </li>\n\n <li>\n     run the main trunk network with shared parameters on each of the masked resolutions\n </li>\n\n <li>\n     combine the outputs with a simple channel concatenation\n </li>\n\n <li>\n     do one more non linear mixing (because, why not..)\n </li>\n\n <li>\n     finish with the logits\n </li>\n</ol>\n<img src=\"/blog/imgs/2021/ecs/multi_res.svg.png\"/>\n\n<p>note: try as i might i can't get steps 2 to 4 to run parallelised in a pmap.\n   <a href=\"https://github.com/google/jax/discussions/5895\">asked on github about it</a>\n   and looks to be something you can't do at the moment.\n</p>\n\n<h1>the channel cost vs loss pareto front</h1>\n<p>when we consider channel cost vs loss there is no single best solution, it's a classic\n   example of a\n   <a href=\"https://en.wikipedia.org/wiki/Pareto_efficiency\">pareto front</a>\n   where we see a tradeoff between the channel_cost and loss.\n</p>\n<p>consider this sampling of 1,000 random channel masks...\n</p>\n<img src=\"/blog/imgs/2021/ecs/pareto_front.just_random.png\"/>\n\n\n<h1>rerunning the GA</h1>\n<p>the GA needs to operate with a fitness that's a single scalar; for now we just use\n   a simple combo of <code>(1.0 / loss) - channel_cost</code>\n</p>\n<p>running with this fitness function we evolve the solution\n   <code>[x16, x64, x64, x16, x32, ignore, x8, x64, x8, ignore, x8, ignore, x32]</code>\n</p>\n<p>it's on the pareto front, as we'd hope, and it's interesting that it includes\n   a mix of resolutions including ignoring 3 channels completely :)\n</p>\n<img src=\"/blog/imgs/2021/ecs/pareto_front.with_ga.png\"/>\n\n<p>different mixings of loss and channel_cost would result in different GA solutions along the front\n</p>\n\n<h1>code</h1>\n<p>all the code is <a href=\"https://github.com/matpalm/evolved_channel_selection\">on github</a>\n</p>"
}