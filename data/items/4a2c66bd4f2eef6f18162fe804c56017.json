{
  "title": "DP$^2$-VAE: Differentially Private Pre-trained Variational Autoencoders. (arXiv:2208.03409v2 [cs.LG] UPDATED)",
  "link": "http://arxiv.org/abs/2208.03409",
  "description": "<p>Modern machine learning systems achieve great success when trained on large\ndatasets. However, these datasets usually contain sensitive information (e.g.\nmedical records, face images), leading to serious privacy concerns.\nDifferentially private generative models (DPGMs) emerge as a solution to\ncircumvent such privacy concerns by generating privatized sensitive data.\nSimilar to other differentially private (DP) learners, the major challenge for\nDPGM is also how to achieve a subtle balance between utility and privacy. We\npropose DP$^2$-VAE, a novel training mechanism for variational autoencoders\n(VAE) with provable DP guarantees and improved utility via \\emph{pre-training\non private data}. Under the same DP constraints, DP$^2$-VAE minimizes the\nperturbation noise during training, and hence improves utility. DP$^2$-VAE is\nvery flexible and easily amenable to many other VAE variants. Theoretically, we\nstudy the effect of pretraining on private data. Empirically, we conduct\nextensive experiments on image datasets to illustrate our superiority over\nbaselines under various privacy budgets and evaluation metrics.\n</p>",
  "dc:creator": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_D/0/1/0/all/0/1\">Dihong Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1\">Guojun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karami_M/0/1/0/all/0/1\">Mahdi Karami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_Y/0/1/0/all/0/1\">Yunfeng Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yaoliang Yu</a>"
}