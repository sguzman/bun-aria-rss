{
  "title": "GPU Powered DeepLearning with NVIDIA DIGITS on EC2",
  "link": "https://www.joyofdata.de/blog/gpu-powered-deeplearning-with-nvidia-digits/",
  "comments": "https://www.joyofdata.de/blog/gpu-powered-deeplearning-with-nvidia-digits/#comments",
  "pubDate": "Sat, 25 Apr 2015 20:26:13 +0000",
  "dc:creator": "Raffael Vogler",
  "category": [
    "Machine Learning",
    "Deep Learning",
    "GPU",
    "Kaggle"
  ],
  "guid": "http://www.joyofdata.de/blog/?p=3524",
  "description": "In this tutorial I am going to show you how to set up CUDA 7, cuDNN, caffe and DIGITS on a g2.2xlarge EC2 instance (running Ubuntu 14.04 64 bit) and how to get started with DIGITS. For illustrating DIGITS&#8217; application &#8230; <a href=\"https://www.joyofdata.de/blog/gpu-powered-deeplearning-with-nvidia-digits/\">Continue reading <span class=\"meta-nav\">&#8594;</span></a>",
  "content:encoded": "<p style=\"text-align: justify;\"><img class=\"alignright wp-image-3536 size-thumbnail\" src=\"http://www.joyofdata.de/blog/wp-content/uploads/2015/04/activations-e1429992979162-150x150.png\" alt=\"activations\" width=\"150\" height=\"150\" />In this tutorial I am going to show you how to set up <a href=\"http://en.wikipedia.org/wiki/CUDA\" target=\"_blank\" rel=\"noopener noreferrer\">CUDA 7</a>, <a href=\"https://developer.nvidia.com/cuDNN\" target=\"_blank\" rel=\"noopener noreferrer\">cuDNN</a>, <a href=\"http://caffe.berkeleyvision.org/\" target=\"_blank\" rel=\"noopener noreferrer\">caffe</a> and <a href=\"https://github.com/NVIDIA/DIGITS\" target=\"_blank\" rel=\"noopener noreferrer\">DIGITS</a> on a <a href=\"http://aws.amazon.com/ec2/instance-types/\" target=\"_blank\" rel=\"noopener noreferrer\">g2.2xlarge</a> EC2 instance (running Ubuntu 14.04 64 bit) and how to get started with DIGITS. For illustrating DIGITS&#8217; application I use a current <a href=\"http://www.kaggle.com/c/diabetic-retinopathy-detection\" target=\"_blank\" rel=\"noopener noreferrer\">Kaggle competition about detecting diabetic retinopathy</a> and its state from <a href=\"http://en.wikipedia.org/wiki/Fluorescein_angiography\" target=\"_blank\" rel=\"noopener noreferrer\">fluorescein angiography</a>.</p>\n<h1 style=\"text-align: justify;\">Convolutional Deep Neural Networks for Image Classification</h1>\n<p style=\"text-align: justify;\">For classification or regression on images you have two choices:</p>\n<ul style=\"text-align: justify;\">\n<li>Feature engineering and upon that translating an image into a vector</li>\n<li>Relying on a <a href=\"http://en.wikipedia.org/wiki/Convolutional_neural_network\" target=\"_blank\" rel=\"noopener noreferrer\">convolutional DNN</a> to figure out the features</li>\n</ul>\n<p><span id=\"more-3524\"></span></p>\n<p style=\"text-align: justify;\">Deep Neural Networks are computationally quite demanding. This is the case for two reasons:</p>\n<ul style=\"text-align: justify;\">\n<li>The input data is much larger if you use even a small image resolution of 256 x 256 RGB-pixel implies 196&#8217;608 input neurons (256 x 256 x 3). If you engineer your features intelligently then a 1000 neurons would be a lot already.</li>\n<li>Saddling the network with the burden of figuring out the relevant features also requires a more sophisticated network structure and more layers.</li>\n</ul>\n<p style=\"text-align: justify;\">Luckily many of the involved floating point matrix operations have been unintentionally addressed by your<a href=\"http://www.nvidia.com/object/what-is-gpu-computing.html\" target=\"_blank\" rel=\"noopener noreferrer\"> graphic card&#8217;s GPU</a>.</p>\n<h1 style=\"text-align: justify;\">NVIDIA DIGITS and caffe</h1>\n<p><span class=\"alignright\"></span></p>\n<p style=\"text-align: justify;\">There are three major GPU utilizing Deep Learning frameworks available &#8211; <a href=\"http://deeplearning.net/software/theano/\" target=\"_blank\" rel=\"noopener noreferrer\">Theano</a>, <a href=\"http://torch.ch/\" target=\"_blank\" rel=\"noopener noreferrer\">Torch</a> and caffe. <a href=\"https://developer.nvidia.com/digits\" target=\"_blank\" rel=\"noopener noreferrer\">NVIDIA DIGITS</a> is a web server providing a convenient web interface for training and testing Deep Neural Networks based on caffe. I intend to cover in a future article how to work with caffe. Here I will show you how to set up CUDA</p>\n<p style=\"text-align: justify;\">First of all you need an AWS account and g2.2xlarge instance up and running. That is mostly self-explanatory &#8211; for the command line parts (and some tips) you might want to have a look at my previous tutorial &#8220;<a href=\"http://www.joyofdata.de/blog/guide-to-aws-ec2-on-cli/\" target=\"_blank\" rel=\"noopener noreferrer\">Guide to EC2 from the Command Line</a>&#8220;. Make sure to add an inbound rule for port 5000 for your IP &#8211; b/c this is where the DIGITS server is made available at.</p>\n<p></p><pre class=\"crayon-plain-tag\"># don't forget to get your system up to date\nsudo apt-get update\nsudo apt-get dist-upgrade</pre><p></p>\n<h1>Installing CUDA 7</h1>\n<p>Main source for this step is <a href=\"http://markus.com/install-theano-on-aws/\" target=\"_blank\" rel=\"noopener noreferrer\">Markus Beissinger&#8217;s blog post on setting up Theano</a>.</p><pre class=\"crayon-plain-tag\"># installation of required tools\nsudo apt-get install -y gcc g++ gfortran build-essential \\\n  git wget linux-image-generic libopenblas-dev python-dev \\\n  python-pip python-nose python-numpy python-scipy\n\n# downloading the (currently) most recent version of CUDA 7\nsudo wget http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1404/x86_64/cuda-repo-ubuntu1404_7.0-28_amd64.deb\n\n# installing CUDA\nsudo dpkg -i cuda-repo-ubuntu1404_7.0-28_amd64.deb\n\nsudo apt-get update\nsudo apt-get install cuda\n\n# setting the environment variables so CUDA will be found\necho -e \"\\nexport PATH=/usr/local/cuda/bin:$PATH\" >> .bashrc\necho -e \"\\nexport LD_LIBRARY_PATH=/usr/local/cuda/lib64\" >> .bashrc\n\nsudo reboot\n\n# installing the samples and checking the GPU\ncuda-install-samples-7.0.sh ~/\ncd NVIDIA\\_CUDA-7.0\\_Samples/1\\_Utilities/deviceQuery  \nmake  \n./deviceQuery</pre><p></p>\n<h1>Installing cuDNN</h1>\n<p style=\"text-align: justify;\">To further speed up deep learning relevant calculations it is a good idea to set up the cuDNN library. For that purpose you will have to get an NVIDIA developer account and join the CUDA registered developer program. The last step requires NVIDIA to unlock your account  and that might take one or two days. But you can get started also without cuDNN library. As soon as you have the okay from them &#8211; <a href=\"https://developer.nvidia.com/cuDNN\" target=\"_blank\" rel=\"noopener noreferrer\">download cuDNN</a> and upload it to your instance.</p>\n<p></p><pre class=\"crayon-plain-tag\"># unpack the library\ngzip -d cudnn-6.5-linux-x64-v2.tar.gz\ntar xf cudnn-6.5-linux-x64-v2.tar\n\n# copy the library files into CUDA's include and lib folders\nsudo cp cudnn-6.5-linux-x64-v2/cudnn.h /usr/local/cuda-7.0/include\nsudo cp cudnn-6.5-linux-x64-v2/libcudnn* /usr/local/cuda-7.0/lib64</pre><p></p>\n<h1>Installing caffe</h1>\n<p>Main source for this and the following step is the <a href=\"https://github.com/NVIDIA/DIGITS/blob/master/README.md\" target=\"_blank\" rel=\"noopener noreferrer\">readme of the DIGITS project</a>.</p><pre class=\"crayon-plain-tag\">sudo apt-get install libprotobuf-dev libleveldb-dev \\\n  libsnappy-dev libopencv-dev libboost-all-dev libhdf5-serial-dev \\\n  libgflags-dev libgoogle-glog-dev liblmdb-dev protobuf-compiler \\\n  libatlas-base-dev\n\n# the version number of the required branch might change\n# consult https://github.com/NVIDIA/DIGITS/blob/master/README.md\ngit clone --branch v0.11.0 https://github.com/NVIDIA/caffe.git\n\ncd ~/caffe/python\nfor req in $(cat requirements.txt); do sudo pip install $req; done\n\ncd ~/caffe\ncp Makefile.config.example Makefile.config\n\n# check that USE_CUDNN is set to 1 in case you would\n# like to use it and to 0 if not\n\nmake all\nmake py\nmake test\nmake runtest\n\necho -e \"\\nexport CAFFE_HOME=/home/ubuntu/caffe\" >> ~/.bashrc\n\n# load the new environmental variables\nbash</pre><p></p>\n<h1>Installing DIGITS</h1>\n<p></p><pre class=\"crayon-plain-tag\">cd ~\ngit clone https://github.com/NVIDIA/DIGITS.git digits\ncd digits\nsudo apt-get install graphviz gunicorn\nfor req in $(cat requirements.txt); do sudo pip install $req; done</pre><p></p>\n<h1>Starting and Configuring DIGITS</h1>\n<p style=\"text-align: justify;\">The first time you start DIGITS it will ask you number of questions for the purpose of its configuration. But those settings are pretty much self-explanatory and you can change them afterwards in <pre class=\"crayon-plain-tag\">~/.digits/digits.cfg</pre> . You might want to consider locating your job-directory (<pre class=\"crayon-plain-tag\">jobs_dir</pre>) on an <a href=\"http://aws.amazon.com/ebs/\" target=\"_blank\" rel=\"noopener noreferrer\">EBS</a> &#8211; the data set of about 140&#8217;000 PNGs in the example I feature here consumes about 10 GB of space and the trained models (with all its model snapshots) accounts for about 1 GB.</p>\n<p></p><pre class=\"crayon-plain-tag\"># change into your digits directory\ncd digits\n\n# start the server\n./digits-devserver</pre><p></p>\n<h1>Troubleshooting DIGITS</h1>\n<p style=\"text-align: justify;\">When you start DIGITS for the first time you might run into a number of errors and warnings. Here&#8217;s my take on them.</p>\n<p></p><pre class=\"crayon-plain-tag\">\"libdc1394 error: Failed to initialize libdc1394\"\n\n# no big deal - either ignore or treat symptomatically\nsudo ln /dev/null /dev/raw1394</pre><p></p><pre class=\"crayon-plain-tag\">\"Gtk-WARNING **: Locale not supported by C library.\"\n\n# not sure how serious this is - but it is easy to resolve\nsudo apt-get install language-pack-en-base\nsudo dpkg-reconfigure locales\n\n# check what locales are available and then ...\nlocale -a\n# ... set LC_ALL to it\necho -e \"\\nexport LC_ALL=\\\"en_US.utf8\\\"\" >> ~/.bashrc</pre><p></p><pre class=\"crayon-plain-tag\">\"Gdk-CRITICAL **: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed\"\n\n# this is a big deal and will cause the server start up to fail:\n# connect with ssh flags -Xi\nssh -Xi ...</pre><p></p><pre class=\"crayon-plain-tag\">\"Couldn't import dot_parser, loading of dot files will not be possible.\"\n\n# reinstall pyparsing:\nsudo pip uninstall pyparsing\nsudo pip install pyparsing==1.5.7\nsudo pip install pydot</pre><p></p>\n<h1>Getting Started with DIGITS</h1>\n<p style=\"text-align: justify;\"><a href=\"http://www.joyofdata.de/blog/wp-content/uploads/2015/04/digits_new_dataset.png\"><img class=\"alignright size-medium wp-image-3533\" src=\"http://www.joyofdata.de/blog/wp-content/uploads/2015/04/digits_new_dataset-300x194.png\" alt=\"digits_new_dataset\" width=\"300\" height=\"194\" srcset=\"https://www.joyofdata.de/blog/wp-content/uploads/2015/04/digits_new_dataset-300x194.png 300w, https://www.joyofdata.de/blog/wp-content/uploads/2015/04/digits_new_dataset-1024x663.png 1024w, https://www.joyofdata.de/blog/wp-content/uploads/2015/04/digits_new_dataset-463x300.png 463w, https://www.joyofdata.de/blog/wp-content/uploads/2015/04/digits_new_dataset.png 1174w\" sizes=\"(max-width: 300px) 100vw, 300px\" /></a>First you have to create the data set on which you want to train a model. You have to provide at least one large set of pictures for the training and optionally two smaller sets for validation and testing. You can either separate those sets (and their correct labels) by means of different folders or &#8211; what I&#8217;d recommend &#8211; by providing corresponding CSVs. Those CSVs are supposed to feature two unnamed tab separated columns. The first column keeps the full path of the image (don&#8217;t use <pre class=\"crayon-plain-tag\">~</pre> for home, but the its path equivalent) and the second column keeps a 0-based index referencing the correct class. You will also have to provide a text file holding the different classes &#8211; one per line. <a href=\"http://www.joyofdata.de/blog/wp-content/uploads/2015/04/digits_new_model.png\"><img class=\"alignleft wp-image-3534 size-medium\" src=\"http://www.joyofdata.de/blog/wp-content/uploads/2015/04/digits_new_model-276x300.png\" alt=\"digits_new_model\" width=\"276\" height=\"300\" srcset=\"https://www.joyofdata.de/blog/wp-content/uploads/2015/04/digits_new_model-276x300.png 276w, https://www.joyofdata.de/blog/wp-content/uploads/2015/04/digits_new_model.png 879w\" sizes=\"(max-width: 276px) 100vw, 276px\" /></a>For example if you have two classes &#8220;pos&#8221; (1st line) and &#8220;neg&#8221; (2nd line) &#8211; then an image belonging to class &#8220;pos&#8221; would have to have a class index of 0 associated with it. Loading might take a while. Loading my 140&#8217;000 PNGs with 256&#215;256 resolution took about one hour.</p>\n<p style=\"text-align: justify;\">Setting up the model you intend to train is even easier provided you stick with the suggested defaults &#8211; just choose the data set you want to use, a network and you&#8217;re ready to go! Training a <a href=\"http://arxiv.org/abs/1409.4842\" target=\"_blank\" rel=\"noopener noreferrer\">GoogLeNet</a> for 30 epochs on the described data set took about one day and 6 hours. This is why you should make sure that &#8230;</p>\n<ul>\n<li style=\"text-align: justify;\">&#8230; your bidding for a Spot instance is not too low &#8211; or you risk it being terminated</li>\n<li style=\"text-align: justify;\">&#8230; you start the server in <a href=\"http://en.wikipedia.org/wiki/Tmux\" target=\"_blank\" rel=\"noopener noreferrer\">tmux</a> session. Otherwise if you lose connection &#8211; maybe b/c your IP changes over night &#8211; the server process will be killed</li>\n</ul>\n<h1>Tackling the Diabetic Retinopathy Kaggle challenge</h1>\n<p><span class=\"alignright\"></span></p>\n<p style=\"text-align: justify;\">The provided training set consists of about 35 thousand images of high resolution &#8211; zipped and split accross five files. The whole zip archive is about 33 GB large. I downloaded the five components directly onto an EBS using lynx &#8211; b/c you can just regularly log on and initiate the download. The download speed on the g2.2xlarge instance btw was incredible &#8211; you are granted up to 100 MB per second. I started all five downloads in parallel &#8211; each going at 6 MB per second. And yes, its mega byte &#8211; not mega bit (the unit DSL providers use).</p>\n<p style=\"text-align: justify;\">The visible indicators of diabetic retinopathy are as I understand it mostly leaking (aneurysms) and pathologically growing blood vessels. I figure those features are mirror and rotation invariant. So to increase the available training set I created four versions:</p>\n<ul style=\"text-align: justify;\">\n<li>(A): As is but resized to 256&#215;256 pixels and saved as PNG</li>\n<li>(R): 180 degree rotation of (A)</li>\n<li>Vertical mirroring of (A)</li>\n<li>Vertical mirroring of (R)</li>\n</ul>\n<p style=\"text-align: justify;\">Because the task at hand is obviously not a classification but a regression I abstained from attempting to learn a classification into no DR and the four stages of DR. I labelled all DR cases as &#8220;positive&#8221; and the no-DR cases respectively as &#8220;negative&#8221;. This would have to be done for all four possible splits ({0} vs {1,&#8230;,4}, &#8230;, {0,&#8230;,3},{4}) and those predictions would finally be regressed against the actual stage.</p>\n<p>The bash script for this transformation you may find on <a href=\"https://github.com/joyofdata/joyofdata-articles/blob/master/installing-digits/transform-and-duplicate-training-images.sh\" target=\"_blank\" rel=\"noopener noreferrer\">bash commands for the processing</a>.</p>\n<p style=\"text-align: center; border: 1px solid #378efd\">\n<img src=\"http://www.joyofdata.de/blog/wp-content/uploads/2015/05/stay-tuned.png\" alt=\"stay-tuned\" style=\"padding-right:30px; height:30px\"/>\n\n<a href=\"https://twitter.com/joyofdata\" target=\"new\" style=\"padding-right:20px\">\n<img src=\"http://www.joyofdata.de/blog/wp-content/uploads/2015/05/twitter.png\" alt=\"twitter\" height=\"28\" /></a>\n<a href=\"http://feedly.com/i/subscription/feed/http://www.joyofdata.de/blog/feed/\" target=\"new\" style=\"padding-right:20px\">\n<img src=\"http://www.joyofdata.de/blog/wp-content/uploads/2015/05/feedly.png\" alt=\"feedly\" width=\"30\" height=\"30\" /></a>\n<a href=\"https://github.com/joyofdata\" target=\"new\" style=\"padding-right:20px\">\n<img src=\"http://www.joyofdata.de/blog/wp-content/uploads/2015/05/github.png\" alt=\"github\" width=\"30\" height=\"30\" /></a>\n</p>\n<h1>The Result</h1>\n<p style=\"text-align: justify;\"><a href=\"http://www.joyofdata.de/blog/wp-content/uploads/2015/04/GoogLeNet.png\"><img class=\"alignright wp-image-3532 size-medium\" src=\"http://www.joyofdata.de/blog/wp-content/uploads/2015/04/GoogLeNet-300x212.png\" alt=\"GoogLeNet\" width=\"300\" height=\"212\" srcset=\"https://www.joyofdata.de/blog/wp-content/uploads/2015/04/GoogLeNet-300x212.png 300w, https://www.joyofdata.de/blog/wp-content/uploads/2015/04/GoogLeNet-425x300.png 425w, https://www.joyofdata.de/blog/wp-content/uploads/2015/04/GoogLeNet.png 716w\" sizes=\"(max-width: 300px) 100vw, 300px\" /></a>Well &#8230; on one hand I would have liked to see a higher accuracy &#8211; on the other hand I can barely (if at all) make out the difference between some healthy cases and some extreme stage four cases. As 73.95% is the share of negative cases &#8211; this is also were the accuracy of the network started out at. In the course of 30 epochs it improved about 8 p.p. to 81.8%.</p>\n<h1>Any Questions?</h1>\n<p style=\"text-align: justify;\">I highly recommend the <a href=\"https://groups.google.com/forum/#!forum/digits-users\" target=\"_blank\" rel=\"noopener noreferrer\">DIGITS Google Group</a> for your questions on features and issues. The developers of DIGITS are very helpful and open for suggestions.</p>\n<hr />\n<p style=\"text-align: justify;\">(original article published on <a href=\"http://www.joyofdata.de/blog/gpu-powered-deeplearning-with-nvidia-digits/\">www.joyofdata.de</a>)</p>\n",
  "wfw:commentRss": "https://www.joyofdata.de/blog/gpu-powered-deeplearning-with-nvidia-digits/feed/",
  "slash:comments": 8
}