{
  "title": "Selection of K in K-means Clustering, Reloaded",
  "link": "https://datasciencelab.wordpress.com/2014/01/21/selection-of-k-in-k-means-clustering-reloaded/",
  "comments": "https://datasciencelab.wordpress.com/2014/01/21/selection-of-k-in-k-means-clustering-reloaded/#comments",
  "dc:creator": "datasciencelab",
  "pubDate": "Tue, 21 Jan 2014 14:43:04 +0000",
  "category": [
    "Experiments",
    "clustering",
    "k-means",
    "unsupervised learning"
  ],
  "guid": "http://datasciencelab.wordpress.com/?p=661",
  "description": "This article follows up on the series devoted to k-means clustering at The Data Science Lab. Previous posts have dealt with how to implement Lloyd&#8217;s algorithm for clustering in python, described an improved initialization algorithm for proper seeding of the initial clusters, k-means++, and introduced the gap statistic as a method of finding the optimal [&#8230;]",
  "content:encoded": "<p>This article follows up on the series devoted to <a href=\"https://datasciencelab.wordpress.com/tag/k-means/\">k-means clustering at The Data Science Lab</a>. Previous posts have dealt with how to implement <a title=\"Clustering With K-Means in Python\" href=\"https://datasciencelab.wordpress.com/2013/12/12/clustering-with-k-means-in-python/\">Lloyd&#8217;s algorithm</a> for clustering in python, described an improved initialization algorithm for <a title=\"Improved Seeding For Clustering With K-Means++\" href=\"https://datasciencelab.wordpress.com/2014/01/15/improved-seeding-for-clustering-with-k-means/\">proper seeding of the initial clusters, k-means++</a>, and introduced the <a title=\"Finding the K in K-Means Clustering\" href=\"https://datasciencelab.wordpress.com/2013/12/27/finding-the-k-in-k-means-clustering/\">gap statistic as a method of finding the optimal K for k-means clustering</a>.</p>\n<p>Although the gap statistic, based on a paper by <a href=\"http://www.stanford.edu/~hastie/Papers/gap.pdf\">Tibshirani et al</a> was shown to find optimal values for the number of clusters in a variety of cases when the clusters where globular and mildly disjointed, its performance might be hampered by the need of perfoming Monte Carlo simulations to estimate the reference datasets. A reader of this blog, <a href=\"http://jonathanstray.com/\">Jonathan Stray</a>, <a href=\"https://datasciencelab.wordpress.com/2013/12/27/finding-the-k-in-k-means-clustering/comment-page-1/#comment-17\">pointed out</a> a potentially superior method for selecting the K in k-means clustering, so let us implement it and compare.</p>\n<h3>An alternative approach to finding the optimal K</h3>\n<p>The approach suggested by our reader is based on a publication by <a href=\"http://www.ee.columbia.edu/~dpwe/papers/PhamDN05-kmeans.pdf\">Pham, Dimov and Nguyen from 2004</a>. The article is very much worth reading, as it includes an explanation of the drawbacks of the standard k-means algorithm as well as a comprehensive survey on different methods that have been proposed for selecting an optimal number of clusters.</p>\n<p>In section 3 of the paper, the authors justify the introduction of a function <img src=\"https://s0.wp.com/latex.php?latex=f%28K%29&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=f%28K%29&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%28K%29&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"f(K)\" class=\"latex\" /> to evaluate the quality of the resulting clustering and help decide on the optimal value of <img src=\"https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"K\" class=\"latex\" /> for each data set. Quoting from the paper:</p>\n<blockquote><p>A data set with <img src=\"https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"n\" class=\"latex\" /> objects could be grouped into any number of clusters between 1 and <img src=\"https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"n\" class=\"latex\" />, which would correspond to the lowest and the highest levels of detail respectively. By specifying different <img src=\"https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"K\" class=\"latex\" /> values, it is possible to assess the results of grouping objects into various numbers of clusters. From this evaluation, more than one <img src=\"https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"K\" class=\"latex\" /> value could be recommended to users, but the ﬁnal selection is made by them.</p></blockquote>\n<p>The goal of a clustering algorithm is to identify regions in which the data points are concentrated. It is also important to analyze the internal distribution of each cluster as well as its relation to other clusters in the data set. The distorsion of a cluster is a measure of the distance between points in a cluster and its centroid:</p>\n<p style=\"text-align:center;\"><img src=\"https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+I_j+%3D+%5Csum_%7B%5Cmathrm%7Bx%7D_i+%5Cin+C_j%7D+%7C%7C%5Cmathrm%7Bx%7D_i+-+%5Cmu_j+%7C%7C%5E2&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+I_j+%3D+%5Csum_%7B%5Cmathrm%7Bx%7D_i+%5Cin+C_j%7D+%7C%7C%5Cmathrm%7Bx%7D_i+-+%5Cmu_j+%7C%7C%5E2&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+I_j+%3D+%5Csum_%7B%5Cmathrm%7Bx%7D_i+%5Cin+C_j%7D+%7C%7C%5Cmathrm%7Bx%7D_i+-+%5Cmu_j+%7C%7C%5E2&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;displaystyle I_j = &#92;sum_{&#92;mathrm{x}_i &#92;in C_j} ||&#92;mathrm{x}_i - &#92;mu_j ||^2\" class=\"latex\" />.</p>\n<p>The global impact of all clusters&#8217; distortions is given by the quantity </p>\n<p style=\"text-align:center;\"><img src=\"https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+S_k+%3D+%5Csum_%7Bj%3D1%7D%5EK+I_j&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+S_k+%3D+%5Csum_%7Bj%3D1%7D%5EK+I_j&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+S_k+%3D+%5Csum_%7Bj%3D1%7D%5EK+I_j&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;displaystyle S_k = &#92;sum_{j=1}^K I_j\" class=\"latex\" />.</p>\n<p>The authors Pham et al. proceed to discuss further constrains that the sought-after function <img src=\"https://s0.wp.com/latex.php?latex=f%28K%29&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=f%28K%29&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%28K%29&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"f(K)\" class=\"latex\" /> should verify for it to be informative to the problem of selection of K. They finally arrive at the following definition:</p>\n<p style=\"text-align:center;\"><a href=\"https://datasciencelab.files.wordpress.com/2014/01/fk.png\"><img loading=\"lazy\" data-attachment-id=\"668\" data-permalink=\"https://datasciencelab.wordpress.com/2014/01/21/selection-of-k-in-k-means-clustering-reloaded/fk/\" data-orig-file=\"https://datasciencelab.files.wordpress.com/2014/01/fk.png\" data-orig-size=\"939,502\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\"}\" data-image-title=\"fK\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://datasciencelab.files.wordpress.com/2014/01/fk.png?w=300\" data-large-file=\"https://datasciencelab.files.wordpress.com/2014/01/fk.png?w=830\" class=\"wp-image-668 aligncenter\" alt=\"fK\" src=\"https://datasciencelab.files.wordpress.com/2014/01/fk.png?w=359&#038;h=192\" width=\"359\" height=\"192\" srcset=\"https://datasciencelab.files.wordpress.com/2014/01/fk.png?w=359&h=192 359w, https://datasciencelab.files.wordpress.com/2014/01/fk.png?w=718&h=384 718w, https://datasciencelab.files.wordpress.com/2014/01/fk.png?w=150&h=80 150w, https://datasciencelab.files.wordpress.com/2014/01/fk.png?w=300&h=160 300w\" sizes=\"(max-width: 359px) 100vw, 359px\" /></a></p>\n<p><img src=\"https://s0.wp.com/latex.php?latex=N_d&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=N_d&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=N_d&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"N_d\" class=\"latex\" /> is the number of dimensions (attributes) of the data set and <img src=\"https://s0.wp.com/latex.php?latex=%5Calpha_K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Calpha_K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha_K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;alpha_K\" class=\"latex\" /> is a weight factor. With this definition, <img src=\"https://s0.wp.com/latex.php?latex=f%28K%29&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=f%28K%29&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%28K%29&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"f(K)\" class=\"latex\" />  is the ratio of the real distortion to the estimated distortion and decreases when there are areas of concentration in the data distribution. Values of <img src=\"https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"K\" class=\"latex\" /> that yield small <img src=\"https://s0.wp.com/latex.php?latex=f%28K%29&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=f%28K%29&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%28K%29&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"f(K)\" class=\"latex\" /> can be regarded as giving well-deﬁned clusters.</p>\n<h3>A python implementation of Pham et al. f(K)</h3>\n<p>Our implementation of the Pham et al. procedure builds on the <code>KMeans</code> and <code>KPlusPlus</code> python classes defined in our <a href=\"https://datasciencelab.wordpress.com/2014/01/15/improved-seeding-for-clustering-with-k-means/\" title=\"Improved Seeding For Clustering With K-Means++\">article on the k-means++ algorithm</a>. We define a new class that inherits from <code>KPlusPlus</code> and contains a function to compute <img src=\"https://s0.wp.com/latex.php?latex=f%28K%29&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=f%28K%29&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%28K%29&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"f(K)\" class=\"latex\" />:</p>\n<pre class=\"brush: python; title: ; notranslate\">\nclass DetK(KPlusPlus):\n    def fK(self, thisk, Skm1=0):\n        X = self.X\n        Nd = len(X[0])\n        a = lambda k, Nd: 1 - 3/(4*Nd) if k == 2 else a(k-1, Nd) + (1-a(k-1, Nd))/6\n        self.find_centers(thisk, method='++')\n        mu, clusters = self.mu, self.clusters\n        Sk = sum([np.linalg.norm(mu[i]-c)**2 \\\n                 for i in range(thisk) for c in clusters[i]])\n        if thisk == 1:\n            fs = 1\n        elif Skm1 == 0:\n            fs = 1\n        else:\n            fs = Sk/(a(thisk,Nd)*Skm1)\n        return fs, Sk   \n</pre>\n<p>Note the recursive definition of <img src=\"https://s0.wp.com/latex.php?latex=%5Calpha_K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Calpha_K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha_K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;alpha_K\" class=\"latex\" /> (variable <code>a</code> in the code snapshot above) and the fact that the computation of <img src=\"https://s0.wp.com/latex.php?latex=S_K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=S_K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S_K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"S_K\" class=\"latex\" /> for <img src=\"https://s0.wp.com/latex.php?latex=K+%3E+1&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=K+%3E+1&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=K+%3E+1&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"K > 1\" class=\"latex\" /> requires knowing the value of <img src=\"https://s0.wp.com/latex.php?latex=S_%7BK-1%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=S_%7BK-1%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S_%7BK-1%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"S_{K-1}\" class=\"latex\" />, which is passed as input parameter to the function. </p>\n<p>This article aims at showing that the Pham et al. procedure works and is computationally more efficient than the <a href=\"https://datasciencelab.wordpress.com/2013/12/27/finding-the-k-in-k-means-clustering/\" title=\"Finding the K in K-Means Clustering\">gap statistic</a>. Therefore, we will code up the algorithm for the gap statistic within the same class <code>DetK</code>, so that we can run both procedures simultaneously. The full code is below the fold: </p>\n<pre class=\"brush: python; collapse: true; light: false; title: class DetK(KPlusPlus): (click to expand); toolbar: true; notranslate\">\nclass DetK(KPlusPlus):\n    def fK(self, thisk, Skm1=0):\n        X = self.X\n        Nd = len(X[0])\n        a = lambda k, Nd: 1 - 3/(4*Nd) if k == 2 else a(k-1, Nd) + (1-a(k-1, Nd))/6\n        self.find_centers(thisk, method='++')\n        mu, clusters = self.mu, self.clusters\n        Sk = sum([np.linalg.norm(mu[i]-c)**2 \\\n                 for i in range(thisk) for c in clusters[i]])\n        if thisk == 1:\n            fs = 1\n        elif Skm1 == 0:\n            fs = 1\n        else:\n            fs = Sk/(a(thisk,Nd)*Skm1)\n        return fs, Sk  \n\n    def _bounding_box(self):\n        X = self.X\n        xmin, xmax = min(X,key=lambda a:a[0])[0], max(X,key=lambda a:a[0])[0]\n        ymin, ymax = min(X,key=lambda a:a[1])[1], max(X,key=lambda a:a[1])[1]\n        return (xmin,xmax), (ymin,ymax)        \n        \n    def gap(self, thisk):\n        X = self.X\n        (xmin,xmax), (ymin,ymax) = self._bounding_box()\n        self.init_centers(thisk)\n        self.find_centers(thisk, method='++')\n        mu, clusters = self.mu, self.clusters\n        Wk = np.log(sum([np.linalg.norm(mu[i]-c)**2/(2*len(c)) \\\n                    for i in range(thisk) for c in clusters[i]]))\n        # Create B reference datasets\n        B = 10\n        BWkbs = zeros(B)\n        for i in range(B):\n            Xb = []\n            for n in range(len(X)):\n                Xb.append([random.uniform(xmin,xmax), \\\n                          random.uniform(ymin,ymax)])\n            Xb = np.array(Xb)\n            kb = DetK(thisk, X=Xb)\n            kb.init_centers(thisk)\n            kb.find_centers(thisk, method='++')\n            ms, cs = kb.mu, kb.clusters\n            BWkbs[i] = np.log(sum([np.linalg.norm(ms[j]-c)**2/(2*len(c)) \\\n                              for j in range(thisk) for c in cs[j]]))\n        Wkb = sum(BWkbs)/B\n        sk = np.sqrt(sum((BWkbs-Wkb)**2)/float(B))*np.sqrt(1+1/B)\n        return Wk, Wkb, sk\n    \n    def run(self, maxk, which='both'):\n        ks = range(1,maxk)\n        fs = zeros(len(ks))\n        Wks,Wkbs,sks = zeros(len(ks)+1),zeros(len(ks)+1),zeros(len(ks)+1)\n        # Special case K=1\n        self.init_centers(1)\n        if which == 'f':\n            fs[0], Sk = self.fK(1)\n        elif which == 'gap':\n            Wks[0], Wkbs[0], sks[0] = self.gap(1)\n        else:\n            fs[0], Sk = self.fK(1)\n            Wks[0], Wkbs[0], sks[0] = self.gap(1)\n        # Rest of Ks\n        for k in ks[1:]:\n            self.init_centers(k)\n            if which == 'f':\n                fs[k-1], Sk = self.fK(k, Skm1=Sk)\n            elif which == 'gap':\n                Wks[k-1], Wkbs[k-1], sks[k-1] = self.gap(k)\n            else:\n                fs[k-1], Sk = self.fK(k, Skm1=Sk)\n                Wks[k-1], Wkbs[k-1], sks[k-1] = self.gap(k)\n        if which == 'f':\n            self.fs = fs\n        elif which == 'gap':\n            G = []\n            for i in range(len(ks)):\n                G.append((Wkbs-Wks)[i] - ((Wkbs-Wks)[i+1]-sks[i+1]))\n            self.G = np.array(G)\n        else:\n            self.fs = fs\n            G = []\n            for i in range(len(ks)):\n                G.append((Wkbs-Wks)[i] - ((Wkbs-Wks)[i+1]-sks[i+1]))\n            self.G = np.array(G)\n    \n    def plot_all(self):\n        X = self.X\n        ks = range(1, len(self.fs)+1)\n        fig = plt.figure(figsize=(18,5))\n        # Plot 1\n        ax1 = fig.add_subplot(131)\n        ax1.set_xlim(-1,1)\n        ax1.set_ylim(-1,1)\n        ax1.plot(zip(*X)[0], zip(*X)[1], '.', alpha=0.5)\n        tit1 = 'N=%s' % (str(len(X)))\n        ax1.set_title(tit1, fontsize=16)\n        # Plot 2\n        ax2 = fig.add_subplot(132)\n        ax2.set_ylim(0, 1.25)\n        ax2.plot(ks, self.fs, 'ro-', alpha=0.6)\n        ax2.set_xlabel('Number of clusters K', fontsize=16)\n        ax2.set_ylabel('f(K)', fontsize=16) \n        foundfK = np.where(self.fs == min(self.fs))[0][0] + 1\n        tit2 = 'f(K) finds %s clusters' % (foundfK)\n        ax2.set_title(tit2, fontsize=16)\n        # Plot 3\n        ax3 = fig.add_subplot(133)\n        ax3.bar(ks, self.G, alpha=0.5, color='g', align='center')\n        ax3.set_xlabel('Number of clusters K', fontsize=16)\n        ax3.set_ylabel('Gap', fontsize=16)\n        foundG = np.where(self.G > 0)[0][0] + 1\n        tit3 = 'Gap statistic finds %s clusters' % (foundG)\n        ax3.set_title(tit3, fontsize=16)\n        ax3.xaxis.set_ticks(range(1,len(ks)+1))\n        plt.savefig('detK_N%s.png' % (str(len(X))), \\\n                     bbox_inches='tight', dpi=100)\n</pre>\n<p>For a first experiment comparing the Pham et al. and the gap statistic approaches, we create a data set comprising 300 points around 2 Gaussian-distributed clusters. We run both methods to select <img src=\"https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"K\" class=\"latex\" /> spanning the values <img src=\"https://s0.wp.com/latex.php?latex=K%3D1%2C+%5Cldots%2C+9&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=K%3D1%2C+%5Cldots%2C+9&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=K%3D1%2C+%5Cldots%2C+9&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"K=1, &#92;ldots, 9\" class=\"latex\" />. (The function <code>run</code> from class <code>DetK</code> takes a value <img src=\"https://s0.wp.com/latex.php?latex=k_%7Bthr%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=k_%7Bthr%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k_%7Bthr%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"k_{thr}\" class=\"latex\" /> as input and checks all values such that <img src=\"https://s0.wp.com/latex.php?latex=k+%3C+k_%7Bthr%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=k+%3C+k_%7Bthr%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k+%3C+k_%7Bthr%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"k < k_{thr}\" class=\"latex\" />.) Note that every run of the k-means clustering algorithm for different values of <img src=\"https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"K\" class=\"latex\" /> is preceded by the k-means++ initialization algorithm, to prevent landing at suboptimal clustering solutions. </p>\n<p>To run a full comparison of both methods, the following simple commands are invoked: </p>\n<pre class=\"brush: python; title: ; notranslate\">\nkpp = DetK(2, N=300)\nkpp.run(10)\nkpp.plot_all()\n</pre>\n<p>This produces the following result plots:</p>\n<p><a href=\"https://datasciencelab.files.wordpress.com/2014/01/detk_n300.png\"><img loading=\"lazy\" data-attachment-id=\"673\" data-permalink=\"https://datasciencelab.wordpress.com/2014/01/21/selection-of-k-in-k-means-clustering-reloaded/detk_n300/\" data-orig-file=\"https://datasciencelab.files.wordpress.com/2014/01/detk_n300.png\" data-orig-size=\"1451,472\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\"}\" data-image-title=\"detK_N300\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://datasciencelab.files.wordpress.com/2014/01/detk_n300.png?w=300\" data-large-file=\"https://datasciencelab.files.wordpress.com/2014/01/detk_n300.png?w=830\" src=\"https://datasciencelab.files.wordpress.com/2014/01/detk_n300.png?w=830&#038;h=269\" alt=\"detK_N300\" width=\"830\" height=\"269\" class=\"alignnone size-large wp-image-673\" srcset=\"https://datasciencelab.files.wordpress.com/2014/01/detk_n300.png?w=827&h=269 827w, https://datasciencelab.files.wordpress.com/2014/01/detk_n300.png?w=150&h=49 150w, https://datasciencelab.files.wordpress.com/2014/01/detk_n300.png?w=300&h=98 300w, https://datasciencelab.files.wordpress.com/2014/01/detk_n300.png?w=768&h=250 768w, https://datasciencelab.files.wordpress.com/2014/01/detk_n300.png?w=1024&h=333 1024w, https://datasciencelab.files.wordpress.com/2014/01/detk_n300.png 1451w\" sizes=\"(max-width: 830px) 100vw, 830px\" /></a></p>\n<p>According to Pham et al. lower values of <img src=\"https://s0.wp.com/latex.php?latex=f%28K%29&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=f%28K%29&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%28K%29&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"f(K)\" class=\"latex\" />, and especially values <img src=\"https://s0.wp.com/latex.php?latex=f%28K%29+%3C+0.85&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=f%28K%29+%3C+0.85&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%28K%29+%3C+0.85&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"f(K) < 0.85\" class=\"latex\" /> are an indication of cluster-like features in the data at that particular <img src=\"https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"K\" class=\"latex\" />. In the case of <img src=\"https://s0.wp.com/latex.php?latex=K%3D2&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=K%3D2&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=K%3D2&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"K=2\" class=\"latex\" />, the global minimum of <img src=\"https://s0.wp.com/latex.php?latex=f%28K%29&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=f%28K%29&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%28K%29&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"f(K)\" class=\"latex\" /> in the central plot leaves no doubt that this is the right value to choose for this particular data configuration. The gap statistic, depicted in the plot on the right, yields the same result of <img src=\"https://s0.wp.com/latex.php?latex=K%3D2&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=K%3D2&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=K%3D2&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"K=2\" class=\"latex\" />. Remember that the optimal <img src=\"https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"K\" class=\"latex\" /> with the gap statistic is the smallest value for which the gap quantity becomes positive. </p>\n<p>Similarly, we can analyze a data set consisting of 100 points around a single cluster. The results are shown in the plots below. We observe how the function <img src=\"https://s0.wp.com/latex.php?latex=f%28K%29&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=f%28K%29&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%28K%29&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"f(K)\" class=\"latex\" /> does not show any prominent valley or value for which <img src=\"https://s0.wp.com/latex.php?latex=f%28K%29+%3C+0.85&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=f%28K%29+%3C+0.85&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%28K%29+%3C+0.85&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"f(K) < 0.85\" class=\"latex\" /> for any of the surveyed <img src=\"https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"K\" class=\"latex\" />s. According to the Pham et al. paper, this is an indication of no clustering, as is the case. The gap statistic agrees that there is no more than one cluster in this case.</p>\n<p><a href=\"https://datasciencelab.files.wordpress.com/2014/01/detk_n100.png\"><img loading=\"lazy\" data-attachment-id=\"675\" data-permalink=\"https://datasciencelab.wordpress.com/2014/01/21/selection-of-k-in-k-means-clustering-reloaded/detk_n100/\" data-orig-file=\"https://datasciencelab.files.wordpress.com/2014/01/detk_n100.png\" data-orig-size=\"1451,472\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\"}\" data-image-title=\"detK_N100\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://datasciencelab.files.wordpress.com/2014/01/detk_n100.png?w=300\" data-large-file=\"https://datasciencelab.files.wordpress.com/2014/01/detk_n100.png?w=830\" src=\"https://datasciencelab.files.wordpress.com/2014/01/detk_n100.png?w=830&#038;h=269\" alt=\"detK_N100\" width=\"830\" height=\"269\" class=\"alignnone size-large wp-image-675\" srcset=\"https://datasciencelab.files.wordpress.com/2014/01/detk_n100.png?w=827&h=269 827w, https://datasciencelab.files.wordpress.com/2014/01/detk_n100.png?w=150&h=49 150w, https://datasciencelab.files.wordpress.com/2014/01/detk_n100.png?w=300&h=98 300w, https://datasciencelab.files.wordpress.com/2014/01/detk_n100.png?w=768&h=250 768w, https://datasciencelab.files.wordpress.com/2014/01/detk_n100.png?w=1024&h=333 1024w, https://datasciencelab.files.wordpress.com/2014/01/detk_n100.png 1451w\" sizes=\"(max-width: 830px) 100vw, 830px\" /></a></p>\n<p>Finally, let us look at two cases, both with 500 data points around 4 clusters. Below are the plots of the results: </p>\n<p><a href=\"https://datasciencelab.files.wordpress.com/2014/01/detk_n500_1.png\"><img loading=\"lazy\" data-attachment-id=\"677\" data-permalink=\"https://datasciencelab.wordpress.com/2014/01/21/selection-of-k-in-k-means-clustering-reloaded/detk_n500_1/\" data-orig-file=\"https://datasciencelab.files.wordpress.com/2014/01/detk_n500_1.png\" data-orig-size=\"1451,472\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\"}\" data-image-title=\"detK_N500_1\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://datasciencelab.files.wordpress.com/2014/01/detk_n500_1.png?w=300\" data-large-file=\"https://datasciencelab.files.wordpress.com/2014/01/detk_n500_1.png?w=830\" src=\"https://datasciencelab.files.wordpress.com/2014/01/detk_n500_1.png?w=830&#038;h=269\" alt=\"detK_N500_1\" width=\"830\" height=\"269\" class=\"alignnone size-large wp-image-677\" srcset=\"https://datasciencelab.files.wordpress.com/2014/01/detk_n500_1.png?w=827&h=269 827w, https://datasciencelab.files.wordpress.com/2014/01/detk_n500_1.png?w=150&h=49 150w, https://datasciencelab.files.wordpress.com/2014/01/detk_n500_1.png?w=300&h=98 300w, https://datasciencelab.files.wordpress.com/2014/01/detk_n500_1.png?w=768&h=250 768w, https://datasciencelab.files.wordpress.com/2014/01/detk_n500_1.png?w=1024&h=333 1024w, https://datasciencelab.files.wordpress.com/2014/01/detk_n500_1.png 1451w\" sizes=\"(max-width: 830px) 100vw, 830px\" /></a></p>\n<p><a href=\"https://datasciencelab.files.wordpress.com/2014/01/detk_n500.png\"><img loading=\"lazy\" data-attachment-id=\"676\" data-permalink=\"https://datasciencelab.wordpress.com/2014/01/21/selection-of-k-in-k-means-clustering-reloaded/detk_n500/\" data-orig-file=\"https://datasciencelab.files.wordpress.com/2014/01/detk_n500.png\" data-orig-size=\"1451,472\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\"}\" data-image-title=\"detK_N500\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://datasciencelab.files.wordpress.com/2014/01/detk_n500.png?w=300\" data-large-file=\"https://datasciencelab.files.wordpress.com/2014/01/detk_n500.png?w=830\" src=\"https://datasciencelab.files.wordpress.com/2014/01/detk_n500.png?w=830&#038;h=269\" alt=\"detK_N500\" width=\"830\" height=\"269\" class=\"alignnone size-large wp-image-676\" srcset=\"https://datasciencelab.files.wordpress.com/2014/01/detk_n500.png?w=827&h=269 827w, https://datasciencelab.files.wordpress.com/2014/01/detk_n500.png?w=150&h=49 150w, https://datasciencelab.files.wordpress.com/2014/01/detk_n500.png?w=300&h=98 300w, https://datasciencelab.files.wordpress.com/2014/01/detk_n500.png?w=768&h=250 768w, https://datasciencelab.files.wordpress.com/2014/01/detk_n500.png?w=1024&h=333 1024w, https://datasciencelab.files.wordpress.com/2014/01/detk_n500.png 1451w\" sizes=\"(max-width: 830px) 100vw, 830px\" /></a></p>\n<p>For the data distribution on the top, one can see that the 4 clusters are positioned in such a way that they could also be interpreted as 2 clusters made of 2 subclusters each. The <img src=\"https://s0.wp.com/latex.php?latex=f%28K%29&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=f%28K%29&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%28K%29&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"f(K)\" class=\"latex\" /> detects this configuration and suggests 2 possible values of <img src=\"https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"K\" class=\"latex\" />, with a slight preference for <img src=\"https://s0.wp.com/latex.php?latex=K%3D2&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=K%3D2&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=K%3D2&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"K=2\" class=\"latex\" /> over <img src=\"https://s0.wp.com/latex.php?latex=K%3D4&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=K%3D4&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=K%3D4&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"K=4\" class=\"latex\" />. The gap statistic changes sign at <img src=\"https://s0.wp.com/latex.php?latex=K%3D2&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=K%3D2&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=K%3D2&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"K=2\" class=\"latex\" />, albeit barely, and it does it again and more clearly at <img src=\"https://s0.wp.com/latex.php?latex=K%3D4&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=K%3D4&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=K%3D4&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"K=4\" class=\"latex\" />. In both cases, a strict application of the rules prescribed to select the correct <img src=\"https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"K\" class=\"latex\" /> does lead to a rather suboptimal, or at least dubious, choice. </p>\n<p>In the bottom plot however, the 4 clusters are somehow more evenly spreaded and both algorithms succeed at identifying <img src=\"https://s0.wp.com/latex.php?latex=K%3D4&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=K%3D4&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=K%3D4&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"K=4\" class=\"latex\" />. The <img src=\"https://s0.wp.com/latex.php?latex=f%28K%29&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=f%28K%29&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%28K%29&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"f(K)\" class=\"latex\" /> method still shows a relative minimum at <img src=\"https://s0.wp.com/latex.php?latex=K%3D2&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=K%3D2&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=K%3D2&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"K=2\" class=\"latex\" />, indicating a potentially alternative clustering. </p>\n<h3>Performance comparison of f(K) and the gap statistic</h3>\n<p>If both methods to select the optimal <img src=\"https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"K\" class=\"latex\" /> for k-means clustering yield similar results, one should ask about the relative performance of them in real-life data science clustering problems. It is straightforward to predict that the gap statistic, with its need for running the k-means algorithm multiple times to create a Monte Carlo reference distribution, will necessarily be a poorer performer. We can easily test this hypothesis with our code by running both approaches and timing them using the IPython magic <code>%time</code> function. For a data set with <img src=\"https://s0.wp.com/latex.php?latex=N+%3D+500&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=N+%3D+500&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=N+%3D+500&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"N = 500\" class=\"latex\" />:</p>\n<pre class=\"brush: python; title: ; notranslate\">\n%time kpp.run(10, which='f')\n</pre>\n<p><code>CPU times: user 2.72 s, sys: 0.00 s, total: 2.72 s<br />\nWall time: 2.90 s</code></p>\n<pre class=\"brush: python; title: ; notranslate\">\n%time kpp.run(10, which='gap')\n</pre>\n<p><code>CPU times: user 51.30 s, sys: 0.01 s, total: 51.31 s<br />\nWall time: 51.40 s</code></p>\n<p>In this particular example, the <img src=\"https://s0.wp.com/latex.php?latex=f%28K%29&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=f%28K%29&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%28K%29&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"f(K)\" class=\"latex\" /> method is more than one order of magnitude more performant than the gap statistic, and this comparison looks worse for the latter the more data we take into consideration and the larger the number <img src=\"https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"B\" class=\"latex\" /> employed for generating the reference distributions.</p>\n<h3>Table-top data experiment take-away message</h3>\n<p>The estimation of the optimal number of clusters within a set of data points is a very important problem, as most clustering algorithms need that parameter as input in order to group the data. Many methods have been proposed to find the proper <img src=\"https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"K\" class=\"latex\" />, among which the approach proposed by Pham et al. in 2004 seems to offer a very straightforward and performant solution. The estimation of the function <img src=\"https://s0.wp.com/latex.php?latex=f%28K%29&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=f%28K%29&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%28K%29&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"f(K)\" class=\"latex\" /> over the desired range of test values for <img src=\"https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"K\" class=\"latex\" /> offers an immediate way of assessing when the cluster-like features appear and allows to choose among a best value and other alternatives. A comparison in performance with the gap statistic method of Tibshirani et al. concludes that the <img src=\"https://s0.wp.com/latex.php?latex=f%28K%29&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=f%28K%29&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%28K%29&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"f(K)\" class=\"latex\" /> is computationally advantageous. </p>\n",
  "wfw:commentRss": "https://datasciencelab.wordpress.com/2014/01/21/selection-of-k-in-k-means-clustering-reloaded/feed/",
  "slash:comments": 32,
  "media:content": [
    {
      "media:title": "datasciencelab"
    },
    {
      "media:title": "fK"
    },
    {
      "media:title": "detK_N300"
    },
    {
      "media:title": "detK_N100"
    },
    {
      "media:title": "detK_N500_1"
    },
    {
      "media:title": "detK_N500"
    }
  ]
}