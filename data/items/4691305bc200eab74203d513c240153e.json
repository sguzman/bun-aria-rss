{
  "title": "Where to find terabyte-size dataset for machine learning",
  "link": "https://fullstackml.com/where-to-find-terabyte-size-dataset-for-machine-learning-c69ffefefd7?source=rss----46e065078cc1---4",
  "guid": "https://medium.com/p/c69ffefefd7",
  "category": [
    "big-data",
    "dataset",
    "apache-spark",
    "sql"
  ],
  "dc:creator": "Dmitry Petrov",
  "pubDate": "Tue, 24 Nov 2015 16:44:17 GMT",
  "atom:updated": "2017-03-06T05:32:09.768Z",
  "content:encoded": "<p>In the previous blog posts we played with a large multi-gigabyte dataset. This 34 GB dataset is based on stackoverflow.com data. A couple days ago<strong> I found another great large dataset. This is a two terabyte snapshot from Reddit website.</strong> This dataset is perfect for text mining and NLP experimentation.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/425/1*xfny6pVUdsrt3quIWUEFXA.jpeg\" /><figcaption>The image was taken from <a href=\"https://malziano.wordpress.com/2015/07/14/product-life-cycle-of-floppy-disc/\">this web page</a>.</figcaption></figure><h3>1. Two terabytes data set</h3><p>The full dataset contains two terabytes of data in JSON format. Thank you for <a href=\"https://www.reddit.com/user/Stuck_In_the_Matrix\">Stuck_In_the_Matrix</a> who created this dataset! The compressed version is 250 GB. You can find this dataset <a href=\"https://www.reddit.com/r/datasets/comments/3bxlg7/i_have_every_publicly_available_reddit_comment/\">here in Reddit</a>. You should use torrent to download this compressed data.</p><p>Additionally, you might find a 32 gb subset of this data in Kaggle website in SQLite format <a href=\"https://www.kaggle.com/c/reddit-comments-may-2015\">here</a>. Also, you can play with the data online through R or Python in the Kaggle competition.</p><h3>2. Easy to use 16 gigabytes subset</h3><p><strong>To simplify the process of working with this data, I created a subset of this data in plain text TSV format</strong> (tab separated values) <a href=\"https://www.dropbox.com/s/q857wo62184bofp/reddit-May2015_z.tsv.zip?dl=0\"><strong>here in my dropbox folder</strong></a><strong> </strong>(updated, old Mac OS compatable only archive is <a href=\"https://www.dropbox.com/s/9ga5x7k6yacfcby/reddit-May2015.tsv.zip?dl=0\">here</a>). The file contains the copy of the Kaggle subset. File size is 16GB uncompressed (yes, it is 2 times smaller than the Kaggel file because of plain text format without indexes) and 6.6GB in archive.</p><p>SQLite code for converting the Kaggle file to a plain text:</p><iframe src=\"\" width=\"0\" height=\"0\" frameborder=\"0\" scrolling=\"no\"><a href=\"https://medium.com/media/53a595f75913d7a3d428a77d4fdb8d11/href\">https://medium.com/media/53a595f75913d7a3d428a77d4fdb8d11/href</a></iframe><p>Note that I replace all tabs (X’09') and newlines (X’0A’) to spaces for all text columns. Please let me know if you know how to combine two character replacement to one operations.</p><h3>3. Read data in Spark</h3><iframe src=\"\" width=\"0\" height=\"0\" frameborder=\"0\" scrolling=\"no\"><a href=\"https://medium.com/media/8dc37624662cbb2ee90e74a7ccff94eb/href\">https://medium.com/media/8dc37624662cbb2ee90e74a7ccff94eb/href</a></iframe><h3>Conclusion</h3><p>Today is not easy to find great and interesting dataset for testing, training and research. So, let's collect some interesting datasets. <strong>Please share with the community your newly found information.</strong></p><h4>P.S.</h4><p>I looked into the licensing of this dataset. The dataset publisher <a href=\"https://www.reddit.com/user/Stuck_In_the_Matrix\">Stuck_In_the_Matrix</a> just published the dataset and provided description and links to the torrent directly in the Reddit website. Please note that Reddit sponsors the Kaggle competition with this dataset. It appears that we may play with the dataset for non-business related purposes.</p><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=c69ffefefd7\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://fullstackml.com/where-to-find-terabyte-size-dataset-for-machine-learning-c69ffefefd7\">Where to find terabyte-size dataset for machine learning</a> was originally published in <a href=\"https://fullstackml.com\">FullStackML</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
}