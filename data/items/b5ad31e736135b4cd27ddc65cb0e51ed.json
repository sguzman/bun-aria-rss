{
  "title": "Benchmarking Apache Cassandra with Rust",
  "link": "",
  "published": "2020-10-05T00:00:00+00:00",
  "updated": "2020-10-05T00:00:00+00:00",
  "id": "https://pkolaczk.github.io/benchmarking-cassandra",
  "content": "<p>Performance of a database system depends on many factors: hardware, configuration, \ndatabase schema, amount of data, workload type, network latency, and many others.\nTherefore, one typically can’t tell the actual performance of such system without\nfirst measuring it. In this blog post I’m describing how to build a benchmarking tool\nfor Apache Cassandra from scratch in Rust and how to avoid many pitfalls. \nThe techniques I show are applicable to any system with an async API.</p>\n\n<!--more-->\n\n<p><a href=\"https://cassandra.apache.org/\">Apache Cassandra</a> is a popular, scalable, distributed, open-source database system.\nIt comes with its own benchmarking tool <code class=\"language-plaintext highlighter-rouge\">cassandra-stress</code> that can issue queries in parallel and measure\nthroughtput and response times. It offers not just a few built-in standard benchmarks, but also allows defining \ncustom schemas and workloads, making it really versatile. So why write another one?</p>\n\n<p>Being written in Java, <code class=\"language-plaintext highlighter-rouge\">cassanda-stress</code> has a few downsides:</p>\n\n<ul>\n  <li>\n    <p>It consumes a significant amount of CPU and RAM resources by itself. This makes it a bad idea to\nrun it on the same machine as the database server, because the amount of resources available to the server\nwould be strongly reduced. This problem obviously exists for just <em>any</em> benchmarking tool regardless of its performance, \nbut I was really surprised to find that <code class=\"language-plaintext highlighter-rouge\">cassandra-stress</code> often takes about the same amount of CPU time as the server \nit benchmarks, essentially halving the CPU time available to Cassandra. This also means that even when running it on a separate computer, \nyou need to make sure it is as powerful as the system under test. Or in case of bigger clusters - you need a decent cluster just for the client machines.</p>\n  </li>\n  <li>\n    <p>It requires warmup for the JVM. This is a problem of all JVM-based benchmarking tools (including \nexcellent benchmarking frameworks like JMH). You can’t run a test for a second or even a few secods, because\ninitial measurements are inaccurate and need to be thrown-away. This problem might be considered a minor annoyance, \nbut it seriously gets in a way if you ever wanted to measure the effect of JVM warmup on the server side performance \n(which happens e.g. after restarting the server). In this case you can’t tell the effects of the warmup on the server \nside from the effects on the client side.</p>\n  </li>\n  <li>\n    <p>JVM that runs the benchmark tool and its GC are an additional source of unpredictable delays. \nThe reported latency analysis is affected by the delays happening on the client, so these ideally should be as \nlow as possible. Modern Java GCs claim sub-10 ms pause times, and I find them too high for benchmarking a system \nthat aims for sub millisecond average response-times.</p>\n  </li>\n</ul>\n\n<p>A natively compiled, GC-less language like C, C++ or Rust addresses all of these issues.\nLet’s see how we can write a benchmarking tool in Rust.</p>\n\n<h1 id=\"connecting-to-cassandra\">Connecting to Cassandra</h1>\n<p>Before we can issue any queries, we need to establish a connection to the database and obtain a session. \nTo access Cassandra, we’ll use <a href=\"https://docs.rs/cassandra-cpp/0.15.1/cassandra_cpp/\">cassandra_cpp</a> \ncrate which is a Rust wrapper over <a href=\"https://docs.datastax.com/en/developer/cpp-driver/index.html\">the official Cassandra driver for C++</a> \nfrom <a href=\"https://www.datastax.com\">DataStax</a>. There exist other third-party drivers developed natively in Rust from scratch, but at the time of writing this post,\nthey weren’t production ready.</p>\n\n<p>Installing the driver on Ubuntu is straightforward:</p>\n<pre>\nsudo apt install libuv1 libuv1-dev\nsudo dpkg -i cassandra-cpp-driver_2.15.3-1_amd64.deb\nsudo dpkg -i cassandra-cpp-driver-dev_2.15.3-1_amd64.deb\n</pre>\n\n<p>Then we need to add <code class=\"language-plaintext highlighter-rouge\">cassandra_cpp</code> dependency to <code class=\"language-plaintext highlighter-rouge\">Cargo.toml</code>:</p>\n\n<div class=\"language-toml highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"py\">cassandra-cpp</span> <span class=\"p\">=</span> <span class=\"s\">\"0.15.1\"</span>\n</code></pre></div></div>\n\n<p>Configuring the connection is performed through <code class=\"language-plaintext highlighter-rouge\">Cluster</code> type:</p>\n<div class=\"language-rust highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">use</span> <span class=\"nn\">cassandra_cpp</span><span class=\"p\">::</span><span class=\"o\">*</span><span class=\"p\">;</span>\n\n<span class=\"k\">let</span> <span class=\"k\">mut</span> <span class=\"n\">cluster</span> <span class=\"o\">=</span> <span class=\"nn\">Cluster</span><span class=\"p\">::</span><span class=\"nf\">default</span><span class=\"p\">();</span>\n<span class=\"n\">cluster</span><span class=\"nf\">.set_contact_points</span><span class=\"p\">(</span><span class=\"s\">\"localhost\"</span><span class=\"p\">)</span><span class=\"nf\">.unwrap</span><span class=\"p\">();</span>\n<span class=\"n\">cluster</span><span class=\"nf\">.set_core_connections_per_host</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span><span class=\"nf\">.unwrap</span><span class=\"p\">();</span>\n<span class=\"n\">cluster</span><span class=\"nf\">.set_max_connections_per_host</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span><span class=\"nf\">.unwrap</span><span class=\"p\">();</span>    \n<span class=\"n\">cluster</span><span class=\"nf\">.set_queue_size_io</span><span class=\"p\">(</span><span class=\"mi\">1024</span><span class=\"p\">)</span><span class=\"nf\">.unwrap</span><span class=\"p\">();</span>\n<span class=\"n\">cluster</span><span class=\"nf\">.set_num_threads_io</span><span class=\"p\">(</span><span class=\"mi\">4</span><span class=\"p\">)</span><span class=\"nf\">.unwrap</span><span class=\"p\">();</span>\n<span class=\"n\">cluster</span><span class=\"nf\">.set_connect_timeout</span><span class=\"p\">(</span><span class=\"nn\">time</span><span class=\"p\">::</span><span class=\"nn\">Duration</span><span class=\"p\">::</span><span class=\"nf\">seconds</span><span class=\"p\">(</span><span class=\"mi\">5</span><span class=\"p\">));</span>\n<span class=\"n\">cluster</span><span class=\"nf\">.set_load_balance_round_robin</span><span class=\"p\">();</span>\n</code></pre></div></div>\n\n<p>Finally, we can connect:</p>\n<div class=\"language-rust highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">let</span> <span class=\"n\">session</span> <span class=\"o\">=</span> <span class=\"k\">match</span> <span class=\"n\">cluster</span><span class=\"nf\">.connect</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n  <span class=\"nf\">Ok</span><span class=\"p\">(</span><span class=\"n\">s</span><span class=\"p\">)</span> <span class=\"k\">=&gt;</span> <span class=\"n\">s</span><span class=\"p\">,</span>\n  <span class=\"nf\">Err</span><span class=\"p\">(</span><span class=\"n\">e</span><span class=\"p\">)</span> <span class=\"k\">=&gt;</span> <span class=\"p\">{</span>\n      <span class=\"nd\">eprintln!</span><span class=\"p\">(</span><span class=\"s\">\"error: Failed to connect to Cassandra: {}\"</span><span class=\"p\">,</span> <span class=\"n\">e</span><span class=\"p\">);</span>\n      <span class=\"nf\">exit</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n  <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<h1 id=\"just-a-loop\">Just a Loop</h1>\n<p>Now that we have the <code class=\"language-plaintext highlighter-rouge\">session</code>, we can issue queries.\nHow hard could writing a database benchmark be? It is just sending queries in a loop and measuring how long they take, isn’t it?\nFor simplicity, let’s assume there already exists a table <code class=\"language-plaintext highlighter-rouge\">test</code> in <code class=\"language-plaintext highlighter-rouge\">keyspace1</code> with the following schema:</p>\n\n<div class=\"language-sql highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">CREATE</span> <span class=\"k\">TABLE</span> <span class=\"n\">keyspace1</span><span class=\"p\">.</span><span class=\"n\">test</span><span class=\"p\">(</span><span class=\"n\">pk</span> <span class=\"nb\">BIGINT</span> <span class=\"k\">PRIMARY</span> <span class=\"k\">KEY</span><span class=\"p\">,</span> <span class=\"n\">col</span> <span class=\"nb\">BIGINT</span><span class=\"p\">);</span>\n</code></pre></div></div>\n\n<p>Let’s issue some reads from this table and measure how long they took:</p>\n<div class=\"language-rust highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">use</span> <span class=\"nn\">std</span><span class=\"p\">::</span><span class=\"nn\">time</span><span class=\"p\">::{</span><span class=\"n\">Duration</span><span class=\"p\">,</span> <span class=\"n\">Instant</span><span class=\"p\">};</span>\n\n<span class=\"k\">let</span> <span class=\"n\">session</span> <span class=\"o\">=</span> <span class=\"c\">// ... setup the session</span>\n<span class=\"k\">let</span> <span class=\"n\">count</span> <span class=\"o\">=</span> <span class=\"mi\">100000</span><span class=\"p\">;</span>\n<span class=\"k\">let</span> <span class=\"n\">start</span> <span class=\"o\">=</span> <span class=\"nn\">Instant</span><span class=\"p\">::</span><span class=\"nf\">now</span><span class=\"p\">();</span>\n<span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"n\">in</span> <span class=\"mi\">0</span><span class=\"o\">..</span><span class=\"n\">count</span> <span class=\"p\">{</span>\n  <span class=\"n\">session</span>\n    <span class=\"nf\">.execute</span><span class=\"p\">(</span><span class=\"o\">&amp;</span><span class=\"nd\">stmt!</span><span class=\"p\">(</span><span class=\"s\">\"SELECT * FROM keyspace1.test WHERE pk = 1\"</span><span class=\"p\">))</span>\n    <span class=\"nf\">.wait</span><span class=\"p\">()</span>\n    <span class=\"nf\">.unwrap</span><span class=\"p\">();</span>\n<span class=\"p\">}</span>\n<span class=\"k\">let</span> <span class=\"n\">end</span> <span class=\"o\">=</span> <span class=\"nn\">Instant</span><span class=\"p\">::</span><span class=\"nf\">now</span><span class=\"p\">();</span>\n<span class=\"nd\">println!</span><span class=\"p\">(</span>\n    <span class=\"s\">\"Throughput: {:.1} request/s\"</span><span class=\"p\">,</span>\n    <span class=\"mf\">1000000.0</span> <span class=\"o\">*</span> <span class=\"n\">count</span> <span class=\"k\">as</span> <span class=\"nb\">f64</span> <span class=\"o\">/</span> <span class=\"p\">(</span><span class=\"n\">end</span> <span class=\"o\">-</span> <span class=\"n\">start</span><span class=\"p\">)</span><span class=\"nf\">.as_micros</span><span class=\"p\">()</span> <span class=\"k\">as</span> <span class=\"nb\">f64</span>\n<span class=\"p\">);</span>\n\n</code></pre></div></div>\n\n<p>I bet you’ve seen similar benchmarking code in some benchmarks on the Internet.\nI’ve seen results from code like this being used to justify a choice of one database system over another.\nUnfortunately, this simple code has a few very serious issues and can lead to incorrect conclusions \nabout performance of the system:</p>\n\n<ol>\n  <li>\n    <p>The loop performs only one request at a time. In case of systems like Apache Cassandra which are optimised\nto handle <em>many thousands</em> of parallel requests, this leaves most of the available computing resources idle.\nMost (all?) modern CPUs have multiple cores. Hard drives also <a href=\"/disk-parallelism/\">benefit from parallel access</a>.\nAdditionally, there is non-zero network latency for sending the request to the server and \nsending the response back to the client. Even if running this client code on the same computer, there is non-zero time needed \nfor the operating system to deliver the data from one process to another over the loopback. \nDuring that time, the server has literally <em>nothing to do</em>. The result throughput you’ll get from such a naive benchmark loop \nwill be significantly lower than the server is really capable of.</p>\n  </li>\n  <li>\n    <p>Sending a single query at a time precludes the driver from automatically \nbatching multiple requests. Batching can improve the network bandwidth by using a more \nefficient data representation and can reduce the number of syscalls, e.g. by writing\nmany requests to the network socket at once. Reading requests from the socket on the server side \nis also much more efficient if there are many available in the socket buffer.</p>\n  </li>\n  <li>\n    <p>The code doesn’t use prepared statements. Many database systems, not only Cassandra, but also many traditional relational \ndatabase systems, have this feature for a reason: parsing and planning a query can be a substantial amount of work, \nand it is makes sense to do it only once.</p>\n  </li>\n  <li>\n    <p>The code is reading the same row over and over again. Depending on what you wish to measure this could be a good or a bad thing.\nIn this case, the database system would cache the data fully and serve it from RAM, so you might actually overestimate the performance, \nbecause real workloads rarely fetch a single row in a loop. On the other hand, such test would make some sense if you deliberately\nwant to test the happy-path performance of the cache layer.</p>\n  </li>\n</ol>\n\n<p>As a result, the reported throughput is abysmally poor:</p>\n<pre>\nThroughput: 2279.7 request/s\n</pre>\n\n<h1 id=\"prepared-statements\">Prepared Statements</h1>\n<p>The problems #3 and #4 are the easiest to solve. Let’s change the code to use a prepared statement, and let’s introduce a parameter\nso we’re not fetching the same row all the time:</p>\n\n<div class=\"language-rust highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">use</span> <span class=\"nn\">cassandra_cpp</span><span class=\"p\">::</span><span class=\"o\">*</span><span class=\"p\">;</span>\n<span class=\"k\">use</span> <span class=\"nn\">std</span><span class=\"p\">::</span><span class=\"nn\">time</span><span class=\"p\">::{</span><span class=\"n\">Duration</span><span class=\"p\">,</span> <span class=\"n\">Instant</span><span class=\"p\">};</span>\n\n<span class=\"k\">let</span> <span class=\"n\">session</span> <span class=\"o\">=</span> <span class=\"c\">// ... setup the session</span>\n<span class=\"k\">let</span> <span class=\"n\">statement</span> <span class=\"o\">=</span> <span class=\"n\">session</span>\n    <span class=\"nf\">.prepare</span><span class=\"p\">(</span><span class=\"s\">\"SELECT * FROM keyspace1.test WHERE pk = ?\"</span><span class=\"p\">)</span><span class=\"o\">?</span>\n    <span class=\"nf\">.wait</span><span class=\"p\">()</span><span class=\"o\">?</span><span class=\"p\">;</span>\n<span class=\"k\">let</span> <span class=\"n\">count</span> <span class=\"o\">=</span> <span class=\"mi\">100000</span><span class=\"p\">;</span>\n<span class=\"k\">let</span> <span class=\"n\">start</span> <span class=\"o\">=</span> <span class=\"nn\">Instant</span><span class=\"p\">::</span><span class=\"nf\">now</span><span class=\"p\">();</span>\n<span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"n\">in</span> <span class=\"mi\">0</span><span class=\"o\">..</span><span class=\"n\">count</span> <span class=\"p\">{</span>\n    <span class=\"k\">let</span> <span class=\"k\">mut</span> <span class=\"n\">statement</span> <span class=\"o\">=</span> <span class=\"n\">statement</span><span class=\"nf\">.bind</span><span class=\"p\">();</span>\n    <span class=\"n\">statement</span><span class=\"nf\">.bind</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">i</span> <span class=\"k\">as</span> <span class=\"nb\">i64</span><span class=\"p\">)</span><span class=\"o\">?</span><span class=\"p\">;</span>\n    <span class=\"n\">session</span><span class=\"nf\">.execute</span><span class=\"p\">(</span><span class=\"o\">&amp;</span><span class=\"n\">statement</span><span class=\"p\">)</span><span class=\"nf\">.wait</span><span class=\"p\">()</span><span class=\"nf\">.unwrap</span><span class=\"p\">();</span>\n<span class=\"p\">}</span>\n<span class=\"k\">let</span> <span class=\"n\">end</span> <span class=\"o\">=</span> <span class=\"nn\">Instant</span><span class=\"p\">::</span><span class=\"nf\">now</span><span class=\"p\">();</span>\n<span class=\"nd\">println!</span><span class=\"p\">(</span>\n    <span class=\"s\">\"Throughput: {:.1} request/s\"</span><span class=\"p\">,</span>\n    <span class=\"mf\">1000000.0</span> <span class=\"o\">*</span> <span class=\"n\">count</span> <span class=\"k\">as</span> <span class=\"nb\">f64</span> <span class=\"o\">/</span> <span class=\"p\">(</span><span class=\"n\">end</span> <span class=\"o\">-</span> <span class=\"n\">start</span><span class=\"p\">)</span><span class=\"nf\">.as_micros</span><span class=\"p\">()</span> <span class=\"k\">as</span> <span class=\"nb\">f64</span>\n<span class=\"p\">);</span>\n</code></pre></div></div>\n\n<p>Unfortunately, the performance is still extremely low.</p>\n<pre>\nThroughput: 2335.9 request/s\n</pre>\n\n<h1 id=\"going-async\">Going <code class=\"language-plaintext highlighter-rouge\">async</code></h1>\n<p>To fix the problems #1 and #2, we need to send more than one query at a time.\nIn the codes above we’re calling <code class=\"language-plaintext highlighter-rouge\">wait()</code> on the futures returned from the driver \nand that call is blocking. And because our program is single-threaded, it can’t do anything \nelse while being blocked.</p>\n\n<p>There are two approaches we can take:</p>\n\n<ul>\n  <li>\n    <p>Launch many threads and let each thread run its own loop coded in the way as shown above.\nI tried this, and you have to believe this approach requires <em>hundreds</em> of threads to get a decent\nperformance from a single-node Cassandra cluster. I won’t show it here, because I don’t prefer this solution – it feels \nunnatural when the driver offers excellent async capabilities\n(but feel free to drop a comment and share your experience if you coded it by yourself). \nMore importantly, this approach is susceptible to coordinated omission, where a single slow requests \n(e.g. blocked by server-side GC) could delay sending a bunch of other requests, hence making the reported\nresponse times too optimistic.</p>\n  </li>\n  <li>\n    <p>Use async programming model: don’t block immediately on the returned future after spawning a single request, \nbut spawn many requests and collect results asynchronously when they are ready. This way we’re making sending \nrequests independent from each other, thus avoiding coordinated omission.\nIt is easy to do with <code class=\"language-plaintext highlighter-rouge\">cassandra_cpp</code> and Cassandra C++ driver because internally it also uses that style.\nYou can notice that almost all the functions of the driver \nreturn futures that are compatible with Rust’s <code class=\"language-plaintext highlighter-rouge\">async</code>/<code class=\"language-plaintext highlighter-rouge\">await</code> feature.</p>\n  </li>\n</ul>\n\n<p>In order to be able to use async functions at all, first we need to initialize an async runtime.\nI decided to use a very popular crate <a href=\"https://tokio.rs/\">tokio</a>. Installation is adding just the following line \nto <code class=\"language-plaintext highlighter-rouge\">Cargo.toml</code>:</p>\n\n<div class=\"language-toml highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nn\">tokio</span> <span class=\"o\">=</span> <span class=\"p\">{</span> <span class=\"py\">version</span> <span class=\"p\">=</span> <span class=\"s\">\"0.2\"</span><span class=\"p\">,</span> <span class=\"py\">features</span> <span class=\"p\">=</span> <span class=\"nn\">[\"full\"]</span> <span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>Now we can annotate the main function as <code class=\"language-plaintext highlighter-rouge\">async</code>, replace <code class=\"language-plaintext highlighter-rouge\">wait</code> with <code class=\"language-plaintext highlighter-rouge\">await</code>, and call <code class=\"language-plaintext highlighter-rouge\">tokio::spawn</code> \nto launch the requests. Although <code class=\"language-plaintext highlighter-rouge\">await</code> looks like blocking, it doesn’t block the calling thread, but \nallows it to move on to the next task.</p>\n\n<div class=\"language-rust highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nd\">#[tokio::main]</span>\n<span class=\"k\">async</span> <span class=\"k\">fn</span> <span class=\"nf\">main</span><span class=\"p\">()</span> <span class=\"k\">-&gt;</span> <span class=\"nn\">cassandra_cpp</span><span class=\"p\">::</span><span class=\"n\">Result</span><span class=\"o\">&lt;</span><span class=\"p\">()</span><span class=\"o\">&gt;</span> <span class=\"p\">{</span>\n    <span class=\"k\">let</span> <span class=\"k\">mut</span> <span class=\"n\">cluster</span> <span class=\"o\">=</span> <span class=\"nn\">Cluster</span><span class=\"p\">::</span><span class=\"nf\">default</span><span class=\"p\">();</span>\n    <span class=\"c\">// ... configure cluster</span>\n    <span class=\"k\">let</span> <span class=\"n\">session</span> <span class=\"o\">=</span> <span class=\"n\">cluster</span><span class=\"nf\">.connect_async</span><span class=\"p\">()</span><span class=\"k\">.await</span><span class=\"o\">?</span><span class=\"p\">;</span>\n    <span class=\"k\">let</span> <span class=\"n\">statement</span> <span class=\"o\">=</span> <span class=\"n\">session</span>\n        <span class=\"nf\">.prepare</span><span class=\"p\">(</span><span class=\"s\">\"SELECT * FROM keyspace1.test WHERE pk = ?\"</span><span class=\"p\">)</span><span class=\"o\">?</span>\n        <span class=\"k\">.await</span><span class=\"o\">?</span><span class=\"p\">;</span>\n    <span class=\"k\">let</span> <span class=\"n\">count</span> <span class=\"o\">=</span> <span class=\"mi\">100000</span><span class=\"p\">;</span>\n    <span class=\"k\">let</span> <span class=\"n\">start</span> <span class=\"o\">=</span> <span class=\"nn\">Instant</span><span class=\"p\">::</span><span class=\"nf\">now</span><span class=\"p\">();</span>\n    <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"n\">in</span> <span class=\"mi\">0</span><span class=\"o\">..</span><span class=\"n\">count</span> <span class=\"p\">{</span>\n        <span class=\"k\">let</span> <span class=\"k\">mut</span> <span class=\"n\">statement</span> <span class=\"o\">=</span> <span class=\"n\">statement</span><span class=\"nf\">.bind</span><span class=\"p\">();</span>\n        <span class=\"n\">statement</span><span class=\"nf\">.bind</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">i</span> <span class=\"k\">as</span> <span class=\"nb\">i64</span><span class=\"p\">)</span><span class=\"nf\">.unwrap</span><span class=\"p\">();</span>\n        <span class=\"nn\">tokio</span><span class=\"p\">::</span><span class=\"nf\">spawn</span><span class=\"p\">(</span><span class=\"k\">async</span> <span class=\"p\">{</span>\n            <span class=\"k\">let</span> <span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">session</span><span class=\"nf\">.execute</span><span class=\"p\">(</span><span class=\"o\">&amp;</span><span class=\"n\">statement</span><span class=\"p\">);</span>\n            <span class=\"n\">result</span><span class=\"k\">.await</span><span class=\"nf\">.unwrap</span><span class=\"p\">();</span>\n        <span class=\"p\">});</span>\n    <span class=\"p\">}</span>\n    <span class=\"k\">let</span> <span class=\"n\">end</span> <span class=\"o\">=</span> <span class=\"nn\">Instant</span><span class=\"p\">::</span><span class=\"nf\">now</span><span class=\"p\">();</span>\n    <span class=\"nd\">println!</span><span class=\"p\">(</span>\n        <span class=\"s\">\"Throughput: {:.1} request/s\"</span><span class=\"p\">,</span>\n        <span class=\"mf\">1000000.0</span> <span class=\"o\">*</span> <span class=\"n\">count</span> <span class=\"k\">as</span> <span class=\"nb\">f64</span> <span class=\"o\">/</span> <span class=\"p\">(</span><span class=\"n\">end</span> <span class=\"o\">-</span> <span class=\"n\">start</span><span class=\"p\">)</span><span class=\"nf\">.as_micros</span><span class=\"p\">()</span> <span class=\"k\">as</span> <span class=\"nb\">f64</span>\n    <span class=\"p\">);</span>\n    <span class=\"nf\">Ok</span><span class=\"p\">(())</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>Unfortunately, this doesn’t compile, because our friend borrow-checker\ncorrectly notices that the async code inside of the loop can live longer than the \n<code class=\"language-plaintext highlighter-rouge\">main()</code> function and its local variables such as <code class=\"language-plaintext highlighter-rouge\">i</code>, <code class=\"language-plaintext highlighter-rouge\">session</code> and <code class=\"language-plaintext highlighter-rouge\">statement</code>:</p>\n\n<pre>\nerror[E0373]: async block may outlive the current function, but it borrows `i`, which is owned by the current function\n262 |           tokio::spawn(async {\n...\nhelp: to force the async block to take ownership of `i` (and any other referenced variables), use the `move` keyword\n\nerror[E0373]: async block may outlive the current function, but it borrows `statement`, which is owned by the current function\nhelp: to force the async block to take ownership of `statement` (and any other referenced variables), use the `move` keyword\n\nerror[E0373]: async block may outlive the current function, but it borrows `session`, which is owned by the current function\nhelp: to force the async block to take ownership of `session` (and any other referenced variables), use the `move` keyword\n</pre>\n\n<p>The compiler advices us to use <code class=\"language-plaintext highlighter-rouge\">move</code> to move these shared variables into the async code:</p>\n<div class=\"language-rust highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>    <span class=\"c\">// ...</span>\n    <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"n\">in</span> <span class=\"mi\">0</span><span class=\"o\">..</span><span class=\"n\">count</span> <span class=\"p\">{</span>\n        <span class=\"nn\">tokio</span><span class=\"p\">::</span><span class=\"nf\">spawn</span><span class=\"p\">(</span><span class=\"k\">async</span> <span class=\"k\">move</span> <span class=\"p\">{</span>\n            <span class=\"c\">//...</span>\n   \n</code></pre></div></div>\n\n<p>Fortunately, the problem with the loop counter <code class=\"language-plaintext highlighter-rouge\">i</code> and <code class=\"language-plaintext highlighter-rouge\">statement</code> is gone now.\nBut that still doesn’t work for <code class=\"language-plaintext highlighter-rouge\">session</code>:</p>\n<pre>\nerror[E0382]: use of moved value: `session`\n   --&gt; src/main.rs:262:33\n    |\n255 |       let session = cluster.connect_async().await.unwrap();\n    |           ------- move occurs because `session` has type `cassandra_cpp::Session`, which does not implement the `Copy` trait\n...\n262 |           tokio::spawn(async move {\n    |  _________________________________^\n263 | |             let result = session.execute(&amp;statement);\n    | |                          ------- use occurs due to use in generator\n264 | |             result.await.unwrap();\n265 | |         });\n    | |_________^ value moved here, in previous iteration of loop\n</pre>\n\n<p>This is quite obvious – we’re spawning more than one async task here, but because <code class=\"language-plaintext highlighter-rouge\">session</code> is not copyable,\nthere can only exist one of each. Of course, we don’t want multiple sessions or statements here – we need a single one shared\namong all the tasks. But how to pass only <code class=\"language-plaintext highlighter-rouge\">session</code> by reference but still use <code class=\"language-plaintext highlighter-rouge\">move</code> for passing the loop\ncounter <code class=\"language-plaintext highlighter-rouge\">i</code> and <code class=\"language-plaintext highlighter-rouge\">statement</code>?</p>\n\n<p>Let’s take the reference to <code class=\"language-plaintext highlighter-rouge\">session</code> before the loop – references are copyable:</p>\n\n<div class=\"language-rust highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>    <span class=\"c\">// ...</span>\n    <span class=\"k\">let</span> <span class=\"n\">session</span> <span class=\"o\">=</span> <span class=\"o\">&amp;</span><span class=\"n\">session</span><span class=\"p\">;</span>\n    <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"n\">in</span> <span class=\"mi\">0</span><span class=\"o\">..</span><span class=\"n\">count</span> <span class=\"p\">{</span>\n        <span class=\"c\">// ...</span>\n        <span class=\"nn\">tokio</span><span class=\"p\">::</span><span class=\"nf\">spawn</span><span class=\"p\">(</span><span class=\"k\">async</span> <span class=\"k\">move</span> <span class=\"p\">{</span>\n            <span class=\"c\">// ...</span>\n</code></pre></div></div>\n\n<p>But this brings us back to the first problem of insufficient lifetime, though:</p>\n<pre>\nerror[E0597]: `session` does not live long enough\n   --&gt; src/main.rs:262:19\n    |\n262 |       let session = &session;\n    |                     ^^^^^^^^ borrowed value does not live long enough\n...\n265 |           tokio::spawn(async move {\n    |  ______________________-\n266 | |             let result = session.execute(&amp;statement);\n267 | |             result.await.unwrap();\n268 | |         });\n    | |_________- argument requires that `session` is borrowed for `'static`\n...\n276 |   }\n    |   - `session` dropped here while still borrowed\n\n</pre>\n\n<p>So it looks like we can’t pass the session by move, \nbecause we want sharing, but we also can’t pass it by reference because the \nsession doesn’t live long enough.</p>\n\n<h1 id=\"scopes\">Scopes?</h1>\n<p>In <a href=\"/multiple-threadpools-rust/\">one of the earlier blog bosts</a> I showed how this problem\ncan be solved by using scoped threads. The concept of scope allows to force\nall background tasks to finish before the shared variables are dropped.</p>\n\n<p>Unfortunately, I haven’t found anything like scopes inside of the <code class=\"language-plaintext highlighter-rouge\">tokio</code> crate. \nA search reveals a <a href=\"https://github.com/tokio-rs/tokio/issues/2596\">ticket</a>, but it has been closed\nand the conclusion is a bit disappointing:</p>\n\n<blockquote>\n  <p>As @Matthias247 pointed out, one should be able to establish scopes at any point. \nHowever, there is no way to enforce the scope without blocking the thread. \nThe best we can do towards enforcing the scope is to panic when used “incorrectly”. \nThis is the strategy @Matthias247 has taken in his PRs. However, dropping adhoc is currently a key async rust pattern. \nI think this prohibits pancing when dropping a scope that isn’t 100% complete. If we do this, using a scope within a select! would lead to panics.\nWe are at an impasse. Maybe if AsyncDrop lands in Rust then we can investigate this again. Until then, we have no way forward, so I will close this. \nIt is definitely an unfortunate outcome.</p>\n</blockquote>\n\n<p>Of course, if you are fine with blocking the thread on scope exit, you can use the \n<a href=\"https://docs.rs/tokio-scoped/0.1.0/tokio_scoped/\">tokio_scoped</a> crate.</p>\n\n<h1 id=\"arc\">ARC</h1>\n<p>The lifetime problem can be also solved with automatic reference counting. \nLet’s wrap the <code class=\"language-plaintext highlighter-rouge\">session</code> and <code class=\"language-plaintext highlighter-rouge\">statement</code> in <code class=\"language-plaintext highlighter-rouge\">Arc</code>. <code class=\"language-plaintext highlighter-rouge\">Arc</code> will keep the shared session and statement\nlive as long as there exists at least one unfinished task:</p>\n\n<div class=\"language-rust highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>    <span class=\"c\">// ...</span>\n    <span class=\"k\">let</span> <span class=\"n\">session</span> <span class=\"o\">=</span> <span class=\"nn\">Arc</span><span class=\"p\">::</span><span class=\"nf\">new</span><span class=\"p\">(</span><span class=\"n\">session</span><span class=\"p\">);</span>\n    <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"n\">in</span> <span class=\"mi\">0</span><span class=\"o\">..</span><span class=\"n\">count</span> <span class=\"p\">{</span>\n        <span class=\"k\">let</span> <span class=\"k\">mut</span> <span class=\"n\">statement</span> <span class=\"o\">=</span> <span class=\"n\">statement</span><span class=\"nf\">.bind</span><span class=\"p\">();</span>\n        <span class=\"n\">statement</span><span class=\"nf\">.bind</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">i</span> <span class=\"k\">as</span> <span class=\"nb\">i64</span><span class=\"p\">)</span><span class=\"nf\">.unwrap</span><span class=\"p\">();</span>\n        <span class=\"k\">let</span> <span class=\"n\">session</span> <span class=\"o\">=</span> <span class=\"n\">session</span><span class=\"nf\">.clone</span><span class=\"p\">();</span>\n        <span class=\"nn\">tokio</span><span class=\"p\">::</span><span class=\"nf\">spawn</span><span class=\"p\">(</span><span class=\"k\">async</span> <span class=\"k\">move</span> <span class=\"p\">{</span>\n            <span class=\"c\">// ...</span>\n\n</code></pre></div></div>\n\n<p>This compiles fine and it wasn’t even that hard! Let’s run it:</p>\n<pre>\nthread 'tokio-runtime-worker' panicked at 'called `Result::unwrap()` on an `Err` value: \nError(CassError(LIB_REQUEST_QUEUE_FULL, \"The request queue has reached capacity\"), State { next_error: None, backtrace: InternalBacktrace { backtrace: None } })', src/main.rs:271:26\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\n</pre>\n\n<p>We submitted 100000 async queries all at once and the client driver’s queue can’t hold so many. \nLet’s do a quick temporary workaround: lower the <code class=\"language-plaintext highlighter-rouge\">count</code> to 1000.\nThe benchmark finishes fine now:</p>\n\n<pre>\nThroughput: 3095975.2 request/s\n</pre>\n\n<p>But is the result correct? Is Apache Cassandra really so fast? I’d really love to use a database that can do 3+ mln queries per second on a developer’s laptop,\nbut unfortunately this isn’t the case. The benchmark is still incorrect. Now we don’t wait at all for the results to come back from the database. \nThe benchmark submits the queries to the driver’s queue as fast as possible and then it immediately considers its job done. So we only measured how fast we\ncan send the queries to the local driver’s queue (not even how fast we can push them to the database server).</p>\n\n<h1 id=\"waiting-for-everything-to-finish\">Waiting for Everything to Finish</h1>\n<p>Look at what we’re doing with the result of the query:</p>\n\n<div class=\"language-rust highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>            <span class=\"c\">// ...</span>\n            <span class=\"k\">let</span> <span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">session</span><span class=\"nf\">.execute</span><span class=\"p\">(</span><span class=\"o\">&amp;</span><span class=\"n\">statement</span><span class=\"p\">);</span>\n            <span class=\"n\">result</span><span class=\"k\">.await</span><span class=\"nf\">.unwrap</span><span class=\"p\">();</span>        \n        <span class=\"p\">});</span>\n</code></pre></div></div>\n\n<p>The problem is: we’re doing nothing! After unwrapping, we’re just throwing the result away. \nAlthough the <code class=\"language-plaintext highlighter-rouge\">await</code> might look like we were waiting for the result from the server, note this is \nall happening in the coroutine and the top-level code doesn’t wait for it.</p>\n\n<p>Can we pass the results back from the nested tasks to the top level and wait for them at the end? \nYes! Tokio provides its own, async implementation of a communication channel. \nLet’s setup a channel, plug its sending side to the coroutine and receive at the top-level at the end, \nbut before computing the end time:</p>\n\n<div class=\"language-rust highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>    <span class=\"k\">let</span> <span class=\"n\">start</span> <span class=\"o\">=</span> <span class=\"nn\">Instant</span><span class=\"p\">::</span><span class=\"nf\">now</span><span class=\"p\">();</span>\n    <span class=\"k\">let</span> <span class=\"p\">(</span><span class=\"n\">tx</span><span class=\"p\">,</span> <span class=\"k\">mut</span> <span class=\"n\">rx</span><span class=\"p\">)</span> <span class=\"o\">=</span> <span class=\"nn\">tokio</span><span class=\"p\">::</span><span class=\"nn\">sync</span><span class=\"p\">::</span><span class=\"nn\">mpsc</span><span class=\"p\">::</span><span class=\"nf\">unbounded_channel</span><span class=\"p\">();</span>\n    <span class=\"k\">let</span> <span class=\"n\">session</span> <span class=\"o\">=</span> <span class=\"nn\">Arc</span><span class=\"p\">::</span><span class=\"nf\">new</span><span class=\"p\">(</span><span class=\"n\">session</span><span class=\"p\">);</span>\n    <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"n\">in</span> <span class=\"mi\">0</span><span class=\"o\">..</span><span class=\"n\">count</span> <span class=\"p\">{</span>\n        <span class=\"k\">let</span> <span class=\"k\">mut</span> <span class=\"n\">statement</span> <span class=\"o\">=</span> <span class=\"n\">statement</span><span class=\"nf\">.bind</span><span class=\"p\">();</span>\n        <span class=\"n\">statement</span><span class=\"nf\">.bind</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">i</span> <span class=\"k\">as</span> <span class=\"nb\">i64</span><span class=\"p\">)</span><span class=\"nf\">.unwrap</span><span class=\"p\">();</span>\n\n        <span class=\"k\">let</span> <span class=\"n\">session</span> <span class=\"o\">=</span> <span class=\"n\">session</span><span class=\"nf\">.clone</span><span class=\"p\">();</span>\n        <span class=\"k\">let</span> <span class=\"n\">tx</span> <span class=\"o\">=</span> <span class=\"n\">tx</span><span class=\"nf\">.clone</span><span class=\"p\">();</span>\n        <span class=\"nn\">tokio</span><span class=\"p\">::</span><span class=\"nf\">spawn</span><span class=\"p\">(</span><span class=\"k\">async</span> <span class=\"k\">move</span> <span class=\"p\">{</span>\n            <span class=\"k\">let</span> <span class=\"n\">query_start</span> <span class=\"o\">=</span> <span class=\"nn\">Instant</span><span class=\"p\">::</span><span class=\"nf\">now</span><span class=\"p\">();</span>\n            <span class=\"k\">let</span> <span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">session</span><span class=\"nf\">.execute</span><span class=\"p\">(</span><span class=\"o\">&amp;</span><span class=\"n\">statement</span><span class=\"p\">);</span>\n            <span class=\"n\">result</span><span class=\"k\">.await</span><span class=\"nf\">.unwrap</span><span class=\"p\">();</span>\n            <span class=\"k\">let</span> <span class=\"n\">query_end</span> <span class=\"o\">=</span> <span class=\"nn\">Instant</span><span class=\"p\">::</span><span class=\"nf\">now</span><span class=\"p\">();</span>\n            <span class=\"k\">let</span> <span class=\"n\">duration_micros</span><span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">query_end</span> <span class=\"o\">-</span> <span class=\"n\">query_start</span><span class=\"p\">)</span><span class=\"nf\">.as_micros</span><span class=\"p\">();</span>\n            <span class=\"n\">tx</span><span class=\"nf\">.send</span><span class=\"p\">(</span><span class=\"n\">duration_micros</span><span class=\"p\">)</span><span class=\"nf\">.unwrap</span><span class=\"p\">();</span>\n        <span class=\"p\">});</span>\n    <span class=\"p\">}</span>   \n    <span class=\"c\">// We need to drop the top-level tx we created at the beginning,</span>\n    <span class=\"c\">// so all txs are dropped when all queries finish. </span>\n    <span class=\"c\">// Otherwise the following read loop would wait for more data forever.</span>\n    <span class=\"k\">drop</span><span class=\"p\">(</span><span class=\"n\">tx</span><span class=\"p\">);</span>\n\n    <span class=\"k\">let</span> <span class=\"k\">mut</span> <span class=\"n\">successful_count</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span>\n    <span class=\"k\">while</span> <span class=\"k\">let</span> <span class=\"nf\">Some</span><span class=\"p\">(</span><span class=\"n\">duration</span><span class=\"p\">)</span> <span class=\"o\">=</span> <span class=\"n\">rx</span><span class=\"nf\">.next</span><span class=\"p\">()</span><span class=\"k\">.await</span> <span class=\"p\">{</span>\n        <span class=\"c\">// Here we get a sequence of durations</span>\n        <span class=\"c\">// We could use it also to compute e.g. the mean duration or the histogram</span>\n        <span class=\"n\">successful_count</span> <span class=\"o\">+=</span> <span class=\"mi\">1</span><span class=\"p\">;</span>\n    <span class=\"p\">}</span>\n\n    <span class=\"k\">let</span> <span class=\"n\">end</span> <span class=\"o\">=</span> <span class=\"nn\">Instant</span><span class=\"p\">::</span><span class=\"nf\">now</span><span class=\"p\">();</span>\n    <span class=\"nd\">println!</span><span class=\"p\">(</span>\n        <span class=\"s\">\"Throughput: {:.1} request/s\"</span><span class=\"p\">,</span>\n        <span class=\"mf\">1000000.0</span> <span class=\"o\">*</span> <span class=\"n\">successful_count</span> <span class=\"k\">as</span> <span class=\"nb\">f64</span> <span class=\"o\">/</span> <span class=\"p\">(</span><span class=\"n\">end</span> <span class=\"o\">-</span> <span class=\"n\">start</span><span class=\"p\">)</span><span class=\"nf\">.as_micros</span><span class=\"p\">()</span> <span class=\"k\">as</span> <span class=\"nb\">f64</span>\n    <span class=\"p\">);</span>\n\n</code></pre></div></div>\n\n<p>This prints a much more accurate number:</p>\n<pre>\nThroughput: 91734.7 request/s\n</pre>\n\n<p>Can we now increase the count back to 100,000?\nNot yet. Although we’re waiting at the end, the loop still spins like crazy submitting all the\nqueries at once and overflowing the queues. We need to slow it down.</p>\n\n<h1 id=\"backpressure\">Backpressure</h1>\n<p>We don’t want to exceed the capacity of the internal queues of the driver.\nHence, we need to keep the number of submitted but unfinished queries limited.\nThis is a good task for a semaphore. A semaphore is a structure that allows at most\nN parallel tasks. Tokio comes with a nice, asynchronous implementation of semaphore.\nThe <code class=\"language-plaintext highlighter-rouge\">Semaphore</code> structure allows a limited number of permits. The function of obtaining\na permit is asynchronous, so it composes with the other elements we already use here.\nWe’ll obtain a permit before spawning a task, and drop the permit after receiving the\nresults.</p>\n\n<div class=\"language-rust highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>    <span class=\"c\">// ...</span>\n    <span class=\"k\">let</span> <span class=\"n\">parallelism_limit</span> <span class=\"o\">=</span> <span class=\"mi\">1000</span><span class=\"p\">;</span>\n    <span class=\"k\">let</span> <span class=\"n\">semaphore</span> <span class=\"o\">=</span> <span class=\"nn\">Arc</span><span class=\"p\">::</span><span class=\"nf\">new</span><span class=\"p\">(</span><span class=\"nn\">Semaphore</span><span class=\"p\">::</span><span class=\"nf\">new</span><span class=\"p\">(</span><span class=\"n\">parallelism_limit</span><span class=\"p\">));</span>\n    <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"n\">in</span> <span class=\"mi\">0</span><span class=\"o\">..</span><span class=\"n\">count</span> <span class=\"p\">{</span>\n        <span class=\"c\">// ...</span>\n        <span class=\"k\">let</span> <span class=\"n\">permit</span> <span class=\"o\">=</span> <span class=\"n\">semaphore</span><span class=\"nf\">.clone</span><span class=\"p\">()</span><span class=\"nf\">.acquire_owned</span><span class=\"p\">()</span><span class=\"k\">.await</span><span class=\"p\">;</span>\n        <span class=\"nn\">tokio</span><span class=\"p\">::</span><span class=\"nf\">spawn</span><span class=\"p\">(</span><span class=\"k\">async</span> <span class=\"k\">move</span> <span class=\"p\">{</span>\n            <span class=\"c\">// ... run the query and await the result</span>\n\n            <span class=\"c\">// Now drop the permit; </span>\n            <span class=\"c\">// Actually it is sufficient to reference the permit value </span>\n            <span class=\"c\">// anywhere inside the coroutine so it is moved here and it would be dropped</span>\n            <span class=\"c\">// automatically at the closing brace. But drop is more explicitly </span>\n            <span class=\"c\">// telling the intent.</span>\n            <span class=\"k\">drop</span><span class=\"p\">(</span><span class=\"n\">permit</span><span class=\"p\">);</span>\n        <span class=\"p\">}</span>\n    <span class=\"p\">});</span>\n    <span class=\"c\">// ...</span>\n\n</code></pre></div></div>\n<p>Because the permit is passed to the asynchronous code that may outlive the\nscope of main, here again we need to use <code class=\"language-plaintext highlighter-rouge\">Arc</code>. We also needed to use an owned permit,\nrather than the standard one obtained by <code class=\"language-plaintext highlighter-rouge\">acquire()</code>. \nAn owned permit can be moved, a standard one cannot.</p>\n\n<p>After putting it all together, and running the benchmark for a few times to warmup the server, \nthe final throughput of running 100k queries was:</p>\n<pre>\nThroughput: 152374.3 request/s\n</pre>\n\n<h1 id=\"the-final-word\">The Final Word</h1>\n<p>Benchmarking is hard and it is easy to get \nincorrect results or arrive at incorrect conclusions.</p>\n\n<p>Keep in mind that the way how you query data may severly affect the numbers you get.\nWatch for:</p>\n<ul>\n  <li>Parallelism levels</li>\n  <li>Number of connections / threads</li>\n  <li>Coordinated omission</li>\n  <li>Caching effects</li>\n  <li>JVM warmup effects</li>\n  <li>Data sizes (does the query even return any results?)</li>\n  <li>Waiting for all the stuff to actually finish before reading the wall clock time</li>\n  <li>Using the available database features (e.g. prepared statements)</li>\n  <li>Queue size limits / backpressure</li>\n  <li>CPU and other resources consumed by the benchmarking program</li>\n</ul>\n\n<p>If you’d like to measure performance of your Cassandra cluster, \nyou should try the tool I’m working on at the moment: \n<a href=\"https://github.com/pkolaczk/latte\">Latte</a>. \nLatte uses uses the approach described in this blog post to measure \nthe throughput and response times. It is still very early-stage and \nI look forward to your feedback!</p>",
  "author": {
    "name": "Piotr Kołaczkowski"
  },
  "category": [
    "",
    "",
    "",
    "",
    "",
    ""
  ],
  "summary": "Performance of a database system depends on many factors: hardware, configuration, database schema, amount of data, workload type, network latency, and many others. Therefore, one typically can’t tell the actual performance of such system without first measuring it. In this blog post I’m describing how to build a benchmarking tool for Apache Cassandra from scratch in Rust and how to avoid many pitfalls. The techniques I show are applicable to any system with an async API."
}