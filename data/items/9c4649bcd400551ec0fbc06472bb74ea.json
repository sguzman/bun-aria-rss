{
  "title": "Thermal Vision: Night Object Detection with PyTorch and YOLOv5 (real project)",
  "link": "https://pyimagesearch.com/2022/10/31/thermal-vision-night-object-detection-with-pytorch-and-yolov5-real-project/",
  "dc:creator": "Raul Garcia-Martin",
  "pubDate": "Mon, 31 Oct 2022 13:00:00 +0000",
  "category": [
    "Infrared Vision",
    "IR Vision",
    "Object Detection",
    "OpenCV Tutorials",
    "Tutorials",
    "YOLOv5",
    "infrared vision",
    "night vision",
    "object detection",
    "opencv",
    "python",
    "tutorials",
    "yolov5"
  ],
  "guid": "https://pyimagesearch.com/?p=29516",
  "description": "<p>Table of Contents Thermal Vision: Night Object Detection with PyTorch and YOLOv5 (real project) Object Detection with Deep Learning Through PyTorch and YOLOv5 Discovering FLIR Thermal Starter Dataset Thermal Object Detection Using PyTorch and YOLOv5 Configuring Your Development Environment Having&#8230;</p>\n<p>The post <a rel=\"nofollow\" href=\"https://pyimagesearch.com/2022/10/31/thermal-vision-night-object-detection-with-pytorch-and-yolov5-real-project/\">Thermal Vision: Night Object Detection with PyTorch and YOLOv5 (real project)</a> appeared first on <a rel=\"nofollow\" href=\"https://pyimagesearch.com\">PyImageSearch</a>.</p>\n",
  "content:encoded": "\n<script src=\"https://fast.wistia.com/embed/medias/lv2p11fz0s.jsonp\" async=\"\"></script><script src=\"https://fast.wistia.com/assets/external/E-v1.js\" async=\"\"></script><div class=\"wistia_responsive_padding\" style=\"padding:56.25% 0 0 0;position:relative;\"><div class=\"wistia_responsive_wrapper\" style=\"height:100%;left:0;position:absolute;top:0;width:100%;\"><div class=\"wistia_embed wistia_async_lv2p11fz0s videoFoam=true\" style=\"height:100%;position:relative;width:100%\"><div class=\"wistia_swatch\" style=\"height:100%;left:0;opacity:0;overflow:hidden;position:absolute;top:0;transition:opacity 200ms;width:100%;\"><img src=\"https://fast.wistia.com/embed/medias/lv2p11fz0s/swatch\" style=\"filter:blur(5px);height:100%;object-fit:contain;width:100%;\" alt=\"\" aria-hidden=\"true\" onload=\"this.parentNode.style.opacity=1;\"></div></div></div></div>\n\n\n\n<hr class=\"wp-block-separator has-alpha-channel-opacity\" id=\"TOC\"/>\n\n\n\n<h2><strong>Table of Contents</strong></h2>\n\n\n\n<div class=\"toc\">\n<ul>\n    <li><a rel=\"noopener\" target=\"_blank\" href=\"#h2BPTitle\">Thermal Vision: Night Object Detection with PyTorch and YOLOv5 (real project)</a></li>\n        <ul>\n            <li><a rel=\"noopener\" target=\"_blank\" href=\"#h3PyTorch\">Object Detection with Deep Learning Through PyTorch and YOLOv5</a></li>\n            <li><a rel=\"noopener\" target=\"_blank\" href=\"#h3FLIR\">Discovering FLIR Thermal Starter Dataset</a></li>\n            <li><a rel=\"noopener\" target=\"_blank\" href=\"#h3Thermal\">Thermal Object Detection Using PyTorch and YOLOv5</a></li>\n            <li><a rel=\"noopener\" target=\"_blank\" href=\"#h3Environment\">Configuring Your Development Environment</a></li>\n            <li><a rel=\"noopener\" target=\"_blank\" href=\"#h3Problems\">Having Problems Configuring Your Development Environment?</a></li>\n            <li><a rel=\"noopener\" target=\"_blank\" href=\"#h3Structure\">Project Structure</a></li>\n                <ul>\n                    <li><a rel=\"noopener\" target=\"_blank\" href=\"#h4PreTraining\">Pre-Training</a></li>\n                    <li><a rel=\"noopener\" target=\"_blank\" href=\"#h4Training\">Training</a></li>\n                    <li><a rel=\"noopener\" target=\"_blank\" href=\"#h4Testing\">Testing</a></li>\n                </ul>\n        </ul>\n    <li><a rel=\"noopener\" target=\"_blank\" href=\"#h2Summary\">Summary</a></li>\n        <ul>\n            <li><a rel=\"noopener\" target=\"_blank\" href=\"#h3Citation\">Citation Information</a></li>\n        </ul>\n</ul>\n</div>\n\n\n\n<hr class=\"wp-block-separator has-alpha-channel-opacity\" id=\"h2BPTitle\"/>\n\n\n\n<h2><a href=\"#TOC\"><strong>Thermal Vision: Night Object Detection with PyTorch and YOLOv5 (real project)</strong></a></h2>\n\n\n\n<p>In today’s tutorial, you will detect objects in thermal images using Deep Learning and combining Python and OpenCV. As we have already discovered, thermal cameras allow us to see in absolute darkness, so we will learn how to detect objects under any visible light condition!</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter is-resized\"><a href=\"https://lh4.googleusercontent.com/LHaSngo7_dt5r51J1diPxZvMdZFHr2cfAWrLaXExZXs9Ux9eVyRGqApyFpeTbdFbUwChWbGjbmS-6MILvzVeFzfMQjbO7LNEJyTLIZJ6vnIxLPSM_P2mH4F1nVC7U745rWPOyXHFfReyS4Q9vN8FocunUeS6BjYODvEGKJkqSGgsG6MGzLUvE6ctBw\" target=\"_blank\" rel=\"noreferrer noopener\"><img src=\"https://lh4.googleusercontent.com/LHaSngo7_dt5r51J1diPxZvMdZFHr2cfAWrLaXExZXs9Ux9eVyRGqApyFpeTbdFbUwChWbGjbmS-6MILvzVeFzfMQjbO7LNEJyTLIZJ6vnIxLPSM_P2mH4F1nVC7U745rWPOyXHFfReyS4Q9vN8FocunUeS6BjYODvEGKJkqSGgsG6MGzLUvE6ctBw\" alt=\"\" width=\"700\" height=\"393\"/></a></figure></div>\n\n\n<p>This lesson includes:</p>\n\n\n\n<ul><li>Object Detection with Deep Learning through PyTorch and YOLOv5</li><li>Discovering FLIR Thermal Starter Dataset</li><li>Thermal Object Detection Using PyTorch and YOLOv5</li></ul>\n\n\n\n<p>This tutorial is the last of our 4-part course on <strong>Infrared Vision Basics</strong>:</p>\n\n\n\n<ol><li><a href=\"https://pyimg.co/oj6kb\" target=\"_blank\" rel=\"noreferrer noopener\"><em>Introduction to Infrared Vision: Near vs. Mid-Far Infrared Images</em></a></li><li><a href=\"https://pyimg.co/mns3e\" target=\"_blank\" rel=\"noreferrer noopener\"><em>Thermal Vision: Measuring your First Temperature from an Image with Python and OpenCV</em></a></li><li><a href=\"https://pyimg.co/6nxs0\" target=\"_blank\" rel=\"noreferrer noopener\"><em>Thermal Vision: Fever Detector with Python and OpenCV (starter project)</em></a></li><li><a href=\"https://pyimg.co/p2zsm\" target=\"_blank\" rel=\"noreferrer noopener\"><strong><em>Thermal Vision: Night Object Detection with PyTorch and YOLOv5 (real project)</em></strong></a><strong> (today’s tutorial)</strong></li></ol>\n\n\n\n<p>By the end of this lesson, you’ll learn how to detect different objects using thermal images and Deep Learning in a very quick, easy, and up-to-date way, using only four pieces of code!</p>\n\n\n\n<p><strong>To learn how to utilize YOLOv5 using your custom thermal imaging dataset, </strong><strong><em>just keep reading</em></strong><strong>.</strong></p>\n\n\n\n<hr class=\"wp-block-separator has-alpha-channel-opacity\" id=\"h2BPTitle\"/>\n\n\n\n<h2><a href=\"#TOC\"><strong>Thermal Vision: Night Object Detection with PyTorch and YOLOv5 (real project)</strong></a></h2>\n\n\n\n<hr class=\"wp-block-separator has-alpha-channel-opacity\" id=\"h3PyTorch\"/>\n\n\n\n<h3><a href=\"#TOC\"><strong>Object Detection with Deep Learning Through PyTorch and YOLOv5</strong></a></h3>\n\n\n\n<p>In our <a href=\"https://pyimg.co/6nxs0\" target=\"_blank\" rel=\"noreferrer noopener\">previous tutorial</a>, we covered how we can apply, in a real solution, the temperature measured from a thermal image using Python, OpenCV, and a traditional Machine Learning method.</p>\n\n\n\n<p>From that point and based on all the content covered during this course, the PyImageSearch team appeals to your imagination to excel in any thermal imaging situation, but not before providing you with another powerful and real-life example of this incredible combination: Computer Vision + Thermal Imaging.</p>\n\n\n\n<p>In this case, we will learn how computers can see in the dark distinguishing different object classes in real time.</p>\n\n\n\n<p>Before starting this tutorial, for better comprehension, we encourage you to take the Torch Hub Series course at PyImageSearch University or gain some experience with PyTorch and Deep Learning. As in all PyImageSearch University courses, we will cover all aspects step by step.</p>\n\n\n\n<p>As explained in <a href=\"https://pyimagesearch.com/2022/01/03/torch-hub-series-3-yolov5-and-ssd-models-on-object-detection/\" target=\"_blank\" rel=\"noreferrer noopener\">Torch Hub Series #3: YOLOv5 and SSD — Models on Object Detection</a>, YOLOv5 — <a href=\"https://arxiv.org/abs/1506.02640\" target=\"_blank\" rel=\"noreferrer noopener\">You Only Look Once</a> (<strong>Figure 1</strong>, 2015) version 5 — is the fifth version of one of the most powerful state-of-the-art Convolutional Neural Network models. This fast object detector model is usually trained on the <a href=\"https://cocodataset.org/#home\" target=\"_blank\" rel=\"noreferrer noopener\">COCO dataset</a>, an open-access Microsoft RGB imaging database consisting of 330K images, 91 object classes, and 2.5 million labeled instances.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-large is-resized\"><img src=\"https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-1-yolo-logo-1024x544.png?lossy=1&strip=1&webp=1\" alt=\"\" class=\"wp-image-35339\" width=\"512\" height=\"272\" srcset=\"https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-1-yolo-logo.png?size=126x67&lossy=1&strip=1&webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-1-yolo-logo-300x159.png?lossy=1&strip=1&webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-1-yolo-logo.png?size=378x201&lossy=1&strip=1&webp=1 378w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-1-yolo-logo.png?size=504x268&lossy=1&strip=1&webp=1 504w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-1-yolo-logo-768x408.png?lossy=1&strip=1&webp=1 768w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-1-yolo-logo-1024x544.png?lossy=1&strip=1&webp=1 1024w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-1-yolo-logo.png?lossy=1&strip=1&webp=1 1337w\" sizes=\"(max-width: 512px) 100vw, 512px\" /><figcaption><strong>Figure 1:</strong> Original YOLO logo (<a href=\"https://pjreddie.com/darknet/yolo/\" target=\"_blank\" rel=\"noreferrer noopener\">source</a>).</figcaption></figure></div>\n\n\n<p>This strong combination makes YOLOv5 the perfect model to detect objects even in our custom imaging datasets. For obtaining a thermal object detector, we will use Transfer Learning (i.e., to train the COCO-pre-trained YOLOv5 model on a real thermal imaging dataset especially collected for self-driving car solutions).</p>\n\n\n\n<hr class=\"wp-block-separator has-alpha-channel-opacity\" id=\"h3FLIR\"/>\n\n\n\n<h3><a href=\"#TOC\"><strong>Discovering FLIR Thermal Starter Dataset</strong></a></h3>\n\n\n\n<p>The thermal imaging dataset that we are going to use to train our pre-trained YOLOv5 model is the <a href=\"https://www.kaggle.com/datasets/deepnewbie/flir-thermal-images-dataset\" target=\"_blank\" rel=\"noreferrer noopener\">free Teledyne FLIR ADAS Dataset</a>.</p>\n\n\n\n<p>This database consists of 14,452 thermal images in gray8 and gray16 format, which, as we have learned, allows us to measure any pixel temperature. All the 14,452 gray8 images acquired in some streets of California with a mounted-car thermal camera are hand-labeled with bounding boxes, as <strong>Figure 2</strong> shows. We will use these annotations (labels + bounding boxes) to detect four different object categories out of the four classes predefined in this dataset: <code class=\"EnlighterJSRAW\" data-enlighter-language=\"python\">car</code>, <code class=\"EnlighterJSRAW\" data-enlighter-language=\"python\">person</code>, <code class=\"EnlighterJSRAW\" data-enlighter-language=\"python\">bicycle</code>, and <code class=\"EnlighterJSRAW\" data-enlighter-language=\"python\">dog</code>.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-large is-resized\"><a href=\"https://pyimagesearch.com/wp-content/uploads/2022/10/figure-2-dataset.png\" target=\"_blank\" rel=\"noreferrer noopener\"><img src=\"https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-2-dataset-1024x489.png?lossy=1&strip=1&webp=1\" alt=\"\" class=\"wp-image-35341\" width=\"700\" height=\"334\" srcset=\"https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-2-dataset.png?size=126x60&lossy=1&strip=1&webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-2-dataset-300x143.png?lossy=1&strip=1&webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-2-dataset.png?size=378x180&lossy=1&strip=1&webp=1 378w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-2-dataset.png?size=504x240&lossy=1&strip=1&webp=1 504w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-2-dataset.png?size=630x301&lossy=1&strip=1&webp=1 630w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-2-dataset-768x367.png?lossy=1&strip=1&webp=1 768w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-2-dataset-1024x489.png?lossy=1&strip=1&webp=1 1024w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-2-dataset-1536x734.png?lossy=1&strip=1&webp=1 1536w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-2-dataset.png?lossy=1&strip=1&webp=1 1710w\" sizes=\"(max-width: 630px) 100vw, 630px\" /></a><figcaption><strong>Figure 2:</strong> Example of a gray8 thermal image (<em>left</em>) and a gray8 thermal image hand-labeled with bounding boxes (<em>right</em>). The hand-labeled image (<em>right</em>) shows the object detection of the 4 defined classes: <code>car</code> (yellow), <code>person</code> (pink), <code>bicycle</code> (purple), and <code>dog</code> (red).</figcaption></figure></div>\n\n\n<p>A JSON file with the COCO format annotations is provided. To simplify this tutorial, we give you the annotations in the YOLOv5 PyTorch format. You can find a <code class=\"EnlighterJSRAW\" data-enlighter-language=\"python\">labels</code> folder with individual annotations for each gray8 image.</p>\n\n\n\n<p>We have also reduced the dataset to 1,772 images: 1000 to train our pre-trained YOLOv5 model and 772 to validate it (i.e., approximately 60-40% training-validation split). These images have been selected from the training portion of the original dataset.</p>\n\n\n\n<hr class=\"wp-block-separator has-alpha-channel-opacity\" id=\"h3Thermal\"/>\n\n\n\n<h3><a href=\"#TOC\"><strong>Thermal Object Detection Using PyTorch and YOLOv5</strong></a></h3>\n\n\n\n<p>Once we have learned all the concepts seen so far … let’s play!</p>\n\n\n\n<hr class=\"wp-block-separator has-alpha-channel-opacity\" id=\"h3Environment\"/>\n\n\n\n<h3><a href=\"#TOC\"><strong>Configuring Your Development Environment</strong></a></h3>\n\n\n\n<p>To follow this guide, you need to have the OpenCV library installed on your system.</p>\n\n\n\n<p>Luckily, OpenCV is pip-installable:</p>\n\n\n\n<pre class=\"EnlighterJSRAW\" data-enlighter-language=\"shell\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"true\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"Thermal Vision: Night Object Detection with PyTorch and YOLOv5 (real project)\" data-enlighter-group=\"101\">$ pip install opencv-contrib-python</pre>\n\n\n\n<p><strong>If you need help configuring your development environment for OpenCV, we <em>highly recommend</em> that you read our </strong><a href=\"https://pyimagesearch.com/2018/09/19/pip-install-opencv/\" target=\"_blank\" rel=\"noreferrer noopener\"><strong><em>pip install OpenCV</em> guide</strong></a> — it will have you up and running in a matter of minutes.</p>\n\n\n\n<hr class=\"wp-block-separator has-alpha-channel-opacity\" id=\"h3Problems\"/>\n\n\n\n<h3><a href=\"#TOC\"><strong>Having Problems Configuring Your Development Environment?</strong></a></h3>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><a href=\"https://pyimagesearch.com/pyimagesearch-university/\" target=\"_blank\" rel=\"noreferrer noopener\"><img width=\"500\" height=\"334\" src=\"https://929687.smushcdn.com/2633864/wp-content/uploads/2021/05/pyimagesearch_plus_jupyter.png?lossy=1&strip=1&webp=1\" alt=\"\" class=\"wp-image-19836\" srcset=\"https://929687.smushcdn.com/2633864/wp-content/uploads/2021/05/pyimagesearch_plus_jupyter.png?size=126x84&lossy=1&strip=1&webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2021/05/pyimagesearch_plus_jupyter-300x200.png?lossy=1&strip=1&webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2021/05/pyimagesearch_plus_jupyter.png?size=378x253&lossy=1&strip=1&webp=1 378w, https://929687.smushcdn.com/2633864/wp-content/uploads/2021/05/pyimagesearch_plus_jupyter.png?lossy=1&strip=1&webp=1 500w\" sizes=\"(max-width: 500px) 100vw, 500px\" /></a><figcaption>Having trouble configuring your dev environment? Want access to pre-configured Jupyter Notebooks running on Google Colab? Be sure to join <a href=\"https://pyimagesearch.com/pyimagesearch-university/\" target=\"_blank\" rel=\"noreferrer noopener\">PyImageSearch University</a> — you’ll be up and running with this tutorial in a matter of minutes.</figcaption></figure></div>\n\n\n<p>All that said, are you:</p>\n\n\n\n<ul><li>Short on time?</li><li>Learning on your employer’s administratively locked system?</li><li>Wanting to skip the hassle of fighting with the command line, package managers, and virtual environments?</li><li><strong>Ready to run the code </strong><strong><em>right now</em></strong><strong> on your Windows, macOS, or Linux system?</strong></li></ul>\n\n\n\n<p>Then join <a href=\"https://pyimagesearch.com/pyimagesearch-university/\" target=\"_blank\" rel=\"noreferrer noopener\">PyImageSearch University</a> today!</p>\n\n\n\n<p><strong>Gain access to Jupyter Notebooks for this tutorial and other PyImageSearch guides that are </strong><strong><em>pre-configured</em></strong><strong> to run on Google Colab’s ecosystem right in your web browser!</strong> No installation required.</p>\n\n\n\n<p>And best of all, these Jupyter Notebooks will run on Windows, macOS, and Linux!</p>\n\n\n\n<hr class=\"wp-block-separator has-alpha-channel-opacity\" id=\"h3Structure\"/>\n\n\n\n<h3><a href=\"#TOC\"><strong>Project Structure</strong></a></h3>\n\n\n\n<p>We first need to review our project directory structure.</p>\n\n\n\n<p>Start by accessing this tutorial’s <strong><em>“Downloads”</em></strong> section to retrieve the source code and example images.</p>\n\n\n\n<p>From there, take a look at the directory structure:</p>\n\n\n\n<pre class=\"EnlighterJSRAW\" data-enlighter-language=\"shell\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"true\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"Thermal Vision: Night Object Detection with PyTorch and YOLOv5 (real project)\" data-enlighter-group=\"1\">$ tree --dirsfirst\n.\n└── yolov5\n    ├── data\n    ├── models\n    ├── utils\n    ├── CONTRIBUTING.md\n    ├── Dockerfile\n    ├── LICENSE\n    ├── ...\n    └── val.py\n\n1 directory, XX files</pre>\n\n\n\n<p>We set up this structure by cloning the official YOLOv5 repository.</p>\n\n\n\n<pre class=\"EnlighterJSRAW\" data-enlighter-language=\"python\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"true\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"Thermal Vision: Night Object Detection with PyTorch and YOLOv5 (real project)\" data-enlighter-group=\"2\"># clone the yolov5 repository from GitHub and install some necessary packages (requirements.txt file)\n!git clone https://github.com/ultralytics/yolov5\n%cd yolov5\n%pip install -qr requirements.txt</pre>\n\n\n\n<p>See the codes on <strong>Lines 2 and 3</strong>.</p>\n\n\n\n<p>Notice that we also installed the required libraries indicated in the <code data-enlighter-language=\"python\" class=\"EnlighterJSRAW\">requirements.txt</code> file (<strong>Line 4</strong>): Matplotlib, NumPy, OpenCV, PyTorch, etc.</p>\n\n\n\n<p>In the <code class=\"EnlighterJSRAW\" data-enlighter-language=\"python\">yolov5</code> folder, we can find all the necessary files to use YOLOv5 in any of our projects:</p>\n\n\n\n<ul><li><code class=\"EnlighterJSRAW\" data-enlighter-language=\"python\">data</code>: contains the required information to manage different datasets as COCO.</li><li><code class=\"EnlighterJSRAW\" data-enlighter-language=\"python\">models</code>: we can find all the YOLOv5 CNN structures in Yet Another Markup Language (YAML) format, a human-friendly data serialization language for programming languages.</li><li><code class=\"EnlighterJSRAW\" data-enlighter-language=\"python\">utils</code>: includes some necessary Python files to manage the training, the dataset, the information visualization, and general project utilities.</li></ul>\n\n\n\n<p>The rest of the files in the <code class=\"EnlighterJSRAW\" data-enlighter-language=\"python\">yolov5</code> files are required, but we will only run two of them: </p>\n\n\n\n<ul><li><code><a href=\"https://github.com/ultralytics/yolov5/blob/master/train.py\" target=\"_blank\" rel=\"noreferrer noopener\">train.py</a></code>: is a file to train our model, which is part of the repository we cloned above </li><li><code><a href=\"https://github.com/ultralytics/yolov5/blob/master/detect.py\" target=\"_blank\" rel=\"noreferrer noopener\">detect.py</a></code>: is a file to test our model by inferring the detected objects, which is also part of the repository we cloned above </li></ul>\n\n\n\n<p>The <code class=\"EnlighterJSRAW\" data-enlighter-language=\"python\">thermal_imaging_dataset</code> folder includes our 1,772 gray8 thermal images. This folder contains the images (<code class=\"EnlighterJSRAW\" data-enlighter-language=\"python\">thermal_imaging_dataset/images</code>) and the labels (<code class=\"EnlighterJSRAW\" data-enlighter-language=\"python\">thermal_imaging_dataset/labels</code>) split into the training and validation sets, respectively, <code class=\"EnlighterJSRAW\" data-enlighter-language=\"python\">train</code> and <code class=\"EnlighterJSRAW\" data-enlighter-language=\"python\">val</code> folders.</p>\n\n\n\n<p>The <code class=\"EnlighterJSRAW\" data-enlighter-language=\"python\">thermal_imaging_video_test.mp4</code> is the video file on which we will test our thermal object detection model. It contains 4,224 thermal frames acquired at 30 fps with scenes of streets and highways.</p>\n\n\n\n<pre class=\"EnlighterJSRAW\" data-enlighter-language=\"python\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"true\" data-enlighter-lineoffset=\"6\" data-enlighter-title=\"Thermal Vision: Night Object Detection with PyTorch and YOLOv5 (real project)\" data-enlighter-group=\"3\"># import PyTorch and check versions\nimport torch\nfrom yolov5 import utils\ndisplay = utils.notebook_init()</pre>\n\n\n\n<p>Open your <code class=\"EnlighterJSRAW\" data-enlighter-language=\"python\">yolov5.py</code> file and import the required packages (<strong>Lines 7 and 8</strong>), checking your notebook features (<strong>Line 9</strong>) if you are working with Jupyter Notebooks on Google Colab.</p>\n\n\n\n<p>Check that your environment includes a GPU (<strong>Figure 3</strong>) to run our next training process in a reasonable time successfully.</p>\n\n\n\n<div class=\"wp-container-9 wp-block-columns\">\n<div class=\"wp-container-8 wp-block-column\" style=\"flex-basis:100%\">\n<figure class=\"wp-block-image\"><img src=\"https://lh6.googleusercontent.com/u6OC0ZeCMvFXgTkzF-ArL4N27YbEAp96am18xziCyx94z8f-bMqppyyAmpO6BpIkESUE7VSEd1hAPIHpv9bWO6NA-RFlLAspoVxfJ2X2qa4gyVNZ_D3gk559ny7v6oTgiqrivbfoI5dRYsuFi5EsQqVF5F2nzO5o5RahgTzrApeTwnPWKeBboQLf\" alt=\"\"/></figure>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://lh3.googleusercontent.com/57bhXAqJqABFRrnOpYRdBWuQz1mdL_oCGn7oH1OppohtQWfi7rZKgfscEMHu8hIN4Nh5ncZNsVftyuGv36ihjrp-s_ALgr4XsO3raWP4RTswrdmcqO5byWoKaWNQRlms-Lhji3d426lcZxwUrM97h-ST2VolFxmPoO5yuDUCSJrwENIkUgtGGLw-\" alt=\"\"/></figure>\n\n\n\n<div class=\"wp-container-5 wp-block-columns\">\n<div class=\"wp-container-1 wp-block-column is-vertically-aligned-center\" style=\"flex-basis:50%\">\n<figure class=\"wp-block-image is-resized\"><img src=\"https://lh3.googleusercontent.com/2EUe61BzvqPpLYamqjP7aOqyRRSL5bl8QGJ2GonQXjgd1lyNS0VrzFrUob4Iuxu1iKco7Jmt1mHowjdSzHP9CdfU933mQ1V9L0r49JPMdhsnBm4x_Ngc0WFMKBdaTzB0oBprZhzjWyMInwK5Ce1jWn4oTxRYjyh0zHkqzuWJHJNb6V741RlEUEE2\" alt=\"\" width=\"350\" height=\"454\"/></figure>\n</div>\n\n\n\n<div class=\"wp-container-4 wp-block-column is-vertically-aligned-center\" style=\"flex-basis:50%\">\n<figure class=\"wp-container-3 wp-block-gallery-2 wp-block-gallery alignleft has-nested-images columns-default is-cropped\">\n<figure class=\"wp-block-image size-full\"><a href=\"https://pyimagesearch.com/wp-content/uploads/2022/10/figure-3-jupyter-set-up-4-2.png\" target=\"_blank\" rel=\"noreferrer noopener\"><img width=\"495\" height=\"472\" src=\"https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-3-jupyter-set-up-4-2.png?lossy=1&strip=1&webp=1\" alt=\"\" class=\"wp-image-35433\" srcset=\"https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-3-jupyter-set-up-4-2.png?size=126x120&lossy=1&strip=1&webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-3-jupyter-set-up-4-2-300x286.png?lossy=1&strip=1&webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-3-jupyter-set-up-4-2.png?size=378x360&lossy=1&strip=1&webp=1 378w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-3-jupyter-set-up-4-2.png?lossy=1&strip=1&webp=1 495w\" sizes=\"(max-width: 495px) 100vw, 495px\" /></a></figure>\n</figure>\n</div>\n</div>\n\n\n\n<figure class=\"wp-container-7 wp-block-gallery-6 wp-block-gallery aligncenter has-nested-images columns-default is-cropped\"><figcaption class=\"blocks-gallery-caption\"><strong>Figure 3:</strong> Jupyter Notebooks GPU configuration. Step 1: Go to <br><code>Additional connection options</code> and click <code>View resources</code> (<em>top</em>). Step 2: Check that your device has GPU RAM (<em>middle</em>); if not, follow the next step. Step 3: Click on <code>Change runtime type</code> (<em>bottom-left</em>). Step 4: Select GPU as a hardware accelerator (<em>bottom-right</em>).</figcaption></figure>\n</div>\n</div>\n\n\n\n<h4><a href=\"#TOC\"><strong>Pre-Training</strong></a></h4>\n\n\n\n<p>As we have already mentioned, we’ll use Transfer Learning to train our object detector model on our thermal imaging dataset using the YOLOv5 CNN architecture pre-trained on the COCO dataset as a starting point.</p>\n\n\n\n<p>For this purpose, the trained YOLOv5 model selected is the YOLOv5s version due to its high speed-accuracy performance.</p>\n\n\n\n<hr class=\"wp-block-separator has-alpha-channel-opacity\" id=\"h4Training\"/>\n\n\n\n<h4><a href=\"#TOC\"><strong>Training</strong></a></h4>\n\n\n\n<p>After setting up the environment and fulfilling all the requirements, let’s train our pre-trained model!</p>\n\n\n\n<pre class=\"EnlighterJSRAW\" data-enlighter-language=\"python\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"true\" data-enlighter-lineoffset=\"11\" data-enlighter-title=\"Thermal Vision: Night Object Detection with PyTorch and YOLOv5 (real project)\" data-enlighter-group=\"4\"># train pretrained YOLOv5s model on the custom thermal imaging dataset,\n# basic parameters:\n#  - image size (img): image size of the thermal dataset is 640 x 512, 640 passed\n#  - batch size (batch): 16 by default, 16 passed\n#  - epochs (epochs): number of epochs, 30 passed\n#  - dataset (data): dataset in .yaml file format, custom thermal image dataset passed \n#  - pre-trained YOLOv5 model (weights): YOLOv5 model version, YOLOv5s (small version) passed\n!python train.py --img 640 --batch 16 --epochs 30 --data thermal_image_dataset.yaml --weights yolov5s.pt</pre>\n\n\n\n<p>On <strong>Line 18</strong>, after importing the PyTorch and the YOLOv5 utils (<strong>Lines 7-9</strong>), we run the <code data-enlighter-language=\"python\" class=\"EnlighterJSRAW\">train.py</code> file by specifying the following parameters:</p>\n\n\n\n<ul><li><code data-enlighter-language=\"python\" class=\"EnlighterJSRAW\">img</code>: image size of the training images to be passed through our model. In our case, thermal images have a <code data-enlighter-language=\"python\" class=\"EnlighterJSRAW\">640x512</code> resolution, so we indicate the maximum size, 640 pixels.</li><li><code data-enlighter-language=\"python\" class=\"EnlighterJSRAW\">batch</code>: batch size. We set up a batch size of 16 images.</li><li><code data-enlighter-language=\"python\" class=\"EnlighterJSRAW\">epochs</code>: training epochs. After some tests, we established 30 epochs as a good number of iterations.</li><li><code data-enlighter-language=\"python\" class=\"EnlighterJSRAW\">data</code>: YAML dataset file. <strong>Figure 4</strong> shows our dataset file. It is pointing to the YOLOv5 dataset structure, previously explained: <br><br><code data-enlighter-language=\"python\" class=\"EnlighterJSRAW\">thermal_imaging_dataset/images/train</code> <br><code data-enlighter-language=\"python\" class=\"EnlighterJSRAW\">thermal_imaging_dataset/labels/train</code> ,<br><br>for training and: <br><br><code data-enlighter-language=\"python\" class=\"EnlighterJSRAW\">thermal_imaging_dataset/images/val</code> <br><code data-enlighter-language=\"python\" class=\"EnlighterJSRAW\">thermal_imaging_dataset/labels/val</code> ,<br><br>for validation.<br><br>It also indicates the number of classes, <code data-enlighter-language=\"python\" class=\"EnlighterJSRAW\">nc: 4</code>, and the class names, <code data-enlighter-language=\"python\" class=\"EnlighterJSRAW\">names: ['bicycle', 'car', 'dog', 'person']</code>. <br><br>This YAML dataset file should be located in <code data-enlighter-language=\"python\" class=\"EnlighterJSRAW\">yolov5/data</code>. </li><li><code data-enlighter-language=\"python\" class=\"EnlighterJSRAW\">weights</code>: calculates weights of the pre-trained model, in our case, YOLOv5s, on the COCO dataset. The <code data-enlighter-language=\"python\" class=\"EnlighterJSRAW\">yolov5s.pt</code> file is the pre-trained model that contains these weights and is located in <code data-enlighter-language=\"python\" class=\"EnlighterJSRAW\">yolov5/models</code>.</li></ul>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><a href=\"https://pyimagesearch.com/wp-content/uploads/2022/10/figure-4-yaml-dataset-file.png\" target=\"_blank\" rel=\"noreferrer noopener\"><img width=\"752\" height=\"140\" src=\"https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-4-yaml-dataset-file.png?lossy=1&strip=1&webp=1\" alt=\"\" class=\"wp-image-35363\" srcset=\"https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-4-yaml-dataset-file.png?size=126x23&lossy=1&strip=1&webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-4-yaml-dataset-file-300x56.png?lossy=1&strip=1&webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-4-yaml-dataset-file.png?size=378x70&lossy=1&strip=1&webp=1 378w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-4-yaml-dataset-file.png?size=504x94&lossy=1&strip=1&webp=1 504w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-4-yaml-dataset-file.png?size=630x117&lossy=1&strip=1&webp=1 630w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-4-yaml-dataset-file.png?lossy=1&strip=1&webp=1 752w\" sizes=\"(max-width: 630px) 100vw, 630px\" /></a><figcaption><strong>Figure 4:</strong> YAML dataset file: data <code>thermal_image_dataset.yaml</code>. It contains the thermal imaging dataset path, the number of classes, and the class names.</figcaption></figure></div>\n\n\n<p>That’s all we need to train our model!</p>\n\n\n\n<p>Let’s check out the results!</p>\n\n\n\n<p>After 30 epochs completed in the GPU NVIDIA Tesla T4 in 0.279 hours, our model has learned to detect the classes <code class=\"EnlighterJSRAW\" data-enlighter-language=\"python\">person</code>, <code class=\"EnlighterJSRAW\" data-enlighter-language=\"python\">car</code>, <code class=\"EnlighterJSRAW\" data-enlighter-language=\"python\">bicycle</code>, and <code class=\"EnlighterJSRAW\" data-enlighter-language=\"python\">dog</code>, achieving the mean Average Precision of 50.7%, mAP (IoU = 0.5) = 0.507, as <strong>Figure 5</strong> shows. This means that our average prediction, with an Intersection over Union (IoU, <strong>Figure 6</strong>) of 0.5, is 50.7% for all our classes.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-large\"><a href=\"https://pyimagesearch.com/wp-content/uploads/2022/10/figure-5-results.png\" target=\"_blank\" rel=\"noreferrer noopener\"><img width=\"1024\" height=\"283\" src=\"https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-5-results-1024x283.png?lossy=1&strip=1&webp=1\" alt=\"\" class=\"wp-image-35365\" srcset=\"https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-5-results.png?size=126x35&lossy=1&strip=1&webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-5-results-300x83.png?lossy=1&strip=1&webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-5-results.png?size=378x104&lossy=1&strip=1&webp=1 378w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-5-results.png?size=504x139&lossy=1&strip=1&webp=1 504w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-5-results.png?size=630x174&lossy=1&strip=1&webp=1 630w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-5-results-768x212.png?lossy=1&strip=1&webp=1 768w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-5-results-1024x283.png?lossy=1&strip=1&webp=1 1024w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-5-results.png?lossy=1&strip=1&webp=1 1195w\" sizes=\"(max-width: 630px) 100vw, 630px\" /></a><figcaption><strong>Figure 5:</strong> Results for our YOLOv5 model trained on the thermal imaging dataset. Inside the green box, the mean Average Precision for all classes is shown, mAP (IoU = 0.5) = 0.507. The mean Average Precision for each class is shown: <code>bicycle</code> (red), <code>car</code> (pink), <code>dog</code> (blue), and <code>person</code> (yellow). As you can deduce, our <code>bicycle</code> and <code>dog</code> classes are underrepresented with mAP <code>bicycle</code> (IoU = 0.5) = 0.456 and mAP <code>dog</code> (IoU = 0.5) = 0.004, respectively.</figcaption></figure></div>\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter\"><a href=\"https://lh3.googleusercontent.com/RMkuHUykGe2jBKvvaK9hn2kwLeVOBqPrVtzvUu9s3cQCi90lnLvNEJcXpG9UW86SgMwvFqyga9UScHmSKEWttLHuusXlRTj3f1HvwHAjwzSa3duwP1_-jDH8yPxl_DSbP9UupYjVBMli3l7SLRibDWJEP1Rd-k1jTSN6cgFJX20j97K8e2ITeJtF\" target=\"_blank\" rel=\"noreferrer noopener\"><img src=\"https://lh3.googleusercontent.com/RMkuHUykGe2jBKvvaK9hn2kwLeVOBqPrVtzvUu9s3cQCi90lnLvNEJcXpG9UW86SgMwvFqyga9UScHmSKEWttLHuusXlRTj3f1HvwHAjwzSa3duwP1_-jDH8yPxl_DSbP9UupYjVBMli3l7SLRibDWJEP1Rd-k1jTSN6cgFJX20j97K8e2ITeJtF\" alt=\"\"/></a><figcaption><strong>Figure 6:</strong> Intersection over Union (IoU) definition. Thermal image example from the dataset (<em>left</em>) with the hand-labeled bounding box (green) and the bounding box predicted by our trained YOLOv5 model (blue). The Intersection over Union is (IoU) the percentage calculated by dividing the Overlap Area (orange) and the Union Area (purple).</figcaption></figure></div>\n\n\n<p>As is shown in <strong>Figure 6</strong>, the Intersection over Union (IoU) is the right overlap of the bounding boxes when the original and the prediction are compared.</p>\n\n\n\n<p>So, for our <code class=\"EnlighterJSRAW\" data-enlighter-language=\"python\">person</code> class, our model properly detects, on average, 77.7% of the cases, considering a correct prediction when there is a bounding-boxes intersection of 50% or higher.</p>\n\n\n\n<p><strong>Figure 7</strong> compares two original images, their hand-labeled bounding boxes, and their predicted results.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter\"><a href=\"https://lh3.googleusercontent.com/5qH8NjpX8rnkDg2xcAVcw55W1nTKCienu5ECFHJqmf9O5StG77fsNbwwDF9hQwqd7-acm28hh48SU0Iimu_nWpWmEzlrom2IAr_NWKbsmLMTo3r_rYUZeMXCfjV32eNuJ6RfOC_NARO_jtDusTrMtktHgBYrklkmo3rJxMLPntJi_0LQqKvPQIAD\" target=\"_blank\" rel=\"noreferrer noopener\"><img src=\"https://lh3.googleusercontent.com/5qH8NjpX8rnkDg2xcAVcw55W1nTKCienu5ECFHJqmf9O5StG77fsNbwwDF9hQwqd7-acm28hh48SU0Iimu_nWpWmEzlrom2IAr_NWKbsmLMTo3r_rYUZeMXCfjV32eNuJ6RfOC_NARO_jtDusTrMtktHgBYrklkmo3rJxMLPntJi_0LQqKvPQIAD\" alt=\"\"/></a><figcaption><strong>Figure 7:</strong> Two image results of our trained model. Original images (<em>left</em>), hand-labeled images (<em>middle</em>), and predicted images (<em>right</em>). The hand-labeled images (<em>middle</em>)  and the YOLOv5 predicted images (<em>right</em>) show the object detection of 3 out of the 4 defined classes: <code>car</code> (pink), <code>person</code> (yellow), and <code>bicycle</code> (red).</figcaption></figure></div>\n\n\n<p>Although it is out of the scope of this tutorial, it is important to note that our dataset is highly unbalanced, with only 280 and 31 labels, respectively, for our <code class=\"EnlighterJSRAW\" data-enlighter-language=\"python\">bicycle</code> and <code class=\"EnlighterJSRAW\" data-enlighter-language=\"python\">dog</code> classes. That is why we obtain mAP <code class=\"EnlighterJSRAW\" data-enlighter-language=\"python\">bicycle</code> (IoU = 0.5) = 0.456 and mAP <code class=\"EnlighterJSRAW\" data-enlighter-language=\"python\">dog</code> (IoU = 0.5) = 0.004, respectively.</p>\n\n\n\n<p>Finally, to verify our results, <strong>Figure 8</strong> shows the Classification Loss during the training (<em>top-left</em>) and the validation (<em>bottom-left</em>) processes, and the mean Average Precision at IoU 50% (<em>middle-right</em>), mAP (IoU = 0.5) for all the classes through the 30 epochs.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-large\"><img width=\"864\" height=\"1024\" src=\"https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-8-training-validation-loss-864x1024.png?lossy=1&strip=1&webp=1\" alt=\"\" class=\"wp-image-35369\" srcset=\"https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-8-training-validation-loss.png?size=126x149&lossy=1&strip=1&webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-8-training-validation-loss-253x300.png?lossy=1&strip=1&webp=1 253w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-8-training-validation-loss.png?size=378x448&lossy=1&strip=1&webp=1 378w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-8-training-validation-loss.png?size=504x597&lossy=1&strip=1&webp=1 504w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-8-training-validation-loss.png?size=630x747&lossy=1&strip=1&webp=1 630w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-8-training-validation-loss-768x910.png?lossy=1&strip=1&webp=1 768w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-8-training-validation-loss-864x1024.png?lossy=1&strip=1&webp=1 864w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-8-training-validation-loss-1296x1536.png?lossy=1&strip=1&webp=1 1296w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-8-training-validation-loss.png?lossy=1&strip=1&webp=1 1672w\" sizes=\"(max-width: 630px) 100vw, 630px\" /><figcaption><strong>Figure 8:</strong> Classification training loss (<em>top-left</em>), classification validation loss (<em>bottom-left</em>), and mean Average Precision at IoU 50% (<em>middle-right</em>), mAP (IoU = 0.5).</figcaption></figure></div>\n\n\n<p>But now, let’s test our model!</p>\n\n\n\n<hr class=\"wp-block-separator has-alpha-channel-opacity\" id=\"h4Testing\"/>\n\n\n\n<h4><a href=\"#TOC\"><strong>Testing</strong></a></h4>\n\n\n\n<p>For this purpose, we will use the <code class=\"EnlighterJSRAW\" data-enlighter-language=\"python\">thermal_imaging_video_test.mp4</code>, located at the project’s root, passing it through the layers of our model using the Python file <code class=\"EnlighterJSRAW\" data-enlighter-language=\"python\">detect.py</code>.</p>\n\n\n\n<pre class=\"EnlighterJSRAW\" data-enlighter-language=\"python\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"true\" data-enlighter-lineoffset=\"21\" data-enlighter-title=\"Thermal Vision: Night Object Detection with PyTorch and YOLOv5 (real project)\" data-enlighter-group=\"5\"># test the trained model (night_object_detector.pt) on a thermal imaging video,\n# parameters:\n#  - trained model (weights): model trained in the previous step, night_object_detector.pt passed\n#  - image size (img): frame size of the thermal video is 640 x 512, 640 passed\n#  - confidence (conf): confidence threshold, only the inferences higher than this value will be shown, 0.35 passed\n#  - video file (source): thermal imaging video, thermal_imaging_video.mp4 passed\n!python detect.py --weights runs/train/exp/weights/best.pt --img 640 --conf 0.35 --source ../thermal_imaging_video.mp4</pre>\n\n\n\n<p><strong>Line 27</strong> shows how to do it.</p>\n\n\n\n<p>We run the <code class=\"EnlighterJSRAW\" data-enlighter-language=\"python\">detect.py</code> by specifying the following parameters:</p>\n\n\n\n<ul><li><code class=\"EnlighterJSRAW\" data-enlighter-language=\"python\">weights</code>: points to our trained model. Calculated weights collected at <code class=\"EnlighterJSRAW\" data-enlighter-language=\"python\">best.pt</code> file (<code class=\"EnlighterJSRAW\" data-enlighter-language=\"python\">runs/train/exp/weights/best.pt</code>).</li><li><code class=\"EnlighterJSRAW\" data-enlighter-language=\"python\">img</code>: image size of the testing images that will be passed through our model. In our case, thermal images from our video have a <code class=\"EnlighterJSRAW\" data-enlighter-language=\"python\">640x512</code> resolution, so we indicate the maximum size as 640 pixels.</li><li><code class=\"EnlighterJSRAW\" data-enlighter-language=\"python\">conf</code>: confidence of each detection. This threshold establishes the level of probability of detection from which the detections are considered correct and therefore shown. We set up the confidence at 35%.</li><li><code class=\"EnlighterJSRAW\" data-enlighter-language=\"python\">source</code>: images to test the model, in our case, the video file <code class=\"EnlighterJSRAW\" data-enlighter-language=\"python\">thermal_imaging_video.mp4</code>.</li></ul>\n\n\n\n<p>Let’s test it!</p>\n\n\n\n<p><strong>Figure 9</strong> shows a GIF of our good results!</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter\"><a href=\"https://lh4.googleusercontent.com/C5HI_Po2XhluIr7LkW40EIEV_6JBTQN0LMc30zVNeIfaU9dpwXaFdkt1b8Jco-fP4kv5mIWO7yhA6MG5FCrzwiHS4dkLSBvefoHKhDvKtgdJwdo_8FiwqGas-z2z7LAnwkI-QclrJsR3kyIBxQFF0IPBbdKe7f2W6q_d2up4P5GoIr7MW8MtqTQs\" target=\"_blank\" rel=\"noreferrer noopener\"><img src=\"https://lh4.googleusercontent.com/C5HI_Po2XhluIr7LkW40EIEV_6JBTQN0LMc30zVNeIfaU9dpwXaFdkt1b8Jco-fP4kv5mIWO7yhA6MG5FCrzwiHS4dkLSBvefoHKhDvKtgdJwdo_8FiwqGas-z2z7LAnwkI-QclrJsR3kyIBxQFF0IPBbdKe7f2W6q_d2up4P5GoIr7MW8MtqTQs\" alt=\"\"/></a><figcaption><strong>Figure 9:</strong> YOLOv5 Thermal Object Detector test.</figcaption></figure></div>\n\n\n<p>As we have indicated, the night object detection of this video has been obtained with 35% confidence. To modify this factor, we should check the curve obtained in <strong>Figure 10</strong>, where Precision is plotted against Confidence.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-large\"><a href=\"https://pyimagesearch.com/wp-content/uploads/2022/10/figure-10-p-curve.png\" target=\"_blank\" rel=\"noreferrer noopener\"><img width=\"1024\" height=\"683\" src=\"https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-10-p-curve-1024x683.png?lossy=1&strip=1&webp=1\" alt=\"\" class=\"wp-image-35371\" srcset=\"https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-10-p-curve.png?size=126x84&lossy=1&strip=1&webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-10-p-curve-300x200.png?lossy=1&strip=1&webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-10-p-curve.png?size=378x252&lossy=1&strip=1&webp=1 378w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-10-p-curve.png?size=504x336&lossy=1&strip=1&webp=1 504w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-10-p-curve.png?size=630x420&lossy=1&strip=1&webp=1 630w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-10-p-curve-768x512.png?lossy=1&strip=1&webp=1 768w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-10-p-curve-1024x683.png?lossy=1&strip=1&webp=1 1024w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-10-p-curve-1536x1024.png?lossy=1&strip=1&webp=1 1536w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/10/figure-10-p-curve-2048x1365.png?lossy=1&strip=1&webp=1 2048w\" sizes=\"(max-width: 630px) 100vw, 630px\" /></a><figcaption><strong>Figure 10:</strong> Precision vs. Confidence curve for our tested model.</figcaption></figure></div>\n\n\n<hr class=\"wp-block-separator has-alpha-channel-opacity\"/>\n\n\n\n<div id=\"pitch\" style=\"padding: 40px; width: 100%; background-color: #F4F6FA;\">\n\t<h3>What's next? I recommend <a target=\"_blank\" href=\"https://pyimagesearch.com/pyimagesearch-university/?utm_source=blogPost&utm_medium=bottomBanner&utm_campaign=What%27s%20next%3F%20I%20recommend\">PyImageSearch University</a>.</h3>\n\n\t<script src=\"https://fast.wistia.com/embed/medias/kno0cmko2z.jsonp\" async></script><script src=\"https://fast.wistia.com/assets/external/E-v1.js\" async></script><div class=\"wistia_responsive_padding\" style=\"padding:56.25% 0 0 0;position:relative;\"><div class=\"wistia_responsive_wrapper\" style=\"height:100%;left:0;position:absolute;top:0;width:100%;\"><div class=\"wistia_embed wistia_async_kno0cmko2z videoFoam=true\" style=\"height:100%;position:relative;width:100%\"><div class=\"wistia_swatch\" style=\"height:100%;left:0;opacity:0;overflow:hidden;position:absolute;top:0;transition:opacity 200ms;width:100%;\"><img src=\"https://fast.wistia.com/embed/medias/kno0cmko2z/swatch\" style=\"filter:blur(5px);height:100%;object-fit:contain;width:100%;\" alt=\"\" aria-hidden=\"true\" onload=\"this.parentNode.style.opacity=1;\" /></div></div></div></div>\n\n\t<div style=\"margin-top: 32px; margin-bottom: 32px; \">\n\t\t<strong>Course information:</strong><br/>\n\t\t53+ total classes • 57+ hours of on-demand code walkthrough videos • Last updated: October 2022<br/>\n\t\t<span style=\"color: #169FE6;\">★★★★★</span> 4.84 (128 Ratings) • 15,800+ Students Enrolled\n\t</div>\n\n\t<p><strong>I strongly believe that if you had the right teacher you could <em>master</em> computer vision and deep learning.</strong></p>\n\n\t<p>Do you think learning computer vision and deep learning has to be time-consuming, overwhelming, and complicated? Or has to involve complex mathematics and equations? Or requires a degree in computer science?</p>\n\n\t<p>That’s <em>not</em> the case.</p>\n\n\t<p>All you need to master computer vision and deep learning is for someone to explain things to you in <em>simple, intuitive</em> terms. <em>And that’s exactly what I do</em>. My mission is to change education and how complex Artificial Intelligence topics are taught.</p>\n\n\t<p>If you're serious about learning computer vision, your next stop should be PyImageSearch University, the most comprehensive computer vision, deep learning, and OpenCV course online today. Here you’ll learn how to <em>successfully</em> and <em>confidently</em> apply computer vision to your work, research, and projects. Join me in computer vision mastery.</p>\n\n\t<p><strong>Inside PyImageSearch University you'll find:</strong></p>\n\n\t<ul style=\"margin-left: 0px;\">\n\t\t<li style=\"list-style: none;\">&check; <strong>53+ courses</strong> on essential computer vision, deep learning, and OpenCV topics</li>\n\t\t<li style=\"list-style: none;\">&check; <strong>53+ Certificates</strong> of Completion</li>\n\t\t<li style=\"list-style: none;\">&check; <strong>57+ hours</strong> of on-demand video</li>\n\t\t<li style=\"list-style: none;\">&check; <strong>Brand new courses released <em>regularly</em></strong>, ensuring you can keep up with state-of-the-art techniques</li>\n\t\t<li style=\"list-style: none;\">&check; <strong>Pre-configured Jupyter Notebooks in Google Colab</strong></li>\n\t\t<li style=\"list-style: none;\">&check; Run all code examples in your web browser — works on Windows, macOS, and Linux (no dev environment configuration required!)</li>\n\t\t<li style=\"list-style: none;\">&check; Access to <strong>centralized code repos for <em>all</em> 450+ tutorials</strong> on PyImageSearch</li>\n\t\t<li style=\"list-style: none;\">&check; <strong> Easy one-click downloads</strong> for code, datasets, pre-trained models, etc.</li>\n\t\t<li style=\"list-style: none;\">&check; <strong>Access</strong> on mobile, laptop, desktop, etc.</li>\n\t</ul>\n\n\t<p style=\"text-align: center;\">\n\t\t<a target=\"_blank\" class=\"button link\" href=\"https://pyimagesearch.com/pyimagesearch-university/?utm_source=blogPost&utm_medium=bottomBanner&utm_campaign=What%27s%20next%3F%20I%20recommend\" style=\"background-color: #6DC713; border-bottom: none;\">Click here to join PyImageSearch University</a>\n\t</p>\n</div>\n\n\n\n<hr class=\"wp-block-separator has-alpha-channel-opacity\" id=\"h2Summary\"/>\n\n\n\n<h2><a href=\"#TOC\"><strong>Summary</strong></a></h2>\n\n\n\n<p>We would like to acknowledge the great work of <a href=\"https://github.com/ultralytics\" target=\"_blank\" rel=\"noreferrer noopener\">Ultralytics</a>.  We found their <code><a href=\"https://github.com/ultralytics/yolov5/blob/master/train.py\" target=\"_blank\" rel=\"noreferrer noopener\">train.py</a></code> and <code><a href=\"https://github.com/ultralytics/yolov5/blob/master/detect.py\" target=\"_blank\" rel=\"noreferrer noopener\">detect.py</a></code> files so great we included them in this post.  </p>\n\n\n\n<p>In this tutorial, we have learned how to detect different objects under any light condition, combining Thermal Vision and Deep Learning, using the CNN YOLOv5 architecture and our custom thermal imaging dataset. </p>\n\n\n\n<p>For this purpose, we have discovered how to train the state-of-the-art YOLOv5 model, previously trained using the Microsoft COCO dataset, on the FLIR Thermal Starter Dataset. </p>\n\n\n\n<p>Even though the thermal images are completely different from common RGB images of the COCO dataset, the great performance and results obtained show how powerful the YOLOv5 model is. </p>\n\n\n\n<p>We can conclude that Artificial Intelligence goes through incredible and useful paradigms nowadays. </p>\n\n\n\n<p>This tutorial shows you how to apply Thermal Vision and Deep Learning in real applications (e.g., Self-Driving Cars). If you would like to learn about this awesome topic, check out the <strong>Autonomous Car</strong> courses at <a href=\"https://pyimagesearch.com/pyimagesearch-university/\" target=\"_blank\" rel=\"noreferrer noopener\">PyImageSearch University</a>.</p>\n\n\n\n<p>The PyImageSearch team hopes that you have enjoyed and interiorized all the concepts taught during this <strong>Infrared Vision Basics</strong> course.</p>\n\n\n\n<p>See you in the next courses!</p>\n\n\n\n<hr class=\"wp-block-separator has-alpha-channel-opacity\" id=\"h3Citation\"/>\n\n\n\n<h3><a href=\"#TOC\"><strong>Citation Information</strong></a></h3>\n\n\n\n<p><strong>Garcia-Martin, R. </strong>“Thermal Vision: Night Object Detection with PyTorch and YOLOv5 (real project),” <em>PyImageSearch</em>, P. Chugh, A. R. Gosthipaty, S. Huot, K. Kidriavsteva, and R. Raha, eds., 2022, <a href=\"https://pyimg.co/p2zsm\">https://pyimg.co/p2zsm</a></p>\n\n\n\n<pre class=\"EnlighterJSRAW\" data-enlighter-language=\"raw\" data-enlighter-theme=\"classic\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"false\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">@incollection{RGM_2022_PYTYv5,\n  author = {Raul Garcia-Martin},\n  title = {Thermal Vision: Night Object Detection with {PyTorch} and {YOLOv5} (real project)},\n  booktitle = {PyImageSearch},\n  editor = {Puneet Chugh and Aritra Roy Gosthipaty and Susan Huot and Kseniia Kidriavsteva and Ritwik Raha},\n  year = {2022},\n  note = {https://pyimg.co/p2zsm},\n}</pre>\n\n\n\n<hr class=\"wp-block-separator has-alpha-channel-opacity\"/>\n\n\n\n<div style=\"padding: 40px; width: 100%; background-color: #F4F6FA;\">\n\t<h3>Want free GPU credits to train models?</h3>\n\n\t<ul style=\"margin-left: 0px;\">\n\t\t<li style=\"list-style: none;\">We used <a target=\"_blank\" href=\"https://cloud.jarvislabs.ai/\">Jarvislabs.ai</a>, a GPU cloud, for all the experiments.</li>\n\t\t<li style=\"list-style: none;\">We are proud to offer PyImageSearch University students $20 worth of Jarvislabs.ai GPU cloud credits. Join PyImageSearch University and claim your $20 credit <a target=\"_blank\" href=\"https://pyimagesearch.com/pyimagesearch-university/\">here</a>.</li>\n\t</ul>\n\n\n\t<p>In Deep Learning, we need to train Neural Networks. These Neural Networks can be trained on a CPU but take a lot of time. Moreover, sometimes these networks do not even fit (run) on a CPU.</p>\n\n\t<p>To overcome this problem, we use <strong>GPUs</strong>.  The problem is these GPUs are <strong>expensive</strong> and become outdated quickly. </p>\n\n\t<p>GPUs are great because they take your Neural Network and train it quickly.  The problem is that GPUs are expensive, so you don’t want to buy one and use it only occasionally.  Cloud GPUs let you use a GPU and <strong>only pay for the time you are running the GPU</strong>.  It’s a brilliant idea that saves you money.</p>\n\n\t<p><strong>JarvisLabs</strong> provides the best-in-class GPUs, and <strong>PyImageSearch University students</strong> get between 10-50 hours on a world-class GPU (time depends on the specific GPU you select).</p>\n\n\n\t<p>This gives you a chance to <strong>test-drive a monstrously powerful GPU</strong> on any of our tutorials in a jiffy. So join <a target=\"_blank\" href=\"https://pyimagesearch.com/pyimagesearch-university/\">PyImageSearch University</a> today and try it for yourself.</p>\n\n\n\t<p style=\"text-align: center;\">\n\t\t<a target=\"_blank\" class=\"button link\" href=\"https://pyimagesearch.com/pyimagesearch-university/\" style=\"background-color: #6DC713; border-bottom: none;\">Click here to get Jarvislabs credits now</a>\n\t</p>\n</div>\n\n\n\n<hr class=\"wp-block-separator has-alpha-channel-opacity\"/>\n\n\n\n<p><strong>To download the source code to this post (and be notified when future tutorials are published here on PyImageSearch), <em>simply enter your email address in the form below!</em></strong></p>\n\n\n\n<div id=\"download-the-code\" class=\"post-cta-wrap\">\n<div class=\"gpd-post-cta\">\n\t<div class=\"gpd-post-cta-content\">\n\t\t\n\n\t\t\t<div class=\"gpd-post-cta-top\">\n\t\t\t\t<div class=\"gpd-post-cta-top-image\"><img src=\"https://929687.smushcdn.com/2633864/wp-content/uploads/2020/01/cta-source-guide-1.png?lossy=1&strip=1&webp=1\" alt=\"\" srcset=\"https://929687.smushcdn.com/2633864/wp-content/uploads/2020/01/cta-source-guide-1.png?lossy=1&strip=1&webp=1 410w,https://929687.smushcdn.com/2633864/wp-content/uploads/2020/01/cta-source-guide-1.png?size=126x174&lossy=1&strip=1&webp=1 126w,https://929687.smushcdn.com/2633864/wp-content/uploads/2020/01/cta-source-guide-1.png?size=252x348&lossy=1&strip=1&webp=1 252w\" sizes=\"(max-width: 410px) 100vw, 410px\" /></div>\n\t\t\t\t\n\t\t\t\t<div class=\"gpd-post-cta-top-title\"><h4>Download the Source Code and FREE 17-page Resource Guide</h4></div>\n\t\t\t\t<div class=\"gpd-post-cta-top-desc\"><p>Enter your email address below to get a .zip of the code and a <strong>FREE 17-page Resource Guide on Computer Vision, OpenCV, and Deep Learning.</strong> Inside you'll find my hand-picked tutorials, books, courses, and libraries to help you master CV and DL!</p></div>\n\n\n\t\t\t</div>\n\n\t\t\t<div class=\"gpd-post-cta-bottom\">\n\t\t\t\t<form id=\"footer-cta-code\" class=\"footer-cta\" action=\"https://www.getdrip.com/forms/4130035/submissions\" method=\"post\" target=\"blank\" data-drip-embedded-form=\"4130035\">\n\t\t\t\t\t<input name=\"fields[email]\" type=\"email\" value=\"\" placeholder=\"Your email address\" class=\"form-control\" />\n\n\t\t\t\t\t<button type=\"submit\">Download the code!</button>\n\n\t\t\t\t\t<div style=\"display: none;\" aria-hidden=\"true\"><label for=\"website\">Website</label><br /><input type=\"text\" id=\"website\" name=\"website\" tabindex=\"-1\" autocomplete=\"false\" value=\"\" /></div>\n\t\t\t\t</form>\n\t\t\t</div>\n\n\n\t\t\n\t</div>\n\n</div>\n</div>\n<p>The post <a rel=\"nofollow\" href=\"https://pyimagesearch.com/2022/10/31/thermal-vision-night-object-detection-with-pytorch-and-yolov5-real-project/\">Thermal Vision: Night Object Detection with PyTorch and YOLOv5 (real project)</a> appeared first on <a rel=\"nofollow\" href=\"https://pyimagesearch.com\">PyImageSearch</a>.</p>\n"
}