{
  "title": "Does MetaHuman’s Digital Clone Cross the Uncanny Valley?",
  "link": "https://spectrum.ieee.org/uncanny-valley-metahuman-digital-clone",
  "description": "\n<img src=\"https://spectrum.ieee.org/media-library/a-metahuman-character-open-for-edits-in-the-metahuman-software.jpg?id=30126649&width=1245&height=700&coordinates=0%2C0%2C0%2C0\"/><br/><br/><p>Creating your virtual clone isn’t as difficult as you’d think.</p><p>Epic Games recently introduced Mesh to <a href=\"https://www.unrealengine.com/en-US/blog/new-release-brings-mesh-to-metahuman-to-unreal-engine-and-much-more\" target=\"_blank\">MetaHuman</a>, a framework for creating photorealistic human characters. It lets creators sculpt an imported mesh to create a convincing character in less than an hour.</p><p>“It’s incredibly simple compared to a lot of other tools,” says Stu Richards (a.k.a. <a href=\"https://www.hundo.xyz/stories/meet-the-metaversers-meta-mike\" target=\"_blank\">Meta Mike</a>), partner success lead at <a href=\"https://www.giglabs.io/\" rel=\"noopener noreferrer\" target=\"_blank\">GigLabs</a> and Cofounder of <a href=\"https://www.versed.digital/\" rel=\"noopener noreferrer\" target=\"_blank\">Versed</a>. “I’d compare it to a character creator in a game.”</p><hr/><h2>Creating your clone</h2><p>Photorealistic characters remain the holy grail of 3D graphics. It’s a difficult task due <a href=\"https://spectrum.ieee.org/what-is-the-uncanny-valley\" target=\"_self\">to the “uncanny valley” phenomenon</a>, which theorizes humanlike characters become less appealing as they approach a realistic representation. Characters in big-budget games or animated films take months (if not years) of effort and often rely on detailed scans of real human models captured with expensive, specialized equipment.</p><p>Mesh to MetaHuman breaks this barrier to entry. Richards used his iPhone to scan a model of his face and create his own MetaHuman avatar. “After, I think, about 40 photos, it put together all the different angles, and creates a 3D model of my face,” he says. “You take that mesh, bring it into Unreal Engine…and overlay a MetaHuman head onto that mesh.” </p><p class=\"pull-quote\">“The barrier of entry to getting into the tool itself is almost zero.” <br/>—Justin Vu, 3D animator</p><p>The mesh begins as an untextured, gray surface, but MetaHuman’s interface provides numerous options that can be changed with a click. Creators can tweak physique, head and facial hair, eyebrows, skin tone, and even the look of pores and opacity of skin to create a convincing virtual clone—or model an idealized avatar. </p><p>MetaHuman also rigs the mesh for animation. “You can select different poses and different animations,” says Richards. “But when you bring that back into Unreal, you have a lot of flexibility. You can create your own animation sets, create full-on controller mapping.” </p><p>Creators can even use Live Link, an Unreal Engine plug-in, to capture facial expressions in real time on a smartphone or tablet and stream it to a MetaHuman character.</p><p class=\"shortcode-media shortcode-media-youtube\">\n<span class=\"rm-shortcode\" data-rm-shortcode-id=\"5159714986927a7daa9f3b2555f747e3\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/lDFLrzZy2R4?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span>\n<small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\">Live Link Face Tutorial with New Metahumans in Unreal Engine 4</small>\n<small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">\n<a href=\"https://www.youtube.com/watch?v=lDFLrzZy2R4\" target=\"_blank\">www.youtube.com</a>\n</small>\n</p><p>While Mesh to MetaHuman is more approachable than previous workflows, Richards cautions that some familiarity with 3D modeling and animation is required for the best results. Creators can expect minor errors in the mesh captured by a smartphone or tablet that must be fixed in 3D-modeling software. And while MetaHuman’s interface is simple, Unreal Engine 5 remains complex.<br/></p><p>“From a user perspective, I think that at this point in time, having something a bit more lightweight, with lower fidelity, and more interoperable, is what’s going to resonate with people,” says Richards. “Especially in the NFT and web3 world.” </p><h2>MetaHuman beyond the metaverse</h2><p>Contrary to its name, MetaHuman is not a tool exclusively for metaverse avatars. In fact, that’s not even its primary use case (for now). Rather, MetaHuman is, according to Epic Games, ideal for creators working on smaller projects with a modest budget, such as independent games and short films. </p><p><a href=\"https://www.linkedin.com/in/jvu907/\" rel=\"noopener noreferrer\" target=\"_blank\">Justin Vu</a>, an animator and 3D generalist specializing in filmmaking with Maya and Unreal Editor, is one such creator. He put MetaHuman to work in a series of promotional shorts from Allstate Insurance Company called <em><a href=\"https://www.linkedin.com/posts/visual-creatures_unrealengine-creative-thefutureofprotection-activity-6911951738610597888-Yi1C/\" target=\"_blank\">The Future of Protection</a></em>. Vu was able to use MetaHuman despite having little prior experience with Unreal Engine.<br/></p><p>“The barrier of entry to getting into the tool itself is almost zero,” says Vu. “So long as you have a computer that runs a modern video game, you can get started.”</p><p>It was especially useful during the peak of COVID. The difficulty of shooting live action in the middle of a lockdown and travel restrictions made animation appealing. MetaHuman helped Vu create convincing animated characters in a fraction of the time that might otherwise be required.</p><p>“What’s great about Metahuman is that it generates high fidelity models, which can be used with facial recording capture,” says Vu. “It’s very convincing to the average person and does a lot to cross the uncanny valley.”</p><p class=\"shortcode-media shortcode-media-rebelmouse-image\">\n<img alt=\"A MetaHuman character imported into an Unreal Engine project. \" class=\"rm-shortcode\" data-rm-shortcode-id=\"6dc1ecfca5468b4d3bfd0fd4974f880f\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"72e56\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/a-metahuman-character-imported-into-an-unreal-engine-project.jpg?id=30126634&width=980\"/>\n<small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\">MetaHuman characters can be imported to Unreal Engine projects, such as the Matrix Awakens demo. </small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">Epic Games</small></p><p>Animators can conduct a virtual casting by quickly iterating on characters that differ in age, hairstyle, height, facial structure, and physique. The tool’s automatic animation rigging is especially useful, as Vu says manual rigging of a high-fidelity 3D character can take “a few weeks, if not a few months.” Quick rigging helps animators try poses and expressions before deciding which character to use for a project.</p><p>Despite these strengths, Vu shared Richards’s caution that MetaHuman’s approachability has limits. While creating a character is relatively simple, character models and animations require tweaks for best results. He also notes MetaHuman has a limited selection of wardrobe options. This can be changed once a character is imported to Unreal Engine but, again, requires expertise in traditional 3D modeling and animation. </p><p>“While the tools are accessible and easy to start up, it really requires the hand of a good animator, a good actor, or good director, to drag it out of uncanny valley and make it convincing,” says Vu. </p><p>This sets the stage for competition in the space as alternative tools become more capable. <a href=\"https://blog.unity.com/news/welcome-ziva-dynamics\" rel=\"noopener noreferrer\" target=\"_blank\">Unity purchased Ziva Dynamics</a>, a VFX studio known for its work creating lifelike characters, in January 2022. Other alternatives, like <a href=\"https://www.animaze.us/\" rel=\"noopener noreferrer\" target=\"_blank\">Animaze</a> and <a href=\"https://readyplayer.me/\" rel=\"noopener noreferrer\" target=\"_blank\">Ready Player Me</a>, lack realism but don’t require experience with 3D modeling or animation for usable results. These tools are popular with <a href=\"https://en.wikipedia.org/wiki/VTuber\" rel=\"noopener noreferrer\" target=\"_blank\">Vtubers</a> and fans of metaverse social platforms like <a href=\"https://hello.vrchat.com/\" rel=\"noopener noreferrer\" target=\"_blank\">VRChat</a>.</p><p>MetaHuman leads the effort to cross the uncanny valley—but it’s still anyone’s race.</p><p><strong></strong><em><strong>Correction (</strong></em><strong><em>18 July 2022): </em></strong><em>This story was updated to remove reference to a short film Justin Vu worked on, in which he used Unreal Engine but did <u>not</u> use MetaHuman as was originally reported. </em><br/></p>",
  "pubDate": "Sat, 16 Jul 2022 14:00:00 +0000",
  "guid": "https://spectrum.ieee.org/uncanny-valley-metahuman-digital-clone",
  "category": [
    "Face capture",
    "Metahumans",
    "Motion capture",
    "Metaverse",
    "Virtual reality",
    "Unreal engine",
    "Avatars"
  ],
  "dc:creator": "Matthew S. Smith",
  "media:content": ""
}