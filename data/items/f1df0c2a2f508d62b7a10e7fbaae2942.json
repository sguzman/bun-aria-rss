{
  "title": "Dask Development Log",
  "link": "",
  "updated": "2017-01-30T00:00:00+00:00",
  "id": "https://mrocklin.github.io/blog/work/2017/01/30/dask-dev-6",
  "content": "<p><em>This work is supported by <a href=\"http://continuum.io\">Continuum Analytics</a>\nthe <a href=\"http://www.darpa.mil/program/XDATA\">XDATA Program</a>\nand the Data Driven Discovery Initiative from the <a href=\"https://www.moore.org/\">Moore\nFoundation</a></em></p>\n\n<p>To increase transparency I’m blogging weekly about the work done on Dask and\nrelated projects during the previous week.  This log covers work done between\n2017-01-17 and 2016-01-30.  Nothing here is ready for production.  This\nblogpost is written in haste, so refined polish should not be expected.</p>\n\n<p>Themes of the last couple of weeks:</p>\n\n<ol>\n  <li>Micro-release of distributed scheduler</li>\n  <li>as_completed for asynchronous algorithms</li>\n  <li>Testing ZeroMQ and communication refactor</li>\n  <li>Persist, and Dask-GLM</li>\n</ol>\n\n<h3 id=\"stability-enhancements-and-micro-release\">Stability enhancements and micro-release</h3>\n\n<p>We’ve released dask.distributed version 1.15.2, which includes some important\nperformance improvements for communicating multi-dimensional arrays, cleaner\nscheduler shutdown of workers for adaptive deployments, an improved\nas_completed iterator that can accept new futures in flight, and a few other\nsmaller features.</p>\n\n<p>The feature here that excites me the most is improved communication of\nmulti-dimensional arrays across the network.  In a\n<a href=\"http://matthewrocklin.com/blog/work/2017/01/17/dask-images\">recent blogpost about image processing on a cluster</a>\nwe noticed that communication bandwidth was far lower than expected.  This led\nus to uncover a flaw in our compression heuristics.  Dask doesn’t compress all\ndata, instead it takes a few 10kB samples of the data, compresses them, and if\nthat goes well, decides to compress the entire thing.  Unfortunately, due to\nour mishandling of memoryviews we ended up taking <em>much</em> larger samples than\n1kB when dealing with multi-dimensional arrays.</p>\n\n<h3 id=\"xarray-release\">XArray release</h3>\n\n<p>This improvement is particularly timely because a new release of\n<a href=\"http://xarray.pydata.org/en/stable/\">XArray</a> (a project that wraps around\nDask.array for large labeled arrays) is now available with better data\ningestion support for NetCDF data on distributed clusters.  This opens up\ndistributed array computing to Dask’s first (and possibly largest) scientific\nuser community, atmospheric scientists.</p>\n\n<h3 id=\"as_completed-accepts-futures\">as_completed accepts futures.</h3>\n\n<p>In addition to arrays, dataframes, and the delayed decorator, Dask.distributed\nalso implements the  <a href=\"http://xarray.pydata.org/en/stable/\">concurrent.futures</a>\ninterface from the standard library (except that Dask’s version parallelizes\nacross a cluster and has a few other benefits).  Part of this interface is the\n<a href=\"http://xarray.pydata.org/en/stable/\">as_completed</a> function, which takes in a\nlist of futures and yields those futures in the order in which they finish.\nThis enables the construction of fairly responsive asynchronous computations.\nAs soon as some work finishes you can look at the result and submit more work\nbased on the current state.</p>\n\n<p>That has been around in Dask for some time.</p>\n\n<p>What’s <em>new</em> is that you can now push more futures into as_completed</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">futures</span> <span class=\"o\">=</span> <span class=\"n\">client</span><span class=\"p\">.</span><span class=\"nb\">map</span><span class=\"p\">(</span><span class=\"n\">my_function</span><span class=\"p\">,</span> <span class=\"n\">sequence</span><span class=\"p\">)</span>\n\n<span class=\"n\">ac</span> <span class=\"o\">=</span> <span class=\"n\">as_completed</span><span class=\"p\">(</span><span class=\"n\">futures</span><span class=\"p\">)</span>\n<span class=\"k\">for</span> <span class=\"n\">future</span> <span class=\"ow\">in</span> <span class=\"n\">ac</span><span class=\"p\">:</span>\n    <span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">future</span><span class=\"p\">.</span><span class=\"n\">result</span><span class=\"p\">()</span>  <span class=\"c1\"># future is already finished, so this is fast\n</span>    <span class=\"k\">if</span> <span class=\"n\">condition</span><span class=\"p\">:</span>\n        <span class=\"n\">new_future</span> <span class=\"o\">=</span> <span class=\"n\">client</span><span class=\"p\">.</span><span class=\"n\">submit</span><span class=\"p\">(</span><span class=\"n\">function</span><span class=\"p\">,</span> <span class=\"o\">*</span><span class=\"n\">args</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">)</span>\n        <span class=\"n\">ac</span><span class=\"p\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">new_future</span><span class=\"p\">)</span>    <span class=\"c1\"># &lt;&lt;---- This is the new ability\n</span></code></pre></div></div>\n\n<p>So the <code class=\"language-plaintext highlighter-rouge\">as_completed</code> iterator can keep going for quite a while with a set of\nfutures always in flight.  This relatively simple change allows for the easy\nexpression of a broad set of asynchronous algorithms.</p>\n\n<h3 id=\"zeromq-and-communication-refactor\">ZeroMQ and Communication Refactor</h3>\n\n<p>As part of a large effort, Antoine Pitrou has been refactoring Dask’s\ncommunication system.  One sub-goal of this refactor was to allow us to explore\nother transport mechanisms than Tornado IOStreams in a pluggable way.</p>\n\n<p>One such alternative is ZeroMQ sockets.  We’ve gotten both incredibly positive\nand incredibly negative praise/warnings about using ZeroMQ.  It’s not a great\nfit because Dask mostly just does point-to-point communication, so we don’t\nbenefit from all of ZeroMQ’s patterns, which now become more of a hindrance\nthan a benefit.  However, we were interested in the performance impact of\nmanaging all of our network communication in a completely separately managed\nC++ thread unaffected by GIL issues.</p>\n\n<p>Whether or you hate or love ZeroMQ you can now pick and choose.  Antoine’s\nbranch allows for easy swapping between transport mechanisms and opens the\npossibility for more in the future like intra-process communication with\nQueues, MPI, etc..  This doesn’t affect most users, but some Dask deployments\nare on supercomputers with exotic networks capable of very fast speeds.  The\npossibility that we might tap into Infiniband someday and have the ability to\nmanage data locally without copies (Tornado does not achieve this) is very\nattractive to some user communities.</p>\n\n<p>After very preliminary benchmarking we’ve found that ZeroMQ offers a small\nspeedup, but results in a lack of stability in the cluster under complex\nworkloads (likely our fault, not ZeroMQs, but still).  ZeroMQ support is\nstrictly experimental and will likely stay that way for a long time.  Readers\nshould not get excited about this.</p>\n\n<h3 id=\"perist-and-dask-glm\">Perist and Dask-GLM</h3>\n\n<p>In collaboration with researchers at Capital One we’ve been working on a <a href=\"http://github.com/dask/dask-glm\">set\nof parallel solvers for first and second order\nmethods</a>, such as are commonly used in a broad\nclass of statistical and machine learning algorithms.</p>\n\n<p>One challenge in this process has been building algorithms that are\nsimultaneously optimal for both the single machine and distributed schedulers.\nThe distributeed scheduler requires that we think about where data is, on the\nclient or on the cluster, where for the single machine scheudler this is less\nof a problem.  The distrbuted scheduler appropriately has a new verb,\n<code class=\"language-plaintext highlighter-rouge\">persist</code>, which keeps data as a Dask collection, but triggers all of the\ninternal computation</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">compute</span><span class=\"p\">(</span><span class=\"n\">dask</span> <span class=\"n\">array</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">numpy</span> <span class=\"n\">array</span>\n<span class=\"n\">persist</span><span class=\"p\">(</span><span class=\"n\">dask</span> <span class=\"n\">array</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">dask</span> <span class=\"n\">array</span>\n</code></pre></div></div>\n\n<p>We have now mirrored this verb to the single machine scheduler in <a href=\"https://github.com/dask/dask/pull/1927\">dask/dask\n#1927</a> and we get very nice performance\non dask-glm’s algorithms in both cases now.</p>\n\n<p>Working with the developers at Capital One has been very rewarding.  I would\nlike to find more machine learning groups that fit the following criteria:</p>\n\n<ol>\n  <li>Are focused on performance</li>\n  <li>Need parallel computing</li>\n  <li>Are committed to built good open source software</li>\n  <li>Are sufficiently expert in their field to understand correct algorithms</li>\n</ol>\n\n<p>If you know such a person or such a group, either in industry or just a grad\nstudent in university, please encourage them to raise an issue at\nhttp://github.com/dask/dask/issues/new .  I will likely write a larger blogpost\non this topic in the near future.</p>"
}