{
  "title": "CAMANet: Class Activation Map Guided Attention Network for Radiology Report Generation. (arXiv:2211.01412v1 [cs.CV])",
  "link": "http://arxiv.org/abs/2211.01412",
  "description": "<p>Radiology report generation (RRG) has gained increasing research attention\nbecause of its huge potential to mitigate medical resource shortages and aid\nthe process of disease decision making by radiologists. Recent advancements in\nRadiology Report Generation (RRG) are largely driven by improving models'\ncapabilities in encoding single-modal feature representations, while few\nstudies explore explicitly the cross-modal alignment between image regions and\nwords. Radiologists typically focus first on abnormal image regions before they\ncompose the corresponding text descriptions, thus cross-modal alignment is of\ngreat importance to learn an abnormality-aware RRG model. Motivated by this, we\npropose a Class Activation Map guided Attention Network (CAMANet) which\nexplicitly promotes cross-modal alignment by employing the aggregated class\nactivation maps to supervise the cross-modal attention learning, and\nsimultaneously enriches the discriminative information. Experimental results\ndemonstrate that CAMANet outperforms previous SOTA methods on two commonly used\nRRG benchmarks.\n</p>",
  "dc:creator": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhalerao_A/0/1/0/all/0/1\">Abhir Bhalerao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_T/0/1/0/all/0/1\">Terry Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+See_S/0/1/0/all/0/1\">Simon See</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yulan He</a>"
}