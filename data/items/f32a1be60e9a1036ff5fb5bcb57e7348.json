{
  "title": "Monitoring tiny web services",
  "link": "",
  "updated": "2022-07-09T09:25:21+00:00",
  "id": "https://jvns.ca/blog/2022/07/09/monitoring-small-web-services/",
  "content": "\n\n<p>Hello! I&rsquo;ve started to run a few more servers recently\n(<a href=\"https://nginx-playground.wizardzines.com\">nginx playground</a>,\n<a href=\"https://messwithdns.net\">mess with dns</a>,\n<a href=\"https://dns-lookup.jvns.ca\">dns lookup</a>), so I&rsquo;ve been\nthinking about monitoring.</p>\n\n<p>It wasn&rsquo;t initially totally obvious to me how to monitor these websites, so I\nwanted to quickly write up what how I did it.</p>\n\n<p>I&rsquo;m not going to talk about how to monitor Big Serious Mission Critical\nwebsites at all, only tiny unimportant websites.</p>\n\n<h3 id=\"goal-spend-approximately-0-time-on-operations\">goal: spend approximately 0 time on operations</h3>\n\n<p>I want the sites to mostly work, but I also want to spend approximately 0% of\nmy time on the ongoing operations.</p>\n\n<p>I was initially very wary of running servers at all because at my last job I\nwas on a <sup>24</sup>&frasl;<sub>7</sub> oncall rotation for some critical services, and in my mind &ldquo;being\nresponsible for servers&rdquo; meant &ldquo;get woken up at 2am to fix the servers&rdquo; and\n&ldquo;have lots of complicated dashboards&rdquo;.</p>\n\n<p>So for a while I only made static websites so that I wouldn&rsquo;t have to think\nabout servers.</p>\n\n<p>But eventually I realized that any server I was going to write was going to be\nvery low stakes, if they occasionally go down for 2 hours it&rsquo;s no big deal, and\nI could just set up some very simple monitoring to help keep them running.</p>\n\n<h3 id=\"not-having-monitoring-sucks\">not having monitoring sucks</h3>\n\n<p>At first I didn&rsquo;t set up any monitoring for my servers at all. This had the\nextremely predictable outcome of &ndash; sometimes the site broke, and I didn&rsquo;t find\nout about it until somebody told me!</p>\n\n<h3 id=\"step-1-an-uptime-checker\">step 1: an uptime checker</h3>\n\n<p>The first step was to set up an uptime checker. There are tons of these out\nthere, the ones I&rsquo;m using right now are <a href=\"https://updown.io/\">updown.io</a> and\n<a href=\"https://uptimerobot.com/\">uptime robot</a>. I like updown&rsquo;s user interface and\n<a href=\"https://updown.io/#pricing\">pricing</a> structure more (it&rsquo;s per request instead of a monthly fee), but uptime\nrobot has a more generous free tier.</p>\n\n<p>These</p>\n\n<ol>\n<li>check that the site is up</li>\n<li>if it goes down, it emails me</li>\n</ol>\n\n<p>I find that email notifications are a good level for me, I&rsquo;ll find out pretty\nquickly if the site goes down but it doesn&rsquo;t wake me up or anything.</p>\n\n<h3 id=\"step-2-an-end-to-end-healthcheck\">step 2: an end-to-end healthcheck</h3>\n\n<p>Next, let&rsquo;s talk about what &ldquo;check that the site is up&rdquo; actually means.</p>\n\n<p>At first I just made one of my healthcheck endpoints a function that returned\n<code>200 OK</code> no matter what.</p>\n\n<p>This is kind of useful &ndash; it told me that the server was on!</p>\n\n<p>But unsurprisingly I ran into problems because it wasn&rsquo;t checking that the API\nwas actually <em>working</em> &ndash; sometimes the healthcheck succeeded even though the\nrest of the service had actually gotten into a bad state.</p>\n\n<p>So I updated it to actually make a real API request and make sure it\nsucceeded.</p>\n\n<p>All of my services do very few things (the nginx playground has just 1\nendpoint), so it&rsquo;s pretty easy to set up a healthcheck that actually runs\nthrough most of the actions the service is supposed to do.</p>\n\n<p>Here&rsquo;s what the end-to-end healthcheck handler for the nginx playground looks\nlike. It&rsquo;s very basic: it just makes another POST request (to itself) and\nchecks if that request succeeds or fails.</p>\n\n<pre><code>func healthHandler(w http.ResponseWriter, r *http.Request) {\n\t// make a request to localhost:8080 with `healthcheckJSON` as the body\n\t// if it works, return 200\n\t// if it doesn't, return 500\n\tclient := http.Client{}\n\tresp, err := client.Post(\"http://localhost:8080/\", \"application/json\", strings.NewReader(healthcheckJSON))\n\tif err != nil {\n\t\tlog.Println(err)\n\t\tw.WriteHeader(http.StatusInternalServerError)\n\t\treturn\n\t}\n\tif resp.StatusCode != http.StatusOK {\n\t\tlog.Println(resp.StatusCode)\n\t\tw.WriteHeader(http.StatusInternalServerError)\n\t\treturn\n\t}\n\tw.WriteHeader(http.StatusOK)\n}\n</code></pre>\n\n<h3 id=\"healthcheck-frequency-hourly\">healthcheck frequency: hourly</h3>\n\n<p>Right now I&rsquo;m running most of my healthchecks every hour, and some every 30\nminutes.</p>\n\n<p>I run them hourly because updown.io&rsquo;s pricing is per healthcheck, I&rsquo;m\nmonitoring 18 different URLs, and I wanted to keep my healthcheck budget pretty\nminimal at $5/year.</p>\n\n<p>Taking an hour to find out that one of these websites has gone down seems ok to\nme &ndash; if there is a problem there&rsquo;s no guarantee I&rsquo;ll get to fixing it all that\nquickly anyway.</p>\n\n<p>If it were free to run them more often I&rsquo;d probably run them every 5-10 minutes instead.</p>\n\n<h3 id=\"step-3-automatically-restart-if-the-healthcheck-fails\">step 3: automatically restart if the healthcheck fails</h3>\n\n<p>Some of my websites are on fly.io, and fly has a pretty standard feature where\nI can configure a HTTP healthcheck for a service and restart the service if the\nhealthcheck starts failing.</p>\n\n<p>&ldquo;Restart a lot&rdquo; is a very useful strategy to paper over bugs that I haven&rsquo;t\ngotten around to fixing yet &ndash; for a while the nginx playground had a process\nleak where <code>nginx</code> processes weren&rsquo;t getting terminated, so the server kept\nrunning out of RAM.</p>\n\n<p>With the healthcheck, the result of this was that every day or so, this would happen:</p>\n\n<ul>\n<li>the server ran out of RAM</li>\n<li>the healthcheck started failing</li>\n<li>it get restarted</li>\n<li>everything was fine again</li>\n<li>repeat the whole saga again some number of hours later</li>\n</ul>\n\n<p>Eventually I got around to actually fixing the process leak, but it was nice to\nhave a workaround in place that could keep things running while I was\nprocrastinating fixing the bug.</p>\n\n<p>These healthchecks to decide whether to restart the service run more often: every 5 minutes or so.</p>\n\n<h3 id=\"this-is-not-the-best-way-to-monitor-big-services\">this is not the best way to monitor Big Services</h3>\n\n<p>This is probably obvious and I said this already at the beginning, but &ldquo;write\none HTTP healthcheck&rdquo; is not the best approach for monitoring a large complex\nservice. But I won&rsquo;t go into that because that&rsquo;s not what this post is about.</p>\n\n<h3 id=\"it-s-been-working-well-so-far\">it&rsquo;s been working well so far!</h3>\n\n<p>I originally wrote this post 3 months ago in April, but I waited until now to\npublish it to make sure that the whole setup was working.</p>\n\n<p>It&rsquo;s made a pretty big difference &ndash; before I was having some very silly\ndowntime problems, and now for the last few months the sites have been up\n99.95% of the time!</p>\n"
}