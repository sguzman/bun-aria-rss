{
  "title": "Representational Power of Deeper Layers",
  "link": "",
  "published": "2016-03-30T00:00:00-04:00",
  "updated": "2016-03-30T00:00:00-04:00",
  "author": {
    "name": "Silviu Pitis"
  },
  "id": "tag:r2rt.com,2016-03-30:/representational-power-of-deeper-layers.html",
  "summary": "The hidden layers in a neural network can be seen as different representations of the input. Do deeper layers learn \"better\" representations? In a network trained to solve a classification problem, this would mean that deeper layers provide better features than earlier layers. The natural hypothesis is that this is indeed the case. In this post, I test this hypothesis on an network with three hidden layers trained to classify the MNIST dataset. It is shown that deeper layers do in fact produce better representations of the input.",
  "content": "<!DOCTYPE html>\n<html>\n<head>\n  <meta charset=\"utf-8\">\n  <meta name=\"generator\" content=\"pandoc\">\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, user-scalable=yes\">\n  <title></title>\n  <style type=\"text/css\">code{white-space: pre;}</style>\n  <style type=\"text/css\">\ndiv.sourceCode { overflow-x: auto; }\ntable.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {\n  margin: 0; padding: 0; vertical-align: baseline; border: none; }\ntable.sourceCode { width: 100%; line-height: 100%; }\ntd.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }\ntd.sourceCode { padding-left: 5px; }\ncode > span.kw { color: #007020; font-weight: bold; } /* Keyword */\ncode > span.dt { color: #902000; } /* DataType */\ncode > span.dv { color: #40a070; } /* DecVal */\ncode > span.bn { color: #40a070; } /* BaseN */\ncode > span.fl { color: #40a070; } /* Float */\ncode > span.ch { color: #4070a0; } /* Char */\ncode > span.st { color: #4070a0; } /* String */\ncode > span.co { color: #60a0b0; font-style: italic; } /* Comment */\ncode > span.ot { color: #007020; } /* Other */\ncode > span.al { color: #ff0000; font-weight: bold; } /* Alert */\ncode > span.fu { color: #06287e; } /* Function */\ncode > span.er { color: #ff0000; font-weight: bold; } /* Error */\ncode > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */\ncode > span.cn { color: #880000; } /* Constant */\ncode > span.sc { color: #4070a0; } /* SpecialChar */\ncode > span.vs { color: #4070a0; } /* VerbatimString */\ncode > span.ss { color: #bb6688; } /* SpecialString */\ncode > span.im { } /* Import */\ncode > span.va { color: #19177c; } /* Variable */\ncode > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */\ncode > span.op { color: #666666; } /* Operator */\ncode > span.bu { } /* BuiltIn */\ncode > span.ex { } /* Extension */\ncode > span.pp { color: #bc7a00; } /* Preprocessor */\ncode > span.at { color: #7d9029; } /* Attribute */\ncode > span.do { color: #ba2121; font-style: italic; } /* Documentation */\ncode > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */\ncode > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */\ncode > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */\n  </style>\n  <!--[if lt IE 9]>\n    <script src=\"//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js\"></script>\n  <![endif]-->\n</head>\n<body>\n<p>The hidden layers in a neural network can be seen as different representations of the input. Do deeper layers learn “better” representations? In a network trained to solve a classification problem, this would mean that deeper layers provide better features than earlier layers. The natural hypothesis is that this is indeed the case. In this post, I test this hypothesis on an network with three hidden layers trained to classify the MNIST dataset. It is shown that deeper layers do in fact produce better representations of the input.</p>\n<h3 id=\"model-setup\">Model setup</h3>\n<div class=\"sourceCode\"><pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"im\">import</span> tensorflow <span class=\"im\">as</span> tf\n<span class=\"im\">import</span> numpy <span class=\"im\">as</span> np\n<span class=\"im\">import</span> load_mnist\n<span class=\"im\">import</span> matplotlib.pyplot <span class=\"im\">as</span> plt\n<span class=\"op\">%</span>matplotlib inline\nmnist <span class=\"op\">=</span> load_mnist.read_data_sets(<span class=\"st\">&#39;MNIST_data&#39;</span>, one_hot<span class=\"op\">=</span><span class=\"va\">True</span>)\n\nsess <span class=\"op\">=</span> tf.InteractiveSession()\n\n<span class=\"kw\">def</span> weight_variable(shape):\n  initial <span class=\"op\">=</span> tf.truncated_normal(shape, stddev<span class=\"op\">=</span><span class=\"fl\">0.1</span>)\n  <span class=\"cf\">return</span> tf.Variable(initial)\n\n<span class=\"kw\">def</span> bias_variable(shape):\n  initial <span class=\"op\">=</span> tf.constant(<span class=\"fl\">0.1</span>, shape<span class=\"op\">=</span>shape)\n  <span class=\"cf\">return</span> tf.Variable(initial)\n\n<span class=\"kw\">def</span> simple_fc_layer(input_layer, shape):\n    w <span class=\"op\">=</span> weight_variable(shape)\n    b <span class=\"op\">=</span> bias_variable([shape[<span class=\"dv\">1</span>]])\n    <span class=\"cf\">return</span> tf.nn.tanh(tf.matmul(input_layer,w) <span class=\"op\">+</span> b)\n\nx <span class=\"op\">=</span> tf.placeholder(<span class=\"st\">&quot;float&quot;</span>, shape<span class=\"op\">=</span>[<span class=\"va\">None</span>, <span class=\"dv\">784</span>])\ny_ <span class=\"op\">=</span> tf.placeholder(<span class=\"st\">&quot;float&quot;</span>, shape<span class=\"op\">=</span>[<span class=\"va\">None</span>, <span class=\"dv\">10</span>])\n\nl1 <span class=\"op\">=</span> simple_fc_layer(x, [<span class=\"dv\">784</span>,<span class=\"dv\">100</span>])\nl2 <span class=\"op\">=</span> simple_fc_layer(l1, [<span class=\"dv\">100</span>,<span class=\"dv\">100</span>])\nl3 <span class=\"op\">=</span> simple_fc_layer(l2, [<span class=\"dv\">100</span>,<span class=\"dv\">100</span>])\n\nw <span class=\"op\">=</span> weight_variable([<span class=\"dv\">100</span>,<span class=\"dv\">10</span>])\nb <span class=\"op\">=</span> bias_variable([<span class=\"dv\">10</span>])\ny <span class=\"op\">=</span> tf.nn.softmax(tf.matmul(l3,w) <span class=\"op\">+</span> b)\n\ncross_entropy <span class=\"op\">=</span> <span class=\"op\">-</span>tf.reduce_sum(y_<span class=\"op\">*</span>tf.log(y))\ntrain_step <span class=\"op\">=</span> tf.train.GradientDescentOptimizer(<span class=\"fl\">0.01</span>).minimize(cross_entropy)\n\nsess.run(tf.initialize_all_variables())\n\nsaver <span class=\"op\">=</span> tf.train.Saver()\nsaver.save(sess, <span class=\"st\">&#39;/tmp/initial_variables.ckpt&#39;</span>)\n\ncorrect_prediction <span class=\"op\">=</span> tf.equal(tf.argmax(y,<span class=\"dv\">1</span>), tf.argmax(y_,<span class=\"dv\">1</span>))\naccuracy <span class=\"op\">=</span> tf.reduce_mean(tf.cast(correct_prediction, <span class=\"st\">&quot;float&quot;</span>))\n\nbase_accuracy <span class=\"op\">=</span> []\n<span class=\"cf\">for</span> i <span class=\"kw\">in</span> <span class=\"bu\">range</span>(<span class=\"dv\">10000</span>):\n    start <span class=\"op\">=</span> (<span class=\"dv\">50</span><span class=\"op\">*</span>i) <span class=\"op\">%</span> <span class=\"dv\">54950</span>\n    end <span class=\"op\">=</span> start <span class=\"op\">+</span> <span class=\"dv\">50</span>\n    train_step.run(feed_dict<span class=\"op\">=</span>{x: mnist.train.images[start:end], y_: mnist.train.labels[start:end]})\n    <span class=\"cf\">if</span> i <span class=\"op\">%</span> <span class=\"dv\">100</span> <span class=\"op\">==</span> <span class=\"dv\">0</span>:\n        base_accuracy.append(accuracy.<span class=\"bu\">eval</span>(feed_dict<span class=\"op\">=</span>{x: mnist.test.images, y_: mnist.test.labels}))\n\n<span class=\"bu\">print</span>(base_accuracy[<span class=\"op\">-</span><span class=\"dv\">1</span>])</code></pre></div>\n<pre><code>0.971</code></pre>\n<p>The network achieves an accuracy of about 97% after 10000 training steps in batches of 50 (about 1 epoch of the dataset).</p>\n<h3 id=\"increasing-representational-power\">Increasing representational power</h3>\n<p>To show increasing representational power, I run logistic regression (supervised) and PCA (unsupervised) models on each layer of the data and show that they perform progressively better with deeper layers.</p>\n<div class=\"sourceCode\"><pre class=\"sourceCode python\"><code class=\"sourceCode python\">x_test, y_test <span class=\"op\">=</span> mnist.test.images[:<span class=\"dv\">1000</span>], mnist.test.labels[:<span class=\"dv\">1000</span>]\n\ny_train_single <span class=\"op\">=</span> np.<span class=\"bu\">sum</span>((mnist.train.labels[:<span class=\"dv\">1000</span>] <span class=\"op\">*</span> np.array([<span class=\"dv\">0</span>,<span class=\"dv\">1</span>,<span class=\"dv\">2</span>,<span class=\"dv\">3</span>,<span class=\"dv\">4</span>,<span class=\"dv\">5</span>,<span class=\"dv\">6</span>,<span class=\"dv\">7</span>,<span class=\"dv\">8</span>,<span class=\"dv\">9</span>])),axis<span class=\"op\">=</span><span class=\"dv\">1</span>)\ny_test_single <span class=\"op\">=</span> np.<span class=\"bu\">sum</span>((y_test <span class=\"op\">*</span> np.array([<span class=\"dv\">0</span>,<span class=\"dv\">1</span>,<span class=\"dv\">2</span>,<span class=\"dv\">3</span>,<span class=\"dv\">4</span>,<span class=\"dv\">5</span>,<span class=\"dv\">6</span>,<span class=\"dv\">7</span>,<span class=\"dv\">8</span>,<span class=\"dv\">9</span>])),axis<span class=\"op\">=</span><span class=\"dv\">1</span>)\n\nx_arr_test <span class=\"op\">=</span> [x_test] <span class=\"op\">+</span> sess.run([l1,l2,l3],feed_dict<span class=\"op\">=</span>{x:x_test,y_:y_test})\nx_arr_train <span class=\"op\">=</span> [mnist.train.images[:<span class=\"dv\">1000</span>]] <span class=\"op\">+</span> sess.run([l1,l2,l3],feed_dict<span class=\"op\">=</span>{x:mnist.train.images[:<span class=\"dv\">1000</span>],y:mnist.train.labels[:<span class=\"dv\">1000</span>]})</code></pre></div>\n<h3 id=\"logistic-regression\">Logistic Regression</h3>\n<div class=\"sourceCode\"><pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"im\">from</span> sklearn.linear_model <span class=\"im\">import</span> LogisticRegression\nlog_reg <span class=\"op\">=</span> LogisticRegression()\n\n<span class=\"cf\">for</span> idx, i <span class=\"kw\">in</span> <span class=\"bu\">enumerate</span>(x_arr_train):\n    log_reg.fit(i,y_train_single)\n    <span class=\"bu\">print</span>(<span class=\"st\">&quot;Layer &quot;</span> <span class=\"op\">+</span> <span class=\"bu\">str</span>(idx) <span class=\"op\">+</span> <span class=\"st\">&quot; accuracy is: &quot;</span> <span class=\"op\">+</span> <span class=\"bu\">str</span>(log_reg.score(x_arr_test[idx],y_test_single)))</code></pre></div>\n<pre><code>Layer 0 accuracy is: 0.828\nLayer 1 accuracy is: 0.931\nLayer 2 accuracy is: 0.953\nLayer 3 accuracy is: 0.966</code></pre>\n<p>In support of the hypothesis, logistic regression performs progressively better the deeper the representation. There appear to be decreasing marginal returns to each additional hidden layer, and it would be interesting to see if this pattern holds up for deeper / more complex models.</p>\n<h3 id=\"pca\">PCA</h3>\n<div class=\"sourceCode\"><pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"im\">from</span> sklearn.decomposition <span class=\"im\">import</span> PCA\n<span class=\"im\">from</span> matplotlib <span class=\"im\">import</span> cm\n<span class=\"kw\">def</span> plot_mnist_pca(axis, x, ix1, ix2, colors, num<span class=\"op\">=</span><span class=\"dv\">1000</span>):\n    pca <span class=\"op\">=</span> PCA()\n    pca.fit(x)\n    x_red <span class=\"op\">=</span> pca.transform(x)\n    axis.scatter(x_red[:num,ix1],x_red[:num,ix2],c<span class=\"op\">=</span>colors[:<span class=\"dv\">1000</span>],cmap<span class=\"op\">=</span>cm.rainbow_r)\n\n<span class=\"kw\">def</span> plot(list_to_plot):\n    fig,ax <span class=\"op\">=</span> plt.subplots(<span class=\"dv\">3</span>,<span class=\"dv\">4</span>,figsize<span class=\"op\">=</span>(<span class=\"dv\">12</span>,<span class=\"dv\">9</span>))\n    fig.tight_layout()\n    perms <span class=\"op\">=</span> [(<span class=\"dv\">0</span>,<span class=\"dv\">1</span>),(<span class=\"dv\">0</span>,<span class=\"dv\">2</span>),(<span class=\"dv\">1</span>,<span class=\"dv\">2</span>)]\n    colors <span class=\"op\">=</span> y_test_single\n\n    index <span class=\"op\">=</span> np.zeros(colors.shape)\n    <span class=\"cf\">for</span> i <span class=\"kw\">in</span> list_to_plot:\n        index <span class=\"op\">+=</span> (colors<span class=\"op\">==</span>i)\n\n    <span class=\"cf\">for</span> row, axis_row <span class=\"kw\">in</span> <span class=\"bu\">enumerate</span>(ax):\n        <span class=\"cf\">for</span> col, axis <span class=\"kw\">in</span> <span class=\"bu\">enumerate</span>(axis_row):\n             plot_mnist_pca(axis, x_arr_test[col][index<span class=\"op\">==</span><span class=\"dv\">1</span>], perms[row][<span class=\"dv\">0</span>], perms[row][<span class=\"dv\">1</span>], colors[index<span class=\"op\">==</span><span class=\"dv\">1</span>], num<span class=\"op\">=</span><span class=\"dv\">1000</span>)\n\nplot(<span class=\"bu\">range</span>(<span class=\"dv\">4</span>))</code></pre></div>\n<figure>\n<img src=\"https://r2rt.com/static/images/RPDL_output_9_0.png\" />\n</figure>\n<p>Each row of the above grid plots combinations (pairs) of the first three principal components with respect to the numbers 0, 1, 2 and 3 (using only 4 numbers at a time makes the separation more visible). The columns, from left to right, correspond to the input layer, the first hidden layer, the second hidden layer and the final hidden layer.</p>\n<p>In support of the hypothesis, the principal components of deeper layers provide visibly better separation of the data than earlier layers.</p>\n<h3 id=\"a-failed-experiment-teaching-the-neural-network-features\">A failed experiment: teaching the neural network features</h3>\n<p>I had hypothesized that we could use the most prominent features (the top three principal components) of the final hidden layer to train a new neural network and have it perform better. For each training example, in addition to predicting the classification, the new network also performs a regression on the top three principal components of that training example’s third hidden layer representation according to the first model. The training step backpropagates both the classification error and the regression error.</p>\n<p>Unfortunately, this approach did not provide any noticeable improvement over the original model.</p>\n<div class=\"sourceCode\"><pre class=\"sourceCode python\"><code class=\"sourceCode python\">pca <span class=\"op\">=</span> PCA()\nl3_train <span class=\"op\">=</span> l3.<span class=\"bu\">eval</span>(feed_dict<span class=\"op\">=</span>{x:mnist.train.images})\nl3_test  <span class=\"op\">=</span> l3.<span class=\"bu\">eval</span>(feed_dict<span class=\"op\">=</span>{x:mnist.test.images})\n\npca.fit(l3_train)\ny_new_train <span class=\"op\">=</span> pca.transform(l3_train)[:,:<span class=\"dv\">3</span>]\ny_new_test <span class=\"op\">=</span> pca.transform(l3_test)[:,:<span class=\"dv\">3</span>]\n\nsaver.restore(sess, <span class=\"st\">&#39;/tmp/initial_variables.ckpt&#39;</span>)\n\n<span class=\"co\"># create new placeholder for 3 new variables</span>\ny_3newfeatures_ <span class=\"op\">=</span> tf.placeholder(<span class=\"st\">&quot;float&quot;</span>, shape<span class=\"op\">=</span>[<span class=\"va\">None</span>, <span class=\"dv\">3</span>])\n\n<span class=\"co\"># add linear regression for new features</span>\nw <span class=\"op\">=</span> weight_variable([<span class=\"dv\">100</span>,<span class=\"dv\">3</span>])\nb <span class=\"op\">=</span> bias_variable([<span class=\"dv\">3</span>])\ny_3newfeatures <span class=\"op\">=</span> tf.matmul(l1,w) <span class=\"op\">+</span> b\n\nsess.run(tf.initialize_all_variables())\n\nnew_feature_loss <span class=\"op\">=</span> <span class=\"fl\">1e-1</span><span class=\"op\">*</span>tf.reduce_sum(tf.<span class=\"bu\">abs</span>(y_3newfeatures_<span class=\"op\">-</span>y_3newfeatures))\n\ntrain_step_new_features <span class=\"op\">=</span> tf.train.GradientDescentOptimizer(<span class=\"fl\">0.01</span>).minimize(cross_entropy <span class=\"op\">+</span> new_feature_loss)\n\nnew_accuracy <span class=\"op\">=</span> []\n<span class=\"cf\">for</span> i <span class=\"kw\">in</span> <span class=\"bu\">range</span>(<span class=\"dv\">10000</span>):\n    start <span class=\"op\">=</span> (<span class=\"dv\">50</span><span class=\"op\">*</span>i) <span class=\"op\">%</span> <span class=\"dv\">54950</span>\n    end <span class=\"op\">=</span> start <span class=\"op\">+</span> <span class=\"dv\">50</span>\n    train_step_new_features.run(feed_dict<span class=\"op\">=</span>{x: mnist.train.images[start:end], y_: mnist.train.labels[start:end],y_3newfeatures_:y_new_train[start:end]})\n    <span class=\"cf\">if</span> i <span class=\"op\">%</span> <span class=\"dv\">100</span> <span class=\"op\">==</span> <span class=\"dv\">0</span>:\n        acc, ce, lr <span class=\"op\">=</span> sess.run([accuracy, cross_entropy, new_feature_loss],feed_dict<span class=\"op\">=</span>{x:mnist.test.images,y_:mnist.test.labels,y_3newfeatures_:y_new_test})\n        new_accuracy.append(acc)\n        <span class=\"bu\">print</span>(<span class=\"st\">&quot;Accuracy: &quot;</span> <span class=\"op\">+</span> <span class=\"bu\">str</span>(acc) <span class=\"op\">+</span> <span class=\"st\">&quot; -- Cross entropy: &quot;</span> <span class=\"op\">+</span> <span class=\"bu\">str</span>(ce) <span class=\"op\">+</span> <span class=\"st\">&quot; -- New feature loss: &quot;</span> <span class=\"op\">+</span> <span class=\"bu\">str</span>(lr),end<span class=\"op\">=</span><span class=\"st\">&quot;</span><span class=\"ch\">\\r</span><span class=\"st\">&quot;</span>)\n\n<span class=\"bu\">print</span>(new_accuracy[<span class=\"op\">-</span><span class=\"dv\">1</span>])</code></pre></div>\n<pre><code>0.9707</code></pre>\n<div class=\"sourceCode\"><pre class=\"sourceCode python\"><code class=\"sourceCode python\">fig, ax <span class=\"op\">=</span> plt.subplots()\n\nax.plot(base_accuracy, label<span class=\"op\">=</span><span class=\"st\">&#39;Base&#39;</span>)\nax.plot(new_accuracy, label<span class=\"op\">=</span><span class=\"st\">&#39;New&#39;</span>)\nax.set_xlabel(<span class=\"st\">&#39;Training steps&#39;</span>)\nax.set_ylabel(<span class=\"st\">&#39;Accuracy&#39;</span>)\nax.set_title(<span class=\"st\">&#39;Base vs New Accuracy&#39;</span>)\nax.legend(loc<span class=\"op\">=</span><span class=\"dv\">4</span>)\nplt.show()</code></pre></div>\n<figure>\n<img src=\"https://r2rt.com/static/images/RPDL_output_13_0.png\" />\n</figure>\n</body>\n</html>"
}