{
  "title": "MotionDeltaCNN: Sparse CNN Inference of Frame Differences in Moving Camera Videos. (arXiv:2210.09887v3 [cs.CV] UPDATED)",
  "link": "http://arxiv.org/abs/2210.09887",
  "description": "<p>Convolutional neural network inference on video input is computationally\nexpensive and has high memory bandwidth requirements. Recently, researchers\nmanaged to reduce the cost of processing upcoming frames by only processing\npixels that changed significantly. Using sparse convolutions, the sparsity of\nframe differences can be translated to speedups on current inference devices.\nHowever, previous work was relying on static cameras. Moving cameras add new\nchallenges in how to fuse newly unveiled image regions with already processed\nregions efficiently to minimize the update rate - without increasing memory\noverhead and without knowing the camera extrinsics of future frames. In this\nwork, we propose MotionDeltaCNN, a CNN framework that supports moving cameras\nand variable resolution input. We propose a spherical buffer which enables\nseamless fusion of newly unveiled regions and previously processed regions -\nwithout increasing the memory footprint. Our evaluations show that we\noutperform previous work by up to 90% by explicitly adding support for moving\ncamera input.\n</p>",
  "dc:creator": "<a href=\"http://arxiv.org/find/cs/1/au:+Parger_M/0/1/0/all/0/1\">Mathias Parger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_C/0/1/0/all/0/1\">Chengcheng Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neff_T/0/1/0/all/0/1\">Thomas Neff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Twigg_C/0/1/0/all/0/1\">Christopher D. Twigg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keskin_C/0/1/0/all/0/1\">Cem Keskin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Robert Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steinberger_M/0/1/0/all/0/1\">Markus Steinberger</a>"
}