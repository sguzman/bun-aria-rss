{
  "title": "Implement Simple Convolution with Java",
  "link": "http://ramok.tech/2018/09/27/convolution-in-java/",
  "dc:creator": "Klevis Ramo",
  "pubDate": "Thu, 27 Sep 2018 20:35:32 +0000",
  "category": [
    "Machine Learning",
    "convolution neural network",
    "java machine learning",
    "java neural network"
  ],
  "guid": "http://ramok.tech/?p=2027",
  "description": "In this post we are going to walk through the details and intuition behind simple convolution operation as one one of the most fundamental concept in Computer Vision. Additionally we will build a Java Application GUI which uses different convolution filters(implemented purely in java) to transform images of your choice. Please find the free open &#8230; <a href=\"http://ramok.tech/2018/09/27/convolution-in-java/\" class=\"more-link\">Continue reading<span class=\"screen-reader-text\"> \"Implement Simple Convolution with Java\"</span></a>",
  "content:encoded": "<p>In this post we are going to walk through the details and intuition behind simple convolution operation as one one of the most fundamental concept in Computer Vision. Additionally we will build a <a href=\"https://github.com/PacktPublishing/Java-Machine-Learning-for-Computer-Vision/tree/master/EdgeDetection\">Java Application GUI</a> which uses different convolution filters(implemented purely in java) to transform images of your choice. Please find the free open source code at this <a href=\"https://github.com/PacktPublishing/Java-Machine-Learning-for-Computer-Vision\">github repository</a> as part of <a href=\"https://www.packtpub.com/big-data-and-business-intelligence/java-machine-learning-computer-vision-video\">Packt Java Machine Learning for Computer Vision Course</a>.</p>\n<h3>How Computers perceive images</h3>\n<p>Although computers cannot perceive colors as we do they understand numbers quite good. So to no surprise  a way was found to encode colors as numbers so a computer will understand.</p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-2030\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/vertical.png?resize=821%2C291\" alt=\"\" width=\"821\" height=\"291\" srcset=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/vertical.png?w=821 821w, https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/vertical.png?resize=300%2C106 300w, https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/vertical.png?resize=768%2C272 768w\" sizes=\"(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 984px) 61vw, (max-width: 1362px) 45vw, 600px\" data-recalc-dims=\"1\" /></p>\n<p>For <em><strong>black an white</strong>(gray scale) </em>images this is quite easy each number represent light intensity from 0 -255. With 0 meaning no light(black) and 255  meaning white so full brightness. Since in the end this numbers will be converted to colors in a display we need a number per display pixel. Pixels are two dimensional matrices with dimension like 1920 x  1080 or 1280 x 1024 therefore we will a number representing the light intensity per each of the matrices cell.</p>\n<p>For <strong>colored images</strong> the idea stays the same but in addition we have three intensity of colors to take care Red, Green and Blue intensity(yes the famous RGB). So basically we need three of the two dimensional matrices we saw in white black case with each of them representing respective color intensity  Red, Green and Blue(RGB). In a few words we will have a three dimensional matrix containing numbers from 0-255 representing intensity for one of the colors R,G,B e.x <em>image[i][j][<strong>0</strong>] is Red value, image[i][j][<strong>1</strong>] Green value, image[i][j][<strong>2</strong>]</em> Blue .  <img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-2033\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/colored.png?resize=800%2C399\" alt=\"\" width=\"800\" height=\"399\" srcset=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/colored.png?w=800 800w, https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/colored.png?resize=300%2C150 300w, https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/colored.png?resize=768%2C383 768w\" sizes=\"(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 984px) 61vw, (max-width: 1362px) 45vw, 600px\" data-recalc-dims=\"1\" /></p>\n<h3>Edge Detection</h3>\n<p><i><a href=\"https://en.wikipedia.org/wiki/Edge_detection\">Wikipedia definition</a> : Edge </i><i>detection includes a variety of mathematical methods that aim at identifying points in a </i><i>digital image</i><i> at which the </i><i>image brightness</i><i> changes sharply or, more formally, has discontinuities. </i></p>\n<p><i>The points at which image brightness changes sharply are typically organized into a set of curved line segments called </i>edges<i>.</i></p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-2058\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/show2.png?resize=840%2C505\" alt=\"\" width=\"840\" height=\"505\" srcset=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/show2.png?w=991 991w, https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/show2.png?resize=300%2C180 300w, https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/show2.png?resize=768%2C462 768w\" sizes=\"(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px\" data-recalc-dims=\"1\" /></p>\n<p>Historically computer vision has always been a hard problem to solve due to small image data sets and because the problem is kind of hard in itself(<em>you have a bunch of numbers and want to figure out what are those numbers representing</em>). So for this reasons people had to come up with different techniques and methods to overcome this problem. Edge detection is one of those techniques that helped Computer Vision to achieve outstanding results and was first used for <a href=\"http://yann.lecun.com/exdb/mnist/\">digit recognition back in 90&#8217;s</a>(LeNet).</p>\n<p>Relying completely on original images has proven to produce poor results because the model tends to be very sensitive to simple changes in light,shadows, not centered objects(object moving slightly left,right,down or up) etc&#8230; Edge Detection greatly helps with this problems because it enables the neural network to focus more on the object shapes(light intensity and object moving is not a big problem anymore) therefore make the prediction more robust.</p>\n<h3>Convolution</h3>\n<p>Although by now is clear that Edge Detection is worth to try we still need a way to implement it in a computer system where colors are matrices with numbers.</p>\n<h4>Vertical edge detection</h4>\n<p>Lets introduce a small matrix 3×3 called a filter more specifically a vertical filter.</p>\n<table style=\"width: 599px;\" border=\"0\" width=\"192\" cellspacing=\"0\" cellpadding=\"0\">\n<colgroup>\n<col span=\"3\" width=\"64\" /></colgroup>\n<tbody>\n<tr>\n<td style=\"width: 182px;\" align=\"right\" height=\"20\"><span style=\"color: #ff0000;\">1</span></td>\n<td style=\"width: 185px;\" align=\"right\"><span style=\"color: #ff0000;\">0</span></td>\n<td style=\"width: 186px;\" align=\"right\"><span style=\"color: #ff0000;\">-1</span></td>\n</tr>\n<tr>\n<td style=\"width: 182px;\" align=\"right\" height=\"20\"><span style=\"color: #ff0000;\">1</span></td>\n<td style=\"width: 185px;\" align=\"right\"><span style=\"color: #ff0000;\">0</span></td>\n<td style=\"width: 186px;\" align=\"right\"><span style=\"color: #ff0000;\">-1</span></td>\n</tr>\n<tr>\n<td style=\"width: 182px;\" align=\"right\" height=\"20\"><span style=\"color: #ff0000;\">1</span></td>\n<td style=\"width: 185px;\" align=\"right\"><span style=\"color: #ff0000;\">0</span></td>\n<td style=\"width: 186px;\" align=\"right\"><span style=\"color: #ff0000;\">-1</span></td>\n</tr>\n</tbody>\n</table>\n<p>Additionally we are going to introduce an operation<strong> *</strong> called convolution and than simply convolve the image matrix(which is a simple black and white image on the left) with the vertical filter.</p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-2037\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/convolve.png?resize=840%2C235\" alt=\"\" width=\"840\" height=\"235\" srcset=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/convolve.png?w=1038 1038w, https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/convolve.png?resize=300%2C84 300w, https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/convolve.png?resize=768%2C215 768w, https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/convolve.png?resize=1024%2C287 1024w\" sizes=\"(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px\" data-recalc-dims=\"1\" /></p>\n<p style=\"text-align: center;\"><em>For the sake of the argument  we are not using <strong>0</strong> for black but rather small number <strong>10(not perfect black but very near)</strong>. </em></p>\n<p>The convolution operation will look like below:</p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter wp-image-1404 zoooom\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-08_22h55_11.gif?resize=840%2C473\" alt=\"\" width=\"840\" height=\"473\" data-recalc-dims=\"1\" /></p>\n<p style=\"text-align: left;\">We are just sliding the filter one position horizontally and vertically until the end. Each time we multiply the filter matrices elements with the selected area(sub-matrix) on the image matrix elements and than add all together. So for position (<strong>0,0)</strong> we <em>do: </em></p>\n<p style=\"text-align: center;\"><em><span style=\"font-size: 10pt;\"><strong>(1 * 255 + 0 * 255 + -1 * 255 )+ (1 * 255 + 0 * 255 + -1 * 255) +( 1 * 255 + 0 * 255 + -1 * 255) =<span style=\"color: #ff0000;\">0</span></strong></span></em></p>\n<p>while for position <strong>(0,1)</strong> we do:</p>\n<p><strong><span style=\"font-size: 10pt;\"><em>(1 * 255 + 0 * 255 + -1 * 10 )+ (1 * 255 + 0 * 255 + -1 * 10) +( 1 * 255 + 0 * 255 + -1 * 10) =<span style=\"color: #ff0000;\">735</span></em></span></strong></p>\n<p>and son&#8230;</p>\n<p>Eventually this will produce the below output matrix:</p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-2040\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/outConvolv.png?resize=840%2C322\" alt=\"\" width=\"840\" height=\"322\" srcset=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/outConvolv.png?w=1119 1119w, https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/outConvolv.png?resize=300%2C115 300w, https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/outConvolv.png?resize=768%2C294 768w, https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/outConvolv.png?resize=1024%2C393 1024w\" sizes=\"(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px\" data-recalc-dims=\"1\" /></p>\n<p>Lets analyse a bit what happened during the convolution.</p>\n<ul>\n<li>First lets remind that we want to detect vertical edges and looking at the input image the edge is right into the middle. So the region where the color sharply changes from one color(white) to another(black).</li>\n<li>It is easy to notice that right into the middle we have two rows of 735 values. Since the maximum number value we can have to represent a color is 255 for values bigger than that(735) we just don&#8217;t care but instead consider the maximum which 255. Same for values(e.x -735)  less the than the minimum 0 we are going to consider 0 and ignore the rest. Following this approach the output matrix is visualized as an image with the sides as black and in the middle a white region.</li>\n<li>Actually the white region on the output image is exactly the vertical edge we were looking for. So 735 values(white) were actually pointing out the presence on an edge while zeros(black) the absence of such edge. Indeed if look the input images on the sides(only white, only black ) there is no edges but rather only in the middle we have the color sharply changing from white to black.</li>\n<li>Due to small images/matrix used for explanation reasons please notice that the white region is quite big making it hard to look like an edge. Anyway executed in the java <a href=\"https://github.com/PacktPublishing/Java-Machine-Learning-for-Computer-Vision/tree/master/EdgeDetection\">application GUI</a> on a bigger black and white image of <strong>466 X 291</strong> the results would look more clear like below e.x:</li>\n</ul>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-1416\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/edgesComparison.png?resize=840%2C248\" alt=\"\" width=\"840\" height=\"248\" srcset=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/edgesComparison.png?w=984 984w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/edgesComparison.png?resize=300%2C89 300w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/edgesComparison.png?resize=768%2C227 768w\" sizes=\"(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px\" data-recalc-dims=\"1\" /></p>\n<h4>Horizontal edge detection</h4>\n<p>Horizontal edge detection is quite similar like the vertical one but is just using a different filter(flipped version of vertical filter).</p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-2042\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/horizFOut.png?resize=840%2C318\" alt=\"\" width=\"840\" height=\"318\" srcset=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/horizFOut.png?w=1117 1117w, https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/horizFOut.png?resize=300%2C114 300w, https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/horizFOut.png?resize=768%2C291 768w, https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/horizFOut.png?resize=1024%2C388 1024w\" sizes=\"(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px\" data-recalc-dims=\"1\" /></p>\n<p>Similarly notice how we have the 735 values right into the middle where the edge is located and zero values where there is no edge on the up and down sides. Executed in the <a href=\"https://github.com/PacktPublishing/Java-Machine-Learning-for-Computer-Vision/tree/master/EdgeDetection\">java application GUI</a> on a bigger black and white image of <strong>466 X 291</strong> the results would look more clear like below e.x:</p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-1426\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/edgeHComparison.png?resize=825%2C241\" alt=\"\" width=\"825\" height=\"241\" srcset=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/edgeHComparison.png?w=825 825w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/edgeHComparison.png?resize=300%2C88 300w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/edgeHComparison.png?resize=768%2C224 768w\" sizes=\"(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 984px) 61vw, (max-width: 1362px) 45vw, 600px\" data-recalc-dims=\"1\" /></p>\n<h4>Other Edge Detectors</h4>\n<p>There also other edge detectors beside what we saw so fare and we will see them all in action when running the <a href=\"https://github.com/PacktPublishing/Java-Machine-Learning-for-Computer-Vision/tree/master/EdgeDetection\">java edge detection application</a>.</p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-2047\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/filters.png?resize=840%2C328\" alt=\"\" width=\"840\" height=\"328\" srcset=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/filters.png?w=1007 1007w, https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/filters.png?resize=300%2C117 300w, https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/filters.png?resize=768%2C300 768w\" sizes=\"(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px\" data-recalc-dims=\"1\" /></p>\n<p style=\"text-align: center;\"><em>Sobel and Scharr can also flipped and transform to horizontal  version. Both of them introduce more weights on the sides by making the edge thicker(more on show case).</em></p>\n<h4>Edge Detection Intuition</h4>\n<p>By now we already have an intuition why convolution detect edges so lets shortly re visit what happened.</p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-2043\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/Intuitionpng.png?resize=840%2C283\" alt=\"\" width=\"840\" height=\"283\" srcset=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/Intuitionpng.png?w=1073 1073w, https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/Intuitionpng.png?resize=300%2C101 300w, https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/Intuitionpng.png?resize=768%2C258 768w, https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/Intuitionpng.png?resize=1024%2C345 1024w\" sizes=\"(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px\" data-recalc-dims=\"1\" /><br />\nIn the figure above  we have the vertical filter on red and the horizontal filter green. Regardless of their position on the matrix the filters are both interested on sides by ignoring the middle row. Filters are interested if there is any difference in numbers(recall numbers are colors so change in color so edge) on the sides by ignoring the middle. Depending on the sides values their could be two cases:</p>\n<ol>\n<li>When both sides have the same values the sum will be zero since the middle is ignored and filter have positive and negative values on sides. This simply means there is not edge on this region selected by the filter.</li>\n<li>When both sides are different the  sum will have a value different than zero (usually in absolute terms big)since the middle is ignored and filter have positive and negative values on sides. As we saw previously big values indicate the presence of an edge since the color on the sides has sharply changed.</li>\n</ol>\n<h4>Convolution on Colored Images</h4>\n<p>As we know RGB images differ from black and white by having instead of one three matrices with values from 0-255 each representing intensity of Red,Green and Blue color. So as you may already figure it out by now it looks reasonable to convolve each of this matrices with some chosen filter(<strong><em>not necessarily the same filter as in figure</em></strong>).</p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-2052\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/RGBConvolve.png?resize=840%2C324\" alt=\"\" width=\"840\" height=\"324\" srcset=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/RGBConvolve.png?w=1123 1123w, https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/RGBConvolve.png?resize=300%2C116 300w, https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/RGBConvolve.png?resize=768%2C296 768w, https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/RGBConvolve.png?resize=1024%2C395 1024w\" sizes=\"(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px\" data-recalc-dims=\"1\" />Convolving with three filters each will result in three output matrices each representing the convolution output of specific color(R,G,B). Having a closer look a this matrices we will notice that actually those matrices are not representing anymore colors but rather represent the presence of an edge or not. So each those pixels(matrices cells) not are flagging the possibility of an edge presence. Therefore keeping them separated does not bring any value since there is no RGB anymore. As a result we are going to sum all three those matrices together and have only one matrices as result.</p>\n<h3>Convolution in Neural Networks</h3>\n<p>Although so fare we have seen different type of filters or convolution types, there is still one question: what filter or convolution works better with neural networks for specific problem?</p>\n<p>As we already mention computer vision problems are hard and is quite difficult and in flexible to choose only one of the filters or even a mixture of them. So why don&#8217;t we let the neural networks figure out what type of filters works better for a particular problem?</p>\n<p>Maybe Neural Networks can find out better filters than Vertical,Horizontal or Sobel. So instead of having filters with values on the matrices cells we are going to parametrize(<strong>W<sup>ij</sup></strong>) those cells and let the neural network learn those parameters as it needs.</p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-2048\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/parametrize.png?resize=840%2C326\" alt=\"\" width=\"840\" height=\"326\" srcset=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/parametrize.png?w=1066 1066w, https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/parametrize.png?resize=300%2C117 300w, https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/parametrize.png?resize=768%2C298 768w, https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/parametrize.png?resize=1024%2C398 1024w\" sizes=\"(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px\" data-recalc-dims=\"1\" /></p>\n<p>The purpose of this post is to walk through the intuition of convolution and implement a simple convolution in pure java. When it comes in using the convolution in deep neural networks there are a few more details related to convolution which are explained in detail in previous post as <a href=\"http://ramok.tech/2017/12/13/java-digit-recognizer-with-convolutional-neural-networks/#Convolution_Parameters\">Convolution Parameters</a> , <a href=\"http://ramok.tech/2017/12/13/java-digit-recognizer-with-convolutional-neural-networks/#Pooling_Layers\">Pooling Layers</a> and in addition also a <a href=\"http://ramok.tech/2017/12/13/java-digit-recognizer-with-convolutional-neural-networks/#Application\">java application for hand wiring digits recognition</a> is build using the explained concepts(for more application about deep convolution networks please refer at<a href=\"http://ramok.tech/2018/01/03/java-image-cat-vs-dog-recognizer-with-deep-neural-networks/\"> CatVsDog Recognition Java Application</a>).</p>\n<h3>The Code</h3>\n<p>The details of the full code can be found at this <a href=\"https://github.com/PacktPublishing/Java-Machine-Learning-for-Computer-Vision\">github repository</a> as part of <a href=\"https://www.packtpub.com/big-data-and-business-intelligence/java-machine-learning-computer-vision-video\">Packt Java Machine Learning for Computer Vision</a> course.</p>\n<p>As a first step we will need to read a colored RGB images and build a three dimensional matrix out of that:</p>\n<pre>private double[][][] transformImageToArray(BufferedImage bufferedImage) {\n    int width = bufferedImage.getWidth();\n    int height = bufferedImage.getHeight();\n\n    double[][][] image = new double[3][height][width];\n    for (int i = 0; i < height; i++) {\n        for (int j = 0; j < width; j++) {\n            Color color = new Color(bufferedImage.getRGB(j, i));\n            image[0][i][j] = color.getRed();\n            image[1][i][j] = color.getGreen();\n            image[2][i][j] = color.getBlue();\n        }\n    }\n    return image;\n}</pre>\n<p>Than as we saw during the theory we need to apply convolution with some chosen filter to each of this matrices R,G,B and of course in the end we will sum up since convolution on colored images produces on matrix:</p>\n<pre>private double[][] applyConvolution(int width, int height, double[][][] image, double[][] filter) {\n    Convolution convolution = new Convolution();\n    double[][] redConv = convolution.convolutionType2(image[0], height, width, filter, 3, 3, 1);\n    double[][] greenConv = convolution.convolutionType2(image[1], height, width, filter, 3, 3, 1);\n    double[][] blueConv = convolution.convolutionType2(image[2], height, width, filter, 3, 3, 1);\n    double[][] finalConv = new double[redConv.length][redConv[0].length];\n//sum up all convolution outputs\n    for (int i = 0; i < redConv.length; i++) {\n        for (int j = 0; j < redConv[i].length; j++) {\n            finalConv[i][j] = redConv[i][j] + greenConv[i][j] + blueConv[i][j];\n        }\n    }\n    return finalConv;\n}</pre>\n<p>After that there is one last step is showing the convolution output matrix as an image into GUI:</p>\n<pre>private File createImageFromConvolutionMatrix(BufferedImage originalImage, double[][] imageRGB) throws IOException {\n    BufferedImage writeBackImage = new BufferedImage(originalImage.getWidth(), originalImage.getHeight(), BufferedImage.TYPE_INT_RGB);\n    for (int i = 0; i < imageRGB.length; i++) {\n        for (int j = 0; j < imageRGB[i].length; j++) {\n            Color color = new Color(fixOutOfRangeRGBValues(imageRGB[i][j]),\n                    fixOutOfRangeRGBValues(imageRGB[i][j]),\n                    fixOutOfRangeRGBValues(imageRGB[i][j]));\n            writeBackImage.setRGB(j, i, color.getRGB());\n        }\n    }\n    File outputFile = new File(\"EdgeDetection/edgesTmp.png\");\n    ImageIO.write(writeBackImage, \"png\", outputFile);\n    return outputFile;\n}</pre>\n<pre>private int fixOutOfRangeRGBValues(double value) {\n    if (value < 0.0) {\n        value = -value;\n    }\n    if (value > 255) {\n        return 255;\n    } else {\n        return (int) value;\n    }\n}</pre>\n<p>As we already mention values bigger than 255 are just 255 and values smaller than 0 are just 0 because there is the only way we can show the image in java in RGB(probably other languages as well).</p>\n<p>In the end we need to put all together with below simple method:</p>\n<pre>public File detectEdges(BufferedImage bufferedImage, String selectedFilter) throws IOException {\n    double[][][] image = transformImageToArray(bufferedImage);\n    double[][] filter = filterMap.get(selectedFilter);\n    double[][] convolvedPixels = applyConvolution(bufferedImage.getWidth(),\n            bufferedImage.getHeight(), image, filter);\n    return createImageFromConvolutionMatrix(bufferedImage, convolvedPixels);\n}</pre>\n<p>Of course there is one last piece missing the convolution operation itself. The code is a bit too long(less than 140 lines) to show full in here but quite straight forward so please feel free to explore <a href=\"https://github.com/PacktPublishing/Java-Machine-Learning-for-Computer-Vision/blob/master/EdgeDetection/src/main/java/ramo/klevis/ml/Convolution.java\">Convolution class</a> in <a href=\"https://github.com/PacktPublishing/Java-Machine-Learning-for-Computer-Vision/tree/master/EdgeDetection\">github</a>.</p>\n<pre>public double[][] convolutionType2(double[][] input,\n                                   int width, int height,\n                                   double[][] kernel,\n                                   int kernelWidth, int kernelHeight,\n                                   int iterations) {\n    double[][] newInput = input.clone();\n    double[][] output = input.clone();\n\n    for (int i = 0; i < iterations; ++i) {\n        output = convolution2DPadded(newInput, width, height,\n                kernel, kernelWidth, kernelHeight);\n        newInput = output.clone();\n    }\n    return output;\n}</pre>\n<h3>Application & Showcase</h3>\n<p>Application can be run by executing <a href=\"https://github.com/PacktPublishing/Java-Machine-Learning-for-Computer-Vision/blob/master/EdgeDetection/src/main/java/ramo/klevis/ml/RunEdgeDetection.java\">RunEdgeDetection class</a> and than GUI will be shown as below in which a type of filter is chosen together with an images:</p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-2057\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/show1.png?resize=840%2C496\" alt=\"\" width=\"840\" height=\"496\" srcset=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/show1.png?w=992 992w, https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/show1.png?resize=300%2C177 300w, https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/show1.png?resize=768%2C454 768w\" sizes=\"(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px\" data-recalc-dims=\"1\" /></p>\n<p>Feel free to explore the effect of choosing different filters and images. In addition some examples below:</p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-2058\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/show2.png?resize=840%2C505\" alt=\"\" width=\"840\" height=\"505\" srcset=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/show2.png?w=991 991w, https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/show2.png?resize=300%2C180 300w, https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/show2.png?resize=768%2C462 768w\" sizes=\"(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px\" data-recalc-dims=\"1\" /></p>\n<p style=\"text-align: center;\"><em>Notice how Scharre produces thicker edges and a bit more edges as well due to bigger weights.</em></p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-2059\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/show3.png?resize=840%2C505\" alt=\"\" width=\"840\" height=\"505\" srcset=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/show3.png?w=991 991w, https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/show3.png?resize=300%2C180 300w, https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/show3.png?resize=768%2C462 768w\" sizes=\"(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px\" data-recalc-dims=\"1\" /></p>\n<p style=\"text-align: center;\"><em>Because of the horizontal nature of the picture convolution detects almost all edges beside some vertical edges which are detected better below:</em></p>\n<p style=\"text-align: center;\"><em><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-2060\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/show4.png?resize=840%2C505\" alt=\"\" width=\"840\" height=\"505\" srcset=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/show4.png?w=991 991w, https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/show4.png?resize=300%2C180 300w, https://i0.wp.com/ramok.tech/wp-content/uploads/2018/09/show4.png?resize=768%2C462 768w\" sizes=\"(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px\" data-recalc-dims=\"1\" />At this case because of choosing vertical filter we are missing some horizontal edges but quite more vertical lines are well detected </em></p>\n",
  "post-id": 2027
}