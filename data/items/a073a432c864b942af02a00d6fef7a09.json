{
  "title": "On the Safety of Interpretable Machine Learning: A Maximum Deviation Approach. (arXiv:2211.01498v1 [cs.LG])",
  "link": "http://arxiv.org/abs/2211.01498",
  "description": "<p>Interpretable and explainable machine learning has seen a recent surge of\ninterest. We focus on safety as a key motivation behind the surge and make the\nrelationship between interpretability and safety more quantitative. Toward\nassessing safety, we introduce the concept of maximum deviation via an\noptimization problem to find the largest deviation of a supervised learning\nmodel from a reference model regarded as safe. We then show how\ninterpretability facilitates this safety assessment. For models including\ndecision trees, generalized linear and additive models, the maximum deviation\ncan be computed exactly and efficiently. For tree ensembles, which are not\nregarded as interpretable, discrete optimization techniques can still provide\ninformative bounds. For a broader class of piecewise Lipschitz functions, we\nleverage the multi-armed bandit literature to show that interpretability\nproduces tighter (regret) bounds on the maximum deviation. We present case\nstudies, including one on mortgage approval, to illustrate our methods and the\ninsights about models that may be obtained from deviation maximization.\n</p>",
  "dc:creator": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_D/0/1/0/all/0/1\">Dennis Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nair_R/0/1/0/all/0/1\">Rahul Nair</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dhurandhar_A/0/1/0/all/0/1\">Amit Dhurandhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Varshney_K/0/1/0/all/0/1\">Kush R. Varshney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Daly_E/0/1/0/all/0/1\">Elizabeth M. Daly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_M/0/1/0/all/0/1\">Moninder Singh</a>"
}