{
  "title": "Pivoting",
  "link": "",
  "updated": "2015-01-30T17:03:00+01:00",
  "published": "2015-01-30T17:03:00+01:00",
  "author": {
    "name": "Mikio L. Braun",
    "uri": "http://mikiobraun.de",
    "email": "mikiobraun@gmail.com"
  },
  "id": "http://blog.mikiobraun.de/2015/01/pivoting",
  "content": "<p><p>To make a long story short, I’ve decided to scale back my involvement with the streamdrill company to a purely advisory role. The reasons for this are naturally very complex, but in the end, I wasn’t seeing the kind of traction or the prospect of traction necessary to keep going at the pace I was going, splitting time between family, the university jobs, which paid my bills, and doing the dev work and marketing for streamdrill.</p>\n\n<p>In fact I still believe the base technology is pretty compelling, so we’re going to open source the core, to allow me to continue to work on it. That’s something I had been wanting to do for some time, because in the Big Data community, having some part as open-source is necessary to get people to try this out. At streamdrill, we always had more of a focus on providing some directly usable end product, so this won’t hurt the company (which Leo is planning to continue.)</p>\n\n<p>So the big question (or maybe not) is what to do now. In fact, I already got plenty to do… .</p>\n\n<p>So I’m still at the TU Berlin, and let me whine about the situation here for one paragraph ;) It’s not ideal. I sort of have accepted for myself that my interests are just too applied for academia (one simply does not write software at my level anymore, people told me it’s suspicious and I should stop it). In terms of career I have moved up to a point where the work I’m expected to do is mostly teaching, advising students, and stuff like grant proposal and project management. And while I seem to do OK, this makes me deal with stuff I find extremely painful. On the plus side, it provides good job security and somewhat fair pay, but that will only get you so far, soulwise.</p>\n\n<p>And the workload is pretty high. I have to do about a professor level of teaching, and am currently supervising about 5 students writing their master thesis and something like two to three Ph.D. students.</p>\n\n<p>I’m sort of managing our side of the <a href=\"http://www.bbdc.berlin/\">Berlin Big Data Center</a> project. Luckily this project aligns well with my interests. It’s about bringing together machine learning people and people who build scalable distributed infrastructure. We’re closely related to the <a href=\"http://flink.apache.org/\">Apache Flink</a> project, which is also really picking up lately. There’s lots of mutual interest, so I’m definitely looking forward to that.</p>\n\n<p>There is also another project which is potentially coming up, so my current workload is two projects, half a dozen students, and about 20 or so students to supervise in four teaching courses.</p>\n\n<p>I’ve recently started to join the <a href=\"http://www.infoq.com/author/Mikio-Braun\">InfoQ editorial board</a> and try to cover about one Big Data related news item per week. And I’m again taking part in the 3rd batch of the <a href=\"http://datascienceretreat.com/\">Data Science Retreat</a> starting in February.</p>\n\n<p>And there’s still more stuff I’m interested in:</p>\n\n<ul>\n  <li><em><a href=\"http://jblas.org\">jblas</a> needs some love.</em> My last serious updates are two years old, but with all that JVM based data analysis happening, jblas usage has picked up recently. I have some ideas to unclutter the code, make the whole build process more manageable, and maybe look into some new ideas to make use of native code also in cases where copying would be prohibitive, maybe by using caches or explicit memory handling.</li>\n  <li><em>open source streamdrill</em>, of course. Use of probabilistic data structures are picking up recently, and I always thought that it’s time to take it to the next level and write analysis algorithms which naturally use these structures as building blocks.</li>\n  <li>There’s a lot of talk about data science / Big Data convergence, but based on the people who are doing Ph.D.s in machine learning at TU Berlin, the existing technology is still much too unwieldy to use. Ever tried setting up Hadoop from the sources? I simply cannot see that someone who is used to Python would want to do that. Spark, for example, is investing a lot in that area, but their <a href=\"http://blog.mikiobraun.de/2013/09/designing-machine-learning-frameworks.html\">machine learning efforts are still very rough and somewhat premature</a>.</li>\n  <li>Likewise, there is a lot of training under way to get more Data Scientists, but I think that the way data analysis is taught at universities is a very bad guideline, because that’s really trying to teach people to become researchers and create new data analysis methods, not use them reasonably. I think similar to the division between people who build tools and those who use tools to do something valuable with it, there needs to be a separation of training programs. And for that existing tools need to mature more. <a href=\"http://scikit-learn.org/\">Scikit-learn</a>, for example, is an awesome collection of many, many methods, but it has very little in terms of high-level stuff to support the process of data analysis.</li>\n  <li><em><a href=\"http://www.infoq.com/news/2014/12/ipython-notebooks\">Notebooks is the new excel</a>.</em> I’m seeing a lot of use of IPython style notebooks lately to get to a more “literal” style of data analysis to get data analysis and business people to collaborate. Also the integration of code, plots, and results is really nice.</li>\n  <li><em>Moving out of out-of-core-learning.</em> After working with streaming for so long, the classical Python/R way of doing data analysis feels so weird. Why do I have to load all that data into memory? I understand that learning methods are so complex and data access patterns so random that this is the only way, but it now feels like a big restriction that your data set needs to fit into memory. Machine learning should be more like UNIX where stuff is file based and 10k C programs can work with gigabytes of data with 32MB of RAM if they need to (ok, I’m thinking of how it was back in 1994, but you get my point). And I’m not simply talking about <a href=\"http://datascienceatthecommandline.com/\">data science on the command line</a>, we probably need new algorithms for that, too.</li>\n</ul>\n\n<p>And then there are even other odds and bits. I mean why is everything so complex nowadays? Just frameworks wrapping frameworks. CSS frameworks? I mean, c’mon! What about things which did one thing well and weren’t a pain to set up?</p>\n\n<p>I want to keep attending more non-academic meetings. I’ll try to go to QCon London for at least one day, and I’ll be also speaking at Strata in London in May.</p>\n\n<p>Still, the whole situation is hardly ideal. Maybe it’s asking too much of a job to have perfect alignment between interests and job related activities, but I think there’s room for improvement. Stay tuned.</p>\n\n</p>\n   <p><a href=\"http://blog.mikiobraun.de/2015/01/pivoting.html\">Click here for the full article</a>"
}