{
  "title": "linselect demo: a tech sector stock analysis",
  "link": "",
  "published": "2018-05-31T14:17:00-07:00",
  "updated": "2018-05-31T14:17:00-07:00",
  "author": {
    "name": "Jonathan Landy"
  },
  "id": "tag:efavdb.com,2018-05-31:/linselect-demo",
  "summary": "<p>This is a tutorial post relating to our python feature selection package, <code>linselect</code>. The package allows one to easily identify minimal, informative feature subsets within a given data&nbsp;set.</p>\n<p>Here, we demonstrate <code>linselect</code><span class=\"quo\">&#8216;</span>s basic <span class=\"caps\">API</span> by exploring the relationship between the daily percentage lifts of 50 tech stocks over …</p>",
  "content": "<p>This is a tutorial post relating to our python feature selection package, <code>linselect</code>. The package allows one to easily identify minimal, informative feature subsets within a given data&nbsp;set.</p>\n<p>Here, we demonstrate <code>linselect</code><span class=\"quo\">&#8216;</span>s basic <span class=\"caps\">API</span> by exploring the relationship between the daily percentage lifts of 50 tech stocks over one trading year. We will be interested in identifying minimal stock subsets that can be used to predict the lifts of the&nbsp;others.</p>\n<p>This is a demonstration walkthrough, with commentary and interpretation throughout. See the package docs folder for docstrings that succinctly detail the <span class=\"caps\">API</span>.</p>\n<p>Contents:</p>\n<ul>\n<li>Load the data and examine some stock&nbsp;traces</li>\n<li>FwdSelect, RevSelect; supervised, single&nbsp;target</li>\n<li>FwdSelect, RevSelect; supervised, multiple&nbsp;targets</li>\n<li>FwdSelect, RevSelect;&nbsp;unsupervised</li>\n<li>GenSelect</li>\n</ul>\n<p>The data and a Jupyter notebook containing the code for this demo are available on our github, <a href=\"https://github.com/EFavDB/linselect_demos\">here</a>.</p>\n<p>The <code>linselect</code> package can be found on our github, <a href=\"https://github.com/efavdb/linselect\">here</a>.</p>\n<h2>1 - Load the data and examine some stock&nbsp;traces</h2>\n<p>In this tutorial, we will explore using <code>linselect</code> to carry out various feature selection tasks on a prepared data set of daily percentage lifts for 50 of the largest tech stocks. This covers data from 2017-04-18 to 2018-04-13. In this section, we load the data and take a look at a couple of the stock traces that we will be&nbsp;studying.</p>\n<h3>Load&nbsp;data</h3>\n<p>The code snippet below loads the data and shows a small&nbsp;sample.</p>\n<div class=\"highlight\"><pre><span></span><span class=\"c1\"># load packages  </span>\n<span class=\"kn\">from</span> <span class=\"nn\">linselect</span> <span class=\"kn\">import</span> <span class=\"n\">FwdSelect</span><span class=\"p\">,</span> <span class=\"n\">RevSelect</span><span class=\"p\">,</span> <span class=\"n\">GenSelect</span>  \n<span class=\"kn\">import</span> <span class=\"nn\">matplotlib.pyplot</span> <span class=\"k\">as</span> <span class=\"nn\">plt</span>  \n<span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>  \n<span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n\n<span class=\"c1\"># load the data, print out a sample  </span>\n<span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">read_csv</span><span class=\"p\">(</span><span class=\"s1\">&#39;stocks.csv&#39;</span><span class=\"p\">)</span>  \n<span class=\"nb\">print</span> <span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">iloc</span><span class=\"p\">[:</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"p\">:</span><span class=\"mi\">5</span><span class=\"p\">]</span>  \n<span class=\"nb\">print</span> <span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">shape</span>\n\n<span class=\"c1\"># date AAPL ADBE ADP ADSK  </span>\n<span class=\"c1\"># 0 2017-04-18 -0.004442 -0.001385 0.000687 0.004884  </span>\n<span class=\"c1\"># 1 2017-04-19 -0.003683 0.003158 0.001374 0.017591  </span>\n<span class=\"c1\"># 2 2017-04-20 0.012511 0.009215 0.009503 0.005459  </span>\n<span class=\"c1\"># (248, 51)  </span>\n</pre></div>\n\n\n<p>The last line here shows that there were 248 trading days in the range&nbsp;considered.</p>\n<h3>Plot some stock&nbsp;traces</h3>\n<p>The plot below shows Apple&#8217;s and Google&#8217;s daily lifts on top of each other, over our full date range (the code for the plot can be found in our notebook). Visually, it&#8217;s clear that the two are highly correlated &#8212; when one goes up or down, the other tends to as well. This suggests that it should be possible to get a good fit to any one of the stocks using the changes in each of the other&nbsp;stocks.</p>\n<p><a href=\"https://efavdb.com/wp-content/uploads/2018/05/apple_google.jpg\"><img alt=\"apple_google\" src=\"https://efavdb.com/wp-content/uploads/2018/05/apple_google.jpg\"></a></p>\n<p>In general, a stock&#8217;s daily price change should be a function of the market at large, the behavior of its market segment(s) and sub-segment(s), and some idiosyncratic behavior special to the company in question. Given this intuition, it seems reasonable to expect one to be able to fit a given stock given the lifts from just a small subset of the other stocks &#8212; stocks representative of the sectors relevant to the stock in question. Adding multiple stocks from each segment shouldn&#8217;t provide much additional value since these should be redundant. We&#8217;ll confirm this intuition below and use <code>linselect</code> to identify these optimal&nbsp;subsets.</p>\n<p><strong>Lesson</strong>: The fluctuations of related stocks are often highly correlated. Below, we will be using <code>linselect</code> to find minimal subsets of the 50 stocks that we can use to develop good linear fits to one, multiple, or all of the&nbsp;others.</p>\n<h2>2 - FwdSelect and RevSelect; supervised, single&nbsp;target</h2>\n<p>Goal: Demonstrate how to identify subsets of the stocks that can be used to fit a given target stock&nbsp;well.</p>\n<ul>\n<li>First we carry out a <code>FwdSelect</code> fit to identify good&nbsp;choices.</li>\n<li>Next, we compare the <code>FwdSelect</code> and <code>RevSelect</code> results</li>\n</ul>\n<h3>Forward selection applied to <span class=\"caps\">AAPL</span></h3>\n<p>The code snippet below uses our forward selection class, <code>FwdSelect</code> to seek the best feature subsets to fit <span class=\"caps\">AAPL</span>&#8217;s&nbsp;performance.</p>\n<div class=\"highlight\"><pre><span></span><span class=\"c1\"># Define X, y variables  </span>\n<span class=\"k\">def</span> <span class=\"nf\">get_feature_tickers</span><span class=\"p\">(</span><span class=\"n\">targets</span><span class=\"p\">):</span>  \n    <span class=\"n\">all_tickers</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">iloc</span><span class=\"p\">[:,</span> <span class=\"mi\">1</span><span class=\"p\">:]</span><span class=\"o\">.</span><span class=\"n\">columns</span>  \n    <span class=\"k\">return</span> <span class=\"nb\">list</span><span class=\"p\">(</span><span class=\"n\">c</span> <span class=\"k\">for</span> <span class=\"n\">c</span> <span class=\"ow\">in</span> <span class=\"n\">all_tickers</span> <span class=\"k\">if</span> <span class=\"n\">c</span> <span class=\"ow\">not</span> <span class=\"ow\">in</span> <span class=\"n\">targets</span><span class=\"p\">)</span>\n\n<span class=\"n\">TARGET_TICKERS</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">&#39;AAPL&#39;</span><span class=\"p\">]</span>  \n<span class=\"n\">FEATURE_TICKERS</span> <span class=\"o\">=</span> <span class=\"n\">get_feature_tickers</span><span class=\"p\">(</span><span class=\"n\">TARGET_TICKERS</span><span class=\"p\">)</span>\n\n<span class=\"n\">X</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"n\">FEATURE_TICKERS</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">values</span>  \n<span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"n\">TARGET_TICKERS</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">values</span>\n\n<span class=\"c1\"># Forward step-wise selection  </span>\n<span class=\"n\">selector</span> <span class=\"o\">=</span> <span class=\"n\">FwdSelect</span><span class=\"p\">()</span>  \n<span class=\"n\">selector</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Print out main results of selection process (ordered feature indices, CODs)  </span>\n<span class=\"nb\">print</span> <span class=\"n\">selector</span><span class=\"o\">.</span><span class=\"n\">ordered_features</span><span class=\"p\">[:</span><span class=\"mi\">3</span><span class=\"p\">]</span>  \n<span class=\"nb\">print</span> <span class=\"n\">selector</span><span class=\"o\">.</span><span class=\"n\">ordered_cods</span><span class=\"p\">[:</span><span class=\"mi\">3</span><span class=\"p\">]</span>\n\n<span class=\"c1\"># [25, 7, 41]  </span>\n<span class=\"c1\"># [0.43813848, 0.54534304, 0.58577418]  </span>\n</pre></div>\n\n\n<p>The last two lines above print out the main outputs of <code>FwdSelect</code>:</p>\n<ul>\n<li>The <code>ordered_features</code> list provides the indices of the features, ranked by the algorithm. The first index shown provides the best possible single feature fit to <span class=\"caps\">AAPL</span>, the second index provides the next best addition, etc. Note that we can get the tickers corresponding to these indices using:<br>\n<code>python  \n    print [FEATURE_TICKERS[i] for i in selector.ordered_features[:3]]  \n    # ['MSFT' 'AVGO' 'TSM']</code><br>\n    A little thought plus a Google search rationalizes why these might be the top three predictors for <span class=\"caps\">AAPL</span>: First, Microsoft is probably a good representative of the large-scale tech sector, and second the latter two companies work closely with Apple. <span class=\"caps\">AVGO</span> (Qualcomm) made Apple&#8217;s modem chips until very recently, while <span class=\"caps\">TSM</span> (Taiwan semi-conductor) makes the processors for iphones and ipads &#8212; and may perhaps soon also provide the CPUs for all Apple computers. Apparently, we can predict <span class=\"caps\">APPL</span> performance using only a combination of (a) a read on the tech sector at large, plus (b) a bit of idiosyncratic information also present in <span class=\"caps\">APPL</span>&#8217;s partner&nbsp;stocks.</li>\n<li>The <code>ordered_cods</code> list records the coefficient of determination (<span class=\"caps\">COD</span> or R^2) of the fits in question &#8212; the first number gives the <span class=\"caps\">COD</span> obtained with just <span class=\"caps\">MSFT</span>, the second with <span class=\"caps\">MSFT</span> and <span class=\"caps\">AVGO</span>,&nbsp;etc.</li>\n</ul>\n<p>A plot of the values in <code>ordered_cods</code> versus feature count is given below. Here, we have labeled the x-axis with the tickers corresponding to the elements of our <code>selector.ordered_features</code>. We see that the top three features almost fit <span class=\"caps\">AAPL</span>&#8217;s performance as well as the full&nbsp;set!</p>\n<p><a href=\"https://efavdb.com/wp-content/uploads/2018/05/apple.png\"><img alt=\"apple\" src=\"https://efavdb.com/wp-content/uploads/2018/05/apple.png\"></a></p>\n<p><strong>Lesson</strong>: We can often use <code>linselect</code> to significantly reduce the dimension of a given feature set, with minimal cost in performance. This can be used to compress a data set and can also improve our understanding of the problem&nbsp;considered.</p>\n<p><strong>Lesson</strong>: To get a feel for the effective number of useful features we have at hand, we can plot the output <code>ordered_cods</code> versus feature&nbsp;count.</p>\n<h3>Compare forward and reverse selection applied to <span class=\"caps\">TSLA</span></h3>\n<p>The code snippet below applies both <code>FwdSelect</code> and <code>RevSelect</code> to seek minimal subsets that fit Tesla&#8217;s daily lifts well. The outputs are plotted below this. This shows that <code>FwdSelect</code> performs slightly better when two or fewer features are included here, but that <code>RevSelect</code> finds better subsets after&nbsp;that.</p>\n<p><strong>Lesson</strong>: In general, we expect forward selection to work better when looking for small subsets and reverse selection to perform better at large&nbsp;subsets.</p>\n<div class=\"highlight\"><pre><span></span><span class=\"c1\"># Define X, y variables  </span>\n<span class=\"n\">TARGET_TICKERS</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">&#39;TSLA&#39;</span><span class=\"p\">]</span>  \n<span class=\"n\">FEATURE_TICKERS</span> <span class=\"o\">=</span> <span class=\"n\">get_feature_tickers</span><span class=\"p\">(</span><span class=\"n\">TARGET_TICKERS</span><span class=\"p\">)</span>\n\n<span class=\"n\">X</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"n\">FEATURE_TICKERS</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">values</span>  \n<span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"n\">TARGET_TICKERS</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">values</span>\n\n<span class=\"c1\"># Forward step-wise selection  </span>\n<span class=\"n\">selector</span> <span class=\"o\">=</span> <span class=\"n\">FwdSelect</span><span class=\"p\">()</span>  \n<span class=\"n\">selector</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Reverse step-wise selection  </span>\n<span class=\"n\">selector2</span> <span class=\"o\">=</span> <span class=\"n\">RevSelect</span><span class=\"p\">()</span>  \n<span class=\"n\">selector2</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">)</span>  \n</pre></div>\n\n\n<p><a href=\"https://efavdb.com/wp-content/uploads/2018/05/rev2.jpg\"><img alt=\"rev2\" src=\"https://efavdb.com/wp-content/uploads/2018/05/rev2.jpg\"></a></p>\n<h2>3 - FwdSelect and RevSelect; supervised, multiple&nbsp;targets</h2>\n<p>In the code below, we seek feature subsets that perform well when fitting multiple targets&nbsp;simultaneously.</p>\n<p><strong>Lesson</strong>: <code>linselect</code> can be used to find minimal feature subsets useful for fitting multiple targets. The optimal, &#8220;perfect score&#8221; <span class=\"caps\">COD</span> in this case is equal to number of targets (three in our&nbsp;example).</p>\n<div class=\"highlight\"><pre><span></span><span class=\"c1\"># Define X, y variables  </span>\n<span class=\"n\">TARGET_TICKERS</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">&#39;TSLA&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;ADP&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;NFLX&#39;</span><span class=\"p\">]</span>  \n<span class=\"n\">FEATURE_TICKERS</span> <span class=\"o\">=</span> <span class=\"n\">get_feature_tickers</span><span class=\"p\">(</span><span class=\"n\">TARGET_TICKERS</span><span class=\"p\">)</span>\n\n<span class=\"n\">X</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"n\">FEATURE_TICKERS</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">values</span>  \n<span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"n\">TARGET_TICKERS</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">values</span>\n\n<span class=\"c1\"># Forward step-wise selection  </span>\n<span class=\"n\">selector</span> <span class=\"o\">=</span> <span class=\"n\">FwdSelect</span><span class=\"p\">()</span>  \n<span class=\"n\">selector</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Reverse step-wise selection  </span>\n<span class=\"n\">selector2</span> <span class=\"o\">=</span> <span class=\"n\">RevSelect</span><span class=\"p\">()</span>  \n<span class=\"n\">selector2</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">)</span>  \n</pre></div>\n\n\n<p><a href=\"https://efavdb.com/wp-content/uploads/2018/05/multiple.jpg\"><img alt=\"multiple\" src=\"https://efavdb.com/wp-content/uploads/2018/05/multiple.jpg\"></a></p>\n<h2>4 - FwdSelect and RevSelect;&nbsp;unsupervised</h2>\n<p>Here, we seek those features that give us a best fit to / linear representation of the whole set. This goal is analogous to that addressed by <span class=\"caps\">PCA</span>, but is a feature selection variant: Whereas <span class=\"caps\">PCA</span> returns a set of linear combinations of the original features, the approach here will return a subset of the original features. This has the benefit of leaving one with a feature subset that is&nbsp;interpretable.</p>\n<p>(Note: See [1] for more examples like this. There, I show that if you try to fit smoothed versions of the stock performances, very good, small subsets can be found. Without smoothing, noise obscures this&nbsp;point).</p>\n<p><strong>Lesson</strong>: Unsupervised selection seeks to find those features that best describe the full data set &#8212; a feature selection analog of <span class=\"caps\">PCA</span>.</p>\n<p><strong>Lesson</strong>: Again, a perfect <span class=\"caps\">COD</span> score is equal to the number of targets. In the unsupervised case, this is also the number of features (50 in our&nbsp;example).</p>\n<div class=\"highlight\"><pre><span></span><span class=\"c1\"># Set X equal to full data set.  </span>\n<span class=\"n\">ALL_TICKERS</span> <span class=\"o\">=</span> <span class=\"nb\">list</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">iloc</span><span class=\"p\">[:,</span> <span class=\"mi\">1</span><span class=\"p\">:]</span><span class=\"o\">.</span><span class=\"n\">columns</span><span class=\"p\">)</span>  \n<span class=\"n\">X</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"n\">ALL_TICKERS</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">values</span>\n\n<span class=\"c1\"># Stepwise regressions  </span>\n<span class=\"n\">selector</span> <span class=\"o\">=</span> <span class=\"n\">FwdSelect</span><span class=\"p\">()</span>  \n<span class=\"n\">selector</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">)</span>\n\n<span class=\"n\">selector2</span> <span class=\"o\">=</span> <span class=\"n\">RevSelect</span><span class=\"p\">()</span>  \n<span class=\"n\">selector2</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">)</span>  \n</pre></div>\n\n\n<p><a href=\"https://efavdb.com/wp-content/uploads/2018/05/unsupervised.jpg\"><img alt=\"unsupervised\" src=\"https://efavdb.com/wp-content/uploads/2018/05/unsupervised.jpg\"></a></p>\n<h2>5 -&nbsp;GenSelect</h2>\n<p><code>GenSelect</code><span class=\"quo\">&#8216;</span>s <span class=\"caps\">API</span> is designed to expose the full flexibility of the efficient linear stepwise algorithm. Because of this, its <span class=\"caps\">API</span> is somewhat more complex than that of <code>FwdSelect</code> and <code>RevSelect</code>. Here, our aim is to quickly demo this <span class=\"caps\">API</span>.</p>\n<p>The Essential&nbsp;ingredients:</p>\n<ul>\n<li>We pass only a single data matrix <code>X</code>, and must specify which columns are the predictors and which are&nbsp;targets.</li>\n<li>Because we might sweep up and down, we cannot define an <code>ordered_features</code> list as in <code>FwdSelect</code> and <code>RevSelect</code> (the best subset of size three now may not contain the features in the best subset of size two). Instead, <code>GenSelect</code> maintains a dictionary <code>best_results</code> that stores information on the best results seen so far for each possible feature count. The keys of this dictionary correspond to the possible feature set sizes. The values are also dictionaries, each having two keys: <code>s</code> and <code>cod</code>. These specify the best feature subset seen so far with size equal to the outer key, and the corresponding <span class=\"caps\">COD</span>,&nbsp;respectively.</li>\n<li>We can move back and forth, adding features to or removing them from the predictor set. We can specify the search protocol for doing&nbsp;this.</li>\n<li>We can reposition our search to any predictor set location and continue the search from&nbsp;there.</li>\n<li>We can access the costs of each possible move from our current location, without&nbsp;stepping.</li>\n</ul>\n<p>If an <span class=\"math\">\\(m \\times n\\)</span> data matrix <code>X</code> is passed to <code>GenSelect</code>, three Boolean arrays define the state of the&nbsp;search.</p>\n<ul>\n<li><code>s</code> &#8212; This array specifies which of the columns are currently being used as&nbsp;predictors.</li>\n<li><code>targets</code> &#8212; This specifies which of the columns are the target&nbsp;variables.</li>\n<li><code>mobile</code> &#8212; This specifies which of the columns are locked into or out of our fit &#8212; those that are not mobile are marked <code>False</code>.</li>\n</ul>\n<p>Note: We usually want the targets to not be mobile &#8212; though this is not the case in unsupervised applications. One might sometimes also want to lock certain features into the predictor set, and the <code>mobile</code> parameter can be used to accomplish&nbsp;this.</p>\n<h3>Use GenSelect to carry out a forward sweep for <span class=\"caps\">TSLA</span></h3>\n<p>The code below carries out a single forward sweep for <span class=\"caps\">TSLA</span>. Note that the <code>protocol</code> argument of <code>search</code> is set to <code>(1, 0)</code>, which gives a forward search (see docstrings). For this reason, our results match those of <code>FwdSelect</code> at this&nbsp;point.</p>\n<p><strong>Lesson</strong>: Setting up a basic <code>GenSelect</code> call requires defining a few input&nbsp;parameters.</p>\n<div class=\"highlight\"><pre><span></span><span class=\"c1\"># Define X  </span>\n<span class=\"n\">X</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"n\">ALL_TICKERS</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">values</span>\n\n<span class=\"c1\"># Define targets and mobile Boolean arrays  </span>\n<span class=\"n\">TARGET_TICKERS</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">&#39;TSLA&#39;</span><span class=\"p\">]</span>  \n<span class=\"n\">FEATURE_TICKERS</span> <span class=\"o\">=</span> <span class=\"n\">get_feature_tickers</span><span class=\"p\">(</span><span class=\"n\">TARGET_TICKERS</span><span class=\"p\">)</span>  \n<span class=\"n\">targets</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">in1d</span><span class=\"p\">(</span><span class=\"n\">ALL_TICKERS</span><span class=\"p\">,</span> <span class=\"n\">TARGET_TICKERS</span><span class=\"p\">)</span>  \n<span class=\"n\">mobile</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">in1d</span><span class=\"p\">(</span><span class=\"n\">ALL_TICKERS</span><span class=\"p\">,</span> <span class=\"n\">FEATURE_TICKERS</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Set up search with an initial \\`position\\`. Then search.  </span>\n<span class=\"n\">selector</span> <span class=\"o\">=</span> <span class=\"n\">GenSelect</span><span class=\"p\">()</span>  \n<span class=\"n\">selector</span><span class=\"o\">.</span><span class=\"n\">position</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">mobile</span><span class=\"o\">=</span><span class=\"n\">mobile</span><span class=\"p\">,</span> <span class=\"n\">targets</span><span class=\"o\">=</span><span class=\"n\">targets</span><span class=\"p\">)</span>  \n<span class=\"n\">selector</span><span class=\"o\">.</span><span class=\"n\">search</span><span class=\"p\">(</span><span class=\"n\">protocol</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">),</span> <span class=\"n\">steps</span><span class=\"o\">=</span><span class=\"n\">X</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">])</span>\n\n<span class=\"c1\"># Review best 3 feature set found  </span>\n<span class=\"nb\">print</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">(</span><span class=\"n\">ALL_TICKERS</span><span class=\"p\">)[</span><span class=\"n\">selector</span><span class=\"o\">.</span><span class=\"n\">best_results</span><span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">][</span><span class=\"s1\">&#39;s&#39;</span><span class=\"p\">]],</span> <span class=\"n\">selector</span><span class=\"o\">.</span><span class=\"n\">best_results</span><span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">][</span><span class=\"s1\">&#39;cod&#39;</span><span class=\"p\">]</span>\n\n<span class=\"c1\"># [&#39;ATVI&#39; &#39;AVGO&#39; &#39;CTSH&#39;] 0.225758  </span>\n</pre></div>\n\n\n<h3>Continue the search&nbsp;above</h3>\n<p>A <code>GenSelect</code> instance always retains a summary of the best results it has seen so far. This means that we can continue a search where we left off after a <code>search</code> call completes. Below, we reposition our search and sweep back and forth to better explore a particular region. Note that this slightly improves our&nbsp;result.</p>\n<p><strong>Lesson</strong>: We can carry out general search protocols using <code>GenSelect</code><span class=\"quo\">&#8216;</span>s <code>position</code> and <code>search</code> methods.</p>\n<div class=\"highlight\"><pre><span></span><span class=\"c1\"># Reposition back to the best fit of size 3 seen above.  </span>\n<span class=\"n\">s</span> <span class=\"o\">=</span> <span class=\"n\">selector</span><span class=\"o\">.</span><span class=\"n\">best_results</span><span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">][</span><span class=\"s1\">&#39;s&#39;</span><span class=\"p\">]</span>  \n<span class=\"n\">selector</span><span class=\"o\">.</span><span class=\"n\">position</span><span class=\"p\">(</span><span class=\"n\">s</span><span class=\"o\">=</span><span class=\"n\">s</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Now sweep back and forth around there a few times.  </span>\n<span class=\"n\">STEPS</span> <span class=\"o\">=</span> <span class=\"mi\">10</span>  \n<span class=\"n\">SWEEPS</span> <span class=\"o\">=</span> <span class=\"mi\">3</span>\n\n<span class=\"n\">selector</span><span class=\"o\">.</span><span class=\"n\">search</span><span class=\"p\">(</span><span class=\"n\">protocol</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">),</span> <span class=\"n\">steps</span><span class=\"o\">=</span><span class=\"n\">STEPS</span><span class=\"p\">)</span>  \n<span class=\"n\">selector</span><span class=\"o\">.</span><span class=\"n\">search</span><span class=\"p\">(</span><span class=\"n\">protocol</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">2</span> <span class=\"o\">*</span> <span class=\"n\">STEPS</span><span class=\"p\">,</span> <span class=\"mi\">2</span> <span class=\"o\">*</span> <span class=\"n\">STEPS</span><span class=\"p\">),</span> <span class=\"n\">steps</span><span class=\"o\">=</span><span class=\"n\">SWEEPS</span> <span class=\"o\">*</span> <span class=\"mi\">4</span> <span class=\"o\">*</span> <span class=\"n\">STEPS</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Review best results found now with exactly N_RETAINED features (different from first pass in cell above?)  </span>\n<span class=\"nb\">print</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">(</span><span class=\"n\">ALL_TICKERS</span><span class=\"p\">)[</span><span class=\"n\">selector</span><span class=\"o\">.</span><span class=\"n\">best_results</span><span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">][</span><span class=\"s1\">&#39;s&#39;</span><span class=\"p\">]],</span> <span class=\"n\">selector</span><span class=\"o\">.</span><span class=\"n\">best_results</span><span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">][</span><span class=\"s1\">&#39;cod&#39;</span><span class=\"p\">]</span>\n\n<span class=\"c1\"># [&#39;AMZN&#39; &#39;NVDA&#39; &#39;ZNGA&#39;] 0.229958  </span>\n</pre></div>\n\n\n<h3>Compare to forward and reverse search&nbsp;results</h3>\n<p>Below, we compare the <span class=\"caps\">COD</span> values of our three&nbsp;classes.</p>\n<p><strong>Lesson</strong>: <code>GenSelect</code> can be used to do a more thorough search than <code>FwdSelect</code> and <code>RevSelect</code>, and so can sometimes find better feature&nbsp;subsets.</p>\n<div class=\"highlight\"><pre><span></span><span class=\"c1\"># Get the best COD values seen for each feature set size from GenSelect search  </span>\n<span class=\"n\">gen_select_cods</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>  \n<span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">X</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]):</span>  \n    <span class=\"k\">if</span> <span class=\"n\">i</span> <span class=\"ow\">not</span> <span class=\"ow\">in</span> <span class=\"n\">selector</span><span class=\"o\">.</span><span class=\"n\">best_results</span><span class=\"p\">:</span>  \n        <span class=\"k\">break</span>  \n    <span class=\"n\">gen_select_cods</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">selector</span><span class=\"o\">.</span><span class=\"n\">best_results</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">][</span><span class=\"s1\">&#39;cod&#39;</span><span class=\"p\">])</span>\n\n<span class=\"c1\"># Plot cod versus feature set size.  </span>\n<span class=\"n\">fig</span><span class=\"p\">,</span> <span class=\"n\">ax</span> <span class=\"o\">=</span> <span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">subplots</span><span class=\"p\">(</span><span class=\"n\">figsize</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">,</span><span class=\"mi\">5</span><span class=\"p\">))</span>  \n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">gen_select_cods</span><span class=\"p\">,</span> <span class=\"n\">label</span><span class=\"o\">=</span><span class=\"s1\">&#39;GenSelect&#39;</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># FwdSelect again to get corresponding results.  </span>\n<span class=\"n\">selector2</span> <span class=\"o\">=</span> <span class=\"n\">FwdSelect</span><span class=\"p\">()</span>  \n<span class=\"n\">selector2</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">[:,</span> <span class=\"n\">mobile</span><span class=\"p\">],</span> <span class=\"n\">X</span><span class=\"p\">[:,</span> <span class=\"n\">targets</span><span class=\"p\">])</span>  \n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">selector2</span><span class=\"o\">.</span><span class=\"n\">ordered_cods</span><span class=\"p\">,</span><span class=\"s1\">&#39;--&#39;</span><span class=\"p\">,</span> <span class=\"n\">label</span><span class=\"o\">=</span><span class=\"s1\">&#39;FwdSelect&#39;</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># RevSelect again to get corresponding results.  </span>\n<span class=\"n\">selector3</span> <span class=\"o\">=</span> <span class=\"n\">RevSelect</span><span class=\"p\">()</span>  \n<span class=\"n\">selector3</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">[:,</span> <span class=\"n\">mobile</span><span class=\"p\">],</span> <span class=\"n\">X</span><span class=\"p\">[:,</span> <span class=\"n\">targets</span><span class=\"p\">])</span>  \n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">selector3</span><span class=\"o\">.</span><span class=\"n\">ordered_cods</span><span class=\"p\">,</span> <span class=\"s1\">&#39;-.&#39;</span><span class=\"p\">,</span><span class=\"n\">label</span><span class=\"o\">=</span><span class=\"s1\">&#39;RevSelect&#39;</span><span class=\"p\">)</span>  \n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">title</span><span class=\"p\">(</span><span class=\"s1\">&#39;Coefficient of Determination (COD or R^2) for </span><span class=\"si\">{target}</span><span class=\"s1\"> vs features retained&#39;</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span>  \n<span class=\"n\">target</span><span class=\"o\">=</span><span class=\"s1\">&#39;, &#39;</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">(</span><span class=\"n\">TARGET_TICKERS</span><span class=\"p\">)))</span>  \n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">legend</span><span class=\"p\">()</span>  \n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">show</span><span class=\"p\">()</span>  \n</pre></div>\n\n\n<p><a href=\"https://efavdb.com/wp-content/uploads/2018/05/comparison.jpg\"><img alt=\"comparison\" src=\"https://efavdb.com/wp-content/uploads/2018/05/comparison.jpg\"></a></p>\n<h3>Examine the cost of removing a feature from the predictor&nbsp;set</h3>\n<p>Below, we reposition to the best feature set of size 10 seen so far. We then apply the method <code>reverse_cods</code> to expose the cost of removing each of these individuals from the predictor set at this point. Were we to take a reverse step, the feature with the least cost would be the one taken (looks like <span class=\"caps\">FB</span> from the&nbsp;plot).</p>\n<p><strong>Lesson</strong>: We can easily access the costs associated with removing individual features from our current location. We can also access the <span class=\"caps\">COD</span> gains associated with adding in new features by calling the <code>forward_cods</code> method.</p>\n<div class=\"highlight\"><pre><span></span><span class=\"c1\"># Reposition  </span>\n<span class=\"n\">s</span> <span class=\"o\">=</span> <span class=\"n\">selector</span><span class=\"o\">.</span><span class=\"n\">best_results</span><span class=\"p\">[</span><span class=\"mi\">10</span><span class=\"p\">][</span><span class=\"s1\">&#39;s&#39;</span><span class=\"p\">]</span>  \n<span class=\"n\">selector</span><span class=\"o\">.</span><span class=\"n\">position</span><span class=\"p\">(</span><span class=\"n\">s</span><span class=\"o\">=</span><span class=\"n\">s</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Get costs to remove a feature (see also \\`forward_cods\\` method)  </span>\n<span class=\"n\">costs</span> <span class=\"o\">=</span> <span class=\"n\">selector</span><span class=\"o\">.</span><span class=\"n\">reverse_cods</span><span class=\"p\">()[</span><span class=\"n\">s</span><span class=\"p\">]</span>  \n<span class=\"n\">TICKERS</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">(</span><span class=\"n\">ALL_TICKERS</span><span class=\"p\">)[</span><span class=\"n\">selector</span><span class=\"o\">.</span><span class=\"n\">best_results</span><span class=\"p\">[</span><span class=\"mi\">10</span><span class=\"p\">][</span><span class=\"s1\">&#39;s&#39;</span><span class=\"p\">]]</span>\n\n<span class=\"c1\"># Plot costs to remove each feature given current position  </span>\n<span class=\"n\">fig</span><span class=\"p\">,</span> <span class=\"n\">ax</span> <span class=\"o\">=</span> <span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">subplots</span><span class=\"p\">(</span><span class=\"n\">figsize</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">,</span><span class=\"mi\">5</span><span class=\"p\">))</span>  \n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">costs</span><span class=\"p\">)</span>  \n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">xticks</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">arange</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">TICKERS</span><span class=\"p\">)),</span> <span class=\"n\">rotation</span><span class=\"o\">=</span><span class=\"mi\">90</span><span class=\"p\">)</span>  \n<span class=\"n\">ax</span><span class=\"o\">.</span><span class=\"n\">set_xticklabels</span><span class=\"p\">(</span><span class=\"n\">TICKERS</span><span class=\"p\">)</span>  \n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">show</span><span class=\"p\">()</span>  \n</pre></div>\n\n\n<p><a href=\"https://efavdb.com/wp-content/uploads/2018/05/cost.jpg\"><img alt=\"cost\" src=\"https://efavdb.com/wp-content/uploads/2018/05/cost.jpg\"></a></p>\n<h2>Final&nbsp;comments</h2>\n<p>In this tutorial, we&#8217;ve illustrated many of the basic <span class=\"caps\">API</span> calls available in <code>linselect</code>. In a future tutorial post, we plan to illustrate some interesting use cases of some of these <span class=\"caps\">API</span> calls &#8212; e.g., how to use <code>GenSelect</code><span class=\"quo\">&#8216;</span>s arguments to explore the value of supplemental features, added to an already existing data&nbsp;set.</p>\n<h2>References</h2>\n<p>[1] J. Landy. Stepwise regression for unsupervised learning, 2017. <a href=\"https://arxiv.org/abs/1706.03265\">arxiv.1706.03265</a>.</p>\n<script type=\"text/javascript\">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {\n    var align = \"center\",\n        indent = \"0em\",\n        linebreak = \"false\";\n\n    if (false) {\n        align = (screen.width < 768) ? \"left\" : align;\n        indent = (screen.width < 768) ? \"0em\" : indent;\n        linebreak = (screen.width < 768) ? 'true' : linebreak;\n    }\n\n    var mathjaxscript = document.createElement('script');\n    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';\n    mathjaxscript.type = 'text/javascript';\n    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';\n\n    var configscript = document.createElement('script');\n    configscript.type = 'text/x-mathjax-config';\n    configscript[(window.opera ? \"innerHTML\" : \"text\")] =\n        \"MathJax.Hub.Config({\" +\n        \"    config: ['MMLorHTML.js'],\" +\n        \"    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } },\" +\n        \"    jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" +\n        \"    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" +\n        \"    displayAlign: '\"+ align +\"',\" +\n        \"    displayIndent: '\"+ indent +\"',\" +\n        \"    showMathMenu: true,\" +\n        \"    messageStyle: 'normal',\" +\n        \"    tex2jax: { \" +\n        \"        inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" +\n        \"        displayMath: [ ['$$','$$'] ],\" +\n        \"        processEscapes: true,\" +\n        \"        preview: 'TeX',\" +\n        \"    }, \" +\n        \"    'HTML-CSS': { \" +\n        \"        availableFonts: ['STIX', 'TeX'],\" +\n        \"        preferredFont: 'STIX',\" +\n        \"        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" +\n        \"        linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" +\n        \"    }, \" +\n        \"}); \" +\n        \"if ('default' !== 'default') {\" +\n            \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" +\n                \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" +\n                \"VARIANT['normal'].fonts.unshift('MathJax_default');\" +\n                \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" +\n                \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" +\n                \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" +\n            \"});\" +\n            \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" +\n                \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" +\n                \"VARIANT['normal'].fonts.unshift('MathJax_default');\" +\n                \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" +\n                \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" +\n                \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" +\n            \"});\" +\n        \"}\";\n\n    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);\n    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);\n}\n</script>",
  "category": [
    "",
    ""
  ]
}