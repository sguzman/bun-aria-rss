{
  "title": "What We Talk About When We Talk About Algorithms",
  "itunes:title": "What We Talk About When We Talk About Algorithms",
  "pubDate": "Thu, 07 Jul 2022 09:00:16 GMT",
  "itunes:duration": "1:03:30",
  "enclosure": "",
  "guid": "62c5eb0dcc49bb0012e56485",
  "itunes:explicit": "no",
  "link": "https://shows.acast.com/lawfare/episodes/what-we-talk-about-when-we-talk-about-algorithms",
  "acast:episodeId": "62c5eb0dcc49bb0012e56485",
  "acast:episodeUrl": "what-we-talk-about-when-we-talk-about-algorithms",
  "acast:settings": "ozu8rXK33NzX6c6CybB5UCT97XEpG0AhrnPuboek4zvH35TCBe4yORgGiwGuiujkFWjsF9iEOTkFqp7hbiAIwpb3W7XY98wFoQ0JVxKxYsO10i2uJWVrXKC+7OKeJUwqX+5QL5s5ZIdGCu7fi3dmEqUbuaI3Xb9n6TUHDRDRLPJU8rODxqmdMmdQ/JhGdo9ZRuzeJvTW39mcXopQo2Ic9VghUuwe/pqbth6Sx6ISFjNlmKEUmz991qT6247yCds/sq8NgLxkw4D44xCNuCCB9eR4B3q+uDwxi5AU6dxUJ1Z6hJtS4kjkch9zQN5PFJd7wfgmoYZP0stjt+Mr2DLj8ao8udHIr57G0H8V4OzyW+597nKMa5Onf2lD4wfjNC0xpGWvy7MyxxBW9QzXrQkNT2PCxsqvIrlOHY+YGuCbo5Rgf+sMTvWjJxAqYDHLmDRp8ynknfs9NmvUbFqdPprSA/JmXCJrIpywd2pD4bMF8/w7gLnoU7PL93kWOVCAS5yMvEeZHVKT2I0W0LP1kQvljnPaux6UwSG03ErssBhrpDno5/96geOCTuVobe1PTOUQ/IN9R6UyoQ7JzQT5muKaHysfH6YnjuXiuJQWDwDmP6QtrId7Z2oXqiu2GtSKxrDjVT2Cj2d7D88eYT7r1GQmOPEHuJ0fL1ThCuXbOfkHoD9zxgO6GB9neDK59jKzjDBmYsgIkQ2Ds3hxkuaXQ6dJgXY+NPHHNFNV2LzJPa8riEs=",
  "itunes:episodeType": "full",
  "itunes:image": "",
  "description": "<p>Algorithms! We hear a lot about them. They drive social media platforms and, according to popular understanding, are responsible for a great deal of what’s wrong about the internet today—and maybe the downfall of democracy itself. But … what exactly are algorithms? And, given they’re not going away, what should they be designed to do?</p><br><p>Evelyn Douek and Quinta Jurecic spoke with Jonathan Stray, a senior scientist at the Berkeley Center for Human-Compatible AI and someone who has thought a <em>lot </em>about what we mean when we say the word “algorithm”—and also when we discuss things like “<a href=\"https://medium.com/understanding-recommenders/whats-right-and-what-s-wrong-with-optimizing-for-engagement-5abaac021851\" rel=\"noopener noreferrer\" target=\"_blank\">engagement</a>” and “<a href=\"https://techpolicy.press/what-will-amplification-mean-in-court/\" rel=\"noopener noreferrer\" target=\"_blank\">amplification</a>.” He helped them pin down a more precise understanding of what those terms mean and why that precision is so important in crafting good technology policy. They also talked about what role social media algorithms do and don’t play in stoking political polarization, and how they might be <a href=\"https://arxiv.org/abs/2107.04953\" rel=\"noopener noreferrer\" target=\"_blank\">designed</a> to decrease polarization instead.</p><p><br></p><ul><li>If you’re interested, you can read the <a href=\"https://www.commerce.senate.gov/services/files/62102355-DC26-4909-BF90-8FB068145F18\" rel=\"noopener noreferrer\" target=\"_blank\">Senate testimony</a> by Dean Eckles on algorithms that Jonathan mentions during the show.</li><li>We also mentioned&nbsp;<a href=\"https://www.wired.com/story/polarization-isnt-americas-biggest-problem-or-facebooks/\" rel=\"noopener noreferrer\" target=\"_blank\">this article</a>&nbsp;by Daniel Kreiss on polarization.</li></ul><p>Support this show <a target=\"_blank\" rel=\"payment\" href=\"http://supporter.acast.com/lawfare\">http://supporter.acast.com/lawfare</a>.</p><br /><hr><p style='color:grey; font-size:0.75em;'> Hosted on Acast. See <a style='color:grey;' target='_blank' rel='noopener noreferrer' href='https://acast.com/privacy'>acast.com/privacy</a> for more information.</p>",
  "itunes:summary": "<p>Algorithms! We hear a lot about them. They drive social media platforms and, according to popular understanding, are responsible for a great deal of what’s wrong about the internet today—and maybe the downfall of democracy itself. But … what exactly are algorithms? And, given they’re not going away, what should they be designed to do?</p><br><p>Evelyn Douek and Quinta Jurecic spoke with Jonathan Stray, a senior scientist at the Berkeley Center for Human-Compatible AI and someone who has thought a <em>lot </em>about what we mean when we say the word “algorithm”—and also when we discuss things like “<a href=\"https://medium.com/understanding-recommenders/whats-right-and-what-s-wrong-with-optimizing-for-engagement-5abaac021851\" rel=\"noopener noreferrer\" target=\"_blank\">engagement</a>” and “<a href=\"https://techpolicy.press/what-will-amplification-mean-in-court/\" rel=\"noopener noreferrer\" target=\"_blank\">amplification</a>.” He helped them pin down a more precise understanding of what those terms mean and why that precision is so important in crafting good technology policy. They also talked about what role social media algorithms do and don’t play in stoking political polarization, and how they might be <a href=\"https://arxiv.org/abs/2107.04953\" rel=\"noopener noreferrer\" target=\"_blank\">designed</a> to decrease polarization instead.</p><p><br></p><ul><li>If you’re interested, you can read the <a href=\"https://www.commerce.senate.gov/services/files/62102355-DC26-4909-BF90-8FB068145F18\" rel=\"noopener noreferrer\" target=\"_blank\">Senate testimony</a> by Dean Eckles on algorithms that Jonathan mentions during the show.</li><li>We also mentioned&nbsp;<a href=\"https://www.wired.com/story/polarization-isnt-americas-biggest-problem-or-facebooks/\" rel=\"noopener noreferrer\" target=\"_blank\">this article</a>&nbsp;by Daniel Kreiss on polarization.</li></ul><p>Support this show <a target=\"_blank\" rel=\"payment\" href=\"http://supporter.acast.com/lawfare\">http://supporter.acast.com/lawfare</a>.</p><br /><hr><p style='color:grey; font-size:0.75em;'> Hosted on Acast. See <a style='color:grey;' target='_blank' rel='noopener noreferrer' href='https://acast.com/privacy'>acast.com/privacy</a> for more information.</p>"
}