{
  "title": "Grounding Scene Graphs on Natural Images via Visio-Lingual Message Passing. (arXiv:2211.01969v1 [cs.CV])",
  "link": "http://arxiv.org/abs/2211.01969",
  "description": "<p>This paper presents a framework for jointly grounding objects that follow\ncertain semantic relationship constraints given in a scene graph. A typical\nnatural scene contains several objects, often exhibiting visual relationships\nof varied complexities between them. These inter-object relationships provide\nstrong contextual cues toward improving grounding performance compared to a\ntraditional object query-only-based localization task. A scene graph is an\nefficient and structured way to represent all the objects and their semantic\nrelationships in the image. In an attempt towards bridging these two modalities\nrepresenting scenes and utilizing contextual information for improving object\nlocalization, we rigorously study the problem of grounding scene graphs on\nnatural images. To this end, we propose a novel graph neural network-based\napproach referred to as Visio-Lingual Message PAssing Graph Neural Network\n(VL-MPAG Net). In VL-MPAG Net, we first construct a directed graph with object\nproposals as nodes and an edge between a pair of nodes representing a plausible\nrelation between them. Then a three-step inter-graph and intra-graph message\npassing is performed to learn the context-dependent representation of the\nproposals and query objects. These object representations are used to score the\nproposals to generate object localization. The proposed method significantly\noutperforms the baselines on four public datasets.\n</p>",
  "dc:creator": "<a href=\"http://arxiv.org/find/cs/1/au:+Tripathi_A/0/1/0/all/0/1\">Aditay Tripathi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_A/0/1/0/all/0/1\">Anand Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_A/0/1/0/all/0/1\">Anirban Chakraborty</a>"
}