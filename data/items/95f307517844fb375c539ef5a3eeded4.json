{
  "title": "TANGO: Text-driven Photorealistic and Robust 3D Stylization via Lighting Decomposition. (arXiv:2210.11277v2 [cs.CV] UPDATED)",
  "link": "http://arxiv.org/abs/2210.11277",
  "description": "<p>Creation of 3D content by stylization is a promising yet challenging problem\nin computer vision and graphics research. In this work, we focus on stylizing\nphotorealistic appearance renderings of a given surface mesh of arbitrary\ntopology. Motivated by the recent surge of cross-modal supervision of the\nContrastive Language-Image Pre-training (CLIP) model, we propose TANGO, which\ntransfers the appearance style of a given 3D shape according to a text prompt\nin a photorealistic manner. Technically, we propose to disentangle the\nappearance style as the spatially varying bidirectional reflectance\ndistribution function, the local geometric variation, and the lighting\ncondition, which are jointly optimized, via supervision of the CLIP loss, by a\nspherical Gaussians based differentiable renderer. As such, TANGO enables\nphotorealistic 3D style transfer by automatically predicting reflectance\neffects even for bare, low-quality meshes, without training on a task-specific\ndataset. Extensive experiments show that TANGO outperforms existing methods of\ntext-driven 3D style transfer in terms of photorealistic quality, consistency\nof 3D geometry, and robustness when stylizing low-quality meshes. Our codes and\nresults are available at our project webpage https://cyw-3d.github.io/tango/.\n</p>",
  "dc:creator": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yongwei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1\">Rui Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_J/0/1/0/all/0/1\">Jiabao Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yabin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_K/0/1/0/all/0/1\">Kui Jia</a>"
}