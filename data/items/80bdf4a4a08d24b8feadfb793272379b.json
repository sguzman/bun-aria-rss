{
  "title": "Asynchronous Optimization Algorithms with Dask",
  "link": "",
  "updated": "2017-04-19T00:00:00+00:00",
  "id": "https://mrocklin.github.io/blog/work/2017/04/19/dask-glm-2",
  "content": "<p><em>This work is supported by <a href=\"http://continuum.io\">Continuum Analytics</a>,\nthe <a href=\"http://www.darpa.mil/program/XDATA\">XDATA Program</a>,\nand the Data Driven Discovery Initiative from the <a href=\"https://www.moore.org/\">Moore\nFoundation</a>.</em></p>\n\n<h2 id=\"summary\">Summary</h2>\n\n<p>In a previous post <a href=\"http://matthewrocklin.com/blog/work/2017/03/22/dask-glm-1\">we built convex optimization algorithms with\nDask</a> that ran\nefficiently on a distributed cluster and were important for a broad class of\nstatistical and machine learning algorithms.</p>\n\n<p>We now extend that work by looking at <em>asynchronous algorithms</em>.  We show the\nfollowing:</p>\n\n<ol>\n  <li>APIs within Dask to build asynchronous computations generally, not just for\nmachine learning and optimization</li>\n  <li>Reasons why asynchronous algorithms are valuable in machine learning</li>\n  <li>A concrete asynchronous algorithm (Async ADMM) and its performance on a\ntoy dataset</li>\n</ol>\n\n<p>This blogpost is co-authored by <a href=\"https://github.com/moody-marlin/\">Chris White</a>\n(Capital One) who knows optimization and <a href=\"http://matthewrocklin.com/\">Matthew\nRocklin</a> (Continuum Analytics) who knows\ndistributed computing.</p>\n\n<p><a href=\"https://gist.github.com/4fc08482f33d60cc90cc3f8723146de5\">Reproducible notebook available here</a></p>\n\n<h2 id=\"asynchronous-vs-blocking-algorithms\">Asynchronous vs Blocking Algorithms</h2>\n\n<p>When we say <em>asynchronous</em> we contrast it against synchronous or blocking.</p>\n\n<p>In a blocking algorithm you send out a bunch of work and then wait for the\nresult.  Dask’s normal <code class=\"language-plaintext highlighter-rouge\">.compute()</code> interface is blocking.  Consider the\nfollowing computation where we score a bunch of inputs in parallel and then\nfind the best:</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">import</span> <span class=\"nn\">dask</span>\n\n<span class=\"n\">scores</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">dask</span><span class=\"p\">.</span><span class=\"n\">delayed</span><span class=\"p\">(</span><span class=\"n\">score</span><span class=\"p\">)(</span><span class=\"n\">x</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">x</span> <span class=\"ow\">in</span> <span class=\"n\">L</span><span class=\"p\">]</span>  <span class=\"c1\"># many lazy calls to the score function\n</span><span class=\"n\">best</span> <span class=\"o\">=</span> <span class=\"n\">dask</span><span class=\"p\">.</span><span class=\"n\">delayed</span><span class=\"p\">(</span><span class=\"nb\">max</span><span class=\"p\">)(</span><span class=\"n\">scores</span><span class=\"p\">)</span>\n<span class=\"n\">best</span> <span class=\"o\">=</span> <span class=\"n\">best</span><span class=\"p\">.</span><span class=\"n\">compute</span><span class=\"p\">()</span>  <span class=\"c1\"># Trigger all computation and wait until complete\n</span></code></pre></div></div>\n\n<p>This <em>blocks</em>.  We can’t do anything while it runs.  If we’re in a Jupyter\nnotebook we’ll see a little asterisk telling us that we have to wait.</p>\n\n<p><img src=\"https://mrocklin.github.io/blog/images/jupyter-blocking-cell.png\" width=\"100%\" alt=\"A Jupyter notebook cell blocking on a dask computation\" /></p>\n\n<p>In a non-blocking or asynchronous algorithm we send out work and track results\nas they come in.  We are still able to run commands locally while our\ncomputations run in the background (or on other computers in the cluster).\nDask has a variety of asynchronous APIs, but the simplest is probably the\n<a href=\"https://docs.python.org/3/library/concurrent.futures.html\">concurrent.futures</a>\nAPI where we submit functions and then can wait and act on their return.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">from</span> <span class=\"nn\">dask.distributed</span> <span class=\"kn\">import</span> <span class=\"n\">Client</span><span class=\"p\">,</span> <span class=\"n\">as_completed</span>\n<span class=\"n\">client</span> <span class=\"o\">=</span> <span class=\"n\">Client</span><span class=\"p\">(</span><span class=\"s\">'scheduler-address:8786'</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Send out several computations\n</span><span class=\"n\">futures</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">client</span><span class=\"p\">.</span><span class=\"n\">submit</span><span class=\"p\">(</span><span class=\"n\">score</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">x</span> <span class=\"ow\">in</span> <span class=\"n\">L</span><span class=\"p\">]</span>\n\n<span class=\"c1\"># Find max as results arrive\n</span><span class=\"n\">best</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>\n<span class=\"k\">for</span> <span class=\"n\">future</span> <span class=\"ow\">in</span> <span class=\"n\">as_completed</span><span class=\"p\">(</span><span class=\"n\">futures</span><span class=\"p\">):</span>\n    <span class=\"n\">score</span> <span class=\"o\">=</span> <span class=\"n\">future</span><span class=\"p\">.</span><span class=\"n\">result</span><span class=\"p\">()</span>\n    <span class=\"k\">if</span> <span class=\"n\">score</span> <span class=\"o\">&gt;</span> <span class=\"n\">best</span><span class=\"p\">:</span>\n        <span class=\"n\">best</span> <span class=\"o\">=</span> <span class=\"n\">score</span>\n</code></pre></div></div>\n\n<p>These two solutions are computationally equivalent.  They do the same work and\nrun in the same amount of time.  The blocking <code class=\"language-plaintext highlighter-rouge\">dask.delayed</code> solution is\nprobably simpler to write down but the non-blocking <code class=\"language-plaintext highlighter-rouge\">futures + as_completed</code>\nsolution lets us be more <em>flexible</em>.</p>\n\n<p>For example, if we get a score that is <em>good enough</em> then we might stop early.\nIf we find that certain kinds of values are giving better scores than others\nthen we might submit more computations around those values while cancelling\nothers, changing our computation during execution.</p>\n\n<p>This ability to monitor and adapt a computation during execution is one reason\nwhy people choose asynchronous algorithms.  In the case of optimization\nalgorithms we are doing a search process and frequently updating parameters.\nIf we are able to update those parameters more frequently then we may be able\nto slightly improve every subsequently launched computation.  Asynchronous\nalgorithms enable increased flow of information around the cluster in\ncomparison to more lock-step batch-iterative algorithms.</p>\n\n<h2 id=\"asynchronous-admm\">Asynchronous ADMM</h2>\n\n<p>In our <a href=\"http://matthewrocklin.com/blog/work/2017/03/22/dask-glm-1\">last blogpost</a>\nwe showed a simplified implementation of <a href=\"http://stanford.edu/~boyd/admm.html\">Alternating Direction Method of\nMultipliers</a> (ADMM) with\n<a href=\"http://dask.pydata.org/en/latest/delayed.html\">dask.delayed</a>.  We saw that in\na distributed context it performed well when compared to a more traditional\ndistributed gradient descent.  This algorithm works by solving a small\noptimization problem on every chunk of our data using our current parameter\nestimates, bringing these back to the local process, combining them, and then\nsending out new computation on updated parameters.</p>\n\n<p>Now we alter this algorithm to update asynchronously, so that our parameters\nchange continuously as partial results come in in real-time.  Instead of\nsending out and waiting on batches of results, we now consume and emit a\nconstant stream of tasks with slightly improved parameter estimates.</p>\n\n<p>We show three algorithms in sequence:</p>\n\n<ol>\n  <li>Synchronous: The original synchronous algorithm</li>\n  <li>Asynchronous-single: updates parameters with every new result</li>\n  <li>Asynchronous-batched: updates with all results that have come in since we\nlast updated.</li>\n</ol>\n\n<h2 id=\"setup\">Setup</h2>\n\n<p>We create fake data</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">n</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"p\">,</span> <span class=\"n\">chunksize</span> <span class=\"o\">=</span> <span class=\"mi\">50000000</span><span class=\"p\">,</span> <span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"mi\">50000</span>\n\n<span class=\"n\">beta</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">(</span><span class=\"n\">k</span><span class=\"p\">)</span> <span class=\"c1\"># random beta coefficients, no intercept\n</span><span class=\"n\">zero_idx</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">.</span><span class=\"n\">choice</span><span class=\"p\">(</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">beta</span><span class=\"p\">),</span> <span class=\"n\">size</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">)</span>\n<span class=\"n\">beta</span><span class=\"p\">[</span><span class=\"n\">zero_idx</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"mi\">0</span> <span class=\"c1\"># set some parameters to 0\n</span><span class=\"n\">X</span> <span class=\"o\">=</span> <span class=\"n\">da</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">.</span><span class=\"n\">normal</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">size</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"n\">n</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"p\">),</span> <span class=\"n\">chunks</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"n\">chunksize</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"p\">))</span>\n<span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">X</span><span class=\"p\">.</span><span class=\"n\">dot</span><span class=\"p\">(</span><span class=\"n\">beta</span><span class=\"p\">)</span> <span class=\"o\">+</span> <span class=\"n\">da</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">.</span><span class=\"n\">normal</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">size</span><span class=\"o\">=</span><span class=\"n\">n</span><span class=\"p\">,</span> <span class=\"n\">chunks</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"n\">chunksize</span><span class=\"p\">,))</span> <span class=\"c1\"># add noise\n</span>\n<span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">persist</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">)</span>  <span class=\"c1\"># trigger computation in the background\n</span></code></pre></div></div>\n\n<p>We define local functions for ADMM.  These correspond to solving an l1-regularized Linear\nregression problem:</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">def</span> <span class=\"nf\">local_f</span><span class=\"p\">(</span><span class=\"n\">beta</span><span class=\"p\">,</span> <span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">z</span><span class=\"p\">,</span> <span class=\"n\">u</span><span class=\"p\">,</span> <span class=\"n\">rho</span><span class=\"p\">):</span>\n    <span class=\"k\">return</span> <span class=\"p\">((</span><span class=\"n\">y</span> <span class=\"o\">-</span> <span class=\"n\">X</span><span class=\"p\">.</span><span class=\"n\">dot</span><span class=\"p\">(</span><span class=\"n\">beta</span><span class=\"p\">))</span> <span class=\"o\">**</span><span class=\"mi\">2</span><span class=\"p\">).</span><span class=\"nb\">sum</span><span class=\"p\">()</span> <span class=\"o\">+</span> <span class=\"p\">(</span><span class=\"n\">rho</span> <span class=\"o\">/</span> <span class=\"mi\">2</span><span class=\"p\">)</span> <span class=\"o\">*</span> <span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">dot</span><span class=\"p\">(</span><span class=\"n\">beta</span> <span class=\"o\">-</span> <span class=\"n\">z</span> <span class=\"o\">+</span> <span class=\"n\">u</span><span class=\"p\">,</span>\n                                                              <span class=\"n\">beta</span> <span class=\"o\">-</span> <span class=\"n\">z</span> <span class=\"o\">+</span> <span class=\"n\">u</span><span class=\"p\">)</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">local_grad</span><span class=\"p\">(</span><span class=\"n\">beta</span><span class=\"p\">,</span> <span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">z</span><span class=\"p\">,</span> <span class=\"n\">u</span><span class=\"p\">,</span> <span class=\"n\">rho</span><span class=\"p\">):</span>\n    <span class=\"k\">return</span> <span class=\"mi\">2</span> <span class=\"o\">*</span> <span class=\"n\">X</span><span class=\"p\">.</span><span class=\"n\">T</span><span class=\"p\">.</span><span class=\"n\">dot</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">.</span><span class=\"n\">dot</span><span class=\"p\">(</span><span class=\"n\">beta</span><span class=\"p\">)</span> <span class=\"o\">-</span> <span class=\"n\">y</span><span class=\"p\">)</span> <span class=\"o\">+</span> <span class=\"n\">rho</span> <span class=\"o\">*</span> <span class=\"p\">(</span><span class=\"n\">beta</span> <span class=\"o\">-</span> <span class=\"n\">z</span> <span class=\"o\">+</span> <span class=\"n\">u</span><span class=\"p\">)</span>\n\n\n<span class=\"k\">def</span> <span class=\"nf\">shrinkage</span><span class=\"p\">(</span><span class=\"n\">beta</span><span class=\"p\">,</span> <span class=\"n\">t</span><span class=\"p\">):</span>\n    <span class=\"k\">return</span> <span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">maximum</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">beta</span> <span class=\"o\">-</span> <span class=\"n\">t</span><span class=\"p\">)</span> <span class=\"o\">-</span> <span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">maximum</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"n\">beta</span> <span class=\"o\">-</span> <span class=\"n\">t</span><span class=\"p\">)</span>\n\n<span class=\"n\">local_update2</span> <span class=\"o\">=</span> <span class=\"n\">partial</span><span class=\"p\">(</span><span class=\"n\">local_update</span><span class=\"p\">,</span> <span class=\"n\">f</span><span class=\"o\">=</span><span class=\"n\">local_f</span><span class=\"p\">,</span> <span class=\"n\">fprime</span><span class=\"o\">=</span><span class=\"n\">local_grad</span><span class=\"p\">)</span>\n\n<span class=\"n\">lamduh</span> <span class=\"o\">=</span> <span class=\"mf\">7.2</span> <span class=\"c1\"># regularization parameter\n</span>\n<span class=\"c1\"># algorithm parameters\n</span><span class=\"n\">rho</span> <span class=\"o\">=</span> <span class=\"mf\">1.2</span>\n<span class=\"n\">abstol</span> <span class=\"o\">=</span> <span class=\"mf\">1e-4</span>\n<span class=\"n\">reltol</span> <span class=\"o\">=</span> <span class=\"mf\">1e-2</span>\n\n<span class=\"n\">z</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">zeros</span><span class=\"p\">(</span><span class=\"n\">p</span><span class=\"p\">)</span>  <span class=\"c1\"># the initial consensus estimate\n</span>\n<span class=\"c1\"># an array of the individual \"dual variables\" and parameter estimates,\n# one for each chunk of data\n</span><span class=\"n\">u</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">array</span><span class=\"p\">([</span><span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">zeros</span><span class=\"p\">(</span><span class=\"n\">p</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">nchunks</span><span class=\"p\">)])</span>\n<span class=\"n\">betas</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">array</span><span class=\"p\">([</span><span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">zeros</span><span class=\"p\">(</span><span class=\"n\">p</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">nchunks</span><span class=\"p\">)])</span>\n</code></pre></div></div>\n\n<p>Finally because ADMM doesn’t want to work on distributed arrays, but instead\non lists of remote numpy arrays (one numpy array per chunk of the dask.array)\nwe convert each our Dask.arrays into a list of dask.delayed objects:</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">XD</span> <span class=\"o\">=</span> <span class=\"n\">X</span><span class=\"p\">.</span><span class=\"n\">to_delayed</span><span class=\"p\">().</span><span class=\"n\">flatten</span><span class=\"p\">().</span><span class=\"n\">tolist</span><span class=\"p\">()</span> <span class=\"c1\"># a list of numpy arrays, one for each chunk\n</span><span class=\"n\">yD</span> <span class=\"o\">=</span> <span class=\"n\">y</span><span class=\"p\">.</span><span class=\"n\">to_delayed</span><span class=\"p\">().</span><span class=\"n\">flatten</span><span class=\"p\">().</span><span class=\"n\">tolist</span><span class=\"p\">()</span>\n</code></pre></div></div>\n\n<h2 id=\"synchronous-admm\">Synchronous ADMM</h2>\n\n<p>In this algorithm we send out many tasks to run, collect their results, update\nparameters, and repeat.  In this simple implementation we continue for a fixed\namount of time but in practice we would want to check some convergence\ncriterion.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">start</span> <span class=\"o\">=</span> <span class=\"n\">time</span><span class=\"p\">.</span><span class=\"n\">time</span><span class=\"p\">()</span>\n\n<span class=\"k\">while</span> <span class=\"n\">time</span><span class=\"p\">()</span> <span class=\"o\">-</span> <span class=\"n\">start</span> <span class=\"o\">&lt;</span> <span class=\"n\">MAX_TIME</span><span class=\"p\">:</span>\n    <span class=\"c1\"># process each chunk in parallel, using the black-box 'local_update' function\n</span>    <span class=\"n\">betas</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">delayed</span><span class=\"p\">(</span><span class=\"n\">local_update2</span><span class=\"p\">)(</span><span class=\"n\">xx</span><span class=\"p\">,</span> <span class=\"n\">yy</span><span class=\"p\">,</span> <span class=\"n\">bb</span><span class=\"p\">,</span> <span class=\"n\">z</span><span class=\"p\">,</span> <span class=\"n\">uu</span><span class=\"p\">,</span> <span class=\"n\">rho</span><span class=\"p\">)</span>\n             <span class=\"k\">for</span> <span class=\"n\">xx</span><span class=\"p\">,</span> <span class=\"n\">yy</span><span class=\"p\">,</span> <span class=\"n\">bb</span><span class=\"p\">,</span> <span class=\"n\">uu</span> <span class=\"ow\">in</span> <span class=\"nb\">zip</span><span class=\"p\">(</span><span class=\"n\">XD</span><span class=\"p\">,</span> <span class=\"n\">yD</span><span class=\"p\">,</span> <span class=\"n\">betas</span><span class=\"p\">,</span> <span class=\"n\">u</span><span class=\"p\">)]</span>\n    <span class=\"n\">betas</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">array</span><span class=\"p\">(</span><span class=\"n\">da</span><span class=\"p\">.</span><span class=\"n\">compute</span><span class=\"p\">(</span><span class=\"o\">*</span><span class=\"n\">betas</span><span class=\"p\">))</span>  <span class=\"c1\"># collect results back\n</span>\n    <span class=\"c1\"># Update Parameters\n</span>    <span class=\"n\">ztilde</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">mean</span><span class=\"p\">(</span><span class=\"n\">betas</span> <span class=\"o\">+</span> <span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">array</span><span class=\"p\">(</span><span class=\"n\">u</span><span class=\"p\">),</span> <span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n    <span class=\"n\">z</span> <span class=\"o\">=</span> <span class=\"n\">shrinkage</span><span class=\"p\">(</span><span class=\"n\">ztilde</span><span class=\"p\">,</span> <span class=\"n\">lamduh</span> <span class=\"o\">/</span> <span class=\"p\">(</span><span class=\"n\">rho</span> <span class=\"o\">*</span> <span class=\"n\">nchunks</span><span class=\"p\">))</span>\n    <span class=\"n\">u</span> <span class=\"o\">+=</span> <span class=\"n\">betas</span> <span class=\"o\">-</span> <span class=\"n\">z</span>  <span class=\"c1\"># update dual variables\n</span>\n    <span class=\"c1\"># track convergence metrics\n</span>    <span class=\"n\">update_metrics</span><span class=\"p\">()</span>\n</code></pre></div></div>\n\n<h2 id=\"asynchronous-admm-1\">Asynchronous ADMM</h2>\n\n<p>In the asynchronous version we send out only enough tasks to occupy all of our\nworkers.  We collect results one by one as they finish, update parameters, and\nthen send out a new task.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\"># Submit enough tasks to occupy our current workers\n</span><span class=\"n\">starting_indices</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">.</span><span class=\"n\">choice</span><span class=\"p\">(</span><span class=\"n\">nchunks</span><span class=\"p\">,</span> <span class=\"n\">size</span><span class=\"o\">=</span><span class=\"n\">ncores</span><span class=\"o\">*</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">replace</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">)</span>\n<span class=\"n\">futures</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">client</span><span class=\"p\">.</span><span class=\"n\">submit</span><span class=\"p\">(</span><span class=\"n\">local_update</span><span class=\"p\">,</span> <span class=\"n\">XD</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">],</span> <span class=\"n\">yD</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">],</span> <span class=\"n\">betas</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">],</span> <span class=\"n\">z</span><span class=\"p\">,</span> <span class=\"n\">u</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">],</span>\n                           <span class=\"n\">rho</span><span class=\"p\">,</span> <span class=\"n\">f</span><span class=\"o\">=</span><span class=\"n\">local_f</span><span class=\"p\">,</span> <span class=\"n\">fprime</span><span class=\"o\">=</span><span class=\"n\">local_grad</span><span class=\"p\">)</span>\n           <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"n\">starting_indices</span><span class=\"p\">]</span>\n<span class=\"n\">index</span> <span class=\"o\">=</span> <span class=\"nb\">dict</span><span class=\"p\">(</span><span class=\"nb\">zip</span><span class=\"p\">(</span><span class=\"n\">futures</span><span class=\"p\">,</span> <span class=\"n\">starting_indices</span><span class=\"p\">))</span>\n\n<span class=\"c1\"># An iterator that returns results as they come in\n</span><span class=\"n\">pool</span> <span class=\"o\">=</span> <span class=\"n\">as_completed</span><span class=\"p\">(</span><span class=\"n\">futures</span><span class=\"p\">,</span> <span class=\"n\">with_results</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">)</span>\n\n<span class=\"n\">start</span> <span class=\"o\">=</span> <span class=\"n\">time</span><span class=\"p\">.</span><span class=\"n\">time</span><span class=\"p\">()</span>\n<span class=\"n\">count</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>\n\n<span class=\"k\">while</span> <span class=\"n\">time</span><span class=\"p\">()</span> <span class=\"o\">-</span> <span class=\"n\">start</span> <span class=\"o\">&lt;</span> <span class=\"n\">MAX_TIME</span><span class=\"p\">:</span>\n    <span class=\"c1\"># Get next completed result\n</span>    <span class=\"n\">future</span><span class=\"p\">,</span> <span class=\"n\">local_beta</span> <span class=\"o\">=</span> <span class=\"nb\">next</span><span class=\"p\">(</span><span class=\"n\">pool</span><span class=\"p\">)</span>\n    <span class=\"n\">i</span> <span class=\"o\">=</span> <span class=\"n\">index</span><span class=\"p\">.</span><span class=\"n\">pop</span><span class=\"p\">(</span><span class=\"n\">future</span><span class=\"p\">)</span>\n    <span class=\"n\">betas</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">local_beta</span>\n    <span class=\"n\">count</span> <span class=\"o\">+=</span> <span class=\"mi\">1</span>\n\n    <span class=\"c1\"># Update parameters (this could be made more efficient)\n</span>    <span class=\"n\">ztilde</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">mean</span><span class=\"p\">(</span><span class=\"n\">betas</span> <span class=\"o\">+</span> <span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">array</span><span class=\"p\">(</span><span class=\"n\">u</span><span class=\"p\">),</span> <span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n\n    <span class=\"k\">if</span> <span class=\"n\">count</span> <span class=\"o\">&lt;</span> <span class=\"n\">nchunks</span><span class=\"p\">:</span>  <span class=\"c1\"># artificially inflate beta in the beginning\n</span>        <span class=\"n\">ztilde</span> <span class=\"o\">*=</span> <span class=\"n\">nchunks</span> <span class=\"o\">/</span> <span class=\"p\">(</span><span class=\"n\">count</span> <span class=\"o\">+</span> <span class=\"mi\">1</span><span class=\"p\">)</span>\n    <span class=\"n\">z</span> <span class=\"o\">=</span> <span class=\"n\">shrinkage</span><span class=\"p\">(</span><span class=\"n\">ztilde</span><span class=\"p\">,</span> <span class=\"n\">lamduh</span> <span class=\"o\">/</span> <span class=\"p\">(</span><span class=\"n\">rho</span> <span class=\"o\">*</span> <span class=\"n\">nchunks</span><span class=\"p\">))</span>\n    <span class=\"n\">update_metrics</span><span class=\"p\">()</span>\n\n    <span class=\"c1\"># Submit new task to the cluster\n</span>    <span class=\"n\">i</span> <span class=\"o\">=</span> <span class=\"n\">random</span><span class=\"p\">.</span><span class=\"n\">randint</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">nchunks</span> <span class=\"o\">-</span> <span class=\"mi\">1</span><span class=\"p\">)</span>\n    <span class=\"n\">u</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">+=</span> <span class=\"n\">betas</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">-</span> <span class=\"n\">z</span>\n    <span class=\"n\">new_future</span> <span class=\"o\">=</span> <span class=\"n\">client</span><span class=\"p\">.</span><span class=\"n\">submit</span><span class=\"p\">(</span><span class=\"n\">local_update2</span><span class=\"p\">,</span> <span class=\"n\">XD</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">],</span> <span class=\"n\">yD</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">],</span> <span class=\"n\">betas</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">],</span> <span class=\"n\">z</span><span class=\"p\">,</span> <span class=\"n\">u</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">],</span> <span class=\"n\">rho</span><span class=\"p\">)</span>\n    <span class=\"n\">index</span><span class=\"p\">[</span><span class=\"n\">new_future</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">i</span>\n    <span class=\"n\">pool</span><span class=\"p\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">new_future</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<h2 id=\"batched-asynchronous-admm\">Batched Asynchronous ADMM</h2>\n\n<p>With enough distributed workers we find that our parameter-updating loop on the\nclient can be the limiting factor.  After profiling it seems that our client\nwas bound not by updating parameters, but rather by computing the performance\nmetrics that we are going to use for the convergence plots below (so not\nactually a limitation in practice).  However we decided to leave this in\nbecause it is good practice for what is likely to occur in larger clusters,\nwhere the single machine that updates parameters is possibly overwhelmed by a\nhigh volume of updates from the workers.  To resolve this, we build in\nbatching.</p>\n\n<p>Rather than update our parameters one by one, we update them with however many\nresults have come in so far.  This provides a natural defense against a slow\nclient.  This approach smoothly shifts our algorithm back over to the\nsynchronous solution when the client becomes overwhelmed.  (though again, at\nthis scale we’re fine).</p>\n\n<p>Conveniently, the <code class=\"language-plaintext highlighter-rouge\">as_completed</code> iterator has a <code class=\"language-plaintext highlighter-rouge\">.batches()</code> method that\niterates over all of the results that have come in so far.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\"># ... same setup as before\n</span>\n<span class=\"n\">pool</span> <span class=\"o\">=</span> <span class=\"n\">as_completed</span><span class=\"p\">(</span><span class=\"n\">new_betas</span><span class=\"p\">,</span> <span class=\"n\">with_results</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">)</span>\n\n<span class=\"n\">batches</span> <span class=\"o\">=</span> <span class=\"n\">pool</span><span class=\"p\">.</span><span class=\"n\">batches</span><span class=\"p\">()</span>            <span class=\"c1\"># &lt;&lt;&lt;--- this is new\n</span>\n<span class=\"k\">while</span> <span class=\"n\">time</span><span class=\"p\">()</span> <span class=\"o\">-</span> <span class=\"n\">start</span> <span class=\"o\">&lt;</span> <span class=\"n\">MAX_TIME</span><span class=\"p\">:</span>\n\n    <span class=\"c1\"># Get all tasks that have come in since we checked last time\n</span>    <span class=\"n\">batch</span> <span class=\"o\">=</span> <span class=\"nb\">next</span><span class=\"p\">(</span><span class=\"n\">batches</span><span class=\"p\">)</span>           <span class=\"c1\"># &lt;&lt;&lt;--- this is new\n</span>    <span class=\"k\">for</span> <span class=\"n\">future</span><span class=\"p\">,</span> <span class=\"n\">result</span> <span class=\"ow\">in</span> <span class=\"n\">batch</span><span class=\"p\">:</span>\n        <span class=\"n\">i</span> <span class=\"o\">=</span> <span class=\"n\">index</span><span class=\"p\">.</span><span class=\"n\">pop</span><span class=\"p\">(</span><span class=\"n\">future</span><span class=\"p\">)</span>\n        <span class=\"n\">betas</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">result</span>\n        <span class=\"n\">count</span> <span class=\"o\">+=</span> <span class=\"mi\">1</span>\n\n    <span class=\"n\">ztilde</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">mean</span><span class=\"p\">(</span><span class=\"n\">betas</span> <span class=\"o\">+</span> <span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">array</span><span class=\"p\">(</span><span class=\"n\">u</span><span class=\"p\">),</span> <span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n    <span class=\"k\">if</span> <span class=\"n\">count</span> <span class=\"o\">&lt;</span> <span class=\"n\">nchunks</span><span class=\"p\">:</span>\n        <span class=\"n\">ztilde</span> <span class=\"o\">*=</span> <span class=\"n\">nchunks</span> <span class=\"o\">/</span> <span class=\"p\">(</span><span class=\"n\">count</span> <span class=\"o\">+</span> <span class=\"mi\">1</span><span class=\"p\">)</span>\n    <span class=\"n\">z</span> <span class=\"o\">=</span> <span class=\"n\">shrinkage</span><span class=\"p\">(</span><span class=\"n\">ztilde</span><span class=\"p\">,</span> <span class=\"n\">lamduh</span> <span class=\"o\">/</span> <span class=\"p\">(</span><span class=\"n\">rho</span> <span class=\"o\">*</span> <span class=\"n\">nchunks</span><span class=\"p\">))</span>\n    <span class=\"n\">update_metrics</span><span class=\"p\">()</span>\n\n    <span class=\"c1\"># Submit as many new tasks as we collected\n</span>    <span class=\"k\">for</span> <span class=\"n\">_</span> <span class=\"ow\">in</span> <span class=\"n\">batch</span><span class=\"p\">:</span>                 <span class=\"c1\"># &lt;&lt;&lt;--- this is new\n</span>        <span class=\"n\">i</span> <span class=\"o\">=</span> <span class=\"n\">random</span><span class=\"p\">.</span><span class=\"n\">randint</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">nchunks</span> <span class=\"o\">-</span> <span class=\"mi\">1</span><span class=\"p\">)</span>\n        <span class=\"n\">u</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">+=</span> <span class=\"n\">betas</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">-</span> <span class=\"n\">z</span>\n        <span class=\"n\">new_fut</span> <span class=\"o\">=</span> <span class=\"n\">client</span><span class=\"p\">.</span><span class=\"n\">submit</span><span class=\"p\">(</span><span class=\"n\">local_update2</span><span class=\"p\">,</span> <span class=\"n\">XD</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">],</span> <span class=\"n\">yD</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">],</span> <span class=\"n\">betas</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">],</span> <span class=\"n\">z</span><span class=\"p\">,</span> <span class=\"n\">u</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">],</span> <span class=\"n\">rho</span><span class=\"p\">)</span>\n        <span class=\"n\">index</span><span class=\"p\">[</span><span class=\"n\">new_fut</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">i</span>\n        <span class=\"n\">pool</span><span class=\"p\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">new_fut</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<h2 id=\"visual-comparison-of-algorithms\">Visual Comparison of Algorithms</h2>\n\n<p>To show the qualitative difference between the algorithms we include profile\nplots of each.  Note the following:</p>\n\n<ol>\n  <li>Synchronous has blocks of full CPU use followed by blocks of no use</li>\n  <li>The Asynchrhonous methods are more smooth</li>\n  <li>The Asynchronous single-update method has a lot of whitespace / time when\nCPUs are idling.  This is artifiical and because our code that tracks\nconvergence diagnostics for our plots below is wasteful and inside the\nclient inner-loop</li>\n  <li>We intentionally leave in this wasteful code so that we can reduce it by\nbatching in the third plot, which is more saturated.</li>\n</ol>\n\n<p>You can zoom in using the tools to the upper right of each plot.  You can view\nthe full profile in a full window by clicking on the “View full page” link.</p>\n\n<h3 id=\"synchronous\">Synchronous</h3>\n\n<p><a href=\"https://cdn.rawgit.com/mrocklin/2a1dbae5e846dce787bdbdeb7fb13be5/raw/1090bf7698aa72c672b6d490766c2c26b86f9279/task-stream-admm-sync.html\">View full page</a></p>\n<iframe src=\"https://cdn.rawgit.com/mrocklin/2a1dbae5e846dce787bdbdeb7fb13be5/raw/1090bf7698aa72c672b6d490766c2c26b86f9279/task-stream-admm-sync.html\" width=\"800\" height=\"300\"></iframe>\n\n<h3 id=\"asynchronous-single-update\">Asynchronous single-update</h3>\n\n<p><a href=\"https://cdn.rawgit.com/mrocklin/2a1dbae5e846dce787bdbdeb7fb13be5/raw/1090bf7698aa72c672b6d490766c2c26b86f9279/task-stream-admm-async.html\">View full page</a></p>\n<iframe src=\"https://cdn.rawgit.com/mrocklin/2a1dbae5e846dce787bdbdeb7fb13be5/raw/1090bf7698aa72c672b6d490766c2c26b86f9279/task-stream-admm-async.html\" width=\"800\" height=\"300\"></iframe>\n\n<h3 id=\"asynchronous-batched-update\">Asynchronous batched-update</h3>\n\n<p><a href=\"https://cdn.rawgit.com/mrocklin/2a1dbae5e846dce787bdbdeb7fb13be5/raw/1090bf7698aa72c672b6d490766c2c26b86f9279/task-stream-admm-batched.html\">View full page</a></p>\n<iframe src=\"https://cdn.rawgit.com/mrocklin/2a1dbae5e846dce787bdbdeb7fb13be5/raw/1090bf7698aa72c672b6d490766c2c26b86f9279/task-stream-admm-batched.html\" width=\"800\" height=\"300\"></iframe>\n\n<h2 id=\"plot-convergence-criteria\">Plot Convergence Criteria</h2>\n\n<p><img src=\"https://mrocklin.github.io/blog/images/admm-async-primal-residual.png\" alt=\"Primal residual for async-admm\" width=\"100%\" />\n<img src=\"https://mrocklin.github.io/blog/images/admm-async-convergence.png\" alt=\"Primal residual for async-admm\" width=\"100%\" /></p>\n\n<h2 id=\"analysis\">Analysis</h2>\n<p>To get a better sense of what these plots convey, recall that optimization problems always come in pairs: the <em>primal</em> problem \nis typically the main problem of interest, and the <em>dual</em> problem is a closely related problem that provides information about \nthe constraints in the primal problem.  Perhaps the most famous example of duality is the <a href=\"https://en.wikipedia.org/wiki/Max-flow_min-cut_theorem\">Max-flow-min-cut Theorem</a>\nfrom graph theory.  In many cases, solving both of these problems simultaneously leads to gains in performance, which is what ADMM seeks to do.</p>\n\n<p>In our case, the constraint in the primal problem is that <em>all workers must agree on the optimum parameter estimate.</em> Consequently, we can think\nof the dual variables (one for each chunk of data) as measuring the “cost” of agreement for their respective chunks.  Intuitively, they will start\nout small and grow incrementally to find the right “cost” for each worker to have consensus.  Eventually, they will level out at an optimum cost.</p>\n\n<p>So:</p>\n<ul>\n  <li>the primal residual plot measures the amount of disagreement; “small” values imply agreement</li>\n  <li>the dual residual plot measures the total “cost” of agreement; this increases until the correct cost is found</li>\n</ul>\n\n<p>The plots then tell us the following:</p>\n<ul>\n  <li>the cost of agreement is higher for asynchronous algorithms, which makes sense because each worker is always working with a slightly out-of-date global parameter estimate, \nmaking consensus harder</li>\n  <li>blocked ADMM doesn’t update at all until shortly after 5 seconds have passed, whereas async has already had time to converge.\n(In practice with real data, we would probably specify that all workers need to report in every K updates).</li>\n  <li>asynchronous algorithms take a little while for the information to properly diffuse, but once that happens they converge quickly.</li>\n  <li>both asynchronous and synchronous converge almost immediately; this is most likely due to a high degree of homogeneity in the data (which was generated to fit the model well). Our next experiment should involve real world data.</li>\n</ul>\n\n<h2 id=\"what-we-could-have-done-better\">What we could have done better</h2>\n\n<p>Analysis wise we expect richer results by performing this same experiment on a real world data set that isn’t as homogeneous as the current toy dataset.</p>\n\n<p>Performance wise we can get much better CPU saturation by doing two things:</p>\n\n<ol>\n  <li>Not running our convergence diagnostics, or making them much faster</li>\n  <li>Not running full <code class=\"language-plaintext highlighter-rouge\">np.mean</code> computations over all of beta when we’ve only\nupdated a few elements.  Instead we should maintain a running aggregation\nof these results.</li>\n</ol>\n\n<p>With these two changes (each of which are easy) we’re fairly confident that we\ncan scale out to decently large clusters while still saturating hardware.</p>"
}