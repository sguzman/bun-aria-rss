{
  "title": "Deep learning for Hackers with MXNet (3): Instant neural art style transfer",
  "link": "https://no2147483647.wordpress.com/2017/03/16/deep-learning-for-hackers-3-instant-neural-art-style-transfer/",
  "comments": "https://no2147483647.wordpress.com/2017/03/16/deep-learning-for-hackers-3-instant-neural-art-style-transfer/#comments",
  "dc:creator": "phunterlau",
  "pubDate": "Thu, 16 Mar 2017 05:56:57 +0000",
  "category": "Machine Learning",
  "guid": "http://no2147483647.wordpress.com/?p=264",
  "description": "This blog is originally posted in Chinese from my zhihu category. So long from last blog, and thanks for coming back. Here I want to present a MXNet example of instant neural art style transfer, from which you can build your own Prisma app. Do you know MXNet now can be installed via pip? pip [&#8230;]",
  "content:encoded": "<p>This blog is originally posted <a href=\"https://zhuanlan.zhihu.com/p/24205969\">in Chinese</a> from my <code>zhihu</code> category.</p>\n<p>So long from last blog, and thanks for coming back. Here I want to present a MXNet example of instant neural art style transfer, from which you can build your own <a href=\"http://prisma-ai.com/\">Prisma</a> app.</p>\n<p>Do you know <code>MXNet</code> now can be installed via <code>pip</code>?</p>\n<div>\n<pre><code class=\"language-none\">pip search mxnet\nmxnet-cu75 (0.9.3a3)  - MXNet is an ultra-scalable deep learning framework. This version uses CUDA-7.5.\nmxnet (0.9.3a3)       - MXNet is an ultra-scalable deep learning framework. This version uses openblas.\nmxnet-cu80 (0.9.3a3)  - MXNet is an ultra-scalable deep learning framework. This version uses CUDA-8.0.</code></pre>\n</div>\n<h2 id=\"toc_1\">Let&#8217;s go</h2>\n<p>After installing <code>MXNet</code>, please do</p>\n<div>\n<pre><code class=\"language-none\">git clone https://github.com/zhaw/neural_style</code></pre>\n</div>\n<p>which includes three different implementations of fast neural art style transfer. Big thanks to the author <a href=\"https://github.com/zhaw\">Zhao Wei</a>. In this blog, I am going to talk about Perceptual Losses by Justin Johnson et al described in this <a href=\"https://arxiv.org/abs/1603.08155\">paper</a>. After <code>git clone</code>, please go to <code>neural_style/perceptual/</code> and execute the following script:</p>\n<div>\n<pre><code class=\"language-none\">import make_image\nmaker = make_image.Maker('models/s4', (512, 512))\nmaker.generate('output.jpg', 'niba.jpg')</code></pre>\n</div>\n<p>where <code>output.jpg</code> is the output and <code>niba.jpg</code> is picture of the cutest deep learning cat <code>Niba</code>. Within a blink, we can see the output like this:</p>\n<p><img data-attachment-id=\"266\" data-permalink=\"https://no2147483647.wordpress.com/2017/03/16/deep-learning-for-hackers-3-instant-neural-art-style-transfer/niba-instant-transfer1/#main\" data-orig-file=\"https://no2147483647.files.wordpress.com/2017/03/niba-instant-transfer1.png\" data-orig-size=\"600,335\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"niba-instant-transfer1\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://no2147483647.files.wordpress.com/2017/03/niba-instant-transfer1.png?w=300\" data-large-file=\"https://no2147483647.files.wordpress.com/2017/03/niba-instant-transfer1.png?w=600\" class=\"alignnone size-full wp-image-266\" src=\"https://no2147483647.files.wordpress.com/2017/03/niba-instant-transfer1.png?w=1008\" alt=\"niba-instant-transfer1.png\" srcset=\"https://no2147483647.files.wordpress.com/2017/03/niba-instant-transfer1.png 600w, https://no2147483647.files.wordpress.com/2017/03/niba-instant-transfer1.png?w=150 150w, https://no2147483647.files.wordpress.com/2017/03/niba-instant-transfer1.png?w=300 300w\" sizes=\"(max-width: 600px) 100vw, 600px\"   /></p>\n<p>&nbsp;</p>\n<p>Beside this art style, multiple other pretrained neural art models are mentioned in <code>README</code> page under <code>neural_style/perceptual/</code>, please download them via the link mentioned in the page. These pretrained models should produce the art work and combine with <code>ImageTrick</code>:</p>\n<div>\n<pre><code class=\"language-none\">montage output*.jpg -geometry +7+7+7 merge.jpg</code></pre>\n</div>\n<p>&nbsp;</p>\n<p><img data-attachment-id=\"267\" data-permalink=\"https://no2147483647.wordpress.com/2017/03/16/deep-learning-for-hackers-3-instant-neural-art-style-transfer/niba-instant-transfer2/#main\" data-orig-file=\"https://no2147483647.files.wordpress.com/2017/03/niba-instant-transfer2.jpg\" data-orig-size=\"600,400\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"niba-instant-transfer2\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://no2147483647.files.wordpress.com/2017/03/niba-instant-transfer2.jpg?w=300\" data-large-file=\"https://no2147483647.files.wordpress.com/2017/03/niba-instant-transfer2.jpg?w=600\" class=\"alignnone size-full wp-image-267\" src=\"https://no2147483647.files.wordpress.com/2017/03/niba-instant-transfer2.jpg?w=1008\" alt=\"niba-instant-transfer2.png\" srcset=\"https://no2147483647.files.wordpress.com/2017/03/niba-instant-transfer2.jpg 600w, https://no2147483647.files.wordpress.com/2017/03/niba-instant-transfer2.jpg?w=150 150w, https://no2147483647.files.wordpress.com/2017/03/niba-instant-transfer2.jpg?w=300 300w\" sizes=\"(max-width: 600px) 100vw, 600px\"   /></p>\n<p>Please note: some machines may encounter the following error</p>\n<div>\n<pre><code class=\"language-none\">terminate called after throwing an instance of 'dmlc::Error' what():  [21:25:23] src/engine/./threaded_engine.h:306: [21:25:23] src/operator/./convolution-inl.h:299: Check failed: (param_.workspace) >= (required_size)</code></pre>\n</div>\n<p>The reason behind this is fromÂ the <code>workspace</code> size of the convolution layers, where the default <code>workspace</code> might be too small for some large images. Please edit <code>symbol.py</code> by adding <code>workspace=4092</code> to each <code>mx.symbol.Convolution</code> function.</p>\n<p>Hope you have some fun with your own <code>Prisma</code> app <img src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f642.png\" alt=\"ðŸ™‚\" class=\"wp-smiley\" style=\"height: 1em; max-height: 1em;\" /></p>\n<h2 id=\"toc_2\">Theory</h2>\n<p><code>Neural art transfer</code> has been a hot topic in deep learning, and it starts from this paper <a href=\"https://arxiv.org/abs/1508.06576\"><code>A Neural Algorithm of Artistic Style</code></a>. As we have discussed in the last blog, this idea leverages the power of convolutional network where the high level features can describe so called <code>style</code> of an image, if apply this high level feature to a new image, one can transfer the art style and generate new art work. In the original paper, <code>gram matrix</code> is used for this magic. To understand <code>gram matrix</code> magic, one can take look at my friend&#8217;s paper <a href=\"https://arxiv.org/abs/1701.01036\"><code>Demystifying Neural Style Transfer</code></a> for further understanding. There are many blogs and papers trying to understand why neural art transfer works, and this paper is probably the only correct one.</p>\n<p>Back to the original neural art transfer: the original version calculates the per-pixel loss from the content image to the style image, and introduces a very large <code>gram matrix</code>, meanwhile, it has to run a logistic regression for tuning the weight of each layer. This method needs much computing time due to couple of heavy load from per-pixel loss, gram matrix plus the LR. In the market, there are several faster implementation, where <code>Perceptual Losses</code> method is one of the fastest ones. <code>Perceptual Losses</code> introduces pretrained <code>loss networks</code> from <code>ImageNet</code>, and re-uses the content loss and style loss to calculate perceptual loss, however, it doesn&#8217;t update the loss network, which saves much computing time. It works like this: when give the input image (e.g. <code>Niba</code>) to the transform network, it calculates the loss from the pretrained loss network, and gets back to transform network to minimize the loss, so transform network can learn the loss network style from minimizing the loss.</p>\n<p>Perceptual loss network needs a set of pretrained network where each network for a style. One can follow <code>train.py</code> under the same repo for creating new styles.</p>\n<h2 id=\"toc_3\">Appendix</h2>\n<p>Why I paused updating this blog for a long time and resume?</p>\n<p>Because I was carefully thinking about teaching <code>MXNet</code> and <code>deep learning</code> in <strong>a different way</strong>, much different from many other blogs or medium posts where each tutorial starts with theory or math or whatever fundamental knowledge, needs at least 30 minutes reading time, professionals don&#8217;t like the repeated fundamental knowledge part since they already know it, but new readers can&#8217;t understand what to do.</p>\n<p>I believe the only way readers can remember the knowledge is by <code>JUST DO IT!</code>. From last year, I opened my <a href=\"https://zhuanlan.zhihu.com/gomxnet\">category</a> on <code>zhihu.com</code> and started publishing <code>two minutes demo of deep learning</code> in Chinese. It turned out very welcomed: my 2000+ followers had much fun trying these demos, they really learned after doing it and reading the <code>theory</code> part. If miss some math knowledge, I showed them where to learn. So, I am thinking that, why don&#8217;t I translate it back to English, and share with more readers. I will keep posting more blogs like this, hope you like them.</p>\n<p>And, as always, have you clicked the <code>star</code> and <code>fork</code> buttons on <code>MXNet</code> repo <a href=\"https://github.com/dmlc/mxnet\">https://github.com/dmlc/mxnet</a> ?</p>\n",
  "wfw:commentRss": "https://no2147483647.wordpress.com/2017/03/16/deep-learning-for-hackers-3-instant-neural-art-style-transfer/feed/",
  "slash:comments": 2,
  "media:thumbnail": "",
  "media:content": [
    {
      "media:title": "niba_original"
    },
    {
      "media:title": "phunterlau"
    },
    {
      "media:title": "niba-instant-transfer1.png"
    },
    {
      "media:title": "niba-instant-transfer2.png"
    }
  ]
}