{
  "id": "tag:blogger.com,1999:blog-8474926331452026626.post-5836135189460527312",
  "published": "2022-09-17T19:00:00.003-07:00",
  "updated": "2022-10-21T06:31:19.010-07:00",
  "category": [
    "",
    "",
    ""
  ],
  "title": "Google at Interspeech 2022",
  "content": "<span class=\"byline-author\">Posted by Cat Armato, Program Manager, Google</span> <p>This week, the 23rd Annual <a href=\"https://www.interspeech2022.org/\">Conference of the International Speech Communication Association</a> (INTERSPEECH 2022) is being held in Incheon, South Korea, representing one of the world’s most extensive conferences on research and technology of spoken language understanding and processing. Over 2,000 experts in speech-related research fields gather to take part in oral presentations and poster sessions and to collaborate with streamed events across the globe. </p><a name='more'></a><p>We are excited to be a Diamond Sponsor of INTERSPEECH 2022, where we will be showcasing nearly 50 research publications and supporting a number of workshops, special sessions and tutorials. We welcome in-person attendees to drop by the Google booth to meet our researchers and participate in Q&amp;As and demonstrations of some of our latest speech technologies, which help to improve accessibility and provide convenience in communication for billions of users. In addition, online attendees are encouraged to visit our virtual booth in <a href=\"https://spotvirtual.com/invite/lifeskilz-69dZxjOOvd\">GatherTown</a> where you can get up-to-date information on research and opportunities at Google. You can also learn more about the Google research being presented at INTERSPEECH 2022 below (Google affiliations in <b>bold</b>). </p><br /><p><b><span style=\"text-decoration: underline;\">Organizing Committee</span></b></p><p>Industry Liaisons include: <b><i>Bhuvana Ramabahdran</i></b></p><p>Area Chairs include: <i><b>John Hershey</b>, <b>Heiga Zen</b>, <b>Shrikanth Narayanan</b>, <b>Bastiaan Kleijn</b></i></p><br /><p><b><span style=\"text-decoration: underline;\">ISCA Fellows</span></b></p><p>Include: <i><b>Tara Sainath</b>, <b>Heiga Zen</b></i></p><br /><p><b><span style=\"text-decoration: underline;\">Publications</span></b></p><p><a href=\"https://arxiv.org/pdf/2204.06322.pdf\">Production Federated Keyword Spotting via Distillation, Filtering, and Joint Federated-Centralized Training</a><br />  <i><b>Andrew Hard</b>, <b>Kurt Partridge</b>, <b>Neng Chen</b>, <b>Sean Augenstein</b>, <b>Aishanee Shah</b>, <b>Hyun Jin Park</b>, <b>Alex Park</b>, <b>Sara Ng</b>, <b>Jessica Nguyen</b>, <b>Ignacio Lopez Moreno</b>, <b>Rajiv Mathews</b>, <b>Françoise Beaufays</b></i></p><p><a href=\"https://arxiv.org/pdf/2203.13339.pdf\">Leveraging Unsupervised and Weakly-Supervised Data to Improve Direct Speech-to-Speech Translation</a><br />  <i><b>Ye Jia</b>, <b>Yifan Ding</b>, <b>Ankur Bapna</b>, <b>Colin Cherry</b>, <b>Yu Zhang</b>, <b>Alexis Conneau</b>, <b>Nobu Morioka</b></i></p><p><a href=\"https://arxiv.org/pdf/2203.05008.pdf\">Sentence-Select: Large-Scale Language Model Data Selection for Rare-Word Speech Recognition</a><br />  <i><b>W. Ronny Huang</b>, <b>Cal Peyser</b>, <b>Tara N. Sainath</b>, <b>Ruoming Pang</b>, <b>Trevor Strohman</b>, <b>Shankar Kumar</b></i></p><p><a href=\"https://arxiv.org/pdf/2207.00706.pdf\">UserLibri: A Dataset for ASR Personalization Using Only Text</a><br />  <i><b>Theresa Breiner</b>, <b>Swaroop Ramaswamy</b>, <b>Ehsan Variani</b>, <b>Shefali Garg</b>, <b>Rajiv Mathews</b>, <b>Khe Chai Sim</b>, <b>Kilol Gupta</b>, <b>Mingqing Chen</b>, <b>Lara McConnaughey</b></i></p><p><a href=\"https://arxiv.org/pdf/2111.00764.pdf\">SNRi Target Training for Joint Speech Enhancement and Recognition</a><br />  <i><b>Yuma Koizumi</b>, <b>Shigeki Karita</b>, <b>Arun Narayanan</b>, <b>Sankaran Panchapagesan</b>, <b>Michiel Bacchiani</b></i></p><p><a href=\"https://arxiv.org/pdf/2208.13321.pdf\">Turn-Taking Prediction for Natural Conversational Speech</a><br />  <i><b>Shuo-Yiin Chang</b>, <b>Bo Li</b>, <b>Tara Sainath</b>, <b>Chao Zhang</b>, <b>Trevor Strohman</b>, <b>Qiao Liang</b>, <b>Yanzhang He</b></i></p><p><a href=\"https://arxiv.org/pdf/2208.13322.pdf\">Streaming Intended Query Detection Using E2E Modeling for Continued Conversation</a><br />  <i><b>Shuo-Yiin Chang</b>, <b>Guru Prakash</b>, <b>Zelin Wu</b>, <b>Tara Sainath</b>, <b>Bo Li</b>, <b>Qiao Liang</b>, <b>Adam Stambler</b>, <b>Shyam Upadhyay</b>, <b>Manaal Faruqui</b>, <b>Trevor Strohman</b></i></p><p><a href=\"https://arxiv.org/pdf/2203.16104.pdf\">Improving Distortion Robustness of Self-Supervised Speech Processing Tasks with Domain Adaptation</a><br /><i>  Kuan Po Huang, Yu-Kuan Fu,<b> Yu Zhang</b>, Hung-yi Lee </i></p><p><a href=\"https://arxiv.org/pdf/2111.09296.pdf\">XLS-R: Self-Supervised Cross-Lingual Speech Representation Learning at Scale</a><br /><i>  Arun Babu, Changhan Wang, Andros Tjandra, Kushal Lakhotia, Qiantong Xu, Naman Goyal, Kritika Singh, Patrick von Platen, Yatharth Saraf, Juan Pino, Alexei Baevski, <b>Alexis Conneau</b>, Michael Auli </i></p><p><a href=\"https://arxiv.org/pdf/2204.08345.pdf\">Extracting Targeted Training Data from ASR Models, and How to Mitigate It</a><br />  <i><b>Ehsan Amid</b>, <b>Om Thakkar</b>, <b>Arun Narayanan</b>, <b>Rajiv Mathews</b>, <b>Françoise Beaufays</b></i></p><p><a href=\"https://arxiv.org/abs/2204.09606\">Detecting Unintended Memorization in Language-Model-Fused ASR</a><br />  <i><b>W. Ronny Huang</b>, <b>Steve Chien</b>, <b>Om Thakkar</b>, <b>Rajiv Mathews</b></i></p><p><a href=\"https://arxiv.org/pdf/2206.07684.pdf\">AVATAR: Unconstrained Audiovisual Speech Recognition</a><br />  <i><b>Valentin Gabeur</b>, <b>Paul Hongsuck Seo</b>, <b>Arsha Nagrani</b>, <b>Chen Sun</b>, Karteek Alahari, <b>Cordelia Schmid</b></i></p><p><a href=\"https://arxiv.org/pdf/2204.00652.pdf\">End-to-End Multi-talker Audio-Visual ASR Using an Active Speaker Attention Module</a><br />  <i><b>Richard Rose</b>, <b>Olivier Siohan</b></i></p><p><a href=\"https://arxiv.org/pdf/2201.10439.pdf\">Transformer-Based Video Front-Ends for Audio-Visual Speech Recognition for Single and Multi-person Video</a><br />  <i><b>Dmitriy Serdyuk</b>, <b>Otavio Braga</b>, <b>Olivier Siohan</b></i></p><p><a href=\"https://arxiv.org/pdf/2204.01981.pdf\">Unsupervised Data Selection via Discrete Speech Representation for ASR</a><br />  <i><b>Zhiyun Lu</b>, <b>Yongqiang Wang</b>, <b>Yu Zhang</b>, <b>Wei Han</b>, <b>Zhehuai Chen</b>, <b>Parisa Haghani</b></i></p><p><a href=\"https://arxiv.org/abs/2209.06987\">Non-parallel Voice Conversion for ASR Augmentation</a><br />  <i><b>Gary Wang</b>, <b>Andrew Rosenberg</b>, <b>Bhuvana Ramabhadran</b>, <b>Fadi Biadsy</b>, <b>Jesse Emond</b>, <b>Yinghui Huang</b>, <b>Pedro J. Moreno</b></i></p><p><a href=\"https://arxiv.org/pdf/2207.02262.pdf\">Ultra-Low-Bitrate Speech Coding with Pre-trained Transformers</a><br /><i>  Ali Siahkoohi, <b>Michael Chinen</b>, <b>Tom Denton</b>, <b>W. Bastiaan Kleijn</b>, <b>Jan Skoglund</b></i></p><p><a href=\"https://drive.google.com/file/d/1EOLTniiA30yenTHyM3dgXcL2whthz1hc/view?usp=sharing&amp;resourcekey=0-xmtb_udWK0467lOOMA42IA\">Streaming End-to-End Multilingual Speech Recognition with Joint Language Identification</a><br />  <i><b>Chao Zhang</b>, <b>Bo Li</b>, <b>Tara Sainath</b>, <b>Trevor Strohman</b>, <b>Sepand Mavandadi</b>, <b>Shuo-Yiin Chang</b>, <b>Parisa Haghani</b></i></p><p><a href=\"https://arxiv.org/pdf/2206.14716.pdf\">Improving Deliberation by Text-Only and Semi-supervised Training</a><br />  <i><b>Ke Hu, Tara N. Sainath</b>, <b>Yanzhang He</b>, <b>Rohit Prabhavalkar</b>, <b>Trevor Strohman</b>, <b>Sepand Mavandadi</b>, <b>Weiran Wang</b></i></p><p><a href=\"https://arxiv.org/pdf/2204.10749.pdf\">E2E Segmenter: Joint Segmenting and Decoding for Long-Form ASR</a><br />  <i><b>W. Ronny Huang</b>, <b>Shuo-yiin Chang</b>, <b>David Rybach</b>, <b>Rohit Prabhavalkar</b>, <b>Tara N. Sainath</b>, <b>Cyril Allauzen</b>, <b>Cal Peyser</b>, <b>Zhiyun Lu</b></i></p><p><a href=\"https://arxiv.org/pdf/2203.15652.pdf\">CycleGAN-Based Unpaired Speech Dereverberation</a><br />  <i><b>Alexis Conneau</b>, <b>Ankur Bapna</b>, <b>Yu Zhang</b>, <b>Min Ma</b>, Patrick von Platen, Anton Lozhkov, <b>Colin Cherry</b>, <b>Ye Jia</b>, <b>Clara Rivera</b>, <b>Mihir Kale</b>, <b>Daan van Esch</b>, <b>Vera Axelrod</b>, <b>Simran Khanuja</b>, <b>Jonathan Clark</b>, <b>Orhan Firat</b>, Michael Auli, <b>Sebastian Ruder</b>, <b>Jason Riesa, Melvin Johnson</b></i></p><p><a href=\"https://aps.arxiv.org/pdf/2203.00236.pdf\">TRILLsson: Distilled Universal Paralinguistic Speech Representations</a><b> </b>(see <a href=\"https://ai.googleblog.com/2022/03/trillsson-small-universal-speech.html\">blog post</a>) <br />  <i><b>Joel Shor</b>, <b>Subhashini Venugopalan</b></i></p><p><a href=\"https://arxiv.org/pdf/2203.15519.pdf\">Learning Neural Audio Features Without Supervision</a><br /><i>  Sarthak Yadav, <b>Neil Zeghidour</b></i></p><p><a href=\"https://arxiv.org/pdf/2202.07273.pdf\">SpeechPainter: Text-Conditioned Speech Inpainting</a><br />  <i><b>Zalan Borsos</b>, <b>Matthew Sharifi</b>, <b>Marco Tagliasacchi</b></i></p><p><a href=\"https://arxiv.org/pdf/2203.16749.pdf\">SpecGrad: Diffusion Probabilistic Model-Based Neural Vocoder with Adaptive Noise Spectral Shaping</a><br />  <i><b>Yuma Koizumi</b>, <b>Heiga Zen</b>, Kohei Yatabe, <b>Nanxin Chen</b>, <b>Michiel Bacchiani</b></i></p><p><a href=\"https://arxiv.org/pdf/2207.00562.pdf\">Distance-Based Sound Separation</a><br />  <i><b>Katharine Patterson</b>, <b>Kevin Wilson</b>, <b>Scott Wisdom</b>, <b>John R. Hershey</b></i></p><p><a href=\"https://arxiv.org/pdf/2209.06096.pdf\">Analysis of Self-Attention Head Diversity for Conformer-Based Automatic Speech Recognition</a><br />  <i><b>Kartik Audhkhasi</b>, <b>Yinghui Huang</b>, <b>Bhuvana Ramabhadran</b>, <b>Pedro J. Moreno</b></i></p><p><a href=\"https://arxiv.org/pdf/2204.07553.pdf\">Improving Rare Word Recognition with LM-Aware MWER Training</a><br />  <i><b>Wang Weiran</b>, <b>Tongzhou Chen</b>, <b>Tara Sainath</b>, <b>Ehsan Variani</b>, <b>Rohit Prabhavalkar</b>, <b>W. Ronny Huang</b>, <b>Bhuvana Ramabhadran</b>, <b>Neeraj Gaur</b>, <b>Sepand Mavandadi</b>, <b>Cal Peyser</b>, <b>Trevor Strohman</b>, <b>Yanzhang He</b>, <b>David Rybach</b></i></p><p><a href=\"https://arxiv.org/pdf/2204.03409.pdf\">MAESTRO: Matched Speech Text Representations Through Modality Matching</a><br />  <i><b>Zhehuai Chen</b>, <b>Yu Zhang</b>, <b>Andrew Rosenberg</b>, <b>Bhuvana Ramabhadran</b>, <b>Pedro J. Moreno</b>, <b>Ankur Bapna</b>, <b>Heiga Zen</b></i></p><p><a href=\"https://arxiv.org/pdf/2203.12668.pdf\">Pseudo Label is Better Than Human Label</a><br />  <i><b>Dongseong Hwang</b>, <b>Khe Chai Sim</b>, <b>Zhouyuan Huo</b>, <b>Trevor Strohman</b></i></p><p>On the Optimal Interpolation Weights for Hybrid Autoregressive Transducer Model <br />  <i><b>Ehsan Variani</b>, <b>Michael Riley</b>, <b>David Rybach</b>, <b>Cyril Allauzen</b>, <b>Tongzhou Chen</b>, <b>Bhuvana Ramabhadran</b></i></p><p><a href=\"https://arxiv.org/pdf/2204.07556.pdf\">Streaming Align-Refine for Non-autoregressive Deliberation</a><br />  <i><b>Wang Weiran</b>, <b>Ke Hu</b>, <b>Tara Sainath</b></i></p><p><a href=\"https://arxiv.org/pdf/2209.06359.pdf\">Federated Pruning: Improving Neural Network Efficiency with Federated Learning</a><br /><i>  Rongmei Lin<a href=\"#1\" name=\"top1\"><span class=\"Apple-style-span\" style=\"font-size: small;\"><sup>*</sup></span></a>, <b>Yonghui Xiao</b>, <b>Tien-Ju Yang</b>, <b>Ding Zhao</b>, Li Xiong, <b>Giovanni Motta</b>, <b>Fran</b></i><i><b>ç</b></i><i><b>oise Beaufays</b></i></p><p><a href=\"https://arxiv.org/pdf/2204.06164.pdf\">A Unified Cascaded Encoder ASR Model for Dynamic Model Sizes</a><br />  <i><b>Shaojin Ding</b>, <b>Weiran Wang</b>, <b>Ding Zhao</b>, <b>Tara N Sainath</b>, <b>Yanzhang He</b>, <b>Robert David</b>, <b>Rami Botros</b>, <b>Xin Wang</b>, <b>Rina Panigrahy</b>, <b>Qiao Liang</b>, <b>Dongseong Hwang</b>, <b>Ian McGraw</b>, <b>Rohit Prabhavalkar</b>, <b>Trevor Strohman</b></i></p><p><a href=\"https://arxiv.org/pdf/2203.15952.pdf\">4-Bit Conformer with Native Quantization Aware Training for Speech Recognition</a><br />  <i><b>Shaojin Ding</b>, <b>Phoenix Meadowlark</b>, <b>Yanzhang He</b>, <b>Lukasz Lew</b>, <b>Shivani Agrawal</b>, <b>Oleg Rybakov</b></i></p><p><a href=\"https://arxiv.org/pdf/2207.07935.pdf\">Visually-Aware Acoustic Event Detection Using Heterogeneous Graphs</a><br /><i>  Amir Shirian, <b>Krishna Somandepalli</b>, Victor Sanchez, Tanaya Guha </i></p><p><a href=\"https://arxiv.org/pdf/2205.03481.pdf\">A Conformer-Based Waveform-Domain Neural Acoustic Echo Canceller Optimized for ASR Accuracy</a><br />  <i><b>Sankaran Panchapagesan</b>, <b>Arun Narayanan</b>, <b>Turaj Zakizadeh Shabestary</b>, <b>Shuai Shao</b>, <b>Nathan Howard</b>, <b>Alex Park</b>, <b>James Walker</b>, <b>Alexander Gruenstein</b></i></p><p><a href=\"https://research.google/pubs/pub51530/\">Reducing Domain Mismatch in Self-Supervised Speech Pre-training</a><br /><i>  Murali Karthick Baskar, <b>Andrew Rosenberg</b>, <b>Bhuvana Ramabhadran</b>, <b>Yu Zhang</b>, <b>Nicolás Serrano</b></i></p><p><a href=\"https://drive.google.com/file/d/1vCrHH2lfWgVzyxH0R6i9H-wPtb0GYTmx/view?usp=sharing\">On-the-Fly ASR Corrections with Audio Exemplars</a><br />  <i><b>Golan Pundak</b>, <b>Tsendsuren Munkhdalai</b>, <b>Khe Chai Sim</b></i></p><p><a href=\"https://arxiv.org/pdf/2208.13916.pdf\">A Language Agnostic Multilingual Streaming On-Device ASR System</a><br />  <i><b>Bo Li</b>, <b>Tara Sainath</b>, Ruoming Pang*, <b>Shuo-Yiin Chang</b>, <b>Qiumin Xu</b>, <b>Trevor Strohman</b>, <b>Vince Chen</b>, <b>Qiao Liang</b>, <b>Heguang Liu</b>, <b>Yanzhang He</b>, <b>Parisa Haghani</b>, <b>Sameer Bidichandani</b></i></p><p><a href=\"https://arxiv.org/pdf/2203.10752.pdf\">XTREME-S: Evaluating Cross-Lingual Speech Representations</a><br />  <i><b>Alexis Conneau</b>, <b>Ankur Bapna</b>, <b>Yu Zhang</b>, <b>Min Ma</b>, Patrick von Platen, Anton Lozhkov, <b>Colin Cherry</b>, <b>Ye Jia</b>, <b>Clara Rivera</b>, <b>Mihir Kale</b>, <b>Daan van Esch</b>, <b>Vera Axelrod</b>, <b>Simran Khanuja</b>, <b>Jonathan Clark</b>, <b>Orhan Firat</b>, Michael Auli, <b>Sebastian Ruder</b>, <b>Jason Riesa</b>, <b>Melvin Johnson</b></i></p><p><a href=\"https://arxiv.org/pdf/2208.13191.pdf\">Towards Disentangled Speech Representations</a><br />  <i><b>Cal Peyser</b>, <b>Ronny Huang</b>, <b>Andrew Rosenberg</b>, <b>Tara Sainath</b>, Michael Picheny, Kyunghyun Cho </i></p><p><a href=\"https://arxiv.org/pdf/2204.03793.pdf\">Personal VAD 2.0: Optimizing Personal Voice Activity Detection for On-Device Speech Recognition</a><br />  <i><b>Shaojin Ding</b>, <b>Rajeev Rikhye</b>, <b>Qiao Liang</b>, <b>Yanzhang He</b>, <b>Quan Wang</b>, <b>Arun Narayanan</b>, <b>Tom O'Malley</b>, <b>Ian McGraw</b></i></p><p><a href=\"https://arxiv.org/pdf/2209.06410.pdf\">A Universally-Deployable ASR Frontend for Joint Acoustic Echo Cancellation, Speech Enhancement, and Voice Separation</a><br />  <i><b>Tom O’Malley</b>, <b>Arun Narayanan</b>, <b>Quan Wang</b></i></p><p><a href=\"https://arxiv.org/pdf/2208.13183\">Training Text-To-Speech Systems From Synthetic Data: A Practical Approach For Accent Transfer Tasks</a><br />  <i><b>Lev Finkelstein</b>, <b>Heiga Zen</b>, Norman Casagrande, <b>Chun-an Chan</b>, <b>Ye Jia</b>, <b>Tom Kenter</b>, <b>Alex Petelin</b>, Jonathan Shen*,<b> Vincent Wan</b>, <b>Yu Zhang</b>, <b>Yonghui Wu</b>, <b>Robert Clark</b></i></p><p><a href=\"https://arxiv.org/pdf/2203.12559.pdf\">A Scalable Model Specialization Framework for Training and Inference Using Submodels and Its Application to Speech Model Personalization</a><br />  <i><b>Fadi Biadsy</b>, <b>Youzheng Chen</b>, <b>Xia Zhang</b>, <b>Oleg Rybakov</b>, <b>Andrew Rosenberg</b>, <b>Pedro Moreno</b></i></p><p><a href=\"https://arxiv.org/pdf/2204.05738.pdf\">Text-Driven Separation of Arbitrary Sounds</a><br />  <i><b>Kevin Kilgour</b>, <b>Beat Gfeller</b>, <b>Qingqing Huang</b>, <b>Aren Jansen</b>, <b>Scott Wisdom</b>, <b>Marco Tagliasacchi</b></i></p><br /><p><b><span style=\"text-decoration: underline;\">Workshops, Tutorials &amp; Special  Sessions</span></b></p><p><a href=\"https://mm.kaist.ac.kr/datasets/voxceleb/voxsrc\">The VoxCeleb Speaker Recognition Challenge 2022 (VoxSRC-22)</a><br />  Organizers include: <b><i>Arsha Nagrani</i></b></p><p>Self-Supervised Representation Learning for Speech Processing <br />  Organizers include: <b><i>Tara Sainath</i></b></p><p>Learning from Weak Labels <br />  Organizers include: <b><i>Ankit Shah</i></b></p><p><a href=\"https://arxiv.org/pdf/2203.03543.pdf\">RNN Transducers for Named Entity Recognition with Constraints on Alignment for Understanding Medical Conversations</a><br />  Authors: <i><b>Hagen Soltau</b>, <b>Izhak Shafran</b>, <b>Mingqiu Wang</b>, <b>Laurent El Shafey</b></i></p><p><a href=\"https://claritychallenge.org/clarity2021-workshop/papers/Clarity_2021_paper_yang.pdf\">Listening with Googlears: Low-Latency Neural Multiframe Beamforming and Equalization for Hearing Aids</a><br />  Authors: <i><b>Samuel Yang</b>, <b>Scott Wisdom</b>, <b>Chet Gnegy</b>, <b>Richard F. Lyon</b>, <b>Sagar Savla</b></i></p><p><a href=\"https://arxiv.org/pdf/2209.06358.pdf\">Using Rater and System Metadata to Explain Variance in the VoiceMOS Challenge 2022 Dataset</a><br />  Authors: <i><b>Michael Chinen</b>, <b>Jan Skoglund</b>, <b>Chandan K. A. Reddy</b>, Alessandro Ragano, Andrew Hines </i></p><p><a href=\"https://arxiv.org/pdf/2110.00155.pdf\">Incremental Layer-Wise Self-Supervised Learning for Efficient Unsupervised Speech Domain Adaptation On Device</a><br />  Authors: <i><b>Zhouyuan Huo</b>, <b>Dongseong Hwang</b>, <b>Khe Chai Sim</b>, <b>Shefali Garg</b>, <b>Ananya Misra</b>, <b>Nikhil Siddhartha</b>, <b>Trevor Strohman</b>, <b>Fran</b></i><i><b>ç</b></i><i><b>oise Beaufays</b></i></p><p>Trustworthy Speech Processing <br />  Organizers include: <b><i>Shrikanth Narayanan</i></b></p> <!--Footnotes themselves at the bottom.--> <hr width=\"80%\" /><span class=\"Apple-style-span\" style=\"font-size: x-small;\"><br />  <a name=\"1\"><sup>*</sup></a>Work done while at Google.<a href=\"#top1\"> &nbsp;<sup>↩</sup></a></span>",
  "link": [
    "",
    "",
    "",
    "",
    ""
  ],
  "author": {
    "name": "Google AI",
    "uri": "http://www.blogger.com/profile/12098626514775266161",
    "email": "noreply@blogger.com",
    "gd:image": ""
  },
  "thr:total": 0
}