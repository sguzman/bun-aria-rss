{
  "id": "tag:drsimonj.svbtle.com,2014:Post/big-data-solutions-a-b-t-test",
  "published": "2017-08-14T09:03:18-07:00",
  "updated": "2017-08-14T09:03:18-07:00",
  "link": "",
  "title": "Big Data Solutions: A/B t test",
  "content": "<p><a href=\"https://twitter.com/drsimonj\" rel=\"nofollow\">@drsimonj</a> here to share my code for using <a href=\"https://en.wikipedia.org/wiki/Welch%27s_t-test\" rel=\"nofollow\">Welch’s <em>t</em>-test</a> to compare group means using summary statistics.</p>\n<h2 id=\"motivation_2\">Motivation <a class=\"head_anchor\" href=\"#motivation_2\" rel=\"nofollow\">#</a>\n</h2>\n<p>I’ve just started working with A/B tests that use big data. Where once I’d whimsically run <code class=\"prettyprint\">t.test()</code>, now my data won’t fit into memory!</p>\n\n<p>I’m sharing my solution here in the hope that it might help others.</p>\n<h2 id=\"inmemory-data_2\">In-memory data <a class=\"head_anchor\" href=\"#inmemory-data_2\" rel=\"nofollow\">#</a>\n</h2>\n<p>As a baseline, let’s start with an in-memory case by comparing whether automatic and manual cars have different Miles Per Gallon ratings on average (using the <code class=\"prettyprint\">mtcars</code> data set).</p>\n\n<pre><code class=\"prettyprint lang-r\">t.test(mpg ~ am, data = mtcars)\n#&gt; \n#&gt;  Welch Two Sample t-test\n#&gt; \n#&gt; data:  mpg by am\n#&gt; t = -3.7671, df = 18.332, p-value = 0.001374\n#&gt; alternative hypothesis: true difference in means is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -11.280194  -3.209684\n#&gt; sample estimates:\n#&gt; mean in group 0 mean in group 1 \n#&gt;        17.14737        24.39231\n</code></pre>\n\n<p>Well… that was easy!</p>\n<h2 id=\"big-data_2\">Big Data <a class=\"head_anchor\" href=\"#big-data_2\" rel=\"nofollow\">#</a>\n</h2>\n<p>The problem with big data is that we can’t pull it into memory and work with R.</p>\n\n<p>Fortunately, we don’t need the raw data to run Welch’s <em>t</em>-test. All we need is the mean, variance, and sample size of each group. So our raw data might have billions of rows, but we only need six numbers.</p>\n\n<p>Here are the numbers we need for the previous example:</p>\n\n<pre><code class=\"prettyprint lang-r\">library(dplyr)\n\ngrp_summary &lt;- mtcars %&gt;% \n  group_by(am) %&gt;% \n  summarise(\n    mpg_mean = mean(mpg),\n    mpg_var  = var(mpg),\n    n        = n()\n  )\n\ngrp_summary\n#&gt; # A tibble: 2 x 4\n#&gt;      am mpg_mean  mpg_var     n\n#&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;int&gt;\n#&gt; 1     0 17.14737 14.69930    19\n#&gt; 2     1 24.39231 38.02577    13\n</code></pre>\n\n<p>This is everything we need to obtain a <em>t</em> value, degrees of freedom, and a <em>p</em> value.</p>\n<h3 id=\"emtem-value_3\">\n<em>t</em> value <a class=\"head_anchor\" href=\"#emtem-value_3\" rel=\"nofollow\">#</a>\n</h3>\n<p>Here we use the means, varianes, and sample sizes to compute Welch’s <em>t</em>:</p>\n\n<pre><code class=\"prettyprint lang-r\">welch_t &lt;- diff(grp_summary$mpg_mean) / sqrt(sum(grp_summary$mpg_var/grp_summary$n))\n\ncat(\"Welch's t value of the mean difference is\", welch_t)\n#&gt; Welch's t value of the mean difference is 3.767123\n</code></pre>\n\n<p>This is the same value returned by <code class=\"prettyprint\">t.test()</code>, apart from the sign (which is unimportant).</p>\n<h3 id=\"degrees-of-freedom_3\">Degrees of Freedom <a class=\"head_anchor\" href=\"#degrees-of-freedom_3\" rel=\"nofollow\">#</a>\n</h3>\n<p>Here, we use the variances and sample sizes to compute the degrees of freedom, which is estimated by the <a href=\"https://en.wikipedia.org/wiki/Welch%E2%80%93Satterthwaite_equation\" rel=\"nofollow\">Welch–Satterthwaite equation</a>:</p>\n\n<pre><code class=\"prettyprint lang-r\">welch_df &lt;- ((sum(grp_summary$mpg_var/grp_summary$n))^2) /\n            sum(grp_summary$mpg_var^2/(grp_summary$n^2 * (grp_summary$n - 1)))\n\ncat(\"Degrees of Freedom for Welch's t is\", welch_df)\n#&gt; Degrees of Freedom for Welch's t is 18.33225\n</code></pre>\n\n<p>Again, same as <code class=\"prettyprint\">t.test()</code>.</p>\n<h3 id=\"empem-value_3\">\n<em>p</em> value <a class=\"head_anchor\" href=\"#empem-value_3\" rel=\"nofollow\">#</a>\n</h3>\n<p>We can now calculate the <em>p</em> value thanks to R’s <code class=\"prettyprint\">pt()</code>. Assuming we want to conduct a two-tailed test, here’s what we need to do:</p>\n\n<pre><code class=\"prettyprint lang-r\">welch_p &lt;- 2 * pt(abs(welch_t), welch_df, lower.tail = FALSE)\n\ncat(\"p-value for Welch's t is\", welch_p)\n#&gt; p-value for Welch's t is 0.001373638\n</code></pre>\n\n<p>Same as <code class=\"prettyprint\">t.test()</code> again!</p>\n<h2 id=\"allinone-function_2\">All-in-one Function <a class=\"head_anchor\" href=\"#allinone-function_2\" rel=\"nofollow\">#</a>\n</h2>\n<p>Now we know the math, let’s write a function that takes 2-element vectors of means, variances, and sample sizes, and returns the results in a data frame:</p>\n\n<pre><code class=\"prettyprint lang-r\">welch_t_test &lt;- function(sample_means, sample_vars, sample_ns) {\n  t_val &lt;- diff(sample_means) / sqrt(sum(sample_vars/sample_ns))\n\n  df    &lt;- ((sum(sample_vars/sample_ns))^2) /\n            sum(sample_vars^2/(sample_ns^2 * (sample_ns - 1)))\n\n  p_val &lt;- 2 * pt(abs(t_val), df, lower.tail = FALSE)\n\n  data.frame(t_val = t_val,\n             df    = df,\n             p_val = p_val)\n}\n</code></pre>\n\n<pre><code class=\"prettyprint lang-r\">welch_t_test(grp_summary$mpg_mean,\n             grp_summary$mpg_var,\n             grp_summary$n)\n#&gt;      t_val       df       p_val\n#&gt; 1 3.767123 18.33225 0.001373638\n</code></pre>\n\n<p>Excellent!</p>\n<h2 id=\"back-to-big-data_2\">Back to Big Data <a class=\"head_anchor\" href=\"#back-to-big-data_2\" rel=\"nofollow\">#</a>\n</h2>\n<p>The point of all this was to help me conduct an A/B test with big data. Has it?</p>\n\n<p>Of course! I don’t pull billions of rows from my data base into memory. Instead, I create a table of the summary statistics within my big data ecosystem. These are easy to pull into memory.</p>\n\n<p>How you create this summary table will vary depending on your setup, but here’s a mock Hive/SQL query to demonstrate the idea:</p>\n\n<pre><code class=\"prettyprint lang-sql\">CREATE TABLE summary_tbl AS\n\nSELECT\n    group_var\n  , AVG(outcome)      AS outcome_mean\n  , VARIANCE(outcome) AS outcome_variance\n  , COUNT(*)          AS n\n\nFROM\n  raw_tbl\n\nGROUP BY\n  group_var\n</code></pre>\n\n<p>Happy testing!</p>\n<h2 id=\"sign-off_2\">Sign off <a class=\"head_anchor\" href=\"#sign-off_2\" rel=\"nofollow\">#</a>\n</h2>\n<p>Thanks for reading and I hope this was useful for you.</p>\n\n<p>For updates of recent blog posts, follow <a href=\"https://twitter.com/drsimonj\" rel=\"nofollow\">@drsimonj</a> on Twitter, or email me at <a href=\"mailto:drsimonjackson@gmail.com\" rel=\"nofollow\">drsimonjackson@gmail.com</a> to get in touch.</p>\n\n<p>If you’d like the code that produced this blog, check out the <a href=\"https://github.com/drsimonj/blogR\" rel=\"nofollow\">blogR GitHub repository</a>.</p>"
}