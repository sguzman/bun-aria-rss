{
  "title": "Knowledge Graphs and Causality",
  "link": "https://datasciencevademecum.com/2019/12/19/knowledge-graphs-and-causality/",
  "dc:creator": "Gianmario",
  "pubDate": "Thu, 19 Dec 2019 12:00:00 +0000",
  "category": [
    "Knowledge Graphs",
    "causality",
    "cause and effects",
    "knowledge graph",
    "thebookofwhy"
  ],
  "guid": "https://datasciencevademecum.wordpress.com/?p=2345",
  "description": "<p>Symbolic AI (or Classical AI) was one of the first branches of artificial intelligence attempting to explicitly represent human knowledge in a declarative form using symbols and rules. </p>\n<p>The post <a rel=\"nofollow\" href=\"https://datasciencevademecum.com/2019/12/19/knowledge-graphs-and-causality/\">Knowledge Graphs and Causality</a> appeared first on <a rel=\"nofollow\" href=\"https://datasciencevademecum.com\">Vademecum of Practical Data Science</a>.</p>\n",
  "content:encoded": "\n<p><em>This piece is part of a series on 2019 trends in the AI and Machine Learning industry. You can read my full thoughts on the past year in </em><a href=\"https://www.helixa.ai/blog/ai-trends-2019\"><em>this summary I wrote for the Helixa blog</em></a><em>, which also includes links to the other in-depth pieces in this series.</em></p>\n\n\n\n<p><em>&#8212;&#8212;&#8212;-</em></p>\n\n\n\n<p>Symbolic AI (or Classical AI) was one of the first branches of artificial intelligence attempting to explicitly represent human knowledge in a declarative form using symbols and rules.&nbsp;</p>\n\n\n\n<p>This process has evident limitations, such as how to explicitly define common sense knowledge and the plethora of multi-dimensional complex relationships. Deep neural networks dominate AI implementation due to their capacity to organize knowledge in implicit structures (embeddings) and hierarchical patterns.&nbsp;</p>\n\n\n\n<p>If “shallow” machine learning can learn the mapping from data representation to the output, “deep learning” can also learn the representation itself. No wonder that part of the scientific community is using the expression “representation learning” as a better expression for deep learning. One of the major scientific conferences in the field is <a href=\"https://iclr.cc/\">ICLR</a> — pronounced “eye-clear” — and it stands for International Conference on Learning Representations.</p>\n\n\n\n<p>We might conclude that we don’t need to represent knowledge in graphs explicitly anymore, but one of the hottest fields right now involves using deep learning to learn embedding representations of the base knowledge graph. By following this approach we could offer logical inference paths to support evidence for predictions. At the same time, we can use deep learning to learn the existence of new relationships between concepts, enriching the base graph, and mapping the graph representation to the final output required by the task we want to solve.</p>\n\n\n\n<p>A great example of this methodology is “<a href=\"https://blog.grakn.ai/kgcns-machine-learning-over-knowledge-graphs-with-tensorflow-a1d3328b8f02\">KGCN: Knowledge Graph Convolution Networks</a>” implemented by Grakn. This novel algorithm, inspired by a few concepts of language models, learns embedding representations while predicting neighbors, starting from an incomplete subgraph.&nbsp;</p>\n\n\n\n<figure class=\"wp-block-image size-large\"><img decoding=\"async\" loading=\"lazy\" width=\"624\" height=\"376\" src=\"https://i0.wp.com/datasciencevademecum.com/wp-content/uploads/2019/12/s4vswPzsvgvW8QL0PFLoroA.png?resize=624%2C376&#038;ssl=1\" alt=\"graph embedding\" class=\"wp-image-2375\" srcset=\"https://i0.wp.com/datasciencevademecum.com/wp-content/uploads/2019/12/s4vswPzsvgvW8QL0PFLoroA.png?w=624&ssl=1 624w, https://i0.wp.com/datasciencevademecum.com/wp-content/uploads/2019/12/s4vswPzsvgvW8QL0PFLoroA.png?resize=300%2C181&ssl=1 300w\" sizes=\"(max-width: 624px) 100vw, 624px\" data-recalc-dims=\"1\" /></figure>\n\n\n\n<p>Other similar works are: “<a href=\"https://arxiv.org/abs/1904.12575\">Knowledge Graph Convolutional Networks for Recommender Systems</a>”, “<a href=\"https://torchbiggraph.readthedocs.io/en/latest/\">Pytorch BigGraph: A large-scale graph embedding system</a>”, and “<a href=\"https://arxiv.org/abs/1802.08773\">GraphRNN: Generating Realistic Graphs with Deep Auto-regressive Models</a>”.</p>\n\n\n\n<p>Another important commercial application is the virtual assistant Einstein, developed by Salesforce, which is able to explain question answering using what they call “<a href=\"https://www.zdnet.com/article/salesforce-research-knowledge-graphs-and-machine-learning-to-power-einstein/\">symbolic compositionality of knowledge graph relations in embedding approaches</a>”.</p>\n\n\n\n<figure class=\"wp-block-image size-large\"><img decoding=\"async\" loading=\"lazy\" width=\"624\" height=\"330\" src=\"https://i0.wp.com/datasciencevademecum.com/wp-content/uploads/2020/04/sv_HVQ3-Bl5OUP6AGQZJ64w.png?resize=624%2C330&#038;ssl=1\" alt=\"\" class=\"wp-image-2377\" srcset=\"https://i0.wp.com/datasciencevademecum.com/wp-content/uploads/2020/04/sv_HVQ3-Bl5OUP6AGQZJ64w.png?w=624&ssl=1 624w, https://i0.wp.com/datasciencevademecum.com/wp-content/uploads/2020/04/sv_HVQ3-Bl5OUP6AGQZJ64w.png?resize=300%2C159&ssl=1 300w\" sizes=\"(max-width: 624px) 100vw, 624px\" data-recalc-dims=\"1\" /></figure>\n\n\n\n<p>I would like to conclude this post with an <a href=\"https://www.wired.com/story/ai-pioneer-algorithms-understand-why/\">interview with Yoshua Bengio</a>, Professor at the University of Montreal and pioneer of deep learning research and 2018 Turing Award winner. The interview covers the importance of integrating causality into AI. What Bengio claims is that deep learning, the currently most advanced implementation of AI, is substantially blind to cause and effects and focuses primarily on correlations in the observed data.&nbsp;</p>\n\n\n\n<p>Understanding the “why” would make AI systems smarter and more efficient. We could see a system that is able to learn from fewer examples and generalize to unseen circumstances, just like human intelligence does. For more on this topic, I would suggest <a href=\"https://www.penguin.co.uk/books/289/289825/the-book-of-why/9780141982410.html\">The Book of Why</a> by J Pearl and D. Mackenzie.</p>\n\n\n\n<p>What we might see in 2020 and the following years is a shift from “improving accuracy on test benchmarks” to “re-designing algorithms around causal reasoning”.</p>\n\n\n\n<p>&#8212;&#8212;&#8212;-</p>\n\n\n\n<p><em>For curious, AI-focused professionals who want to innovate responsibly, Helixa derives complex human insights through ethical and intentional machine learning. We do this more effectively than anyone else by aggregating multiple data sources, prioritizing consumer privacy, and returning results in seconds. Visit </em><a href=\"http://www.helixa.ai\"><em>www.helixa.ai</em></a><em> to learn more.</em></p>\n<p>The post <a rel=\"nofollow\" href=\"https://datasciencevademecum.com/2019/12/19/knowledge-graphs-and-causality/\">Knowledge Graphs and Causality</a> appeared first on <a rel=\"nofollow\" href=\"https://datasciencevademecum.com\">Vademecum of Practical Data Science</a>.</p>\n",
  "post-id": 2345
}