{
  "id": "tag:blogger.com,1999:blog-5547907074344788039.post-7452195429120354320",
  "published": "2013-09-08T20:07:00.000-07:00",
  "updated": "2013-09-08T20:37:12.744-07:00",
  "title": "Matching misspelled brand names -- the easy way",
  "content": "On Friday, <a href=\"http://www.warbyparker.com/\">Warby Parker</a>'s Director of Consumer Insights approached me with some data. They had sent out a survey one question of which was \"list up to five eyeglass brands you are familiar with.\" She was wanting to aggregate the data but, being free text, the answers were riddled with misspellings. Manually, it would take a lot of time and effort to resolve the variants. She asked if there was a better way to standardize them.<br /><br />With a question like this, your first reaction might be to think of regular expressions. While there are common forms of misspelling such as transposed characters (ie &lt;--&gt; ei) and (un)doubled consonants (Cincinnati, Mississippi), this is not a tenable approach. First, you are not going to capture all of the variants, common and uncommon. Second, brand names are not necessarily dictionary words and so may not follow normal spelling rules.<br /><br />If we had a set of target brands, we might be able to use <a href=\"http://en.wikipedia.org/wiki/Edit_distance\">edit distance</a> to associate some variants but \"d+g\" is very far away from \"Dolce &amp; Gabbana\". That won't work. Besides, we don't have a limited list of brands. This is an open-ended question and gives rise to open ended results. For instance, Dale Earnhardt Jr has a line of glasses (who knew?) and appeared in our results.<br /><br />To get a sense of the problem, &nbsp;here are the variants of just <a href=\"http://usa.tommy.com/webapp/wcs/stores/servlet/en/thb2cus\">Tommy Hilfiger</a> in our dataset:<br /><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><b>tommy helfinger</b></span><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><b>tommy hf</b></span><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><b>tommy hildfigers</b></span><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><b>tommy hilfger</b></span><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><b>tommy hilfieger</b></span><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><b>tommy hilfigar</b></span><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><b>tommy hilfiger</b></span><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><b>tommy hilfigger</b></span><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><b>tommy hilfigher</b></span><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><b>tommy hilfigur</b></span><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><b>tommy hilfigure</b></span><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><b>tommy hilfiinger</b></span><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><b>tommy hilfinger</b></span><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><b>tommy hilifiger</b></span><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><b>tommy hillfiger</b></span><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><b>tommy hillfigger</b></span><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><b>tommy hillfigur</b></span><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><b>tommy hillfigure</b></span><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><b>tommy hillfinger</b></span><br /><br />Even if it kind of worked and you could resolve the easy cases, leaving the remainder to resolve manually, it still is not desirable. We want to run this kind of survey at regular intervals and I'm lazy: I want to write code for the whole problem once and rerun multiple times later. Set it and forget it.<br /><br />This kind of problem is something that search engines contend with all the time. So, what would google do? They have a sophisticated set of algorithms which associate document content and especially link text with target websites. They also have a ton of data and can reach out along the long tail of these variants. For my purposes, however, it doesn't matter how they do it but whether I can piggyback off their efforts.<br /><br />Here was my solution to the problem:<br /><br />If I type in \"Diane von Burstenburg\" into google, it returns,<br /><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><b>Showing results for Diane von Furstenberg</b></span><br /><div><br /></div>and the top result is for <a href=\"http://dvf.com/\">dvf.com</a>. This is precisely the behavior I want. It will map all of those Tommy Hilfiger variants to the same website.<br /><br />We now have a reasonable approach. What about implementation? Google has really locked down API access. Their old JSON API is deprecated but is still available but limited to 100 queries per day. (I used pygoogle to query it easily with<br /><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><b>&gt;&gt;&gt; from pygoogle import pygoogle</b></span><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><b>&gt;&gt;&gt; g = pygoogle('ray ban')</b></span><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><b>&gt;&gt;&gt; g.pages = 1</b></span><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><b>&gt;&gt;&gt; g.get_urls()[0]</b></span><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><b>u'http://www.ray-ban.com/'</b></span><br /><div><br /></div><div>but was shut down by google within minutes). Even if you <a href=\"http://www.gnu.org/software/wget/\">wget</a> their results pages, it doesn't even contain the search results as they are all ajaxed in. I didn't want to pay for API access to their results for a small one off project so went looking elsewhere. DuckDuckGo has a nice JSON API but its results are limited. I didn't feel like parsing Bing's results page. Yahoo (+&nbsp;<a href=\"http://www.crummy.com/software/BeautifulSoup/\">BeautifulSoup</a> + ulrlib) saves the day!</div><div><span style=\"font-family: inherit; line-height: 17px;\"><br /></span></div><div><span style=\"font-family: inherit; line-height: 17px;\">The following works well, albeit slowly due to my rate limiting (sleep for 15 seconds):</span></div><span style=\"background-color: white; font-family: Arial, FreeSans, Helvetica, sans-serif; font-size: 13px; line-height: 17px;\"><br /></span><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><span style=\"line-height: 17px;\"><b>from bs4 import BeautifulSoup</b></span></span><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><span style=\"line-height: 17px;\"><b>import urllib</b></span></span><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><span style=\"line-height: 17px;\"><b>import time</b></span></span><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><span style=\"line-height: 17px;\"><b>import urlparse</b></span></span><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><span style=\"line-height: 17px;\"><b><br /></b></span></span><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><span style=\"line-height: 17px;\"><b>f_out = open(\"output_terms.tsv\",\"w\") #list of terms, one per line</b></span></span><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><span style=\"line-height: 17px;\"><b>f = open(\"terms.txt\",\"r\")</b></span></span><br /><span style=\"line-height: 17px;\"><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><b>for line in f.readlines():</b></span></span><br /><span style=\"line-height: 17px;\"><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><b>&nbsp; &nbsp; term = line.strip()</b></span></span><br /><span style=\"line-height: 17px;\"><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><b>&nbsp; &nbsp; try:</b></span></span><br /><span style=\"line-height: 17px;\"><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><b>&nbsp; &nbsp; &nbsp; &nbsp; print term</b></span></span><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><b><span style=\"line-height: 17px;\">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;f = urllib.urlopen(\"http://search.yahoo.com/search?p=\" + \"\\\"\" + term +\"\\\"\")&nbsp;</span></b></span><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><span style=\"line-height: 17px;\"><b>&nbsp; &nbsp; &nbsp; &nbsp; soup = BeautifulSoup(f)</b></span></span><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><span style=\"line-height: 17px;\"><b>&nbsp; &nbsp; &nbsp; &nbsp; link = soup.find(\"a\", {\"id\": \"link-1\"})['href']</b></span></span><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><span style=\"line-height: 17px;\"><b>&nbsp; &nbsp; &nbsp; &nbsp; parsed_uri = urlparse.urlparse( link )</b></span></span><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><span style=\"line-height: 17px;\"><b>&nbsp; &nbsp; &nbsp; &nbsp; domain = '{uri.scheme}://{uri.netloc}/'.format(uri=parsed_uri)</b></span></span><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><span style=\"line-height: 17px;\"><b>&nbsp; &nbsp; &nbsp; &nbsp; f_out.write( term + \"\\t\" + link + \"\\t\" + domain + \"\\n\")</b></span></span><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><span style=\"line-height: 17px;\"><b>&nbsp; &nbsp; &nbsp; &nbsp; time.sleep(15)</b></span></span><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><span style=\"line-height: 17px;\"><b>&nbsp; &nbsp; except TypeError:</b></span></span><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><span style=\"line-height: 17px;\"><b>&nbsp; &nbsp; &nbsp; &nbsp;print \"ERROR with\" + term</b></span></span><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><span style=\"line-height: 17px;\"><b><br /></b></span></span><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><span style=\"line-height: 17px;\"><b>f.close()</b></span></span><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><b><span style=\"background-color: white; line-height: 17px;\"></span></b></span><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><span style=\"line-height: 17px;\"><b>f_out.close()</b></span></span><br /><br />where&nbsp;<b style=\"color: #3d85c6; font-family: 'Courier New', Courier, monospace; font-size: small; line-height: 17px;\">output_terms.tsv&nbsp;</b>was the set of unique terms after I lowercased each term, remove hyphens, ampersands and \" and \".<br /><br />This code outputs rows such as:<br /><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><b>under amour<span class=\"Apple-tab-span\" style=\"white-space: pre;\"> </span>http://www.underarmour.com/shop/us/en/<span class=\"Apple-tab-span\" style=\"white-space: pre;\"> </span>http://www.underarmour.com/</b></span><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><b>under armer<span class=\"Apple-tab-span\" style=\"white-space: pre;\"> </span>http://www.underarmour.com/shop/us/en/<span class=\"Apple-tab-span\" style=\"white-space: pre;\"> </span>http://www.underarmour.com/</b></span><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><b>under armor<span class=\"Apple-tab-span\" style=\"white-space: pre;\"> </span>http://www.underarmour.com/shop/us/en/<span class=\"Apple-tab-span\" style=\"white-space: pre;\"> </span>http://www.underarmour.com/</b></span><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><b>under armour<span class=\"Apple-tab-span\" style=\"white-space: pre;\"> </span>http://www.underarmour.com/shop/us/en/<span class=\"Apple-tab-span\" style=\"white-space: pre;\"> </span>http://www.underarmour.com/</b></span><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><b>underarmor<span class=\"Apple-tab-span\" style=\"white-space: pre;\"> </span>http://www.underarmour.com/shop/us/en/<span class=\"Apple-tab-span\" style=\"white-space: pre;\"> </span>http://www.underarmour.com/</b></span><br /><div><br /></div>It is not perfect by any means. Those Tommy Hilfiger variants result in a mix of tommy.com and tommyhilfiger.com, which is Hilfiger's fault for having confusing / poor SEO. More importantly, about 10% of the the results map to wikipedia:<br /><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><b>karl lagerfeld<span class=\"Apple-tab-span\" style=\"white-space: pre;\"> </span>http://en.wikipedia.org/wiki/Karl_Lagerfeld</b></span><br /><br />For these, I did<br /><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><b>cat output_terms.tsv | grep wikipedia | awk -F '\\t' '{print $1}' &gt; wikipediaterms.txt</b></span><br /><br />and reran these through my code using this query instead:<br /><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><b>f = urllib.urlopen(\"http://search.yahoo.com/search?p=\" + \"\\\"\" + term +\"\\\"\" + \"-wikipedia\")</b></span><br /><br />This worked well and Lagerfeld now maps to<br /><br /><span style=\"color: #3d85c6; font-family: Courier New, Courier, monospace;\"><b>karl lagerfeld<span class=\"Apple-tab-span\" style=\"white-space: pre;\"> </span>http://www.karl.com/<span class=\"Apple-tab-span\" style=\"white-space: pre;\"> </span>http://www.karl.com/</b></span><br /><div><br /></div><div>(There are of course still errors: Catherine Deneuve maps to&nbsp;http://www.imdb.com/name/nm0000366/<span class=\"Apple-tab-span\" style=\"white-space: pre;\"> </span>http://www.imdb.com/, a perfectly reasonable response. I tried queries with '\"<i>searchterm\"</i> +glasses' for greater context but the overall results were not great. With that I got lots of ebay links appearing.)</div><div><br /></div>Now I have a hands-free process that seems to captures most of the variants and has trouble mostly only on low frequency, seemingly genuinely ambiguous cases. This can easily be run and rerun for future surveys. Laziness for the win! I don't even care if it fails to swap out very uncommon variants because in this case we don't need perfect data. We will aggregate the websites and filter out anything with frequency less than say X so those odd terms this process got wrong, we don't need to worry about. In other words, we care most about the first few bars of our ordered histogram.<br /><br />Data scientists need to be good at lateral thinking. One skill is not to focus too much on the perfect algorithmic solution to a problem but, when possible, find a quick, cheap and dirty solution that gets you what you want. If that means a simple hack to piggyback of a huge team of search engine engineers and their enormous corpus, so much the better.<br /><br /><br />",
  "link": [
    "",
    "",
    "",
    "",
    ""
  ],
  "author": {
    "name": "Carl Anderson",
    "uri": "http://www.blogger.com/profile/11930448254473684406",
    "email": "noreply@blogger.com",
    "gd:image": ""
  },
  "thr:total": 4
}