{
  "title": "Thoughts on Trace Estimation in Deep Learning",
  "link": "",
  "published": "2022-08-09T19:00:00+01:00",
  "updated": "2022-08-09T19:00:00+01:00",
  "author": {
    "name": "Sebastian Nowozin"
  },
  "id": "tag:www.nowozin.net,2022-08-09:/sebastian/blog/thoughts-on-trace-estimation-in-deep-learning.html",
  "summary": "<p>Efficiently estimating the <em>trace</em> <span class=\"math\">\\(\\textrm{tr}(A) = \\sum_{i=1}^d A_{ii}\\)</span> of a\nsquare matrix <span class=\"math\">\\(A \\in \\mathbb{R}^{d \\times d}\\)</span> is an important problem required\nin a number of recent deep learning and machine learning models â€¦</p>",
  "content": "<p>Efficiently estimating the <em>trace</em> <span class=\"math\">\\(\\textrm{tr}(A) = \\sum_{i=1}^d A_{ii}\\)</span> of a\nsquare matrix <span class=\"math\">\\(A \\in \\mathbb{R}^{d \\times d}\\)</span> is an important problem required\nin a number of recent deep learning and machine learning models.  In those\ncases the matrix <span class=\"math\">\\(A\\)</span> is typically\n<a href=\"https://en.wikipedia.org/wiki/Definite_matrix\">positive-definite</a>, large and\ndense.</p>\n<p>As a sample of recent occurences of needing to compute the trace of large\nmatrices in machine learning, I picked the following applications.</p>\n<ul>\n<li><strong>Continuous normalizing flows</strong>, as in diffusion models <a href=\"https://arxiv.org/pdf/2011.13456.pdf\">(Song et al., ICLR\n  2021)</a>, FFJORD <a href=\"https://arxiv.org/pdf/1810.01367.pdf\">(Grathwohl et al., ICLR\n  2019)</a> and Neural ODEs <a href=\"https://proceedings.neurips.cc/paper/2018/file/69386f6bb1dfed68692a24c8686939b9-Paper.pdf\">(Chen et al.,\n  NeurIPS 2018)</a>,\n  where an initial sample <span class=\"math\">\\(x(0) \\sim p_0\\)</span> is continuously transformed by a function, i.e.\n  <span class=\"math\">\\(\\partial x(t)/\\partial t = f(x(t),t)\\)</span> from <span class=\"math\">\\(t=0\\)</span> to <span class=\"math\">\\(t=1\\)</span>.\n  To evaluate <span class=\"math\">\\(\\log p(x(1))\\)</span> we need to rely on the <em>instantaneous change of variable</em> formula,\n  <div class=\"math\">$$\\frac{\\partial \\log p(x(t))}{\\partial t} = -\\textrm{tr}\\left(\n  \\frac{\\partial f}{\\partial x(t)}\\right),$$</div>\n  such that the log-probability is determined by\n  <div class=\"math\">$$\\log p(x(1)) = \\log p(x(0)) - \\int_0^1 \\textrm{tr}\\left(\n  \\frac{\\partial f}{\\partial x(t)}\\right)\\,\\textrm{d}t.$$</div>\n  Computing the trace of the <a href=\"https://en.wikipedia.org/wiki/Jacobian_matrix_and_determinant\">Jacobian <span class=\"math\">\\(\\frac{\\partial f}{\\partial x(t)}\\)</span></a> is the computational bottleneck.</li>\n<li><strong>Efficient Gaussian Process evidence computation</strong>. <a href=\"https://proceedings.mlr.press/v162/wenger22a/wenger22a.pdf\">(Wenger et al., ICML\n  2022)</a>, where\n  trace estimation is used to estimate the log-marginal likelihood, and the\n  matrix <span class=\"math\">\\(A\\)</span> is a <a href=\"https://en.wikipedia.org/wiki/Positive-definite_kernel\">kernel matrix</a>.</li>\n<li><strong>Approximating log-determinants in invertible ResNets</strong>.  <a href=\"https://arxiv.org/pdf/1811.00995.pdf\">(Behrmann et al.,\n  2018)</a> propose a variant of ResNet\n  blocks that is invertible by constraining the Lipschitz-constant of the ResNet\n  block update to be smaller than one.  Once invertible the ResNet block can be\n  used for generative modelling via a normalizing flow model.  That is, we sample\n  <span class=\"math\">\\(x_0 \\sim p_0\\)</span> from a simple prior <span class=\"math\">\\(p_0\\)</span> and then map <span class=\"math\">\\(f(x_0)\\)</span> to the target\n  density.  To compute log-likelihoods for a given <span class=\"math\">\\(x\\)</span> we invert the map and\n  compute <span class=\"math\">\\(\\log p(x) = \\log p_0(f^{-1}(x)) + \\log |\\det J_{f^{-1}}(x)|\\)</span>.\n  By exploiting the structure of the <span class=\"math\">\\(i\\)</span>'th ResNet block, <span class=\"math\">\\(f_i(x) = x +\n  g_i(x)\\)</span>, and the Lipschitz constraint on <span class=\"math\">\\(g_i\\)</span>, the log-determinant\n  computation can be reduced to a convergent power series,\n  <span class=\"math\">\\(\\textrm{tr}(\\log (I + J_g(x))) = \\sum_{k=1}^{\\infty} \\frac{(-1)^{k+1}}{k} \\textrm{tr}(J^k_g).\\)</span>\n  Without going into detail, Behrmann et al. truncate the power series and\n  compute the trace terms using Hutchinson's trace estimator, thus are able to\n  use invertible ResNets for generative modelling.\n  The same group, in <a href=\"https://arxiv.org/pdf/1906.02735.pdf\">(Chen et al.,\n  2019)</a>, improve on the finite truncation\n  by using stochastic truncation in the form of <em>Russian roulette estimators</em>,\n  managing to create unbiased estimates, again using trace estimation for each\n  term of the power series.   (If you hear the term \"Russian\n  roulette estimator\" for the first time, it is a quite general technique that is\n  worth knowing about; a good self-contained brief introduction and history of\n  randomized series truncation can be found in section 2.1 and 2.2 of <a href=\"http://proceedings.mlr.press/v97/beatson19a/beatson19a.pdf\">(Beatson\n  and Adams, 2019)</a>.)</li>\n<li><strong>Regularizing continuous dynamics</strong>. <a href=\"http://proceedings.mlr.press/v119/finlay20a/finlay20a.pdf\">(Finlay et al., ICML\n  2020)</a> regularize\n  the <a href=\"https://en.wikipedia.org/wiki/Matrix_norm#Frobenius_norm\">Frobenius norm</a>\n  <span class=\"math\">\\(\\|A\\|_F^2 = \\textrm{tr}(A^T A)\\)</span> of the Jacobian of a neural ODE leading to\n  smoother dynamics and fewer adaptive integrator steps.</li>\n<li><strong>Neural network quantization layer-wise sensitivity metric</strong>.\n  <a href=\"https://proceedings.neurips.cc/paper/2020/file/d77c703536718b95308130ff2e5cf9ee-Paper.pdf\">(Dong et al., NeurIPS 2020)</a> and <a href=\"https://arxiv.org/pdf/2008.08284.pdf\">(Qian et al., 2020)</a> use the\n  trace-of-Hessian of parameters belonging to the same neural network layer to\n  allocate the quantization fidelity needed.\n  Such a <em>trace-of-Hessian</em> regularization is also effectively used in one of\n  the early papers on energy-based models, <a href=\"https://proceedings.neurips.cc/paper/2010/file/6f3e29a35278d71c7f65495871231324-Paper.pdf\">(Kingma and Le Cun,\n  2010)</a>,\n  there it is used to regularize the curvature of learned energy functions.\n  The diagonal of the Hessian is a natural local sensitivity measure and\n  perhaps the earliest use in neural networks is in the classic <em>optimal brain\n  damage</em> sensitivity metric of <a href=\"https://proceedings.neurips.cc/paper/1989/file/6c9882bbac1c7093bd25041881277658-Paper.pdf\">(Le Cun et al., 1989)</a>,\n  which used second derivatives for each parameter to determine deletion\n  of neurons.</li>\n<li><strong>Sliced score matching</strong>.  <a href=\"https://www.jmlr.org/papers/volume6/hyvarinen05a/hyvarinen05a.pdf\">(Hyvarinen, JMLR\n  2005)</a>\n  introduced <em>score matching</em> as a learning objective for energy-based models,\n  <span class=\"math\">\\(p(x) \\propto \\exp(-E(x))\\)</span>, and in the score matching objective a sum of\n  second derivates of the energy function needs to be evaluated,\n  <span class=\"math\">\\(\\sum_{i=1}^d \\partial^2 E(x) / (\\partial x_i)^2\\)</span>.  Because evaluating these\n  second-order derivates is expensive this limited the applicability of score\n  matching until <a href=\"http://proceedings.mlr.press/v115/song20a/song20a.pdf\">(Song et al., UAI\n  2020)</a> introduced\n  <em>sliced score matching</em> where the expensive term is replaced by a stochastic estimate\n  <span class=\"math\">\\(\\mathbb{E}_z\\left[\\sum_{i=1}^d \\sum_{j=1}^d \\frac{\\partial^2 E(x)}{\\partial x_i \\, \\partial x_j} z_i z_j\\right]\\)</span>, i.e. a Hutchinson estimate of the trace of the Hessian of <span class=\"math\">\\(E\\)</span>.\n  For a great overview of these techniques see the recent review by <a href=\"https://arxiv.org/pdf/2101.03288.pdf\">(Song and\n  Kingma, 2021)</a>.</li>\n</ul>\n<p>What is the shared difficulty in all of the above applications?\nAfter all, computing the trace of an <em>explicitly given matrix</em> <span class=\"math\">\\(A\\)</span> is trivial:\nsimply sum the diagonal elements,</p>\n<div class=\"math\">$$\\textrm{tr}(A) := \\sum_i A_{ii}.$$</div>\n<p>However, in the above applications arising in deep learning the problem is that\nit is very expensive to compute <span class=\"math\">\\(A\\)</span> explicitly, but we <em>can</em> query\nmatrix-vector products efficiently.  Given <span class=\"math\">\\(z \\in \\mathbb{R}^d\\)</span>, we can\nefficiently compute</p>\n<div class=\"math\">$$y = A \\, z.$$</div>\n<p>Clearly, if we are able to compute many such products, say <span class=\"math\">\\(d\\)</span> times, we can\nreconstruct the matrix <span class=\"math\">\\(A\\)</span> completely.  The simplest example is to take\n<span class=\"math\">\\(z^{(m)} := e_m\\)</span>, the natural basis vectors in <span class=\"math\">\\(\\mathbb{R}^d\\)</span>, such that\n<span class=\"math\">\\(y^{(m)} = A \\, z^{(m)}\\)</span> directly extracts the <span class=\"math\">\\(m\\)</span>'th row of the matrix.  By\nextracting all rows we could obtain <span class=\"math\">\\(A\\)</span> in explicit forms.</p>\n<p>The drawback of this technique is that performing many matrix-vector\nmultiplications is expensive, where typically each matrix-vector product\ncorresponds to one forward-backprop operation in a neural network.\nIs there a better way, requiring only a <em>small</em> number of matrix-vector\nproducts to obtain an accurate <em>estimate</em> of the trace of <span class=\"math\">\\(A\\)</span>?</p>\n<p>Yes, and we will discuss the main technique below.  But first, to add more\nexcitement to our goal: if the problem of trace estimation is amenable, a\nnumber of related problems are also in reach using extended methods such as\nvariants of conjugate gradients <a href=\"https://link.springer.com/chapter/10.1007/978-94-015-7860-8_48\">(Seeger,\n2000)</a> and the\n<em>stochastic Lanczos quadrature</em> method of <a href=\"https://shashankaubaru.github.io/Papers/Lanc_Quad.pdf\">(Ubaru et al.,\n2017)</a> which allows\nefficient estimation of functions of the form</p>\n<div class=\"math\">$$\\textrm{tr}(f(A)),$$</div>\n<p>where <span class=\"math\">\\(f: \\mathbb{R} \\to \\mathbb{R}\\)</span> is a scalar function and\n<span class=\"math\">\\(\\textrm{tr}(f(\\cdot))\\)</span> is the resulting <a href=\"https://en.wikipedia.org/wiki/Trace_inequality#Trace_function\">trace\nfunction</a>,\n<span class=\"math\">\\(\\textrm{tr}(f(A)) := \\sum_{i=1}^d f(\\lambda_i(A))\\)</span>.  Through different choices\nof <span class=\"math\">\\(f\\)</span> trace functions enable estimation of other quantities,</p>\n<ul>\n<li><em>Log-determinants</em>,\n  <span class=\"math\">\\(\\log \\det(A) = \\textrm{tr}(\\log(A)) = \\sum_{i=1}^d \\log(\\lambda_i)\\)</span>.</li>\n<li><em>Nuclear norm</em>, for <span class=\"math\">\\(X \\in \\mathbb{R}^{k \\times d}\\)</span> defined as <span class=\"math\">\\(\\|X\\|_*\n  = \\textrm{tr}(\\sqrt{X^T X})\\)</span>, and more general <em>Schatten <span class=\"math\">\\(p\\)</span>-norms</em>.</li>\n<li><em>Trace of <span class=\"math\">\\(A^{-1}\\)</span></em>, where <span class=\"math\">\\(\\textrm{tr}(A^{-1}) = \\textrm{tr}(f(A))\\)</span> with <span class=\"math\">\\(f(t)=1/t\\)</span>.</li>\n</ul>\n<p>As we will see below, another quantity that can be estimated using\nHutchinson-style estimators is the <em>diagonal</em> of a matrix <span class=\"math\">\\(A\\)</span>.</p>\n<h2>Skilling-Hutchinson 1989 trace estimator</h2>\n<p>The estimator appeared in two works in parallel.\nIn his original 1989 paper, <a href=\"https://www.tandfonline.com/doi/abs/10.1080/03610918908812806?journalCode=lssp20\">(Hutchinson, \"A Stochastic Estimator of the Trace\nof the Influence Matrix for Laplacian Smoothing Splines\",\n1989)</a>,\nHutchinson introduced the first stochastic estimator of the matrix trace, and\nsimultaneously John Skilling introduced the same technique in <a href=\"https://link.springer.com/chapter/10.1007/978-94-015-7860-8_48\">(Skilling, \"The\nEigenvalues of Mega-dimensional Matrices\",\n1989)</a>.</p>\n<p>The Skilling-Hutchinson trace estimator is not just historially interesting; it\nis still the most common method used today due to its general applicability and\nsimplicity of implementation.</p>\n<p><strong>Skilling-Hutchinson's trace estimate:</strong>\nIf <span class=\"math\">\\(z \\in \\mathbb{R}^{d}\\)</span> is a random vector satisfying\n<span class=\"math\">\\(\\mathbb{E}[z z^T] = I\\)</span>, then</p>\n<div class=\"math\">$$\\mathbb{E}[z^T A z] = \\textrm{tr}(A).$$</div>\n<p>The Skilling-Hutchinson estimator is</p>\n<div class=\"math\">$$\\hat{T}_{\\cdot,M}(A) := \\frac{1}{M} \\sum_{m=1}^M (z^{(m)})^T A\\, z^{(m)},$$</div>\n<p>where <span class=\"math\">\\(z^{(m)}\\)</span> are random vectors satisfying the above condition.  In\nHutchinson's original estimator these vectors are <em>Rademacher vectors</em> with\nelements iid in <span class=\"math\">\\(\\{-1,1\\}\\)</span> and we write <span class=\"math\">\\(\\hat{T}_{H,M}\\)</span>, but the term\n<em>Hutchinson's trace estimator</em> is also commonly used nowadays if standard\nNormal vectors are used in the <em>Gaussian trace estimator</em> <span class=\"math\">\\(\\hat{T}_{G,M}\\)</span>.</p>\n<p>The Skilling-Hutchinson estimator is <em>unbiased</em>, meaning\n<span class=\"math\">\\(\\mathbb{E}[\\hat{T}_{\\cdot,M}(A)] = \\textrm{tr}(A)\\)</span>.\nMoreover, it is known that for standard Normal vectors we have</p>\n<div class=\"math\">$$\\mathbb{V}[\\hat{T}_{G,M}(A)] = \\frac{2}{M} \\|A\\|_F^2 = \\frac{2}{M} \\sum_{i=1}^d \\lambda^2_i(A),$$</div>\n<p>where <span class=\"math\">\\(\\lambda_i(A)\\)</span> is the <span class=\"math\">\\(i\\)</span>'th Eigenvalue of <span class=\"math\">\\(A\\)</span>.\nFor Rademacher vectors it is known that</p>\n<div class=\"math\">$$\\mathbb{V}[\\hat{T}_{H,M}(A)] = \\frac{2}{M} \\left(\\|A\\|_F^2 - \\sum_{i=1}^d A_{ii}^2\\right).$$</div>\n<p>You can see that using Rademacher vectors has provably smaller variance than\nusing Gaussian vectors,</p>\n<div class=\"math\">$$\\mathbb{V}[\\hat{T}_{H,M}(A)] \\leq \\mathbb{V}[\\hat{T}_{G,M}(A)].$$</div>\n<p>There is a wealth of theory available for the estimator, and a good recent\nentry point into known results is <em>Maciej Skorksi</em>'s paper \"A Modern Analysis\nof Hutchinson's Trace Estimator\" from 2020\n(<a href=\"https://arxiv.org/pdf/2012.12895.pdf\">PDF</a>).\nIn it he gives a error bound for the Rademacher version, using the <em>relative\nerror</em></p>\n<div class=\"math\">$$\\textrm{err}(\\hat{T}_{H,M}, A) := \\frac{\\hat{T}_{H,M}(A)}{\\textrm{tr}(A)}-1.$$</div>\n<p>For this error and for any <span class=\"math\">\\(d \\geq 2\\)</span> he gives the tail bound for any <span class=\"math\">\\(0 &lt;\n\\varepsilon &lt; 3/8\\)</span> of the form</p>\n<div class=\"math\">$$P(|\\textrm{err}(\\hat{T}_{H,M}, A)| \\geq \\varepsilon)\n\\leq \\exp\\left(-\\frac{M \\varepsilon^2}{2(1-8/3\\varepsilon)}\\right).$$</div>\n<h2>Praise for Hutchinson's estimator</h2>\n<p>There is a lot of good to say about Hutchinson's trace estimator:</p>\n<p><em>It is simple</em>: the estimator is easy to understand and implement.  It is free\nfrom exotic ingredients, uses just basic linear algebra, and does not make\nstrong assumptions thus is widely applicable.  Because it is simple it works\nwell with auto-differentiation.</p>\n<p><em>Linear trade-off <span class=\"math\">\\(M\\)</span></em>: Hutchinson's estimator comes with a free choice of <span class=\"math\">\\(M\n\\geq 1\\)</span>, the number of matrix-vector products to evaluate.  The parameter <span class=\"math\">\\(M\\)</span>\nlinearly controls both variance and computational effort with the estimator\nbecoming exact for <span class=\"math\">\\(M \\to \\infty\\)</span>.</p>\n<p><em>Parallelizable</em>: for larger values of <span class=\"math\">\\(M\\)</span> all evaluations can be done in\nparallel, i.e. the sequential compute depth does not increase for more\naccurate estimates.</p>\n<p><em>Unbiasedness</em>: for any <span class=\"math\">\\(M \\geq 1\\)</span> the estimator is unbiased.  How valuable is\nan unbiased estimator?  In general whether an estimator is unbiased or not may\nnot matter (see <em>Andrew Gelman's</em> points\n<a href=\"https://statmodeling.stat.columbia.edu/2011/10/15/the-bias-variance-tradeoff/\">here</a>\nand\n<a href=\"https://statmodeling.stat.columbia.edu/2015/05/11/theres-no-such-thing-as-unbiased-estimation-and-its-a-good-thing-too/\">here</a>).\nBut our situation here is special for two reasons: 1. there is an exact\nquantity of interest, <span class=\"math\">\\(\\textrm{tr}(A)\\)</span>, and our estimation is done only for\ncomputational benefits; and 2. for most deep learning applications it is\nincredibly important: it allows iterative stochastic optimization algorithms to\nwork correctly and to asymptotically average out estimator variance.</p>\n<p>So is all good then with Hutchinson's estimator?</p>\n<h2>Problems of Hutchinson's estimator</h2>\n<p>Despite singing the praise just now, the estimator has a number of fundamental\nproblems as well.</p>\n<p><em>High Monte Carlo variance</em>: the estimator has a decaying variance at rate <span class=\"math\">\\(O(1/M)\\)</span>\narising from taking the average of <span class=\"math\">\\(M\\)</span> estimates.  To see why this is a bad\nrate, consider the case where we take <span class=\"math\">\\(M=d\\)</span>, and we take Normal vectors\n<span class=\"math\">\\(z^{(m)} \\sim \\mathcal{N}_d(0,I)\\)</span>.  We then could recover the exact matrix <span class=\"math\">\\(A\\)</span>\nand thus its trace without any uncertainty.  Hutchinson would still offer us\nonly a <span class=\"math\">\\(1/d\\)</span> decrease in variance and hence does not use all information\ncontained in our measurements.</p>\n<p>The analysis from Skorski reflects this hungryness for large sample sizes.\nSkorksi's analysis estimates that for given <span class=\"math\">\\((\\varepsilon,\\delta)\\)</span> parameters,\nwe need <span class=\"math\">\\(n(\\varepsilon,\\delta) =\n2(1-(8/3)\\varepsilon)\\log(1/\\delta)/\\varepsilon^2\\)</span> samples to achieve an\nabsolute bound of <span class=\"math\">\\(\\varepsilon\\)</span> on the relative error with probability\n<span class=\"math\">\\(1-\\delta\\)</span>.  As an example, his results requires that <span class=\"math\">\\(n(0.1, 0.1) = 337\\)</span> and\n<span class=\"math\">\\(n(0.01, 0.1)=44824\\)</span> for example, independent of <span class=\"math\">\\(d\\)</span>.</p>\n<p><em>Complete prior ignorance</em>: in some applications we may have a prior idea about\n<span class=\"math\">\\(A\\)</span> or of its trace value.  For example, in deep learning we learn iteratively\nby gradient descent, and a matrix <span class=\"math\">\\(A_t\\)</span> at step <span class=\"math\">\\(t\\)</span> may not be too different\nfrom a matrix <span class=\"math\">\\(A_{t+\\Delta}\\)</span> for small <span class=\"math\">\\(\\Delta\\)</span>.</p>\n<p><em>Complete random design <span class=\"math\">\\((z^{(1)},\\dots,z^{(M)})\\)</span></em>:\nwhether Normal or Rademacher vectors are used, the random vectors <span class=\"math\">\\(z^{(m)}\\)</span> are\nchosen independently at random.  Can we improve the estimate by chosing them\n<em>dependently</em>?\nOr by chosing <span class=\"math\">\\(z^{(m)}\\)</span> adaptively based on <span class=\"math\">\\((y^{(j)},z^{(j)})_{j &lt; m}\\)</span>?\nThe latter is an <em>adaptive experimental design</em> and may or may not be an option\ndepending on our needs to parallelize computation over <span class=\"math\">\\(z^{(m)}\\)</span>'s.</p>\n<h1>Variance Reduction Approaches</h1>\n<p>A number of approaches have been proposed to preserve the spirit of the\nHutchinson estimator but to lower its variance.  The shared idea is to think\nsequentially and to use prior measurements to construct some form of estimate\n<span class=\"math\">\\(\\hat{A}\\)</span> of <span class=\"math\">\\(A\\)</span>, which can then be used to lower the variance.</p>\n<p>I am aware of two classes of methods: one based on control-variates, and one\nbased on constructing a low-rank approximation to <span class=\"math\">\\(A\\)</span>.</p>\n<p>In addition to these two classes, I will also throw in an attractive new method\ninto the mix, based on randomized quasi Monte Carlo.</p>\n<h2>Control-variate Methods</h2>\n<p><em>Control variates</em> are a classic method for variance reduction and are\nfrequently used in reinforcement learning, where they are called <em>baselines</em>.\nA great introduction to classic variance reduction methods can be found in\n<a href=\"https://artowen.su.domains/mc/Ch-var-basic.pdf\">Chapter 8</a> of <a href=\"https://artowen.su.domains/mc/\">Art Owen's\nyet-unreleased Monte Carlo book</a>, with\n<a href=\"https://artowen.su.domains/mc/Ch-var-basic.pdf\">Section 8.9</a> introducing\nvarious forms of control variates.</p>\n<p>In its simplest form the idea is this: we are interested in estimating\n<span class=\"math\">\\(\\mathbb{E}_{z \\sim p}[f(z)]\\)</span> using samples from <span class=\"math\">\\(p(z)\\)</span>.  If we know a \"simple\"\nfunction <span class=\"math\">\\(h\\)</span> and this function is similar to <span class=\"math\">\\(f\\)</span>, i.e. we have <span class=\"math\">\\(h(z) \\approx\nf(z)\\)</span>, then we can instead attempt to estimate the equivalent quantity</p>\n<div class=\"math\">$$\\mathbb{E}_{z \\sim p}[f(z) - h(z)] + \\mathbb{E}_{z \\sim p}[h(z)].$$</div>\n<p>The first expectation is now likely smaller in magnitude, so our Monte Carlo\nestimate of this first term has smaller variance.  But what about the second\nterm?  If <span class=\"math\">\\(h\\)</span> is simple enough we may be able to compute this quantity\nanalytically, with no Monte Carlo variance at all.</p>\n<p>To make this idea realistic, we typically relax the definition somewhat and\ndefine <span class=\"math\">\\(h_{\\beta}(z) := \\beta \\, h(z)\\)</span>, where <span class=\"math\">\\(\\beta \\in \\mathbb{R}\\)</span> can be\nestimated to maximally mimic the behaviour of <span class=\"math\">\\(f(z)\\)</span> and thus to reduce the\nvariance of <span class=\"math\">\\(f(z) - h_{\\beta}(z)\\)</span> the most.</p>\n<p>For trace estimation <a href=\"https://arxiv.org/pdf/1802.03451.pdf\">(Adams et al.,\n2018)</a> first proposed to use control\nvariates to reduce variance:</p>\n<ul>\n<li>They propose to set <span class=\"math\">\\(h_{\\beta}(z) = \\beta \\, z^T B z\\)</span>, where <span class=\"math\">\\(B \\in\n  \\mathbb{R}^{d \\times d}\\)</span> is a matrix chosen by us, ideally <span class=\"math\">\\(B \\approx A\\)</span>, and\n  <span class=\"math\">\\(\\beta \\in \\mathbb{R}\\)</span> is estimated or fixed to <span class=\"math\">\\(\\beta=1\\)</span>.</li>\n<li>The <span class=\"math\">\\(M\\)</span>-sample trace estimator now becomes\n  <div class=\"math\">$$\\hat{T}_{C}(A,B,\\beta) = \\frac{1}{M}\\sum_{m=1}^M \\left[(z^{(m)})^T A z^{(m)} - \\beta (z^{m})^T B z^{(m)}\\right] + \\beta \\textrm{tr}(B).$$</div>\n</li>\n<li>When <span class=\"math\">\\(z^{(m)} \\sim \\mathcal{N}_d(0,I)\\)</span>, Adams et al. show (Lemma 4.1 in their\n  work) that the variance-minimizing choice of <span class=\"math\">\\(\\beta\\)</span> is <span class=\"math\">\\(\\beta^* =\n  \\textrm{tr}(A\\,B)/\\textrm{tr}(B\\,B)\\)</span> and that for this choice the variance of\n  the estimator is <em>reduced</em> compared to the Gaussian trace estimator by <span class=\"math\">\\(2\n  \\textrm{tr}(A \\,B)^2 / \\textrm{tr}(B \\, B)\\)</span>.  This also shows that when <span class=\"math\">\\(B=A\\)</span>\n  the estimator variance is zero.</li>\n</ul>\n<p>How to select the matrix <span class=\"math\">\\(B\\)</span>?  Adams et al. make one efficient proposal, which\nis to estimate the diagonal of <span class=\"math\">\\(A\\)</span> in the form <span class=\"math\">\\(B = \\textrm{diag}(b)\\)</span>, where <span class=\"math\">\\(b\n\\in \\mathbb{R}^d\\)</span>.  The diagonal is a simple choice because we can evaluate\n<span class=\"math\">\\(\\textrm{tr}(B) = \\sum_{i=1}^d b_i\\)</span> but also because the Hutchinson-style trace\nestimator already contains an estimator of the diagonal within it:</p>\n<div class=\"math\">$$\\mathbb{E}_{z}[z \\odot (A z)] = \\textrm{diag}(A),$$</div>\n<p>where <span class=\"math\">\\(\\odot\\)</span> is the elementwise product.\nThis identity holds for both the Rademacher vectors and the Gaussian vectors\nbecause <span class=\"math\">\\(\\mathbb{E}[z_i^2] = 1\\)</span>.  For the <span class=\"math\">\\(i\\)</span>'th element of the diagonal, we\ncan see that\n</p>\n<div class=\"math\">$$\n\\begin{align*}\n\\mathbb{E}\\left[z_i \\left(\\sum_{j=1}^d A_{ij} z_j\\right)\\right]\n&amp;= \\sum_{j=1}^d A_{ij} \\mathbb{E}[z_i z_j]\\\\\n&amp;= A_{ii} \\underbrace{\\mathbb{E}[z_i^2]}_{=1}\n    + \\sum_{j \\neq i} A_{ij} \\underbrace{\\mathbb{E}[z_i]}_{=0}\n        \\underbrace{\\mathbb{E}[z_j]}_{=0}\\\\\n&amp;= A_{ii}.\n\\end{align*}\n$$</div>\n<p>Adams et al. also propose to apply the control variate idea once more to the\ndiagonal estimate itself.\nTo see one way to achieve this is to look at the <span class=\"math\">\\(m\\)</span>'th iteration, where our\ninstantaneous diagonal estimate is</p>\n<div class=\"math\">$$\\hat{b}^{(m)} = z^{(m)} \\odot A z^{(m)}.$$</div>\n<p>Instead we can use our existing knowledge of <span class=\"math\">\\(A\\)</span>, in the form of <span class=\"math\">\\(\\hat{b}^{(m)}\\)</span>:</p>\n<div class=\"math\">$$\n\\begin{align*}\n\\hat{b}^{(m)}\n&amp;:= z^{(m)} \\odot \\left(A-\\textrm{diag}(\\hat{b}^{(m-1)})\\right) z^{(m)}\n    + \\mathbb{E}_z\\left[z \\odot \\textrm{diag}(\\hat{b}^{(m-1)}) z\\right]\\\\\n&amp;= z^{(m)} \\odot \\left(A-\\textrm{diag}(\\hat{b}^{(m-1)})\\right) z^{(m)}\n    + \\hat{b}^{(m-1)}.\n\\end{align*}\n$$</div>\n<p>Putting the two control variate ideas together, we can implement the Adams et\nal. trace estimator in the following Julia code.</p>\n<div class=\"highlight\"><pre><span></span><code><span class=\"k\">function</span> <span class=\"n\">adams_trace_estimator</span><span class=\"p\">(</span><span class=\"n\">A</span><span class=\"p\">,</span> <span class=\"n\">M</span><span class=\"o\">::</span><span class=\"kt\">Int</span><span class=\"p\">;</span> <span class=\"n\">use_diag_cv</span><span class=\"o\">=</span><span class=\"kc\">false</span><span class=\"p\">)</span>\n    <span class=\"n\">d</span> <span class=\"o\">=</span> <span class=\"n\">size</span><span class=\"p\">(</span><span class=\"n\">A</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n    <span class=\"n\">b_diag</span> <span class=\"o\">=</span> <span class=\"n\">zeros</span><span class=\"p\">(</span><span class=\"n\">d</span><span class=\"p\">)</span>   <span class=\"c\"># B = diag(b_diag)</span>\n\n    <span class=\"n\">tr_est</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>\n    <span class=\"k\">for</span> <span class=\"n\">m</span> <span class=\"o\">=</span> <span class=\"mi\">1</span><span class=\"o\">:</span><span class=\"n\">M</span>\n    <span class=\"n\">z</span> <span class=\"o\">=</span> <span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"n\">d</span><span class=\"p\">)</span>    <span class=\"c\"># Gaussian z^{(m)}</span>\n    <span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">A</span><span class=\"o\">*</span><span class=\"n\">z</span>\n\n    <span class=\"n\">y_B</span> <span class=\"o\">=</span> <span class=\"n\">b_diag</span> <span class=\"o\">.*</span> <span class=\"n\">z</span>   <span class=\"c\"># B z</span>\n    <span class=\"n\">tr_est</span> <span class=\"o\">+=</span> <span class=\"n\">z</span><span class=\"o\">&#39;*</span><span class=\"n\">y</span> <span class=\"o\">-</span> <span class=\"p\">(</span><span class=\"n\">z</span><span class=\"o\">&#39;*</span><span class=\"n\">y_B</span> <span class=\"o\">-</span> <span class=\"n\">sum</span><span class=\"p\">(</span><span class=\"n\">b_diag</span><span class=\"p\">))</span>   <span class=\"c\"># z&#39;Az - (z&#39;Bz - tr(B))</span>\n\n    <span class=\"c\"># Update diagonal estimate</span>\n    <span class=\"k\">if</span> <span class=\"n\">use_diag_cv</span>\n        <span class=\"n\">b_diag_cur</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">z</span> <span class=\"o\">.*</span> <span class=\"p\">(</span><span class=\"n\">y</span> <span class=\"o\">-</span> <span class=\"n\">y_B</span><span class=\"p\">))</span> <span class=\"o\">+</span> <span class=\"n\">b_diag</span>  <span class=\"c\"># z .* ((A-B)z) + diag(B)</span>\n    <span class=\"k\">else</span>\n        <span class=\"n\">b_diag_cur</span> <span class=\"o\">=</span> <span class=\"n\">z</span> <span class=\"o\">.*</span> <span class=\"n\">y</span>   <span class=\"c\"># instantaneous estimate of diag(A)</span>\n    <span class=\"k\">end</span>\n    <span class=\"n\">b_diag</span> <span class=\"o\">.*=</span> <span class=\"p\">(</span><span class=\"n\">m</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n    <span class=\"n\">b_diag</span> <span class=\"o\">+=</span> <span class=\"n\">b_diag_cur</span>\n    <span class=\"n\">b_diag</span> <span class=\"o\">./=</span> <span class=\"n\">m</span>        <span class=\"c\"># Invariant: b^{(M)} = (1/M) sum_{m=1}^M (z^{(m)} .* y^{(m)})</span>\n    <span class=\"k\">end</span>\n    <span class=\"n\">tr_est</span> <span class=\"o\">/</span> <span class=\"n\">M</span><span class=\"p\">,</span> <span class=\"n\">b_diag</span>\n<span class=\"k\">end</span>\n</code></pre></div>\n\n<h2>Low-rank Approximation Methods (Hutch++)</h2>\n<p><a href=\"https://arxiv.org/pdf/2010.09649.pdf\">(Meyer et al., 2021)</a> present\nimprovements on the Hutchinson estimator by first extracting a low-rank\napproximation to <span class=\"math\">\\(A\\)</span> and then using this low-rank approximation to reduce the\nvariance of the trace estimate.</p>\n<p>Given a good approximation <span class=\"math\">\\(\\tilde{A}\\)</span> of <span class=\"math\">\\(A\\)</span> the method also uses the same\ntechnique as the control variate approach, representing</p>\n<div class=\"math\">$$\\textrm{tr}(A) = \\textrm{tr}(\\tilde{A}) + \\textrm{tr}(A - \\tilde{A}),$$</div>\n<p>where <span class=\"math\">\\(\\textrm{tr}(\\tilde{A})\\)</span> is computed analytically and the second term is\nstochastically estimated at reduced variance.\nHow to obtain a good approximation <span class=\"math\">\\(\\tilde{A}\\)</span>?\nMeyer et al. make two proposals, which then form the Hutch++ and the\nNystroem-Hutch++ estimator.  I will only discuss the Hutch++ briefly here.</p>\n<p><strong>Hutch++ estimator</strong>.  Given a symmetric psd matrix <span class=\"math\">\\(A \\in \\mathbb{R}^{d\n\\times d}\\)</span> and an overall budget of <span class=\"math\">\\(m\\)</span> query vectors, split this budget into\n<span class=\"math\">\\(q_k\\)</span> and <span class=\"math\">\\(\\ell\\)</span> such that <span class=\"math\">\\(2 q_k + \\ell = m\\)</span>.  Create <span class=\"math\">\\(S \\in\n\\mathbb{R}^{d,q_k}\\)</span> with each element <span class=\"math\">\\(S_{ij} \\sim \\mathcal{N}(0,1)\\)</span>.  Evaluate\n<span class=\"math\">\\(Y = A S\\)</span> and orthonormalize <span class=\"math\">\\(Y\\)</span> to <span class=\"math\">\\(Q \\in \\mathbb{R}^{d \\times q_k}\\)</span>.\nSet <span class=\"math\">\\(\\tilde{A} = Q^T A Q\\)</span> and apply the control variate method on <span class=\"math\">\\(\\ell\\)</span>\nadditional samples.</p>\n<p>In Julia this can be implemented as follows.</p>\n<div class=\"highlight\"><pre><span></span><code><span class=\"k\">function</span> <span class=\"n\">hutchpp</span><span class=\"p\">(</span><span class=\"n\">A</span><span class=\"p\">,</span><span class=\"n\">m</span><span class=\"p\">)</span>\n    <span class=\"n\">d</span> <span class=\"o\">=</span> <span class=\"n\">size</span><span class=\"p\">(</span><span class=\"n\">A</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n    <span class=\"n\">k</span> <span class=\"o\">=</span> <span class=\"n\">floor</span><span class=\"p\">(</span><span class=\"kt\">Int</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">m</span><span class=\"o\">-</span><span class=\"mi\">2</span><span class=\"p\">)</span><span class=\"o\">/</span><span class=\"mi\">8</span><span class=\"p\">)</span>   <span class=\"c\"># Variance-optimal allocation of initial queries</span>\n    <span class=\"n\">qk</span> <span class=\"o\">=</span> <span class=\"mi\">2</span><span class=\"o\">*</span><span class=\"n\">k</span><span class=\"o\">+</span><span class=\"mi\">1</span>                <span class=\"c\"># qk: number of initial query vectors</span>\n    <span class=\"n\">ell</span> <span class=\"o\">=</span> <span class=\"n\">m</span> <span class=\"o\">-</span> <span class=\"mi\">2</span><span class=\"o\">*</span><span class=\"n\">qk</span>            <span class=\"c\"># ell: remaining budget for final estimate</span>\n    <span class=\"nd\">@assert</span> <span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"o\">*</span><span class=\"p\">(</span><span class=\"n\">qk</span><span class=\"p\">)</span><span class=\"o\">+</span><span class=\"n\">ell</span><span class=\"p\">)</span> <span class=\"o\">&lt;=</span> <span class=\"n\">m</span> <span class=\"c\"># make sure total query budget m is satisfied</span>\n\n    <span class=\"c\"># initial basis construction</span>\n    <span class=\"n\">S</span> <span class=\"o\">=</span> <span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"n\">d</span><span class=\"p\">,</span> <span class=\"n\">qk</span><span class=\"p\">)</span>      <span class=\"c\"># qk initial query vectors</span>\n    <span class=\"n\">Y</span> <span class=\"o\">=</span> <span class=\"n\">A</span><span class=\"o\">*</span><span class=\"n\">S</span>              <span class=\"c\"># query matrix</span>\n    <span class=\"n\">Q</span> <span class=\"o\">=</span> <span class=\"kt\">Matrix</span><span class=\"p\">(</span><span class=\"n\">qr</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">Q</span><span class=\"p\">)</span>  <span class=\"c\"># orthonormalize SY to a (d,qk) basis</span>\n\n    <span class=\"c\"># variance-reduced stochastic estimate</span>\n    <span class=\"n\">z</span> <span class=\"o\">=</span> <span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"n\">d</span><span class=\"p\">,</span><span class=\"n\">ell</span><span class=\"p\">)</span>      <span class=\"c\"># ell remaining queries</span>\n    <span class=\"n\">y0</span> <span class=\"o\">=</span> <span class=\"n\">A</span><span class=\"o\">*</span><span class=\"n\">z</span>\n    <span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">y0</span> <span class=\"o\">-</span> <span class=\"n\">Q</span><span class=\"o\">*</span><span class=\"p\">(</span><span class=\"n\">Q</span><span class=\"o\">&#39;*</span><span class=\"n\">y0</span><span class=\"p\">)</span>    <span class=\"c\"># adjust estimate using low-rank approximation</span>\n    <span class=\"n\">tr_ests</span> <span class=\"o\">=</span> <span class=\"n\">sum</span><span class=\"p\">(</span><span class=\"n\">z</span> <span class=\"o\">.*</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">dims</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n    <span class=\"n\">tr_est</span> <span class=\"o\">=</span> <span class=\"n\">Statistics</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">(</span><span class=\"n\">tr_ests</span><span class=\"p\">)</span> <span class=\"o\">+</span> <span class=\"n\">tr</span><span class=\"p\">(</span><span class=\"n\">Q</span><span class=\"o\">&#39;*</span><span class=\"n\">A</span><span class=\"o\">*</span><span class=\"n\">Q</span><span class=\"p\">)</span>   <span class=\"c\"># another qk queries</span>\n    <span class=\"n\">tr_est</span>\n<span class=\"k\">end</span>\n</code></pre></div>\n\n<p>A problem of the Hutch++ family of estimators shared with the control\nvariate one is that it is difficult to parallelize: there are two sequential\nsteps and the second step relies on the output of the first.  This may not be a\nproblem in most applications, but in training deep neural networks we typically\nprefer parallelization.</p>\n<h2>Preconditioning</h2>\n<p>If the matrix <span class=\"math\">\\(A\\)</span> is a <em>kernel matrix</em>, i.e. <span class=\"math\">\\(K_{ij} = k(x_i, x_j)\\)</span> for some\n<em>kernel function</em> <span class=\"math\">\\(k\\)</span>, then variance of a stochastic trace estimator can be\ngreatly reduced using an appropriate preconditioner.</p>\n<p>An extensive set of results is given by <a href=\"https://proceedings.mlr.press/v162/wenger22a/wenger22a.pdf\">(Wenger et al., \"Preconditioning for\nScalable GP Hyperparameter Optimization\", ICML\n2022)</a> with the\napplication of computing the log-marginal likelihood (evidence) of Gaussian\nprocesses.</p>\n<p>In their application, they exploit the identity</p>\n<div class=\"math\">$$\\log \\det K = \\log \\det P + \\textrm{tr}(\\log K - \\log P),$$</div>\n<p>and estimate the second term using a stochastic trace estimator for variance\nreduction.</p>\n<p>Wenger et al. show in theory and through experiments that this leads to large\nreduction in variance.\nAs an example, if <span class=\"math\">\\(A\\)</span> is a kernel matrix arising from a radial basis function\n(RBF) kernel in one dimension then the variance scaling that can be achieved\nwith a suitable precondition can be exponential, <span class=\"math\">\\(\\mathbb{V}[\\hat{T}_P] =\nexp(-c m)\\)</span>.</p>\n<p>The paper by Wenger et al. is very well written and the <a href=\"https://github.com/cornellius-gp/gpytorch\">code is already\navailable in GPyTorch</a>.</p>\n<h2>Randomized Quasi Monte-Carlo (RQMC)</h2>\n<p>Quasi Monte Carlo methods (QMC) aim to improve on Monte Carlo integration.\nWhereas basic Monte Carlo methods draw samples independently, quasi Monte Carlo\nmethods draw samples from a dependent distribution chosen such that for classes\nof integrands better convergence rates are obtained.\nTypically QMC methods start with a <em>uniform</em> distribution in the hypercube\n<span class=\"math\">\\([0,1]^d\\)</span>.\nWe can map the hypercube <span class=\"math\">\\([0,1]^d\\)</span> to a domain such as <span class=\"math\">\\([-\\infty,\\infty]^d\\)</span> using the\n<a href=\"https://en.wikipedia.org/wiki/Inverse_transform_sampling\">inverse cumulative distribution\nfunction</a> (inverse CDF)\nof a chosen distribution.  For example, for the standard Normal distribution\nthe inverse CDF would be the <a href=\"https://en.wikipedia.org/wiki/Normal_distribution#Quantile_function\">Normal quantile\nfunction</a>.\nQMC points are deterministic and this determinism would lead to unavoidable\nbias when used for sampling.  An effective remedy is to <em>randomize</em> QMC methods\nonce more, by shifting all generated points using a randomly chosen offset.\nThis is the RQMC constructions and it guarantees that the marginal distribution\nof every point is following the target distribution.</p>\n<p>To see intuitively how selecting dependent samples could lead to better\nproperties, here is a visual example of 64 multivariate Normal samples in 2D as\nused in Monte Carlo methods such as the Gaussian trace estimator:</p>\n<p><img alt=\"Monte Carlo Normal draws in 2D\" src=\"http://www.nowozin.net/sebastian/blog/images/trace-estimation-mc-2D-draws.png\"></p>\n<p>Now, for comparison, the following Figure shows a draw of marginally\nNormal-distributed points generated with a RQMC construction, implemented by\nthe following Julia code using the <a href=\"https://github.com/stevengj/Sobol.jl\">Sobol.jl\npackage</a>.</p>\n<div class=\"highlight\"><pre><span></span><code><span class=\"n\">M</span> <span class=\"o\">=</span> <span class=\"mi\">64</span>\n<span class=\"n\">d</span> <span class=\"o\">=</span> <span class=\"mi\">2</span>\n<span class=\"n\">points</span> <span class=\"o\">=</span> <span class=\"n\">zeros</span><span class=\"p\">(</span><span class=\"n\">M</span><span class=\"p\">,</span> <span class=\"n\">d</span><span class=\"p\">)</span>\n<span class=\"n\">sobolseq</span> <span class=\"o\">=</span> <span class=\"n\">skip</span><span class=\"p\">(</span><span class=\"n\">SobolSeq</span><span class=\"p\">(</span><span class=\"n\">d</span><span class=\"p\">),</span> <span class=\"n\">max_M</span><span class=\"p\">)</span>\n<span class=\"k\">for</span> <span class=\"n\">m</span> <span class=\"o\">=</span> <span class=\"mi\">1</span><span class=\"o\">:</span><span class=\"n\">max_M</span>\n    <span class=\"n\">points</span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"p\">,</span><span class=\"o\">:</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">Sobol</span><span class=\"o\">.</span><span class=\"n\">next!</span><span class=\"p\">(</span><span class=\"n\">sobolseq</span><span class=\"p\">)</span>\n<span class=\"k\">end</span>\n<span class=\"n\">points</span> <span class=\"o\">=</span> <span class=\"n\">mod</span><span class=\"o\">.</span><span class=\"p\">(</span><span class=\"n\">points</span> <span class=\"o\">.+</span> <span class=\"n\">rand</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"n\">d</span><span class=\"p\">),</span> <span class=\"mf\">1.0</span><span class=\"p\">)</span>\n<span class=\"n\">points</span> <span class=\"o\">=</span> <span class=\"n\">quantile</span><span class=\"o\">.</span><span class=\"p\">(</span><span class=\"n\">Normal</span><span class=\"p\">(),</span> <span class=\"n\">points</span><span class=\"p\">)</span>\n</code></pre></div>\n\n<p><img alt=\"Randomized QMC Normal draws in 2D\" src=\"http://www.nowozin.net/sebastian/blog/images/trace-estimation-rqmc-2D-draws.png\"></p>\n<p>As you can see the points are more equally spaced out.  The hope with RQMC\nmethods is that such more homogeneous spacing improves the rate of the Monte\nCarlo average.</p>\n<p>Formally, the <a href=\"https://hal.inria.fr/hal-01561550/document\">starting point of RQMC\nmethods</a> is to assume an\nintegration problem over a function <span class=\"math\">\\(f: [0,1]^d \\to \\mathbb{R}\\)</span>.\nHere, for the purpose of trace estimation, we can define our function as</p>\n<div class=\"math\">$$f(u) = (\\Psi^{-1}(u))^T A \\, \\Psi^{-1}(u),$$</div>\n<p>where <span class=\"math\">\\(\\Psi^{-1}\\)</span> is the <a href=\"https://en.wikipedia.org/wiki/Normal_distribution#Quantile_function\">standard Normal quantile\nfunction</a>,\napplied elementwise.  We have</p>\n<div class=\"math\">$$\\int_{u \\in [0,1]^d} f(u) \\,\\textrm{d}u = \\textrm{tr}(A).$$</div>\n<p>This construction is beneficial if we can approximate the integral of <span class=\"math\">\\(f\\)</span> over\nthe <span class=\"math\">\\(d\\)</span>-dimensional unit cube effectively.  This is what randomized QMC methods\ndo.  The theory of most QMC results requires <span class=\"math\">\\(f\\)</span> to satisfy bounded variation\nconditions on partial derivatives (\"bounded variation in the sense of Hardy and\nKrause\", aka BVHK), but these conditions can be difficult to verify.  Here <span class=\"math\">\\(f\\)</span>\nhas unbounded derivatives and even <span class=\"math\">\\(\\Psi^{-1}\\)</span> itself is unbounded when\napproaching the boundary at zero or one.  Nevertheless, we can still go ahead\nand simply apply RQMC methods to assess their performance empirically.  This is\npopular practice in quantitative finance and other applications of RQMC\nmethods, and as safety net RQMC methods typically never perform worse than\nplain Monte Carlo and has also been used successfully in other applications in\nmachine learning, e.g. for variational inference in <a href=\"https://ml.cs.uni-kl.de/publications/2018/qmcvi_ICML.pdf\">(Buchholz et al.,\n2018)</a>.</p>\n<p><strong>RQMC trace estimator.</strong> The proposed trace estimator is simply the Hutchinson\nconstruction but using a RQMC point set instead of independent samples.  Here I\nuse a <a href=\"https://en.wikipedia.org/wiki/Sobol_sequence\">Sobol sequence</a>.</p>\n<h1>Comparison</h1>\n<p>For testing the estimators we will use a matrix extracted from a recent\ndiffusion model for image generation.  This model generates 32x32x3 ImageNet\nimages and in order to compute the training objective we need to estimate the\ntrace of a 3072-by-3072 matrix.  I extracted this implicit matrix by performing\n3072 matrix-vector products with the canonical basis vectors.  The matrix is\nquite benign, is positive-definite and has a rather smooth spectrum (see plot\nbelow).\nI assume these nice properties are present in most image diffusion models.</p>\n<p><img alt=\"Spectrum\" src=\"http://www.nowozin.net/sebastian/blog/images/trace-estimation-spectrum-unet.png\"></p>\n<p>I ran 500 replicates of the following experiment: draw <span class=\"math\">\\(z^{(m)} \\sim\n\\mathcal{N}_d(0,I)\\)</span>, <span class=\"math\">\\(m=1,2,\\dots,250\\)</span>, and pass this vector to all estimators.\nI record the estimate after each value of <span class=\"math\">\\(m\\)</span> for each replicate.  Then I\nestimate the variance of the estimator, as well as its bias.  All estimators\nare unbiased for all values of <span class=\"math\">\\(m\\)</span>, as expected, so the main quantity of\ninterest is the variance as a function of <span class=\"math\">\\(m\\)</span>.</p>\n<p>We can understand the variance behaviour best in a <a href=\"https://en.wikipedia.org/wiki/Log%E2%80%93log_plot\">log-log\nplot</a> because relationships\nof the form <span class=\"math\">\\(y=b x^{\\alpha}\\)</span> become linear in the log-log plot, <span class=\"math\">\\(\\log y = \\log\nb + \\alpha \\log x\\)</span>, and if the behaviour is well modelled as a line in the\nlog-log plot, then the slope coefficient <span class=\"math\">\\(\\alpha\\)</span> gives us the scaling behavior\nas <span class=\"math\">\\(M \\to \\infty\\)</span>.  For example, simple Monte Carlo estimates have variance\nbehavior <span class=\"math\">\\(M^{-1}\\)</span> so <span class=\"math\">\\(\\alpha = -1\\)</span>.  Any value smaller than <span class=\"math\">\\(-1\\)</span> denotes an\nimprovement over simple Monte Carlo.  Randomized Quasi Monte Carlo methods can\nachieve <span class=\"math\">\\(\\alpha = -2\\)</span> for example, <a href=\"https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/rssb.12104\">(Gerber and Chopin,\n2015)</a>.</p>\n<p><img alt=\"Variance comparison\" src=\"http://www.nowozin.net/sebastian/blog/images/trace-estimator-unet-variance.png\"></p>\n<p><strong>Hutch++ estimator</strong>: Unfortunately, despite solid theory in the paper, I have\nnot been able to observe practical improvements over even the simple Gaussian\ntrace estimate on my test matrix.</p>\n<p><img alt=\"Hutch++ estimator variance\" src=\"http://www.nowozin.net/sebastian/blog/images/trace-estimation-hutchpp.png\"></p>\n<h1>Bayesian Estimation</h1>\n<p>A classic method for approaching estimation problems is Bayesian decision\ntheory.  (Sidenote: I have mentioned <a href=\"https://www.wiley.com/en-us/Decision+Theory%3A+Principles+and+Approaches-p-9780471496571\">(Parmigiani and Inoue, \"Decision Theory:\nPrinciples and Approaches\",\n2009)</a>\nin my blog before, but it really is a wonderful introduction to the topic.)</p>\n<p>The key steps in the Bayesian approach are: 1. write down what you know; 2.\nwrite down how what you know relates to what you would like to know; and 3.\nmake optimal decisions by optimizing expected utility.  This recipe is simple\nand elegant in principle but becomes challenging quickly, as we will see\nshortly for trace estimation.</p>\n<h2>Benefits and Pitfalls of Bayesian Estimation</h2>\n<p>Before we look at trace estimation, I want to give one concrete example of the\nrisks but also benefits of the Bayesian approach to estimation.  This is the\nexample of <a href=\"http://www.nowozin.net/sebastian/blog/estimating-discrete-entropy-part-3.html\">estimating the entropy of a discrete random variable discussed on\nthis blog\nbefore</a>.\nA short summary is this: between 1993-1995 David Wolpert and David Wolf proposed a <a href=\"http://www.santafe.edu/media/workingpapers/93-07-046.pdf\">sound\nBayesian approach to the\nproblem</a>, using a\nstandard <a href=\"https://en.wikipedia.org/wiki/Dirichlet-multinomial_distribution\">Dirichlet-Multinomial model</a>,\nwhich allows for efficient estimation due to\n<a href=\"https://en.wikipedia.org/wiki/Conjugate_prior\">conjugacy</a>.  The model appears\nelegant, and has support everywhere, thus can recover the true entropy and is\nasymptotically unbiased as well.</p>\n<p>However, six years later, in 2001, Ilya Nemenman and colleagues found grave\nflaws in this benign looking Bayesian approach: the prior almost completely\nspecifies the entropy, i.e. the prior predictive is highly concentrated when\nsamples from the Dirichlet distribution, i.e. probability vectors, are\nmapped to their entropy.  The full story is in my <a href=\"http://www.nowozin.net/sebastian/blog/estimating-discrete-entropy-part-3.html\">prior blog\narticle</a>.</p>\n<p>It is really nice that the story does not end here: <a href=\"http://arxiv.org/abs/physics/0108025\">(Nemenman, Shafee, and\nBialek, \"Entropy and inference, revisited\",\n2001)</a> proposed to add one more\nhyperprior layer to the Dirichlet-Multinomial model and chose this hyperprior\nto be maximially uninformative with respect to entropy, akin to a <em>reference\nprior</em> approach, but targetted to entropy inference.  This estimator, the <em>NSB\nestimator of entropy</em> is still state-of-the-art for estimating the entropy of\ndiscrete random variables, dominating almost all other methods in terms of RMSE\nand bias in a wide variety of practical distribution types.  However, it is\ncomputationally expensive compared to most other entropy estimates.</p>\n<p>This story is very concrete but the lessons implied are general:</p>\n<ul>\n<li>Bayesian estimation relies on a suitable prior, and whether a prior is\n  suitable or not also depends on the <em>implied prior predictive</em> over the\n  quantity of interest.</li>\n<li>It may be hard to construct suitable uninformative priors, and it may not be\n  obvious when to call a model a success.</li>\n<li>When a suitable prior can be designed, the Bayesian approach uses <em>all</em>\n  information in the data, and can provide accurate estimates with uncertainty\n  quantification.</li>\n<li>There may be a tradeoff between computational efficiency and suitability of\n  the model.</li>\n</ul>\n<h2>Bayesian Trace Estimation</h2>\n<p>For Bayesian trace estimation we can propose the following directed graphical model.</p>\n<p><img alt=\"Directed graphical model for trace estimation\" src=\"http://www.nowozin.net/sebastian/blog/images/trace-estimation-bayes-240.png\"></p>\n<p>The unknown matrix <span class=\"math\">\\(A\\)</span> is assumed to come from a <em>prior</em> <span class=\"math\">\\(p(A)\\)</span> and\n<span class=\"math\">\\(T=\\textrm{tr}(A)\\)</span> is the implied distribution over the trace.\n<span class=\"math\">\\(z^{(m)} \\sim p(z)\\)</span> independently, for example <span class=\"math\">\\(z^{(m)} \\sim \\mathcal{N}_d(0,I)\\)</span>.\nWe then observe <span class=\"math\">\\(y^{(m)} = A z^{(m)}\\)</span> and are interested in\n<span class=\"math\">\\(p(T|(z^{(m)},y^{(m)})_{m=1,\\dots,M})\\)</span>.</p>\n<p>To make things concrete we can assume <span class=\"math\">\\(A\\)</span> is symmetric and model <span class=\"math\">\\(A_{ij} \\sim\n\\mathcal{N}(0,\\sigma^2)\\)</span> for <span class=\"math\">\\(i \\leq j\\)</span>.  Thus <span class=\"math\">\\(A \\sim \\mathcal{N}(\\mu, \\Sigma)\\)</span> with\n<span class=\"math\">\\(\\mu = 0_n\\)</span> and <span class=\"math\">\\(\\Sigma = \\sigma^2 I_n\\)</span>, where <span class=\"math\">\\(n=d(d+1)/2\\)</span> are the number of\nupper-triangular elements in the unknown <span class=\"math\">\\(A\\)</span>, so we index with coordinates of\n<span class=\"math\">\\(A\\)</span>, like so <span class=\"math\">\\(\\mu_{(i,j)}\\)</span>, and <span class=\"math\">\\(\\Sigma_{(i,j),(k,l)}\\)</span>.</p>\n<p>When observing <span class=\"math\">\\(y^{(m)}\\)</span> we know with certainty that</p>\n<div class=\"math\">$$y^{(m)} = A z^{(m)}$$</div>\n<p>must hold for any possible <span class=\"math\">\\(A\\)</span>.  Thus we can remove all matrices from our prior\nwhich violate this equality constraint.  This means we condition our\nmultivariate Normal belief\n<span class=\"math\">\\(A \\sim \\mathcal{N}(A; \\mu, \\Sigma)\\)</span>\non a subspace implied by the equality.  Doing so is not a standard operation on\nmultivariate Normals, but is possible and results in a rank-deficient\nmultivariate Normal.  The result is a new posterior belief\n<span class=\"math\">\\(A \\sim \\mathcal{N}(A; \\mu', \\Sigma')\\)</span>.</p>\n<p>Graphically, in 2D, this conditioning on a subsapce looks as in this figure.\n(The detailed equation for conditioning a multivariate Normal on a subspace are\nin the appendix below.)\nThe black dots are samples of possible matrices from the prior, and after\nconditioning on an observed subspace we retain a rank-deficient posterior,\nvisualized by blue samples.</p>\n<p><img alt=\"Conditioning 2D Normal on subspace\" src=\"http://www.nowozin.net/sebastian/blog/images/trace-estimation-mvn-conditioning.png\"></p>\n<p>Thus, for our simple choice of multivariate Normal prior on <span class=\"math\">\\(A\\)</span> we can, for\neach observed <span class=\"math\">\\((z^{(m)}, y^{(m)})\\)</span> pair update our posterior beliefs\nanalytically.  (This update is relatively expensive and may preclude the\nBayesian approach entirely, see discussion below.)</p>\n<p>At any time, we can also compute the closed-form posterior over the trace\nitself, as it is a sum of Normal random variables and thus <a href=\"https://en.wikipedia.org/wiki/Variance#Sum_of_correlated_variables\">Bienayme's\nidentity</a>\napplies and moreover the resulting sum is again Normal.\nWe have <span class=\"math\">\\(T \\sim \\mathcal{N}(\\mu_T, \\sigma^2_T)\\)</span>, with</p>\n<div class=\"math\">$$\\mu_{T} = \\sum_{i=1}^d \\mu_{ii},$$</div>\n<div class=\"math\">$$\\sigma^2_T = \\sum_{i=1}^d \\Sigma_{(i,i),(i,i)} + 2 \\sum_{i=1}^d \\sum_{j=i+1}^d \\Sigma_{(i,i),(j,j)}.$$</div>\n<p>Overall this seems a satisfactory if computationally heavy model for trace\nestimation.  But we can go further with the Bayesian approach and choose\n<span class=\"math\">\\(z^{(m)}\\)</span> intelligently using <em>adaptive experimental design</em> techniques.</p>\n<h2>Adaptive Experimental Design</h2>\n<p><em>Experimental design</em> refers to making intelligent choices about what to\nmeasure in order to draw more informative inferences.\nIn <em>static</em> experimental design one chooses a set of things to measure apriori,\nselecting measurements that for example are on average not too strongly\ncorrelated in order to maximize the expected information content of the\nmeasurements.  The RQMC approach would be a simple example of a static\nexperimental design because the <span class=\"math\">\\(z^{(m)}\\)</span> choices are <em>dependent</em> for different\nvalues of <span class=\"math\">\\(m\\)</span>.</p>\n<p>In <em>adaptive</em> experimental design we consider a sequential setting and thus\nsequentially decide <em>what to measure</em> based on all observations measured up\nto that point.\nYou can think of adaptive experimental design as a simplification to the\ngeneral reinforcement learning setup: your actions (what to measure) do not\nhave an effect on the state of the world, and your reward is internal in terms\nof what information you have gained.</p>\n<p>As a simple example, consider a paper survey setting: a static experimental\ndesign consists of a printed questionnaire with a set of well-chosen questions.\nAn adaptive experimental design would only show one question to you at first\nand pick the next question based on your answer to all prior questions.</p>\n<p><strong>Personal anecdote.</strong> As a personal anecdote, I first used Bayesian\nexperimental design to great effect in my work with Microsoft Israel on\ntime-of-flight (ToF) camera technology (around 2013-2017).  A time-of-flight\ncamera is an active sensing system where time-modulated light is emitted into\nthe world and the light bounces are recorded back on a camera, whose\nsensitivies are also time-modulated.  By using Bayesian experimental design\nmethods we were able to design the actively controllable part of the system and\nhalve the mean absolute range estimation error (<a href=\"http://www.nowozin.net/sebastian/papers/adam2016bayesiantof.pdf\">Section 7 in TPAMI 2016\npaper</a>) and to\nlearn to measure maximally complementary information over time (<a href=\"http://www.nowozin.net/sebastian/papers/schober2017dynamictof.pdf\">dynamic\ntime-of-flight CVPR 2017\npaper</a>).\nThe Bayesian ToF approach shipped in a few thousand first-gen Hololens\nprototypes to developers but was replaced a year later with a different sensor\nand algorithm and unfortunately the entire Microsoft Israel time-of-flight team\nwas let go, thus four years of hard work and my collaboration with an\noutstanding team in Israel, Amit Adam in particular, came to an end.  (That is\na separate story for another day.)</p>\n<p>Later, in 2018, Cheng Zhang, Chao Ma, myself, and colleagues at Microsoft used\nadaptive Bayesian experimental design in more general settings such as\nquestionnaire design (<a href=\"https://arxiv.org/abs/1809.11142\">ICML 2019 paper</a>,\n<a href=\"https://arxiv.org/abs/1908.04537\">NeurIPS 2019 paper</a>) and Cheng and team\nproductized much of this work, now available through Azure and shipped in\nsuccessful products.</p>\n<p>For a wonderful introduction to experimental design and decision theory more\ngenerally, I highly recommend the book <a href=\"https://www.wiley.com/en-us/Decision+Theory%3A+Principles+and+Approaches-p-9780471496571\">(Parmigiani and Inoue, \"Decision\nTheory: Principles and Approaches\",\n2009)</a>.</p>\n<p><strong>For trace estimation</strong>, here is what the adaptive experimental design\nmodel would look like, visualized as <a href=\"https://en.wikipedia.org/wiki/Influence_diagram\">influence\ndiagram</a>.</p>\n<p><img alt=\"Influence diagram for adaptive trace estimation\" src=\"http://www.nowozin.net/sebastian/blog/images/trace-estimation-bayes-adaptive-240.png\"></p>\n<p>Choice nodes <span class=\"math\">\\(z^{(m)}\\)</span> are now rectangular to indicate that they are under our\ncontrol and not independent random variables as before.\nHow should we choose <span class=\"math\">\\(z^{(m)}\\)</span>?  A natural approach is to select <span class=\"math\">\\(z^{(m)}\\)</span> as\nthe one that maximizes the reduction in posterior uncertainty or variance.\nFor this, denote all prior observations as\n<span class=\"math\">\\(\\mathcal{D}_{&lt;k} := \\{(z^{(i)},y^{(i)})\\}_{i &lt; k}\\)</span>.\nThen we can choose <span class=\"math\">\\(z^{(m)}\\)</span> as</p>\n<div class=\"math\">$$z^{(m)} = \\textrm{argmax}_{z \\in \\mathbb{R}^d}\n    \\mathbb{V}[T | \\mathcal{D}_{&lt;m}]\n    - \\mathbb{E}_{(y,A) \\sim p(y|A,z) \\, p(A| \\mathcal{D}_{&lt;m})}\\left[\n        \\mathbb{V}[T | \\mathcal{D}_{&lt;m}, (z, y)]\n    \\right].\n$$</div>\n<p>This expression looks somewhat complex but here are some interpretation aids:</p>\n<ul>\n<li>It reads \"variance before minus variance after\".  The \"variance after\", i.e.\n  after additionally measuring <span class=\"math\">\\((z,y)\\)</span> is <em>always</em> smaller than the \"variance\n  before\".  Hence the objective measures the <em>reduction</em> in variance, which we\n  want to maximize.</li>\n<li>The \"variance after\" term is also contained in an expectation over <span class=\"math\">\\((y,A)\\)</span>.\n  How come?  We do not know <span class=\"math\">\\(y\\)</span> and <span class=\"math\">\\(A\\)</span>, so we take an expectation over our\n  best current beliefs up to that point.</li>\n</ul>\n<p>The optimization problem may or may not have a closed-form solution, I did not\ninvestigate this.  Instead, I did a simple implementation where I sample 100\npoints from <span class=\"math\">\\(\\mathcal{N}(0,I)\\)</span>, then pick the point that maximizes the\nobjective.</p>\n<p>Here is a small experiment.  The experiment is smaller than small: with <span class=\"math\">\\(d=16\\)</span>\nI sampled <span class=\"math\">\\(A \\sim \\textrm{symmat}(\\mathcal{N}_k(0,\\Sigma_0)\\)</span>, where\n<span class=\"math\">\\(k=d(d+1)/2\\)</span> and <span class=\"math\">\\(\\Sigma_0\\)</span> is chosen such that\n<span class=\"math\">\\(\\Sigma_{(i,i),(i,i)}=\\sigma_d^2\\)</span> and <span class=\"math\">\\(\\Sigma_{(i,i),(j,j)}=\\sigma_o^2\\)</span> for\n<span class=\"math\">\\(i\\neq j\\)</span>.  I used <span class=\"math\">\\(\\sigma_d=200\\)</span> and <span class=\"math\">\\(\\sigma_o=5\\)</span>.  This prior encodes\ndiagonal-dominant matrices.\nTo give the maximal possible edge to the Bayesian model I sampled <span class=\"math\">\\(A\\)</span> from this\nprior, i.e. there is no misspecification in this experiment.\nI ran 500 replicates of the trace estimation experiment, so the plots will be a\nbit noisy, but here are the results.</p>\n<p><img alt=\"Bayesian experiment variance results\" src=\"http://www.nowozin.net/sebastian/blog/images/trace-estimation-bayes16-var.png\"></p>\n<p>The Bayes model has an order of magnitude lower variance than the next best\nmethod (RQMC).\nThe Bayesian method is not unbiased, so this low variance could be due to strong influence of the prior, so let's look at the root-mean-squared-error (RMSE) as well.</p>\n<p><img alt=\"Bayesian experiment RMSE results\" src=\"http://www.nowozin.net/sebastian/blog/images/trace-estimation-bayes16-rmse.png\"></p>\n<p>Again both Bayes methods are doing very well.  If my implementation is correct,\nthis must in fact be the case, as the Bayes estimate is optimal and thus the\nmodel achieves the Bayes risk in terms of RMSE.\nBut is the model biased?  The limited experiments do not allow a conclusion\nexcept that the plot shows that the unbiased methods show up as biased due to\nthe estimated bias itself having an estimation error and the Bayesian models\nbeing in that same range.</p>\n<p><img alt=\"Bayesian experiment mean results\" src=\"http://www.nowozin.net/sebastian/blog/images/trace-estimation-bayes16-mean.png\"></p>\n<h2>Difficulties of the Bayesian approach</h2>\n<p>Clearly, the Bayesian approach to trace estimation is not ready to be used due\nto excessive runtime requirements.  It may be possible to intelligently perform\nthe same computation in terms of sparse updates or implicit representations of\nthe evolution of <span class=\"math\">\\(\\Sigma\\)</span>, and thus make the Bayesian approach relevant.</p>\n<h1>Conclusion and Future Directions</h1>\n<p>We looked at a few existing estimators of the trace of a matrix.\nHere is a list of ideas for research in this area:</p>\n<ul>\n<li><em>Sequential or not</em>?  The estimators we have discussed can be divided into\n  two classes.  In the first class we have <em>static</em> estimators that can be\n  parallelized because no computation depends on the output of prior\n  computation.  In the second class we have estimators that do some clever\n  <em>sequential</em> processing (estimating control variates, estimating a low-rank\n  approximation, or similar) and then benefit in a second stage.  In practice,\n  for deep learning applications, we may be able to get the best of both worlds\n  by amortizing computation over time: instead of treating one optimization\n  step as a closed-world, we can estimate the necessary quantities over multiple\n  steps, for example in the control variate or low-rank approximation case.  So\n  the dichotomy between static and sequential is not as hard, which brings me\n  to the following concrete idea.</li>\n<li><em>Parameterized control variates</em>: in ML applications we often need trace\n  estimates where the matrix <span class=\"math\">\\(A\\)</span> is a function of other quantities.  For\n  example, in diffusion models the matrix <span class=\"math\">\\(A\\)</span> may depend an input vector or\n  time variable, e.g. <span class=\"math\">\\(A=A(x,t)\\)</span>, and we do not have one trace estimation task\n  but a large number of unique tasks with varying <span class=\"math\">\\(x\\)</span> and <span class=\"math\">\\(t\\)</span>.  This makes\n  Hutchinson's estimator so popular: it is cheap in this setting, and this\n  dependence on inputs seems to rule out approaches such as the control variate\n  method which requires multiple samples.  However, in reinforcement learning\n  control variates called <em>state-dependent baselines</em> are commonly employed for\n  variance reduction in policy gradient methods, e.g. <a href=\"https://arxiv.org/pdf/1802.10031.pdf\">(Tucker et al.,\n  2018)</a>.  So if our matrix has\n  dependencies such as <span class=\"math\">\\(A(x,t)\\)</span> it may be beneficial to simultaneously learn a\n  cheap control variate <span class=\"math\">\\(B(x,t)\\)</span>, perhaps as an auxiliary output of the main\n  model, in order to amortize computation over learning iterations, in effect\n  is a simple form of learning-to-learn more efficiently.</li>\n<li><em>Bayesian trace estimation</em>?  Conceptually the Bayesian approach is\n  particularly attractive for trace estimation as the latent structure of the\n  problem is exactly known.  In practice I have my doubts whether this approach\n  will be useful in deep learning, for three reasons: 1. already the simplest\n  faithful model I could come up with is computationally very expensive; 2. it\n  seems challenging to find suitable priors <span class=\"math\">\\(p(A)\\)</span> over matrices for two\n  reasons, a) standard choices such as Wishart distributions are not closed\n  under subspace conditioning so must be handled using even more expensive\n  computational approaches, and b) trace estimation is used in a wide variety\n  of domains and a generally useful yet uninformative prior seems too much to\n  ask for; and 3. unbiasedness is highly desirable in most deep learning uses\n  of trace estimation and Bayesian estimates are generally biased in the small\n  sample setting and only asymptotically unbiased for <span class=\"math\">\\(M \\to \\infty\\)</span>, whereas\n  Hutchinson's estimator is unbiased for any <span class=\"math\">\\(M\\)</span>.\n  Finding a general prior for matrices that is computationally efficient under\n  subspace conditioning would could be interesting.  Perhaps a good starting\n  point would be the multivariate Normal distribution but then to marginalize\n  most dimensions away.  This would make computation more efficient while\n  retaining tractability.</li>\n</ul>\n<p>So there you have it.  Given my understanding so far, I even venture to make\nsome recommendations for the current estimators:</p>\n<ol>\n<li>First, use Hutchinson's estimator or the Gaussian trace estimator.  Try both\n   and measure the variance.</li>\n<li>If you can afford <span class=\"math\">\\(M &gt; 1\\)</span> and <span class=\"math\">\\(d &lt; 21,201\\)</span>: give the RQMC approach a try; it\n   should be simple to implement, with\n   <a href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.qmc.Sobol.html\">SciPy</a>,\n   <a href=\"https://www.tensorflow.org/api_docs/python/tf/math/sobol_sample\">Tensorflow</a>,\n   and\n   <a href=\"https://pytorch.org/docs/stable/generated/torch.quasirandom.SobolEngine.html\">PyTorch</a>\n   all supporting Sobol sequence generation.  (The restriction to <span class=\"math\">\\(d &lt; 21,201\\)</span>\n   is not intrinsic to the approach but a <a href=\"https://web.maths.unsw.edu.au/~fkuo/sobol/\">practical constraint due to limited\n   availability of so called direction numbers</a>.)</li>\n<li>If variance of the estimates in your trace estimates are a major bottleneck\n   in your application, try the diagonal control variate approach, perhaps\n   learning this control variate as part of your learning objective if the\n   matrix is varying with the inputs to your network.</li>\n</ol>\n<p><em>Acknowledgements.</em> I thank <a href=\"https://yang-song.net/\">Yang Song</a> for careful\nreading and feedback on the draft including a number of corrections and\npointing me to two more uses of trace estimation;\nto <a href=\"http://florianwenzel.com/\">Florian Wenzel</a> for corrections, references, and\nimprovements to the quasi Monte Carlo methods.</p>\n<h2>Appendix</h2>\n<h3>Conditioning a multivariate Normal on a subspace</h3>\n<p>First, the following result: if <span class=\"math\">\\(x \\sim \\mathcal{N}(\\mu,\\Sigma)\\)</span>, and</p>\n<div class=\"math\">$$T(x) := Ax + b,$$</div>\n<p>then <span class=\"math\">\\(T(x) \\sim \\mathcal{N}(A\\mu + b, A\\Sigma A^T)\\)</span>.\nFurthermore we have joint Normality,</p>\n<div class=\"math\">$$\\left[\\begin{array}{c}x\\\\T(x)\\end{array}\\right] \\sim\n\\mathcal{N}\\left(\n\\left[\\begin{array}{c}\\mu\\\\ A\\mu + b\\end{array}\\right],\n\\left[\\begin{array}{cc}\\Sigma,&amp;\\Sigma A^T\\\\ A\\Sigma,&amp; A\\Sigma A^T\\end{array}\\right]\n\\right).$$</div>\n<p>Observing <span class=\"math\">\\(y=T(x)\\)</span> we have <span class=\"math\">\\(x | y \\sim \\mathcal{N}(\\bar{\\mu},\\bar{\\Sigma})\\)</span>, with</p>\n<div class=\"math\">$$\\bar{\\mu} = \\mu + \\Sigma A^T (A \\Sigma A^T)^{-1} (y-(A\\mu + b)),$$</div>\n<div class=\"math\">$$\\bar{\\Sigma} = \\Sigma - \\Sigma A^T (A \\Sigma A^T)^{-1} A \\Sigma.$$</div>\n<script type=\"text/javascript\">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {\n    var align = \"center\",\n        indent = \"0em\",\n        linebreak = \"false\";\n\n    if (false) {\n        align = (screen.width < 768) ? \"left\" : align;\n        indent = (screen.width < 768) ? \"0em\" : indent;\n        linebreak = (screen.width < 768) ? 'true' : linebreak;\n    }\n\n    var mathjaxscript = document.createElement('script');\n    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';\n    mathjaxscript.type = 'text/javascript';\n    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';\n\n    var configscript = document.createElement('script');\n    configscript.type = 'text/x-mathjax-config';\n    configscript[(window.opera ? \"innerHTML\" : \"text\")] =\n        \"MathJax.Hub.Config({\" +\n        \"    config: ['MMLorHTML.js'],\" +\n        \"    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } },\" +\n        \"    jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" +\n        \"    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" +\n        \"    displayAlign: '\"+ align +\"',\" +\n        \"    displayIndent: '\"+ indent +\"',\" +\n        \"    showMathMenu: true,\" +\n        \"    messageStyle: 'normal',\" +\n        \"    tex2jax: { \" +\n        \"        inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" +\n        \"        displayMath: [ ['$$','$$'] ],\" +\n        \"        processEscapes: true,\" +\n        \"        preview: 'TeX',\" +\n        \"    }, \" +\n        \"    'HTML-CSS': { \" +\n        \"        availableFonts: ['STIX', 'TeX'],\" +\n        \"        preferredFont: 'STIX',\" +\n        \"        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" +\n        \"        linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" +\n        \"    }, \" +\n        \"}); \" +\n        \"if ('default' !== 'default') {\" +\n            \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" +\n                \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" +\n                \"VARIANT['normal'].fonts.unshift('MathJax_default');\" +\n                \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" +\n                \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" +\n                \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" +\n            \"});\" +\n            \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" +\n                \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" +\n                \"VARIANT['normal'].fonts.unshift('MathJax_default');\" +\n                \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" +\n                \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" +\n                \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" +\n            \"});\" +\n        \"}\";\n\n    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);\n    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);\n}\n</script>",
  "category": ""
}