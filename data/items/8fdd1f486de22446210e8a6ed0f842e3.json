{
  "title": "Things I wish someone told me about microscopy",
  "description": "<h2 id=\"if-you-want-to-learn-some-culprits-of-microscopy\">If you want to learn some culprits of microscopy</h2>\n\n<p>… you’d better watch this video by microbehunter,\nbecause rest of the post is view of ML person on things \nyou should (not) expect from lab microscopy during experiment design.</p>\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Ir9TGt6zljI\" frameborder=\"0\" allow=\"clipboard-write; encrypted-media; picture-in-picture\" allowfullscreen=\"\">\n</iframe>\n\n<p><strong>Warning:</strong><br />\nThis post contains reflections and is not meant to be an easy reading.<br />\nThis post assumes that you understand wave mechanics.</p>\n\n<p>I have a nice general background in physics,\nhowever just that was clearly insufficient — a lot of specificity towards.</p>\n\n<h2 id=\"things-i-wanted-to-know-about-microscopy\">Things I wanted to know about microscopy</h2>\n\n<ul>\n  <li>there are myriads of different microscopes from trivial ones for mid-schools to EM (electron microscopes) and light-sheets\n    <ul>\n      <li>Ranges of prices from hundreds of dollars to millions. In some applications 100x cheaper microscope can still be more useful</li>\n      <li>Manual and automated. Terribly expensive still may not be automated</li>\n    </ul>\n  </li>\n  <li>microscopes are typically designed to be modular, many parts are interchangeable;\nthere is still vendor- and format- specificity</li>\n  <li>when microscope is automated, that typically means that it can at least move its specimen\n(yes, specimen is moved, microscope’s camera and light path are usually steady)\n    <ul>\n      <li>it may or may not be able to switch excitation / emission filters automatically, so ‘automated’ is not a descriptive word. \nAsk about what is automated</li>\n    </ul>\n  </li>\n  <li>while typically microscopes are just ‘make a photo with light’ devices, software for microscopes is a tough topic.\n    <ul>\n      <li>manufacturers want to provide visual interface with windows and buttons, \nbut amount of regimes of possible usage is terribly large, \nand those hardly can be mapped to sequence of buttons</li>\n      <li>as a result both API and interface are far from satisfactory</li>\n    </ul>\n  </li>\n  <li>light source is not moved with specimen, but instead aligned and fixed relative to camera.\n    <ul>\n      <li>You can’t image with different shifts but ‘same light position’</li>\n    </ul>\n  </li>\n  <li>immersion is quite critical when going to higher resolutions (above 20x)</li>\n  <li>objective on a microscope has everything aligned and focusing depth can be adjusted or changed.\n(objectives are also pretty expensive). That’s not your smartphone’s refocusing camera. \nSo 40x on your microscope means that object of size n<em>m in focusing plane (which is fixed) \nliterally projects in 40n</em>40m on detector plane. \nTo complete arithmetics you only need physical size of pixel in a camera - and voila - you have size of pixel.</li>\n  <li>for a long time I was surprised that biologists are on one hand limited by the number of fluorescent channels\nthey can image simultaneously (emission spectra overlap, so you want them to be separable).\n    <ul>\n      <li>At the same time they don’t switch to quantum dots (which have much narrower emission spectra).\nPermeability may be an issue here</li>\n      <li>And they don’t try to go significantly outside of visible spectrum.\n        <ul>\n          <li><em>probably</em> this is due to objectives - correcting aberrations for wide spectrum range is tough</li>\n        </ul>\n      </li>\n      <li>Another factor is penetration depths variability (even within water) for different wavelengths</li>\n      <li>You can take images in IR, but going to deep IR is still rare</li>\n    </ul>\n  </li>\n  <li>there is an uncountable amount of imaging techniques. <br />\nDozens of them with all their variations, with all covering only some part of information.\n    <ul>\n      <li>Very hard to combine many in the same system (while some useful combinations exist)</li>\n      <li>Dream of machine learner - having different imaging systems for the same specimen - can be implemented only in specific cases</li>\n    </ul>\n  </li>\n  <li>more powerful microscope requires identical efforts on sample/environment side\n    <ul>\n      <li>Higher magnification requires better compensation of motion</li>\n      <li>More sensitive to optical properties means you’ll see more artifacts from anything in your system. \nOr maybe plates or slides.\n        <ul>\n          <li>E.g. if method can detect birefringence, any plastic labware is likely to add some birefringence patterns</li>\n        </ul>\n      </li>\n    </ul>\n  </li>\n  <li>well edges introduce significant effects, plate edges also introduce some effects for imaging (both also affect biological processes)</li>\n  <li><a href=\"https://www.youtube.com/user/iBioEducation\">ibiology</a> provides an amazing combination of theory and practice of imaging.\nIt was incredibly helpful</li>\n  <li>imaging protocols are hardly readable. Too many things and parameters, no deduplication.\n    <ul>\n      <li>They remind completely unwrapped low-level code for execution by machine, not ‘settings’.</li>\n      <li>I’ve told about software being tough here, right? There are issues with interfaces on all levels</li>\n    </ul>\n  </li>\n  <li>imaging time is a real issue\n    <ul>\n      <li>“oh, we can just increase stack size” is correct solution to many questions in theory, \n but not in practice</li>\n    </ul>\n  </li>\n  <li>reproducible focusing may be an issue</li>\n  <li>richest sources of information are available only for ex-vivo cells and tissues</li>\n  <li>anything that produces nice high-resolution images will be called by biologist “confocal” \nno matter if confocality is actually used there :)</li>\n  <li>believe data, always believe data. \nIf you think something is misaligned - it almost surely is.</li>\n</ul>\n\n<h2 id=\"contrasting-methods\">Contrasting methods</h2>\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/FUa1GTc69y4\" f=\"\" rameborder=\"0\" allow=\"autoplay; clipboard-write; encrypted-media; picture-in-picture\" allowfullscreen=\"\"></iframe>\n\n<p>The main way to achieve contrast is by using monochromatic (i.e. laser) light, \nand achieve shift in phase between “rays” started from the same source. \nShift in phase affected by specimen provides a contrast visible by a simple detector.</p>\n\n<ul>\n  <li>Simplest example is <a href=\"https://www.olympus-lifescience.com/en/microscope-resource/primer/techniques/dic/dicconfiguration/\">DIC</a> \n(differential interference contrast) - light is split in two parts, \nwhich come through neighboring positions in slide</li>\n  <li>Another example is polarization contrast, where light comes though the same specimen but \ndue to <a href=\"https://en.wikipedia.org/wiki/Birefringence\">birefringence</a> of some materials different polarizations come with different speed, \nwhich produces retardation of one polarization</li>\n  <li><a href=\"https://www.microscopyu.com/tutorials/comparison-of-phase-contrast-and-dic-microscopy\">Phase contrast</a> \norganizes interference between scattered and passed through waves.\nPhase delay adds phase to scattered light. Simplest to setup of these three.</li>\n</ul>\n\n<p>An important property of contrasting optical paths is that optical path lengths \nfor light arriving to the same location should be identical (unless sample perturbations prevent this).\nOptical path is not distance, but time taken by light to travel along a trajectory.</p>\n\n<p>That’s a simple thought and sounds like a natural, but when you look at optical system with all its lenses, \nyou should realize it’s non-trivial behavior.</p>\n\n<h2 id=\"amazing-variability-of-imaging-techniques\">Amazing variability of imaging techniques</h2>\n\n<p>Microscopy world is very limited within one lab (even optical lab) \nbut whole large world of microscopy is so rich and interesting out there.</p>\n\n<ul>\n  <li>Multi-photon imaging\n    <ul>\n      <li>deliver energy required for excitation with several photon simultaneously</li>\n      <li>requires an expensive laser, but imaging is simple</li>\n      <li>can go quite deep into tissue</li>\n      <li>can’t guarantee narrow emission spectra because different number of ph</li>\n    </ul>\n  </li>\n  <li>Electron microscopy\n    <ul>\n      <li>super precise (it’s completely different part of spectra)</li>\n      <li>ex-vivo samples only</li>\n      <li>requires isolated rooms and strong movement compensation</li>\n      <li>not something you will simply hold in a lab, but provides extremely detailed image</li>\n    </ul>\n  </li>\n  <li>LSM: light-sheet microscopy is a demonstration that light source does not have to be on the same axis,\nwhile it sounds like an axiom after lab scopes\n    <ul>\n      <li>LLSM is times cooler</li>\n    </ul>\n  </li>\n  <li>\n    <p>TIRF (total internal reflection) microscopy when combined with photo-activable fluorescent proteins (PALM/STORM) \ncan get to tracking trajectories of individual proteins (while still using visible range spectrum).</p>\n  </li>\n  <li>\n    <p>Another interesting idea is FRET - allows detecting interaction between single molecules \nif those have appropriate fluorescent tags. <br />\nPhotons emitted by one antibody are absorbed by the second one if molecules are in proximity of each other.</p>\n  </li>\n  <li><a href=\"https://www.youtube.com/watch?v=HJnNJIUPm4s\">optical coherence tomography</a> OCT\n    <ul>\n      <li>has nothing to do with tomography and even works based on reflected light</li>\n      <li>widely used for retina scanning</li>\n    </ul>\n  </li>\n  <li><a href=\"https://www.youtube.com/watch?v=tTHvVCPaeWQ\">Ghost imaging</a>. Not-yet-there, but idea is mind-blowing\n    <ul>\n      <li>entangle two photons</li>\n      <li>the first one hits the target, while the second goes to detector</li>\n      <li>entanglement allows partially reconstructing properties of a photon that hit the target</li>\n      <li>there are classical variations as well</li>\n    </ul>\n  </li>\n  <li>Structured illumination (SIM)\n    <ul>\n      <li>Moir patterns + a bit of computational magic allows you going slightly \nabove optical resolution limit</li>\n    </ul>\n  </li>\n</ul>\n\n<p>You may want to check this video \nto orient yourself a bit and get a sense of what sounds appropriate for your case.</p>\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/01v2kR8dlnQ\" frameborder=\"0\" allow=\"autoplay; clipboard-write; encrypted-media; picture-in-picture\" allowfullscreen=\"\"></iframe>",
  "pubDate": "Sun, 01 Nov 2020 12:00:00 +0000",
  "link": "https://arogozhnikov.github.io/2020/11/01/microscopy.html",
  "guid": "https://arogozhnikov.github.io/2020/11/01/microscopy.html",
  "category": "Microscopy"
}