{
  "title": "Simplify your PyTorch model using PyTorch Lightning",
  "description": "<p>Code for machine learning can get repetitive. In this blog post, you will learn to combat code repetition by using PyTorch Lightning.</p><p>Some code of machine learning can get highly repetitive. Think for example of the times you had to write a train loop, logging the evaluation results. Also loading</p>",
  "link": "https://www.data-blogger.com/simplify-your-pytorch-model-using-pytorch-lightning/",
  "guid": "622cfeb9092f120001a24e09",
  "category": [
    "Python",
    "Neural Networks"
  ],
  "dc:creator": "Kevin Jacobs",
  "pubDate": "Fri, 11 Jun 2021 00:00:00 GMT",
  "media:content": "",
  "content:encoded": "<img src=\"https://www.data-blogger.com/content/images/2022/03/Screenshot-2022-03-12-at-21.14.12.png\" alt=\"Simplify your PyTorch model using PyTorch Lightning\"><p>Code for machine learning can get repetitive. In this blog post, you will learn to combat code repetition by using PyTorch Lightning.</p><p>Some code of machine learning can get highly repetitive. Think for example of the times you had to write a train loop, logging the evaluation results. Also loading and storing the model is a task that is often performed. With PyTorch lightning, you can get rid of the repetitive code by wrapping your code in a PyTorch Lightning module. Yet, all of the parts are fully customizable. You can define your own loading and storing procedures and you own evaluation code and train code.</p><pre><code class=\"language-python\">import torch\nfrom torch.nn import functional as F\nfrom torch import nn\nfrom transformers import AdamW\nimport pandas as pd\nimport numpy as np\nfrom sklearn.metrics import classification_report\nimport pytorch_lightning as pl\nfrom torch.utils.data import Dataset\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader\nfrom transformers import AutoTokenizer, AutoModel\nfrom sklearn.metrics import f1_score\n\nclass LitLegalBertClassifier(pl.LightningModule):\n\n    def __init__(self, encoder, model):\n        super().__init__()\n        self.encoder = encoder\n        self.model = model\n\n    def forward(self, x):\n        # in lightning, forward defines the prediction/inference actions\n        embedding = self.encoder(x)\n        return embedding\n\n    def training_step(self, batch, batch_idx):\n        # training_step defines the train loop. It is independent of forward\n        x, attention_mask = self.encoder(batch)\n        y_true = batch['label']\n        y_pred = self.model(x, attention_mask=attention_mask)\n        loss = F.cross_entropy(y_pred, y_true)\n        self.log('train_loss', loss)\n        return loss\n    \n    def validation_step(self, batch, batch_idx):\n        y_pred_proba = base_model(*encoder(batch))\n        y_pred = y_pred_proba.argmax(dim=1).numpy()\n        y_true = batch['label'].numpy()\n        idxs_to_labels = lambda idxs: np.array([ds_test.idx_to_label[idx] for idx in idxs])\n        scores = dict()\n        for label in ds_test.labels:\n            scores[label] = f1_score(idxs_to_labels(y_true) == label, idxs_to_labels(y_pred) == label)\n            self.log('f1_' + label, scores[label])\n        return scores\n\n    def configure_optimizers(self):\n        optimizer = AdamW(self.parameters(), lr=1e-5)\n        return optimizer\n    \n# Load the base model\nbase_model = LegalBertClassifierv2(legalbert, n_classes=3)\n# Wrap it in a PyTorch Lightning module\nmodel = LitLegalBertClassifier(encoder, base_model)\n# Here is my train dataloader\ntrain_dataloader = DataLoader(ds_train, batch_size=4, shuffle=True)\n# And the test dataloader\ntest_dataloader = DataLoader(ds_test, batch_size=len(ds_test), shuffle=False)\n# Setup a trainer\ntrainer = pl.Trainer(max_epochs=None, val_check_interval=1.0)\n# And fit the model using the train dataloader and test dataloader\ntrainer.fit(model, train_dataloader, test_dataloader)</code></pre><p>So, this approach will costs you some time in the beginning, but it will save you a lot of time when refactoring your code. I am currently using this in my research projects. What are your favorite tools and libraries for simplifying ML code?</p>"
}