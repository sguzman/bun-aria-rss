{
  "title": "On Model Mismatch and Bayesian Analysis",
  "link": "http://dustintran.com/blog/on-model-mismatch-and-bayesian-analysis",
  "guid": "http://dustintran.com/blog/on-model-mismatch-and-bayesian-analysis",
  "description": "<p>One aspect I always enjoy about machine learning is that questions\noften go back to the basics. The field essentially goes into an\nexistential crisis every dozen years—rethinking our tools and asking foundational questions\nsuch as “why neural networks” or “why generative models”.<sup>1</sup></p>\n\n<p>This was a theme in my conversations during\n<a href=\"https://nips.cc/Conferences/2016\">NIPS 2016</a> last week, where a\nfrequent topic was\non the advantages of a Bayesian perspective to machine learning.\nNot surprisingly, this appeared as a big discussion point during the\npanel at the <a href=\"http://bayesiandeeplearning.org\">Bayesian deep learning\nworkshop</a>, where many\npanelists were conciliatory to the use of non-Bayesian approaches.\n(Granted, much of it was Neil trolling them to admit when non-Bayesian\napproaches worked better in practice.)</p>\n\n<p>One argument against Bayesian analysis went as follows:</p>\n\n<blockquote>\n  <p>While Bayesian inference can capture uncertainty about parameters,\nit relies on the model being correctly specified. However, in\npractice, all models are wrong. And in fact, this model mismatch can\nbe often be large enough that we should be more concerned with\ncalibrating our inferences to correct for the mismatch than to\nproduce uncertainty estimates from incorrect assumptions.</p>\n</blockquote>\n\n<p>A related complaint was on the separation of model and\ninference, a philosophical point commonly associated with Bayesians:</p>\n\n<blockquote>\n  <p>While in principle it is nice that we can build models separate from\nour choice of inference, we often need to combine the two in practice. (The whole\nnaming behind the popular model-inference classes of “variational\nauto-encoders” <a href=\"#kingma2014autoencoding\">(Kingma &amp; Welling, 2014)</a>\nand “generative adversarial networks” <a href=\"#goodfellow2014generative\">(Goodfellow et al., 2014)</a> are one\nexample.) That is, we often choose our model based on what we know\nenables fast inferences, or we select hyperparameters in our model\nfrom data. This goes against the Bayesian paradigm.</p>\n</blockquote>\n\n<p>First, I’d like to say immediately that I think interpreting Bayesian\nanalysis as a two-step procedure of setting up a probability model,\nthen performing posterior inference is outdated. Certainly this was the\nprevailing perspective back in the 80s’ and 90s’ when Markov chain Monte Carlo\nwas first popularized, and when statisticians started to take Bayesian analysis\nmore seriously <a href=\"#robert2011short\">(Robert &amp; Casella, 2011)</a>.</p>\n\n<p>Quoting <a href=\"#gelman2012philosophy\">Gelman &amp; Shalizi (2012)</a>\nwho summarize this perspective,\n“The expression <script type=\"math/tex\">p(\\theta\\mid y)</script> says it all, and the central goal of Bayesian inference is computing the posterior probabilities of hypotheses. Anything not contained in the posterior distribution <script type=\"math/tex\">p(\\theta\\mid y)</script> is simply irrelevant, and it would be irrational (or incoherent) to attempt falsification, unless that somehow shows up in the posterior.”</p>\n\n<p><strong>Like many statisticians before me</strong>\n(e.g., <a href=\"#box1980sampling\">Box (1980)</a>,\n<a href=\"#good1983good\">Good (1983)</a>,\n<a href=\"#rubin1984bayesianly\">Rubin (1984)</a>,\n<a href=\"#jaynes2003probability\">Jaynes (2003)</a>),\n<strong>I believe this perspective is wrong. Bayesian analysis is no\ndifferent in its testing and falsification of models than any other\ninferential paradigm</strong>\n(<a href=\"#fisher1925statistical\">Fisher (1925)</a>,\n<a href=\"#neyman1933on\">Neyman &amp; Pearson (1933)</a>).</p>\n\n<p>An important third step to all empirical analyses is <em>model criticism</em>\n(<a href=\"#box1980sampling\">Box (1980)</a>,\n<a href=\"#ohagan2011hsss\">O’Hagan (2001)</a>\n),\nalso known as model\nvalidation, or model\nchecking and diagnostics\n(<a href=\"#rubin1984bayesianly\">Rubin (1984)</a>,\n<a href=\"#meng1994posterior\">Meng (1994)</a>,\n<a href=\"#gelman1996posterior\">Gelman, Meng, &amp; Stern (1996)</a>).\nIn criticizing our models after inference, we can either justify\nuse of the model or find directions in which we can revise the model.\nBy revising the model, we go back to the modeling step, thus forming\na loop, called <em>Box’s loop</em>\n(<a href=\"#box1976science\">Box (1976)</a>,\n<a href=\"#blei2014build\">Blei (2014)</a>,\n<a href=\"#gelman2013bayesian\">Gelman et al. (2013)</a>).\n<sup>2</sup></p>\n\n<p>From my perspective, this solves the perceived problem of conflating\nmodel and inference, whether it be to address model mismatch or to\nbuild the model from previous inferences or data.\nThat is, while\nposterior inference is simply a mechanical step of calculating a\nconditional distribution, the\nstep of model criticism is about the relevance of the model to future\ndata—to put it in statistical terms, the relevance of the model with\nrespect to a population distribution\n<a href=\"#wasserman2006frequentist\">(Wasserman, 2006)</a>.\nAs with data, the model is\njust a source of information, and posterior inference simply aggregates these\ntwo sources of information. Thus it\nmakes sense that as we better understand properties of the data, we\ncan revise our information to better formulate a model of it\n<a href=\"#tukey1977exploratory\">(Tukey, 1977)</a>.</p>\n\n<p>This might sound like an awkward way to shoehorn Bayesian analysis to\nmimick frequentist properties, or no different from combining model\nand inference from the get-go.\nHowever, this loop is fundamental because it still emphasizes the\nimportance of separating the two.  We can continue to form\nhypothetico-deductive analyses—namely, a falsificationist view of\nthe world where components of model, inference, and criticism\ninteract—while still incorporating posterior probabilities.</p>\n\n<p>For more details, I highly recommend\n<a href=\"#gelman2012philosophy\">Gelman &amp; Shalizi (2012)</a>\nand of course the classic,\n<a href=\"#rubin1984bayesianly\">Rubin (1984)</a>.</p>\n\n<p><sup>1</sup>\nI take an optimistic viewpoint to the trend of cycling among tools for\nmachine learning. The trend is based on what works best empirically,\nand I think that’s important.</p>\n\n<p><sup>2</sup>\nAs a plug, I should also mention that this is what <a href=\"http://edwardlib.org\">Edward</a> is all about.</p>\n\n<h2 id=\"references\">References</h2>\n\n<ol class=\"bibliography\"><li><span id=\"blei2014build\">Blei, D. M. (2014). Build, compute, critique, repeat: Data analysis with latent variable models. <i>Annual Review of Statistics and Its Application</i>.</span></li>\n<li><span id=\"box1980sampling\">Box, G. E. P. (1980). Sampling and Bayes’ inference in scientific modelling and robustness. <i>Journal of the Royal Statistical Society. Series A. General</i>, <i>143</i>(4), 383–430.</span></li>\n<li><span id=\"box1976science\">Box, G. E. P. (1976). Science and statistics. <i>Journal of the American Statistical Association</i>, <i>71</i>(356), 791–799.</span></li>\n<li><span id=\"fisher1925statistical\">Fisher, R. A. (1925). <i>Statistical Methods for Research Workers</i>. Genesis Publishing Pvt Ltd.</span></li>\n<li><span id=\"gelman2013bayesian\">Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., &amp; Rubin, D. B. (2013). <i>Bayesian data analysis</i> (Third). CRC Press, Boca Raton, FL.</span></li>\n<li><span id=\"gelman1996posterior\">Gelman, A., Meng, X.-L., &amp; Stern, H. (1996). Posterior predictive assessment of model fitness via realized discrepancies. <i>Statistica Sinica</i>.</span></li>\n<li><span id=\"gelman2012philosophy\">Gelman, A., &amp; Shalizi, C. R. (2012). Philosophy and the practice of Bayesian statistics. <i>British Journal of Mathematical and Statistical Psychology</i>, <i>66</i>(1), 8–38.</span></li>\n<li><span id=\"good1983good\">Good, I. J. (1983). <i>Good thinking: The foundations of probability and its applications</i>. U of Minnesota Press.</span></li>\n<li><span id=\"goodfellow2014generative\">Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., … Bengio, Y. (2014). Generative Adversarial Nets. In <i>Neural Information Processing Systems</i>.</span></li>\n<li><span id=\"jaynes2003probability\">Jaynes, E. T. (2003). Probability theory: The logic of science. Washington University St. Louis, MO.</span></li>\n<li><span id=\"kingma2014autoencoding\">Kingma, D. P., &amp; Welling, M. (2014). Auto-Encoding Variational Bayes. In <i>International Conference on Learning Representations</i>.</span></li>\n<li><span id=\"meng1994posterior\">Meng, X.-L. (1994). Posterior predictive p-values. <i>The Annals of Statistics</i>.</span></li>\n<li><span id=\"neyman1933on\">Neyman, J., &amp; Pearson, E. S. (1933). On the Problem of the Most Efficient Tests of Statistical Hypotheses. <i>Philosophical Transactions of the Royal Society A Mathematical, Physical and Engineering Sciences</i>, <i>231</i>, 289–337.</span></li>\n<li><span id=\"ohagan2011hsss\">O’Hagan, A. (2001). <i>HSSS model criticism</i>. University of Sheffield, Department of Probability and Statistics.</span></li>\n<li><span id=\"robert2011short\">Robert, C., &amp; Casella, G. (2011). A short history of Markov Chain Monte Carlo: subjective recollections from incomplete data. <i>Statistical Science</i>.</span></li>\n<li><span id=\"rubin1984bayesianly\">Rubin, D. B. (1984). Bayesianly justifiable and relevant frequency calculations for the applied statistician. <i>The Annals of Statistics</i>, <i>12</i>(4), 1151–1172.</span></li>\n<li><span id=\"tukey1977exploratory\">Tukey, J. W. (1977). Exploratory data analysis.</span></li>\n<li><span id=\"wasserman2006frequentist\">Wasserman, L. (2006). Frequentist Bayes is objective (comment on articles by Berger and by Goldstein). <i>Bayesian Analysis</i>, <i>1</i>(3), 451–456.</span></li></ol>",
  "pubDate": "Tue, 13 Dec 2016 00:00:00 -0800"
}