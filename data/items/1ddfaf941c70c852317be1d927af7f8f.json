{
  "title": "Coverage versus Confidence",
  "link": "https://www.mathematica-journal.com/2021/03/03/coverage-versus-confidence/",
  "comments": "https://www.mathematica-journal.com/2021/03/03/coverage-versus-confidence/#respond",
  "pubDate": "Wed, 03 Mar 2021 23:04:02 +0000",
  "dc:creator": "Todd Akers",
  "category": "Volume 23",
  "guid": "https://www.mathematica-journal.com/?p=60865",
  "description": "https://doi.org/10.3888/tmj.23-1 This article is intended to help students understand the concept of a coverage probability involving confidence intervals. Mathematica is used as a language for describing an algorithm to compute the coverage probability for a simple confidence interval based on the binomial distribution. Then, higher-level functions are used to compute probabilities of expressions in order [&#8230;]",
  "content:encoded": "<div>\n<div class=\"DOIReference\"><span style=\"font-size: xx-small;\"><a href=\"https://doi.org/10.3888/tmj.23-1\">https://doi.org/10.3888/tmj.23-1</a></span></div>\n<div>\nThis article is intended to help students understand the concept of a coverage probability involving confidence intervals. Mathematica is used as a language for describing an algorithm to compute the coverage probability for a simple confidence interval based on the binomial distribution. Then, higher-level functions are used to compute probabilities of expressions in order to obtain coverage probabilities. Several examples are presented: two confidence intervals for a population proportion based on the binomial distribution, an asymptotic confidence interval for the mean of the Poisson distribution, and an asymptotic confidence interval for a population proportion based on the negative binomial distribution.<span id=\"more-60865\"></span></p>\n<h3>1. Introduction</h3>\n<p>Introductory courses in mathematical statistics present the rudimentary concepts behind confidence intervals. The creation of confidence intervals often involves the use of maximum likelihood estimation and the central limit theorem along with estimated standard errors.This is described in Casella and Berger [<a href=\"Casella-Berger\">1</a>] p. 497. Consequently, the level of confidence is often only approximate. This is particularly the case when continuous probability models are used to approximate discrete probabilities. The probability that the interval surrounds the unknown parameter depends on the value of the unknown parameter. Such a probability is called a <em>coverage probability</em>. Confidence is defined as the infimum of the coverage probabilities. The following definitions can be found in Casella and Berger [<a href=\"Casella-Berger\">1</a>] p. 418.</p>\n<p><span class=\"DisplayFormula\"><strong>Definition (Coverage and Confidence)</strong></span></p>\n<p>Let <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_1.gif\" alt=\"\" width=\"105\" height=\"12\" /> where the <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_2.gif\" alt=\"\" width=\"12\" height=\"12\" /> are all independent from a distribution with probability density (or discrete mass) function given by <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_3.gif\" alt=\"\" width=\"101\" height=\"12\" />. The support of each <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_4.gif\" alt=\"\" width=\"12\" height=\"12\" /> is <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_5.gif\" alt=\"\" width=\"8\" height=\"12\" /> and the parameter space is <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_6.gif\" alt=\"\" width=\"8\" height=\"12\" />. Let <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_7.gif\" alt=\"\" width=\"23\" height=\"12\" /> and <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_8.gif\" alt=\"\" width=\"25\" height=\"12\" /> be the lower and upper limits of a confidence interval. Then the coverage probability of the interval evaluated at <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_9.gif\" alt=\"\" width=\"5\" height=\"12\" /> is <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_10.gif\" alt=\"\" width=\"177\" height=\"12\" />. The level of confidence is <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_11.gif\" alt=\"\" width=\"88\" height=\"14\" />.</p>\n<p>Students are often confused about how to compute coverage probabilities. This tutorial is intended to help students understand them. We give a detailed explanation of calculating one particular coverage probability. This also allows one to perform the calculations with a minimum of distraction involving programming. We then compute coverage probabilities using higher-level functions <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_12.gif\" alt=\"\" width=\"79\" height=\"12\" /> and <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_13.gif\" alt=\"\" width=\"86\" height=\"12\" /> that allow specifying a function of a random variable along with its distribution. In both cases these functions allow one to focus on the higher-level ideas rather than low-level nuts and bolts of programming.</p>\n<p>Coverage probabilities are best calculated by computer. This necessitates the choice of a programming language and programming environment. Statisticians are generally familiar with one or more statistical programming languages such as SAS, R and so on. Such languages are necessary productivity tools due to their significant data handling capabilities as well as their statistical methods. They are indispensable to the statistician. However, they are not as useful as a language for describing algorithms. Small <span class=\"special-character OpenCurlyDoubleQuote\">“</span>bookkeeping&#8221; matters often obscure the algorithm or method to be calculated. This tutorial uses Mathematica as a language to describe the computation of coverage probabilities. With a little additional effort, one can produce graphs of coverage probabilities as well as dynamic demonstrations that use a slider to illustrate the effect of the sample size on the graph. The Wolfram Demonstrations Project website contains numerous Demonstrations involving a wide variety of topics. One such Demonstration provided by Heiner and Wagon [<a href=\"Heiner-Wagon\">2</a>] involves coverage probabilities for a population proportion using a Wald approach as well as a Bayesian approach. This article takes a different approach than Heiner and Wagon.</p>\n<p>We illustrate the idea of coverage (and hence confidence) with several examples.</p>\n<p>Section <a href=\"Section:2\">2</a> describes two asymptotically justified confidence intervals for estimating a population proportion based on the binomial distribution. The first confidence interval is a simple hand calculation interval contained in many textbooks. We present a step-by-step algorithm for computing the coverage probability for one specific value of the population parameter. We stress clarity of computation rather than efficiency. The approach is adequate for a population described by a discrete distribution with a finite number of possible values. We then compute the coverage probability using a much higher-level function, <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_14.gif\" alt=\"\" width=\"79\" height=\"12\" />, to automatically compute the probability associated with an inequality. We also use <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_15.gif\" alt=\"\" width=\"79\" height=\"12\" /> for subsequent calculations. We produce a typical graph of coverage probabilities found in some textbooks. The second confidence interval for a population proportion (again based on the binomial distribution) is more complicated but has gained popularity. Naturally, it will be seen that coverage probabilities are generally higher than the level of confidence when approximations are used to create a confidence interval. This is illustrated in the examples below.</p>\n<p>Section <a href=\"Section:3\">3</a> presents an asymptotically justified confidence interval for the mean of a population described by a Poisson distribution. The Poisson distribution has infinitely many possible observable values. The function <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_16.gif\" alt=\"\" width=\"79\" height=\"12\" /> used to evaluate coverage probabilities automatically takes this into account.</p>\n<p>Section <a href=\"Section:4\">4</a> presents a graph of coverage probabilities based on an asymptotically justified confidence interval for estimating a population proportion based on the negative binomial distribution.</p>\n<p>Section <a href=\"Section:5\">5</a> presents a summary.</p>\n<h3>2. A Population Proportion and the Binomial Distribution</h3>\n<h4>The Simplest Confidence Interval</h4>\n<p>A population has a proportion <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_17.gif\" alt=\"\" width=\"7\" height=\"12\" /> of members with a given characteristic. In order to estimate <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_18.gif\" alt=\"\" width=\"7\" height=\"12\" />, one randomly selects <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_19.gif\" alt=\"\" width=\"6\" height=\"12\" /> members of the population with replacement, say <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_20.gif\" alt=\"\" width=\"54\" height=\"12\" />, where the <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_21.gif\" alt=\"\" width=\"12\" height=\"12\" /> are independent and identically distributed random variables, each with a Bernoulli distribution with parameter <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_22.gif\" alt=\"\" width=\"7\" height=\"12\" />. If <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_23.gif\" alt=\"\" width=\"8\" height=\"12\" /> is the number of members in the random sample possessing the target characteristic, that is, <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_24.gif\" alt=\"\" width=\"112\" height=\"12\" />, then <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_25.gif\" alt=\"\" width=\"8\" height=\"12\" /> has a binomial distribution with parameters <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_26.gif\" alt=\"\" width=\"6\" height=\"12\" /> and <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_27.gif\" alt=\"\" width=\"7\" height=\"12\" />. The sample proportion of members with the characteristic is <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_28.gif\" alt=\"\" width=\"43\" height=\"14\" />. Two large sample confidence intervals for <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_29.gif\" alt=\"\" width=\"7\" height=\"12\" /> are typically given. We start with the simplest. A large sample confidence interval of size <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_30.gif\" alt=\"\" width=\"25\" height=\"12\" /> for<img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_31.gif\" alt=\"\" width=\"9\" height=\"12\" /> is given by</p>\n<table class=\"DisplayFormulaNumbered\">\n<tbody>\n<tr>\n<td><img src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_DisplayFormulaNumbered_1.gif\" alt=\"\" width=\"113\" height=\"23\" /></td>\n<td class=\"DisplayFormulaNumberedLabel\"><a name=\"Eq:1\"></a>(1)</td>\n</tr>\n</tbody>\n</table>\n<p>where <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_32.gif\" alt=\"\" width=\"19\" height=\"14\" /> is the upper <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_33.gif\" alt=\"\" width=\"21\" height=\"12\" /> part of the standard normal distribution.</p>\n<p>Let <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_34.gif\" alt=\"\" width=\"109\" height=\"23\" />, the standard error of <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_35.gif\" alt=\"\" width=\"7\" height=\"14\" />. So, we may shorten (<a href=\"Eq:1\">1</a>) by writing it as</p>\n<table class=\"DisplayFormulaNumbered\">\n<tbody>\n<tr>\n<td><img src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_DisplayFormulaNumbered_2.gif\" alt=\"\" width=\"69\" height=\"16\" /></td>\n<td class=\"DisplayFormulaNumberedLabel\"><a name=\"Eq:2\"></a>(2)</td>\n</tr>\n</tbody>\n</table>\n<p>One can find the confidence interval in expression (<a href=\"Eq:2\">2</a>) in virtually any statistics book; in particular, see Devore and Berk [<a href=\"Devore-Berk\">3</a>] p. 396. Also, coverage probabilities for this confidence interval are described in Brown, Cai and DasGupta [<a href=\"Brown-Cai-DasGupta\">4</a>]. The derivation of the interval leads one to believe that the level of confidence is <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_36.gif\" alt=\"\" width=\"25\" height=\"12\" />. However, two approximations are used to derive the interval in expression (<a href=\"Eq:2\">2</a>). One approximation uses the central limit theorem. A second approximation uses an estimated variance for the sampling distribution of the sample proportion <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_37.gif\" alt=\"\" width=\"7\" height=\"12\" />. We want to compute the actual coverage probability for any possible value of the true population proportion <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_38.gif\" alt=\"\" width=\"7\" height=\"12\" />. The coverage probability is</p>\n<table class=\"DisplayFormulaNumbered\">\n<tbody>\n<tr>\n<td><img src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_DisplayFormulaNumbered_3.gif\" alt=\"\" width=\"272\" height=\"18\" /></td>\n<td class=\"DisplayFormulaNumberedLabel\"><a name=\"Eq:3\"></a>(3)</td>\n</tr>\n</tbody>\n</table>\n<p>where <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_39.gif\" alt=\"\" width=\"43\" height=\"14\" />. Books are sometimes vague about whether or not to include the endpoints in the inequality. We exclude the endpoints in order to be consistent with typical hypothesis testing methods.</p>\n<p>The definition of coverage confuses many students. For a given value of <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_40.gif\" alt=\"\" width=\"7\" height=\"12\" /> with <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_41.gif\" alt=\"\" width=\"47\" height=\"12\" />, one must determine the set values of <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_42.gif\" alt=\"\" width=\"8\" height=\"12\" /> satisfying the inequality in expression (<a href=\"Eq:3\">3</a>) and compute the probability of observing such values of <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_43.gif\" alt=\"\" width=\"8\" height=\"12\" />. We will describe how to determine the set of values and then compute their probability. Once we know what is actually being computed, we will move on to higher-level functions that perform the computations automatically.</p>\n<p>We use an example with <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_44.gif\" alt=\"\" width=\"32\" height=\"12\" />. A plot will show how bad the approximation can be and also displays the output of each step of the algorithm. We will compute the coverage probability for <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_45.gif\" alt=\"\" width=\"36\" height=\"12\" />. The input and output are presented in a conversational style with some editorial comments along the way.</p>\n<p>We wish to determine the upper <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_46.gif\" alt=\"\" width=\"15\" height=\"12\" /> percentage value from the standard normal distribution. The variable <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_47.gif\" alt=\"\" width=\"14\" height=\"12\" /> is often called a critical value for the standard normal distribution. The result will be a floating-point number, which restricts the accuracy and precision of all calculations that use it; the result of this calculation is a floating-point number.</p>\n<p class=\"input\"><img src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Input_1.gif\" alt=\"\" width=\"320\" height=\"12\" /></p>\n<p class=\"output\"><img src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Output_1.gif\" alt=\"\" width=\"50\" height=\"12\" /></p>\n<p>Define <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_48.gif\" alt=\"\" width=\"14\" height=\"12\" />.</p>\n<p class=\"input\"><img src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Input_2.gif\" alt=\"\" width=\"162\" height=\"38\" /></p>\n<p>Here is the confidence interval inequality for sample size 10 and general <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_49.gif\" alt=\"\" width=\"7\" height=\"12\" />.</p>\n<p class=\"input\"><img src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Input_3.gif\" alt=\"\" width=\"365\" height=\"12\" /></p>\n<p class=\"output\"><img src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Output_2.gif\" alt=\"\" width=\"382\" height=\"39\" /></p>\n<p>The support of the random variable <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_50.gif\" alt=\"\" width=\"8\" height=\"12\" /> is the set of values <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_51.gif\" alt=\"\" width=\"6\" height=\"12\" /> for which the probability mass function is positive. They also represent the observable values of <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_52.gif\" alt=\"\" width=\"8\" height=\"12\" /> for a discrete random variable. We represent the support of <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_53.gif\" alt=\"\" width=\"8\" height=\"12\" /> with the programming variable <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_54.gif\" alt=\"\" width=\"14\" height=\"12\" />.</p>\n<p class=\"input\"><img src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Input_4.gif\" alt=\"\" width=\"111\" height=\"12\" /></p>\n<p class=\"output\"><img src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Output_3.gif\" alt=\"\" width=\"208\" height=\"12\" /></p>\n<p>This tests whether the inequality is true for each value of <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_55.gif\" alt=\"\" width=\"8\" height=\"12\" /> and probability 0.5.</p>\n<p class=\"input\"><img src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Input_5.gif\" alt=\"\" width=\"203\" height=\"12\" /></p>\n<p class=\"output\"><img src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Output_4.gif\" alt=\"\" width=\"485\" height=\"12\" /></p>\n<p>These are the positions that yield <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_56.gif\" alt=\"\" width=\"29\" height=\"12\" />; <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_57.gif\" alt=\"\" width=\"50\" height=\"12\" /> eliminates one level of parentheses. We wish to compute the probabilities of <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_52.gif\" alt=\"\" width=\"8\" height=\"12\" /> at those positions and sum them.</p>\n<p class=\"input\"><img src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Input_6.gif\" alt=\"\" width=\"305\" height=\"12\" /></p>\n<p class=\"output\"><img src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Output_5.gif\" alt=\"\" width=\"93\" height=\"12\" /></p>\n<p>These are the appropriate values of the variable <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_52.gif\" alt=\"\" width=\"8\" height=\"12\" />.</p>\n<p class=\"input\"><img src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Input_7.gif\" alt=\"\" width=\"193\" height=\"12\" /></p>\n<p class=\"output\"><img src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Output_6.gif\" alt=\"\" width=\"93\" height=\"12\" /></p>\n<p>Now one computes the probabilities for the individual values of <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_52.gif\" alt=\"\" width=\"8\" height=\"12\" /> satisfying the inequality.</p>\n<p class=\"input\"><img src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Input_8.gif\" alt=\"\" width=\"397\" height=\"12\" /></p>\n<p class=\"output\"><img src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Output_7.gif\" alt=\"\" width=\"348\" height=\"12\" /></p>\n<p>Finally, the values of the individual probabilities are summed to create the actual coverage probability for <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_58.gif\" alt=\"\" width=\"36\" height=\"12\" />.</p>\n<p class=\"input\"><img src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Input_9.gif\" alt=\"\" width=\"52\" height=\"12\" /></p>\n<p class=\"output\"><img src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Output_8.gif\" alt=\"\" width=\"58\" height=\"12\" /></p>\n<p>The steps have been broken down so that students can easily understand what is needed. A large sample justification leads us to believe that this number should be about 0.95. The coverage probability is about 0.89 rather than 0.95.</p>\n<p>Here is a much more transparent manner in which to compute the coverage probability. We may use a system function for evaluating the probability of expressions of a random variable. Apparently, the system function automatically tests each possible value of the random variable to determine the ones that satisfy the inequality. (This works quite well for a discrete random variable with a finite number of observable values.) The relevant probabilities are then summed. This approach is not efficient in cases with infinitely many observable values of a random variable. However, it is straightforward and easy for a student to understand. We evaluate the probability of an expression involving the binomial random variable. The expression of the binomial random variable is the confidence interval inequality.</p>\n<p>Let us define a function that constructs the inequality more explicitly.</p>\n<p class=\"input\"><img src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Input_10.gif\" alt=\"\" width=\"273\" height=\"124\" /></p>\n<p>Define the function that computes the coverage.</p>\n<p class=\"input\"><img src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Input_11.gif\" alt=\"\" width=\"257\" height=\"103\" /></p>\n<p>We now plot the coverage probabilities for a range of values of <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_59.gif\" alt=\"\" width=\"7\" height=\"12\" /> in Figure <a href=\"Fig:1\">1</a> below. We also create a horizontal line at a level of 0.95 for comparison purposes. The graph is symmetric due to properties of the binomial distribution and the large sample approximation involved in the confidence interval justification.</p>\n<p class=\"input\"><img src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Input_12.gif\" alt=\"\" width=\"352\" height=\"73\" /></p>\n<p class=\"output\"><img src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Output_9.gif\" alt=\"\" width=\"360\" height=\"236\" /></p>\n<p class=\"NumberedFigureCaption\"><strong>Figure 1.</strong> Coverage plot for first binomial confidence interval, <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_60.gif\" alt=\"\" width=\"25\" height=\"12\" />.</p>\n<p>Examining Figure <a href=\"Fig:1\">1</a> indicates several points. First, the coverage probabilities are in general not equal to the nominal level of confidence<span class=\"special-character LongDash\">—</span>namely .95. Moreover, coverage probabilities near <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_61.gif\" alt=\"\" width=\"27\" height=\"12\" /> and <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_62.gif\" alt=\"\" width=\"27\" height=\"12\" /> are effectively zero. Finally, the coverage probability function is discontinuous. All this with a minimum level of programming. In fact, the programming statements presented are simply a good description of the algorithm.</p>\n<p>More is available. We wish to be able to change the plot by varying the sample size with a slider. A dynamic demonstration can easily be created with the <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_63.gif\" alt=\"\" width=\"72\" height=\"12\" /> function. The manipulate variable is the sample size <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_64.gif\" alt=\"\" width=\"6\" height=\"12\" />, which you can vary with a slider from 5 to 100.</p>\n<p>The graph is in Figure <a href=\"Fig:2\">2</a>. The computer processing time increases with the value of the sample size <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_65.gif\" alt=\"\" width=\"6\" height=\"12\" /> because the inequality must be tested for each possible value of <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_66.gif\" alt=\"\" width=\"8\" height=\"12\" />. The initial sample size is <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_67.gif\" alt=\"\" width=\"32\" height=\"12\" />.</p>\n<p class=\"input\"><img src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Input_13.gif\" alt=\"\" width=\"353\" height=\"163\" /></p>\n<p class=\"output\"><img src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Output_10.gif\" alt=\"\" width=\"403\" height=\"340\" /></p>\n<p class=\"NumberedFigureCaption\"><strong>Figure 2.</strong> Coverage plot as a function of sample size.</p>\n<p>A larger sample size improves the coverage probabilities as one expects. After all, the confidence interval formula is justified by a large sample argument. However, it is very clear that the coverage probability is small when <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_68.gif\" alt=\"\" width=\"7\" height=\"12\" /> is close to either 0 or 1 even with <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_69.gif\" alt=\"\" width=\"32\" height=\"12\" />. For some sample sizes it is even more obvious that this function contains discontinuities.</p>\n<h4>A Better Confidence Interval for a Population Proportion</h4>\n<p>This subsection presents coverage probabilities for an improved confidence interval for a population proportion. The improvement makes coverage probabilities generally larger.</p>\n<p>Devore and Berk [<a href=\"Devore-Berk\">3</a>, p. 395] give a better large sample confidence interval for a population proportion. Based on the same assumptions as expression (<a href=\"Eq:1\">1</a>), a sample confidence interval of size <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_70.gif\" alt=\"\" width=\"25\" height=\"12\" /> for a population proportion <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_71.gif\" alt=\"\" width=\"7\" height=\"12\" /> is given by</p>\n<table class=\"DisplayFormulaNumbered\">\n<tbody>\n<tr>\n<td><img src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_DisplayFormulaNumbered_4.gif\" alt=\"\" width=\"264\" height=\"25\" /></td>\n<td class=\"DisplayFormulaNumberedLabel\"><a name=\"Eq:4\"></a>(4)</td>\n</tr>\n</tbody>\n</table>\n<p>This confidence interval is based on solving the following inequality for <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_72.gif\" alt=\"\" width=\"7\" height=\"12\" />:</p>\n<table class=\"DisplayFormulaNumbered\">\n<tbody>\n<tr>\n<td><img src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_DisplayFormulaNumbered_5.gif\" alt=\"\" width=\"176\" height=\"18\" /></td>\n<td class=\"DisplayFormulaNumberedLabel\"><a name=\"Eq:5\"></a>(5)</td>\n</tr>\n</tbody>\n</table>\n<p>This defines the new inequality accordingly.</p>\n<p class=\"input\"><img src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Input_14.gif\" alt=\"\" width=\"275\" height=\"135\" /></p>\n<p>Just as with the previous kind of inequality, define <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_73.gif\" alt=\"\" width=\"65\" height=\"12\" />.</p>\n<p class=\"input\"><img src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Input_15.gif\" alt=\"\" width=\"257\" height=\"103\" /></p>\n<p>Figure <a href=\"Fig:3\">3</a> is the corresponding plot, again with <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_74.gif\" alt=\"\" width=\"32\" height=\"12\" />.</p>\n<p class=\"input\"><img src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Input_16.gif\" alt=\"\" width=\"345\" height=\"73\" /></p>\n<p class=\"output\"><img src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Output_11.gif\" alt=\"\" width=\"360\" height=\"228\" /></p>\n<p class=\"NumberedFigureCaption\"><strong>Figure 3.</strong> Coverage plot for the better confidence interval, <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_75.gif\" alt=\"\" width=\"25\" height=\"12\" />.</p>\n<p>The inequality in (<a href=\"Eq:5\">5</a>) is supposed to have a probability of approximately <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_76.gif\" alt=\"\" width=\"25\" height=\"12\" /> before sampling the population. We can of course compute the true probability with respect to the correct binomial distribution. The Mathematica code follows along with a dynamic graph in Figure <a href=\"Fig:4\">4</a>.</p>\n<p class=\"input\"><img src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Input_17.gif\" alt=\"\" width=\"346\" height=\"163\" /></p>\n<p class=\"output\"><img src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Output_12.gif\" alt=\"\" width=\"403\" height=\"340\" /></p>\n<p class=\"NumberedFigureCaption\"><strong>Figure 4.</strong> Coverage probabilities for the superior asymptotic confidence interval for a population proportion.</p>\n<p>Figure <a href=\"Fig:5\">5</a> contains the code and plot for the dynamic version of the plot. This plot allows for an easy comparison of the coverage probabilities for the two types of confidence intervals.</p>\n<p class=\"input\"><img src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Input_18.gif\" alt=\"\" width=\"580\" height=\"163\" /></p>\n<p class=\"output\"><img src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Output_13.gif\" alt=\"\" width=\"403\" height=\"340\" /></p>\n<p class=\"NumberedFigureCaption\"><strong>Figure 5.</strong> A comparison of coverage probabilities for the two binomial intervals.</p>\n<p>The coverage probabilities for this improved confidence interval for a population proportion are indeed superior to the simpler interval. In particular, the coverage probabilities are quite large when <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_77.gif\" alt=\"\" width=\"7\" height=\"12\" /> is close to 0 or 1. One can see this even with a sample size of <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_78.gif\" alt=\"\" width=\"32\" height=\"12\" />, for which the large sample approximation is not appropriate. The difference in coverage probabilities with the simple interval (displayed in Figure <a href=\"Fig:2\">2</a>) and this improved interval is striking.</p>\n<h3>3. The Mean of the Poisson Distribution</h3>\n<p>We now turn our attention to the Poisson distribution.</p>\n<p>The book by Devore and Berk [<a href=\"#Devore-Berk\">3</a>, p. 400] presents a homework exercise for determining a confidence interval of size <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_79.gif\" alt=\"\" width=\"25\" height=\"12\" /> for the mean <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_80.gif\" alt=\"\" width=\"5\" height=\"12\" /> of a population described by a Poisson distribution. Let <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_81.gif\" alt=\"\" width=\"75\" height=\"12\" />, where the <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_82.gif\" alt=\"\" width=\"12\" height=\"12\" /> are independent and identically distributed with a Poisson distribution with parameter (mean) of <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_83.gif\" alt=\"\" width=\"5\" height=\"12\" />. Ideally, we must solve the inequality</p>\n<table class=\"DisplayFormulaNumbered\">\n<tbody>\n<tr>\n<td><img src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_DisplayFormulaNumbered_6.gif\" alt=\"\" width=\"145\" height=\"18\" /></td>\n<td class=\"DisplayFormulaNumberedLabel\"><a name=\"Eq:6\"></a>(6)</td>\n</tr>\n</tbody>\n</table>\n<p>to obtain the desired confidence interval. However, if we have a large enough sample, we may replace the true standard error in the denominator with its estimate. Again, this produces a less than ideal result.</p>\n<p>The resulting simple confidence interval of approximate size <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_84.gif\" alt=\"\" width=\"25\" height=\"12\" /> for the mean <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_85.gif\" alt=\"\" width=\"5\" height=\"12\" /> is given by</p>\n<table class=\"DisplayFormulaNumbered\">\n<tbody>\n<tr>\n<td><img src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_DisplayFormulaNumbered_7.gif\" alt=\"\" width=\"198\" height=\"24\" /></td>\n<td class=\"DisplayFormulaNumberedLabel\"><a name=\"Eq:7\"></a>(7)</td>\n</tr>\n</tbody>\n</table>\n<p>which has an approximate level of confidence of <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_86.gif\" alt=\"\" width=\"25\" height=\"12\" />. The parameter <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_87.gif\" alt=\"\" width=\"5\" height=\"12\" /> in the denominator was replaced by the sample mean. Figure <a href=\"Fig:6\">6</a> contains the code and graph for the coverage probabilities. We use <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_88.gif\" alt=\"\" width=\"32\" height=\"12\" />. We let <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_89.gif\" alt=\"\" width=\"51\" height=\"15\" /> where <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_90.gif\" alt=\"\" width=\"50\" height=\"33\" /> has a Poisson distribution with a mean of <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_91.gif\" alt=\"\" width=\"19\" height=\"12\" />. In principle, the inequality must be tested for each of the infinitely many possible values of <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_92.gif\" alt=\"\" width=\"8\" height=\"12\" />. Coverage probabilities are evaluated at a discrete set of points in order to save computational time.</p>\n<p class=\"input\"><img src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Input_19.gif\" alt=\"\" width=\"329\" height=\"295\" /></p>\n<p class=\"output\"><img src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Output_14.gif\" alt=\"\" width=\"360\" height=\"237\" /></p>\n<p class=\"NumberedFigureCaption\"><strong>Figure 6.</strong> Coverage probabilities for the confidence interval for the Poisson mean <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_93.gif\" alt=\"\" width=\"25\" height=\"12\" />.</p>\n<p>Unless <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_94.gif\" alt=\"\" width=\"5\" height=\"12\" /> is close to zero, this large sample approximation is quite good for <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_95.gif\" alt=\"\" width=\"32\" height=\"12\" />, which is easily seen in Figure <a href=\"Fig:6\">6</a>. Given the two approximations used, it is not surprising that the coverage probability is small when <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_96.gif\" alt=\"\" width=\"5\" height=\"12\" /> is close to zero.</p>\n<h3>4. The Population Proportion and the Negative Binomial Distribution</h3>\n<p>This section addresses the situation of estimating a population proportion when the negative binomial distribution is appropriate.</p>\n<p>Let <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_97.gif\" alt=\"\" width=\"75\" height=\"12\" />, where the <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_98.gif\" alt=\"\" width=\"12\" height=\"12\" /> are independent and identically distributed with a geometric distribution with parameter <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_99.gif\" alt=\"\" width=\"7\" height=\"12\" />. It is well known that <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_100.gif\" alt=\"\" width=\"59\" height=\"14\" /> has a negative binomial distribution with parameters <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_101.gif\" alt=\"\" width=\"6\" height=\"12\" /> and <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_102.gif\" alt=\"\" width=\"7\" height=\"12\" />, (see [<a href=\"Kinney\">5</a>], p. 127). Consequently, we use the negative binomial distribution for estimating a population proportion. There are many ways to define the negative binomial distribution. We use the version described in Kinney [<a href=\"Kinney\">5</a>, p. 125]. Conduct independent success/failure trials, each with a probability of success <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_103.gif\" alt=\"\" width=\"7\" height=\"12\" />. Let <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_104.gif\" alt=\"\" width=\"8\" height=\"12\" /> be the total number of trials needed to obtain <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_105.gif\" alt=\"\" width=\"6\" height=\"12\" /> successes. The probability mass function for <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_106.gif\" alt=\"\" width=\"8\" height=\"12\" /> is given by</p>\n<table class=\"DisplayFormulaNumbered\">\n<tbody>\n<tr>\n<td><img src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_DisplayFormulaNumbered_8.gif\" alt=\"\" width=\"223\" height=\"29\" /></td>\n<td class=\"DisplayFormulaNumberedLabel\"><a name=\"Eq:8\"></a>(8)</td>\n</tr>\n</tbody>\n</table>\n<p>where <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_107.gif\" alt=\"\" width=\"47\" height=\"12\" />.</p>\n<p>Some authors count the number of trials before the <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_108.gif\" alt=\"\" width=\"14\" height=\"15\" /> success. Other authors count the number of failures before the <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_109.gif\" alt=\"\" width=\"14\" height=\"15\" /> success. There are other possibilities still. Mathematica uses <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_110.gif\" alt=\"\" width=\"8\" height=\"12\" />, the number of failures before the <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_111.gif\" alt=\"\" width=\"14\" height=\"15\" /> success. Consequently, <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_112.gif\" alt=\"\" width=\"48\" height=\"12\" />.</p>\n<p>Casella and Berger [<a href=\"Casella-Berger\">1</a>, p. 496] describe large sample confidence intervals based on maximum likelihood. It is easily shown that the maximum likelihood estimator for <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_113.gif\" alt=\"\" width=\"7\" height=\"12\" /> is <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_114.gif\" alt=\"\" width=\"43\" height=\"14\" />. Moreover, the asymptotic variance of this estimator is the reciprocal of the Fisher information, <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_115.gif\" alt=\"\" width=\"108\" height=\"18\" />. Fisher information is described in Casella and Berger [<a href=\"Casella-Berger\">1</a>, p. 388]. This variance expression is not useful for creating a confidence interval for <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_116.gif\" alt=\"\" width=\"7\" height=\"12\" /> since it depends on <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_117.gif\" alt=\"\" width=\"7\" height=\"12\" />. So, we estimate the large sample variance by replacing <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_118.gif\" alt=\"\" width=\"7\" height=\"12\" /> with <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_119.gif\" alt=\"\" width=\"7\" height=\"14\" />. This leads to the large sample confidence interval:</p>\n<table class=\"DisplayFormulaNumbered\">\n<tbody>\n<tr>\n<td><img src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_DisplayFormulaNumbered_9.gif\" alt=\"\" width=\"318\" height=\"30\" /></td>\n<td class=\"DisplayFormulaNumberedLabel\"><a name=\"Eq:9\"></a>(9)</td>\n</tr>\n</tbody>\n</table>\n<p>In order to conveniently perform the calculations, we note that <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_120.gif\" alt=\"\" width=\"105\" height=\"14\" />. We evaluate the coverage probability for <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_121.gif\" alt=\"\" width=\"71\" height=\"12\" /> in steps of 0.01. We based the calculations on <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_122.gif\" alt=\"\" width=\"32\" height=\"12\" />. The calculation can take some time depending on the computer. When <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_123.gif\" alt=\"\" width=\"7\" height=\"12\" /> is small, values of <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_124.gif\" alt=\"\" width=\"8\" height=\"12\" /> or <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_125.gif\" alt=\"\" width=\"8\" height=\"12\" /> are extremely unlikely. This makes the internal algorithm take quite a while. We can help speed up the calculations by using <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_126.gif\" alt=\"\" width=\"86\" height=\"12\" /> rather than the symbolic <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_127.gif\" alt=\"\" width=\"79\" height=\"12\" />. The speedup occurs by reducing the required number of digits in calculations. Even so, this calculation takes some time (about four minutes on the author<span class=\"special-character CloseCurlyQuote\">’</span>s computer). A graph of the coverage probabilities is contained in Figure <a href=\"Fig:7\">7</a>.</p>\n<p class=\"input\"><img src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Input_20.gif\" alt=\"\" width=\"374\" height=\"351\" /></p>\n<p class=\"output\"><img src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Output_15.gif\" alt=\"\" width=\"360\" height=\"236\" /></p>\n<p class=\"NumberedFigureCaption\"><strong>Figure 7.</strong> Coverage probabilities for the confidence interval for a population proportion on the negative binomial distribution, <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_128.gif\" alt=\"\" width=\"25\" height=\"12\" />.</p>\n<p>We see from Figure <a href=\"Fig:7\">7</a> that the approximation is quite good for values of <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_129.gif\" alt=\"\" width=\"7\" height=\"12\" /> close to 0.2. We infer that the approximation is also quite good if <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_130.gif\" alt=\"\" width=\"7\" height=\"12\" /> is close to 0. The approximation generally gets worse as <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_131.gif\" alt=\"\" width=\"7\" height=\"12\" /> increases (though not monotonically). A large sample approximation was used. Also, an approximate standard error was used. One sees that the coverage probability is essentially zero when <img style=\"vertical-align: middle;\" src=\"https://content.wolfram.com/uploads/sites/19/2021/02/Cook_Math_132.gif\" alt=\"\" width=\"7\" height=\"12\" /> is close to 1.</p>\n<h3>5. Summary</h3>\n<p>Large sample confidence intervals are often quite easy to derive. This is particularly true when using an estimate for the standard error of an estimator. However, the actual probability of surrounding the parameter value (coverage) can be quite different from the nominal value. It is helpful to graph the coverage probabilities to see this. Mathematica is particularly useful in performing these calculations and providing a language for describing the algorithms.</p>\n<h3>Acknowledgments</h3>\n<p>The author wishes to thank the anonymous reviewer and the editor for their help in improving this article.</p>\n<h3>References</h3>\n<table class=\"ReferenceTable\">\n<tbody>\n<tr>\n<td class=\"Reference\"><a name=\"Casella-Berger\"></a>[1]</td>\n<td>G. Casella and R. Berger, <em>Statistical Inference, </em>2nd ed., United States: Brooks/Cole Cengage Learning, 2002.</td>\n</tr>\n<tr>\n<td class=\"Reference\"><a name=\"Heiner-Wagon\"></a>[2]</td>\n<td>K. Heiner and S. Wagon. <span class=\"special-character OpenCurlyDoubleQuote\">“</span>Wald and Bayesian Confidence Intervals<span class=\"special-character CloseCurlyDoubleQuote\">”</span> from the Wolfram Demonstrations Project<span class=\"special-character LongDash\">—</span>A Wolfram Web Resource. <a href=\"https://www.demonstrations.wolfram.com/WaldAndBayesianConfidenceIntervals\">www.demonstrations.wolfram.com/WaldAndBayesianConfidenceIntervals</a>.</td>\n</tr>\n<tr>\n<td class=\"Reference\"><a name=\"Devore-Berk\"></a>[3]</td>\n<td>J. Devore and K. Berk, <em>Modern Mathematical Statistics with Applications</em>, 2nd ed., New York: Springer, 2012.</td>\n</tr>\n<tr>\n<td class=\"Reference\"><a name=\"Brown-Cai-DasGupta\"></a>[4]</td>\n<td>L. D. Brown, T. T. Cai and A. DasGupta, <span class=\"special-character OpenCurlyDoubleQuote\">“</span>Confidence Intervals for a Binomial Proportion and Asymptotic Expansions,<span class=\"special-character CloseCurlyDoubleQuote\">”</span> The <em>Annals of Statistics</em>, <strong>30</strong>(1), 2002 pp. 160<span class=\"special-character Dash\">–</span>201. <a href=\"https://www.jstor.org/stable/2700007\" target=\"_blank\">www.jstor.org/stable/2700007</a>.</td>\n</tr>\n<tr>\n<td class=\"Reference\"><a name=\"Kinney\"></a>[5]</td>\n<td>J. Kinney, <em>Probability: An Introduction with Statistical Applications</em>, New York: John Wiley and Sons, 1997.</td>\n</tr>\n<tr>\n<td id=\"1099737697\" class=\"DOIReference\" colspan=\"2\"><a name=\"1099737697\"></a>P. Cook, <span class=\"special-character OpenCurlyDoubleQuote\">“</span>Coverage versus Confidence,<span class=\"special-character CloseCurlyDoubleQuote\">”</span> <em>The Mathematica Journal</em>, 2021. <a href=\"https://doi.org/10.3888/tmj.23-1\">https://doi.org/10.3888/tmj.23-1</a>.</td>\n</tr>\n</tbody>\n</table>\n<h3 class=\"SectionAboutAuthor\">About the Author</h3>\n<p class=\"TextAboutAuthor\">Peyton Cook earned a B.A. in Psychology, B.S. in Mathematics, and an M.S. and Ph.D. in Statistics. He is an Associate Professor at The University of Tulsa.</p>\n<p class=\"TextAboutAuthor\"><strong>Peyton Cook</strong><br />\n<em>Department of Mathematics<br />\nThe University of Tulsa<br />\n800 Tucker Drive<br />\nTulsa, Oklahoma 74104<br />\npcook@utulsa.edu</em></p>\n</div>\n</div>\n",
  "wfw:commentRss": "https://www.mathematica-journal.com/2021/03/03/coverage-versus-confidence/feed/",
  "slash:comments": 0
}