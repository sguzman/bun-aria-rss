{
  "title": "Hierarchies over Vector Space: Orienting Word and Graph Embeddings. (arXiv:2211.01430v1 [cs.CL])",
  "link": "http://arxiv.org/abs/2211.01430",
  "description": "<p>Word and graph embeddings are widely used in deep learning applications. We\npresent a data structure that captures inherent hierarchical properties from an\nunordered flat embedding space, particularly a sense of direction between pairs\nof entities. Inspired by the notion of \\textit{distributional generality}, our\nalgorithm constructs an arborescence (a directed rooted tree) by inserting\nnodes in descending order of entity power (e.g., word frequency), pointing each\nentity to the closest more powerful node as its parent.\n</p>\n<p>We evaluate the performance of the resulting tree structures on three tasks:\nhypernym relation discovery, least-common-ancestor (LCA) discovery among words,\nand Wikipedia page link recovery. We achieve average 8.98\\% and 2.70\\% for\nhypernym and LCA discovery across five languages and 62.76\\% accuracy on\ndirected Wiki-page link recovery, with both substantially above baselines.\nFinally, we investigate the effect of insertion order, the power/similarity\ntrade-off and various power sources to optimize parent selection.\n</p>",
  "dc:creator": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1\">Xingzhi Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Skiena_S/0/1/0/all/0/1\">Steven Skiena</a>"
}