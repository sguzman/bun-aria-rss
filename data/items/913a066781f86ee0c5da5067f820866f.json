{
  "title": "Efficient Spatially Sparse Inference for Conditional GANs and Diffusion Models. (arXiv:2211.02048v1 [cs.CV])",
  "link": "http://arxiv.org/abs/2211.02048",
  "description": "<p>During image editing, existing deep generative models tend to re-synthesize\nthe entire output from scratch, including the unedited regions. This leads to a\nsignificant waste of computation, especially for minor editing operations. In\nthis work, we present Spatially Sparse Inference (SSI), a general-purpose\ntechnique that selectively performs computation for edited regions and\naccelerates various generative models, including both conditional GANs and\ndiffusion models. Our key observation is that users tend to make gradual\nchanges to the input image. This motivates us to cache and reuse the feature\nmaps of the original image. Given an edited image, we sparsely apply the\nconvolutional filters to the edited regions while reusing the cached features\nfor the unedited regions. Based on our algorithm, we further propose Sparse\nIncremental Generative Engine (SIGE) to convert the computation reduction to\nlatency reduction on off-the-shelf hardware. With 1.2%-area edited regions, our\nmethod reduces the computation of DDIM by 7.5$\\times$ and GauGAN by 18$\\times$\nwhile preserving the visual fidelity. With SIGE, we accelerate the speed of\nDDIM by 3.0x on RTX 3090 and 6.6$\\times$ on Apple M1 Pro CPU, and GauGAN by\n4.2$\\times$ on RTX 3090 and 14$\\times$ on Apple M1 Pro CPU.\n</p>",
  "dc:creator": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Muyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Ji Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_C/0/1/0/all/0/1\">Chenlin Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ermon_S/0/1/0/all/0/1\">Stefano Ermon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Song Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jun-Yan Zhu</a>"
}