{
  "title": "Streaming Mean and Variance Computation",
  "link": "",
  "published": "2015-01-25T21:30:00+00:00",
  "updated": "2015-01-25T21:30:00+00:00",
  "author": {
    "name": "Sebastian Nowozin"
  },
  "id": "tag:www.nowozin.net,2015-01-25:/sebastian/blog/streaming-mean-and-variance-computation.html",
  "summary": "<p>Given a sequence of observed data we would often like to estimate simple\nquantities like the mean and variance.</p>\n<p>Sometimes the data is available in a <em>streaming</em> setting, that is, we are\ngiven one sample at a time.  For example â€¦</p>",
  "content": "<p>Given a sequence of observed data we would often like to estimate simple\nquantities like the mean and variance.</p>\n<p>Sometimes the data is available in a <em>streaming</em> setting, that is, we are\ngiven one sample at a time.  For example, this is the case when</p>\n<ul>\n<li>the number of samples is apriori unknown,</li>\n<li>we have to perform some stopping test after each sample,</li>\n<li>the number of samples is very large and we cannot store all samples.</li>\n</ul>\n<p>More formally, given weighted observations <span class=\"math\">\\(X_1\\)</span>, <span class=\"math\">\\(X_2\\)</span>, <span class=\"math\">\\(\\dots\\)</span>, with <span class=\"math\">\\(X_i\n\\in \\mathbb{R}\\)</span>, and <span class=\"math\">\\(w_1\\)</span>, <span class=\"math\">\\(w_2\\)</span>, <span class=\"math\">\\(\\dots\\)</span>, with <span class=\"math\">\\(w_i \\geq 0\\)</span> we would like to\ncalculate simple statistics like the weighted mean or weighted variance of the\nsample without having to store all samples, and by processing them one-by-one.</p>\n<p>In this situation we can compute the mean and variance of a sample (and, more\ngenerally, any higher-order moments) using a <a href=\"http://en.wikipedia.org/wiki/Streaming_algorithm\">streaming\nalgorithm</a>.\nMany possibilities exist but because of the incremental computation particular\nattention needs to be paid to numerical stability.\nIf we were to ignore numerical accuracy we could use a simple derivation to\nshow that the following updates for <span class=\"math\">\\(i=1,2,\\dots\\)</span> are correct, when\ninitializing <span class=\"math\">\\(S^{(0)} = T^{(0)} = U^{(0)} = 0\\)</span>:</p>\n<div class=\"math\">$$S^{(i+1)} = S^{(i)} + w_i$$</div>\n<div class=\"math\">$$T^{(i+1)} = T^{(i)} + w_i X_i$$</div>\n<div class=\"math\">$$U^{(i+1)} = U^{(i)} + w_i X_i^2$$</div>\n<p>Then <span class=\"math\">\\(\\hat{\\mu} = T^{(n)} / S^{(n)}\\)</span> is the weighted sample mean, and\n<span class=\"math\">\\(\\hat{\\mathbb{V}} = \\frac{n}{(n-1) S^{(n)}} (U^{(n)} - S^{(n)} \\hat{\\mu}^2)\\)</span>\nis an unbiased estimate of the weighted variance.</p>\n<p>The problem with this naive derivation arises when <span class=\"math\">\\(n\\)</span> is very large.  Then\nthe in all three updates the summation may sum quantities of very different\nmagnitude, leading to <a href=\"http://www.validlab.com/goldberg/paper.pdf\">large round-off\nerrors</a>.\nBy the way, this can even arise when one is computing the simple sum of many\nnumbers, and a classic solution in that case is <a href=\"http://en.wikipedia.org/wiki/Kahan_summation_algorithm\">Kahan\nsummation</a>.</p>\n<p>A clever solution to this problem for streaming mean and variance computation\nwas proposed by West in 1979.\nIn his algorithm the summed quantities are controlled to be on average of\ncomparable size.  (It is not the only alternative, for a detailed numerical\nstudy of possible options, see the paper linked below.)</p>\n<p>The West algorithm supports mean and variance computation for\npositively weighted samples <span class=\"math\">\\((w_i, X_i)\\)</span> with <span class=\"math\">\\(w_i \\geq 0\\)</span>, <span class=\"math\">\\(X_i \\in\n\\mathbb{R}\\)</span> and the original paper is</p>\n<ul>\n<li>D.H.D. West, <a href=\"http://people.xiph.org/~tterribe/tmp/homs/West79-_Updating_Mean_and_Variance_Estimates-_An_Improved_Method.pdf\">\"Updating Mean and Variance Estimates: An Improved\nMethod\"</a>\n(<a href=\"http://dl.acm.org/citation.cfm?id=359153\">publisher link</a>),\nComm. of the ACM, Vol. 22, Issue 9, 532--535, 1979.</li>\n</ul>\n<p>It outputs</p>\n<ol>\n<li>The weighted unbiased mean estimate, <span class=\"math\">\\(\\hat{\\mu} = (\\sum_i w_i X_i) / (\\sum_i w_i)\\)</span>,</li>\n<li>The weighted unbiased variance estimate, <span class=\"math\">\\(\\hat{\\mathbb{V}} = \\left(\\sum_i w_i (X_i - \\mu)^2\\right) / (\\frac{n-1}{n} \\sum_i w_i)\\)</span>.</li>\n</ol>\n<p>Here is an implementation for the <a href=\"http://julialang.org/\">Julia programming\nlanguage</a>.</p>\n<div class=\"highlight\"><pre><span></span><code><span class=\"k\">type</span> <span class=\"n\">MeanVarianceAccumulator</span>\n    <span class=\"n\">sumw</span><span class=\"o\">::</span><span class=\"kt\">Float64</span>\n    <span class=\"n\">wmean</span><span class=\"o\">::</span><span class=\"kt\">Float64</span>\n    <span class=\"n\">t</span><span class=\"o\">::</span><span class=\"kt\">Float64</span>\n    <span class=\"n\">n</span><span class=\"o\">::</span><span class=\"kt\">Int</span>\n\n    <span class=\"k\">function</span> <span class=\"n\">MeanVarianceAccumulator</span><span class=\"p\">()</span>\n        <span class=\"n\">new</span><span class=\"p\">(</span><span class=\"mf\">0.0</span><span class=\"p\">,</span> <span class=\"mf\">0.0</span><span class=\"p\">,</span> <span class=\"mf\">0.0</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">)</span>\n    <span class=\"k\">end</span>\n<span class=\"k\">end</span>\n<span class=\"k\">function</span> <span class=\"n\">observe!</span><span class=\"p\">(</span><span class=\"n\">mvar</span><span class=\"o\">::</span><span class=\"n\">MeanVarianceAccumulator</span><span class=\"p\">,</span> <span class=\"n\">value</span><span class=\"p\">,</span> <span class=\"n\">weight</span><span class=\"p\">)</span>\n    <span class=\"nd\">@assert</span> <span class=\"n\">weight</span> <span class=\"o\">&gt;=</span> <span class=\"mf\">0.0</span>\n    <span class=\"n\">q</span> <span class=\"o\">=</span> <span class=\"n\">value</span> <span class=\"o\">-</span> <span class=\"n\">mvar</span><span class=\"o\">.</span><span class=\"n\">wmean</span>\n    <span class=\"n\">temp_sumw</span> <span class=\"o\">=</span> <span class=\"n\">mvar</span><span class=\"o\">.</span><span class=\"n\">sumw</span> <span class=\"o\">+</span> <span class=\"n\">weight</span>\n    <span class=\"n\">r</span> <span class=\"o\">=</span> <span class=\"n\">q</span><span class=\"o\">*</span><span class=\"n\">weight</span> <span class=\"o\">/</span> <span class=\"n\">temp_sumw</span>\n\n    <span class=\"n\">mvar</span><span class=\"o\">.</span><span class=\"n\">wmean</span> <span class=\"o\">+=</span> <span class=\"n\">r</span>\n    <span class=\"n\">mvar</span><span class=\"o\">.</span><span class=\"n\">t</span> <span class=\"o\">+=</span> <span class=\"n\">q</span><span class=\"o\">*</span><span class=\"n\">r</span><span class=\"o\">*</span><span class=\"n\">mvar</span><span class=\"o\">.</span><span class=\"n\">sumw</span>\n    <span class=\"n\">mvar</span><span class=\"o\">.</span><span class=\"n\">sumw</span> <span class=\"o\">=</span> <span class=\"n\">temp_sumw</span>\n    <span class=\"n\">mvar</span><span class=\"o\">.</span><span class=\"n\">n</span> <span class=\"o\">+=</span> <span class=\"mi\">1</span>\n\n    <span class=\"nb\">nothing</span>\n<span class=\"k\">end</span>\n<span class=\"n\">count</span><span class=\"p\">(</span><span class=\"n\">mvar</span><span class=\"o\">::</span><span class=\"n\">MeanVarianceAccumulator</span><span class=\"p\">)</span> <span class=\"o\">=</span> <span class=\"n\">mvar</span><span class=\"o\">.</span><span class=\"n\">n</span>\n<span class=\"n\">mean</span><span class=\"p\">(</span><span class=\"n\">mvar</span><span class=\"o\">::</span><span class=\"n\">MeanVarianceAccumulator</span><span class=\"p\">)</span> <span class=\"o\">=</span> <span class=\"n\">mvar</span><span class=\"o\">.</span><span class=\"n\">wmean</span>\n<span class=\"n\">var</span><span class=\"p\">(</span><span class=\"n\">mvar</span><span class=\"o\">::</span><span class=\"n\">MeanVarianceAccumulator</span><span class=\"p\">)</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">mvar</span><span class=\"o\">.</span><span class=\"n\">t</span><span class=\"o\">*</span><span class=\"n\">mvar</span><span class=\"o\">.</span><span class=\"n\">n</span><span class=\"p\">)</span><span class=\"o\">/</span><span class=\"p\">(</span><span class=\"n\">mvar</span><span class=\"o\">.</span><span class=\"n\">sumw</span><span class=\"o\">*</span><span class=\"p\">(</span><span class=\"n\">mvar</span><span class=\"o\">.</span><span class=\"n\">n</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">))</span>\n<span class=\"n\">std</span><span class=\"p\">(</span><span class=\"n\">mvar</span><span class=\"o\">::</span><span class=\"n\">MeanVarianceAccumulator</span><span class=\"p\">)</span> <span class=\"o\">=</span> <span class=\"n\">sqrt</span><span class=\"p\">(</span><span class=\"n\">var</span><span class=\"p\">(</span><span class=\"n\">mvar</span><span class=\"p\">))</span>\n</code></pre></div>\n\n<p>You would call it as follows (tested with Julia version 0.3.5):</p>\n<div class=\"highlight\"><pre><span></span><code><span class=\"n\">X</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"mf\">5.0</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mf\">1.5</span><span class=\"p\">,</span> <span class=\"mf\">3.33</span><span class=\"p\">]</span>\n<span class=\"n\">w</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"mf\">0.5</span><span class=\"p\">,</span> <span class=\"mf\">1.0</span><span class=\"p\">,</span> <span class=\"mf\">0.1</span><span class=\"p\">]</span>\n\n<span class=\"n\">n</span> <span class=\"o\">=</span> <span class=\"n\">length</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">)</span>\n<span class=\"n\">mu_exact</span> <span class=\"o\">=</span> <span class=\"n\">sum</span><span class=\"p\">(</span><span class=\"n\">w</span><span class=\"o\">.*</span><span class=\"n\">X</span><span class=\"p\">)</span> <span class=\"o\">/</span> <span class=\"n\">sum</span><span class=\"p\">(</span><span class=\"n\">w</span><span class=\"p\">)</span>\n<span class=\"n\">V_exact</span> <span class=\"o\">=</span> <span class=\"n\">sum</span><span class=\"p\">(</span><span class=\"n\">w</span> <span class=\"o\">.*</span> <span class=\"p\">((</span><span class=\"n\">X</span> <span class=\"o\">.-</span> <span class=\"n\">mu_exact</span><span class=\"p\">)</span><span class=\"o\">.^</span><span class=\"mi\">2</span><span class=\"p\">))</span> <span class=\"o\">/</span> <span class=\"p\">(((</span><span class=\"n\">n</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">)</span><span class=\"o\">/</span><span class=\"n\">n</span><span class=\"p\">)</span> <span class=\"o\">*</span> <span class=\"n\">sum</span><span class=\"p\">(</span><span class=\"n\">w</span><span class=\"p\">))</span>\n\n<span class=\"n\">mvar</span> <span class=\"o\">=</span> <span class=\"n\">MeanVarianceAccumulator</span><span class=\"p\">()</span>\n<span class=\"k\">for</span> <span class=\"n\">i</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"o\">:</span><span class=\"n\">n</span>\n    <span class=\"n\">observe!</span><span class=\"p\">(</span><span class=\"n\">mvar</span><span class=\"p\">,</span> <span class=\"n\">X</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">],</span> <span class=\"n\">w</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">])</span>\n<span class=\"k\">end</span>\n<span class=\"n\">mean</span><span class=\"p\">(</span><span class=\"n\">mvar</span><span class=\"p\">),</span> <span class=\"n\">mu_exact</span><span class=\"p\">,</span> <span class=\"n\">var</span><span class=\"p\">(</span><span class=\"n\">mvar</span><span class=\"p\">),</span> <span class=\"n\">V_exact</span>\n</code></pre></div>\n\n<p>This gives the correct output (running mean, mean, running variance, variance):</p>\n<div class=\"highlight\"><pre><span></span><code><span class=\"p\">(</span><span class=\"mf\">0.8331250000000003</span><span class=\"p\">,</span><span class=\"mf\">0.8331249999999999</span><span class=\"p\">,</span><span class=\"mf\">13.826563476562498</span><span class=\"p\">,</span><span class=\"mf\">13.8265634765625</span><span class=\"p\">)</span>\n</code></pre></div>\n\n<p>Alternative algorithms and variants for higher-order moments can be found on\nthe excellent <a href=\"http://en.wikipedia.org/wiki/Algorithms_for_calculating_variance\">Wikipedia page on the\ntopic</a>.</p>\n<p><strong>Addendum</strong>: (October 2015) A recent paper by <a href=\"http://arxiv.org/abs/1510.04923\">(Meng,\n2015)</a> contains a variant of the above\nalgorithm for the unweighted case to compute the first four central moments\nin a numerically stable manner.  Meng provides a simple implementation\nrequiring only 24 floating point operations per observation.</p>\n<p><em>Acknowledgements</em>.  I thank Amit Adam for reading a draft and providing\ncomments that improved clarity.</p>\n<script type=\"text/javascript\">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {\n    var align = \"center\",\n        indent = \"0em\",\n        linebreak = \"false\";\n\n    if (false) {\n        align = (screen.width < 768) ? \"left\" : align;\n        indent = (screen.width < 768) ? \"0em\" : indent;\n        linebreak = (screen.width < 768) ? 'true' : linebreak;\n    }\n\n    var mathjaxscript = document.createElement('script');\n    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';\n    mathjaxscript.type = 'text/javascript';\n    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';\n\n    var configscript = document.createElement('script');\n    configscript.type = 'text/x-mathjax-config';\n    configscript[(window.opera ? \"innerHTML\" : \"text\")] =\n        \"MathJax.Hub.Config({\" +\n        \"    config: ['MMLorHTML.js'],\" +\n        \"    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } },\" +\n        \"    jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" +\n        \"    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" +\n        \"    displayAlign: '\"+ align +\"',\" +\n        \"    displayIndent: '\"+ indent +\"',\" +\n        \"    showMathMenu: true,\" +\n        \"    messageStyle: 'normal',\" +\n        \"    tex2jax: { \" +\n        \"        inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" +\n        \"        displayMath: [ ['$$','$$'] ],\" +\n        \"        processEscapes: true,\" +\n        \"        preview: 'TeX',\" +\n        \"    }, \" +\n        \"    'HTML-CSS': { \" +\n        \"        availableFonts: ['STIX', 'TeX'],\" +\n        \"        preferredFont: 'STIX',\" +\n        \"        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" +\n        \"        linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" +\n        \"    }, \" +\n        \"}); \" +\n        \"if ('default' !== 'default') {\" +\n            \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" +\n                \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" +\n                \"VARIANT['normal'].fonts.unshift('MathJax_default');\" +\n                \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" +\n                \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" +\n                \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" +\n            \"});\" +\n            \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" +\n                \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" +\n                \"VARIANT['normal'].fonts.unshift('MathJax_default');\" +\n                \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" +\n                \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" +\n                \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" +\n            \"});\" +\n        \"}\";\n\n    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);\n    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);\n}\n</script>",
  "category": ""
}