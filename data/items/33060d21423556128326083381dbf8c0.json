{
  "title": "Java Handwritten Digit Recognition with Convolutional Neural Networks",
  "link": "http://ramok.tech/2017/12/13/java-digit-recognizer-with-convolutional-neural-networks/",
  "dc:creator": "Klevis Ramo",
  "pubDate": "Wed, 13 Dec 2017 23:58:25 +0000",
  "category": [
    "Convolutional Neural Network",
    "Machine Learning",
    "Neural Networks",
    "convolution neural network",
    "deep learning",
    "deeplearning4j",
    "digit recognizer",
    "hand writing digit recognizer",
    "Handwritten Digit Recognition",
    "Handwritten Digit Recognition application",
    "Handwritten Digit Recognizer application",
    "java deep learning",
    "java digit recognizer application",
    "java hand writing digit recognition",
    "java hand writing digit recognizer",
    "java machine learning",
    "machine learning",
    "neural networks"
  ],
  "guid": "http://ramok.tech/?p=1365",
  "description": "Are you Java Developer and eager to learn more about Deep Learning and his applications, but you are not feeling like learning another language at the moment ? Are you facing lack of the support or confusion with Machine Learning and Java? Well you are not alone , as a Java Developer with more than &#8230; <a href=\"http://ramok.tech/2017/12/13/java-digit-recognizer-with-convolutional-neural-networks/\" class=\"more-link\">Continue reading<span class=\"screen-reader-text\"> \"Java Handwritten Digit Recognition with Convolutional Neural Networks\"</span></a>",
  "content:encoded": "<p style=\"text-align: center;\"><span style=\"font-weight: 400; font-family: helvetica, arial, sans-serif; font-size: 10pt;\">Are you<strong> Java Developer</strong> and eager to learn more about <a href=\"https://www.packtpub.com/big-data-and-business-intelligence/java-machine-learning-computer-vision-video\">Deep Learning and his applications</a>, but you are not feeling like learning another language at the moment ? Are you facing lack of the support or confusion with Machine Learning and Java?</span></p>\n<p style=\"text-align: center;\"><span style=\"font-weight: 400; font-family: helvetica, arial, sans-serif; font-size: 10pt;\">Well you are not alone , as a Java Developer with more than 10 years of experience and several java certification I understand the obstacles and how you feel.</span></p>\n<p style=\"text-align: center;\"><span style=\"font-family: helvetica, arial, sans-serif; font-size: 10pt;\"><span style=\"font-weight: 400;\">From my experience I know what obstacles a Java software engineering faces with the Deep Learning so I can</span><a href=\"https://www.packtpub.com/big-data-and-business-intelligence/java-machine-learning-computer-vision-video\"><span style=\"font-weight: 400;\"> be of a great</span><span style=\"font-weight: 400;\"> help </span></a><span style=\"font-weight: 400;\">to you in making the </span><span style=\"font-weight: 400;\">journey with <a href=\"https://www.packtpub.com/big-data-and-business-intelligence/java-machine-learning-computer-vision-video\">deep learning an exciting experience</a>.</span></span></p>\n<p>In this post we are going to develop a Handwritten Digit Recognition <a href=\"https://drive.google.com/open?id=10d9uOMhVfP_coblW_hCMGjUkcz9odMgc\">application</a> using Convolutional Neural Networks and java. On <a href=\"http://ramok.tech/2017/11/29/digit-recognizer-with-neural-networks/\">previous post</a> a java application was developed using simple Neural Networks by achieving a  accuracy of 97% on test data. In this post we will show that Convolutional Networks are more powerful for image recognizing problems therefore producing higher accuracy.Feel free to check out the<a href=\"https://github.com/klevis/DigitRecognizer\"> source code</a> and experiment on your own(fairly short instructions at the end).</p>\n<h2>Neural Network Overview(Optional)</h2>\n<p>If you are not familiar with Neural Networks please feel free to have a quick look at the <a href=\"http://ramok.tech/2017/11/29/digit-recognizer-with-neural-networks/\">NN previous post overview</a> otherwise feel free to skip it.</p>\n<p>So fare we have seen how <a href=\"http://ramok.tech/2017/11/29/digit-recognizer-with-neural-networks/\">Neural Networks</a> (NN) can help in solving more complex problems than simpler algorithms like <a href=\"http://ramok.tech/2017/09/26/email-spam-classifier-java-application-with-spark/\">Logistic Regression</a> or even <a href=\"http://ramok.tech/2017/10/09/spam-emails-with-support-vector-machines/\">SVM</a>. The reason behind their success is the fact that they try to solve the problems step by step(hidden layers) rather in on big step. So to summarize in previous post we end up with below graph for NN:</p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-1367\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/neuronsfinal.jpg?resize=840%2C461\" alt=\"\" width=\"840\" height=\"461\" srcset=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/neuronsfinal.jpg?w=987 987w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/neuronsfinal.jpg?resize=300%2C165 300w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/neuronsfinal.jpg?resize=768%2C422 768w\" sizes=\"(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px\" data-recalc-dims=\"1\" /></p>\n<ul>\n<li>Where the inputs X<span style=\"font-size: 12px;\">1&#8230;<span style=\"font-size: 12pt;\">X<sup>n</sup></span></span> are features of one labeled training example we already have from the training set.The model represents only one sample of training data , to fully train the model we need to execute for every data sample we have in the training set.</li>\n<li>Neurons Layers or Hidden Layers are several layers of fully connected neurons each transforming the input with a <a href=\"http://ramok.tech/2017/09/26/email-spam-classifier-java-application-with-spark/#Model_Representation\">Sigmoid Function</a> and than by multiplying by some weights(<strong>Θ</strong>) as an output for other neurons or maybe the final output.Below a picture how a single neuron looks like:<img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-1370\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/multipleOutput.jpg?resize=840%2C380\" alt=\"\" width=\"840\" height=\"380\" srcset=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/multipleOutput.jpg?w=1087 1087w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/multipleOutput.jpg?resize=300%2C136 300w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/multipleOutput.jpg?resize=768%2C348 768w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/multipleOutput.jpg?resize=1024%2C463 1024w\" sizes=\"(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px\" data-recalc-dims=\"1\" />Now imagine this neuron having as input other neurons similar to itself and outputting value to other similar neurons.</li>\n<li>The final layer output  is basically the number of classes we want to predict. It can be 0,1,2,3,4,5,6,7,8,9 so 10 digits or more simple like is this image a Cat or Not(1,0).</li>\n</ul>\n<h2>Edge Detection</h2>\n<p>Neural Networks(NN) are with no doubt great but image detection problems are hard so we would need to enhance our NN model with more specialized image feature detectors models. One of this methods is <a href=\"https://en.wikipedia.org/wiki/Edge_detection\">Edge Detection</a> , citing from Wikipedia:</p>\n<blockquote><p><b>Edge detection</b> includes a variety of mathematical methods that aim at identifying points in a <a title=\"Digital image\" href=\"https://en.wikipedia.org/wiki/Digital_image\">digital image</a> at which the <a title=\"Luminous intensity\" href=\"https://en.wikipedia.org/wiki/Luminous_intensity\">image brightness</a> changes sharply or, more formally, has discontinuities. The points at which image brightness changes sharply are typically organized into a set of curved line segments termed <i>edges</i>.</p></blockquote>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-1371\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/Blog-Header-Machine-Learning.png?resize=840%2C280\" alt=\"\" width=\"840\" height=\"280\" srcset=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/Blog-Header-Machine-Learning.png?w=1415 1415w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/Blog-Header-Machine-Learning.png?resize=300%2C100 300w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/Blog-Header-Machine-Learning.png?resize=768%2C256 768w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/Blog-Header-Machine-Learning.png?resize=1024%2C341 1024w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/Blog-Header-Machine-Learning.png?resize=1200%2C399 1200w\" sizes=\"(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px\" data-recalc-dims=\"1\" /></p>\n<p>So intuitively we can notice that an edge is just a group of pixels where a continues color suddenly changes for the first time. In above picture we can see that the left part of the hairs are detected thanks to the fact that the green color changes to yellow color. Same we can say the flower edges are detected because of hand color changes to pink&#8230;</p>\n<p>Wouldn&#8217;t it be great if our NN can now detect edges?</p>\n<p>Or even better to learn to detect type of edges by itself?</p>\n<p>Or even more better to learn type of edges that will help to improve the model by predicting with higher accuracy?</p>\n<h3>Data Representation</h3>\n<p>Images are usually represented as a matrix of pixels where each entry have three values from R(red),G(green), B(blue)(RGB System). So more specifically is a 3 dimensional array <em>image[i][j][k]</em> where i , j represents a pixel position(i<span style=\"font-size: 12px;\">x</span>j size can be 1280&#215;800 depending on image resolution) and <em>image[i][j][0] is Red value, image[i][j][1] Green value, image[i][j][2]</em> Blue value.</p>\n<h3><span style=\"font-size: 19px; font-weight: 900; letter-spacing: 0.13333em; text-transform: uppercase;\">Vertical Edge Detector</span></h3>\n<p>Lets see how vertical edge can be detected step by step and than we would see why this works and give a high level intuition behind it.</p>\n<p>Lets suppose we have a simple image like half white and half black (ignoring the contour)</p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-1396\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/simpleImage2-1.png?resize=466%2C291\" alt=\"\" width=\"466\" height=\"291\" srcset=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/simpleImage2-1.png?w=466 466w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/simpleImage2-1.png?resize=300%2C187 300w\" sizes=\"(max-width: 466px) 85vw, 466px\" data-recalc-dims=\"1\" /></p>\n<p>Lets suppose for the sake of a better visualization that the image resolution is really small like 8&#215;6 so 48 pixels. Additionally we will suppose that the image is represented in the Gray Scale. In contrast to RGB where we have a three dimension matrix like <em>image[i][j][k] (where i,j are pixel position and k(0,1,2) indexes for Red,Green,Blue color values)</em> in the Gray Scale we have only a two dimensional matrix like <em>image[i][j] where i,j is still the pixel position but we have a single value range from 0-255 where 0 is black and 255 is white</em>.<em>  </em></p>\n<p>Our simple image will look like below to a computer:</p>\n<table style=\"border-collapse: collapse; width: 288pt;\" border=\"0\" width=\"384\" cellspacing=\"0\" cellpadding=\"0\">\n<colgroup>\n<col style=\"width: 48pt;\" span=\"6\" width=\"64\" /> </colgroup>\n<tbody>\n<tr style=\"height: 15.0pt;\">\n<td style=\"height: 15.0pt; width: 48pt;\" align=\"right\" width=\"64\" height=\"20\">255</td>\n<td style=\"width: 48pt;\" align=\"right\" width=\"64\">255</td>\n<td style=\"width: 48pt;\" align=\"right\" width=\"64\">255</td>\n<td style=\"width: 48pt;\" align=\"right\" width=\"64\">10</td>\n<td style=\"width: 48pt;\" align=\"right\" width=\"64\">10</td>\n<td style=\"width: 48pt;\" align=\"right\" width=\"64\">10</td>\n</tr>\n<tr style=\"height: 15.0pt;\">\n<td style=\"height: 15.0pt;\" align=\"right\" height=\"20\">255</td>\n<td align=\"right\">255</td>\n<td align=\"right\">255</td>\n<td align=\"right\">10</td>\n<td align=\"right\">10</td>\n<td align=\"right\">10</td>\n</tr>\n<tr style=\"height: 15.0pt;\">\n<td style=\"height: 15.0pt;\" align=\"right\" height=\"20\">255</td>\n<td align=\"right\">255</td>\n<td align=\"right\">255</td>\n<td align=\"right\">10</td>\n<td align=\"right\">10</td>\n<td align=\"right\">10</td>\n</tr>\n<tr style=\"height: 15.0pt;\">\n<td style=\"height: 15.0pt;\" align=\"right\" height=\"20\">255</td>\n<td align=\"right\">255</td>\n<td align=\"right\">255</td>\n<td align=\"right\">10</td>\n<td align=\"right\">10</td>\n<td align=\"right\">10</td>\n</tr>\n<tr style=\"height: 15.0pt;\">\n<td style=\"height: 15.0pt;\" align=\"right\" height=\"20\">255</td>\n<td align=\"right\">255</td>\n<td align=\"right\">255</td>\n<td align=\"right\">10</td>\n<td align=\"right\">10</td>\n<td align=\"right\">10</td>\n</tr>\n<tr style=\"height: 15.0pt;\">\n<td style=\"height: 15.0pt;\" align=\"right\" height=\"20\">255</td>\n<td align=\"right\">255</td>\n<td align=\"right\">255</td>\n<td align=\"right\">10</td>\n<td align=\"right\">10</td>\n<td align=\"right\">10</td>\n</tr>\n<tr style=\"height: 15.0pt;\">\n<td style=\"height: 15.0pt;\" align=\"right\" height=\"20\">255</td>\n<td align=\"right\">255</td>\n<td align=\"right\">255</td>\n<td align=\"right\">10</td>\n<td align=\"right\">10</td>\n<td align=\"right\">10</td>\n</tr>\n<tr style=\"height: 15.0pt;\">\n<td style=\"height: 15.0pt;\" align=\"right\" height=\"20\">255</td>\n<td align=\"right\">255</td>\n<td align=\"right\">255</td>\n<td align=\"right\">10</td>\n<td align=\"right\">10</td>\n<td align=\"right\">10</td>\n</tr>\n</tbody>\n</table>\n<p>The values there are perfect white 255(for the left side) and almost perfect black 10 (for the right side). The reason we did not put 0 as perfect black is just because a non zero value is better helping to explain the topic.</p>\n<p>We will introduce another small matrix 3&#215;3 called a filter(a vertical one).</p>\n<table style=\"border-collapse: collapse; width: 144pt;\" border=\"0\" width=\"192\" cellspacing=\"0\" cellpadding=\"0\">\n<colgroup>\n<col style=\"width: 48pt;\" span=\"3\" width=\"64\" /> </colgroup>\n<tbody>\n<tr style=\"height: 15.0pt;\">\n<td style=\"height: 15.0pt; width: 48pt;\" align=\"right\" width=\"64\" height=\"20\">1</td>\n<td style=\"width: 48pt;\" align=\"right\" width=\"64\">0</td>\n<td style=\"width: 48pt;\" align=\"right\" width=\"64\">-1</td>\n</tr>\n<tr style=\"height: 15.0pt;\">\n<td style=\"height: 15.0pt;\" align=\"right\" height=\"20\">1</td>\n<td align=\"right\">0</td>\n<td align=\"right\">-1</td>\n</tr>\n<tr style=\"height: 15.0pt;\">\n<td style=\"height: 15.0pt;\" align=\"right\" height=\"20\">1</td>\n<td align=\"right\">0</td>\n<td align=\"right\">-1</td>\n</tr>\n</tbody>\n</table>\n<p>Now lets introduce a new operation <strong>*</strong> called convolution as below:</p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-1392\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/convulution.png?resize=638%2C177\" alt=\"\" width=\"638\" height=\"177\" srcset=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/convulution.png?w=638 638w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/convulution.png?resize=300%2C83 300w\" sizes=\"(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 984px) 61vw, (max-width: 1362px) 45vw, 600px\" data-recalc-dims=\"1\" /></p>\n<p>Convolution is fairly simple operation once you see it in action:</p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter wp-image-1404 zoooom\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-08_22h55_11.gif?resize=840%2C473\" alt=\"\" width=\"840\" height=\"473\" data-recalc-dims=\"1\" /></p>\n<p style=\"text-align: center;\"><em>As you already notice by now we are just sliding the filter one position horizontally and vertically until the end. Each time we multiply the filters matrix elements with the selected area(sub-matrix) on the image matrix and than add all together. So for position (<strong>0,0)</strong> we do: </em></p>\n<p style=\"text-align: center;\"><strong><em>(1 * <span style=\"font-size: 10pt;\">255 + 0 * 255 + -1 * 255 )+ (1 * 255 + 0 * 255 + -1 * 255) +( 1 * 255 + 0 * 255 + -1 * 255) = 0</span></em></strong></p>\n<p>This new operation produces as we can see the below new matrix:</p>\n<table style=\"border-collapse: collapse; width: 192pt;\" border=\"0\" width=\"256\" cellspacing=\"0\" cellpadding=\"0\">\n<colgroup>\n<col style=\"width: 48pt;\" span=\"4\" width=\"64\" /> </colgroup>\n<tbody>\n<tr style=\"height: 15.0pt;\">\n<td style=\"height: 15.0pt; width: 48pt;\" align=\"right\" width=\"64\" height=\"20\">0</td>\n<td style=\"width: 48pt;\" align=\"right\" width=\"64\">735</td>\n<td style=\"width: 48pt;\" align=\"right\" width=\"64\">735</td>\n<td style=\"width: 48pt;\" align=\"right\" width=\"64\">0</td>\n</tr>\n<tr style=\"height: 15.0pt;\">\n<td style=\"height: 15.0pt;\" align=\"right\" height=\"20\">0</td>\n<td align=\"right\">735</td>\n<td align=\"right\">735</td>\n<td align=\"right\">0</td>\n</tr>\n<tr style=\"height: 15.0pt;\">\n<td style=\"height: 15.0pt;\" align=\"right\" height=\"20\">0</td>\n<td align=\"right\">735</td>\n<td align=\"right\">735</td>\n<td align=\"right\">0</td>\n</tr>\n<tr style=\"height: 15.0pt;\">\n<td style=\"height: 15.0pt;\" align=\"right\" height=\"20\">0</td>\n<td align=\"right\">735</td>\n<td align=\"right\">735</td>\n<td align=\"right\">0</td>\n</tr>\n<tr style=\"height: 15.0pt;\">\n<td style=\"height: 15.0pt;\" align=\"right\" height=\"20\">0</td>\n<td align=\"right\">735</td>\n<td align=\"right\">735</td>\n<td align=\"right\">0</td>\n</tr>\n<tr style=\"height: 15.0pt;\">\n<td style=\"height: 15.0pt;\" align=\"right\" height=\"20\">0</td>\n<td align=\"right\">735</td>\n<td align=\"right\">735</td>\n<td align=\"right\">0</td>\n</tr>\n</tbody>\n</table>\n<p>One of the first observation is that this new matrix dimension have shrink from 8&#215;6 to 6&#215;4 pixels(more on this later).</p>\n<p>And most importantly we can see that in the middle matrix has high non zero values while on two sides just zeros. Recalling the fact that we wanted to detect vertical edges in a black and white image lets see if this helps. If we transform this matrix back into an image while keeping in mind 0 is black and 255 or greater is white will get something like this:</p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-1409\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/vedgeDetected.png?resize=278%2C123\" alt=\"\" width=\"278\" height=\"123\" data-recalc-dims=\"1\" /></p>\n<p>The image now has a white area right on the middle ,exactly where we were looking for the edge on simple black and white image. If you are wondering about the fact that the white area indicating the edge is bigger than sides, well this is due to our small 8&#215;6 pixels example. If we were going to pick up wider image like 8&#215;20 pixels the white are will be much smaller in comparison to the sides.</p>\n<p>There is an simple implementation of <a href=\"https://github.com/klevis/DigitRecognizer/blob/master/src/main/java/ramo/klevis/cnn/EdgeDetection.java\">EdgeDetection</a> if you would like to  try it on your own.Executed on a bigger black and white image of 466&#215;291 pixels the results would look like below:</p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-1416\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/edgesComparison.png?resize=840%2C248\" alt=\"\" width=\"840\" height=\"248\" srcset=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/edgesComparison.png?w=984 984w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/edgesComparison.png?resize=300%2C89 300w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/edgesComparison.png?resize=768%2C227 768w\" sizes=\"(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px\" data-recalc-dims=\"1\" /></p>\n<p style=\"text-align: center;\"><em>The edge now is clearly visible and also much smaller than the sides.</em></p>\n<h3>Horizontal Edge Detector</h3>\n<p>In the previous topic we explored the core concept behind Edge Detectors by giving an example of Vertical Edge Detector. In this section,similarly we will walk through an example for detecting Horizontal Edges.</p>\n<p>First lets define our image example as below:</p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-1421\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/horizontalmage.png?resize=394%2C241\" alt=\"\" width=\"394\" height=\"241\" srcset=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/horizontalmage.png?w=394 394w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/horizontalmage.png?resize=300%2C184 300w\" sizes=\"(max-width: 394px) 85vw, 394px\" data-recalc-dims=\"1\" /></p>\n<p>Similarly for simplicity we will work with a 8&#215;6 pixels image that would have the below matrix values representation:</p>\n<table style=\"border-collapse: collapse; width: 288pt;\" border=\"0\" width=\"384\" cellspacing=\"0\" cellpadding=\"0\">\n<colgroup>\n<col style=\"width: 48pt;\" span=\"6\" width=\"64\" /> </colgroup>\n<tbody>\n<tr style=\"height: 15.0pt;\">\n<td style=\"height: 15.0pt; width: 48pt;\" align=\"right\" width=\"64\" height=\"20\">255</td>\n<td style=\"width: 48pt;\" align=\"right\" width=\"64\">255</td>\n<td style=\"width: 48pt;\" align=\"right\" width=\"64\">255</td>\n<td style=\"width: 48pt;\" align=\"right\" width=\"64\">255</td>\n<td style=\"width: 48pt;\" align=\"right\" width=\"64\">255</td>\n<td style=\"width: 48pt;\" align=\"right\" width=\"64\">255</td>\n</tr>\n<tr style=\"height: 15.0pt;\">\n<td style=\"height: 15.0pt;\" align=\"right\" height=\"20\">255</td>\n<td align=\"right\">255</td>\n<td align=\"right\">255</td>\n<td align=\"right\">255</td>\n<td align=\"right\">255</td>\n<td align=\"right\">255</td>\n</tr>\n<tr style=\"height: 15.0pt;\">\n<td style=\"height: 15.0pt;\" align=\"right\" height=\"20\">255</td>\n<td align=\"right\">255</td>\n<td align=\"right\">255</td>\n<td align=\"right\">255</td>\n<td align=\"right\">255</td>\n<td align=\"right\">255</td>\n</tr>\n<tr style=\"height: 15.0pt;\">\n<td style=\"height: 15.0pt;\" align=\"right\" height=\"20\">255</td>\n<td align=\"right\">255</td>\n<td align=\"right\">255</td>\n<td align=\"right\">255</td>\n<td align=\"right\">255</td>\n<td align=\"right\">255</td>\n</tr>\n<tr style=\"height: 15.0pt;\">\n<td style=\"height: 15.0pt;\" align=\"right\" height=\"20\">10</td>\n<td align=\"right\">10</td>\n<td align=\"right\">10</td>\n<td align=\"right\">10</td>\n<td align=\"right\">10</td>\n<td align=\"right\">10</td>\n</tr>\n<tr style=\"height: 15.0pt;\">\n<td style=\"height: 15.0pt;\" align=\"right\" height=\"20\">10</td>\n<td align=\"right\">10</td>\n<td align=\"right\">10</td>\n<td align=\"right\">10</td>\n<td align=\"right\">10</td>\n<td align=\"right\">10</td>\n</tr>\n<tr style=\"height: 15.0pt;\">\n<td style=\"height: 15.0pt;\" align=\"right\" height=\"20\">10</td>\n<td align=\"right\">10</td>\n<td align=\"right\">10</td>\n<td align=\"right\">10</td>\n<td align=\"right\">10</td>\n<td align=\"right\">10</td>\n</tr>\n<tr style=\"height: 15.0pt;\">\n<td style=\"height: 15.0pt;\" align=\"right\" height=\"20\">10</td>\n<td align=\"right\">10</td>\n<td align=\"right\">10</td>\n<td align=\"right\">10</td>\n<td align=\"right\">10</td>\n<td align=\"right\">10</td>\n</tr>\n</tbody>\n</table>\n<p>Same as previous example 255 is representing white and 10 is representing black(0 will be the darkest black but for sake of explanation we keep some value rather than 0).</p>\n<p>Now is time to define the filter. This time we will use a slightly different filter which is just a flipped 90<sub>o</sub>right vertical filter (horizontal filter):</p>\n<table style=\"border-collapse: collapse; width: 144pt;\" border=\"0\" width=\"192\" cellspacing=\"0\" cellpadding=\"0\">\n<colgroup>\n<col style=\"width: 48pt;\" span=\"3\" width=\"64\" /> </colgroup>\n<tbody>\n<tr style=\"height: 15.0pt;\">\n<td style=\"height: 15.0pt; width: 48pt;\" align=\"right\" width=\"64\" height=\"20\">1</td>\n<td style=\"width: 48pt;\" align=\"right\" width=\"64\">1</td>\n<td style=\"width: 48pt;\" align=\"right\" width=\"64\">1</td>\n</tr>\n<tr style=\"height: 15.0pt;\">\n<td style=\"height: 15.0pt;\" align=\"right\" height=\"20\">0</td>\n<td align=\"right\">0</td>\n<td align=\"right\">0</td>\n</tr>\n<tr style=\"height: 15.0pt;\">\n<td style=\"height: 15.0pt;\" align=\"right\" height=\"20\">-1</td>\n<td align=\"right\">-1</td>\n<td align=\"right\">-1</td>\n</tr>\n</tbody>\n</table>\n<p>If we apply the convolution like explained in previous topic we will get the below matrix values for the convolution matrix:</p>\n<table style=\"border-collapse: collapse; width: 192pt;\" border=\"0\" width=\"256\" cellspacing=\"0\" cellpadding=\"0\">\n<colgroup>\n<col style=\"width: 48pt;\" span=\"4\" width=\"64\" /> </colgroup>\n<tbody>\n<tr style=\"height: 15.0pt;\">\n<td style=\"height: 15.0pt; width: 48pt;\" align=\"right\" width=\"64\" height=\"20\">0</td>\n<td style=\"width: 48pt;\" align=\"right\" width=\"64\">0</td>\n<td style=\"width: 48pt;\" align=\"right\" width=\"64\">0</td>\n<td style=\"width: 48pt;\" align=\"right\" width=\"64\">0</td>\n</tr>\n<tr style=\"height: 15.0pt;\">\n<td style=\"height: 15.0pt;\" align=\"right\" height=\"20\">0</td>\n<td align=\"right\">0</td>\n<td align=\"right\">0</td>\n<td align=\"right\">0</td>\n</tr>\n<tr style=\"height: 15.0pt;\">\n<td style=\"height: 15.0pt;\" align=\"right\" height=\"20\">735</td>\n<td align=\"right\">735</td>\n<td align=\"right\">735</td>\n<td align=\"right\">735</td>\n</tr>\n<tr style=\"height: 15.0pt;\">\n<td style=\"height: 15.0pt;\" align=\"right\" height=\"20\">735</td>\n<td align=\"right\">735</td>\n<td align=\"right\">735</td>\n<td align=\"right\">735</td>\n</tr>\n<tr style=\"height: 15.0pt;\">\n<td style=\"height: 15.0pt;\" align=\"right\" height=\"20\">0</td>\n<td align=\"right\">0</td>\n<td align=\"right\">0</td>\n<td align=\"right\">0</td>\n</tr>\n<tr style=\"height: 15.0pt;\">\n<td style=\"height: 15.0pt;\" align=\"right\" height=\"20\">0</td>\n<td align=\"right\">0</td>\n<td align=\"right\">0</td>\n<td align=\"right\">0</td>\n</tr>\n</tbody>\n</table>\n<p>Same as before the first observation is that the matrix dimension have shrink from 8&#215;6 to 6&#215;4 and the second observation is that in the middle we see big non zero values in comparison to zero on sides.</p>\n<p>Recalling the fact that we wanted to detect horizontal edges in a black and white image lets see if this helps. If we transform this matrix back into an image while keeping in mind 0 is black and 255 or greater is white will get something like this:</p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-1424\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/hEdge.png?resize=249%2C140\" alt=\"\" width=\"249\" height=\"140\" data-recalc-dims=\"1\" /></p>\n<p>The image has a white area right into the middle, exactly where we were looking for the edge.. The edge here is quite thick because of the small resolution we have pick up 8&#215;6 in below example the edge will much more thinner.</p>\n<p>There is an simple implementation of <a href=\"https://github.com/klevis/DigitRecognizer/blob/master/src/main/java/ramo/klevis/cnn/EdgeDetection.java\">EdgeDetection</a> if you would like to  try it on your own.Executed on a bigger black and white image of 466&#215;291 pixels the results would look like below:</p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-1426\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/edgeHComparison.png?resize=825%2C241\" alt=\"\" width=\"825\" height=\"241\" srcset=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/edgeHComparison.png?w=825 825w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/edgeHComparison.png?resize=300%2C88 300w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/edgeHComparison.png?resize=768%2C224 768w\" sizes=\"(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 984px) 61vw, (max-width: 1362px) 45vw, 600px\" data-recalc-dims=\"1\" /></p>\n<h3>Edge Detector Intuition</h3>\n<p>What is the convolution with small matrix doing that enabled us to detect edges therefore having more specialized image features?</p>\n<p>An edge is just group of pixels where a continues color changed for the first time into some other color. Referring our simple black and white image the edge was in middle where white change to black. Also it wouldn&#8217;t be difficult to imagine edges in more complicated images , we need just to follow the colors boundaries.</p>\n<p>Lets see one more time our two filters:</p>\n<table style=\"border-collapse: collapse; width: 336pt;\" border=\"0\" width=\"448\" cellspacing=\"0\" cellpadding=\"0\">\n<colgroup>\n<col style=\"width: 48pt;\" span=\"7\" width=\"64\" /> </colgroup>\n<tbody>\n<tr style=\"height: 15.0pt;\">\n<td class=\"xl63\" style=\"height: 15.0pt; width: 48pt;\" width=\"64\" height=\"20\">1</td>\n<td class=\"xl63\" style=\"width: 48pt;\" width=\"64\">0</td>\n<td class=\"xl63\" style=\"width: 48pt;\" width=\"64\">-1</td>\n<td style=\"width: 48pt;\" width=\"64\"></td>\n<td class=\"xl63\" style=\"width: 48pt;\" width=\"64\">1</td>\n<td class=\"xl63\" style=\"width: 48pt;\" width=\"64\">1</td>\n<td class=\"xl63\" style=\"width: 48pt;\" width=\"64\">1</td>\n</tr>\n<tr style=\"height: 15.0pt;\">\n<td class=\"xl63\" style=\"height: 15.0pt; width: 48pt;\" width=\"64\" height=\"20\">1</td>\n<td class=\"xl63\" style=\"width: 48pt;\" width=\"64\">0</td>\n<td class=\"xl63\" style=\"width: 48pt;\" width=\"64\">-1</td>\n<td></td>\n<td class=\"xl63\" style=\"width: 48pt;\" width=\"64\">0</td>\n<td class=\"xl63\" style=\"width: 48pt;\" width=\"64\">0</td>\n<td class=\"xl63\" style=\"width: 48pt;\" width=\"64\">0</td>\n</tr>\n<tr style=\"height: 15.0pt;\">\n<td class=\"xl63\" style=\"height: 15.0pt; width: 48pt;\" width=\"64\" height=\"20\">1</td>\n<td class=\"xl63\" style=\"width: 48pt;\" width=\"64\">0</td>\n<td class=\"xl63\" style=\"width: 48pt;\" width=\"64\">-1</td>\n<td></td>\n<td class=\"xl63\" style=\"width: 48pt;\" width=\"64\">-1</td>\n<td class=\"xl63\" style=\"width: 48pt;\" width=\"64\">-1</td>\n<td class=\"xl63\" style=\"width: 48pt;\" width=\"64\">-1</td>\n</tr>\n</tbody>\n</table>\n<p style=\"text-align: left;\"><em>On the left we have the vertical filter and on the right the horizontal filter</em></p>\n<p>As we saw the filters were sliding first one position horizontally until we reach the last column and than slide on position vertically and again horizontally until we reach the last row and column. Like below:</p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-1432\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-09_22h36_08.gif?resize=840%2C564\" alt=\"\" width=\"840\" height=\"564\" data-recalc-dims=\"1\" />Each time the filter is processing a sub matrix of the same size. In this case it processes a small sub matrix of <strong>3&#215;3</strong> in the big original image matrix starting at some position depending where the filter would be. Lets see what is filter doing to this sub matrix:</p>\n<table style=\"border-collapse: collapse; width: 532px;\" border=\"0\" cellspacing=\"0\" cellpadding=\"0\">\n<colgroup>\n<col style=\"width: 48pt;\" span=\"7\" width=\"64\" /> </colgroup>\n<tbody>\n<tr style=\"height: 15.0pt;\">\n<td style=\"height: 15pt; width: 74px;\" height=\"20\">1 * 255</td>\n<td style=\"width: 65px;\">0 * 255</td>\n<td class=\"xl65\" style=\"width: 36px;\">-1*255</td>\n<td style=\"width: 18px;\"></td>\n<td class=\"xl66\" style=\"width: 93px;\">1 * 255</td>\n<td class=\"xl66\" style=\"width: 75px;\">1 * 255</td>\n<td class=\"xl66\" style=\"width: 74px;\">1 * 255</td>\n</tr>\n<tr style=\"height: 15.0pt;\">\n<td style=\"height: 15pt; width: 74px;\" height=\"20\">1 * 255</td>\n<td style=\"width: 65px;\">0 * 255</td>\n<td class=\"xl65\" style=\"width: 36px;\">-1*256</td>\n<td style=\"width: 18px;\"></td>\n<td class=\"xl66\" style=\"width: 93px;\">0 * 255</td>\n<td class=\"xl66\" style=\"width: 75px;\">0 * 255</td>\n<td class=\"xl66\" style=\"width: 74px;\">0 * 255</td>\n</tr>\n<tr style=\"height: 15.0pt;\">\n<td style=\"height: 15pt; width: 74px;\" height=\"20\">1 * 255</td>\n<td style=\"width: 65px;\">0 * 255</td>\n<td class=\"xl65\" style=\"width: 36px;\">-1*257</td>\n<td style=\"width: 18px;\"></td>\n<td class=\"xl66\" style=\"width: 93px;\">-1 * 255</td>\n<td class=\"xl66\" style=\"width: 75px;\">-1 *255</td>\n<td class=\"xl66\" style=\"width: 74px;\">-1 * 255</td>\n</tr>\n</tbody>\n</table>\n<p style=\"text-align: center;\"><em>On the left is the <span style=\"text-decoration: underline;\">vertical filter</span> in action and on the right is the <span style=\"text-decoration: underline;\">horizontal filter</span> in action.</em></p>\n<p>Mathematically what is doing is just multiplying each position and than add up all together by getting only a number in the end. So one position movement produces a number only.</p>\n<p>Both of the fitters are ignoring the middle row by multiplying with zero. So they are both interested only on the sides , vertical filter is interested for the left and right side and horizontal filter interested for the up and down sides.</p>\n<p>Regardless of the sides position(left , up or right down) filters can produce two states:</p>\n<ol>\n<li>Colors are identical on both sides. So the right and left side are black(or white or other same color) or up and the down sides are  black(or white , or other same color). <span style=\"text-decoration: underline;\">So no edge here </span>since there was not any color change just a continuation of the color. The output will be 0 as one side is positive(multiplying by 1) and the other side is negative(multiplying by -1) , adding them gives 0.</li>\n<li>Sides are different color. I.e the right size was white and the left is black. Similar up side was white and the down side is black. <span style=\"text-decoration: underline;\">As consequence we have an edge here </span>as the color changed from one side to the other one. The output is non zero, it can be a negative value(from black smaller values 10 to white greater values 255)  or a positive value(from white bigger values 255 to black smaller values 10) but definitely not zero so it will signal a difference between sides.</li>\n</ol>\n<p>The row in the middle was left out this time but of course it will be included next time when the filter will slide one position to the right for vertical filter and one position down for the horizontal filter.</p>\n<p>Basically what a filter is doing is just transforming the image matrix to another image matrix where every pixel now signals an edge or not. In our case in this new matrix: if the pixel is 0 it mean no edge here so we fill it with black color. On the other hand if a pixel has a value we take the absolute(-100 or 100 is the same 100)value with a max of 255(-735 or 735 is 255)indicating the presence of an edge,  draw with white since higher number means more whiter.</p>\n<h2>Convolution on RGB Images(Examples)</h2>\n<p>So fare we only walked through simple black and white images. Now is time to explain how convolution will work with RGB colorful images.</p>\n<p>Recalling from <strong>Data Representation</strong> section a RGB image is represented by a three dimensional matrix <em>image[i][j][k] where (i,j) are the positions of pixels and k index(0,1,2) of colors value for Red,Green and Blue. </em>Comparing to black and white sample which had only one matrix with gray scale values from 0-255(0 black, 255 white) now we have three matrices each representing values 0-255 for Red,Green,Blue like below:</p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-1446\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-10_15h04_24.jpg?resize=840%2C693\" alt=\"\" width=\"840\" height=\"693\" srcset=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-10_15h04_24.jpg?w=896 896w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-10_15h04_24.jpg?resize=300%2C247 300w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-10_15h04_24.jpg?resize=768%2C633 768w\" sizes=\"(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px\" data-recalc-dims=\"1\" /></p>\n<p>The problem does not sound hard to address as now we only have three matrices instead of one. One can suggest to just apply convolution to each of them separately similarly as we did for one black and white:</p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-1448\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-10_15h15_27.jpg?resize=749%2C743\" alt=\"\" width=\"749\" height=\"743\" srcset=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-10_15h15_27.jpg?w=749 749w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-10_15h15_27.jpg?resize=150%2C150 150w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-10_15h15_27.jpg?resize=300%2C298 300w\" sizes=\"(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 984px) 61vw, (max-width: 1362px) 45vw, 600px\" data-recalc-dims=\"1\" />Well this worked quite well as we similarly to the black and white matrix have value from 0-255 for each transformed matrix. It is just that they instead of gray scale represent R,G,B respectively but a computer does not really care as long as you feed him with numbers.</p>\n<p>Although it looks like a solution we have a one last problem to solve. As we know after the convolution the matrices pixels represent knowledge if the pixel is an edge or not. So they do not represent anymore any color information or at least not in the same format as the original matrices R,G,B. Keeping this int mind , does it really make sense to keep three of them?</p>\n<p>Indeed keeping them separately intuitively does not seem useful beside we occupy useful memory and processing power. Maybe it will interesting research to try keeping three of them( if such research is not already existing as I am not aware of any at the moment). The solution again is pretty intuitive we just add three matrices together so in the end there is only one matrix left.</p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-1466\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-10_20h09_24.jpg?resize=840%2C506\" alt=\"\" width=\"840\" height=\"506\" srcset=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-10_20h09_24.jpg?w=1229 1229w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-10_20h09_24.jpg?resize=300%2C181 300w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-10_20h09_24.jpg?resize=768%2C462 768w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-10_20h09_24.jpg?resize=1024%2C617 1024w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-10_20h09_24.jpg?resize=1200%2C723 1200w\" sizes=\"(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px\" data-recalc-dims=\"1\" /></p>\n<p>As we can see convolution always will result in one single matrix regardless of the number(number of channel will be one) you had before applying it(usually 3 as RGB but it can also have more channels).</p>\n<p>Notice that we used the same Filter for the input R,G,B matrix but in reality those filters maybe different. So the convolution of RGB(WxHx<span style=\"color: #ff0000;\"><strong>3</strong></span>) matrix is done with a three dimensional Filter(WxHx<span style=\"color: #ff0000;\"><strong>3</strong></span> where W,H can be 5&#215;5 but the third parameter has to be equal to input matrix <strong>3</strong>). If the input matrix has more channels like 4,5,6 than the convolution has to have a filter with same dimension as well 4,5,6. Anyway regardless of the third dimension value(channels number) still the convolution always produces a two dimensional matrix by cutting the third dimension.</p>\n<p>There is an simple implementation of <a href=\"https://github.com/klevis/DigitRecognizer/blob/master/src/main/java/ramo/klevis/cnn/EdgeDetection.java\">EdgeDetection</a> if you would like to  try it on your own. Executed on below image:</p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-1473\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/smallGirl.png?resize=705%2C468\" alt=\"\" width=\"705\" height=\"468\" srcset=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/smallGirl.png?w=705 705w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/smallGirl.png?resize=300%2C199 300w\" sizes=\"(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 984px) 61vw, (max-width: 1362px) 45vw, 600px\" data-recalc-dims=\"1\" /></p>\n<p>it gives below results for vertical , horizontal and <a href=\"https://en.wikipedia.org/wiki/Sobel_operator\">sobel</a> filters:</p>\n<p><strong>Vertical:</strong></p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-1475\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/edges1.png?resize=705%2C468\" alt=\"\" width=\"705\" height=\"468\" srcset=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/edges1.png?w=705 705w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/edges1.png?resize=300%2C199 300w\" sizes=\"(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 984px) 61vw, (max-width: 1362px) 45vw, 600px\" data-recalc-dims=\"1\" /></p>\n<p><strong>Horizontal:</strong></p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-1474\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/edges2.png?resize=705%2C468\" alt=\"\" width=\"705\" height=\"468\" srcset=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/edges2.png?w=705 705w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/edges2.png?resize=300%2C199 300w\" sizes=\"(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 984px) 61vw, (max-width: 1362px) 45vw, 600px\" data-recalc-dims=\"1\" /></p>\n<p><strong>Sobel:</strong></p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-1476\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/edges3.png?resize=705%2C468\" alt=\"\" width=\"705\" height=\"468\" srcset=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/edges3.png?w=705 705w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/edges3.png?resize=300%2C199 300w\" sizes=\"(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 984px) 61vw, (max-width: 1362px) 45vw, 600px\" data-recalc-dims=\"1\" /></p>\n<h2>Convolution Parameters</h2>\n<p>Already we have seen that the convolution operation:</p>\n<ul>\n<li>shrinks the matrix dimensions from 8&#215;6 to 6&#215;4 in our case</li>\n<li>results always in one matrix regardless of original number of matrices</li>\n</ul>\n<p>We can of course control both of them in a way that will serve better our model. We have three ways If we would like to control the convolution matrix(CM) dimensions.</p>\n<h4>Padding</h4>\n<p>We can use <strong>padding</strong> in the case we want our CM to be equal or even greater than the original image(the third dimension is one for the black and white example). What padding does is just adding more zero value rows and columns to the original image. So in our simple black and white representation it look like below :</p>\n<table style=\"border-collapse: collapse; width: 384pt;\" border=\"0\" width=\"512\" cellspacing=\"0\" cellpadding=\"0\">\n<colgroup>\n<col style=\"width: 48pt;\" span=\"8\" width=\"64\" /> </colgroup>\n<tbody>\n<tr style=\"height: 15.0pt;\">\n<td class=\"xl64\" style=\"height: 15.0pt; width: 48pt;\" align=\"right\" width=\"64\" height=\"20\"><span style=\"color: #ff0000;\">0</span></td>\n<td class=\"xl64\" style=\"width: 48pt;\" align=\"right\" width=\"64\"><span style=\"color: #ff0000;\">0</span></td>\n<td class=\"xl64\" style=\"width: 48pt;\" align=\"right\" width=\"64\"><span style=\"color: #ff0000;\">0</span></td>\n<td class=\"xl64\" style=\"width: 48pt;\" align=\"right\" width=\"64\"><span style=\"color: #ff0000;\">0</span></td>\n<td class=\"xl64\" style=\"width: 48pt;\" align=\"right\" width=\"64\"><span style=\"color: #ff0000;\">0</span></td>\n<td class=\"xl64\" style=\"width: 48pt;\" align=\"right\" width=\"64\"><span style=\"color: #ff0000;\">0</span></td>\n<td class=\"xl64\" style=\"width: 48pt;\" align=\"right\" width=\"64\"><span style=\"color: #ff0000;\">0</span></td>\n<td class=\"xl64\" style=\"width: 48pt;\" align=\"right\" width=\"64\"><span style=\"color: #ff0000;\">0</span></td>\n</tr>\n<tr style=\"height: 15.0pt;\">\n<td class=\"xl65\" style=\"height: 15.0pt;\" align=\"right\" height=\"20\"><span style=\"color: #ff0000;\">0</span></td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">255</td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">255</td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">255</td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">10</td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">10</td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">10</td>\n<td class=\"xl64\" style=\"width: 48pt;\" align=\"right\" width=\"64\"><span style=\"color: #ff0000;\">0</span></td>\n</tr>\n<tr style=\"height: 15.0pt;\">\n<td class=\"xl65\" style=\"height: 15.0pt;\" align=\"right\" height=\"20\"><span style=\"color: #ff0000;\">0</span></td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">255</td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">255</td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">255</td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">10</td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">10</td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">10</td>\n<td class=\"xl64\" style=\"width: 48pt;\" align=\"right\" width=\"64\"><span style=\"color: #ff0000;\">0</span></td>\n</tr>\n<tr style=\"height: 15.0pt;\">\n<td class=\"xl65\" style=\"height: 15.0pt;\" align=\"right\" height=\"20\"><span style=\"color: #ff0000;\">0</span></td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">255</td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">255</td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">255</td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">10</td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">10</td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">10</td>\n<td class=\"xl64\" style=\"width: 48pt;\" align=\"right\" width=\"64\"><span style=\"color: #ff0000;\">0</span></td>\n</tr>\n<tr style=\"height: 15.0pt;\">\n<td class=\"xl65\" style=\"height: 15.0pt;\" align=\"right\" height=\"20\"><span style=\"color: #ff0000;\">0</span></td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">255</td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">255</td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">255</td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">10</td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">10</td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">10</td>\n<td class=\"xl64\" style=\"width: 48pt;\" align=\"right\" width=\"64\"><span style=\"color: #ff0000;\">0</span></td>\n</tr>\n<tr style=\"height: 15.0pt;\">\n<td class=\"xl65\" style=\"height: 15.0pt;\" align=\"right\" height=\"20\"><span style=\"color: #ff0000;\">0</span></td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">255</td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">255</td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">255</td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">10</td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">10</td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">10</td>\n<td class=\"xl64\" style=\"width: 48pt;\" align=\"right\" width=\"64\"><span style=\"color: #ff0000;\">0</span></td>\n</tr>\n<tr style=\"height: 15.0pt;\">\n<td class=\"xl65\" style=\"height: 15.0pt;\" align=\"right\" height=\"20\"><span style=\"color: #ff0000;\">0</span></td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">255</td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">255</td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">255</td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">10</td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">10</td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">10</td>\n<td class=\"xl64\" style=\"width: 48pt;\" align=\"right\" width=\"64\"><span style=\"color: #ff0000;\">0</span></td>\n</tr>\n<tr style=\"height: 15.0pt;\">\n<td class=\"xl65\" style=\"height: 15.0pt;\" align=\"right\" height=\"20\"><span style=\"color: #ff0000;\">0</span></td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">255</td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">255</td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">255</td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">10</td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">10</td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">10</td>\n<td class=\"xl64\" style=\"width: 48pt;\" align=\"right\" width=\"64\"><span style=\"color: #ff0000;\">0</span></td>\n</tr>\n<tr style=\"height: 15.0pt;\">\n<td class=\"xl65\" style=\"height: 15.0pt;\" align=\"right\" height=\"20\"><span style=\"color: #ff0000;\">0</span></td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">255</td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">255</td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">255</td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">10</td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">10</td>\n<td class=\"xl63\" style=\"width: 48pt;\" align=\"right\" width=\"64\">10</td>\n<td class=\"xl64\" style=\"width: 48pt;\" align=\"right\" width=\"64\"><span style=\"color: #ff0000;\">0</span></td>\n</tr>\n<tr style=\"height: 15.0pt;\">\n<td class=\"xl65\" style=\"height: 15.0pt;\" align=\"right\" height=\"20\"><span style=\"color: #ff0000;\">0</span></td>\n<td class=\"xl64\" style=\"width: 48pt;\" align=\"right\" width=\"64\"><span style=\"color: #ff0000;\">0</span></td>\n<td class=\"xl64\" style=\"width: 48pt;\" align=\"right\" width=\"64\"><span style=\"color: #ff0000;\">0</span></td>\n<td class=\"xl64\" style=\"width: 48pt;\" align=\"right\" width=\"64\"><span style=\"color: #ff0000;\">0</span></td>\n<td class=\"xl64\" style=\"width: 48pt;\" align=\"right\" width=\"64\"><span style=\"color: #ff0000;\">0</span></td>\n<td class=\"xl64\" style=\"width: 48pt;\" align=\"right\" width=\"64\"><span style=\"color: #ff0000;\">0</span></td>\n<td class=\"xl64\" style=\"width: 48pt;\" align=\"right\" width=\"64\"><span style=\"color: #ff0000;\">0</span></td>\n<td class=\"xl64\" style=\"width: 48pt;\" align=\"right\" width=\"64\"><span style=\"color: #ff0000;\">0</span></td>\n</tr>\n</tbody>\n</table>\n<p>We changed the dimension from<strong> 8&#215;6 to 10&#215;8</strong> by applying 1 padding(one zero layer all around). Now if we apply a 3&#215;3 convolution filter as explained above to this new <strong>10&#215;8 </strong>matrix(by sliding one position horizontally and than one position vertically) we will get a CM with dimension <strong>8&#215;6 </strong>, same as the original image. Padding more will result CM to be even greater than original image. By now you already guessed that there is a specific formula by which original image dimension is related to the CM. The formula is fairly easy as below:</p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-1458\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-10_19h32_54.jpg?resize=229%2C37\" alt=\"\" width=\"229\" height=\"37\" data-recalc-dims=\"1\" /></p>\n<p style=\"text-align: center;\"><em>where CM is convolutional matrix dimension(column or row) , OM is original matrix dimension (column or row) , P stands for padding number and F is the filter dimensions(column or row). </em></p>\n<p>So if we would like to have the CM matrix same dimension as OM than we need just to solve the above equation to be equal to original matrix dimension:</p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-1546\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-24_23h24_42.jpg?resize=257%2C278\" alt=\"\" width=\"257\" height=\"278\" data-recalc-dims=\"1\" /></p>\n<p>We found that padding by one will give us the same dimension as original matrix after applying the <strong>3&#215;3</strong> convolution.</p>\n<p style=\"text-align: left;\">Padding by one make the <strong>8&#215;6 </strong>matrix evolve to <strong>10&#215;8. </strong>Lets try to apply convolution now<b>:</b></p>\n<p style=\"text-align: left;\"> <i>CM<sup>row</sup> =OM<sup>row </sup>+ 2 * P- F<sup>row </sup>+1 =  8 +(<strong>1</strong> * 2) &#8211; 3 +1 =  8</i></p>\n<p><i> CM<span style=\"font-size: 12px;\">col</span> =OMcol<sup> </sup>+ 2 * P<sup> </sup>&#8211; Fcol<sup> </sup>+1 =  6 + (<strong>1</strong> * 2) &#8211; 3 +1 =  6</i></p>\n<h4>Stride</h4>\n<p>We can use <strong>striding </strong>in the case we would like to shrink our CM(the third dimension is always one) even more as by default it always shrinks a bit. Until this point we always slide the filter on position , what if we can slide 2,3,4? Sliding the filter with greater factor will result the CM to have smaller dimensions as we simply check less elements on the original matrix. The reason we might want to do that is maybe to save some computation and memory so to say maybe this is not impacting our model in a bad way but instead it speeds the learning phase. Of course again there is formula:</p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-1502\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-13_23h25_41.jpg?resize=199%2C63\" alt=\"\" width=\"199\" height=\"63\" data-recalc-dims=\"1\" /></p>\n<p style=\"text-align: center;\"><em>where CM is convolutional matrix dimension(column or row) , OM is original matrix dimension (column or row) , S stands for striding number of positions and F is the filter dimensions(column or row). </em></p>\n<p>So basically S reduces CM dimension by a great factor, in the minimum case is S=2 which means the dimension are divided by two.</p>\n<h4>Multiple FIlters</h4>\n<p>Above we saw how to control CM dimensions on rows and columns but still we always had the third dimension set to one(convolution always produces one two dimensional matrix). This is because as we saw convolution will <strong>add up </strong>all CM matrices into a one CM matrix and this is happening regardless of original matrix had a third dimension(RGB). What we can do here is add more filters and apply convolution to the original matrix for each of this filters. By doing so we end up with multiple CM&#8217;s for each filter. So to say if we add 3 filters(each three dimensional or 3 channels as the original matrix) we would end up with 3 CM&#8217;s same as original RGB matrix. Below is how this may look like:</p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-1541\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-23_21h37_48.jpg?resize=840%2C546\" alt=\"\" width=\"840\" height=\"546\" srcset=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-23_21h37_48.jpg?w=1076 1076w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-23_21h37_48.jpg?resize=300%2C195 300w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-23_21h37_48.jpg?resize=768%2C499 768w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-23_21h37_48.jpg?resize=1024%2C665 1024w\" sizes=\"(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px\" data-recalc-dims=\"1\" /></p>\n<h4>Putting all together</h4>\n<p>So in three above section we learned how to control dimension rows and columns through padding and striding and the number of the third dimension(channel) by adding more filters.</p>\n<p>We can of course combine both <strong>padding and striding </strong>in one final formula which gives us the flexibility to control matrix dimensions:</p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-1503\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-13_23h24_20.jpg?resize=256%2C62\" alt=\"\" width=\"256\" height=\"62\" data-recalc-dims=\"1\" /></p>\n<p style=\"text-align: center;\"><em>where CM is convolutional matrix dimension(column or row) , OM is original matrix dimension (column or row) , P stands for padding number, S stands for striding number of positions and F is the filter dimensions(column or row). </em></p>\n<p>Was not mention above but of course we can shrink the size of CM by also increasing the size of the Filter itself(F). Till not we saw only a 3&#215;3 filter but for sure it may change and from formula we can see that the greater the filter dimensions smaller the CM dimension(keeping other parameters constant).</p>\n<p>The third dimension(channel) is easy to think about as the number of filters affects directly the size of CM channels or third dimension.</p>\n<p>It is possible to produce the same size as the input after applying a convolution ,we just need to solve the above equation to equal to the input size. Usually when we want the same size matrix also after the convolution is applied the operation is called : &#8216;<span style=\"text-decoration: underline;\"><strong>Same Convolution</strong></span>&#8216;.</p>\n<h2>Pooling Layers</h2>\n<p>Pooling layers are another type of filter that usually used for reducing matrix dimensions therefore speed up the computations. Most of the times is used <strong>Max Pooling </strong>but maybe also rarely <strong>Average Pooling. </strong></p>\n<h3>Max Pooling</h3>\n<p>Max Pooling(MP) is very similar to filters for edge detection. MP instead of multiplying and than adding all pixels of the selected sub matrix they just produce as output the maximum value of selected pixels. In the same way as filters they slide one ore more positions horizontally and vertically depending on parameters. So they share exactly  the same formula as filters for controlling the output dimensions.</p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-1503\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-13_23h24_20.jpg?resize=256%2C62\" alt=\"\" width=\"256\" height=\"62\" data-recalc-dims=\"1\" /></p>\n<p style=\"text-align: center;\"><em>IM is input matrix dimension (column or row) , P stands for padding number(<strong>usually 0</strong>), S stands for striding number of positions(usually 2) and F is the max pooling dimensions(column or row, usually 2&#215;2). </em></p>\n<p>One thing to notice about Max Pooling is that they leave the third dimension untouched(same value as it was). We saw that convolution filters cut the third dimension by always producing two dimensional matrix. While Max Pooling are used only to reduce <span style=\"text-decoration: underline;\"><em><strong>heightXwidth</strong></em></span> and leaving third dimension unchanged. This is done by applying the same Max Pooling Filter as much times as the third dimension value was on the original Matrix.( as we saw at <strong>Multiple Filters section)</strong>.</p>\n<p>There is not really much to say about Max Pooling as they share every dynamics with filters. Is hard to say what is the intuition behind Max Pooling but usually they work well to reduce dimension therefore speed up computation, reduce overfitting  and improve also the model accuracy.</p>\n<h3><strong>Average Pooling</strong></h3>\n<p>As the name suggest this Pooling Layer instead of doing the max or multiply and add they calculate the average of selected pixels.In practice is found very rarely as more often a Max Pooling will perform better.</p>\n<h2>Learn with Convolution Neural Network</h2>\n<p>Now is time to put all pieces together in building a model which can actually learn and than help us predict and solve problems. The part that doesn&#8217;t change here is the <a href=\"http://ramok.tech/2017/11/29/digit-recognizer-with-neural-networks/\">Neural Network</a> (NN)we already saw. We only add what is seen so fare before NN start learning, so to say NN now will learn in a more image specialized features processed by Convolutional Technics.</p>\n<p>Anyway there is a final trick we need to discover to make CNN even more powerful. So fare we have seen only a limited number of filters : Vertical Edge Filter, Horizontal and Sobel(by example only).</p>\n<p>Why can&#8217;t we just let the NN figure out what type of filters(edge detectors) are better for the model? Maybe NN can find out better filters than Vertical,Horizontal or Sobel. The final trick consist of parameterizing the filters so instead of hard coding the types they can be discovered by NN. In the same time lets add also many parameterized filters to the model. So it may look as below:</p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-1543\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-23_21h50_20.jpg?resize=840%2C409\" alt=\"\" width=\"840\" height=\"409\" srcset=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-23_21h50_20.jpg?w=1550 1550w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-23_21h50_20.jpg?resize=300%2C146 300w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-23_21h50_20.jpg?resize=768%2C374 768w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-23_21h50_20.jpg?resize=1024%2C498 1024w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-23_21h50_20.jpg?resize=1200%2C584 1200w\" sizes=\"(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px\" data-recalc-dims=\"1\" /></p>\n<p>Filter Θ parameters introduced by filters are identical to NN Θ , they are learned by the network with the help of back propagation as explained at <a href=\"http://ramok.tech/2017/11/29/digit-recognizer-with-neural-networks/#How_to_use_the_modelHypothesis\">previous post</a>. Although there is a small difference with NN parameters, filters parameters are smaller in number so they will not slow down back prop and in the same time offer great features for our model.</p>\n<p>E.x if we add 16 filters with 5x5x<strong>3</strong> dimension and another layer of 32 filters of 3&#215;3<strong>x3</strong> dimension we end up with 2064 parameters. If we take the same example but with neurons :</p>\n<p>Input size 28&#215;28 pixels so 784 ,  two hidden layers (one with 16 neurons and the other with 32) and 10 outputs in total they produce : 784 * 16 * 32 * 10 = 4.014.080 parameters to learn. So the neurons parameters numbers are much larger because they depend on :  fully connected inputs ,hidden layers and outputs. While filters parameters remain constant therefore not slowing down that much.Anyway Still convolutional networks take a long time to train on simple computers because of large multiplication operation number comparing to Neural Networks without convolution layers.</p>\n<p>On the other hand Pooling Layers do not have any parameters they just serve as a transformer or better as a dimension reducer of the input matrix.</p>\n<h2>Application</h2>\n<h3>Data Source</h3>\n<p>Data used for building the <a href=\"https://drive.google.com/open?id=10d9uOMhVfP_coblW_hCMGjUkcz9odMgc\">application</a> were taken from this web <a href=\"http://yann.lecun.com/exdb/mnist/\">site</a> :</p>\n<p><a href=\"http://yann.lecun.com/exdb/mnist/\">MNIST</a> database has 60.000 of training data and 10.000 of test data.  The data contain black white hand written digit images of 28X28 pixels. Each pixel contains a number from 0-255 showing the gray scale, 0 while and 255 black. Data used here are the same as <a href=\"http://ramok.tech/#Data\">previous post</a> so for more details how the data are organised please have a quick look <a href=\"http://ramok.tech/#Data\">here</a>.</p>\n<h3>Network Configuration</h3>\n<p>Same as previous post we usetwo hidden layers 128 and 64 neurons and 10 outputs(0-9 digits). But of course there is crucial difference in front of two hidden layers(before 128 neurons) we apply several convolution layers and max pooling like below:</p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-1506\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-13_23h37_01.jpg?resize=840%2C412\" alt=\"\" width=\"840\" height=\"412\" srcset=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-13_23h37_01.jpg?w=1491 1491w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-13_23h37_01.jpg?resize=300%2C147 300w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-13_23h37_01.jpg?resize=768%2C377 768w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-13_23h37_01.jpg?resize=1024%2C502 1024w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-13_23h37_01.jpg?resize=1200%2C588 1200w\" sizes=\"(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px\" data-recalc-dims=\"1\" /></p>\n<p>Applying the formula we explored at &#8220;<em>Putting All Together Section</em>&#8221; we get the following dimensions:</p>\n<p>First we apply a 20 convolution operations with size 5&#215;5(S=1,P=0) so that gives us: 28-5/1 +1=24 so 24&#215;24 and since we have 20 convolutions we have <span style=\"font-size: 14pt;\"><strong>24x24x20</strong></span></p>\n<p>Second we apply max pooling with 2&#215;2 and s=2 so this gives us:                           24-2/2 +1= 11 so<span style=\"font-size: 14pt;\"> <strong>12x12x20.</strong></span></p>\n<p>Again we apply 50 convolution(5&#215;5 S=1,P=0) and max pooling (2&#215;2 s=2,P=0) and in the end we have <span style=\"font-size: 14pt;\"><strong>4x4x50(800)</strong></span> image size. We feed the new image to a neural network with 4x4x50(800) as input size, two hidden layers 128,64 and one output 10(0-9 digits). Lets see below how the code will look like.</p>\n<h3>Code</h3>\n<p>In previous post we used <a href=\"https://spark.apache.org/docs/latest/ml-classification-regression.html#multilayer-perceptron-classifier\">Spark MLib</a> train a Simple Neural Network and predict hand writing digits. While in this post we used <a href=\"https://deeplearning4j.org/\">Deeplearning4j </a>framework to train a deep convolutional network. The reason behind that is that SPARK MLib at the moment do not offer convolution layers to a Neural Network. Please find below the network configuration matching above topology(for more details find class code <a href=\"https://github.com/klevis/DigitRecognizer/blob/master/src/main/java/ramo/klevis/cnn/ConvolutionalNeuralNetwork.java\">here</a>):</p>\n<pre>int nChannels = 1; // Number of input channels\nint outputNum = 10; // The number of possible outcomes\nint batchSize = 64; // Test batch size\nint nEpochs = 20; // Number of training epochs\nint iterations = 1; // Number of training iterations\nint seed = 123; //\n\nMnistDataSetIterator mnistTrain = new MnistDataSetIterator(batchSize, trainDataSize, false, true, true, 12345);\n\nMultiLayerConfiguration conf = new NeuralNetConfiguration.Builder()\n        .seed(seed)\n        .iterations(iterations)\n        .regularization(false)\n        .learningRate(0.01)\n        .weightInit(WeightInit.XAVIER)\n        .optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT)\n        .updater(Updater.NESTEROVS)\n        .list()\n        .layer(0, new ConvolutionLayer.Builder(5, 5)\n                .nIn(nChannels)\n                .stride(1, 1)\n                .nOut(20)\n                .activation(Activation.IDENTITY)\n                .build())\n        .layer(1, new SubsamplingLayer.Builder(SubsamplingLayer.PoolingType.MAX)\n                .kernelSize(2, 2)\n                .stride(2, 2)\n                .build())\n        .layer(2, new ConvolutionLayer.Builder(5, 5)\n                .nIn(20)\n                .stride(1, 1)\n                .nOut(50)\n                .activation(Activation.IDENTITY)\n                .build())\n        .layer(3, new SubsamplingLayer.Builder(SubsamplingLayer.PoolingType.MAX)\n                .kernelSize(2, 2)\n                .stride(2, 2)\n                .build())\n        .layer(4, new DenseLayer.Builder().activation(Activation.RELU)\n                .nIn(800)\n                .nOut(128).build())\n        .layer(5, new DenseLayer.Builder().activation(Activation.RELU)\n                .nIn(128)\n                .nOut(64).build())\n        .layer(6, new OutputLayer.Builder(LossFunctions.LossFunction.NEGATIVELOGLIKELIHOOD)\n                .nOut(outputNum)\n                .activation(Activation.SOFTMAX)\n                .build())\n        .setInputType(InputType.convolutionalFlat(28, 28, 1))\n        .backprop(true).pretrain(false).build();</pre>\n<h3>Application and Results</h3>\n<p>Training the network this time took approx 1.5 hours and required almost 10GB of RAM memory. As above code shows the network was trained 20 times with a batch size of 64. The accuracy was quite respectable <strong><span style=\"font-size: 14pt;\">99.2%</span> </strong>in comparison to <strong>97%</strong> previously without using Convolution.</p>\n<p>The model was still improving and maybe running 20 more times would improve the accuracy even more but running convolution neural networks takes a lot of resources and time. For this type of applications GPU will greatly help in training bigger neural networks and much faster. Feel free to try more deep network or this topology with more <strong>epochs</strong>. There also already trained networks <a href=\"http://yann.lecun.com/exdb/mnist/\">MNIST DataSet</a> like the well known LeeNet-5. In the source you already can find an implementation of <a href=\"https://github.com/klevis/DigitRecognizer/blob/master/src/main/java/ramo/klevis/cnn/LenetMnistExample.java\">LeeNet-5</a> which when I run it offered 99% accuracy in 15 iterations also quite fast training(maybe better for prototyping).</p>\n<h3><span id=\"Run_Application\" class=\"ez-toc-section\"><span id=\"Application\" class=\"ez-toc-section\">Run Application</span></span></h3>\n<p><a href=\"https://drive.google.com/open?id=10d9uOMhVfP_coblW_hCMGjUkcz9odMgc\">Application </a>can be <a href=\"https://drive.google.com/open?id=10d9uOMhVfP_coblW_hCMGjUkcz9odMgc\">downloaded </a>and executed without any knowledge of java beside JAVA has to be installed on your computer. Feel to try it with choosing different options like:</p>\n<ul>\n<li><em>training data size default to 30.000 and test data size default to 10.000</em></li>\n<li><i>number of neurons and layers, not yet added(<a href=\"https://github.com/klevis/DigitRecognizer\">contributions appreciated</a>) </i></li>\n</ul>\n<p><a href=\"https://drive.google.com/open?id=10d9uOMhVfP_coblW_hCMGjUkcz9odMgc\">Application</a> already loads a default training executed before hand with accuracy 99.2% tested in 10.000 of test data and trained with 60.000 images.</p>\n<p>!!Please try to draw in the center as much as possible as the application do not use centering or crop as the data used for training.</p>\n<p>We can run the from <a href=\"https://github.com/klevis/DigitRecognizer\">source </a>by simply executing the <strong>RUN</strong> class or if you do not fill to open it with IDE just run <span style=\"text-decoration: underline;\"><em><strong>mvn clean install exec:java.</strong></em></span><em><strong>.</strong></em></p>\n<p><a href=\"https://drive.google.com/open?id=10d9uOMhVfP_coblW_hCMGjUkcz9odMgc\">Application </a>was build using Swing as GUI and <a href=\"ttps://deeplearning4j.org\">DeepLearning4J</a> for the executing the <em><strong>run.bat</strong></em> would show the below GUI:</p>\n<p><img decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-1517\" src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-14_01h00_37.jpg?resize=840%2C441\" alt=\"\" width=\"840\" height=\"441\" srcset=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-14_01h00_37.jpg?w=1186 1186w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-14_01h00_37.jpg?resize=300%2C157 300w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-14_01h00_37.jpg?resize=768%2C403 768w, https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-14_01h00_37.jpg?resize=1024%2C537 1024w\" sizes=\"(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px\" data-recalc-dims=\"1\" /></p>\n",
  "post-id": 1365
}