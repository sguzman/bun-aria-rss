{
  "guid": "73edbcf9-6497-4ff7-972b-38f22e1c0035",
  "title": "Controlling AI",
  "description": "<p>AI can do a lot of specific tasks as well as, or even better than, humans can — for example, it can more accurately classify images, more efficiently process mail, and more logically manipulate a Go board. While we have made a lot of advances in task-specific AI, how far are we from artificial general intelligence (AGI), that is AI that matches general human intelligence and capabilities?</p><p>In this podcast, a16z operating partner Frank Chen interviews Stuart Russell, the Founder of the Center for Human-Compatible Artificial Intelligence (CHAI) at UC Berkeley. They outline the conceptual breakthroughs, like natural language understanding, still required for AGI. But more importantly, they explain how and why we should design AI systems to ensure that we can control AI, and eventually AGI, when it’s smarter than we are. The conversation starts by explaining what Hollywood's Skynet gets wrong and ends with why AI is better as \"the perfect Butler, than the genie in the lamp.\"</p>\n",
  "pubDate": "Thu, 16 Jan 2020 21:03:09 +0000",
  "author": "content+a16zpodcast@a16z.com (Das Rush, Frank Chen, Stuart Russell)",
  "link": "https://a16z.simplecast.com/episodes/controllingai-lIq1XNUx",
  "content:encoded": "<p>AI can do a lot of specific tasks as well as, or even better than, humans can — for example, it can more accurately classify images, more efficiently process mail, and more logically manipulate a Go board. While we have made a lot of advances in task-specific AI, how far are we from artificial general intelligence (AGI), that is AI that matches general human intelligence and capabilities?</p><p>In this podcast, a16z operating partner Frank Chen interviews Stuart Russell, the Founder of the Center for Human-Compatible Artificial Intelligence (CHAI) at UC Berkeley. They outline the conceptual breakthroughs, like natural language understanding, still required for AGI. But more importantly, they explain how and why we should design AI systems to ensure that we can control AI, and eventually AGI, when it’s smarter than we are. The conversation starts by explaining what Hollywood's Skynet gets wrong and ends with why AI is better as \"the perfect Butler, than the genie in the lamp.\"</p>\n",
  "enclosure": "",
  "itunes:title": "Controlling AI",
  "itunes:author": "Das Rush, Frank Chen, Stuart Russell",
  "itunes:duration": "00:26:01",
  "itunes:summary": "AI can do a lot of specific tasks as well as, or even better than, humans can — for example, it can more accurately classify images, more efficiently process mail, and more logically manipulate a Go board. While we have made a lot of advances in task-specific AI, how far are we from artificial general intelligence (AGI), that is AI that matches general human intelligence and capabilities?\n\nIn this podcast, a16z operating partner Frank Chen interviews Stuart Russell, Founder of the Center for Human-Compatible Artificial Intelligence (CHAI) at UC Berkeley. They outline the conceptual breakthroughs, like natural language understanding, still required for AGI. But more importantly, they explain how and why we should design AI systems to ensure that we can control AI, and eventually AGI, when it’s smarter than we are. The conversation starts by explaining what Hollywood's Skynet gets wrong and ends with why AI is better as \"the perfect Butler, than the genie in the lamp.\"",
  "itunes:subtitle": "AI can do a lot of specific tasks as well as, or even better than, humans can — for example, it can more accurately classify images, more efficiently process mail, and more logically manipulate a Go board. While we have made a lot of advances in task-specific AI, how far are we from artificial general intelligence (AGI), that is AI that matches general human intelligence and capabilities?\n\nIn this podcast, a16z operating partner Frank Chen interviews Stuart Russell, Founder of the Center for Human-Compatible Artificial Intelligence (CHAI) at UC Berkeley. They outline the conceptual breakthroughs, like natural language understanding, still required for AGI. But more importantly, they explain how and why we should design AI systems to ensure that we can control AI, and eventually AGI, when it’s smarter than we are. The conversation starts by explaining what Hollywood's Skynet gets wrong and ends with why AI is better as \"the perfect Butler, than the genie in the lamp.\"",
  "itunes:keywords": "agi, artificial general intelligence, artificial intelligence, ai",
  "itunes:explicit": "no",
  "itunes:episodeType": "full",
  "itunes:episode": 513
}