{
  "title": "Lawfare Archive: Fighting Deep Fakes",
  "itunes:title": "Lawfare Archive: Fighting Deep Fakes",
  "pubDate": "Sun, 15 Aug 2021 09:00:21 GMT",
  "itunes:duration": "45:19",
  "enclosure": "",
  "guid": "61171a3f98d9270013677e5f",
  "itunes:explicit": "no",
  "link": "https://www.lawfareblog.com/lawfare-podcast-fighting-deep-fakes",
  "acast:episodeId": "61171a3f98d9270013677e5f",
  "acast:episodeUrl": "lawfare-archive-fighting-deep-fakes",
  "acast:settings": "ozu8rXK33NzX6c6CybB5UCT97XEpG0AhrnPuboek4zvH35TCBe4yORgGiwGuiujkFWjsF9iEOTkFqp7hbiAIwpb3W7XY98wFoQ0JVxKxYsO10i2uJWVrXKC+7OKeJUwqX+5QL5s5ZIdGCu7fi3dmEqUbuaI3Xb9n6TUHDRDRLPJU8rODxqmdMmdQ/JhGdo9ZRuzeJvTW39mcXopQo2Ic9VghUuwe/pqbth6Sx6ISFjNdmDd0HdLvsFV5OfBoqMwE0qzoP99xWRSpjsnI0eEYgKtQCnQ55tPrqgtWBe6qJu45iFBE0qW65CxzlrO4NnMN1ceRhnczpKe+2wnKsJavFOOqN2s6RsPHBibK+TfCJcqwxsYdRVlwM4weZT0MI2a3h3pgtPksMh32glxMJzBuNO1lcTbCRrICCykUyhcP5/XqYfuXeQfTp3AskgJpw7XwYUJIFb7RoZcraCkReNPHVurotz9B+03hkemekk9FfavHavwi/xwUzVyqGX6F4/HD0N2n6IotVvLnf/AgqVy9ufdLIQO4gLF3peSzKrw9kYO/3Ho//1NNaQIsJVqLRePUJ0Irl42m3+iZigIy2eZX4wwFzsqPNGU0NQR+Eg3Ionmg8ywOCxPsx7emYN28VJTfcORMSEEawNhvhXyG9YrUOG2Al4rtfLAVRGKSneDbApTgpwXhauK7gwuHY06YtTWfpQ1dqQ7VAomFPxZ3FK+YOn9fcH88yJy0qr/pAm9aJOU=",
  "itunes:episodeType": "full",
  "description": "<p>From August 4, 2018: Technologies that distort representations of reality, like audio, photo and video editing software, are nothing new, but what happens when these technologies are paired with artificial intelligence to produce hyper-realistic media of things that never happened? This new phenomenon, called \"deep fakes,\" poses significant problems for lawyers, policymakers, and technologists.</p><p>On July 19, Klon Kitchen, senior fellow for technology and national security at the Heritage Foundation, moderated a panel with Bobby Chesney of the University of Texas at Austin Law School, Danielle Citron of the University of Maryland Carey School of Law, and Chris Bregler, a senior computer scientist and AI manager at Google. They talked about how deep fakes work, why they don't fit into the current legal and policy thinking, and about how policy, technology and the law can begin to combat them.</p><p>Support this show <a target=\"_blank\" rel=\"payment\" href=\"http://supporter.acast.com/lawfare\">http://supporter.acast.com/lawfare</a>.</p><br /><hr><p style='color:grey; font-size:0.75em;'> Hosted on Acast. See <a style='color:grey;' target='_blank' rel='noopener noreferrer' href='https://acast.com/privacy'>acast.com/privacy</a> for more information.</p>",
  "itunes:summary": "<p>From August 4, 2018: Technologies that distort representations of reality, like audio, photo and video editing software, are nothing new, but what happens when these technologies are paired with artificial intelligence to produce hyper-realistic media of things that never happened? This new phenomenon, called \"deep fakes,\" poses significant problems for lawyers, policymakers, and technologists.</p><p>On July 19, Klon Kitchen, senior fellow for technology and national security at the Heritage Foundation, moderated a panel with Bobby Chesney of the University of Texas at Austin Law School, Danielle Citron of the University of Maryland Carey School of Law, and Chris Bregler, a senior computer scientist and AI manager at Google. They talked about how deep fakes work, why they don't fit into the current legal and policy thinking, and about how policy, technology and the law can begin to combat them.</p><p>Support this show <a target=\"_blank\" rel=\"payment\" href=\"http://supporter.acast.com/lawfare\">http://supporter.acast.com/lawfare</a>.</p><br /><hr><p style='color:grey; font-size:0.75em;'> Hosted on Acast. See <a style='color:grey;' target='_blank' rel='noopener noreferrer' href='https://acast.com/privacy'>acast.com/privacy</a> for more information.</p>"
}