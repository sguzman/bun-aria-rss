{
  "title": "86 | Martin Rees on Threats to Humanity, Prospects for Posthumanity, and Life in the Universe",
  "description": "<p>Anyone who has read histories of the Cold War, including the&nbsp;<a href=\"https://en.wikipedia.org/wiki/Cuban_Missile_Crisis\" target=\"_blank\">Cuban Missile Crisis</a>&nbsp;and the&nbsp;<a href=\"https://en.wikipedia.org/wiki/1983_Soviet_nuclear_false_alarm_incident\" target=\"_blank\">1983 nuclear false alarm,</a>&nbsp;must be struck by how incredibly close humanity has come to wreaking incredible destruction on itself. Nuclear war was the first technology humans created that was truly capable of causing such harm, but the list of potential threats is growing, from artificial pandemics to runaway super-powerful artificial intelligence. In response, today’s guest Martin Rees and others founded the Cambridge Centre for the Study of Existential Risk. We talk about what the major risks are, and how we can best reason about very tiny probabilities multiplied by truly awful consequences. In the second part of the episode we start talking about what humanity might become, as well as the prospect of life elsewhere in the universe, and that was so much fun that we just kept going.</p><p><em>Support Mindscape on&nbsp;</em><a href=\"https://www.patreon.com/seanmcarroll\" target=\"_blank\"><em>Patreon</em></a><em>.</em></p><p>Lord Martin Rees, Baron of Ludlow, received his Ph.D. in physics from University of Cambridge. He is currently Emeritus Professor of Cosmology and Astrophysics at the University of Cambridge, as well as Astronomer Royal of the United Kingdom. He was formerly Master of Trinity College and President of the Royal Society. Among his many awards are the Heineman Prize for Astrophysics, the Gruber Prize in Cosmology, the Crafoord Prize, the Michael Faraday Prize, the Templeton Prize, the Isaac Newton Medal, the Dirac Medal, and the British Order of Merit. He is a co-founder of the Centre for the Study of Existential Risk.</p><ul><li><a href=\"https://people.ast.cam.ac.uk/~mjr/\" target=\"_blank\">Web page</a></li><li><a href=\"https://www.ast.cam.ac.uk/people/Martin.J.Rees\" target=\"_blank\">Institute for Astronomy, Cambridge, web page</a></li><li><a href=\"https://scholar.google.com/scholar?hl=en&as_sdt=0,5&q=mj+rees\" target=\"_blank\">Google Scholar publications</a></li><li><a href=\"https://www.amazon.com/Martin-J.-Rees/e/B000AQ3OR0/ref=ntt_dp_epwbk_0\" target=\"_blank\">Amazon.com author page</a></li><li><a href=\"https://en.wikipedia.org/wiki/Martin_Rees\" target=\"_blank\">Wikipedia</a></li><li><a href=\"https://www.cser.ac.uk/\" target=\"_blank\">Centre for the Study of Existential Risk</a></li></ul><p><br></p><p>See Privacy Policy at <a href=\"https://art19.com/privacy\" rel=\"noopener noreferrer\" target=\"_blank\">https://art19.com/privacy</a> and California Privacy Notice at <a href=\"https://art19.com/privacy#do-not-sell-my-info\" rel=\"noopener noreferrer\" target=\"_blank\">https://art19.com/privacy#do-not-sell-my-info</a>.</p>",
  "itunes:title": "Martin Rees on Threats to Humanity, Prospects for Posthumanity, and Life in the Universe",
  "itunes:episodeType": "full",
  "itunes:episode": 86,
  "itunes:summary": "I talk with astrophysicist Lord Martin Rees about extreme risks to humanity and the Earth, and also about prospects for life elsewhere in the universe.",
  "content:encoded": "<p>Anyone who has read histories of the Cold War, including the&nbsp;<a href=\"https://en.wikipedia.org/wiki/Cuban_Missile_Crisis\" target=\"_blank\">Cuban Missile Crisis</a>&nbsp;and the&nbsp;<a href=\"https://en.wikipedia.org/wiki/1983_Soviet_nuclear_false_alarm_incident\" target=\"_blank\">1983 nuclear false alarm,</a>&nbsp;must be struck by how incredibly close humanity has come to wreaking incredible destruction on itself. Nuclear war was the first technology humans created that was truly capable of causing such harm, but the list of potential threats is growing, from artificial pandemics to runaway super-powerful artificial intelligence. In response, today’s guest Martin Rees and others founded the Cambridge Centre for the Study of Existential Risk. We talk about what the major risks are, and how we can best reason about very tiny probabilities multiplied by truly awful consequences. In the second part of the episode we start talking about what humanity might become, as well as the prospect of life elsewhere in the universe, and that was so much fun that we just kept going.</p><p><em>Support Mindscape on&nbsp;</em><a href=\"https://www.patreon.com/seanmcarroll\" target=\"_blank\"><em>Patreon</em></a><em>.</em></p><p>Lord Martin Rees, Baron of Ludlow, received his Ph.D. in physics from University of Cambridge. He is currently Emeritus Professor of Cosmology and Astrophysics at the University of Cambridge, as well as Astronomer Royal of the United Kingdom. He was formerly Master of Trinity College and President of the Royal Society. Among his many awards are the Heineman Prize for Astrophysics, the Gruber Prize in Cosmology, the Crafoord Prize, the Michael Faraday Prize, the Templeton Prize, the Isaac Newton Medal, the Dirac Medal, and the British Order of Merit. He is a co-founder of the Centre for the Study of Existential Risk.</p><ul><li><a href=\"https://people.ast.cam.ac.uk/~mjr/\" target=\"_blank\">Web page</a></li><li><a href=\"https://www.ast.cam.ac.uk/people/Martin.J.Rees\" target=\"_blank\">Institute for Astronomy, Cambridge, web page</a></li><li><a href=\"https://scholar.google.com/scholar?hl=en&as_sdt=0,5&q=mj+rees\" target=\"_blank\">Google Scholar publications</a></li><li><a href=\"https://www.amazon.com/Martin-J.-Rees/e/B000AQ3OR0/ref=ntt_dp_epwbk_0\" target=\"_blank\">Amazon.com author page</a></li><li><a href=\"https://en.wikipedia.org/wiki/Martin_Rees\" target=\"_blank\">Wikipedia</a></li><li><a href=\"https://www.cser.ac.uk/\" target=\"_blank\">Centre for the Study of Existential Risk</a></li></ul><p><br></p><p>See Privacy Policy at <a href=\"https://art19.com/privacy\" rel=\"noopener noreferrer\" target=\"_blank\">https://art19.com/privacy</a> and California Privacy Notice at <a href=\"https://art19.com/privacy#do-not-sell-my-info\" rel=\"noopener noreferrer\" target=\"_blank\">https://art19.com/privacy#do-not-sell-my-info</a>.</p>",
  "guid": "gid://art19-episode-locator/V0/l76rjeAHTXpoVEw8TVxNCWRa9h5D7iU5rC1WVv-xusY",
  "pubDate": "Mon, 02 Mar 2020 15:51:38 -0000",
  "itunes:explicit": "no",
  "itunes:image": "",
  "itunes:keywords": "existential risk,artificial intelligence,Society,science,Physics,ideas,extraterrestrial life",
  "itunes:duration": "01:40:02",
  "enclosure": ""
}