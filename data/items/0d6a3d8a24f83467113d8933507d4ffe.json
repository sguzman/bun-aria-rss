{
  "title": "is your model overtrained ?",
  "link": "https://calculatedcontent.com/2021/04/04/are-your-models-overtrained/",
  "comments": "https://calculatedcontent.com/2021/04/04/are-your-models-overtrained/#comments",
  "dc:creator": "Charles H Martin, PhD",
  "pubDate": "Sun, 04 Apr 2021 08:51:42 +0000",
  "category": "Uncategorized",
  "guid": "http://calculatedcontent.com/?p=14101",
  "description": "Are your models over-trained ? The weightwatcher tool can detect the signatures of overtraining in specific layers of a pre/trained &#8230; <a class=\"more-link\" href=\"https://calculatedcontent.com/2021/04/04/are-your-models-overtrained/\">More</a>",
  "content:encoded": "\n<p>Are your models over-trained ? The weightwatcher tool can detect the signatures of overtraining in specific layers of a pre/trained Deep Neural Networks.</p>\n\n\n\n<p>In the Figure above, fig (a) is well trained, whereas fig (b) may be over-trained. That orange spike on the far right is the tell-tale clue; it&#8217;s what we call a<em> Correlation Trap.  </em></p>\n\n\n\n<p>Weightwatcher can detect the signatures of overtraining in specific layers of a pre/trained Deep Neural Networks.   In this post, we show how to use the weightwatcher tool to do this.</p>\n\n\n\n<h3>WeightWatcher</h3>\n\n\n\n<p><strong>WeightWatcher</strong>&nbsp;(WW): is an open-source, diagnostic tool for analyzing Deep Neural Networks (DNN), without needing access to training or even test data. It analyzes the weight matrices of a pre/trained DNN, layer-by-layer, to help you detect potential problems.  Problems that can not be seen by just looking at the test accuracy or the training loss.</p>\n\n\n\n<p><strong>Installation</strong>:</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: bash; title: ; notranslate\">\npip install weightwatcher\n</pre></div>\n\n\n<p><strong>Usage:</strong></p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: python; title: ; notranslate\">\nimport weightwatcher as ww\nimport torchvision.models as models\n\nmodel = models.vgg19_bn(pretrained=True)\nwatcher = ww.WeightWatcher(model=model)\ndetails = watcher.analyze(plot=True, randomize=True)\n</pre></div>\n\n\n<p>For each layer, Weightwatcher plots the Empirical Spectral Density, or ESD.  This is just a histogram of the eigenvalues of the layer correlation matrix&nbsp;<strong>X=W<sup>T</sup>W</strong>.  </p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: python; title: ; notranslate\">\nimport numpy as np\nimport matplotlib,pyplot as plt\n...\nX = np.dot(W,W.T)\nevals, evecs = np.linalg.eig(X(\nplt.hist(evals, bin=100, density=True)\n...\n\n</pre></div>\n\n\n<p>By specifying the randomize option, WW randomizes elements of the weight matrix <strong>W</strong>, and then computes the it&#8217;s ESD.  This randomized ESD is overlaid on the orginal ESD of <strong>X</strong>, and ploted on a log scale. </p>\n\n\n\n<p>This is shown above, in the RHS (right hand side).  The original layer ESD is <mark style=\"background-color:rgba(0, 0, 0, 0);color:#67bf96;\" class=\"has-inline-color\"><strong>green</strong></mark>; the randomized ESD is <strong><mark style=\"background-color:rgba(0, 0, 0, 0);color:#c43c1a;\" class=\"has-inline-color\">red</mark></strong>,  And the <strong><mark style=\"background-color:rgba(0, 0, 0, 0);color:#dd5533;\" class=\"has-inline-color\">orange line </mark></strong>depicts the largest eigenvalue <img src=\"https://s0.wp.com/latex.php?latex=%5Clambda_%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Clambda_%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda_%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;lambda_{max}\" class=\"latex\" /> of the randomized ESD.</p>\n\n\n\n<p><img data-attachment-id=\"14298\" data-permalink=\"https://calculatedcontent.com/2021/10/17/fantastic-measures-of-generalization-that-actually-work-part-1/screen-shot-2021-10-17-at-11-47-59-pm/\" data-orig-file=\"https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-17-at-11.47.59-pm.png\" data-orig-size=\"2002,960\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"Screen Shot 2021-10-17 at 11.47.59 PM\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-17-at-11.47.59-pm.png?w=300\" data-large-file=\"https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-17-at-11.47.59-pm.png?w=1024\" class=\"wp-image-14298\" style=\"width:1000px;\" src=\"https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-17-at-11.47.59-pm.png\" alt=\"\"><br>If the layer is  well trained  matrix, then  when <strong>W</strong> is randomized, it&#8217;s ESD will look like that of a normally distributed random matrix.  This is shown in Figure (a), above.  </p>\n\n\n\n<p>But if the layer is over-trained, then it&#8217;s weight matrix <strong>W</strong> may have some unusually large elements, where the correlations may concentrate, or become <em>trapped</em>. In this case, the ESD may have 1 or more unusually large eigenvalues.  This is shown in Figure (b) above, with the <strong><mark style=\"background-color:rgba(0, 0, 0, 0);color:#dd5533;\" class=\"has-inline-color\">orange line</mark></strong> extending to the far right of the bulk of the <strong>red</strong> ESD. </p>\n\n\n\n<p>Notice also that in Figure (a), the <strong><mark style=\"background-color:rgba(0, 0, 0, 0);color:#67bf96;\" class=\"has-inline-color\">green</mark></strong> ESD is very Heavy-Tailed, with the histogram extending out to log10=2, or the largest eigenvalue of nearly 100:  <img src=\"https://s0.wp.com/latex.php?latex=%5Clambda%5Csim10%5E%7B2%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Clambda%5Csim10%5E%7B2%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda%5Csim10%5E%7B2%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;lambda&#92;sim10^{2}\" class=\"latex\" />.  But in  Figure (b),, the green ESD has a distinctly different shape and is smaller in scale than in Figure (a).  In fact, in (b), the <strong><mark style=\"background-color:rgba(0, 0, 0, 0);color:#67bf96;\" class=\"has-inline-color\">green</mark></strong> (original) and <strong><mark style=\"background-color:rgba(0, 0, 0, 0);color:#c43c1a;\" class=\"has-inline-color\">red</mark></strong> (randomized) layer ESDs look almost the same, except for a small shelf of larger <mark style=\"background-color:rgba(0, 0, 0, 0);color:#67bf96;\" class=\"has-inline-color\"><strong>green</strong></mark> eigenvalues, extending out to and concentrating around the <strong><mark style=\"background-color:rgba(0, 0, 0, 0);color:#dd5533;\" class=\"has-inline-color\">orange line</mark></strong>.  </p>\n\n\n\n<p class=\"has-text-align-center\"><strong>In cases like this, we can identify  the <span style=\"color:#dd5533;\" class=\"has-inline-color\">orange line</span> as a <em>Correlation Trap.</em>  </strong></p>\n\n\n\n<p>This indicates that something went wrong in training this layer, and the model did not capture the correlations in this layer in a way that will generalize well to other examples.</p>\n\n\n\n<h3>Conclusion</h3>\n\n\n\n<p>Using the Weight Watcher tool, you can detect this and other potential problems when training or fine-tuning your Deep Neural Networks.</p>\n\n\n\n<p>You can learn more about it on the <a href=\"http://github.com/CalculatedContent/WeightWatcher\">WeightWatcher github website.</a></p>\n",
  "wfw:commentRss": "https://calculatedcontent.com/2021/04/04/are-your-models-overtrained/feed/",
  "slash:comments": 4,
  "media:thumbnail": "",
  "media:content": [
    {
      "media:title": "correlation_trap"
    },
    {
      "media:title": "charlesmartin14"
    },
    ""
  ]
}