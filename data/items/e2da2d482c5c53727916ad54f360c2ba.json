{
  "title": "HyperSound: Generating Implicit Neural Representations of Audio Signals with Hypernetworks. (arXiv:2211.01839v1 [cs.SD])",
  "link": "http://arxiv.org/abs/2211.01839",
  "description": "<p>Implicit neural representations (INRs) are a rapidly growing research field,\nwhich provides alternative ways to represent multimedia signals. Recent\napplications of INRs include image super-resolution, compression of\nhigh-dimensional signals, or 3D rendering. However, these solutions usually\nfocus on visual data, and adapting them to the audio domain is not trivial.\nMoreover, it requires a separately trained model for every data sample. To\naddress this limitation, we propose HyperSound, a meta-learning method\nleveraging hypernetworks to produce INRs for audio signals unseen at training\ntime. We show that our approach can reconstruct sound waves with quality\ncomparable to other state-of-the-art models.\n</p>",
  "dc:creator": "<a href=\"http://arxiv.org/find/cs/1/au:+Szatkowski_F/0/1/0/all/0/1\">Filip Szatkowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piczak_K/0/1/0/all/0/1\">Karol J. Piczak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spurek_P/0/1/0/all/0/1\">Przemys&#x142;aw Spurek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tabor_J/0/1/0/all/0/1\">Jacek Tabor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trzcinski_T/0/1/0/all/0/1\">Tomasz Trzci&#x144;ski</a>"
}