{
  "title": "Video Event Extraction via Tracking Visual States of Arguments. (arXiv:2211.01781v1 [cs.CV])",
  "link": "http://arxiv.org/abs/2211.01781",
  "description": "<p>Video event extraction aims to detect salient events from a video and\nidentify the arguments for each event as well as their semantic roles. Existing\nmethods focus on capturing the overall visual scene of each frame, ignoring\nfine-grained argument-level information. Inspired by the definition of events\nas changes of states, we propose a novel framework to detect video events by\ntracking the changes in the visual states of all involved arguments, which are\nexpected to provide the most informative evidence for the extraction of video\nevents. In order to capture the visual state changes of arguments, we decompose\nthem into changes in pixels within objects, displacements of objects, and\ninteractions among multiple arguments. We further propose Object State\nEmbedding, Object Motion-aware Embedding and Argument Interaction Embedding to\nencode and track these changes respectively. Experiments on various video event\nextraction tasks demonstrate significant improvements compared to\nstate-of-the-art models. In particular, on verb classification, we achieve\n3.49% absolute gains (19.53% relative gains) in F1@5 on Video Situation\nRecognition.\n</p>",
  "dc:creator": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1\">Guang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Manling Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1\">Xudong Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiajie Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1\">Shih-Fu Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1\">Heng Ji</a>"
}