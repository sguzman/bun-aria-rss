{
  "title": "Why WeightWatcher Works",
  "link": "https://calculatedcontent.com/2020/09/14/why-weightwatcher-works/",
  "comments": "https://calculatedcontent.com/2020/09/14/why-weightwatcher-works/#respond",
  "dc:creator": "Charles H Martin, PhD",
  "pubDate": "Tue, 15 Sep 2020 04:10:22 +0000",
  "category": [
    "Uncategorized",
    "Deep Learning",
    "machine learning"
  ],
  "guid": "http://calculatedcontent.com/?p=13605",
  "description": "I am frequently asked, why does weightwatcher work ? The weightwatcher tool uses power law fits to model the eigenvalue &#8230; <a class=\"more-link\" href=\"https://calculatedcontent.com/2020/09/14/why-weightwatcher-works/\">More</a>",
  "content:encoded": "\n<p>I am frequently asked, why does <a href=\"http://github.com/CalculatedContent/WeightWatcher\">weightwatcher</a> work ?</p>\n\n\n\n<p>The weightwatcher tool uses power law fits to model the eigenvalue density <img src=\"https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;rho(&#92;lambda)\" class=\"latex\" /> of weight matrices of any Deep Neural Network (DNN).  </p>\n\n\n\n<p class=\"has-text-align-center\"><img src=\"https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29%5Csim+%5Clambda%5E%7B-%5Calpha%7D%2C%5C%3B%5C%3B%5C%3B%5Clambda%5Cin%5B%5Clambda_%7Bmin%7D%2C%5Clambda_%7Bmax%7D%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29%5Csim+%5Clambda%5E%7B-%5Calpha%7D%2C%5C%3B%5C%3B%5C%3B%5Clambda%5Cin%5B%5Clambda_%7Bmin%7D%2C%5Clambda_%7Bmax%7D%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29%5Csim+%5Clambda%5E%7B-%5Calpha%7D%2C%5C%3B%5C%3B%5C%3B%5Clambda%5Cin%5B%5Clambda_%7Bmin%7D%2C%5Clambda_%7Bmax%7D%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;rho(&#92;lambda)&#92;sim &#92;lambda^{-&#92;alpha},&#92;;&#92;;&#92;;&#92;lambda&#92;in[&#92;lambda_{min},&#92;lambda_{max}]\" class=\"latex\" /></p>\n\n\n\n<p>The average power-law exponent <img src=\"https://s0.wp.com/latex.php?latex=%5Clangle%5Calpha%5Crangle+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Clangle%5Calpha%5Crangle+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clangle%5Calpha%5Crangle+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;langle&#92;alpha&#92;rangle \" class=\"latex\" /> is remarkably well correlated with the test accuracy when changing the number of layers and/or fine-tuning the hyperparameters.   <a href=\"https://arxiv.org/pdf/2002.06716.pdf\">In our latest paper</a>, we demonstrate this using a metaanalysis on hundreds of pre-trained models.  This begs the question:</p>\n\n\n\n<p class=\"has-text-align-center\"><strong>Why can we model the weight matrices of DNNs using power law fits ?</strong></p>\n\n\n\n<p>In theoretical chemistry and physics, we know that strongly correlated, complex systems frequently display power laws.  </p>\n\n\n\n<p>In many machine learning and deep learning models, the correlations also display heavy / power law tails. After all, the whole point of learning is to learn the correlations in the data. Be it a simple clustering algorithm, or a very fancy Deep Neural Network, we want to find the most strongly correlated parts to describe our data and make predictions.</p>\n\n\n\n<p>For example, in strongly correlated systems, if you place an electron in a random potential, it will show a transition from delocalized to localized states, and the spectral density will display power law tails.  This is called Anderson Localization, and Anderson won the Nobel Prize in Physics for this in 1977.    In the early 90s, <a href=\"https://journals.aps.org/pre/abstract/10.1103/PhysRevE.50.1810\">Cizeau and Bouchaud </a>argued that a Wigner-Levy matrix will show a  similar localization transition, and since then have modeled the correlation matrices in finance using their variant of heavy tailed random matrix theory (RMT).   Even today this is still an area of active research <a href=\"https://www.youtube.com/watch?v=1h-SAngNYIA\">in mathematics </a>and<a href=\"https://www.amazon.com/First-Course-Random-Matrix-Theory/dp/1108488080\"> in finance</a>.</p>\n\n\n\n<p>In my earlier days as a scientist, I worked on strongly correlated multi-reference <em>ab initio</em> methods for quantum chemistry. Here, the trick is to find the right correlated subspace to get a good low order description. I believe, in machine learning, the same issues arise.   For this reason, I also model the correlation matrices in Deep Neural Networks <img src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D%3D%5Cmathbf%7BW%7D%5E%7BT%7D%5Cmathbf%7BW%7D&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D%3D%5Cmathbf%7BW%7D%5E%7BT%7D%5Cmathbf%7BW%7D&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D%3D%5Cmathbf%7BW%7D%5E%7BT%7D%5Cmathbf%7BW%7D&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;mathbf{X}=&#92;mathbf{W}^{T}&#92;mathbf{W}\" class=\"latex\" /> using heavy tailed RMT. </p>\n\n\n\n<p>Here I will show that the simplest machine learning model, Latent Semantic Analysis (LSA), shows a localization transition, and that this can be used to identify and characterize the heavy tail of the LSA correlation matrix.</p>\n\n\n\n<h5>Latent Semantic Analysis: a simple example of power law correlations</h5>\n\n\n\n<p>Take Latent Semantic Analysis (LSA). How do we select the Latent Space?  We need to select the top-K components of the TF-IDF Term-Document matrix <img src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BM%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BM%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BM%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;mathbf{M}\" class=\"latex\" />. I believe this can be done by selecting those K eigenvalues that best fit a power law.  Here is an example, using the scikit-learn 20newsgroups data:</p>\n\n\n\n<div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" data-attachment-id=\"13817\" data-permalink=\"https://calculatedcontent.com/screen-shot-2020-09-12-at-9-23-41-pm/\" data-orig-file=\"https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-12-at-9.23.41-pm.png\" data-orig-size=\"1104,746\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"screen-shot-2020-09-12-at-9.23.41-pm\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-12-at-9.23.41-pm.png?w=300\" data-large-file=\"https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-12-at-9.23.41-pm.png?w=1024\" src=\"https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-12-at-9.23.41-pm.png?w=1024\" alt=\"\" class=\"wp-image-13817\" width=\"491\" height=\"332\" srcset=\"https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-12-at-9.23.41-pm.png?w=491 491w, https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-12-at-9.23.41-pm.png?w=982 982w, https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-12-at-9.23.41-pm.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-12-at-9.23.41-pm.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-12-at-9.23.41-pm.png?w=768 768w\" sizes=\"(max-width: 491px) 100vw, 491px\" /></figure></div>\n\n\n\n<p>We call ths plot the Empirical Spectral Density (ESD). This is just a histogram plot, on a log scale,  of the eigenvalues  <img src=\"https://s0.wp.com/latex.php?latex=%5Clog_%7B10%7D%5C%3B+%5Clambda+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Clog_%7B10%7D%5C%3B+%5Clambda+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clog_%7B10%7D%5C%3B+%5Clambda+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;log_{10}&#92;; &#92;lambda \" class=\"latex\" /> of the TF-IDF correlation matrix <img src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;mathbf{X}\" class=\"latex\" />.   The correlation matrix is the square of the TF-IDF matrix</p>\n\n\n\n<p class=\"has-text-align-center\"><img src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D%3D%5Cmathbf%7BM%5E%7BT%7D%7D%5Cmathbf%7BM%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D%3D%5Cmathbf%7BM%5E%7BT%7D%7D%5Cmathbf%7BM%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D%3D%5Cmathbf%7BM%5E%7BT%7D%7D%5Cmathbf%7BM%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;mathbf{X}=&#92;mathbf{M^{T}}&#92;mathbf{M}\" class=\"latex\" /></p>\n\n\n\n<p> and the eigenvalues of <img src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;mathbf{X}\" class=\"latex\" /> are the singular values of <img src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BM%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BM%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BM%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;mathbf{M}\" class=\"latex\" />, squared: <img src=\"https://s0.wp.com/latex.php?latex=%5Clambda_%7Bi%7D%3D%5Csigma_%7Bi%7D%5E%7B2%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Clambda_%7Bi%7D%3D%5Csigma_%7Bi%7D%5E%7B2%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda_%7Bi%7D%3D%5Csigma_%7Bi%7D%5E%7B2%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;lambda_{i}=&#92;sigma_{i}^{2}\" class=\"latex\" />.</p>\n\n\n\n<p>We fit the eigenvalues to a power law (PL) using <a href=\"https://github.com/jeffalstott/powerlaw\">the python powerlaw package</a>, which implements a standard MLE estimator. </p>\n\n\n<pre class=\"brush: python; collapse: false; title: ; wrap-lines: false; notranslate\">\nfit = powerlaw.fit(eigenvalues)\n</pre>\n\n\n\n<p> The fit selects the optimal <code>xmin=</code><img src=\"https://s0.wp.com/latex.php?latex=%5Clambda_%7Bmin%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Clambda_%7Bmin%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda_%7Bmin%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;lambda_{min} \" class=\"latex\" /> using a brute force search, and returns the best PL exponent <img src=\"https://s0.wp.com/latex.php?latex=%5Calpha+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Calpha+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;alpha \" class=\"latex\" />, and the quality of the fit  <img src=\"https://s0.wp.com/latex.php?latex=D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"D \" class=\"latex\" /> (<a href=\"https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test\">the KS-distance</a>).  The <span style=\"color:#f58b28;\" class=\"has-inline-color\">orange line</span> displays the start of the power law tail, which contains the most strongly correlated eigenpairs.</p>\n\n\n\n<p>We can evaluate the quality of the PL fit by comparing the ESD and the actual fit on log-log plot.  </p>\n\n\n\n<div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" data-attachment-id=\"13851\" data-permalink=\"https://calculatedcontent.com/screen-shot-2020-09-14-at-6-09-46-pm/\" data-orig-file=\"https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-6.09.46-pm.png\" data-orig-size=\"838,586\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"screen-shot-2020-09-14-at-6.09.46-pm\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-6.09.46-pm.png?w=300\" data-large-file=\"https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-6.09.46-pm.png?w=838\" src=\"https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-6.09.46-pm.png?w=838\" alt=\"\" class=\"wp-image-13851\" width=\"495\" height=\"345\" srcset=\"https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-6.09.46-pm.png?w=493 493w, https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-6.09.46-pm.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-6.09.46-pm.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-6.09.46-pm.png?w=768 768w, https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-6.09.46-pm.png 838w\" sizes=\"(max-width: 495px) 100vw, 495px\" /><figcaption><strong>Comparison of empirical and fit PDF (blue) and CDF (red)</strong></figcaption></figure></div>\n\n\n\n<p>The<span class=\"has-inline-color has-accent-color\"> </span><strong><span style=\"color:#0a7ba5;\" class=\"has-inline-color\">blue solid line</span> </strong>is the ESD on a log-log scale (or the PDF), and the<span class=\"has-inline-color has-accent-color\"> blue dotted line</span> is the PL fit.  (The <strong><span class=\"has-inline-color has-secondary-color\">red solid line</span></strong> is the empirical CDF, and the <span class=\"has-inline-color has-secondary-color\">red dotted line</span> the fit).  The <span class=\"has-inline-color has-accent-color\">PDF (blue) </span>shows a very good linear fit up,  except perhaps for largest eigenvalues,  <img src=\"https://s0.wp.com/latex.php?latex=%5Clambda%5Clesssim%5Clambda_%7Bmax%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Clambda%5Clesssim%5Clambda_%7Bmax%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda%5Clesssim%5Clambda_%7Bmax%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;lambda&#92;lesssim&#92;lambda_{max} \" class=\"latex\" />.  Likewise, the <span class=\"has-inline-color has-secondary-color\">CDF (red) </span>shows a very good fit, up until the end of the tail.   This is typical of power-law fits on real-world data and is usually best described as a Truncated Power Law (TPL), with some noise in the very far tail *(more on the noise in a future post).  And the reported KS-distance <img src=\"https://s0.wp.com/latex.php?latex=D%3D0.008&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=D%3D0.008&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=D%3D0.008&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"D=0.008\" class=\"latex\" />, which is exceptional. </p>\n\n\n\n<p>We can get even more insight into the quality of the fit by examining how the PL method selected <code>xmin</code><img src=\"https://s0.wp.com/latex.php?latex=%3D%5Clambda_%7Bmin%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%3D%5Clambda_%7Bmin%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%3D%5Clambda_%7Bmin%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"=&#92;lambda_{min}\" class=\"latex\" />, the start of the PL.  Below, we plot the KS-distance for each possible choice of <code>xmin</code>:</p>\n\n\n\n<div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" data-attachment-id=\"13856\" data-permalink=\"https://calculatedcontent.com/screen-shot-2020-09-14-at-7-09-18-pm/\" data-orig-file=\"https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-7.09.18-pm.png\" data-orig-size=\"850,568\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"screen-shot-2020-09-14-at-7.09.18-pm\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-7.09.18-pm.png?w=300\" data-large-file=\"https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-7.09.18-pm.png?w=850\" src=\"https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-7.09.18-pm.png?w=850\" alt=\"\" class=\"wp-image-13856\" width=\"517\" height=\"345\" srcset=\"https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-7.09.18-pm.png?w=517 517w, https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-7.09.18-pm.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-7.09.18-pm.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-7.09.18-pm.png?w=768 768w, https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-7.09.18-pm.png 850w\" sizes=\"(max-width: 517px) 100vw, 517px\" /></figure></div>\n\n\n\n<p>The optimization landscape is convex, with a clear global minimum at the <span style=\"color:#fa9805;\" class=\"has-inline-color\">orange line</span>, which occurs at the <img src=\"https://s0.wp.com/latex.php?latex=%5Clambda_%7B547%7D%3D%5Clambda%7Bmin%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Clambda_%7B547%7D%3D%5Clambda%7Bmin%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda_%7B547%7D%3D%5Clambda%7Bmin%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;lambda_{547}=&#92;lambda{min}\" class=\"latex\" />.  That is, there are 547 eigenpairs in the tail of the ESD displaying strong power-law behavior.</p>\n\n\n\n<p class=\"has-text-align-center\"><em>To form the Latent space, we select these largest 547 eigenpairs, to the right of the <span style=\"color:#f88725;\" class=\"has-inline-color\">orange line</span>, the start of the (truncated) power-law fit</em></p>\n\n\n\n<h4>The Localization Transition</h4>\n\n\n\n<p>To identify the localization transition in LSA, we can plot localization ratios <img src=\"https://s0.wp.com/latex.php?latex=%5Cmathcal%7BL%7D%28%5Cmathbf%7Bv%7D%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Cmathcal%7BL%7D%28%5Cmathbf%7Bv%7D%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathcal%7BL%7D%28%5Cmathbf%7Bv%7D%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;mathcal{L}(&#92;mathbf{v})\" class=\"latex\" /> in the same way, where the localization is defined as in <a href=\"https://arxiv.org/pdf/1810.01075.pdf\">our first paper</a>:</p>\n\n\n\n<p class=\"has-text-align-center\"><img src=\"https://s0.wp.com/latex.php?latex=%5Cmathcal%7BL%7D%28%5Cmathbf%7Bv%7D%29%3D%5Cdfrac%7B%5CVert%5Cmathbf%7Bv%7D%7C%5CVert_%7B1%7D%7D%7B%5CVert%5Cmathbf%7Bv%7D%7C%5CVert_%7B%5Cinfty%7D%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Cmathcal%7BL%7D%28%5Cmathbf%7Bv%7D%29%3D%5Cdfrac%7B%5CVert%5Cmathbf%7Bv%7D%7C%5CVert_%7B1%7D%7D%7B%5CVert%5Cmathbf%7Bv%7D%7C%5CVert_%7B%5Cinfty%7D%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathcal%7BL%7D%28%5Cmathbf%7Bv%7D%29%3D%5Cdfrac%7B%5CVert%5Cmathbf%7Bv%7D%7C%5CVert_%7B1%7D%7D%7B%5CVert%5Cmathbf%7Bv%7D%7C%5CVert_%7B%5Cinfty%7D%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;mathcal{L}(&#92;mathbf{v})=&#92;dfrac{&#92;Vert&#92;mathbf{v}|&#92;Vert_{1}}{&#92;Vert&#92;mathbf{v}|&#92;Vert_{&#92;infty}}\" class=\"latex\" /></p>\n\n\n<pre class=\"brush: python; collapse: false; title: ; wrap-lines: false; notranslate\">\ndef localization_ratio(v):\n    return np.linalg.norm(v, ord=1) / np.linalg.norm(v, ord=np.inf)\n</pre>\n\n\n\n<p>We see that get an elbow curve, and the eigenvalue cutoff appears just to the right of the &#8216;elbow&#8217;:</p>\n\n\n\n<div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" data-attachment-id=\"13864\" data-permalink=\"https://calculatedcontent.com/screen-shot-2020-09-14-at-7-49-48-pm/\" data-orig-file=\"https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-7.49.48-pm.png\" data-orig-size=\"796,574\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"screen-shot-2020-09-14-at-7.49.48-pm\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-7.49.48-pm.png?w=300\" data-large-file=\"https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-7.49.48-pm.png?w=796\" src=\"https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-7.49.48-pm.png?w=796\" alt=\"\" class=\"wp-image-13864\" width=\"501\" height=\"361\" srcset=\"https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-7.49.48-pm.png?w=501 501w, https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-7.49.48-pm.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-7.49.48-pm.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-7.49.48-pm.png?w=768 768w, https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-7.49.48-pm.png 796w\" sizes=\"(max-width: 501px) 100vw, 501px\" /></figure></div>\n\n\n\n<p>Other methods include looking scree plots or even just the sorted eigenvalues themselves.  </p>\n\n\n\n<h5>Comparison with other K-selection methods</h5>\n\n\n\n<p>Typically, in unsupervised learning, one selects the top-K clusters, eigenpairs, etc. by looking at some so-called &#8216;elbow curve&#8217;, and identifying the K at the inflection point. We can make these plots too.  A classic way is to plot the explained variance per eigenpair:</p>\n\n\n\n<div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" data-attachment-id=\"13822\" data-permalink=\"https://calculatedcontent.com/screen-shot-2020-09-12-at-11-39-31-pm/\" data-orig-file=\"https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-12-at-11.39.31-pm.png\" data-orig-size=\"1112,712\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"screen-shot-2020-09-12-at-11.39.31-pm\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-12-at-11.39.31-pm.png?w=300\" data-large-file=\"https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-12-at-11.39.31-pm.png?w=1024\" src=\"https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-12-at-11.39.31-pm.png?w=1024\" alt=\"\" class=\"wp-image-13822\" width=\"542\" height=\"347\" srcset=\"https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-12-at-11.39.31-pm.png?w=1024 1024w, https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-12-at-11.39.31-pm.png?w=542 542w, https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-12-at-11.39.31-pm.png?w=1084 1084w, https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-12-at-11.39.31-pm.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-12-at-11.39.31-pm.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-12-at-11.39.31-pm.png?w=768 768w\" sizes=\"(max-width: 542px) 100vw, 542px\" /></figure></div>\n\n\n\n<p>We see that the power-law <img src=\"https://s0.wp.com/latex.php?latex=%5Clambda_%7Bmin%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Clambda_%7Bmin%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda_%7Bmin%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;lambda_{min}\" class=\"latex\" />,<span style=\"color:#f47210;\" class=\"has-inline-color\"> the orange line</span>, occurs just to the right of the inflection point.  So these two methods give similar results.  No other method provides a theoretically well-defined way, however, of selecting the K components.</p>\n\n\n\n<h5>Conclusion</h5>\n\n\n\n<p>I suspect that in these strongly correlated systems, the power law behavior really kicks it right at / before these inflection points.   So we can find the optimal low-rank approximation to these strongly correlated weight matrices by finding that subspace where the correlations follow a power-law / truncated power law distribution.  Moreover, we can detect, and characterize these correlations, by both the power-law exponent <img src=\"https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;alpha\" class=\"latex\" />, and the quality of the fit D.  </p>\n\n\n\n<p class=\"has-text-align-center\"><em>And AFAIK, this has never been suggested before. </em></p>\n",
  "wfw:commentRss": "https://calculatedcontent.com/2020/09/14/why-weightwatcher-works/feed/",
  "slash:comments": 0,
  "media:thumbnail": "",
  "media:content": [
    {
      "media:title": "screen-shot-2020-09-12-at-9.23.41-pm"
    },
    {
      "media:title": "charlesmartin14"
    },
    "",
    "",
    "",
    "",
    ""
  ]
}