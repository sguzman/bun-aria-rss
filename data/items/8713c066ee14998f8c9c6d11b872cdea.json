{
  "title": "Evolving Networks",
  "link": "https://wellecks.wordpress.com/2019/07/21/evolving-networks/",
  "comments": "https://wellecks.wordpress.com/2019/07/21/evolving-networks/#respond",
  "dc:creator": "wellecks",
  "pubDate": "Sun, 21 Jul 2019 18:35:21 +0000",
  "category": [
    "machine learning",
    "HyperNEAT",
    "maching learning",
    "NEAT",
    "neuroevolution"
  ],
  "guid": "http://wellecks.wordpress.com/?p=1190",
  "description": "Finding neural network topologies is a problem with a rich history in evolutionary computing, or neuroevolution. This post will revisit some of the key ideas and outgoing research paths. Code related to this post is found here: [code link]. NEAT In their 2002 paper, Kenneth Stanley & Risto Miikkulainen proposed the foundational algorithm NeuroEvolution of Augmenting [&#8230;]",
  "content:encoded": "<p>Finding neural network topologies is a problem with a rich history in evolutionary computing, or neuroevolution. This post will revisit some of the key ideas and outgoing research paths. Code related to this post is found here: [<a href=\"https://gist.github.com/wellecks/226dab0ff0dde625b097869fb932cff9\">code link</a>].</p>\n<h2>NEAT</h2>\n<p>In their <a href=\"http://Evolving Neural Networks through Augmenting Topologies\">2002 paper</a>, Kenneth Stanley & Risto Miikkulainen proposed the foundational algorithm NeuroEvolution of Augmenting Topologies (NEAT). I&#8217;ll focus on this algorithm as a starting point; for earlier developments please see <a href=\"https://link.springer.com/article/10.1007/s00521-019-04160-6\">Section 5.2 of this great review,</a> <a href=\"https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=273950\">Schaffer&#8217;s 1992 review</a>, and <a href=\"https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=784219\">Yao&#8217;s 1999 review</a>. The NEAT paper introduces the ideas clearly and there are other great <a href=\"http://blog.otoro.net/2016/05/07/backprop-neat/\">NEAT</a> <a href=\"https://www.cs.ucf.edu/~kstanley/neat.html\">overviews</a>, so to change it up I will try to present the algorithm with generic notation, which is perhaps useful for thinking about how to modify the algorithm or apply it to a new problem setting.</p>\n<p>I&#8217;ve also made an implementation [<a href=\"https://gist.github.com/wellecks/226dab0ff0dde625b097869fb932cff9\">code link</a>] contained in a single python file; you might find it useful to see the entire algorithm in one place, or as a comparison if you also implement NEAT as an exercise. For a more robust implementation, see <a href=\"https://github.com/CodeReclaimers/neat-python\">NEAT-Python</a> (which the code is based on) and its extension <a href=\"https://github.com/uber-research/PyTorch-NEAT\">PyTorch-NEAT</a>.</p>\n<h4><strong>Problem</strong></h4>\n<p>NEAT addresses the problem of finding a computation graph <img src=\"https://s0.wp.com/latex.php?latex=G+%3D+%28V%2C+E%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=G+%3D+%28V%2C+E%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=G+%3D+%28V%2C+E%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"G = (V, E)\" class=\"latex\" />. Each node <img src=\"https://s0.wp.com/latex.php?latex=v%5Cin+V&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=v%5Cin+V&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=v%5Cin+V&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"v&#92;in V\" class=\"latex\" /> has a bias, activation, and aggregation function, written <img src=\"https://s0.wp.com/latex.php?latex=%28b%2C+a%2C+%5Ctext%7Bagg%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%28b%2C+a%2C+%5Ctext%7Bagg%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28b%2C+a%2C+%5Ctext%7Bagg%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"(b, a, &#92;text{agg})\" class=\"latex\" />, and each edge <img src=\"https://s0.wp.com/latex.php?latex=e%5Cin+E&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=e%5Cin+E&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=e%5Cin+E&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"e&#92;in E\" class=\"latex\" /> has a source and destination, a weight, and may be active or inactive, written  <img src=\"https://s0.wp.com/latex.php?latex=%28u%2C+v%2C+w%2C+%5Ctext%7Bactive%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%28u%2C+v%2C+w%2C+%5Ctext%7Bactive%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28u%2C+v%2C+w%2C+%5Ctext%7Bactive%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"(u, v, w, &#92;text{active})\" class=\"latex\" />.</p>\n<p>Searching through the space of these graphs amounts to searching through a space of neural networks. NEAT conducts this search using a few generic neuroevolution concepts, which I&#8217;ll focus on below, and often implements them with design decisions that can be relaxed or modified for different problems.</p>\n<h4><strong>High-Level Method</strong></h4>\n<p>NEAT iteratively produces a set of candidates <img src=\"https://s0.wp.com/latex.php?latex=P%3D%5C%7BG_1%2C%5Cldots%2CG_N%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=P%3D%5C%7BG_1%2C%5Cldots%2CG_N%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=P%3D%5C%7BG_1%2C%5Cldots%2CG_N%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"P=&#92;{G_1,&#92;ldots,G_N&#92;}\" class=\"latex\" />, using a candidate partitioning <img src=\"https://s0.wp.com/latex.php?latex=S%3D%5C%7BS_1%2C%5Cldots%2CS_M%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=S%3D%5C%7BS_1%2C%5Cldots%2CS_M%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S%3D%5C%7BS_1%2C%5Cldots%2CS_M%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"S=&#92;{S_1,&#92;ldots,S_M&#92;}\" class=\"latex\" /> where <img src=\"https://s0.wp.com/latex.php?latex=S_j+%5Csubseteq+P&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=S_j+%5Csubseteq+P&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S_j+%5Csubseteq+P&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"S_j &#92;subseteq P\" class=\"latex\" /> and a given function <img src=\"https://s0.wp.com/latex.php?latex=f%3A%5Cmathcal%7BG%7D%5Crightarrow%5Cmathbb%7BR%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=f%3A%5Cmathcal%7BG%7D%5Crightarrow%5Cmathbb%7BR%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3A%5Cmathcal%7BG%7D%5Crightarrow%5Cmathbb%7BR%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"f:&#92;mathcal{G}&#92;rightarrow&#92;mathbb{R}\" class=\"latex\" /> which measures a candidate&#8217;s quality. The candidates, partitions, and quality function are known as &#8216;population&#8217;, &#8216;species&#8217;, and &#8216;fitness&#8217;, respectively.</p>\n<div data-shortcode=\"caption\" id=\"attachment_1198\" style=\"width: 367px\" class=\"wp-caption aligncenter\"><img loading=\"lazy\" aria-describedby=\"caption-attachment-1198\" data-attachment-id=\"1198\" data-permalink=\"https://wellecks.wordpress.com/2019/07/21/evolving-networks/objects/#main\" data-orig-file=\"https://wellecks.files.wordpress.com/2019/07/objects.png\" data-orig-size=\"312,91\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"objects\" data-image-description=\"\" data-image-caption=\"<p>The candidate set (&#8220;population&#8221;, rectangle) contains partitions (&#8220;species&#8221;, circles), each containing candidate graphs (&#8220;genomes&#8221;, diamonds).</p>\n\" data-medium-file=\"https://wellecks.files.wordpress.com/2019/07/objects.png?w=300\" data-large-file=\"https://wellecks.files.wordpress.com/2019/07/objects.png?w=312\" class=\"alignnone wp-image-1198\" src=\"https://wellecks.files.wordpress.com/2019/07/objects.png?w=357&#038;h=104\" alt=\"objects\" width=\"357\" height=\"104\" srcset=\"https://wellecks.files.wordpress.com/2019/07/objects.png 312w, https://wellecks.files.wordpress.com/2019/07/objects.png?w=150&h=44 150w, https://wellecks.files.wordpress.com/2019/07/objects.png?w=300&h=88 300w\" sizes=\"(max-width: 357px) 100vw, 357px\" /><p id=\"caption-attachment-1198\" class=\"wp-caption-text\">The candidate set (&#8220;population&#8221;, rectangle) contains partitions (&#8220;species&#8221;, circles), each containing candidate graphs (diamonds).</p></div>\n<p>Each NEAT iteration returns a new candidate set and new partitioning, denoted as <img src=\"https://s0.wp.com/latex.php?latex=E%28P%5E%7B%28i%29%7D%2C+S%5E%7B%28i%29%7D%2C+f%29%5Crightarrow+P%5E%7B%28i%2B1%29%7D%2CS%5E%7B%28i%2B1%29%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=E%28P%5E%7B%28i%29%7D%2C+S%5E%7B%28i%29%7D%2C+f%29%5Crightarrow+P%5E%7B%28i%2B1%29%7D%2CS%5E%7B%28i%2B1%29%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=E%28P%5E%7B%28i%29%7D%2C+S%5E%7B%28i%29%7D%2C+f%29%5Crightarrow+P%5E%7B%28i%2B1%29%7D%2CS%5E%7B%28i%2B1%29%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"E(P^{(i)}, S^{(i)}, f)&#92;rightarrow P^{(i+1)},S^{(i+1)}\" class=\"latex\" />. Intuitively E is an &#8216;evolution step&#8217; that produces a new &#8216;generation&#8217;. NEAT&#8217;s goal is to eventually output a &#8216;good&#8217; candidate set <img src=\"https://s0.wp.com/latex.php?latex=P%5E%7B%28i%29%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=P%5E%7B%28i%29%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=P%5E%7B%28i%29%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"P^{(i)}\" class=\"latex\" />. Typically <em>good</em> means that the best candidate has quality exceeding a goal threshold, <img src=\"https://s0.wp.com/latex.php?latex=%5Cmax_j+f%28G%5E%7B%28i%29%7D_j%29+%3E+%5Ctau&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Cmax_j+f%28G%5E%7B%28i%29%7D_j%29+%3E+%5Ctau&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmax_j+f%28G%5E%7B%28i%29%7D_j%29+%3E+%5Ctau&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;max_j f(G^{(i)}_j) > &#92;tau\" class=\"latex\" />. We then use this high-performing neural network on a task.</p>\n<h3>Evolution Steps</h3>\n<p>Each evolution step <img src=\"https://s0.wp.com/latex.php?latex=E%28P%5E%7B%28i%29%7D%2C+S%5E%7B%28i%29%7D%2C+f%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=E%28P%5E%7B%28i%29%7D%2C+S%5E%7B%28i%29%7D%2C+f%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=E%28P%5E%7B%28i%29%7D%2C+S%5E%7B%28i%29%7D%2C+f%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"E(P^{(i)}, S^{(i)}, f)\" class=\"latex\" /> produces a new population using four ideas: mutation, crossover, fitness ranking, and partitioning.</p>\n<p><strong>Mutation</strong> <img src=\"https://s0.wp.com/latex.php?latex=m%28G%29%5Crightarrow+G&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=m%28G%29%5Crightarrow+G&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=m%28G%29%5Crightarrow+G&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"m(G)&#92;rightarrow G\" class=\"latex\" /> randomly perturbs a candidate graph. In NEAT, mutations consist of adding or deleting a node, adding or deleting an edge, or perturbing a node or edge property (such as an edge&#8217;s weight or a node&#8217;s activation). Each mutation type occurs with a pre-specified probability, and involves a random perturbation; for instance an add-edge randomly chooses an edge location and weights are adjusted with Gaussian noise. One can design other mutations, such as resetting a weight to a new value.</p>\n<div data-shortcode=\"caption\" id=\"attachment_1194\" style=\"width: 402px\" class=\"wp-caption aligncenter\"><img aria-describedby=\"caption-attachment-1194\" data-attachment-id=\"1194\" data-permalink=\"https://wellecks.wordpress.com/2019/07/21/evolving-networks/mutation/#main\" data-orig-file=\"https://wellecks.files.wordpress.com/2019/07/mutation.png\" data-orig-size=\"392,131\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"mutation\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://wellecks.files.wordpress.com/2019/07/mutation.png?w=300\" data-large-file=\"https://wellecks.files.wordpress.com/2019/07/mutation.png?w=392\" class=\"aligncenter size-full wp-image-1194\" src=\"https://wellecks.files.wordpress.com/2019/07/mutation.png?w=525\" alt=\"mutation\" srcset=\"https://wellecks.files.wordpress.com/2019/07/mutation.png 392w, https://wellecks.files.wordpress.com/2019/07/mutation.png?w=150 150w, https://wellecks.files.wordpress.com/2019/07/mutation.png?w=300 300w\" sizes=\"(max-width: 392px) 100vw, 392px\"   /><p id=\"caption-attachment-1194\" class=\"wp-caption-text\">An add-node mutation followed by an add-edge mutation. The add-node mutation splits an existing edge into two edges.</p></div>\n<p style=\"text-align:left;\"><strong>Crossover</strong> <img src=\"https://s0.wp.com/latex.php?latex=c%28G_i%2CG_j%29%5Crightarrow+G&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=c%28G_i%2CG_j%29%5Crightarrow+G&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c%28G_i%2CG_j%29%5Crightarrow+G&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"c(G_i,G_j)&#92;rightarrow G\" class=\"latex\" /> produces a new candidate by swapping properties of two existing candidates. In NEAT, roughly speaking if <img src=\"https://s0.wp.com/latex.php?latex=G_i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=G_i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=G_i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"G_i\" class=\"latex\" /> and <img src=\"https://s0.wp.com/latex.php?latex=G_j&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=G_j&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=G_j&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"G_j\" class=\"latex\" /> have a matching node <img src=\"https://s0.wp.com/latex.php?latex=v_i%2C+v_j&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=v_i%2C+v_j&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=v_i%2C+v_j&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"v_i, v_j\" class=\"latex\" />, then <img src=\"https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"G\" class=\"latex\" /> receives one of them randomly (similarly for edges). <img src=\"https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"G\" class=\"latex\" /> simply inherits non-matching nodes or edges. The notion of &#8216;matching&#8217; is tricky due to isomorphic graph structures, so NEAT assigns an ID to each new node and edge, then uses these IDs for comparison (see 2.2 and 3.2 of the NEAT paper for details).  In part due to the added complexity, some papers leave out crossover completely.</p>\n<div data-shortcode=\"caption\" id=\"attachment_1195\" style=\"width: 381px\" class=\"wp-caption aligncenter\"><img loading=\"lazy\" aria-describedby=\"caption-attachment-1195\" data-attachment-id=\"1195\" data-permalink=\"https://wellecks.wordpress.com/2019/07/21/evolving-networks/crossover/#main\" data-orig-file=\"https://wellecks.files.wordpress.com/2019/07/crossover.png\" data-orig-size=\"820,806\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"crossover\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://wellecks.files.wordpress.com/2019/07/crossover.png?w=300\" data-large-file=\"https://wellecks.files.wordpress.com/2019/07/crossover.png?w=525\" class=\"alignnone wp-image-1195\" src=\"https://wellecks.files.wordpress.com/2019/07/crossover.png?w=371&#038;h=364\" alt=\"crossover\" width=\"371\" height=\"364\" srcset=\"https://wellecks.files.wordpress.com/2019/07/crossover.png?w=371&h=364 371w, https://wellecks.files.wordpress.com/2019/07/crossover.png?w=742&h=728 742w, https://wellecks.files.wordpress.com/2019/07/crossover.png?w=150&h=147 150w, https://wellecks.files.wordpress.com/2019/07/crossover.png?w=300&h=295 300w\" sizes=\"(max-width: 371px) 100vw, 371px\" /><p id=\"caption-attachment-1195\" class=\"wp-caption-text\">NEAT crossover mechanism (diagram from the <a href=\"http://nn.cs.utexas.edu/downloads/papers/stanley.ec02.pdf\">NEAT paper</a>)</p></div>\n<p><strong>Fitness Ranking</strong> follows its name, first ranking candidates according to fitness, <img src=\"https://s0.wp.com/latex.php?latex=%28G_%7B1%27%7D%2C%5Cldots%2CG_%7BN%27%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%28G_%7B1%27%7D%2C%5Cldots%2CG_%7BN%27%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28G_%7B1%27%7D%2C%5Cldots%2CG_%7BN%27%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"(G_{1&#039;},&#92;ldots,G_{N&#039;})\" class=\"latex\" /> where <img src=\"https://s0.wp.com/latex.php?latex=i%27%3Ej%27&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=i%27%3Ej%27&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i%27%3Ej%27&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"i&#039;>j&#039;\" class=\"latex\" /> means <img src=\"https://s0.wp.com/latex.php?latex=f%28G_%7Bi%27%7D%29%3Ef%28G_%7Bj%27%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=f%28G_%7Bi%27%7D%29%3Ef%28G_%7Bj%27%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%28G_%7Bi%27%7D%29%3Ef%28G_%7Bj%27%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"f(G_{i&#039;})>f(G_{j&#039;})\" class=\"latex\" />. Only the top (e.g. 20%) candidates are used for crossover and mutation. This locally biases the search towards candidates with high relative fitness.</p>\n<p><strong>Partitioning</strong>, or speciation, groups candidates according to a distance function <img src=\"https://s0.wp.com/latex.php?latex=d%28G_i%2CG_j%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=d%28G_i%2CG_j%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d%28G_i%2CG_j%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"d(G_i,G_j)\" class=\"latex\" />. One use of the partitions is to promote diversity in the solution space by modifying each candidate&#8217;s fitness. To do so, NEAT defines a distance function and adjusts each candidate&#8217;s fitness based on its partition size. Each partition is guaranteed a certain number of candidates in the next generation based on the adjusted fitnesses.</p>\n<p>Intuitively, a small partition contains graphs with relatively unique characteristics which might ultimately be useful in a final solution, even if they do not yield immediate fitness. To avoid erasing these characteristics from the search during fitness ranking, the small partition candidates receive guaranteed spots in the next phase.</p>\n<div data-shortcode=\"caption\" id=\"attachment_1197\" style=\"width: 1378px\" class=\"wp-caption alignnone\"><img aria-describedby=\"caption-attachment-1197\" data-attachment-id=\"1197\" data-permalink=\"https://wellecks.wordpress.com/2019/07/21/evolving-networks/partition-2/#main\" data-orig-file=\"https://wellecks.files.wordpress.com/2019/07/partition-1.jpg\" data-orig-size=\"1368,446\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"1\"}\" data-image-title=\"partition\" data-image-description=\"\" data-image-caption=\"<p>Novel structures (diamonds, triangles) may ultimately yield a performance gain after further development, despite initially having lower fitness (light green) compared to common structures with high fitness (dark green).</p>\n\" data-medium-file=\"https://wellecks.files.wordpress.com/2019/07/partition-1.jpg?w=300\" data-large-file=\"https://wellecks.files.wordpress.com/2019/07/partition-1.jpg?w=525\" class=\"alignnone size-full wp-image-1197\" src=\"https://wellecks.files.wordpress.com/2019/07/partition-1.jpg?w=525\" alt=\"partition\" srcset=\"https://wellecks.files.wordpress.com/2019/07/partition-1.jpg?w=525 525w, https://wellecks.files.wordpress.com/2019/07/partition-1.jpg?w=1050 1050w, https://wellecks.files.wordpress.com/2019/07/partition-1.jpg?w=150 150w, https://wellecks.files.wordpress.com/2019/07/partition-1.jpg?w=300 300w, https://wellecks.files.wordpress.com/2019/07/partition-1.jpg?w=768 768w, https://wellecks.files.wordpress.com/2019/07/partition-1.jpg?w=1024 1024w\" sizes=\"(max-width: 525px) 100vw, 525px\"   /><p id=\"caption-attachment-1197\" class=\"wp-caption-text\">Novel structures (diamonds, triangles) may ultimately yield a performance gain after further development, despite initially having lower fitness (light green) compared to common, developed structures with high fitness (dark green).</p></div>\n<p>We can write this step as <img src=\"https://s0.wp.com/latex.php?latex=f_%7B%5Ctext%7Bpartition%7D%7D%28P%2Cf_1%2C%5Cldots%2Cf_N%2CS%29%5Crightarrow+%28f_1%27%2C%5Cldots%2Cf_N%27%2C+S%27%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=f_%7B%5Ctext%7Bpartition%7D%7D%28P%2Cf_1%2C%5Cldots%2Cf_N%2CS%29%5Crightarrow+%28f_1%27%2C%5Cldots%2Cf_N%27%2C+S%27%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f_%7B%5Ctext%7Bpartition%7D%7D%28P%2Cf_1%2C%5Cldots%2Cf_N%2CS%29%5Crightarrow+%28f_1%27%2C%5Cldots%2Cf_N%27%2C+S%27%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"f_{&#92;text{partition}}(P,f_1,&#92;ldots,f_N,S)&#92;rightarrow (f_1&#039;,&#92;ldots,f_N&#039;, S&#039;)\" class=\"latex\" />. We might alternatively view this step as just fitness re-ranking, <img src=\"https://s0.wp.com/latex.php?latex=f_%7B%5Ctext%7Bre-rank%7D%7D%28P%2Cf_1%2C%5Cldots%2Cf_N%29%5Crightarrow+%28f_1%27%2C%5Cldots%2Cf_N%27%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=f_%7B%5Ctext%7Bre-rank%7D%7D%28P%2Cf_1%2C%5Cldots%2Cf_N%29%5Crightarrow+%28f_1%27%2C%5Cldots%2Cf_N%27%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f_%7B%5Ctext%7Bre-rank%7D%7D%28P%2Cf_1%2C%5Cldots%2Cf_N%29%5Crightarrow+%28f_1%27%2C%5Cldots%2Cf_N%27%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"f_{&#92;text{re-rank}}(P,f_1,&#92;ldots,f_N)&#92;rightarrow (f_1&#039;,&#92;ldots,f_N&#039;)\" class=\"latex\" />, without requiring actual partitions, though without partitions it may be tricky to achieve the exact &#8216;guaranteed spots&#8217; behavior.</p>\n<p>The partitions <img src=\"https://s0.wp.com/latex.php?latex=S%27&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=S%27&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S%27&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"S&#039;\" class=\"latex\" /> could also be useful in problems requiring a <em>collection</em> of solutions rather than a single optimal solution. For instance, rather than just selecting the highest performing candidate, we might consider the <em>best candidate in each partition</em> as the final output of NEAT, thus producing a <em>collection</em> of networks, each maximizing fitness in a different way than the others (assuming a partitioning scheme that promotes diverse solutions).</p>\n<h3>Example Results</h3>\n<p>Let&#8217;s use the implementation [<a href=\"https://gist.github.com/wellecks/226dab0ff0dde625b097869fb932cff9\"><strong>code link</strong></a>] to solve an xor problem and the Cartpole and Lunar-Lander gym environments.</p>\n<p style=\"text-align:left;\">To solve <strong>xor</strong>, NEAT finds a network with a single hidden node:</p>\n<div data-shortcode=\"caption\" id=\"attachment_1207\" style=\"width: 559px\" class=\"wp-caption aligncenter\"><img loading=\"lazy\" aria-describedby=\"caption-attachment-1207\" data-attachment-id=\"1207\" data-permalink=\"https://wellecks.wordpress.com/2019/07/21/evolving-networks/xor-2/#main\" data-orig-file=\"https://wellecks.files.wordpress.com/2019/07/xor-1.png\" data-orig-size=\"1280,960\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"xor\" data-image-description=\"\" data-image-caption=\"<p>An xor network, including input (green), hidden (blue), and output (red) nodes. Labels show edge weights, node biases, and node activations. </p>\n\" data-medium-file=\"https://wellecks.files.wordpress.com/2019/07/xor-1.png?w=300\" data-large-file=\"https://wellecks.files.wordpress.com/2019/07/xor-1.png?w=525\" class=\"alignnone wp-image-1207\" src=\"https://wellecks.files.wordpress.com/2019/07/xor-1.png?w=549&#038;h=412\" alt=\"xor\" width=\"549\" height=\"412\" srcset=\"https://wellecks.files.wordpress.com/2019/07/xor-1.png?w=549&h=412 549w, https://wellecks.files.wordpress.com/2019/07/xor-1.png?w=1098&h=824 1098w, https://wellecks.files.wordpress.com/2019/07/xor-1.png?w=150&h=113 150w, https://wellecks.files.wordpress.com/2019/07/xor-1.png?w=300&h=225 300w, https://wellecks.files.wordpress.com/2019/07/xor-1.png?w=768&h=576 768w, https://wellecks.files.wordpress.com/2019/07/xor-1.png?w=1024&h=768 1024w\" sizes=\"(max-width: 549px) 100vw, 549px\" /><p id=\"caption-attachment-1207\" class=\"wp-caption-text\">An xor network, including input (green), hidden (blue), and output (red) nodes. Labels show edge weights and node activations.</p></div>\n<p><strong>CartPole-v0</strong> is easy to solve (<a href=\"http://kvfrans.com/simple-algoritms-for-solving-cartpole/\">even random search is sufficient</a>), and NEAT finds a simple network without hidden units (for fun we&#8217;ll also construct an artificially complicated solution in the <strong>Variations</strong> section below):</p>\n<p>&nbsp;</p>\n<div data-shortcode=\"caption\" id=\"attachment_1206\" style=\"width: 514px\" class=\"wp-caption aligncenter\"><img loading=\"lazy\" aria-describedby=\"caption-attachment-1206\" data-attachment-id=\"1206\" data-permalink=\"https://wellecks.wordpress.com/2019/07/21/evolving-networks/cartpole-2/#main\" data-orig-file=\"https://wellecks.files.wordpress.com/2019/07/cartpole-1.png\" data-orig-size=\"1280,960\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"cartpole\" data-image-description=\"\" data-image-caption=\"<p>CartPole-v0 network.</p>\n\" data-medium-file=\"https://wellecks.files.wordpress.com/2019/07/cartpole-1.png?w=300\" data-large-file=\"https://wellecks.files.wordpress.com/2019/07/cartpole-1.png?w=525\" class=\"alignnone wp-image-1206\" src=\"https://wellecks.files.wordpress.com/2019/07/cartpole-1.png?w=504&#038;h=378\" alt=\"cartpole\" width=\"504\" height=\"378\" srcset=\"https://wellecks.files.wordpress.com/2019/07/cartpole-1.png?w=504&h=378 504w, https://wellecks.files.wordpress.com/2019/07/cartpole-1.png?w=1008&h=756 1008w, https://wellecks.files.wordpress.com/2019/07/cartpole-1.png?w=150&h=113 150w, https://wellecks.files.wordpress.com/2019/07/cartpole-1.png?w=300&h=225 300w, https://wellecks.files.wordpress.com/2019/07/cartpole-1.png?w=768&h=576 768w\" sizes=\"(max-width: 504px) 100vw, 504px\" /><p id=\"caption-attachment-1206\" class=\"wp-caption-text\">A CartPole-v0 network.</p></div>\n<p><strong>LunarLander-v2</strong> is more difficult, and NEAT finds a network with non-trivial structure:</p>\n<div data-shortcode=\"caption\" id=\"attachment_1205\" style=\"width: 1290px\" class=\"wp-caption alignnone\"><img aria-describedby=\"caption-attachment-1205\" data-attachment-id=\"1205\" data-permalink=\"https://wellecks.wordpress.com/2019/07/21/evolving-networks/lunar-2/#main\" data-orig-file=\"https://wellecks.files.wordpress.com/2019/07/lunar-1.png\" data-orig-size=\"1280,960\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"lunar\" data-image-description=\"\" data-image-caption=\"<p>LunarLander-v2 network. Input nodes are green, output nodes are red. Biases are not shown due to clutter.</p>\n\" data-medium-file=\"https://wellecks.files.wordpress.com/2019/07/lunar-1.png?w=300\" data-large-file=\"https://wellecks.files.wordpress.com/2019/07/lunar-1.png?w=525\" class=\"alignnone size-full wp-image-1205\" src=\"https://wellecks.files.wordpress.com/2019/07/lunar-1.png?w=525\" alt=\"lunar\" srcset=\"https://wellecks.files.wordpress.com/2019/07/lunar-1.png?w=525 525w, https://wellecks.files.wordpress.com/2019/07/lunar-1.png?w=1050 1050w, https://wellecks.files.wordpress.com/2019/07/lunar-1.png?w=150 150w, https://wellecks.files.wordpress.com/2019/07/lunar-1.png?w=300 300w, https://wellecks.files.wordpress.com/2019/07/lunar-1.png?w=768 768w, https://wellecks.files.wordpress.com/2019/07/lunar-1.png?w=1024 1024w\" sizes=\"(max-width: 525px) 100vw, 525px\"   /><p id=\"caption-attachment-1205\" class=\"wp-caption-text\">A LunarLander-v2 network.</p></div>\n<p>On the xor environment, NEAT creates around 10 partitions, on Cartpole just 1, and on LunarLander it tends to create 2-3 partitions. On these simple environments NEAT also performs similarly <em>without crossover</em>.</p>\n<p><strong>Variations</strong> As mentioned before, we may want NEAT to produce a <em>diverse set</em> of solutions rather than a single solution. To manually demonstrate this intuition, suppose I want NEAT to find a network that uses sigmoid activations, and one that uses tanh. To do so, I increased the activation parameter in the node distance function (the <img src=\"https://s0.wp.com/latex.php?latex=d%28%5Ccdot%2C%5Ccdot%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=d%28%5Ccdot%2C%5Ccdot%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d%28%5Ccdot%2C%5Ccdot%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"d(&#92;cdot,&#92;cdot)\" class=\"latex\" /> used in partitioning), then chose the highest scoring network from each partition. On Cartpole, the partitions now naturally separate into sigmoid and tanh networks:</p>\n\n<a href='https://wellecks.wordpress.com/2019/07/21/evolving-networks/sigmoid/#main'><img width=\"150\" height=\"113\" src=\"https://wellecks.files.wordpress.com/2019/07/sigmoid.png?w=150&#038;h=113\" class=\"attachment-thumbnail size-thumbnail\" alt=\"\" loading=\"lazy\" srcset=\"https://wellecks.files.wordpress.com/2019/07/sigmoid.png?w=150 150w, https://wellecks.files.wordpress.com/2019/07/sigmoid.png?w=300 300w\" sizes=\"(max-width: 150px) 100vw, 150px\" data-attachment-id=\"1199\" data-permalink=\"https://wellecks.wordpress.com/2019/07/21/evolving-networks/sigmoid/#main\" data-orig-file=\"https://wellecks.files.wordpress.com/2019/07/sigmoid.png\" data-orig-size=\"1280,960\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"sigmoid\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://wellecks.files.wordpress.com/2019/07/sigmoid.png?w=300\" data-large-file=\"https://wellecks.files.wordpress.com/2019/07/sigmoid.png?w=525\" /></a>\n<a href='https://wellecks.wordpress.com/2019/07/21/evolving-networks/tanh/#main'><img width=\"150\" height=\"113\" src=\"https://wellecks.files.wordpress.com/2019/07/tanh.png?w=150&#038;h=113\" class=\"attachment-thumbnail size-thumbnail\" alt=\"\" loading=\"lazy\" srcset=\"https://wellecks.files.wordpress.com/2019/07/tanh.png?w=150 150w, https://wellecks.files.wordpress.com/2019/07/tanh.png?w=300 300w\" sizes=\"(max-width: 150px) 100vw, 150px\" data-attachment-id=\"1200\" data-permalink=\"https://wellecks.wordpress.com/2019/07/21/evolving-networks/tanh/#main\" data-orig-file=\"https://wellecks.files.wordpress.com/2019/07/tanh.png\" data-orig-size=\"1280,960\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"tanh\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://wellecks.files.wordpress.com/2019/07/tanh.png?w=300\" data-large-file=\"https://wellecks.files.wordpress.com/2019/07/tanh.png?w=525\" /></a>\n\n<p>While Cartpole is evidently simple enough for a network with no hidden layers, perhaps we want to follow a trend of using large networks even for easy problems. We can modify the fitness function to &#8216;reject&#8217; networks without a certain number of connections, and NEAT will yield more complicated solutions:</p>\n<div data-shortcode=\"caption\" id=\"attachment_1201\" style=\"width: 2142px\" class=\"wp-caption alignnone\"><img aria-describedby=\"caption-attachment-1201\" data-attachment-id=\"1201\" data-permalink=\"https://wellecks.wordpress.com/2019/07/21/evolving-networks/complex20/#main\" data-orig-file=\"https://wellecks.files.wordpress.com/2019/07/complex20.png\" data-orig-size=\"2132,1546\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"complex20\" data-image-description=\"\" data-image-caption=\"<p>A more complicated way to play Cartpole.</p>\n\" data-medium-file=\"https://wellecks.files.wordpress.com/2019/07/complex20.png?w=300\" data-large-file=\"https://wellecks.files.wordpress.com/2019/07/complex20.png?w=525\" class=\"alignnone size-full wp-image-1201\" src=\"https://wellecks.files.wordpress.com/2019/07/complex20.png?w=525\" alt=\"complex20\" srcset=\"https://wellecks.files.wordpress.com/2019/07/complex20.png?w=525 525w, https://wellecks.files.wordpress.com/2019/07/complex20.png?w=1050 1050w, https://wellecks.files.wordpress.com/2019/07/complex20.png?w=150 150w, https://wellecks.files.wordpress.com/2019/07/complex20.png?w=300 300w, https://wellecks.files.wordpress.com/2019/07/complex20.png?w=768 768w, https://wellecks.files.wordpress.com/2019/07/complex20.png?w=1024 1024w\" sizes=\"(max-width: 525px) 100vw, 525px\"   /><p id=\"caption-attachment-1201\" class=\"wp-caption-text\">A more complicated way to play Cartpole.</p></div>\n<p>In particular, I added -1000 to the fitness when the network had less than <em>k</em> connections, starting with <em>k=5</em> and incrementing <em>k</em> each time a candidate achieved max fitness at the current <em>k </em>(stopping at k=20).</p>\n<h2>Discussion & Extensions</h2>\n<p>Vanilla NEAT attempts to find both a network structure and the corresponding weights from scratch. This approach is very flexible and involves minimal assumptions, but could limit NEAT to problems requiring small networks. However, the key idea can still be applied or modified in creative ways.</p>\n<h3>Minimal Assumptions</h3>\n<p>NEAT represents an extreme on the spectrum of learned versus hand-crafted architectural biases, by placing few assumptions on graph structure or learning algorithm. At a very speculative level, such flexibility may be useful for networks with <a href=\"https://www.sciencedirect.com/science/article/pii/S1053811908013050?via%3Dihub\">backward or long-range</a> <a href=\"https://www.frontiersin.org/articles/10.3389/fnhum.2015.00253/full\">connections</a> that may be difficult to hand design, or as part of a learning <a href=\"https://www.sciencedirect.com/science/article/abs/pii/S0940960211802554\">process</a> <a href=\"https://www.sciencedirect.com/science/article/pii/S0896627311009184\">which involves</a> <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5649212/pdf/fpsyg-08-01657.pdf\">removing or adding connections</a> rather than optimizing weights of a fixed architecture.</p>\n<p>A more concrete example is the recent Weight Agnostic Neural Networks paper (<a href=\"https://weightagnostic.github.io/\">Gaier & Ha 2019</a>), where the authors aimed to find a model for a task by <em>finding good network structures</em>, rather than finding good weights for a fixed network structure; they use a <em>single shared weight value</em> in each network and evaluate fitness on multiple rollouts, with a randomly selected weight value for each rollout. In this case, a NEAT variant allowed finding exotic network structures from scratch, without requiring prior knowledge such as hand-designed layer types.</p>\n<p class=\"p1\">As a rough approximation, I modified the NEAT implementation so that each network only has a single shared weight value, and included more activation functions (sin, cos, arctan, abs, floor). Each run of evaluation sets the network&#8217;s shared weight to a randomly sampled value (<img src=\"https://s0.wp.com/latex.php?latex=%5Cmathcal%7BU%7D%28%5B-2%2C2%5D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5Cmathcal%7BU%7D%28%5B-2%2C2%5D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathcal%7BU%7D%28%5B-2%2C2%5D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"&#92;mathcal{U}([-2,2])\" class=\"latex\" /> excluding <img src=\"https://s0.wp.com/latex.php?latex=%5B-0.1%2C0.1%5D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=%5B-0.1%2C0.1%5D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5B-0.1%2C0.1%5D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"[-0.1,0.1]\" class=\"latex\" />), and the network&#8217;s overall fitness is the average fitness over 10 runs. On XOR, NEAT finds a network with similar structure as before:</p>\n<div data-shortcode=\"caption\" id=\"attachment_1218\" style=\"width: 455px\" class=\"wp-caption aligncenter\"><img loading=\"lazy\" aria-describedby=\"caption-attachment-1218\" data-attachment-id=\"1218\" data-permalink=\"https://wellecks.wordpress.com/2019/07/21/evolving-networks/screen-shot-2019-07-21-at-3-56-44-pm/#main\" data-orig-file=\"https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-21-at-3.56.44-pm.png\" data-orig-size=\"1234,930\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"xor_shared\" data-image-description=\"\" data-image-caption=\"<p>XOR network with random shared weight value</p>\n\" data-medium-file=\"https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-21-at-3.56.44-pm.png?w=300\" data-large-file=\"https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-21-at-3.56.44-pm.png?w=525\" class=\"alignnone  wp-image-1218\" src=\"https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-21-at-3.56.44-pm.png?w=445&#038;h=335\" alt=\"xor_shared\" width=\"445\" height=\"335\" srcset=\"https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-21-at-3.56.44-pm.png?w=445&h=335 445w, https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-21-at-3.56.44-pm.png?w=890&h=670 890w, https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-21-at-3.56.44-pm.png?w=150&h=113 150w, https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-21-at-3.56.44-pm.png?w=300&h=226 300w, https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-21-at-3.56.44-pm.png?w=768&h=579 768w\" sizes=\"(max-width: 445px) 100vw, 445px\" /><p id=\"caption-attachment-1218\" class=\"wp-caption-text\">XOR network with a random shared weight value</p></div>\n<p class=\"p1\">This was just an initial experiment to give intuition, so check out the <a href=\"https://weightagnostic.github.io/\"><span class=\"s1\">WANN paper</span></a> for a good way of doing this for non-trivial tasks.</p>\n<h3>Scalability</h3>\n<p>One could also consider improving NEAT&#8217;s scalability. A high level strategy is to reduce the search space by restricting the search to topologies, searching at a higher abstraction level, or introducing hierarchy.</p>\n<p>An example is DeepNEAT (<a href=\"https://arxiv.org/pdf/1703.00548.pdf\">Miikkulainen et al 2017</a>), which evolves graph structures using NEAT, but with nodes representing <em>layers</em> rather than single neurons, and edges specifying layer connectivity. Weight and bias values are learned with back-propagation. The authors further extend DeepNEAT to CoDeepNEAT, which represents graphs with a two level hierarchy defined by a <em>blueprint</em> specifying connectivity of <em>modules</em>. Separate blueprint and module populations are evolved, with the full graph (module + blueprint) assembled for fitness evaluation.</p>\n<div data-shortcode=\"caption\" id=\"attachment_1208\" style=\"width: 2610px\" class=\"wp-caption alignnone\"><img aria-describedby=\"caption-attachment-1208\" data-attachment-id=\"1208\" data-permalink=\"https://wellecks.wordpress.com/2019/07/21/evolving-networks/codeepneat/#main\" data-orig-file=\"https://wellecks.files.wordpress.com/2019/07/codeepneat.png\" data-orig-size=\"2600,2072\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"\" data-image-description=\"\" data-image-caption=\"<p>Blueprint and Module populations. Each node in a Blueprint (hexagon) is a Module.</p>\n\" data-medium-file=\"https://wellecks.files.wordpress.com/2019/07/codeepneat.png?w=300\" data-large-file=\"https://wellecks.files.wordpress.com/2019/07/codeepneat.png?w=525\" class=\"alignnone size-full wp-image-1208\" src=\"https://wellecks.files.wordpress.com/2019/07/codeepneat.png?w=525\" alt=\"\" srcset=\"https://wellecks.files.wordpress.com/2019/07/codeepneat.png?w=525 525w, https://wellecks.files.wordpress.com/2019/07/codeepneat.png?w=1050 1050w, https://wellecks.files.wordpress.com/2019/07/codeepneat.png?w=150 150w, https://wellecks.files.wordpress.com/2019/07/codeepneat.png?w=300 300w, https://wellecks.files.wordpress.com/2019/07/codeepneat.png?w=768 768w, https://wellecks.files.wordpress.com/2019/07/codeepneat.png?w=1024 1024w\" sizes=\"(max-width: 525px) 100vw, 525px\"   /><p id=\"caption-attachment-1208\" class=\"wp-caption-text\">Blueprint and Module populations. Each node in a Blueprint (hexagon) is a Module.</p></div>\n<p>This view is quite general, allowing learning the internal structure of reusable modules as well as how they are composed. In the experiments the authors begin with modules involving known components such as convolutional layers or LSTM cells and evolve only specific parts (e.g. connections between LSTM layers), but one might imagine searching for completely novel, reusable modules.</p>\n<h3>Indirect Encodings</h3>\n<p>NEAT essentially writes down a description, or <em>direct encoding</em>, of every node and edge and their properties, then evolves these descriptions. The description size grows as the network grows, making the search space prohibitively large.</p>\n<p>An alternative is to <span style=\"font-style:italic;\">use a function to describe a network</span>. For instance, we can evaluate a function <img src=\"https://s0.wp.com/latex.php?latex=f%3A%5Cmathbb%7BR%7D%5E4%5Crightarrow+%5Cmathbb%7BR%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=f%3A%5Cmathbb%7BR%7D%5E4%5Crightarrow+%5Cmathbb%7BR%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3A%5Cmathbb%7BR%7D%5E4%5Crightarrow+%5Cmathbb%7BR%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"f:&#92;mathbb{R}^4&#92;rightarrow &#92;mathbb{R}\" class=\"latex\" /> at pairs of points from a <img src=\"https://s0.wp.com/latex.php?latex=V%5Ctimes+V&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=V%5Ctimes+V&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=V%5Ctimes+V&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"V&#92;times V\" class=\"latex\" /> grid to obtain a weighted adjacency matrix. This function is an example of an <span style=\"font-style:italic;\">indirect encoding </span>of the graph. Assuming the description of <img src=\"https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"f\" class=\"latex\" /> is small, we can describe very large networks by evaluating a suitable <img src=\"https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"f\" class=\"latex\" /> using a large grid or coordinate pattern. A neural network with a variety of activations that is evaluated in this manner is called a <a href=\"http://eplex.cs.ucf.edu/papers/stanley_gpem07.pdf\">compositional pattern producing network</a> (CPPN) [<a href=\"http://blog.otoro.net/2016/03/25/generating-abstract-patterns-with-tensorflow/\">see</a>,<a href=\"https://distill.pub/2018/differentiable-parameterizations/?spm=a2c4e.11153940.blogcont683655.53.1e195250rLB3BI&utm_source=mybridge&utm_medium=blog&utm_campaign=read_more#section-xy2rgb\"> also</a>].</p>\n<p><a href=\"http://axon.cs.byu.edu/~dan/778/papers/NeuroEvolution/stanley3**.pdf\">HyperNEAT (Stanley et al. 2009)</a> uses this idea to find network weights by <span style=\"font-style:italic;\">evolving an indirect encoding function</span>. HyperNEAT uses NEAT to evolve a (small) CPPN to act as <img src=\"https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"f\" class=\"latex\" />, then evaluates <img src=\"https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"f\" class=\"latex\" /> at coordinates from a hyper-cube, resulting in weights of a (larger) network used for fitness evaluation.</p>\n<p>Several works have adopted or extended ideas from HyperNEAT for a deep learning setting. <a href=\"https://arxiv.org/pdf/1606.02580.pdf\">Fernando et al. 2016</a> proposed the Differentiable Pattern Producing Network (DPPN) which evolves the structure of a weight-generating CPPN <img src=\"https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"f\" class=\"latex\" /> while using back-propagation for its weights. The authors evolve a 200 parameter <img src=\"https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"f\" class=\"latex\" /> that generates weights for a fully connected auto-encoder with ~150,000 weights, though it is for a small-scale MNIST image de-noising task. Interestingly the weight generating function <img src=\"https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002\" srcset=\"https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x\" alt=\"f\" class=\"latex\" /> learns to produce convolution-esque filters embedded in the fully connected network.</p>\n<p><div data-shortcode=\"caption\" id=\"attachment_1211\" style=\"width: 2814px\" class=\"wp-caption alignnone\"><img aria-describedby=\"caption-attachment-1211\" data-attachment-id=\"1211\" data-permalink=\"https://wellecks.wordpress.com/2019/07/21/evolving-networks/screen-shot-2019-07-20-at-4-48-49-pm/#main\" data-orig-file=\"https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-20-at-4.48.49-pm.png\" data-orig-size=\"2804,1402\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"Screen Shot 2019-07-20 at 4.48.49 PM\" data-image-description=\"\" data-image-caption=\"<p>From [Fernando et al 2016]</p>\n\" data-medium-file=\"https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-20-at-4.48.49-pm.png?w=300\" data-large-file=\"https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-20-at-4.48.49-pm.png?w=525\" class=\"alignnone size-full wp-image-1211\" src=\"https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-20-at-4.48.49-pm.png?w=525\" alt=\"Screen Shot 2019-07-20 at 4.48.49 PM\" srcset=\"https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-20-at-4.48.49-pm.png?w=525 525w, https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-20-at-4.48.49-pm.png?w=1050 1050w, https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-20-at-4.48.49-pm.png?w=150 150w, https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-20-at-4.48.49-pm.png?w=300 300w, https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-20-at-4.48.49-pm.png?w=768 768w, https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-20-at-4.48.49-pm.png?w=1024 1024w\" sizes=\"(max-width: 525px) 100vw, 525px\"   /><p id=\"caption-attachment-1211\" class=\"wp-caption-text\">From [Fernando et al 2016]</p></div><a href=\"https://arxiv.org/pdf/1609.09106.pdf\">HyperNetworks (Ha et al 2016)</a> further scales HyperNEAT&#8217;s notion of indirect encodings to more complex tasks by learning a weight generation function with end-to-end training, including an extension that can generate time-varying weights for recurrent networks:</p>\n<div data-shortcode=\"caption\" id=\"attachment_1212\" style=\"width: 3198px\" class=\"wp-caption alignnone\"><img aria-describedby=\"caption-attachment-1212\" data-attachment-id=\"1212\" data-permalink=\"https://wellecks.wordpress.com/2019/07/21/evolving-networks/screen-shot-2019-07-20-at-5-02-39-pm/#main\" data-orig-file=\"https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-20-at-5.02.39-pm.png\" data-orig-size=\"3188,1310\" data-comments-opened=\"1\" data-image-meta=\"{\"aperture\":\"0\",\"credit\":\"\",\"camera\":\"\",\"caption\":\"\",\"created_timestamp\":\"0\",\"copyright\":\"\",\"focal_length\":\"0\",\"iso\":\"0\",\"shutter_speed\":\"0\",\"title\":\"\",\"orientation\":\"0\"}\" data-image-title=\"Screen Shot 2019-07-20 at 5.02.39 PM\" data-image-description=\"\" data-image-caption=\"<p>From [Ha et al. 2016]</p>\n\" data-medium-file=\"https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-20-at-5.02.39-pm.png?w=300\" data-large-file=\"https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-20-at-5.02.39-pm.png?w=525\" class=\"alignnone size-full wp-image-1212\" src=\"https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-20-at-5.02.39-pm.png?w=525\" alt=\"Screen Shot 2019-07-20 at 5.02.39 PM\" srcset=\"https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-20-at-5.02.39-pm.png?w=525 525w, https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-20-at-5.02.39-pm.png?w=1050 1050w, https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-20-at-5.02.39-pm.png?w=150 150w, https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-20-at-5.02.39-pm.png?w=300 300w, https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-20-at-5.02.39-pm.png?w=768 768w, https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-20-at-5.02.39-pm.png?w=1024 1024w\" sizes=\"(max-width: 525px) 100vw, 525px\"   /><p id=\"caption-attachment-1212\" class=\"wp-caption-text\">From [Ha et al. 2016]</p></div>\n<h3>Wrapping Up</h3>\n<p>In this post we revisited a core technique for generating neural network topologies, and briefly traced some of its outgoing research paths. We took a brief step back from the constraints of pre-defined-layer architectures and searched through a space of very general (albeit small-scale) topologies. It was interesting to see how this generality has been refined towards some <a href=\"https://arxiv.org/pdf/1703.01041.pdf\">larger scale</a> tasks, but also <a href=\"https://weightagnostic.github.io/\">revisited</a>.  We briefly saw how fitness re-ranking and partitioning can be used to yield <em>a set of distinct solutions, </em>which connects to <a href=\"https://arxiv.org/pdf/1504.04909.pdf\">other</a> <a href=\"http://eplex.cs.ucf.edu/papers/lehman_ecj11.pdf\">concepts</a> that I may discuss further in future posts.</p>\n<p style=\"text-align:center;\">[<a href=\"https://gist.github.com/wellecks/226dab0ff0dde625b097869fb932cff9\">Code</a>]</p>\n<h2>Further Reading</h2>\n<ul>\n<li><a href=\"http://www.evolvingai.org/files/s42256-018-0006-z.pdf\">Designing Neural Networks through Neuroevolution</a></li>\n<li><a href=\"https://link.springer.com/article/10.1007/s00521-019-04160-6\">On the automated, evolutionary design of neural networks: past, present, and future</a></li>\n</ul>\n<p><span id=\"more-1190\"></span></p>\n",
  "wfw:commentRss": "https://wellecks.wordpress.com/2019/07/21/evolving-networks/feed/",
  "slash:comments": 0,
  "media:content": [
    {
      "media:title": "wellecks"
    },
    {
      "media:title": "objects"
    },
    {
      "media:title": "mutation"
    },
    {
      "media:title": "crossover"
    },
    {
      "media:title": "partition"
    },
    {
      "media:title": "xor"
    },
    {
      "media:title": "cartpole"
    },
    {
      "media:title": "lunar"
    },
    "",
    "",
    {
      "media:title": "complex20"
    },
    {
      "media:title": "xor_shared"
    },
    "",
    {
      "media:title": "Screen Shot 2019-07-20 at 4.48.49 PM"
    },
    {
      "media:title": "Screen Shot 2019-07-20 at 5.02.39 PM"
    }
  ]
}