{
  "title": "TSrepr - Time Series Representations in R",
  "description": "<p>I’m happy to announce a new package that has recently appeared on CRAN, called “<strong>TSrepr</strong>” (version 1.0.0: <a href=\"https://CRAN.R-project.org/package=TSrepr\">https://CRAN.R-project.org/package=TSrepr</a>).</p>\n\n<p>The <strong>TSrepr</strong> package contains methods of time series representations (dimensionality reduction, feature extraction or preprocessing) and several other useful helper methods and functions.</p>\n\n<p>Time series representation can be defined as follows:</p>\n\n<p>Let \\( x \\) be a time series of length \\( n \\), then representation of \\( x \\) is a model \\( \\hat{x} \\) with reduced dimensionality \\( p \\) \\( (p &lt; n) \\) such that \\( \\hat{x} \\) approximates closely \\( x \\) (Esling and Agon (2012)).</p>\n\n<p>Time series representations are used for:</p>\n\n<ul>\n  <li>significant reduction of the time series dimensionality</li>\n  <li>emphasis on fundamental (essential) shape characteristics</li>\n  <li>implicit noise handling</li>\n  <li>reducing the dimension will reduce memory requirements and computational complexity of consequent machine learning methods.</li>\n</ul>\n\n<p>Therefore, they are awesome!</p>\n\n<p>Time series representation methods can be divided into four groups (types) (Ratanamahatana et al. (2005)):</p>\n\n<ul>\n  <li>nondata adaptive</li>\n  <li>data adaptive</li>\n  <li>model-based</li>\n  <li>data dictated (clipped data).</li>\n</ul>\n\n<p>In <strong>nondata adaptive</strong> representations, the parameters of transformation remain the same for all time series, irrespective of their nature.\nIn <strong>data adaptive</strong> representations, the parameters of transformation vary depending on the available data.\nAn approach to the <strong>model-based</strong> representation relies on the assumption that the observed time series was created based on basic model. The aim is to find the parameters of such a model as a representation. Two time series are then considered as similar if they were created by the same set of parameters of a basic model.\nIn <strong>data dictated</strong> approaches, the compression ratio is defined automatically based on raw time series such as clipped (Aghabozorgi, Seyed Shirkhorshidi, and Ying Wah (2015)).</p>\n\n<p>Most famous (well known) methods for <strong>nondata adaptive</strong> type of representations are PAA (Piecewise Aggregate Approximation), DWT (Discrete Wavelet Transform), DFT (Discrete Fourier Transform), DCT (Discrete Cosine Transform) or PIP (Perceptually Important Points). For <strong>data adaptive</strong> type of representations, it is SAX (Symbolic Aggregate approXimation), PLA (Piecewise Linear Approximation) and SVD (Singular Value Decomposition).\nFor <strong>model-based</strong> representations it is ARMA, mean profiles or estimated regression coefficients from a statistical model (e.g. linear model).\nThe <strong>data dictated</strong> is the less known type of representation and the most famous method of this type is clipping (bit-level) representation (Bagnall et al. (2006)).</p>\n\n<h2 id=\"implemented-methods-and-functions\">Implemented methods and functions</h2>\n\n<p>In the <strong>TSrepr</strong> package, these time series representation methods are implemented (the function names are in brackets):</p>\n\n<ul>\n  <li>Nondata adaptive:\n    <ul>\n      <li>PAA - Piecewise Aggregate Approximation (<code class=\"language-plaintext highlighter-rouge\">repr_paa</code>)</li>\n      <li>DWT - Discrete Wavelet Transform (<code class=\"language-plaintext highlighter-rouge\">repr_dwt</code>)</li>\n      <li>DFT - Discrete Fourier Transform (<code class=\"language-plaintext highlighter-rouge\">repr_dft</code>)</li>\n      <li>DCT - Discrete Cosine Transform (<code class=\"language-plaintext highlighter-rouge\">repr_dct</code>)</li>\n      <li>SMA - Simple Moving Average (<code class=\"language-plaintext highlighter-rouge\">repr_sma</code>)</li>\n      <li>PIP - Perceptually Important Points (<code class=\"language-plaintext highlighter-rouge\">repr_pip</code>)</li>\n    </ul>\n  </li>\n  <li>Data adaptive:\n    <ul>\n      <li>SAX - Symbolic Aggregate Approximation (<code class=\"language-plaintext highlighter-rouge\">repr_sax</code>)</li>\n      <li>PLA - Piecewise Linear Approximation (<code class=\"language-plaintext highlighter-rouge\">repr_pla</code>)</li>\n    </ul>\n  </li>\n  <li>Model-based:\n    <ul>\n      <li>Mean seasonal profile - Average seasonal profile, Median seasonal profile, etc. (<code class=\"language-plaintext highlighter-rouge\">repr_seas_profile</code>)</li>\n      <li>Model-based seasonal representations based on linear (additive) model (LM, RLM, L1, GAM) (<code class=\"language-plaintext highlighter-rouge\">repr_lm</code>, <code class=\"language-plaintext highlighter-rouge\">repr_gam</code>)</li>\n      <li>Exponential smoothing seasonal coefficients (<code class=\"language-plaintext highlighter-rouge\">repr_exp</code>)</li>\n    </ul>\n  </li>\n  <li>Data dictated:\n    <ul>\n      <li>FeaClip - Feature extraction from clipping representation (<code class=\"language-plaintext highlighter-rouge\">repr_feaclip</code>, <code class=\"language-plaintext highlighter-rouge\">clipping</code>)</li>\n      <li>FeaTrend - Feature extraction from trending representation (<code class=\"language-plaintext highlighter-rouge\">repr_featrend</code>, <code class=\"language-plaintext highlighter-rouge\">trending</code>)</li>\n      <li>FeaClipTrend - Feature extraction from clipping and trending representation (<code class=\"language-plaintext highlighter-rouge\">repr_feacliptrend</code>)</li>\n    </ul>\n  </li>\n</ul>\n\n<p>Some additional useful functions are also implemented in the <strong>TSrepr</strong> package, such as:</p>\n\n<ul>\n  <li>Windowing (<code class=\"language-plaintext highlighter-rouge\">repr_windowing</code>) - applies to the above mentioned representations to every window of a time series</li>\n  <li>Matrix of representations (<code class=\"language-plaintext highlighter-rouge\">repr_matrix</code>) - applies to the above mentioned representations to every row of a matrix of time series</li>\n  <li>Normalisation functions - z-score (<code class=\"language-plaintext highlighter-rouge\">norm_z</code>), min-max (<code class=\"language-plaintext highlighter-rouge\">norm_min_max</code>)</li>\n  <li>Normalisation functions with output also of scaling parameters - z-score (<code class=\"language-plaintext highlighter-rouge\">norm_z_list</code>), min-max (<code class=\"language-plaintext highlighter-rouge\">norm_min_max_list</code>)</li>\n  <li>Denormalisation functions - z-score (<code class=\"language-plaintext highlighter-rouge\">denorm_z</code>), min-max (<code class=\"language-plaintext highlighter-rouge\">denorm_min_max</code>)</li>\n  <li>Forecasting accuracy measures - MAE, RMSE, MdAE, MAPE, sMAPE, MASE.</li>\n</ul>\n\n<h2 id=\"usage-of-the-tsrepr-package\">Usage of the TSrepr package</h2>\n\n<p>The <strong>TSrepr</strong> functions can be used very easily. The input is always a numeric vector (univariate time series) and additional arguments can occur in some methods.</p>\n\n<p>Let’s load the package and ggplot2 for visualizations:</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-r\" data-lang=\"r\"><span class=\"c1\"># install.packages(\"TSrepr\")</span><span class=\"w\">\n</span><span class=\"n\">library</span><span class=\"p\">(</span><span class=\"n\">TSrepr</span><span class=\"p\">)</span><span class=\"w\">\n</span><span class=\"n\">library</span><span class=\"p\">(</span><span class=\"n\">ggplot2</span><span class=\"p\">)</span></code></pre></figure>\n\n<p>Let’s load electricity consumption data (<code class=\"language-plaintext highlighter-rouge\">elec_load</code>) and use first time series from the dataset. There is 672 values, so 14 days of measurements.</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-r\" data-lang=\"r\"><span class=\"n\">data</span><span class=\"p\">(</span><span class=\"s2\">\"elec_load\"</span><span class=\"p\">)</span><span class=\"w\">\n \n</span><span class=\"n\">data_ts</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"nf\">as.numeric</span><span class=\"p\">(</span><span class=\"n\">elec_load</span><span class=\"p\">[</span><span class=\"m\">1</span><span class=\"p\">,])</span><span class=\"w\">\n \n</span><span class=\"n\">ggplot</span><span class=\"p\">(</span><span class=\"n\">data.frame</span><span class=\"p\">(</span><span class=\"n\">Time</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"m\">1</span><span class=\"o\">:</span><span class=\"nf\">length</span><span class=\"p\">(</span><span class=\"n\">data_ts</span><span class=\"p\">),</span><span class=\"w\"> </span><span class=\"n\">Value</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">data_ts</span><span class=\"p\">),</span><span class=\"w\"> </span><span class=\"n\">aes</span><span class=\"p\">(</span><span class=\"n\">Time</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">Value</span><span class=\"p\">))</span><span class=\"w\"> </span><span class=\"o\">+</span><span class=\"w\">\n  </span><span class=\"n\">geom_line</span><span class=\"p\">()</span><span class=\"w\"> </span><span class=\"o\">+</span><span class=\"w\">\n  </span><span class=\"n\">theme_bw</span><span class=\"p\">()</span></code></pre></figure>\n\n<p><img src=\"/images/post_7/unnamed-chunk-2-1.png\" alt=\"plot of chunk unnamed-chunk-2\" /></p>\n\n<p>Now, we want to for example reduce dimensionality and reduce the noise of our time series. We can of course, use the time series representations from the <strong>TSrepr</strong> package. We can compare multiple methods here that are suitable for this task (smoothing of highly noised time series), for example, <strong>PAA</strong>, <strong>DWT</strong>, <strong>DFT</strong> or <strong>DCT</strong>.\nWe will reduce dimensionality 8 times, so from 672 to 84.</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-r\" data-lang=\"r\"><span class=\"c1\"># DWT with level of 2^3</span><span class=\"w\">\n</span><span class=\"n\">data_dwt</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"n\">repr_dwt</span><span class=\"p\">(</span><span class=\"n\">data_ts</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">level</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"m\">3</span><span class=\"p\">)</span><span class=\"w\">\n</span><span class=\"c1\"># first 84 DFT coefficients are extracted and then inverted</span><span class=\"w\">\n</span><span class=\"n\">data_dft</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"n\">repr_dft</span><span class=\"p\">(</span><span class=\"n\">data_ts</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">coef</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"m\">84</span><span class=\"p\">)</span><span class=\"w\">\n</span><span class=\"c1\"># first 84 DCT coefficients are extracted and then inverted</span><span class=\"w\">\n</span><span class=\"n\">data_dct</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"n\">repr_dct</span><span class=\"p\">(</span><span class=\"n\">data_ts</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">coef</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"m\">84</span><span class=\"p\">)</span><span class=\"w\">\n</span><span class=\"c1\"># Classical PAA</span><span class=\"w\">\n</span><span class=\"n\">data_paa</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"n\">repr_paa</span><span class=\"p\">(</span><span class=\"n\">data_ts</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">q</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"m\">8</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">func</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">mean</span><span class=\"p\">)</span></code></pre></figure>\n\n<p>Let’s plot the results:</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-r\" data-lang=\"r\"><span class=\"n\">data_plot</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"n\">data.frame</span><span class=\"p\">(</span><span class=\"n\">Value</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"nf\">c</span><span class=\"p\">(</span><span class=\"n\">data_dwt</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">data_dft</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">data_dct</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">data_paa</span><span class=\"p\">),</span><span class=\"w\">\n                        </span><span class=\"n\">Time</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"nf\">rep</span><span class=\"p\">(</span><span class=\"m\">1</span><span class=\"o\">:</span><span class=\"nf\">length</span><span class=\"p\">(</span><span class=\"n\">data_dwt</span><span class=\"p\">),</span><span class=\"w\"> </span><span class=\"m\">4</span><span class=\"p\">),</span><span class=\"w\">\n                        </span><span class=\"n\">Method</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">factor</span><span class=\"p\">(</span><span class=\"nf\">rep</span><span class=\"p\">(</span><span class=\"nf\">c</span><span class=\"p\">(</span><span class=\"s2\">\"DWT\"</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"s2\">\"DFT\"</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"s2\">\"DCT\"</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"s2\">\"PAA\"</span><span class=\"p\">),</span><span class=\"w\">\n                                            </span><span class=\"n\">each</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"nf\">length</span><span class=\"p\">(</span><span class=\"n\">data_dwt</span><span class=\"p\">))))</span><span class=\"w\">\n \n</span><span class=\"n\">ggplot</span><span class=\"p\">(</span><span class=\"n\">data_plot</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">aes</span><span class=\"p\">(</span><span class=\"n\">Time</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">Value</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">color</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">Method</span><span class=\"p\">))</span><span class=\"w\"> </span><span class=\"o\">+</span><span class=\"w\">\n  </span><span class=\"n\">geom_line</span><span class=\"p\">(</span><span class=\"n\">alpha</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"m\">0.80</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">size</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"m\">0.8</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"o\">+</span><span class=\"w\">\n  </span><span class=\"n\">theme_bw</span><span class=\"p\">()</span></code></pre></figure>\n\n<p><img src=\"/images/post_7/unnamed-chunk-4-1.png\" alt=\"plot of chunk unnamed-chunk-4\" /></p>\n\n<p>We can see that the electricity consumption pattern remains also after significant reduction of dimensionality. The difference between these four representation methods is not really significant, every one of them “did the job” well.</p>\n\n<p>For seasonal time series as electricity load data, the model-based representations are highly recommended (Laurinec et al. (2016), Laurinec and Lucká (2016)). By model-based representation, we can extract a daily profile of some consumer. We can do it by simple average (or median) daily profile or by extraction of <strong>seasonal regression coefficients</strong>.</p>\n\n<p>For this task, several methods are implemented in the <strong>TSrepr</strong> package. The mean <strong>seasonal profile</strong> (<code class=\"language-plaintext highlighter-rouge\">repr_seas_profile</code>), seasonal linear models (<code class=\"language-plaintext highlighter-rouge\">repr_lm</code>), seasonal additive model (<code class=\"language-plaintext highlighter-rouge\">repr_gam</code>) or seasonal exponential smoothing coefficients (<code class=\"language-plaintext highlighter-rouge\">repr_exp</code>). Let’s compare them on our data.</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-r\" data-lang=\"r\"><span class=\"n\">data_lm</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"n\">repr_lm</span><span class=\"p\">(</span><span class=\"n\">data_ts</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">freq</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"m\">48</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">method</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"s2\">\"lm\"</span><span class=\"p\">)</span><span class=\"w\">\n</span><span class=\"c1\"># robust linear model and l1 regression are also implemented</span><span class=\"w\">\n</span><span class=\"n\">data_l1</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"n\">repr_lm</span><span class=\"p\">(</span><span class=\"n\">data_ts</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">freq</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"m\">48</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">method</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"s2\">\"l1\"</span><span class=\"p\">)</span><span class=\"w\">\n</span><span class=\"c1\"># GAM</span><span class=\"w\">\n</span><span class=\"n\">data_gam</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"n\">repr_gam</span><span class=\"p\">(</span><span class=\"n\">data_ts</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">freq</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"m\">48</span><span class=\"p\">)</span><span class=\"w\">\n</span><span class=\"c1\"># median seasonal profile</span><span class=\"w\">\n</span><span class=\"n\">data_seas_prof</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"n\">repr_seas_profile</span><span class=\"p\">(</span><span class=\"n\">data_ts</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">freq</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"m\">48</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">func</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">median</span><span class=\"p\">)</span><span class=\"w\">\n</span><span class=\"c1\"># exponential smoothing</span><span class=\"w\">\n</span><span class=\"n\">data_exp</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"n\">repr_exp</span><span class=\"p\">(</span><span class=\"n\">data_ts</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">freq</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"m\">48</span><span class=\"p\">)</span></code></pre></figure>\n\n<p>And let’s plot the results:</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-r\" data-lang=\"r\"><span class=\"n\">data_plot</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"n\">data.frame</span><span class=\"p\">(</span><span class=\"n\">Value</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"nf\">c</span><span class=\"p\">(</span><span class=\"n\">data_lm</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">data_l1</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">data_seas_prof</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">data_exp</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">data_gam</span><span class=\"p\">),</span><span class=\"w\">\n                        </span><span class=\"n\">Time</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"nf\">c</span><span class=\"p\">(</span><span class=\"nf\">rep</span><span class=\"p\">(</span><span class=\"m\">1</span><span class=\"o\">:</span><span class=\"nf\">length</span><span class=\"p\">(</span><span class=\"n\">data_lm</span><span class=\"p\">),</span><span class=\"w\"> </span><span class=\"m\">4</span><span class=\"p\">),</span><span class=\"w\"> </span><span class=\"m\">1</span><span class=\"o\">:</span><span class=\"nf\">length</span><span class=\"p\">(</span><span class=\"n\">data_gam</span><span class=\"p\">)),</span><span class=\"w\">\n                        </span><span class=\"n\">Method</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"nf\">c</span><span class=\"p\">(</span><span class=\"nf\">rep</span><span class=\"p\">(</span><span class=\"nf\">c</span><span class=\"p\">(</span><span class=\"s2\">\"LM\"</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"s2\">\"L1\"</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"s2\">\"Median seas. prof.\"</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"s2\">\"Exp. smooth.\"</span><span class=\"p\">),</span><span class=\"w\">\n                                       </span><span class=\"n\">each</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"m\">48</span><span class=\"p\">),</span><span class=\"w\"> </span><span class=\"nf\">rep</span><span class=\"p\">(</span><span class=\"s2\">\"GAM\"</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"m\">47</span><span class=\"p\">)))</span><span class=\"w\">\n \n</span><span class=\"n\">ggplot</span><span class=\"p\">(</span><span class=\"n\">data_plot</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">aes</span><span class=\"p\">(</span><span class=\"n\">Time</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">Value</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">color</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">Method</span><span class=\"p\">))</span><span class=\"w\"> </span><span class=\"o\">+</span><span class=\"w\">\n  </span><span class=\"n\">geom_line</span><span class=\"p\">(</span><span class=\"n\">alpha</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"m\">0.80</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">size</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"m\">0.8</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"o\">+</span><span class=\"w\">\n  </span><span class=\"n\">theme_bw</span><span class=\"p\">()</span></code></pre></figure>\n\n<p><img src=\"/images/post_7/unnamed-chunk-6-1.png\" alt=\"plot of chunk unnamed-chunk-6\" /></p>\n\n<p>We can see that the most fluctuate result has exponential smoothing representation and the most smooth (denoised) result has seasonal <strong>GAM</strong> representation. Median daily profile and seasonal L1 regression coefficients are almost identical, the seasonal linear model regression coefficients representation is similar to them, but not that smooth.</p>\n\n<p>There are also two similar time series representation methods in <strong>TSrepr</strong> package that extract important points from time series - <strong>PIP</strong> and <strong>PLA</strong>. Let’s try it on our data, and we will extract 60 points from the original time series (there will be 61 points in the end because of the nature of these methods). If we set <code class=\"language-plaintext highlighter-rouge\">return = \"both\"</code>, then data.frame with both places and points will be returned.</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-r\" data-lang=\"r\"><span class=\"n\">data_pip</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"n\">repr_pip</span><span class=\"p\">(</span><span class=\"n\">data_ts</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">times</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"m\">60</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">return</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"s2\">\"both\"</span><span class=\"p\">)</span><span class=\"w\">\n</span><span class=\"n\">data_pla</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"n\">repr_pla</span><span class=\"p\">(</span><span class=\"n\">data_ts</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">times</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"m\">60</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">return</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"s2\">\"both\"</span><span class=\"p\">)</span></code></pre></figure>\n\n<p>And, of course, let’s plot the results.</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-r\" data-lang=\"r\"><span class=\"n\">data_plot</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"n\">data.frame</span><span class=\"p\">(</span><span class=\"n\">Value</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"nf\">c</span><span class=\"p\">(</span><span class=\"n\">data_ts</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">data_pip</span><span class=\"o\">$</span><span class=\"n\">points</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">data_pla</span><span class=\"o\">$</span><span class=\"n\">points</span><span class=\"p\">),</span><span class=\"w\">\n                        </span><span class=\"n\">Time</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"nf\">c</span><span class=\"p\">(</span><span class=\"m\">1</span><span class=\"o\">:</span><span class=\"nf\">length</span><span class=\"p\">(</span><span class=\"n\">data_ts</span><span class=\"p\">),</span><span class=\"w\"> </span><span class=\"n\">data_pip</span><span class=\"o\">$</span><span class=\"n\">places</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">data_pla</span><span class=\"o\">$</span><span class=\"n\">places</span><span class=\"p\">),</span><span class=\"w\">\n                        </span><span class=\"n\">Method</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"nf\">c</span><span class=\"p\">(</span><span class=\"nf\">rep</span><span class=\"p\">(</span><span class=\"s2\">\"Original\"</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"nf\">length</span><span class=\"p\">(</span><span class=\"n\">data_ts</span><span class=\"p\">)),</span><span class=\"w\">\n                                   </span><span class=\"nf\">rep</span><span class=\"p\">(</span><span class=\"nf\">c</span><span class=\"p\">(</span><span class=\"s2\">\"PIP\"</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"s2\">\"PLA\"</span><span class=\"p\">),</span><span class=\"w\"> </span><span class=\"n\">each</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"nf\">length</span><span class=\"p\">(</span><span class=\"n\">data_pla</span><span class=\"o\">$</span><span class=\"n\">places</span><span class=\"p\">))))</span><span class=\"w\">\n \n</span><span class=\"n\">ggplot</span><span class=\"p\">(</span><span class=\"n\">data_plot</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">aes</span><span class=\"p\">(</span><span class=\"n\">Time</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">Value</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">color</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">Method</span><span class=\"p\">))</span><span class=\"w\"> </span><span class=\"o\">+</span><span class=\"w\">\n  </span><span class=\"n\">geom_line</span><span class=\"p\">(</span><span class=\"n\">alpha</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"m\">0.65</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">size</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"m\">0.8</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"o\">+</span><span class=\"w\">\n  </span><span class=\"n\">theme_bw</span><span class=\"p\">()</span></code></pre></figure>\n\n<p><img src=\"/images/post_7/unnamed-chunk-8-1.png\" alt=\"plot of chunk unnamed-chunk-8\" /></p>\n\n<p>We can see some significant differences among these two methods, but both approaches identified important points well.</p>\n\n<p>The next data adaptive representation method is <strong>SAX</strong>. The SAX is a famous time series representation method – for its adaptability and originality. It extracts symbols as representation, in other words, it transforms aggregates of a time series to alphabetical symbols. Let’s use it on our data:</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-r\" data-lang=\"r\"><span class=\"c1\"># aggregates of size 12 and alphabet of size 10</span><span class=\"w\">\n</span><span class=\"n\">repr_sax</span><span class=\"p\">(</span><span class=\"n\">data_ts</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">q</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"m\">12</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"m\">10</span><span class=\"p\">)</span></code></pre></figure>\n\n<figure class=\"highlight\"><pre><code class=\"language-text\" data-lang=\"text\">##  [1] \"g\" \"i\" \"g\" \"j\" \"g\" \"j\" \"j\" \"j\" \"f\" \"i\" \"j\" \"j\" \"f\" \"h\" \"j\" \"j\" \"f\"\n## [18] \"i\" \"h\" \"h\" \"f\" \"i\" \"i\" \"i\" \"f\" \"i\" \"f\" \"i\" \"f\" \"g\" \"g\" \"i\" \"f\" \"i\"\n## [35] \"g\" \"h\" \"f\" \"f\" \"f\" \"i\" \"h\" \"h\" \"f\" \"i\" \"f\" \"g\" \"f\" \"i\" \"f\" \"h\" \"g\"\n## [52] \"i\" \"f\" \"h\" \"g\" \"i\"</code></pre></figure>\n\n<p>The last type of implemented representation methods is the <strong>data dictated</strong> - clipped. I developed two methods in this category - <strong>FeaClip</strong> and <strong>FeaTrend</strong>.\nBoth creates bit-level (binary) representation from original time series and computes run lengths of values by RLE (Run Length Encoding). Then interpretable features are extracted from run lengths.</p>\n\n<p>I will now describe the first of the mentioned methods - <strong>FeaClip</strong> (Laurinec and Lucká (2018)). Clipping representation is created very easily - if a value of a time series is greater then its average value, then the value is transformed to 1 and otherwise to 0. It can be defined formally as follows:</p>\n\n\\[\\hat{x}_t = \\left\\{\n\\begin{array}{rl}\n1 &amp; \\text{if } x_t &gt; \\mu \\\\\n0 &amp; \\text{otherwise}\n\\end{array} \\right. ,\\]\n\n<p>where $\\mu$ is the average value of a time series. On <strong>clipping</strong> (bit-level) representation $\\hat{x}$, compression method for binary series named Run Length Encoding (<strong>RLE</strong>) is applied. A run is continuous sequence of ones, respectively zeros. The number of ones respectively zeros in a run we call the run lengths. From run lengths counted by RLE, eight simple interpretable features are extracted to form the final representation and are defined as</p>\n\n\\[\\begin{aligned}\n \\mathbf{repr} = \\{ &amp; max_1 = \\mbox{max. from run lengths of ones}, \\\\\n &amp; sum_1 = \\mbox{sum of run lengths of ones}, \\\\\n &amp; max_0 = \\mbox{max. from run lengths of zeros}, \\\\\n &amp; jumps = \\mbox{length of RLE encoding} - 1, \\\\\n &amp; 0_{1.} = \\mbox{number of first zeros}, \\\\\n &amp; 0_{n.} = \\mbox{number of last zeros}, \\\\\n &amp; 1_{1.} = \\mbox{number of first ones}, \\\\\n &amp; 1_{n.} = \\mbox{number of last ones}, \\} .\n\\end{aligned}\\]\n\n<p>Now, I will use methods implemented in <strong>TSrepr</strong> package to show you how it works. The clipped series is created by function <code class=\"language-plaintext highlighter-rouge\">clipping</code>, I will only extract the first day from the electricity consumption time series.</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-r\" data-lang=\"r\"><span class=\"n\">data_oneday</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"n\">data_ts</span><span class=\"p\">[</span><span class=\"m\">1</span><span class=\"o\">:</span><span class=\"m\">48</span><span class=\"p\">]</span><span class=\"w\">\n</span><span class=\"n\">clipping</span><span class=\"p\">(</span><span class=\"n\">data_oneday</span><span class=\"p\">)</span></code></pre></figure>\n\n<figure class=\"highlight\"><pre><code class=\"language-text\" data-lang=\"text\">##  [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n## [36] 1 1 0 0 0 0 1 1 1 1 1 0 0</code></pre></figure>\n\n<p>If we visualize the data with its average value, then we can see that it works as the definition above:</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-r\" data-lang=\"r\"><span class=\"n\">ggplot</span><span class=\"p\">(</span><span class=\"n\">data.frame</span><span class=\"p\">(</span><span class=\"n\">Time</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"m\">1</span><span class=\"o\">:</span><span class=\"nf\">length</span><span class=\"p\">(</span><span class=\"n\">data_oneday</span><span class=\"p\">),</span><span class=\"w\"> </span><span class=\"n\">Value</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">data_oneday</span><span class=\"p\">),</span><span class=\"w\"> </span><span class=\"n\">aes</span><span class=\"p\">(</span><span class=\"n\">Time</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">Value</span><span class=\"p\">))</span><span class=\"w\"> </span><span class=\"o\">+</span><span class=\"w\">\n  </span><span class=\"n\">geom_line</span><span class=\"p\">()</span><span class=\"w\"> </span><span class=\"o\">+</span><span class=\"w\">\n  </span><span class=\"n\">geom_line</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">data.frame</span><span class=\"p\">(</span><span class=\"n\">Time</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"m\">1</span><span class=\"o\">:</span><span class=\"nf\">length</span><span class=\"p\">(</span><span class=\"n\">data_oneday</span><span class=\"p\">),</span><span class=\"w\"> </span><span class=\"n\">Value</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">mean</span><span class=\"p\">(</span><span class=\"n\">data_oneday</span><span class=\"p\">)),</span><span class=\"w\"> </span><span class=\"n\">aes</span><span class=\"p\">(</span><span class=\"n\">Time</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">Value</span><span class=\"p\">),</span><span class=\"w\"> </span><span class=\"n\">color</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"s2\">\"red\"</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">size</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"m\">1</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">alpha</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"m\">0.8</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"o\">+</span><span class=\"w\">\n  </span><span class=\"n\">theme_bw</span><span class=\"p\">()</span></code></pre></figure>\n\n<p><img src=\"/images/post_7/unnamed-chunk-11-1.png\" alt=\"plot of chunk unnamed-chunk-11\" /></p>\n\n<p>Then RLE is used for the extraction of run lengths:</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-r\" data-lang=\"r\"><span class=\"n\">rleC</span><span class=\"p\">(</span><span class=\"n\">clipping</span><span class=\"p\">(</span><span class=\"n\">data_oneday</span><span class=\"p\">))</span></code></pre></figure>\n\n<figure class=\"highlight\"><pre><code class=\"language-text\" data-lang=\"text\">## $lengths\n## [1] 16  3 15  3  4  5  2\n## \n## $values\n## [1] 0 1 0 1 0 1 0</code></pre></figure>\n\n<p>And finally, the extraction of interpretable features and all previous procedures is implemented in the <code class=\"language-plaintext highlighter-rouge\">repr_feaclip</code> function:</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-r\" data-lang=\"r\"><span class=\"n\">repr_feaclip</span><span class=\"p\">(</span><span class=\"n\">data_oneday</span><span class=\"p\">)</span></code></pre></figure>\n\n<figure class=\"highlight\"><pre><code class=\"language-text\" data-lang=\"text\">## max_1 sum_1 max_0 jumps  0_1.  0_n.  1_1.  1_n. \n##     5    11    16     6    16     2     0     0</code></pre></figure>\n\n<p>The <strong>FeaClip</strong> method is recommended to use with <strong>windowing</strong> approach, so for every specified window the FeaClip computation is separately applied (Laurinec and Lucká (2018)). For the electricity consumption data, I am using the length of the window equal to 1 day so 48 measurements. The windowing method is implemented by function <code class=\"language-plaintext highlighter-rouge\">repr_windowing</code> and its arguments are representation function (<code class=\"language-plaintext highlighter-rouge\">func</code>), window size (<code class=\"language-plaintext highlighter-rouge\">win_size</code>) and list of additional arguments to representation function (<code class=\"language-plaintext highlighter-rouge\">args</code>). Let’s use it in our case:</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-r\" data-lang=\"r\"><span class=\"n\">data_feaclip</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"n\">repr_windowing</span><span class=\"p\">(</span><span class=\"n\">data_ts</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">func</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">repr_feaclip</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">win_size</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"m\">48</span><span class=\"p\">)</span><span class=\"w\">\n \n</span><span class=\"n\">ggplot</span><span class=\"p\">(</span><span class=\"n\">data.frame</span><span class=\"p\">(</span><span class=\"n\">Time</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"m\">1</span><span class=\"o\">:</span><span class=\"nf\">length</span><span class=\"p\">(</span><span class=\"n\">data_feaclip</span><span class=\"p\">),</span><span class=\"w\"> </span><span class=\"n\">Value</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">data_feaclip</span><span class=\"p\">),</span><span class=\"w\"> </span><span class=\"n\">aes</span><span class=\"p\">(</span><span class=\"n\">Time</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">Value</span><span class=\"p\">))</span><span class=\"w\"> </span><span class=\"o\">+</span><span class=\"w\">\n  </span><span class=\"n\">geom_line</span><span class=\"p\">()</span><span class=\"w\"> </span><span class=\"o\">+</span><span class=\"w\">\n  </span><span class=\"n\">theme_bw</span><span class=\"p\">()</span></code></pre></figure>\n\n<p><img src=\"/images/post_7/unnamed-chunk-14-1.png\" alt=\"plot of chunk unnamed-chunk-14\" /></p>\n\n<p>The second data dictated method is <strong>FeaTrend</strong>. It extracts features from “trending” (again binary) representation. The trending representation is defined as follows:</p>\n\n\\[\\hat{x}_t = \\left\\{\n\\begin{array}{rl}\n1 &amp; \\text{if } x_t - x_{t+1} &lt; 0 \\\\\n0 &amp; \\text{otherwise}\n\\end{array} \\right. .\\]\n\n<p>So, when time series value increased then it is 1, otherwise it is 0.</p>\n\n<p>Before the computation of trending representation, a time series is smoothed (denoised) by simple moving average method (<code class=\"language-plaintext highlighter-rouge\">repr_sma</code>) in order to have more compact run lengths. Let’s demonstrate this factor in our example case, so we will use <code class=\"language-plaintext highlighter-rouge\">trending</code> and RLE function on original and also on the smoothed time series:</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-r\" data-lang=\"r\"><span class=\"c1\"># original time series</span><span class=\"w\">\n</span><span class=\"n\">rleC</span><span class=\"p\">(</span><span class=\"n\">trending</span><span class=\"p\">(</span><span class=\"n\">data_oneday</span><span class=\"p\">))</span></code></pre></figure>\n\n<figure class=\"highlight\"><pre><code class=\"language-text\" data-lang=\"text\">## $lengths\n##  [1] 2 2 2 2 1 2 2 4 2 2 1 1 1 2 2 2 1 4 4 4 4\n## \n## $values\n##  [1] 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0</code></pre></figure>\n\n<figure class=\"highlight\"><pre><code class=\"language-r\" data-lang=\"r\"><span class=\"c1\"># smoothed time series by SMA</span><span class=\"w\">\n</span><span class=\"n\">rleC</span><span class=\"p\">(</span><span class=\"n\">trending</span><span class=\"p\">(</span><span class=\"n\">repr_sma</span><span class=\"p\">(</span><span class=\"n\">data_oneday</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">order</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"m\">4</span><span class=\"p\">)))</span></code></pre></figure>\n\n<figure class=\"highlight\"><pre><code class=\"language-text\" data-lang=\"text\">## $lengths\n##  [1] 6 2 2 4 5 4 2 1 2 5 3 5 2\n## \n## $values\n##  [1] 0 1 0 1 0 1 0 1 0 1 0 1 0</code></pre></figure>\n\n<p>As expected, the run lengths of smoothed time series are more compact.\nThe <strong>FeaTrend</strong> is designed to extract an arbitrary feature from run lengths of a trending representation. The recommended feature is the maximum value of zeros and ones, but it can vary from an application. In the <code class=\"language-plaintext highlighter-rouge\">repr_featrend</code> function, the windowing is directly implemented, so the original time series is divided into pieces (subseries) and features are extracted from them separately. Let’s try it in our case, but at first we will smooth original time series <code class=\"language-plaintext highlighter-rouge\">data_ts</code> dramatically by SMA (order of moving average will be 48*7, so weekly seasonality) and do it only on whole time series (<code class=\"language-plaintext highlighter-rouge\">pieces = 1</code>).</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-r\" data-lang=\"r\"><span class=\"c1\"># visualize smoothed time series</span><span class=\"w\">\n</span><span class=\"n\">data_sma</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"n\">repr_sma</span><span class=\"p\">(</span><span class=\"n\">data_ts</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">order</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"m\">48</span><span class=\"o\">*</span><span class=\"m\">7</span><span class=\"p\">)</span><span class=\"w\">\n</span><span class=\"n\">ggplot</span><span class=\"p\">(</span><span class=\"n\">data.frame</span><span class=\"p\">(</span><span class=\"n\">Time</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"m\">1</span><span class=\"o\">:</span><span class=\"nf\">length</span><span class=\"p\">(</span><span class=\"n\">data_sma</span><span class=\"p\">),</span><span class=\"w\"> </span><span class=\"n\">Value</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">data_sma</span><span class=\"p\">),</span><span class=\"w\"> </span><span class=\"n\">aes</span><span class=\"p\">(</span><span class=\"n\">Time</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">Value</span><span class=\"p\">))</span><span class=\"w\"> </span><span class=\"o\">+</span><span class=\"w\">\n  </span><span class=\"n\">geom_line</span><span class=\"p\">()</span><span class=\"w\"> </span><span class=\"o\">+</span><span class=\"w\">\n  </span><span class=\"n\">theme_bw</span><span class=\"p\">()</span></code></pre></figure>\n\n<p><img src=\"/images/post_7/unnamed-chunk-16-1.png\" alt=\"plot of chunk unnamed-chunk-16\" /></p>\n\n<figure class=\"highlight\"><pre><code class=\"language-r\" data-lang=\"r\"><span class=\"c1\"># compute FeaTrend representation</span><span class=\"w\">\n</span><span class=\"n\">repr_featrend</span><span class=\"p\">(</span><span class=\"n\">data_ts</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">func</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">max</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">pieces</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"m\">1</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">order</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"m\">48</span><span class=\"o\">*</span><span class=\"m\">7</span><span class=\"p\">)</span></code></pre></figure>\n\n<figure class=\"highlight\"><pre><code class=\"language-text\" data-lang=\"text\">## [1] 15 30</code></pre></figure>\n\n<p>So, the maximal run length of ones is 15 and maximal run length of zeros is 30, as expected, the number of zeros is much more than the number of ones because of decreasing character of the used time series.</p>\n\n<p>And we have described and used every time series representation method implemented in the <strong>TSrepr</strong> package. In the next post (tutorial), I will show you one typical use case for using time series representation – clustering of time series.</p>\n\n<h2 id=\"references\">References</h2>\n\n<p>Aghabozorgi, Saeed, Ali Seyed Shirkhorshidi, and Teh Ying Wah. 2015. “Time-series clustering - A decade review.” Information Systems 53. Elsevier: 16–38.</p>\n\n<p>Bagnall, Anthony, Chotirat Ratanamahatana, Eamonn Keogh, Stefano Lonardi, and Gareth Janacek. 2006. “A bit level representation for time series data mining with shape based similarity.” Data Mining and Knowledge Discovery 13 (1): 11–40.</p>\n\n<p>Esling, Philippe, and Carlos Agon. 2012. “Time-series data mining.” ACM Computing Surveys 45 (1). ACM: 1–34.</p>\n\n<p>Laurinec, Peter, and Mária Lucká. 2016. “Comparison of Representations of Time Series for Clustering Smart Meter Data.” In Lecture Notes in Engineering and Computer Science: Proceedings of the World Congress on Engineering and Computer Science 2016, 458–63.</p>\n\n<p>Laurinec, Peter, Marek Lóderer, Petra Vrablecová, Mária Lucká, Viera Rozinajová, and Anna Bou Ezzeddine. 2016. “Adaptive Time Series Forecasting of Energy Consumption Using Optimized Cluster Analysis.” In Data Mining Workshops (Icdmw), 2016 Ieee 16th International Conference on, 398–405. IEEE.</p>\n\n<p>Laurinec, Peter, and Mária Lucká. 2018. “Interpretable multiple data streams clustering with clipped streams representation for the improvement of electricity consumption forecasting”. Data Mining and Knowledge Discovery. Springer. DOI: <a href=\"https://doi.org/10.1007/s10618-018-0598-2\">10.1007/s10618-018-0598-2</a>.</p>\n\n<p>Ratanamahatana, Chotirat, Eamonn Keogh, Anthony J Bagnall, and Stefano Lonardi. 2005. “A Novel Bit Level Time Series Representation with Implication of Similarity Search and Clustering.” In Pacific-Asia Conference on Knowledge Discovery and Data Mining, 771–77. Springer.</p>",
  "pubDate": "Fri, 26 Jan 2018 00:00:00 +0000",
  "link": "https://petolau.github.io/TSrepr-time-series-representations/",
  "guid": {
    "@isPermaLink": true,
    "#text": "https://petolau.github.io/TSrepr-time-series-representations/"
  }
}