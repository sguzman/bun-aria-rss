{
  "title": "Tech Companies Are Limiting Police Use of Facial Recognition. Here's Why",
  "description": "Earlier this month, IBM said it was getting out of the facial recognition business. Then Amazon and Microsoft announced prohibitions on law enforcement using their facial recognition tech. There's growing evidence these algorithmic systems are riddled with gender and racial bias. Today on the show, Short Wave speaks with AI policy researcher Mutale Nkonde about algorithmic bias — how facial recognition software can discriminate and reflect the biases of society.",
  "pubDate": "Tue, 23 Jun 2020 04:00:09 -0400",
  "copyright": "Copyright 2019-2021 NPR - For Personal Use Only",
  "guid": "6c6683ed-ea08-445d-96ff-146b939fc09f",
  "link": "https://www.npr.org/2020/06/22/881845711/tech-companies-are-limiting-police-use-of-facial-recognition-heres-why",
  "itunes:title": "Tech Companies Are Limiting Police Use of Facial Recognition. Here's Why",
  "itunes:author": "NPR",
  "itunes:summary": "There's growing evidence these algorithmic systems are riddled with gender and racial bias.",
  "itunes:subtitle": "There's growing evidence these algorithmic systems are riddled with gender and racial bias.",
  "itunes:image": "",
  "itunes:duration": 869,
  "itunes:explicit": "no",
  "itunes:episodeType": "full",
  "content:encoded": "Earlier this month, IBM said it was getting out of the facial recognition business. Then Amazon and Microsoft announced prohibitions on law enforcement using their facial recognition tech. There's growing evidence these algorithmic systems are riddled with gender and racial bias. Today on the show, Short Wave speaks with AI policy researcher Mutale Nkonde about algorithmic bias — how facial recognition software can discriminate and reflect the biases of society.",
  "enclosure": ""
}