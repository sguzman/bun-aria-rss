{
  "title": "Fault-Tolerant Federated Reinforcement Learning with Theoretical Guarantee. (arXiv:2110.14074v2 [cs.LG] UPDATED)",
  "link": "http://arxiv.org/abs/2110.14074",
  "description": "<p>The growing literature of Federated Learning (FL) has recently inspired\nFederated Reinforcement Learning (FRL) to encourage multiple agents to\nfederatively build a better decision-making policy without sharing raw\ntrajectories. Despite its promising applications, existing works on FRL fail to\nI) provide theoretical analysis on its convergence, and II) account for random\nsystem failures and adversarial attacks. Towards this end, we propose the first\nFRL framework the convergence of which is guaranteed and tolerant to less than\nhalf of the participating agents being random system failures or adversarial\nattackers. We prove that the sample efficiency of the proposed framework is\nguaranteed to improve with the number of agents and is able to account for such\npotential failures or attacks. All theoretical results are empirically verified\non various RL benchmark tasks.\n</p>",
  "dc:creator": "<a href=\"http://arxiv.org/find/cs/1/au:+Fan_F/0/1/0/all/0/1\">Flint Xiaofeng Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yining Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_Z/0/1/0/all/0/1\">Zhongxiang Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jing_W/0/1/0/all/0/1\">Wei Jing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1\">Cheston Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Low_B/0/1/0/all/0/1\">Bryan Kian Hsiang Low</a>"
}