{
  "title": "Dask Release 0.14.3",
  "link": "",
  "updated": "2017-05-08T00:00:00+00:00",
  "id": "https://mrocklin.github.io/blog/work/2017/05/08/dask-0.14.3",
  "content": "<p><em>This work is supported by <a href=\"http://continuum.io\">Continuum Analytics</a>\nand the Data Driven Discovery Initiative from the <a href=\"https://www.moore.org/\">Moore\nFoundation</a>.</em></p>\n\n<p>I’m pleased to announce the release of Dask version 0.14.3.  This release\ncontains a variety of performance and feature improvements.  This blogpost\nincludes some notable features and changes since the last release on March\n22nd.</p>\n\n<p>As always you can conda install from conda-forge</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>conda install -c conda-forge dask distributed\n</code></pre></div></div>\n\n<p>or you can pip install from PyPI</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>pip install dask[complete] --upgrade\n</code></pre></div></div>\n\n<p>Conda packages should be on the default channel within a few days.</p>\n\n<h2 id=\"arrays\">Arrays</h2>\n\n<h3 id=\"sparse-arrays\">Sparse Arrays</h3>\n\n<p>Dask.arrays now support sparse arrays and mixed dense/sparse arrays.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">import</span> <span class=\"nn\">dask.array</span> <span class=\"k\">as</span> <span class=\"n\">da</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">da</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">(</span><span class=\"n\">size</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">10000</span><span class=\"p\">,</span> <span class=\"mi\">10000</span><span class=\"p\">,</span> <span class=\"mi\">10000</span><span class=\"p\">,</span> <span class=\"mi\">10000</span><span class=\"p\">),</span>\n<span class=\"p\">...</span>                      <span class=\"n\">chunks</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"mi\">100</span><span class=\"p\">))</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">x</span><span class=\"p\">[</span><span class=\"n\">x</span> <span class=\"o\">&lt;</span> <span class=\"mf\">0.99</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">import</span> <span class=\"nn\">sparse</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">s</span> <span class=\"o\">=</span> <span class=\"n\">x</span><span class=\"p\">.</span><span class=\"n\">map_blocks</span><span class=\"p\">(</span><span class=\"n\">sparse</span><span class=\"p\">.</span><span class=\"n\">COO</span><span class=\"p\">)</span>  <span class=\"c1\"># parallel array of sparse arrays\n</span></code></pre></div></div>\n\n<p>In order to support sparse arrays we did two things:</p>\n\n<ol>\n  <li>Made dask.array support ndarray containers other than NumPy, as long\nas they were API compatible</li>\n  <li>Made a small <a href=\"https://github.com/mrocklin/sparse\">sparse</a> array library\nthat was API compatible to the numpy.ndarray</li>\n</ol>\n\n<p>This process was pretty easy and could be extended to other systems.\nThis also allows for different kinds of ndarrays in the same Dask array, as\nlong as interactions between the arrays are well defined (using the standard\nNumPy protocols like <code class=\"language-plaintext highlighter-rouge\">__array_priority__</code> and so on.)</p>\n\n<p><strong>Documentation</strong>: <a href=\"http://dask.pydata.org/en/latest/array-sparse.html\">http://dask.pydata.org/en/latest/array-sparse.html</a></p>\n\n<p><em>Update: there is already a <a href=\"https://github.com/dask/dask/pull/2301\">pull\nrequest</a> for Masked arrays</em></p>\n\n<h3 id=\"reworked-fft-code\">Reworked FFT code</h3>\n\n<p>The <code class=\"language-plaintext highlighter-rouge\">da.fft</code> submodule has been extended to include most of the functions in\n<code class=\"language-plaintext highlighter-rouge\">np.fft</code>, with the caveat that multi-dimensional FFTs will only work along\nsingle-chunk dimensions.  Still, given that rechunking is decently fast today\nthis can be very useful for large image stacks.</p>\n\n<p><strong>Documentation</strong>: <a href=\"http://dask.pydata.org/en/latest/array-api.html#fast-fourier-transforms\">http://dask.pydata.org/en/latest/array-api.html#fast-fourier-transforms</a></p>\n\n<h3 id=\"constructor-plugins\">Constructor Plugins</h3>\n\n<p>You can now run arbitrary code whenever a dask array is constructed.  This\nempowers users to build in their own policies like rechunking, warning users,\nor eager evaluation.  A dask.array plugin takes in a dask.array and returns\neither a new dask array, or returns None, in which case the original will be\nreturned.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"k\">def</span> <span class=\"nf\">f</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">):</span>\n<span class=\"p\">...</span>     <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s\">'%d bytes'</span> <span class=\"o\">%</span> <span class=\"n\">x</span><span class=\"p\">.</span><span class=\"n\">nbytes</span><span class=\"p\">)</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"k\">with</span> <span class=\"n\">dask</span><span class=\"p\">.</span><span class=\"n\">set_options</span><span class=\"p\">(</span><span class=\"n\">array_plugins</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">f</span><span class=\"p\">]):</span>\n<span class=\"p\">...</span>     <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">da</span><span class=\"p\">.</span><span class=\"n\">ones</span><span class=\"p\">((</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">),</span> <span class=\"n\">chunks</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">))</span>\n<span class=\"p\">...</span>     <span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">x</span><span class=\"p\">.</span><span class=\"n\">dot</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">.</span><span class=\"n\">T</span><span class=\"p\">)</span>\n<span class=\"mi\">80</span> <span class=\"nb\">bytes</span>\n<span class=\"mi\">80</span> <span class=\"nb\">bytes</span>\n<span class=\"mi\">800</span> <span class=\"nb\">bytes</span>\n<span class=\"mi\">800</span> <span class=\"nb\">bytes</span>\n</code></pre></div></div>\n\n<p>This can be used, for example, to convert dask.array code into numpy code to\nidentify bugs quickly:</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"k\">with</span> <span class=\"n\">dask</span><span class=\"p\">.</span><span class=\"n\">set_options</span><span class=\"p\">(</span><span class=\"n\">array_plugins</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"k\">lambda</span> <span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">x</span><span class=\"p\">.</span><span class=\"n\">compute</span><span class=\"p\">()]):</span>\n<span class=\"p\">...</span>     <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">da</span><span class=\"p\">.</span><span class=\"n\">arange</span><span class=\"p\">(</span><span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"n\">chunks</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">)</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">x</span>  <span class=\"c1\"># this was automatically converted into a numpy array\n</span><span class=\"n\">array</span><span class=\"p\">([</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">])</span>\n</code></pre></div></div>\n\n<p>Or to warn users if they accidentally produce an array with large chunks:</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">def</span> <span class=\"nf\">warn_on_large_chunks</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">):</span>\n    <span class=\"n\">shapes</span> <span class=\"o\">=</span> <span class=\"nb\">list</span><span class=\"p\">(</span><span class=\"n\">itertools</span><span class=\"p\">.</span><span class=\"n\">product</span><span class=\"p\">(</span><span class=\"o\">*</span><span class=\"n\">x</span><span class=\"p\">.</span><span class=\"n\">chunks</span><span class=\"p\">))</span>\n    <span class=\"n\">nbytes</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">x</span><span class=\"p\">.</span><span class=\"n\">dtype</span><span class=\"p\">.</span><span class=\"n\">itemsize</span> <span class=\"o\">*</span> <span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">prod</span><span class=\"p\">(</span><span class=\"n\">shape</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">shape</span> <span class=\"ow\">in</span> <span class=\"n\">shapes</span><span class=\"p\">]</span>\n    <span class=\"k\">if</span> <span class=\"nb\">any</span><span class=\"p\">(</span><span class=\"n\">nb</span> <span class=\"o\">&gt;</span> <span class=\"mf\">1e9</span> <span class=\"k\">for</span> <span class=\"n\">nb</span> <span class=\"ow\">in</span> <span class=\"n\">nbytes</span><span class=\"p\">):</span>\n        <span class=\"n\">warnings</span><span class=\"p\">.</span><span class=\"n\">warn</span><span class=\"p\">(</span><span class=\"s\">\"Array contains very large chunks\"</span><span class=\"p\">)</span>\n\n<span class=\"k\">with</span> <span class=\"n\">dask</span><span class=\"p\">.</span><span class=\"n\">set_options</span><span class=\"p\">(</span><span class=\"n\">array_plugins</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">warn_on_large_chunks</span><span class=\"p\">]):</span>\n    <span class=\"p\">...</span>\n</code></pre></div></div>\n\n<p>These features were heavily requested by the climate science community, which\ntends to serve both highly technical computer scientists, and less technical\nclimate scientists who were running into issues with the nuances of chunking.</p>\n\n<h2 id=\"dataframes\">DataFrames</h2>\n\n<p>Dask.dataframe changes are both numerous, and very small, making it difficult\nto give a representative accounting of recent changes within a blogpost.\nTypically these include small changes to either track new Pandas development,\nor to fix slight inconsistencies in corner cases (of which there are many.)</p>\n\n<p>Still, two highlights follow:</p>\n\n<h3 id=\"rolling-windows-with-time-intervals\">Rolling windows with time intervals</h3>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">s</span><span class=\"p\">.</span><span class=\"n\">rolling</span><span class=\"p\">(</span><span class=\"s\">'2s'</span><span class=\"p\">).</span><span class=\"n\">count</span><span class=\"p\">().</span><span class=\"n\">compute</span><span class=\"p\">()</span>\n<span class=\"mi\">2017</span><span class=\"o\">-</span><span class=\"mi\">01</span><span class=\"o\">-</span><span class=\"mi\">01</span> <span class=\"mi\">00</span><span class=\"p\">:</span><span class=\"mi\">00</span><span class=\"p\">:</span><span class=\"mi\">00</span>    <span class=\"mf\">1.0</span>\n<span class=\"mi\">2017</span><span class=\"o\">-</span><span class=\"mi\">01</span><span class=\"o\">-</span><span class=\"mi\">01</span> <span class=\"mi\">00</span><span class=\"p\">:</span><span class=\"mi\">00</span><span class=\"p\">:</span><span class=\"mi\">01</span>    <span class=\"mf\">2.0</span>\n<span class=\"mi\">2017</span><span class=\"o\">-</span><span class=\"mi\">01</span><span class=\"o\">-</span><span class=\"mi\">01</span> <span class=\"mi\">00</span><span class=\"p\">:</span><span class=\"mi\">00</span><span class=\"p\">:</span><span class=\"mi\">02</span>    <span class=\"mf\">2.0</span>\n<span class=\"mi\">2017</span><span class=\"o\">-</span><span class=\"mi\">01</span><span class=\"o\">-</span><span class=\"mi\">01</span> <span class=\"mi\">00</span><span class=\"p\">:</span><span class=\"mi\">00</span><span class=\"p\">:</span><span class=\"mi\">03</span>    <span class=\"mf\">2.0</span>\n<span class=\"mi\">2017</span><span class=\"o\">-</span><span class=\"mi\">01</span><span class=\"o\">-</span><span class=\"mi\">01</span> <span class=\"mi\">00</span><span class=\"p\">:</span><span class=\"mi\">00</span><span class=\"p\">:</span><span class=\"mi\">04</span>    <span class=\"mf\">2.0</span>\n<span class=\"mi\">2017</span><span class=\"o\">-</span><span class=\"mi\">01</span><span class=\"o\">-</span><span class=\"mi\">01</span> <span class=\"mi\">00</span><span class=\"p\">:</span><span class=\"mi\">00</span><span class=\"p\">:</span><span class=\"mi\">05</span>    <span class=\"mf\">2.0</span>\n<span class=\"mi\">2017</span><span class=\"o\">-</span><span class=\"mi\">01</span><span class=\"o\">-</span><span class=\"mi\">01</span> <span class=\"mi\">00</span><span class=\"p\">:</span><span class=\"mi\">00</span><span class=\"p\">:</span><span class=\"mi\">06</span>    <span class=\"mf\">2.0</span>\n<span class=\"mi\">2017</span><span class=\"o\">-</span><span class=\"mi\">01</span><span class=\"o\">-</span><span class=\"mi\">01</span> <span class=\"mi\">00</span><span class=\"p\">:</span><span class=\"mi\">00</span><span class=\"p\">:</span><span class=\"mi\">07</span>    <span class=\"mf\">2.0</span>\n<span class=\"mi\">2017</span><span class=\"o\">-</span><span class=\"mi\">01</span><span class=\"o\">-</span><span class=\"mi\">01</span> <span class=\"mi\">00</span><span class=\"p\">:</span><span class=\"mi\">00</span><span class=\"p\">:</span><span class=\"mi\">08</span>    <span class=\"mf\">2.0</span>\n<span class=\"mi\">2017</span><span class=\"o\">-</span><span class=\"mi\">01</span><span class=\"o\">-</span><span class=\"mi\">01</span> <span class=\"mi\">00</span><span class=\"p\">:</span><span class=\"mi\">00</span><span class=\"p\">:</span><span class=\"mi\">09</span>    <span class=\"mf\">2.0</span>\n<span class=\"n\">dtype</span><span class=\"p\">:</span> <span class=\"n\">float64</span>\n</code></pre></div></div>\n\n<h3 id=\"read-parquet-data-with-arrow\">Read Parquet data with Arrow</h3>\n\n<p>Dask now supports reading Parquet data with both\n<a href=\"http://fastparquet.readthedocs.io/en/latest/\">fastparquet</a> (a Numpy/Numba\nsolution) and <a href=\"https://arrow.apache.org/\">Arrow</a> and\n<a href=\"https://github.com/apache/parquet-cpp\">Parquet-CPP</a>.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">dd</span><span class=\"p\">.</span><span class=\"n\">read_parquet</span><span class=\"p\">(</span><span class=\"s\">'/path/to/mydata.parquet'</span><span class=\"p\">,</span> <span class=\"n\">engine</span><span class=\"o\">=</span><span class=\"s\">'fastparquet'</span><span class=\"p\">)</span>\n<span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">dd</span><span class=\"p\">.</span><span class=\"n\">read_parquet</span><span class=\"p\">(</span><span class=\"s\">'/path/to/mydata.parquet'</span><span class=\"p\">,</span> <span class=\"n\">engine</span><span class=\"o\">=</span><span class=\"s\">'arrow'</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p>Hopefully this capability increases the use of both projects and results in\ngreater feedback to those libraries so that they can continue to advance\nPython’s access to the Parquet format.</p>\n\n<h2 id=\"graph-optimizations\">Graph Optimizations</h2>\n\n<p>Dask performs a few passes of simple linear-time graph optimizations before\nsending a task graph to the scheduler.  These optimizations currently vary by\ncollection type, for example dask.arrays have different optimizations than\ndask.dataframes.  These optimizations can greatly improve performance in some\ncases, but can also increase overhead, which becomes very important for large\ngraphs.</p>\n\n<p>As Dask has grown into more communities, each with strong and differing\nperformance constraints, we’ve found that we needed to allow each community to\ndefine its own optimization schemes.  The defaults have not changed, but now\nyou can override them with your own.  This can be set globally or with a\ncontext manager.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">def</span> <span class=\"nf\">my_optimize_function</span><span class=\"p\">(</span><span class=\"n\">graph</span><span class=\"p\">,</span> <span class=\"n\">keys</span><span class=\"p\">):</span>\n    <span class=\"s\">\"\"\" Takes a task graph and a list of output keys, returns new graph \"\"\"</span>\n    <span class=\"n\">new_graph</span> <span class=\"o\">=</span> <span class=\"p\">{...}</span>\n    <span class=\"k\">return</span> <span class=\"n\">new_graph</span>\n\n<span class=\"k\">with</span> <span class=\"n\">dask</span><span class=\"p\">.</span><span class=\"n\">set_options</span><span class=\"p\">(</span><span class=\"n\">array_optimize</span><span class=\"o\">=</span><span class=\"n\">my_optimize_function</span><span class=\"p\">,</span>\n                      <span class=\"n\">dataframe_optimize</span><span class=\"o\">=</span><span class=\"bp\">None</span><span class=\"p\">,</span>\n                      <span class=\"n\">delayed_optimize</span><span class=\"o\">=</span><span class=\"n\">my_other_optimize_function</span><span class=\"p\">):</span>\n    <span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">dask</span><span class=\"p\">.</span><span class=\"n\">compute</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p><strong>Documentation</strong>: <a href=\"http://dask.pydata.org/en/latest/optimize.html#customizing-optimization\">http://dask.pydata.org/en/latest/optimize.html#customizing-optimization</a></p>\n\n<h3 id=\"speed-improvements\">Speed improvements</h3>\n\n<p>Additionally, task fusion has been significantly accelerated.  This is very\nimportant for large graphs, particularly in dask.array computations.</p>\n\n<h2 id=\"web-diagnostics\">Web Diagnostics</h2>\n\n<p>The distributed scheduler’s web diagnostic page is now served from within the\ndask scheduler process.  This is both good and bad:</p>\n\n<ul>\n  <li><strong>Good</strong>: It is much easier to make new visuals</li>\n  <li><strong>Bad</strong>: Dask and Bokeh now share a single CPU</li>\n</ul>\n\n<p>Because Bokeh and Dask now share the same Tornado event loop we no longer need\nto send messages between them to then send out to a web browser.  The Bokeh\nserver has full access to all of the scheduler state.  This lets us build new\ndiagnostic pages more easily.  This has been around for a while but was largely\nused for development.  In this version we’ve switched the new version to be\ndefault and turned off the old one.</p>\n\n<p><img src=\"https://mrocklin.github.io/blog/images/bokeh-dask-2017-05-03.png\" width=\"50%\" align=\"right\" /></p>\n\n<p>The cost here is that the Bokeh scheduler can take 10-20% of the CPU use.  If\nyou are running a computation that heavily taxes the scheduler then you might\nwant to close your diagnostic pages.  Fortunately, this almost never happens.\nThe dask scheduler is typically fast enough to never get close to this limit.</p>\n\n<h3 id=\"tornado-difficulties\">Tornado difficulties</h3>\n\n<p>Beware that the current versions of Bokeh (0.12.5) and Tornado (4.5) do not\nplay well together.  This has been fixed in development versions, and installing\nwith conda is fine, but if you naively pip install then you may experience bad behavior.</p>\n\n<h2 id=\"joblib\">Joblib</h2>\n\n<p>The Dask.distributed Joblib backend now includes a <code class=\"language-plaintext highlighter-rouge\">scatter=</code> keyword, allowing\nyou to pre-scatter select variables out to all of the Dask workers.  This\nsignificantly cuts down on overhead, especially on machine learning workloads\nwhere most of the data doesn’t change very much.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\"># Send the training data only once to each worker\n</span><span class=\"k\">with</span> <span class=\"n\">parallel_backend</span><span class=\"p\">(</span><span class=\"s\">'dask.distributed'</span><span class=\"p\">,</span> <span class=\"n\">scheduler_host</span><span class=\"o\">=</span><span class=\"s\">'localhost:8786'</span><span class=\"p\">,</span>\n                      <span class=\"n\">scatter</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">digits</span><span class=\"p\">.</span><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">digits</span><span class=\"p\">.</span><span class=\"n\">target</span><span class=\"p\">]):</span>\n    <span class=\"n\">search</span><span class=\"p\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">digits</span><span class=\"p\">.</span><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">digits</span><span class=\"p\">.</span><span class=\"n\">target</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p>Early trials indicate that computations like scikit-learn’s RandomForest scale\nnicely on a cluster without any additional code.</p>\n\n<p><strong>Documentation</strong>: <a href=\"http://distributed.readthedocs.io/en/latest/joblib.html\">http://distributed.readthedocs.io/en/latest/joblib.html</a></p>\n\n<h2 id=\"preload-scripts\">Preload scripts</h2>\n\n<p>When starting a dask.distributed scheduler or worker people often want to\ninclude a bit of custom setup code, for example to configure loggers,\nauthenticate with some network system, and so on.  This has always been possible if\nyou start scheduler and workers from <a href=\"http://distributed.readthedocs.io/en/latest/setup.html#using-the-python-api\">within\nPython</a>\nbut is tricky if you want to use the command line interface.  Now you can write\nyour custom code as a separate standalone script and ask the command line\ninterface to run it for you at startup:</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\"># scheduler-setup.py\n</span><span class=\"kn\">from</span> <span class=\"nn\">distributed.diagnostics.plugin</span> <span class=\"kn\">import</span> <span class=\"n\">SchedulerPlugin</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MyPlugin</span><span class=\"p\">(</span><span class=\"n\">SchedulerPlugin</span><span class=\"p\">):</span>\n    <span class=\"s\">\"\"\" Prints a message whenever a worker is added to the cluster \"\"\"</span>\n    <span class=\"k\">def</span> <span class=\"nf\">add_worker</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">scheduler</span><span class=\"o\">=</span><span class=\"bp\">None</span><span class=\"p\">,</span> <span class=\"n\">worker</span><span class=\"o\">=</span><span class=\"bp\">None</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">):</span>\n        <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s\">\"Added a new worker at\"</span><span class=\"p\">,</span> <span class=\"n\">worker</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">dask_setup</span><span class=\"p\">(</span><span class=\"n\">scheduler</span><span class=\"p\">):</span>\n        <span class=\"n\">plugin</span> <span class=\"o\">=</span> <span class=\"n\">MyPlugin</span><span class=\"p\">()</span>\n        <span class=\"n\">scheduler</span><span class=\"p\">.</span><span class=\"n\">add_plugin</span><span class=\"p\">(</span><span class=\"n\">plugin</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>dask-scheduler --preload scheduler-setup.py\n</code></pre></div></div>\n\n<p>This makes it easier for people to adapt Dask to their particular institution.</p>\n\n<p><strong>Documentation</strong>: <a href=\"http://distributed.readthedocs.io/en/latest/setup.html#customizing-initialization\">http://distributed.readthedocs.io/en/latest/setup.html#customizing-initialization</a></p>\n\n<h2 id=\"network-interfaces-for-infiniband\">Network Interfaces (for infiniband)</h2>\n\n<p>Many people use Dask on high performance supercomputers.  This hardware\ndiffers from typical commodity clusters or cloud services in several ways,\nincluding very high performance network interconnects like\n<a href=\"https://en.wikipedia.org/wiki/InfiniBand\">InfiniBand</a>.  Typically these\nsystems also have normal ethernet and other networks.  You’re probably familiar\nwith this on your own laptop when you have both ethernet and wireless:</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>$ ifconfig\nlo          Link encap:Local Loopback                       # Localhost\n            inet addr:127.0.0.1  Mask:255.0.0.0\n            inet6 addr: ::1/128 Scope:Host\neth0        Link encap:Ethernet  HWaddr XX:XX:XX:XX:XX:XX   # Ethernet\n            inet addr:192.168.0.101\n            ...\nib0         Link encap:Infiniband                           # Fast InfiniBand\n            inet addr:172.42.0.101\n</code></pre></div></div>\n\n<p>The default systems Dask uses to determine network interfaces often choose\nethernet by default.  If you are on an HPC system then this is likely not\noptimal.  You can direct Dask to choose a particular network interface with the\n<code class=\"language-plaintext highlighter-rouge\">--interface</code> keyword</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>$ dask-scheduler --interface ib0\ndistributed.scheduler - INFO -   Scheduler at: tcp://172.42.0.101:8786\n\n$ dask-worker tcp://172.42.0.101:8786 --interface ib0\n</code></pre></div></div>\n\n<h2 id=\"efficient-as_completed\">Efficient as_completed</h2>\n\n<p>The\n<a href=\"http://distributed.readthedocs.io/en/latest/api.html#distributed.client.as_completed\">as_completed</a>\niterator returns futures in the order in which they complete.  It is the base\nof many asynchronous applications using Dask.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">z</span> <span class=\"o\">=</span> <span class=\"n\">client</span><span class=\"p\">.</span><span class=\"nb\">map</span><span class=\"p\">(</span><span class=\"n\">inc</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">])</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"k\">for</span> <span class=\"n\">future</span> <span class=\"ow\">in</span> <span class=\"n\">as_completed</span><span class=\"p\">([</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">z</span><span class=\"p\">]):</span>\n<span class=\"p\">...</span>     <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">future</span><span class=\"p\">.</span><span class=\"n\">result</span><span class=\"p\">())</span>\n<span class=\"mi\">2</span>\n<span class=\"mi\">0</span>\n<span class=\"mi\">1</span>\n</code></pre></div></div>\n\n<p>It can now also wait to yield an element only after the result also arrives</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"k\">for</span> <span class=\"n\">future</span><span class=\"p\">,</span> <span class=\"n\">result</span> <span class=\"ow\">in</span> <span class=\"n\">as_completed</span><span class=\"p\">([</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">z</span><span class=\"p\">],</span> <span class=\"n\">with_results</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">):</span>\n<span class=\"p\">...</span>     <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">result</span><span class=\"p\">)</span>\n<span class=\"mi\">2</span>\n<span class=\"mi\">0</span>\n<span class=\"mi\">1</span>\n</code></pre></div></div>\n\n<p>And also yield all futures (and results) that have finished up until this\npoint.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"k\">for</span> <span class=\"n\">futures</span> <span class=\"ow\">in</span> <span class=\"n\">as_completed</span><span class=\"p\">([</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">z</span><span class=\"p\">]).</span><span class=\"n\">batches</span><span class=\"p\">():</span>\n<span class=\"p\">...</span>    <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">client</span><span class=\"p\">.</span><span class=\"n\">gather</span><span class=\"p\">(</span><span class=\"n\">futures</span><span class=\"p\">))</span>\n<span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">)</span>\n<span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,)</span>\n</code></pre></div></div>\n\n<p>Both of these help to decrease the overhead of tight inner loops within\nasynchronous applications.</p>\n\n<p>Example blogpost here: <a href=\"http://matthewrocklin.com/blog/work/2017/04/19/dask-glm-2\">http://matthewrocklin.com/blog/work/2017/04/19/dask-glm-2</a></p>\n\n<h2 id=\"co-released-libraries\">Co-released libraries</h2>\n\n<p>This release is aligned with a number of other related libraries, notably\nPandas, and several smaller libraries for accessing data, including\n<a href=\"http://s3fs.readthedocs.io/en/latest/\">s3fs</a>,\n<a href=\"http://hdfs3.readthedocs.io/en/latest/\">hdfs3</a>,\n<a href=\"http://fastparquet.readthedocs.io/en/latest/\">fastparquet</a>, and\n<a href=\"https://github.com/andrix/python-snappy\">python-snappy</a> each of which have\nseen numerous updates over the past few months.  Much of the work of these\nlatter libraries is being coordinated by <a href=\"http://martindurant.github.io/\">Martin\nDurant</a></p>\n\n<h2 id=\"acknowledgements\">Acknowledgements</h2>\n\n<p>The following people contributed to the dask/dask repository since the 0.14.1 release\non March 22nd</p>\n\n<ul>\n  <li>Antoine Pitrou</li>\n  <li>Dmitry Shachnev</li>\n  <li>Erik Welch</li>\n  <li>Eugene Pakhomov</li>\n  <li>Jeff Reback</li>\n  <li>Jim Crist</li>\n  <li>John A Kirkham</li>\n  <li>Joris Van den Bossche</li>\n  <li>Martin Durant</li>\n  <li>Matthew Rocklin</li>\n  <li>Michal Ficek</li>\n  <li>Noah D Brenowitz</li>\n  <li>Stuart Archibald</li>\n  <li>Tom Augspurger</li>\n  <li>Wes McKinney</li>\n  <li>wikiped</li>\n</ul>\n\n<p>The following people contributed to the dask/distributed repository since the\n1.16.1 release on March 22nd</p>\n\n<ul>\n  <li>Antoine Pitrou</li>\n  <li>Bartosz Marcinkowski</li>\n  <li>Ben Schreck</li>\n  <li>Jim Crist</li>\n  <li>Jens Nie</li>\n  <li>Krisztián Szűcs</li>\n  <li>Lezyes</li>\n  <li>Luke Canavan</li>\n  <li>Martin Durant</li>\n  <li>Matthew Rocklin</li>\n  <li>Phil Elson</li>\n</ul>"
}