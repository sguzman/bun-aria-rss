{
  "title": "CorrMapper is finished",
  "link": "",
  "published": "2017-04-30T00:00:00+01:00",
  "updated": "2017-04-30T00:00:00+01:00",
  "id": "https://danielhomola.com/phd/corrmapper-is-finished",
  "content": "<h2 id=\"overview\">Overview</h2>\n\n<p>CorrMapper was the main project of my <a href=\"/assets/DanielHomola_PhD.pdf\">PhD</a>. It is an online research tool for the integration and visualisation of complex biomedical and omics datasets.</p>\n\n<!-- Courtesy of embedresponsively.com //-->\n\n<div class=\"responsive-video-container\">\n    <iframe src=\"https://www.youtube-nocookie.com/embed/ZNwc5aCFonI\" frameborder=\"0\" webkitallowfullscreen=\"\" mozallowfullscreen=\"\" allowfullscreen=\"\"></iframe>\n  </div>\n\n<h2 id=\"why-corrmapper-is-needed\">Why CorrMapper is needed?</h2>\n\n<p>CorrMapper could be best understood by thinking of the problems researchers with complex biomedical datasets face these days.</p>\n\n<h3 id=\"analytical-platforms-are-getting-a-lot-cheaper\">Analytical platforms are getting a lot cheaper</h3>\n\n<p>Most of the <strong>analytical platforms</strong> we use today in life sciences and medical research <strong>are getting cheaper each year</strong>. Some of them are getting cheaper at a ridiculous rate. </p>\n\n<p>The sequencing and assembly of the first human genomes cost hundreds of millions of dollars ($3 billion by the US government funded project 1 and $300,000,000 by the private Celera initiative) and took 11 and 3 years respectively.</p>\n\n<p>Yet today, less than 15 years later, we are about to pass the $1000 price point in human genome sequencing, with the Illumina HiSeq X Ten, which will be capable of sequencing 18,000 human genomes per year, to the gold standard of 30× coverage.</p>\n\n<h3 id=\"rise-of-multi-omics-studies\">Rise of multi-omics studies</h3>\n\n<p>Usually, when products get cheaper two things happen:</p>\n<ul>\n  <li>more people start using them,</li>\n  <li>people use more of them. </li>\n</ul>\n\n<p>If this happens to several analytical platform simultaneously, then researchers with the same budget will suddenly be able to design studies which utilise multiple platforms at once. This is precisely what happened in the past 10 years in life sciences and <strong><em>multi-omics</em> studies are becoming a lot more popular and affordable</strong>.</p>\n\n<p>Multi-omics just means that we have more than one omics dataset, where omics is the terminology used in life sciences to collectively refer to the data coming from genomics, transcriptomics, metagenomics, metabolomics, etc.</p>\n\n<p>Multi-omics studies have great potential as they allow us to examine the biology behind a disease from multiple viewpoints, each analytical platform opening a new window to the underlying biochemical processes.  </p>\n\n<p>For example the change of gene expression in colon cancer is just as important as the changes in epigenomic markers, or the gut microbiome which cannot be ignored neither, as there seems to be a complex, multi-level interplay between the bugs in our gut and our health.</p>\n\n<h3 id=\"multi-omics-studies-have-too-many-features\">Multi-omics studies have too many features</h3>\n\n<p>How do we relate these disparate datasets and combine them so that their complimentary information could be harnessed to expand our biomedical knowledge?</p>\n\n<p><strong>Modern omics datasets are extremely feature rich</strong> and in multi-omics studies this complexity is compounded by a second or even third dataset. Many of these features however, might be completely irrelevant to the studied biological problem, or redundant in the context of others (multicollinearity). We wouldn’t expect for example to find all 25000 human genes to be involved in breast cancer, or all urinary metabolites as candidate biomarkers for liver failure.</p>\n\n<h3 id=\"multi-omics-studies-are-hard-to-visualise\">Multi-omics studies are hard to visualise</h3>\n\n<p>Learning from such feature rich datasets inevitably incurs an increased <strong>computational cost</strong>. It also increases the chance of <strong>over- fitting the noise</strong> in our data, while reducing the predictive power of our models. Finally, the correlation networks arising from these high-throughput datasets are often hard to interpret and explore due to their density and lack of interactive tools.</p>\n\n<h3 id=\"clinical-metadata-presents-additional-complexity\">Clinical metadata presents additional complexity</h3>\n\n<p>Finally, biomedical studies will have <strong>increasing amounts of metadata</strong> attached to the actual omics measurements, making the stratification of patients easier than ever before. This is largely due to the explosion of digital/wearable health gadgets and the radical improvement in the digitization of healthcare records.</p>\n\n<h2 id=\"how-does-corrmapper-work\">How does CorrMapper work?</h2>\n\n<p>CorrMapper attempts the near impossible and address several of these problems at once.</p>\n\n<h3 id=\"corrmappers-pipeline\">CorrMapper’s pipeline</h3>\n\n<p><a href=\"/assets/images/corrmapper_pipeline.png\"><img src=\"/assets/images/corrmapper_pipeline.png\" /></a></p>\n\n<h3 id=\"interactive-metadata-explorer\">Interactive metadata explorer</h3>\n\n<p>CorrMapper provides a<strong> completely automatically generated metadata explorer</strong> which allows researchers to explore and stratify their patient cohort with an <strong>interactive dashboard</strong> which seamlessly integrates metadata with up to two omics datasets.</p>\n\n<h3 id=\"advanced-feature-selection\">Advanced feature selection</h3>\n\n<p>Several <strong>cutting edge feature selection algorithms</strong> have been built into CorrMapper to allow researchers to focus their attention to only those features which have the most discriminatory power with respect to a metadata variable, for example cancer vs. control. This not only decreases the computational cost of subsequent analysis steps but also<strong> helps with the interpretation of the data</strong>.</p>\n\n<h3 id=\"estimation-of-sparse-covariance-structures\">Estimation of sparse covariance structures</h3>\n\n<p>The selected features are then used to estimate a sparse inverse covariance matrix using the graphical lasso algorithm. This is useful because under Gaussian assumptions this inverse covarience matrix will only be zero if the row and column variables of the given cell are conditionally independent given all other features in the matrix.</p>\n\n<p>In plain English, we can work out which variables are <strong>conditionally independent</strong> (having removed all the confounding effects of the others). This is hugely important because without this, the complexity of biological systems would almost certainly guarantee that we will see a lot of spurious and confounded correlations in our analysis. Based on the inverse covariance matrix we can draw a <strong>network of correlated variables</strong>, see below.</p>\n\n<h3 id=\"robust-estimation-of-statistical-significance\">Robust estimation of statistical significance</h3>\n\n<p>The <strong>edges of the network represent Spearman rank correlations</strong> for which p values are estimated using 10000 permutations. The <em>p-values</em> are made more precise using a Generalized Pareto Distribution based method. Finally the p values are corrected for multiple testing using one of the user selected methods.</p>\n\n<h3 id=\"highly-interactive-visualisation-of-correlation-networks\">Highly interactive visualisation of correlation networks</h3>\n\n<p>The resulting <strong>heatmap and networks of correlations</strong> are then simultaneously visualised and <strong>interlinked</strong>.</p>\n\n<p>If the uploaded datasets have genomic features, this allows CorrMapper to use a more appropriate <strong>genomic network visualisation</strong>, where the features are laid out in clockwise fashion along the genome of the given species.</p>",
  "author": {
    "name": "danielhomola"
  },
  "category": [
    "",
    "",
    "",
    "",
    ""
  ],
  "summary": "A biomedical data integration and visualisation platform leveraging advanced feature selection and covariance estimation techniques."
}