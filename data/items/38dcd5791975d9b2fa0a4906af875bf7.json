{
  "title": "First Impressions of GPUs and PyData",
  "link": "",
  "updated": "2018-12-17T00:00:00+00:00",
  "id": "https://mrocklin.github.io/blog/work/2018/12/17/gpu-python-challenges",
  "content": "<p>I recently <a href=\"../../../2018/11/26/joining-nvidia\">moved from Anaconda to NVIDIA</a>\nwithin the RAPIDS team, which is building a PyData-friendly GPU-enabled data\nscience stack.  For my first week I explored some of the current challenges of\nworking with GPUs in the PyData ecosystem.  This post shares my first\nimpressions and also outlines plans for near-term work.</p>\n\n<p>First, lets start with the value proposition of GPUs, significant speed\nincreases over traditional CPUs.</p>\n\n<h2 id=\"gpu-performance\">GPU Performance</h2>\n\n<p>Like many PyData developers, I’m loosely aware that GPUs are sometimes fast, but\ndon’t deal with them often enough to have strong feeling about them.</p>\n\n<p>To get a more visceral feel for the performance differences, I logged into a\nGPU machine, opened up <a href=\"http://docs-cupy.chainer.org/en/stable/\">CuPy</a> (a\nNumpy-like GPU library developed mostly by Chainer in Japan) and\n<a href=\"https://cudf.readthedocs.io/en/latest/\">cuDF</a> (a Pandas-like library in\ndevelopment at NVIDIA) and did a couple of small speed comparisons:</p>\n\n<h3 id=\"compare-numpy-and-cupy\">Compare Numpy and Cupy</h3>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">import</span> <span class=\"nn\">numpy</span><span class=\"p\">,</span> <span class=\"n\">cupy</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">numpy</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">((</span><span class=\"mi\">10000</span><span class=\"p\">,</span> <span class=\"mi\">10000</span><span class=\"p\">))</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">cupy</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">((</span><span class=\"mi\">10000</span><span class=\"p\">,</span> <span class=\"mi\">10000</span><span class=\"p\">))</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"o\">%</span><span class=\"n\">timeit</span> <span class=\"nb\">bool</span><span class=\"p\">((</span><span class=\"n\">numpy</span><span class=\"p\">.</span><span class=\"n\">sin</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span> <span class=\"o\">**</span> <span class=\"mi\">2</span> <span class=\"o\">+</span> <span class=\"n\">numpy</span><span class=\"p\">.</span><span class=\"n\">cos</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span> <span class=\"o\">**</span> <span class=\"mi\">2</span> <span class=\"o\">==</span> <span class=\"mi\">1</span><span class=\"p\">).</span><span class=\"nb\">all</span><span class=\"p\">())</span>\n<span class=\"mi\">446</span> <span class=\"n\">ms</span> <span class=\"err\">±</span> <span class=\"mf\">53.1</span> <span class=\"n\">ms</span> <span class=\"n\">per</span> <span class=\"n\">loop</span> <span class=\"p\">(</span><span class=\"n\">mean</span> <span class=\"err\">±</span> <span class=\"n\">std</span><span class=\"p\">.</span> <span class=\"n\">dev</span><span class=\"p\">.</span> <span class=\"n\">of</span> <span class=\"mi\">7</span> <span class=\"n\">runs</span><span class=\"p\">,</span> <span class=\"mi\">1</span> <span class=\"n\">loop</span> <span class=\"n\">each</span><span class=\"p\">)</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"o\">%</span><span class=\"n\">timeit</span> <span class=\"nb\">bool</span><span class=\"p\">((</span><span class=\"n\">cupy</span><span class=\"p\">.</span><span class=\"n\">sin</span><span class=\"p\">(</span><span class=\"n\">y</span><span class=\"p\">)</span> <span class=\"o\">**</span> <span class=\"mi\">2</span> <span class=\"o\">+</span> <span class=\"n\">cupy</span><span class=\"p\">.</span><span class=\"n\">cos</span><span class=\"p\">(</span><span class=\"n\">y</span><span class=\"p\">)</span> <span class=\"o\">**</span> <span class=\"mi\">2</span> <span class=\"o\">==</span> <span class=\"mi\">1</span><span class=\"p\">).</span><span class=\"nb\">all</span><span class=\"p\">())</span>\n<span class=\"mf\">86.3</span> <span class=\"n\">ms</span> <span class=\"err\">±</span> <span class=\"mf\">50.7</span> <span class=\"n\">µs</span> <span class=\"n\">per</span> <span class=\"n\">loop</span> <span class=\"p\">(</span><span class=\"n\">mean</span> <span class=\"err\">±</span> <span class=\"n\">std</span><span class=\"p\">.</span> <span class=\"n\">dev</span><span class=\"p\">.</span> <span class=\"n\">of</span> <span class=\"mi\">7</span> <span class=\"n\">runs</span><span class=\"p\">,</span> <span class=\"mi\">10</span> <span class=\"n\">loops</span> <span class=\"n\">each</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p>On this mundane example, the GPU computation is about 5x faster.</p>\n\n<p><em>Note: an earlier version of this blogpost erroneously showed a 500x speed\nincrease.  This was because cupy was operating asynchronously in the\nbackground rather than blocking on the final result.</em></p>\n\n<h3 id=\"compare-pandas-and-cudf\">Compare Pandas and cuDF</h3>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"n\">pd</span><span class=\"p\">,</span> <span class=\"n\">numpy</span> <span class=\"k\">as</span> <span class=\"n\">np</span><span class=\"p\">,</span> <span class=\"n\">cudf</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">pdf</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"p\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">({</span><span class=\"s\">'x'</span><span class=\"p\">:</span> <span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">(</span><span class=\"mi\">10000000</span><span class=\"p\">),</span>\n                        <span class=\"s\">'y'</span><span class=\"p\">:</span> <span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">.</span><span class=\"n\">randint</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">10000000</span><span class=\"p\">,</span> <span class=\"n\">size</span><span class=\"o\">=</span><span class=\"mi\">10000000</span><span class=\"p\">)})</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">gdf</span> <span class=\"o\">=</span> <span class=\"n\">cudf</span><span class=\"p\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">.</span><span class=\"n\">from_pandas</span><span class=\"p\">(</span><span class=\"n\">pdf</span><span class=\"p\">)</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"o\">%</span><span class=\"n\">timeit</span> <span class=\"n\">pdf</span><span class=\"p\">.</span><span class=\"n\">x</span><span class=\"p\">.</span><span class=\"n\">mean</span><span class=\"p\">()</span>  <span class=\"c1\"># 30x faster\n</span><span class=\"mf\">50.2</span> <span class=\"n\">ms</span> <span class=\"err\">±</span> <span class=\"mi\">970</span> <span class=\"n\">µs</span> <span class=\"n\">per</span> <span class=\"n\">loop</span> <span class=\"p\">(</span><span class=\"n\">mean</span> <span class=\"err\">±</span> <span class=\"n\">std</span><span class=\"p\">.</span> <span class=\"n\">dev</span><span class=\"p\">.</span> <span class=\"n\">of</span> <span class=\"mi\">7</span> <span class=\"n\">runs</span><span class=\"p\">,</span> <span class=\"mi\">10</span> <span class=\"n\">loops</span> <span class=\"n\">each</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"o\">%</span><span class=\"n\">timeit</span> <span class=\"n\">gdf</span><span class=\"p\">.</span><span class=\"n\">x</span><span class=\"p\">.</span><span class=\"n\">mean</span><span class=\"p\">()</span>\n<span class=\"mf\">1.42</span> <span class=\"n\">ms</span> <span class=\"err\">±</span> <span class=\"mf\">5.84</span> <span class=\"n\">µs</span> <span class=\"n\">per</span> <span class=\"n\">loop</span> <span class=\"p\">(</span><span class=\"n\">mean</span> <span class=\"err\">±</span> <span class=\"n\">std</span><span class=\"p\">.</span> <span class=\"n\">dev</span><span class=\"p\">.</span> <span class=\"n\">of</span> <span class=\"mi\">7</span> <span class=\"n\">runs</span><span class=\"p\">,</span> <span class=\"mi\">1000</span> <span class=\"n\">loops</span> <span class=\"n\">each</span><span class=\"p\">)</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"o\">%</span><span class=\"n\">timeit</span> <span class=\"n\">pdf</span><span class=\"p\">.</span><span class=\"n\">groupby</span><span class=\"p\">(</span><span class=\"s\">'y'</span><span class=\"p\">).</span><span class=\"n\">mean</span><span class=\"p\">()</span>  <span class=\"c1\"># 40x faster\n</span><span class=\"mf\">1.15</span> <span class=\"n\">s</span> <span class=\"err\">±</span> <span class=\"mf\">46.5</span> <span class=\"n\">ms</span> <span class=\"n\">per</span> <span class=\"n\">loop</span> <span class=\"p\">(</span><span class=\"n\">mean</span> <span class=\"err\">±</span> <span class=\"n\">std</span><span class=\"p\">.</span> <span class=\"n\">dev</span><span class=\"p\">.</span> <span class=\"n\">of</span> <span class=\"mi\">7</span> <span class=\"n\">runs</span><span class=\"p\">,</span> <span class=\"mi\">1</span> <span class=\"n\">loop</span> <span class=\"n\">each</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"o\">%</span><span class=\"n\">timeit</span> <span class=\"n\">gdf</span><span class=\"p\">.</span><span class=\"n\">groupby</span><span class=\"p\">(</span><span class=\"s\">'y'</span><span class=\"p\">).</span><span class=\"n\">mean</span><span class=\"p\">()</span>\n<span class=\"mi\">54</span> <span class=\"n\">ms</span> <span class=\"err\">±</span> <span class=\"mi\">182</span> <span class=\"n\">µs</span> <span class=\"n\">per</span> <span class=\"n\">loop</span> <span class=\"p\">(</span><span class=\"n\">mean</span> <span class=\"err\">±</span> <span class=\"n\">std</span><span class=\"p\">.</span> <span class=\"n\">dev</span><span class=\"p\">.</span> <span class=\"n\">of</span> <span class=\"mi\">7</span> <span class=\"n\">runs</span><span class=\"p\">,</span> <span class=\"mi\">10</span> <span class=\"n\">loops</span> <span class=\"n\">each</span><span class=\"p\">)</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"o\">%</span><span class=\"n\">timeit</span> <span class=\"n\">pdf</span><span class=\"p\">.</span><span class=\"n\">merge</span><span class=\"p\">(</span><span class=\"n\">pdf</span><span class=\"p\">,</span> <span class=\"n\">on</span><span class=\"o\">=</span><span class=\"s\">'y'</span><span class=\"p\">)</span>  <span class=\"c1\"># 30x faster\n</span><span class=\"mf\">10.3</span> <span class=\"n\">s</span> <span class=\"err\">±</span> <span class=\"mf\">38.2</span> <span class=\"n\">ms</span> <span class=\"n\">per</span> <span class=\"n\">loop</span> <span class=\"p\">(</span><span class=\"n\">mean</span> <span class=\"err\">±</span> <span class=\"n\">std</span><span class=\"p\">.</span> <span class=\"n\">dev</span><span class=\"p\">.</span> <span class=\"n\">of</span> <span class=\"mi\">7</span> <span class=\"n\">runs</span><span class=\"p\">,</span> <span class=\"mi\">1</span> <span class=\"n\">loop</span> <span class=\"n\">each</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"o\">%</span><span class=\"n\">timeit</span> <span class=\"n\">gdf</span><span class=\"p\">.</span><span class=\"n\">merge</span><span class=\"p\">(</span><span class=\"n\">gdf</span><span class=\"p\">,</span> <span class=\"n\">on</span><span class=\"o\">=</span><span class=\"s\">'y'</span><span class=\"p\">)</span>\n<span class=\"mi\">280</span> <span class=\"n\">ms</span> <span class=\"err\">±</span> <span class=\"mi\">856</span> <span class=\"n\">µs</span> <span class=\"n\">per</span> <span class=\"n\">loop</span> <span class=\"p\">(</span><span class=\"n\">mean</span> <span class=\"err\">±</span> <span class=\"n\">std</span><span class=\"p\">.</span> <span class=\"n\">dev</span><span class=\"p\">.</span> <span class=\"n\">of</span> <span class=\"mi\">7</span> <span class=\"n\">runs</span><span class=\"p\">,</span> <span class=\"mi\">1</span> <span class=\"n\">loop</span> <span class=\"n\">each</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p>This is a 30-40x speedup for normal dataframe computing.\nOperations that previously took ten seconds\nnow process in near-interactive speeds.</p>\n\n<p><em>These were done naively on one GPU on a DGX machine.\nThe dataframe examples were cherry-picked to find supported operations\n(see dataframe issues below).</em></p>\n\n<h3 id=\"analysis\">Analysis</h3>\n\n<p>This speed difference is <em>potentially</em> transformative to a number of scientific\ndisciplines.  I intentionally tried examples that were more generic than\ntypical  deep learning workloads today, examples that might represent more\ntraditional scientific computing and data processing tasks.</p>\n\n<p>GPUs seem to offer orders-of-magnitude performance increases over traditional\nCPUs (at least in the naive cases presented above).  This speed difference is\nan interesting lever for us to push on, and is what made me curious about\nworking for NVIDIA in the first place.</p>\n\n<h2 id=\"roadblocks\">Roadblocks</h2>\n\n<p>However, there are many reasons why people don’t use GPUs for general purpose\ncomputational programming today.\nI thought I’d go through a few of them in this blogpost so we can see the sorts\nof things that we would need to resolve.</p>\n\n<ul>\n  <li>Not everyone has a GPU.  They can be large and expensive</li>\n  <li>Installing CUDA-enabled libraries can be tricky, even with conda</li>\n  <li>Current CUDA-enabled libraries don’t yet form a coherent ecosystem with\nestablished conventions</li>\n  <li>Many of the libraries around RAPIDS need specific help:\n    <ul>\n      <li>cuDF is immature, and needs many simple API and feature improvements</li>\n      <li>Array computing libraries need protocols to share data and functionality</li>\n      <li>Deep learning libraries have functionality, but don’t share functionality easily</li>\n      <li>Deploying Dask on multi-GPU systems can be improved</li>\n      <li>Python needs better access to high performance communication libraries</li>\n    </ul>\n  </li>\n</ul>\n\n<p>This is just my personal experience which, let me be clear, is only limited to\na few days.  I’m probably wrong about many topics I discuss below.</p>\n\n<h2 id=\"not-everyone-has-a-gpu\">Not everyone has a GPU</h2>\n\n<p>GPUs can be expensive and hard to put into consumer laptops,\nso there is a simple availability problem.  Most people can’t just crack open a\nlaptop, start IPython or a Jupyter notebook, and try something out immediately.</p>\n\n<p>However, most data scientists, actual scientists, and students that I run into\ntoday do have some access to GPU resources through their institution.  Many\ncompanies, labs, and universities today have purchased a GPU cluster that, more\noften than not, sits under-utilized.  These are often an <code class=\"language-plaintext highlighter-rouge\">ssh</code> command away,\nand generally available.</p>\n\n<p>Two weeks ago I visited with Joe Hamman, a scientific collaborator at NCAR and\nUW eScience institute and he said “Oh yeah, we have a GPU cluster at work that\nI never use”.  About 20 minutes later he had a GPU stack installed and was\nrunning an experiment very much like what we did above.</p>\n\n<h2 id=\"installing-cuda-enabled-libraries-is-complicated-by-drivers\">Installing CUDA-enabled libraries is complicated by drivers</h2>\n\n<p>Before conda packages, wheels, Anaconda, and conda forge, installing the PyData\nsoftware stack (Numpy, Pandas, Scikit-Learn, Matplotlib) was challenging.  This\nwas because users had to match a combination of system libraries, compiler\nstacks, and Python packages.  “Oh, you’re on Mac?  First brew install X, then\nmake sure you have <code class=\"language-plaintext highlighter-rouge\">gfortran</code>, then <code class=\"language-plaintext highlighter-rouge\">pip install scipy</code>”</p>\n\n<p>The ecosystem solved this pain by bringing the entire stack under the single\numbrella of conda where everything could be managed consistently, or\nalternatively was greatly diminished with pip wheels.</p>\n\n<p>Unfortunately, CUDA drivers have to be managed on the system side, so we’re\nback to matching system libraries with Python libraries, depending on what CUDA\nversion you’re using.</p>\n\n<p>Here are PyTorch’s installation instructions as an example:</p>\n\n<ul>\n  <li><strong>CUDA 8.0:</strong> <code class=\"language-plaintext highlighter-rouge\">conda install pytorch torchvision cuda80 -c pytorch</code></li>\n  <li><strong>CUDA 9.2:</strong> <code class=\"language-plaintext highlighter-rouge\">conda install pytorch torchvision -c pytorch</code></li>\n  <li><strong>CUDA 10.0:</strong> <code class=\"language-plaintext highlighter-rouge\">conda install pytorch torchvision cuda100 -c pytorch</code></li>\n  <li><strong>No CUDA:</strong> <code class=\"language-plaintext highlighter-rouge\">conda install pytorch-cpu torchvision-cpu -c pytorch</code></li>\n</ul>\n\n<p>Additionally, these conventions differ from the conventions used by\nAnaconda’s packaging of TensorFlow and NVIDIA’s packaging of RAPIDS.  This\ninconsistency in convention makes it unlikely that a novice user will get a\nworking system if they don’t do some research ahead of time.  PyData survives\nby courting non-expert computer users (they’re often experts in some other\nfield) so this is a challenge.</p>\n\n<p>There is some work happening in Conda that can help with this in the future.\nRegardless, we will need to develop better shared conventions between the\ndifferent Python GPU development groups.</p>\n\n<h2 id=\"no-community-standard-build-infrastructure-exists\">No community standard build infrastructure exists</h2>\n\n<p>After speaking about this with <a href=\"https://github.com/jakirkham\">John Kirkham</a>\n(Conda Forge maintainer), he suggested that the situation is also a bit like\nthe conda ecosystem before conda-forge, where everyone built their own packages\nhowever they liked and uploaded them to anaconda.org without agreeing on a\ncommon build environment.  As much of the scientific community knows, this\ninconsistency can lead to a fragmented stack, where certain families of\npackages work well only with certain packages within their family.</p>\n\n<h2 id=\"development-teams-are-fragmented-across-companies\">Development teams are fragmented across companies</h2>\n\n<p>Many of the large GPU-enabled packages are being developed by large teams\nwithin private institutions.  There isn’t a strong culture of cross-team\ncollaboration.</p>\n\n<p>After working with the RAPIDS team at NVIDIA for a week my sense is that this\nis only due to being unaware of how to act, and not any nefarious purpose (or\nthey were very good at hiding that nefarious purpose).  I suspect that the\nbroader community will be able to bring these groups more into the open quickly\nif they engage.</p>\n\n<h2 id=\"rapids-and-dask-need-specific-attention\">RAPIDS and Dask need specific attention</h2>\n\n<p>Now we switch and discuss technical issues in the RAPIDS stack,\nand Dask’s engagement with GPUs generally.\nThis will be lower-level,\nbut shows the kinds of things that I hope to work on technically over the coming months.</p>\n\n<p>Generally the goal of RAPIDS is to build a data science stack around\nconventional numeric computation that mimics the PyData/SciPy stack.  They\nseem to be targeting libraries like:</p>\n\n<ul>\n  <li>Pandas by building a new library, <a href=\"https://cudf.readthedocs.io/en/latest/\">cuDF</a></li>\n  <li>Scikit-Learn / traditional non-deep machine learning by building a new\nlibrary <a href=\"https://github.com/rapidsai/cuml\">cuML</a></li>\n  <li>Numpy by leveraging existing libraries like CuPy, PyTorch, TensorFlow,\nand focusing on improving interoperation within the ecosystem</li>\n</ul>\n\n<p>Driven by the standard collection  of scientific/data centric applications like\nimaging, earth science, ETL, finance, and so on.</p>\n\n<p>Now lets talk about the current challenges for those systems.  In general, none\nof this stack is yet mature (except for the array-computing-in-deep-learning\ncase).</p>\n\n<h2 id=\"cudf-is-missing-pandas-functionality\">cuDF is missing Pandas functionality</h2>\n\n<p>When I showed cuDF at the top of this post,\nI ran the following computations, which ran 30-40x as fast as Pandas..</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">gdf</span><span class=\"p\">.</span><span class=\"n\">x</span><span class=\"p\">.</span><span class=\"n\">mean</span><span class=\"p\">()</span>\n<span class=\"n\">gdf</span><span class=\"p\">.</span><span class=\"n\">groupby</span><span class=\"p\">(</span><span class=\"s\">'y'</span><span class=\"p\">).</span><span class=\"n\">mean</span><span class=\"p\">()</span>\n<span class=\"n\">gdf</span><span class=\"p\">.</span><span class=\"n\">merge</span><span class=\"p\">(</span><span class=\"n\">gdf</span><span class=\"p\">,</span> <span class=\"n\">on</span><span class=\"o\">=</span><span class=\"s\">'y'</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p>What I <em>failed</em> to show was that many operations erred.\nThe cuDF library has great promise, but still needs work filling out the Pandas\nAPI.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\"># There are many holes in the cuDF API\n</span><span class=\"n\">cudf</span><span class=\"p\">.</span><span class=\"n\">read_csv</span><span class=\"p\">(...)</span>      <span class=\"c1\"># works\n</span><span class=\"n\">cudf</span><span class=\"p\">.</span><span class=\"n\">read_parquet</span><span class=\"p\">(...)</span>  <span class=\"c1\"># fails if compression is present\n</span>\n<span class=\"n\">df</span><span class=\"p\">.</span><span class=\"n\">x</span><span class=\"p\">.</span><span class=\"n\">mean</span><span class=\"p\">()</span>  <span class=\"c1\"># works\n</span><span class=\"n\">df</span><span class=\"p\">.</span><span class=\"n\">mean</span><span class=\"p\">()</span>    <span class=\"c1\"># fails\n</span>\n<span class=\"n\">df</span><span class=\"p\">.</span><span class=\"n\">groupby</span><span class=\"p\">(</span><span class=\"s\">'id'</span><span class=\"p\">).</span><span class=\"n\">mean</span><span class=\"p\">()</span>     <span class=\"c1\"># works\n</span><span class=\"n\">df</span><span class=\"p\">.</span><span class=\"n\">groupby</span><span class=\"p\">(</span><span class=\"s\">'id'</span><span class=\"p\">).</span><span class=\"n\">x</span><span class=\"p\">.</span><span class=\"n\">mean</span><span class=\"p\">()</span>   <span class=\"c1\"># fails\n</span><span class=\"n\">df</span><span class=\"p\">.</span><span class=\"n\">x</span><span class=\"p\">.</span><span class=\"n\">groupby</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">.</span><span class=\"nb\">id</span><span class=\"p\">).</span><span class=\"n\">mean</span><span class=\"p\">()</span>  <span class=\"c1\"># fails\n</span></code></pre></div></div>\n\n<p>Fortunately, this work is happening quickly\n(<a href=\"https://github.com/rapidsai/cudf/issues\">GitHub issues</a> seem to turn quickly into PRs)\nand is mostly straightforward on the Python side.\nThis is a good opportunity for community members who are looking to have a quick impact.\nThere are lots of low-hanging fruit.</p>\n\n<p>Additionally, there are areas where the cudf semantics don’t match Pandas\nsemantics.  In general this is fine (not everyone loves Pandas semantics) but\nit makes it difficult as we try to wrap Dask Dataframe around cuDF.  We would\nlike to grow Dask Dataframe so that it can accept Pandas-<em>like</em> dataframes and\nso then get out-of-core GPU dataframes on a single node, and distributed GPU\ndataframes on multi-GPU or multi-node, and we would like to grow cudf so that\nit can fit into this expectation.</p>\n\n<p>This work has to happen both at the low-level C++/CUDA code, and also at the\nPython level.  The sense I get is that NVIDIA has a ton of people available at\nthe CUDA level, but only a few (very good) people at the Python level who are\nworking to keep up (come help!).</p>\n\n<h2 id=\"array-computing-is-robust-but-fragmented\">Array computing is robust, but fragmented</h2>\n\n<p>The Numpy experience is much smoother, mostly because of the excitement\naround deep learning over the last few years.  Many large tech companies have\nmade their own deep learning framework, each of which contains a partial clone\nof the Numpy API.  These include libraries like TensorFlow, PyTorch,\nChainer/CuPy, and others.</p>\n\n<p>This is great because these libraries provide high quality functionality to\nchoose from, but is also painful because the ecosystem is heavily fragmented.\nData allocated with TensorFlow can’t be computed on with Numba or CuPy\noperations.</p>\n\n<p>We can help to heal this rift with a few technical approaches:</p>\n\n<ul>\n  <li>\n    <p>A standard to communicate low-level information about GPU arrays\nbetween frameworks.  This would include information about an array like a\ndevice memory pointer, datatype, shape, strides, and so on, similar to what\nis in the Python buffer protocol today.</p>\n\n    <p>This would allow people to allocate an array with one framework, but then\nuse computational operations defined in another framework.</p>\n\n    <p>The Numba team prototyped something like this a few months ago, and the\nCuPy team seemed happy enough with it.\nSee <a href=\"https://github.com/cupy/cupy/pull/1144\">cupy/cupy #1144</a></p>\n\n    <div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">@</span><span class=\"nb\">property</span>\n<span class=\"k\">def</span> <span class=\"nf\">__cuda_array_interface__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n    <span class=\"n\">desc</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n        <span class=\"s\">'shape'</span><span class=\"p\">:</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">shape</span><span class=\"p\">,</span>\n        <span class=\"s\">'typestr'</span><span class=\"p\">:</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">dtype</span><span class=\"p\">.</span><span class=\"nb\">str</span><span class=\"p\">,</span>\n        <span class=\"s\">'descr'</span><span class=\"p\">:</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">dtype</span><span class=\"p\">.</span><span class=\"n\">descr</span><span class=\"p\">,</span>\n        <span class=\"s\">'data'</span><span class=\"p\">:</span> <span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">data</span><span class=\"p\">.</span><span class=\"n\">mem</span><span class=\"p\">.</span><span class=\"n\">ptr</span><span class=\"p\">,</span> <span class=\"bp\">False</span><span class=\"p\">),</span>\n        <span class=\"s\">'version'</span><span class=\"p\">:</span> <span class=\"mi\">0</span><span class=\"p\">,</span>\n    <span class=\"p\">}</span>\n    <span class=\"k\">if</span> <span class=\"ow\">not</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">_c_contiguous</span><span class=\"p\">:</span>\n        <span class=\"n\">desc</span><span class=\"p\">[</span><span class=\"s\">'strides'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">_strides</span>\n     <span class=\"k\">return</span> <span class=\"n\">desc</span>\n</code></pre></div>    </div>\n\n    <p>This was also, I believe, accepted into PyTorch.</p>\n  </li>\n  <li>\n    <p>A standard way for developers to write backend-agnostic array code.\nCurrently my favorite approach is to use Numpy functions as a lingua\nfranca, and to allow the frameworks to hijack those functions and interpret\nthem as they will.</p>\n\n    <p>This was proposed and accepted within Numpy itself in\n<a href=\"https://www.numpy.org/neps/nep-0018-array-function-protocol.html\">NEP-0018</a>\nand has been pushed forward by people like Stephan Hoyer, Hameer Abbasi,\nMarten van Kerkwijk, and Eric Wieser.</p>\n\n    <p>This is also useful for other array libraries, like pydata/sparse and dask\narray, and would go a long way towards unifying operations with libraries\nlike XArray.</p>\n  </li>\n</ul>\n\n<h2 id=\"cuml-needs-features-scikit-learn-needs-datastructure-agnosticism\">cuML needs features, Scikit-Learn needs datastructure agnosticism</h2>\n\n<p>While deep learning on the GPU is commonplace today, more traditional\nalgorithms like GLMs, random forests, preprocessing and so on haven’t received\nthe same thorough treatment.</p>\n\n<p>Fortunately the ecosystem is well prepared to accept work in this space,\nlargely because Scikit Learn established a simple pluggable API early on.\nBuilding new estimators in external libraries that connect to the ecosystem\nwell is straightforward.</p>\n\n<p>We should be able to build isolated estimators that can be dropped into\nexisting workflows piece by piece, leveraging the existing infrastructure\nwithin other Scikit-Learn-compatible projects.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\"># This code is aspirational\n</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sklearn.model_selection</span> <span class=\"kn\">import</span> <span class=\"n\">RandomSearchCV</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sklearn.pipeline</span> <span class=\"kn\">import</span> <span class=\"n\">make_pipeline</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sklearn.feature_extraction.text</span> <span class=\"kn\">import</span> <span class=\"n\">TfidfTransformer</span>\n\n<span class=\"c1\"># from sklearn.feature_extraction.text import HashingVectorizer\n</span><span class=\"kn\">from</span> <span class=\"nn\">cuml.feature_extraction.text</span> <span class=\"kn\">import</span> <span class=\"n\">HashingVectorizer</span>  <span class=\"c1\"># swap out for GPU versions\n</span>\n<span class=\"c1\"># from sklearn.linear_model import LogisticRegression, RandomForest\n</span><span class=\"kn\">from</span> <span class=\"nn\">cuml.linear_model</span> <span class=\"kn\">import</span> <span class=\"n\">LogisticRegression</span><span class=\"p\">,</span> <span class=\"n\">RandomForest</span>\n\n<span class=\"n\">pipeline</span> <span class=\"o\">=</span> <span class=\"n\">make_pipeline</span><span class=\"p\">([</span><span class=\"n\">HashingVectorizer</span><span class=\"p\">(),</span>  <span class=\"c1\"># use Scikit-Learn infrastructure\n</span>                          <span class=\"n\">TfidfTransformer</span><span class=\"p\">(),</span>\n                          <span class=\"n\">LogisticRegression</span><span class=\"p\">()])</span>\n\n<span class=\"n\">RandomSearchCV</span><span class=\"p\">(</span><span class=\"n\">pipeline</span><span class=\"p\">).</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">labels</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p><em>Note, the example above is aspirational (that cuml code doesn’t exist yet) and\nprobably naive (I don’t know ML well).</em></p>\n\n<p>However, aside from the straightforward task of building these GPU-enabled\nestimators (which seems to be routine for the CUDA developers at NVIDIA) there\nare still challenges around cleanly passing non-Numpy arrays around, coercing\nonly when necessary, and so on that we’ll need to work out within Scikit-Learn.</p>\n\n<p>Fortunately this work has already started because of Dask Array, which has the\nsame problem.  The Dask and Scikit-Learn communities have been collaborating to\nbetter enable pluggability over the last year.  Hopefully this additional use\ncase proceeds along these existing efforts, but now with more support.</p>\n\n<h2 id=\"deep-learning-frameworks-are-overly-specialized\">Deep learning frameworks are overly specialized</h2>\n\n<p>The SciPy/PyData stack thrived because it was modular and adaptable to new\nsituations.\nThere are many small issues around integrating components of the deep learning\nframeworks into the more general ecosystem.</p>\n\n<p>We went through a similar experience with Dask early on, when the Python\necosystem wasn’t ready for parallel computing.  As Dask expanded we ran into\nmany small issues around parallel computing that hadn’t been addressed before\nbecause, for the most part, few people used Python for parallelism at the time.</p>\n\n<ul>\n  <li>Various libraries didn’t release the GIL (thanks for the work Pandas, Scikit-Image, and others!)</li>\n  <li>Various libraries weren’t threadsafe in some cases (like h5py, and even Scikit-Learn in one case)</li>\n  <li>Function serialization still needed work (thanks <code class=\"language-plaintext highlighter-rouge\">cloudpickle</code> developers!)</li>\n  <li>Compression libraries were unmaintained (like LZ4)</li>\n  <li>Networking libraries weren’t used to high bandwidth workloads (thanks Tornado devs!)</li>\n</ul>\n\n<p>These issues were fixed by a combination of Dask developers and\nthe broader community (it’s amazing what people will do if you provide a\nwell-scoped and well-described problem on GitHub).  These libraries were\ndesigned to be used with other libraries, and so they were well incentivized to\nimprove their usability by the broader ecosystem.</p>\n\n<p>Today deep learning frameworks have these same problems.  They rarely serialize\nwell, aren’t threadsafe when called by external threads, and so on.  This is to\nbe expected, most people using a tool like TensorFlow or PyTorch are\noperating almost entirely within those frameworks.  These projects aren’t being\nstressed against the rest of the ecossytem (no one puts PyTorch arrays as\ncolumns in Pandas, or pickles them to send across a wire).  Taking tools that\nwere designed for narrow workflows and encouraging them towards general\npurpose collaboration takes time and effort, both technically and socially.</p>\n\n<p>The non-deep-learning OSS community has not yet made a strong effort to engage\nthe deep-learning developer communities.  This should be an interesting social\nexperiment between two different of dev cultures.  I suspect that these\ndifferent groups have different styles and can learn from each other.</p>\n\n<p><em>Note: Chainer/CuPy is a notable exception here.  The Chainer library (another\ndeep learning framework) explicitly separates its array library, CuPy, which\nmakes it easier to deal with.  This, combined with a strict adherence to the\nNumpy API, is probably why they’ve been the early target for most ongoing\nPython OSS interactions.</em></p>\n\n<h2 id=\"dask-needs-convenience-scripts-for-gpu-deployment\">Dask needs convenience scripts for GPU deployment</h2>\n\n<p>On high-end systems it is common to have several GPUs on a single machine.\nProgramming across these GPUs is challenging because you need to think about\ndata locality, load balancing, and so on.</p>\n\n<p>Dask is well-positioned to handle this for users.  However, most people using\nDask and GPUs today have a complex setup script that includes a combination of\nenvironment variables, <code class=\"language-plaintext highlighter-rouge\">dask-worker</code> calls, additional calls to CUDA profiling\nutilities, and so on.  We should make a simple <code class=\"language-plaintext highlighter-rouge\">LocalGPUCluster</code> Python\nobject that people can easily call within a local script, similar to how they\ndo today for <code class=\"language-plaintext highlighter-rouge\">LocalCluster</code>.</p>\n\n<p>Additionally, this problem applies to the multi-gpu-multi-node case, and will\nrequire us to be creative with the existing distributed\ndeployment solutions\n(like <a href=\"https://kubernetes.dask.org\">dask-kubernetes</a>,\n<a href=\"https://yarn.dask.org\">dask-yarn</a>,\nand <a href=\"https://jobqueue.dask.org\">dask-jobqueue</a>).\nOf course, adding complexity like this without significantly impacting the\nnon-GPU case and adding to community maintenance costs will be an interesting\nchallenge, and will require creativity.</p>\n\n<h2 id=\"python-needs-high-performance-communication-libraries\">Python needs High Performance Communication libraries</h2>\n\n<p>High-end GPU systems often use high-end networking.  This is especially\nimportant when our compute times drop significantly because communication time\nmay quickly become our new bottleneck if we reduce computation time with GPUs.</p>\n\n<p>Last year Antoine worked to improve Tornado’s handling of high-bandwidth\nconnections to get about 1GB/s per process on Infiniband networks from Python.\nWe may need to go well above this, both for Infiniband and for more exotic\nnetworking solutions.  In particular NVIDIA has systems that support efficient\ntransfer directly between GPU devices without going through host memory.</p>\n\n<p>There is already work here that we can leverage.\nThe <a href=\"http://www.openucx.org/\">OpenUCX</a> project offloads exotic networking\nsolutions (like Infiniband) to a uniform API.  They’re now working to provide a\nPython accessible API that we can then then connect to Dask.  This is good\nalso for Dask-CPU users because Infiniband connections will become more\nefficient (HPC users rejoice) and also for the general Python HPC community,\nwhich will finally have a reasonable Python API for high performance\nnetworking.  This work currently targets the Asyncio event loop.</p>\n\n<p><em>As an aside, this is the kind of work I’d like to see coming out of NVIDIA\n(and other large technology companies) in the future.  It helps to connect\nPython users to their specific hardware yes, but also helps lots of other\nsystems and provides general infrastructure applicable across the community at\nthe same time.</em></p>\n\n<h2 id=\"come-help\">Come help!</h2>\n\n<p>This post started with the promise of 5-50x speed improvements (at least for\ncomputation), and then outlined many of the challenges to getting there.  These\nchallenges are serious, but also mostly straightforward technical and social\nengineering problems.  There is a lot of basic work with a high potential\npayoff.</p>\n\n<p>NVIDIA’s plan to build a GPU-compatible data science stack seems ambitious, but\nthey seem to be treating the problem seriously, and seem willing to put\nresources and company focus behind the problem.</p>\n\n<p>If any of the work above sounds interesting to you please engage either as an\n…</p>\n\n<ul>\n  <li>\n    <p><strong>Individual</strong>: either as an open source contributor (RAPIDS is Apache 2.0\nlicensed and seems to be operating as a normal OSS project on GitHub) or as\nan employee\n(see active <a href=\"https://nvidia.wd5.myworkdayjobs.com/en-US/NVIDIAExternalCareerSite/job/US-TX-Austin/Senior-Library-Software-Engineer---RAPIDS_JR1919608-1\">job postings</a>.  The team is currently remotely distributed.).</p>\n\n    <p>There is lots of exciting work to do here.</p>\n\n    <p>.. or as an …</p>\n  </li>\n  <li>\n    <p><strong>Institution</strong>: You may already have both an under-utilized cluster of GPUs\nwithin your institution, and also large teams of data scientists familiar\nwith the Python but unfamiliar with CUDA.  NVIDIA seems eager to find\npartners who are interested in mutual arrangements to build out\nfunctionality for specific domains.  Please reach out if this sounds\nfamiliar.</p>\n  </li>\n</ul>"
}