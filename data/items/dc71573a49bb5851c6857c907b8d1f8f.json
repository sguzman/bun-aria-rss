{
  "title": "Into and Remote Data",
  "link": "",
  "updated": "2015-02-11T00:00:00+00:00",
  "id": "https://mrocklin.github.io/blog/work/2015/02/11/Into-Remote",
  "content": "<p><strong>tl;dr <code class=\"language-plaintext highlighter-rouge\">into</code> now handles data on remote machines, including HDFS and the Hive\nMetastore (kinda).</strong></p>\n\n<h2 id=\"motivation\">Motivation</h2>\n\n<p><a href=\"https://mrocklin.github.io/blog/work/2015/02/03/Into/\">Last week</a> I wrote about\n<a href=\"http://into.readthedocs.org\"><code class=\"language-plaintext highlighter-rouge\">into</code></a>, a library to migrate data between\nformats.  We saw that a network of pairwise data conversions can robustly\nmigrate data, eliminating some of the frustration of data science.</p>\n\n<p>This frustration compounds when data lives on other computers or distributed\nfile systems like HDFS.  Moving data from your local machine into something\nlike the Hive metastore often requires several steps.</p>\n\n<ol>\n  <li><code class=\"language-plaintext highlighter-rouge\">scp</code> data to cluster</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">hadoop fs -cp</code> data to HDFS</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">CREATE TABLE</code> in Hive/Impala to register data with metastore</li>\n  <li>Write SQL queries</li>\n</ol>\n\n<p>While each of these steps may be relatively straightforward, their combination\ncan be daunting to the casual analyst.</p>\n\n<p><a href=\"http://into.readthedocs.org/en/latest/_images/hdfs.png\">\n    <img src=\"http://into.readthedocs.org/en/latest/_images/hdfs.png\" align=\"right\" width=\"50%\" /></a></p>\n\n<h2 id=\"remote-data-and-into\">Remote data and into</h2>\n\n<p>So we took this as a case study and extended the <code class=\"language-plaintext highlighter-rouge\">into</code> network appropriately.\nWe integrate the following libraries and protocols</p>\n\n<ul>\n  <li><code class=\"language-plaintext highlighter-rouge\">ssh://hostname:myfile.csv</code> accesses data on remote machines through <code class=\"language-plaintext highlighter-rouge\">paramiko</code></li>\n  <li><code class=\"language-plaintext highlighter-rouge\">hdfs://hostname:myfile.csv</code> accesses data on the Hadoop distributed file\n system through WebHDFS using the <code class=\"language-plaintext highlighter-rouge\">pywebhdfs</code> library</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">hive://hostname::tablename</code> accesses data on the Hive Metastore using a\n combination of SQLAlchemy and hand crafted <code class=\"language-plaintext highlighter-rouge\">CREATE TABLE</code> / <code class=\"language-plaintext highlighter-rouge\">LOAD</code>\n statements</li>\n</ul>\n\n<h2 id=\"ssh\">SSH</h2>\n\n<p><code class=\"language-plaintext highlighter-rouge\">into</code> is now a fancy <code class=\"language-plaintext highlighter-rouge\">scp</code>.</p>\n\n<figure class=\"highlight\">\n  <pre><code class=\"language-python\" data-lang=\"python\"><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">auth</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s\">'username'</span><span class=\"p\">:</span> <span class=\"s\">'alice'</span><span class=\"p\">,</span>\n<span class=\"p\">...</span>         <span class=\"s\">'key_filename'</span><span class=\"p\">:</span> <span class=\"s\">'.ssh/id_rsa'</span><span class=\"p\">}</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">into</span><span class=\"p\">(</span><span class=\"s\">'ssh://hostname:myfile.csv'</span><span class=\"p\">,</span> <span class=\"s\">'myfile.csv'</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">auth</span><span class=\"p\">)</span>   <span class=\"c1\"># Move local file\n</span><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">into</span><span class=\"p\">(</span><span class=\"s\">'ssh://hostname:myfile.csv'</span><span class=\"p\">,</span> <span class=\"s\">'myfile.json'</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">auth</span><span class=\"p\">)</span>  <span class=\"c1\"># Move local file</span></code></pre>\n</figure>\n\n<p>Because we’re connected to the network, lots of other things work too.</p>\n\n<figure class=\"highlight\">\n  <pre><code class=\"language-python\" data-lang=\"python\"><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">into</span><span class=\"p\">(</span><span class=\"n\">pd</span><span class=\"p\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">,</span> <span class=\"s\">'ssh://hostname:myfile.json'</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">auth</span><span class=\"p\">)</span></code></pre>\n</figure>\n\n<p>Note that we’re not calling any code on the remote machine so fancy conversions\nalways happen locally.</p>\n\n<p>If you’d like to use ssh generally you might want to take a look at\n<a href=\"http://www.paramiko.org/\">Paramiko</a> which is really doing all of the heavy\nlifting here.</p>\n\n<h2 id=\"hdfs\">HDFS</h2>\n\n<p>WebHDFS is a web interface to the Hadoop File System.  It is surprisingly high\nperformance (I often erroneously think of HTTP as slow) but isn’t always turned\non in every instance.  If it is then you should be able to transfer data in and\nout easily, just as we did for <code class=\"language-plaintext highlighter-rouge\">SSH</code></p>\n\n<figure class=\"highlight\">\n  <pre><code class=\"language-python\" data-lang=\"python\"><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">auth</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s\">'user'</span><span class=\"p\">:</span> <span class=\"s\">'hdfs'</span><span class=\"p\">,</span>\n<span class=\"p\">...</span>         <span class=\"s\">'port'</span><span class=\"p\">:</span> <span class=\"s\">'14000'</span><span class=\"p\">}</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">into</span><span class=\"p\">(</span><span class=\"s\">'hdfs://hostname:myfile.csv'</span><span class=\"p\">,</span> <span class=\"s\">'myfile.csv'</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">auth</span><span class=\"p\">)</span></code></pre>\n</figure>\n\n<h2 id=\"hive\">Hive</h2>\n\n<p>The interesting piece comes when we come to Hive, which, in <code class=\"language-plaintext highlighter-rouge\">into</code> parlance\nexpects one of the following kinds of data:</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>ssh://single-file.csv\nssh://directory-of-files/*.csv\nhdfs://directory-of-files/*.csv\n</code></pre></div></div>\n\n<p>And so we build these routes, enabling operations like the following:</p>\n\n<figure class=\"highlight\">\n  <pre><code class=\"language-python\" data-lang=\"python\"><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">into</span><span class=\"p\">(</span><span class=\"s\">'hive://hostname/default::mytable'</span><span class=\"p\">,</span>\n<span class=\"p\">...</span>      <span class=\"s\">'ssh://hostname:myfile.csv'</span> <span class=\"o\">**</span><span class=\"n\">auth</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">into</span><span class=\"p\">(</span><span class=\"s\">'hive://hostname/default::mytable'</span><span class=\"p\">,</span>\n<span class=\"p\">...</span>      <span class=\"s\">'ssh://hostname:mydata/*.csv'</span> <span class=\"o\">**</span><span class=\"n\">auth</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">into</span><span class=\"p\">(</span><span class=\"s\">'hive://hostname/default::mytable'</span><span class=\"p\">,</span>\n<span class=\"p\">...</span>      <span class=\"s\">'hdfs://hostname:mydata/*.csv'</span> <span class=\"o\">**</span><span class=\"n\">auth</span><span class=\"p\">)</span></code></pre>\n</figure>\n\n<p>But Hive is also a bit finicky.\n<a href=\"http://continuum.io/open-source/blaze/\">Blaze</a> uses the\n<a href=\"https://github.com/dropbox/PyHive/\">PyHive</a> sqlalchemy dialect to query Hive\ntables; unfortunately the way Hive works we need to create them by hand.  Hive\nis different from most databases in that it doesn’t have an internal format.\nInstead, it represents tables as directories of CSV files (or other things).\nThis distinction mucks up <code class=\"language-plaintext highlighter-rouge\">into</code>’s approach a bit but things work ok in normal\nsituations.</p>\n\n<h2 id=\"lessons-learned\">Lessons Learned</h2>\n\n<p>We had to add a couple new ideas to <code class=\"language-plaintext highlighter-rouge\">into</code> to expand out to these systems.</p>\n\n<h3 id=\"type-modifiers\">Type Modifiers</h3>\n\n<p>First, we needed a way to refer to different variants of the same format of\nfile.  For example, for CSV files we now have the following variants</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>A local CSV file\nA CSV file accessible through HDFS\nA CSV file accessible through SSH\nA directory of CSV files\nA directory of CSV files on HDFS\n...\n</code></pre></div></div>\n\n<p>And the same for JSON, text, etc..  Into decides what conversion functions to\nrun based on the type of the data, so in principle we need subclasses for all\ncombinations of format and location.  Yuck.</p>\n\n<p>To solve this problem we create functions, <code class=\"language-plaintext highlighter-rouge\">SSH, HDFS, Directory</code> to create\nsubclasses, we call these <em>type modifiers</em>.  So <code class=\"language-plaintext highlighter-rouge\">SSH(CSV)</code> is a new type that\nacts like a CSV file and like the hidden <code class=\"language-plaintext highlighter-rouge\">_SSH</code> superclass.</p>\n\n<figure class=\"highlight\">\n  <pre><code class=\"language-python\" data-lang=\"python\"><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">SSH</span><span class=\"p\">(</span><span class=\"n\">CSV</span><span class=\"p\">)(</span><span class=\"s\">'/path/to/data'</span><span class=\"p\">,</span> <span class=\"n\">delimiter</span><span class=\"o\">=</span><span class=\"s\">','</span><span class=\"p\">,</span> <span class=\"n\">hostname</span><span class=\"o\">=</span><span class=\"s\">'54.131.11.43'</span><span class=\"p\">,</span> <span class=\"n\">user</span><span class=\"o\">=</span><span class=\"s\">'ubuntu'</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">Directory</span><span class=\"p\">(</span><span class=\"n\">JSON</span><span class=\"p\">)(</span><span class=\"s\">'/path/to/data/'</span><span class=\"p\">)</span></code></pre>\n</figure>\n\n<p>Note that users don’t usually see these (unless they want to be explicit) they\nusually interact with uri strings.</p>\n\n<h3 id=\"temporary-files\">Temporary files</h3>\n\n<p>Second, we need a way to route through temporary files.  E.g. consider the\nfollowing route:</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>SSH(CSV) -&gt; CSV -&gt; pd.DataFrame\n</code></pre></div></div>\n\n<p>Both steps of this path are easy given <code class=\"language-plaintext highlighter-rouge\">paramiko</code> and <code class=\"language-plaintext highlighter-rouge\">pandas</code>.  However we\ndon’t want the intermediate CSV file to hang around (users would hate us if we\nslowly filled up their <code class=\"language-plaintext highlighter-rouge\">/tmp</code> folder.)  We need to clean it up when we’re done.</p>\n\n<p>To solve this problem, we introduce a new type modifier, <code class=\"language-plaintext highlighter-rouge\">Temp</code>, that <code class=\"language-plaintext highlighter-rouge\">drop</code>s\nitself on garbage collection (<code class=\"language-plaintext highlighter-rouge\">drop</code> is another magic function in <code class=\"language-plaintext highlighter-rouge\">into</code>, <a href=\"http://into.readthedocs.org/en/latest/drop.html\">see\ndocs</a>).  This lets us tie the\nPython garbage collector to persistent data outside of the Python process.\nIt’s not fool-proof, but it is pretty effective.</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>SSH(CSV) -&gt; Temp(CSV) -&gt; pd.DataFrame\n</code></pre></div></div>\n\n<p>This is also a good example of how we build type modifiers.  You can safely\nignore the following code:</p>\n\n<figure class=\"highlight\">\n  <pre><code class=\"language-python\" data-lang=\"python\"><span class=\"k\">class</span> <span class=\"nc\">_Temp</span><span class=\"p\">(</span><span class=\"nb\">object</span><span class=\"p\">):</span>\n    <span class=\"s\">\"\"\" Temporary version of persistent storage\n\n    &gt;&gt;&gt; from into import Temp, CSV\n    &gt;&gt;&gt; csv = Temp(CSV)('/tmp/myfile.csv', delimiter=',')\n    \"\"\"</span>\n    <span class=\"k\">def</span> <span class=\"nf\">__del__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"n\">drop</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">)</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">Temp</span><span class=\"p\">(</span><span class=\"n\">cls</span><span class=\"p\">):</span>\n    <span class=\"k\">return</span> <span class=\"nb\">type</span><span class=\"p\">(</span><span class=\"s\">'Temp(%s)'</span> <span class=\"o\">%</span> <span class=\"n\">cls</span><span class=\"p\">.</span><span class=\"n\">__name__</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">_Temp</span><span class=\"p\">,</span> <span class=\"n\">cls</span><span class=\"p\">),</span> <span class=\"p\">{</span><span class=\"s\">'persistent_type'</span><span class=\"p\">:</span> <span class=\"n\">cls</span><span class=\"p\">})</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">toolz</span> <span class=\"kn\">import</span> <span class=\"n\">memoize</span>\n<span class=\"n\">Temp</span><span class=\"p\">.</span><span class=\"n\">__doc__</span> <span class=\"o\">=</span> <span class=\"n\">_Temp</span><span class=\"p\">.</span><span class=\"n\">__doc__</span>\n<span class=\"n\">Temp</span> <span class=\"o\">=</span> <span class=\"n\">memoize</span><span class=\"p\">(</span><span class=\"n\">Temp</span><span class=\"p\">)</span></code></pre>\n</figure>\n\n<p>I won’t be surprised if this approach concerns a few people but I’ve found it to\nbe effective so far.</p>\n\n<h3 id=\"keyword-arguments\">Keyword Arguments</h3>\n\n<p>The number of possible keyword arguments to a single <code class=\"language-plaintext highlighter-rouge\">into</code> call is increasing.\nWe don’t have a good mechanism to help users discover the valid options for\ntheir situation.  Docstrings are hard here because the options depend on the\nsource and target inputs.  For the moment we’re solving this with <a href=\"http://into.readthedocs.org\">online\ndocumentation</a> for each complicated format but\nthere is probably a better solution out there.</p>\n\n<h2 id=\"help\">Help!</h2>\n\n<p>The new behavior around <code class=\"language-plaintext highlighter-rouge\">ssh://</code> and <code class=\"language-plaintext highlighter-rouge\">hdfs://</code> and <code class=\"language-plaintext highlighter-rouge\">hive://</code> is new, error\nprone, and could really use play-testing.  I strongly welcome feedback and\nerror reporting here.  You could\n<a href=\"https://github.com/ContinuumIO/into/issues/new\">file an issue</a>\nor e-mail blaze-dev@continuum.io.</p>\n\n<h2 id=\"other\">Other</h2>\n\n<p>I didn’t mention anything about <code class=\"language-plaintext highlighter-rouge\">S3</code> and <code class=\"language-plaintext highlighter-rouge\">RedShift</code> support that was also\nrecently merged.  This is because I think Phil Cloud might write a separate\nblogpost about it.  We did this work in parallel in an effort to hash out how\nbest to solve the problems above.  I think it worked decently well</p>\n\n<p>Also, we’ve added an <code class=\"language-plaintext highlighter-rouge\">into</code> command line interface.  It works just like the\ninto function with strings, except that we’ve reversed the order of the\narguments to be more like <code class=\"language-plaintext highlighter-rouge\">cp</code>.  An example is below:</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>$ into source target --key value --key value --key value\n$ into myfile.csv ssh://hostname:myfile.json --delimter ','\n</code></pre></div></div>\n\n<p>We also have docs!\n<a href=\"http://into.readthedocs.org/en/latest/\">http://into.readthedocs.org/en/latest/</a></p>"
}