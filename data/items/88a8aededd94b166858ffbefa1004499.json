{
  "title": "Getting Started: Adobe Analytics Clickstream Data Feed",
  "description": "<blockquote>\n  <p>“Well, first you need a TMS and a three-tiered data layer, then some jQuery with a node backend to inject customer data into the page asynchronously if you want to avoid cookie-based limitations with cross-domain tracking and be Internet Explorer 4 compatible…”</p>\n</blockquote>",
  "pubDate": "Tue, 04 Aug 2015 09:00:35 +0000",
  "link": "http://randyzwitch.com/adobe-analytics-clickstream-raw-data-feed/",
  "guid": "http://randyzwitch.com/adobe-analytics-clickstream-raw-data-feed/",
  "content": "<blockquote>\n  <p>“Well, first you need a TMS and a three-tiered data layer, then some jQuery with a node backend to inject customer data into the page asynchronously if you want to avoid cookie-based limitations with cross-domain tracking and be Internet Explorer 4 compatible…”</p>\n</blockquote>\n\n<p>Blah Blah Blah. There’s a whole cottage industry around jargon-ing each other to death about digital data collection. But why? Why do we focus on <em>tools</em>, instead of <em>the data</em>? Because the tools are necessarily inflexible, so we work backwards from the pre-defined reports we have to the data needed to populate them correctly. Let’s go the other way for once: clickstream data to analysis &amp; reporting.</p>\n\n<p>In this blog post, I will show the structure of the Adobe Analytics Clickstream Data Feed and how to work with a day worth of data within R. Clickstream data isn’t as raw as pure server logs, but the only limit to what we can calculate from clickstream data is what we can accomplish with a bit of programming and imagination. In later posts, I’ll show how to store a year worth of data in a relational database, storing the same data in Hadoop and doing analysis using modern tools such as Apache Spark.</p>\n\n<p>This blog post will not cover the mechanics of getting the feed delivered via FTP. The <a href=\"https://marketing.adobe.com/resources/help/en_US/sc/clickstream/datafeeds_configure.html\">Adobe Clickstream Feed documentation</a> is sufficiently clear in how to get started.</p>\n\n<h3 id=\"ftpfile-structure\">FTP/File Structure</h3>\n\n<p>Once your Adobe Clickstream Feed starts being delivered via FTP, you’ll have a file listing that looks similar to the following:</p>\n\n<p><img src=\"/wp-content/uploads/2015/07/adobe-clickstream-data-ftp.png\" alt=\"adobe-clickstream-data-ftp\" /></p>\n\n<p>What you’ll notice is that with daily delivery, three files are provided, each having a consistent file naming format:</p>\n\n<ul>\n  <li>\\d+-\\S+_\\d+-\\d+-\\d+.tsv.gz</li>\n</ul>\n\n<p>This is the main file containing the server call level data</p>\n\n<ul>\n  <li>\\S+_\\d+-\\d+-\\d+-lookup_data.tar.gz</li>\n</ul>\n\n<p>These are the lookup tables, header files, etc.</p>\n\n<ul>\n  <li>\\S+_\\d+-\\d+-\\d+.txt</li>\n</ul>\n\n<p>Manifest file, delivered last so that any automated processes know that Adobe is finished transferring</p>\n\n<p>The regular expressions will be unnecessary for working with our single day of data, but it’s good to realize that there is a consistent naming structure.</p>\n\n<h3 id=\"checking-md5-hashes\">Checking md5 hashes</h3>\n\n<p>As part of the manifest file, Adobe provides <a href=\"https://en.wikipedia.org/wiki/MD5\">md5 hashes</a> of the files. There are at least two purposes to this, including 1) making sure that the files truly were delivered in full and 2) that the files haven’t been manipulated/tampered with. In order to check that your md5 hashes match the values provided by Adobe, we can do the following in R:</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-r\" data-lang=\"r\"><table class=\"rouge-table\"><tbody><tr><td class=\"gutter gl\"><pre class=\"lineno\">1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n</pre></td><td class=\"code\"><pre><span class=\"n\">setwd</span><span class=\"p\">(</span><span class=\"s2\">\"~/Downloads/datafeed/\"</span><span class=\"p\">)</span><span class=\"w\">\n\n</span><span class=\"c1\">#Read in Adobe manifest file</span><span class=\"w\">\n</span><span class=\"n\">manifest</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"n\">read.table</span><span class=\"p\">(</span><span class=\"s2\">\"zwitchdev_2015-07-13.txt\"</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">stringsAsFactors</span><span class=\"o\">=</span><span class=\"kc\">FALSE</span><span class=\"p\">)</span><span class=\"w\">\n</span><span class=\"nf\">names</span><span class=\"p\">(</span><span class=\"n\">manifest</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"nf\">c</span><span class=\"p\">(</span><span class=\"s2\">\"key\"</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"s2\">\"value\"</span><span class=\"p\">)</span><span class=\"w\">\n\n</span><span class=\"c1\">#Use digest library to calculate md5 hashes</span><span class=\"w\">\n</span><span class=\"n\">library</span><span class=\"p\">(</span><span class=\"n\">digest</span><span class=\"p\">)</span><span class=\"w\">\n</span><span class=\"n\">servercalls_md5</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"n\">digest</span><span class=\"p\">(</span><span class=\"s2\">\"01-zwitchdev_2015-07-13.tsv.gz\"</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">algo</span><span class=\"o\">=</span><span class=\"s2\">\"md5\"</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">file</span><span class=\"o\">=</span><span class=\"kc\">TRUE</span><span class=\"p\">)</span><span class=\"w\">\n</span><span class=\"n\">lookup_md5</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"n\">digest</span><span class=\"p\">(</span><span class=\"s2\">\"zwitchdev_2015-07-13-lookup_data.tar.gz\"</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">algo</span><span class=\"o\">=</span><span class=\"s2\">\"md5\"</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">file</span><span class=\"o\">=</span><span class=\"kc\">TRUE</span><span class=\"p\">)</span><span class=\"w\">\n\n</span><span class=\"c1\">#Check to see if hashes contained in manifest file</span><span class=\"w\">\n</span><span class=\"n\">servercalls_md5</span><span class=\"w\"> </span><span class=\"o\">%in%</span><span class=\"w\"> </span><span class=\"n\">manifest</span><span class=\"o\">$</span><span class=\"n\">value</span><span class=\"w\"> </span><span class=\"c1\">#[1] TRUE</span><span class=\"w\">\n</span><span class=\"n\">lookup_md5</span><span class=\"w\"> </span><span class=\"o\">%in%</span><span class=\"w\"> </span><span class=\"n\">manifest</span><span class=\"o\">$</span><span class=\"n\">value</span><span class=\"w\"> </span><span class=\"c1\">#[1] TRUE</span>\n</pre></td></tr></tbody></table></code></pre></figure>\n\n<p>As we can see, both calculated hashes are contained within the manifest, so we can be confident that the files we downloaded haven’t been modified.</p>\n\n<h3 id=\"unzipping-and-loading-raw-files-to-data-frames\">Unzipping and Loading Raw Files to Data Frames</h3>\n\n<p>Now that our file hashes are validated, it’s time to load the files into R. For the example files, I would be able to fit the entire day into RAM because my blog does very little traffic. However, I’m going to still limit the rows brought in, as if we were working with a large e-commerce website with millions of visits per day:</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-r\" data-lang=\"r\"><table class=\"rouge-table\"><tbody><tr><td class=\"gutter gl\"><pre class=\"lineno\">1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n</pre></td><td class=\"code\"><pre><span class=\"c1\">#Get list of lookup files from tarball</span><span class=\"w\">\n</span><span class=\"n\">files_tar</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"n\">untar</span><span class=\"p\">(</span><span class=\"s2\">\"zwitchdev_2015-07-13-lookup_data.tar.gz\"</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">list</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"kc\">TRUE</span><span class=\"p\">)</span><span class=\"w\">\n\n</span><span class=\"c1\">#Extract files to _temp directory. Directory will be created if it doesn't exist</span><span class=\"w\">\n</span><span class=\"n\">untar</span><span class=\"p\">(</span><span class=\"s2\">\"zwitchdev_2015-07-13-lookup_data.tar.gz\"</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">exdir</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"s2\">\"_temp\"</span><span class=\"p\">)</span><span class=\"w\">\n\n</span><span class=\"c1\">#Read each file into a data frame</span><span class=\"w\">\n</span><span class=\"c1\">#If coding like this in R offends you, keep it to yourself...</span><span class=\"w\">\n</span><span class=\"k\">for</span><span class=\"w\"> </span><span class=\"p\">(</span><span class=\"n\">file</span><span class=\"w\"> </span><span class=\"k\">in</span><span class=\"w\"> </span><span class=\"n\">files_tar</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\">\n  </span><span class=\"n\">df_name</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"n\">unlist</span><span class=\"p\">(</span><span class=\"n\">strsplit</span><span class=\"p\">(</span><span class=\"n\">file</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">split</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"s2\">\".tsv\"</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">fixed</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"kc\">TRUE</span><span class=\"p\">))</span><span class=\"w\">\n  </span><span class=\"n\">temp_df</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"n\">read.delim</span><span class=\"p\">(</span><span class=\"n\">paste</span><span class=\"p\">(</span><span class=\"s2\">\"_temp\"</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">file</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">sep</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"s2\">\"/\"</span><span class=\"p\">),</span><span class=\"w\"> </span><span class=\"n\">header</span><span class=\"o\">=</span><span class=\"kc\">FALSE</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">stringsAsFactors</span><span class=\"o\">=</span><span class=\"kc\">FALSE</span><span class=\"p\">)</span><span class=\"w\">\n  </span><span class=\"c1\">#column_headers not used as lookup table</span><span class=\"w\">\n  </span><span class=\"k\">if</span><span class=\"w\"> </span><span class=\"p\">(</span><span class=\"n\">df_name</span><span class=\"w\"> </span><span class=\"o\">!=</span><span class=\"w\"> </span><span class=\"s2\">\"column_headers\"</span><span class=\"p\">){</span><span class=\"w\">\n    </span><span class=\"nf\">names</span><span class=\"p\">(</span><span class=\"n\">temp_df</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"nf\">c</span><span class=\"p\">(</span><span class=\"s2\">\"id\"</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">df_name</span><span class=\"p\">)</span><span class=\"w\">\n  </span><span class=\"p\">}</span><span class=\"w\">\n  </span><span class=\"n\">assign</span><span class=\"p\">(</span><span class=\"n\">df_name</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">temp_df</span><span class=\"p\">)</span><span class=\"w\">\n  </span><span class=\"n\">rm</span><span class=\"p\">(</span><span class=\"n\">temp_df</span><span class=\"p\">)</span><span class=\"w\">\n</span><span class=\"p\">}</span><span class=\"w\">\n\n</span><span class=\"c1\">#gz files can be read directly into dataframes from base R</span><span class=\"w\">\n</span><span class=\"c1\">#Could also use `readr` library for performance</span><span class=\"w\">\n</span><span class=\"n\">servercall_data</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"n\">read.delim</span><span class=\"p\">(</span><span class=\"s2\">\"~/Downloads/datafeed/01-zwitchdev_2015-07-13.tsv.gz\"</span><span class=\"p\">,</span><span class=\"w\">\n                       </span><span class=\"n\">header</span><span class=\"o\">=</span><span class=\"kc\">FALSE</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">stringsAsFactors</span><span class=\"o\">=</span><span class=\"kc\">FALSE</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">nrows</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"m\">500</span><span class=\"p\">)</span><span class=\"w\">\n\n</span><span class=\"c1\">#Use column_headers to label servercall_data data frame using first row of data</span><span class=\"w\">\n</span><span class=\"nf\">names</span><span class=\"p\">(</span><span class=\"n\">servercall_data</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"n\">column_headers</span><span class=\"p\">[</span><span class=\"m\">1</span><span class=\"p\">,]</span>\n</pre></td></tr></tbody></table></code></pre></figure>\n\n<p>If we were to be loading this data into a database, we’d be done with our processing; we have all of our data read into R and it would be a trivial exercise to load the data into a database (we’ll do this in a separate blog post). But since we’re going to be analyze this single day of clickstream data, we need to join these 14 data frames together.</p>\n\n<h3 id=\"sql-the-most-important-language-for-analytics\">SQL: The Most Important Language for Analytics</h3>\n\n<p><em>As a slight tangent, if you don’t know SQL, then you’re going to have a really hard time doing any sort of advanced analytics. There are literally millions of tutorials on the Internet (including <a href=\"http://randyzwitch.com/sqldf-package-r/\">this one from me</a>), and understanding how to join and retrieve data from databases is the key to being more than just a report monkey.</em></p>\n\n<p>The reason why the prior code creates 14 data frames is because the data is delivered in a <a href=\"http://www.studytonight.com/dbms/database-normalization.php\">normalized</a> structure from Adobe. Now we are going to <a href=\"http://searchdatamanagement.techtarget.com/definition/denormalization\">de-normalize</a> the data, which is just a fancy way of saying “join the files together in order to make a gigantic table.”</p>\n\n<p>There are probably a dozen different ways to join data frames using just R code, but I’m going to do it using the <a href=\"https://cran.r-project.org/web/packages/sqldf/index.html\">sqldf</a> package so that I can use SQL. This will allow for a single, declarative statement that shows the relationship between the lookup and fact tables:</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-r\" data-lang=\"r\"><table class=\"rouge-table\"><tbody><tr><td class=\"gutter gl\"><pre class=\"lineno\">1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n</pre></td><td class=\"code\"><pre><span class=\"n\">library</span><span class=\"p\">(</span><span class=\"n\">sqldf</span><span class=\"p\">)</span><span class=\"w\">\n\n</span><span class=\"n\">query</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\">\n</span><span class=\"s2\">\"select\nsc.*,\nbrowser.browser as browser_name,\nbrowser_type,\nconnection_type.connection_type as connection_name,\ncountry.country as country_name,\njavascript_version,\nlanguages.languages as languages,\noperating_systems,\nreferrer_type,\nresolution.resolution as screen_resolution,\nsearch_engines\nfrom servercall_data as sc\nleft join browser on sc.browser = browser.id\nleft join browser_type on sc.browser = browser_type.id\nleft join connection_type on sc.connection_type = connection_type.id\nleft join country on sc.country = country.id\nleft join javascript_version on sc.javascript = javascript_version.id\nleft join languages on sc.language = languages.id\nleft join operating_systems on sc.os = operating_systems.id\nleft join referrer_type on sc.ref_type = referrer_type.id\nleft join resolution on sc.resolution = resolution.id\nleft join search_engines on sc.post_search_engine = search_engines.id\n;\n\"</span><span class=\"w\">\n\n</span><span class=\"n\">denormalized_df</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"n\">sqldf</span><span class=\"p\">(</span><span class=\"n\">query</span><span class=\"p\">)</span>\n</pre></td></tr></tbody></table></code></pre></figure>\n\n<p>There are three lookup tables that weren’t used: <code class=\"language-plaintext highlighter-rouge\">color_depth</code>, <code class=\"language-plaintext highlighter-rouge\">plugins</code> and <code class=\"language-plaintext highlighter-rouge\">event</code>. The first two don’t have a lookup column in my data feed (click link for a full listing of <a href=\"https://marketing.adobe.com/resources/help/en_US/sc/clickstream/datafeeds_reference.html\">Adobe Clickstream data feed</a> columns available). These columns aren’t really useful for my purposes anyway, so not a huge loss. The third table, the <code class=\"language-plaintext highlighter-rouge\">event</code> list, requires a separate processing step.</p>\n\n<h3 id=\"processing-event-data\">Processing Event Data</h3>\n\n<p>As normalized as the Adobe Clickstream Data Feed is, there is one oddity: the events per server call come in a comma-delimited string in a single column with a lookup table. This implies that a separate level of processing is necessary, outside of SQL, since the column “key” is actually multiple keys and the lookup table specifies one event type per row. So if you were to try and join the data together, you wouldn’t get any matches.</p>\n\n<p>To deal with this in R, we are going to do an EXTREMELY wasteful operation: we are going to create a data frame with a column for each possible event, then evaluate each row to see if that event occurred. This will use a massive amount of RAM, but of course, this is a feature/limitation of R which wouldn’t be an issue if the data were stored in a database.</p>\n\n<figure class=\"highlight\"><pre><code class=\"language-r\" data-lang=\"r\"><table class=\"rouge-table\"><tbody><tr><td class=\"gutter gl\"><pre class=\"lineno\">1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n</pre></td><td class=\"code\"><pre><span class=\"c1\">#Create friendly names in events table replacing spaces with underscores</span><span class=\"w\">\n</span><span class=\"n\">event</span><span class=\"o\">$</span><span class=\"n\">names_filled</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"n\">tolower</span><span class=\"p\">(</span><span class=\"n\">gsub</span><span class=\"p\">(</span><span class=\"s2\">\" \"</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"s2\">\"_\"</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">event</span><span class=\"o\">$</span><span class=\"n\">event</span><span class=\"p\">))</span><span class=\"w\">\n\n</span><span class=\"c1\">#Initialize a data frame with all 0 values</span><span class=\"w\">\n</span><span class=\"c1\">#Dimensions are number of observations as rows, with a column for every possible event</span><span class=\"w\">\n</span><span class=\"n\">event_df</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"n\">data.frame</span><span class=\"p\">(</span><span class=\"n\">matrix</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"m\">0</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">ncol</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">nrow</span><span class=\"p\">(</span><span class=\"n\">event</span><span class=\"p\">),</span><span class=\"w\"> </span><span class=\"n\">nrow</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">nrow</span><span class=\"p\">(</span><span class=\"n\">servercall_data</span><span class=\"p\">)))</span><span class=\"w\">\n</span><span class=\"nf\">names</span><span class=\"p\">(</span><span class=\"n\">event_df</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"n\">event</span><span class=\"o\">$</span><span class=\"n\">id</span><span class=\"w\">\n\n</span><span class=\"c1\">#Parse comma-delimited string into vector</span><span class=\"w\">\n</span><span class=\"c1\">#Each vector value represents column name in event_df, assign value of 1</span><span class=\"w\">\n</span><span class=\"k\">for</span><span class=\"p\">(</span><span class=\"n\">row</span><span class=\"w\"> </span><span class=\"k\">in</span><span class=\"w\"> </span><span class=\"n\">servercall_data</span><span class=\"o\">$</span><span class=\"n\">post_event_list</span><span class=\"p\">){</span><span class=\"w\">\n    </span><span class=\"k\">if</span><span class=\"p\">(</span><span class=\"o\">!</span><span class=\"nf\">is.na</span><span class=\"p\">(</span><span class=\"n\">row</span><span class=\"p\">)){</span><span class=\"w\">\n        </span><span class=\"k\">for</span><span class=\"p\">(</span><span class=\"n\">event_</span><span class=\"w\"> </span><span class=\"k\">in</span><span class=\"w\"> </span><span class=\"n\">strsplit</span><span class=\"p\">(</span><span class=\"n\">row</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"s2\">\",\"</span><span class=\"p\">)){</span><span class=\"w\">\n          </span><span class=\"n\">event_df</span><span class=\"p\">[</span><span class=\"nf\">as.character</span><span class=\"p\">(</span><span class=\"n\">event_</span><span class=\"p\">)]</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"m\">1</span><span class=\"w\">\n        </span><span class=\"p\">}</span><span class=\"w\">\n    </span><span class=\"p\">}</span><span class=\"w\">\n</span><span class=\"p\">}</span><span class=\"w\">\n\n</span><span class=\"c1\">#Rename columns with \"friendly\" names</span><span class=\"w\">\n</span><span class=\"nf\">names</span><span class=\"p\">(</span><span class=\"n\">event_df</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"n\">event</span><span class=\"o\">$</span><span class=\"n\">names_filled</span><span class=\"w\">\n\n</span><span class=\"c1\">#Horizontally join datasets to create final dataset</span><span class=\"w\">\n</span><span class=\"n\">oneday_df</span><span class=\"w\"> </span><span class=\"o\">&lt;-</span><span class=\"w\"> </span><span class=\"n\">cbind</span><span class=\"p\">(</span><span class=\"n\">denormalized_df</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">event_df</span><span class=\"p\">)</span>\n</pre></td></tr></tbody></table></code></pre></figure>\n\n<p>With the final <code class=\"language-plaintext highlighter-rouge\">cbind</code> command, we’ve created a 500 row x 1562 column dataset representing a sample of rows from one day of the Adobe Clickstream Data Feed. Having the data denormalized in this fashion takes 6.13 MB of RAM…extrapolating to 1 million rows, you would need 12.26GB of RAM (per day of data you want to analyze, if stored solely in memory).</p>\n\n<h3 id=\"next-step-analytics\">Next Step: Analytics?!</h3>\n\n<p>A thousand words in and 91 lines of R code and we still haven’t done any actual analytics. But we’ve completed the first step in any analytics project: data prep!</p>\n\n<p>In future blog posts in this series, I’ll demonstrate how to actually use this data in analytics, from re-creating reports available in the Adobe Analytics UI (to prove the data is the same) to more advanced analysis such as using association rules, which can be one method for creating a “You may also like…” functionality such as the one at the bottom of this blog.</p>\n\n<h2 id=\"example-files\">Example Files:</h2>\n\n<ul>\n  <li><a href=\"http://randyzwitch.com/wp-content/uploads/2015/08/zwitchdev_2015-07-13.txt\" target=\"_blank\">http://randyzwitch.com/wp-content/uploads/2015/08/zwitchdev_2015-07-13.txt</a></li>\n  <li><a href=\"http://randyzwitch.com/wp-content/uploads/2015/08/zwitchdev_2015-07-13-lookup_data.tar.gz\" target=\"_blank\">http://randyzwitch.com/wp-content/uploads/2015/08/zwitchdev_2015-07-13-lookup_data.tar.gz</a></li>\n  <li><a href=\"http://randyzwitch.com/wp-content/uploads/2015/08/01-zwitchdev_2015-07-13.tsv.gz\" target=\"_blank\">http://randyzwitch.com/wp-content/uploads/2015/08/01-zwitchdev_2015-07-13.tsv.gz</a></li>\n</ul>"
}