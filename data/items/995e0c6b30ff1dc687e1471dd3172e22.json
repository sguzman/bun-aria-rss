{
  "title": "ScoreMix: A Scalable Augmentation Strategy for Training GANs with Limited Data. (arXiv:2210.15137v2 [cs.CV] UPDATED)",
  "link": "http://arxiv.org/abs/2210.15137",
  "description": "<p>Generative Adversarial Networks (GANs) typically suffer from overfitting when\nlimited training data is available. To facilitate GAN training, current methods\npropose to use data-specific augmentation techniques. Despite the\neffectiveness, it is difficult for these methods to scale to practical\napplications. In this work, we present ScoreMix, a novel and scalable data\naugmentation approach for various image synthesis tasks. We first produce\naugmented samples using the convex combinations of the real samples. Then, we\noptimize the augmented samples by minimizing the norms of the data scores,\ni.e., the gradients of the log-density functions. This procedure enforces the\naugmented samples close to the data manifold. To estimate the scores, we train\na deep estimation network with multi-scale score matching. For different image\nsynthesis tasks, we train the score estimation network using different data. We\ndo not require the tuning of the hyperparameters or modifications to the\nnetwork architecture. The ScoreMix method effectively increases the diversity\nof data and reduces the overfitting problem. Moreover, it can be easily\nincorporated into existing GAN models with minor modifications. Experimental\nresults on numerous tasks demonstrate that GAN models equipped with the\nScoreMix method achieve significant improvements.\n</p>",
  "dc:creator": "<a href=\"http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1\">Jie Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_M/0/1/0/all/0/1\">Mandi Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1\">Junchi Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1\">Ming-Hsuan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_R/0/1/0/all/0/1\">Ran He</a>"
}