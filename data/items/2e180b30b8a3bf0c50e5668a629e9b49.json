{
  "guid": "tag:blogger.com,1999:blog-6300367579216018061.post-4014480702246945050",
  "pubDate": "Mon, 03 Nov 2014 22:33:00 +0000",
  "atom:updated": "2014-11-27T19:57:44.593-08:00",
  "category": [
    "analytics",
    "apache hadoop",
    "apache spark",
    "big data",
    "data science",
    "graph database",
    "graph processing",
    "Mazerunner",
    "neo4j",
    "PageRank"
  ],
  "title": "Using Apache Spark and Neo4j for Big Data Graph Analytics",
  "description": "<p>As engineers, when we think about how to solve big data problems, evaluating technologies becomes a choice between scalable and not scalable. Ideally we choose the technologies that can scale to a variety of business problems without hitting a ceiling down the road.</p> <p>Database technologies have evolved to be able to store big data, but are largely inflexible. The data models require tedious transformations and shuffling around of data. This is a complex process that is compounded in its complexity by combining a variety of inflexible solutions and platforms.</p> <p>Fast and scalable analysis of big data has become a critical competitive advantage for companies. There are open source tools like <a href=\"http://en.wikipedia.org/wiki/Apache_Hadoop\" target=\"_blank\">Apache Hadoop</a> and <a href=\"http://en.wikipedia.org/wiki/Apache_Spark\" target=\"_blank\">Apache Spark</a> that are providing opportunities for companies to solve these big data problems in a scalable way. Platforms like these have become the foundation of the big data analysis movement.</p><p>Still, where does all that data come from? Where does it go when the analysis is done?</p><a name='more'></a><h3>Graph databases</h3><div><br /></div>I've been working with the <a href=\"http://www.neo4j.com\">Neo4j graph database</a> for the last few years and I have yet to become jaded by its powerful ability to combine both data transformation and data analysis. Graph databases like Neo4j are solving analytical problems that relational databases struggle to solve in a flexible way.<br /><br />Graph processing at scale from a graph database like Neo4j is a tremendously valuable power.<br /><br />But if you wanted to run PageRank on a dump of Wikipedia articles in less than 2 hours on a laptop, you'd be hard pressed to be successful. More so, what if you wanted the power of a high-performance transactional database that seamlessly handled graph analysis at this scale?<br /><br /><h3>Mazerunner for Neo4j</h3><br /><a href=\"https://github.com/kbastani/neo4j-mazerunner\" target=\"_blank\">Mazerunner</a> is a <a href=\"http://neo4j.com/docs/stable/server-unmanaged-extensions.html\">Neo4j unmanaged extension</a> and distributed graph processing platform that extends Neo4j to do big data graph processing jobs while persisting the results  back to Neo4j.<br /><br />Mazerunner uses a message broker to distribute graph processing jobs to <a href=\"https://spark.apache.org/graphx/\">Apache Spark's GraphX</a> module. When an agent job is dispatched, a subgraph is exported from Neo4j and written to <a href=\"https://hadoop.apache.org/docs/r2.4.1/hadoop-project-dist/hadoop-hdfs/HdfsUserGuide.html\">Apache Hadoop HDFS</a>.<br /><br />After Neo4j exports a subgraph to HDFS, a separate Mazerunner service  for Spark is notified to begin processing that data. The Mazerunner  service will then start a distributed graph processing algorithm using  Scala and Spark's GraphX module. The GraphX algorithm is serialized and  dispatched to Apache Spark for processing.<br /><br />Once the Apache Spark job completes, the results are written back to  HDFS as a Key-Value list of property updates to be applied back to  Neo4j.<br /><br />Neo4j is then notified that a property update list is available from  Apache Spark on HDFS. Neo4j batch imports the results and applies the  updates back to the original graph.<br /><br /><h3>Example</h3><div><br /></div><div>Neo4j ships with a sample movie dataset and I'll use that for this example. The graph data model looks like this:</div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://1.bp.blogspot.com/-gta3ODAcdBg/VFf-ROiOR8I/AAAAAAAAA8w/Jxu99gIW3cE/s1600/movie-model.png\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" src=\"http://1.bp.blogspot.com/-gta3ODAcdBg/VFf-ROiOR8I/AAAAAAAAA8w/Jxu99gIW3cE/s1600/movie-model.png\" height=\"255\" width=\"400\" /></a></div><div><br /></div><br />If we run a transformation on this model and create relationships between people who acted in the same movie, we can use the resulting graph to determine which actors are most valuable to work with.<br /><br />The Cypher query to do this looks like this:<br /><pre><code>MATCH (a1:Person)-[:ACTED_IN]-&gt;(m)&lt;-[:ACTED_IN]-(coActors)<br />CREATE (a1)-[:KNOWS]-&gt;(coActors);</code></pre>Now our model looks like this:<br /><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://3.bp.blogspot.com/-gwGKjYDA-DE/VFgAC9CTEVI/AAAAAAAAA88/oAc0Kgp32pY/s1600/actor-link-graph.png\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" src=\"http://3.bp.blogspot.com/-gwGKjYDA-DE/VFgAC9CTEVI/AAAAAAAAA88/oAc0Kgp32pY/s1600/actor-link-graph.png\" height=\"468\" width=\"640\" /></a></div><div><br />By doing this, we create a direct link between actors that can be used for a PageRank analysis of the most valuable actors to work with.</div><div><br />To start the PageRank job on Apache Spark, Mazerunner extends an endpoint to start the processing job.<br /><pre><code>http://localhost:7474/service/mazerunner/pagerank</code></pre>Hitting this endpoint will run the PageRank algorithm on actors who know each other and then write the results back into Neo4j as a <b>weight</b> property on the <b>Person</b> nodes.<br /><br />When the job finishes then we can find the top ten most valuable actors to work with. Running a Cypher query against this dataset produces the following results:<br /><pre><code><br />neo4j-sh (?)$ MATCH n WHERE HAS(n.weight) RETURN n ORDER BY n.weight DESC LIMIT 10;<br />+-----------------------------------------------------------------------+<br />| n                                                                     |<br />+-----------------------------------------------------------------------+<br />| Node[71]{name:\"Tom Hanks\",born:1956,weight:4.642800717539658}         |<br />| Node[1]{name:\"Keanu Reeves\",born:1964,weight:2.605304495549113}       |<br />| Node[22]{name:\"Cuba Gooding Jr.\",born:1968,weight:2.5655048212974223} |<br />| Node[34]{name:\"Meg Ryan\",born:1961,weight:2.52628473708215}           |<br />| Node[16]{name:\"Tom Cruise\",born:1962,weight:2.430592498009265}        |<br />| Node[19]{name:\"Kevin Bacon\",born:1958,weight:2.0886893112867035}      |<br />| Node[17]{name:\"Jack Nicholson\",born:1937,weight:1.9641313625284538}   |<br />| Node[120]{name:\"Ben Miles\",born:1967,weight:1.8680986516285438}       |<br />| Node[4]{name:\"Hugo Weaving\",born:1960,weight:1.8515582875810466}      |<br />| Node[20]{name:\"Kiefer Sutherland\",born:1966,weight:1.784065038526406} |<br />+-----------------------------------------------------------------------+<br />10 rows</code></pre><br /><h3>PageRank on Wikipedia Dump</h3><br /><div>A small movie dataset is cute, but if we're talking about scale, we need a dataset that is at a massive scale. I took a dump of Wikipedia and imported it into Neo4j using <a href=\"https://github.com/mirkonasato/graphipedia\" target=\"_blank\">Graphipedia</a>.&nbsp;</div><div><br /></div><div>The resulting graph of hyperlink references connecting articles to each other resulted in a massive graph in Neo4j.</div><div><br /></div><b>Nodes</b>: 10,985,338 <br /><b>Relationships</b>: 104,673,778<br /><b>Database</b> size:&nbsp;11,002  MB<br /><br />It took a little less than 3 hours for Mazerunner to run PageRank on 11 million Wikipedia articles on my laptop.</div><div><br /></div><div>Here are the top 100 results of that analysis:</div><div><br /></div><div><pre><code>+-------------------------------------------------------------+<br />| title                                  | weight             |<br />+-------------------------------------------------------------+<br />| \"United States\"                        | 13481.465434735326 |<br />| \"France\"                               | 5866.673240306334  |<br />| \"Animal\"                               | 5665.755894233272  |<br />| \"Country\"                              | 5422.733465218685  |<br />| \"County\"                               | 5097.065153505375  |<br />| \"World War II\"                         | 4903.803574507514  |<br />| \"Germany\"                              | 4758.829204613294  |<br />| \"United Kingdom\"                       | 4538.534060897834  |<br />| \"Russia\"                               | 4328.2166400665055 |<br />| \"English\"                              | 4220.257198573251  |<br />| \"India\"                                | 3956.6896584623237 |<br />| \"England\"                              | 3895.7939536781337 |<br />| \"Japan\"                                | 3665.9152429486285 |<br />| \"Canada\"                               | 3657.4749257843423 |<br />| \"Australia\"                            | 3595.941069092141  |<br />| \"Iran\"                                 | 3482.6418104876884 |<br />| \"Province\"                             | 3400.887300974972  |<br />| \"China\"                                | 3239.811469195496  |<br />| \"American\"                             | 3192.7699175209023 |<br />| \"French\"                               | 3182.4457685761104 |<br />| \"The New York Times\"                   | 3181.5839069249864 |<br />| \"Arthropod\"                            | 3097.8173315850213 |<br />| \"Italy\"                                | 3032.3644182841776 |<br />| \"German\"                               | 3012.815858491087  |<br />| \"London\"                               | 2965.4743930058657 |<br />| \"Insect\"                               | 2869.920827785085  |<br />| \"District\"                             | 2784.755324500963  |<br />| \"Spain\"                                | 2668.2978896378804 |<br />| \"New York City\"                        | 2650.752385794727  |<br />| \"Latin\"                                | 2584.6877541535127 |<br />| \"Poland\"                               | 2575.2112457023773 |<br />| \"World War I\"                          | 2573.8477947401866 |<br />| \"Soviet Union\"                         | 2477.694486425502  |<br />| \"Catholic Church\"                      | 2474.683318006141  |<br />| \"New York\"                             | 2468.8443657519097 |<br />| \"Brazil\"                               | 2435.2531424225617 |<br />| \"Romania\"                              | 2393.1873377303928 |<br />| \"Europe\"                               | 2353.968692909295  |<br />| \"California\"                           | 2266.6608579578156 |<br />| \"Lepidoptera\"                          | 2158.715841127394  |<br />| \"State\"                                | 2132.243578231637  |<br />| \"Italian\"                              | 2106.6553548486086 |<br />| \"Greek\"                                | 2028.1563330073805 |<br />| \"Switzerland\"                          | 2027.8234786567634 |<br />| \"Paris\"                                | 1970.357297581375  |<br />| \"Chordata\"                             | 1950.4239922246595 |<br />| \"Spanish\"                              | 1926.201753857372  |<br />| \"New Zealand\"                          | 1828.6683122383472 |<br />| \"Mexico\"                               | 1828.0197503654385 |<br />| \"British\"                              | 1811.7648105938251 |<br />| \"Washington, D.C.\"                     | 1810.533732133272  |<br />| \"Netherlands\"                          | 1803.7312379217158 |<br />| \"Scotland\"                             | 1776.2112626996402 |<br />| \"National Register of Historic Places\" | 1765.6396180107192 |<br />| \"Sweden\"                               | 1750.4933182628488 |<br />| \"USA\"                                  | 1708.9086633673999 |<br />| \"Chordate\"                             | 1659.5183460486119 |<br />| \"Ireland\"                              | 1630.2162859072075 |<br />| \"United States Census Bureau\"          | 1590.6841804100668 |<br />| \"Turkey\"                               | 1571.7895450758779 |<br />| \"South Africa\"                         | 1552.1113319282647 |<br />| \"Belgium\"                              | 1548.2393303043832 |<br />| \"Austria\"                              | 1517.0098756018515 |<br />| \"Los Angeles\"                          | 1487.3395876804987 |<br />| \"Region\"                               | 1455.4554257569105 |<br />| \"Municipality\"                         | 1422.385733793246  |<br />| \"Greece\"                               | 1415.3614936831354 |<br />| \"CET\"                                  | 1393.056892061773  |<br />| \"Norway\"                               | 1387.064297388938  |<br />| \"Chicago\"                              | 1386.6868499051984 |<br />| \"European Union\"                       | 1382.571030912079  |<br />| \"President\"                            | 1376.0926002579163 |<br />| \"Philippines\"                          | 1371.3808757708794 |<br />| \"BBC\"                                  | 1362.697735274599  |<br />| \"White\"                                | 1329.6229862450132 |<br />| \"Voivodeship\"                          | 1325.3419002294163 |<br />| \"African American\"                     | 1316.08289317503   |<br />| \"New York Times\"                       | 1305.9732797320457 |<br />| \"Israel\"                               | 1289.4941308687928 |<br />| \"United Nations\"                       | 1275.3410092372967 |<br />| \"Rome\"                                 | 1268.7924011211794 |<br />| \"Gmina\"                                | 1264.8386282950032 |<br />| \"CEST\"                                 | 1263.3655294822495 |<br />| \"Canadian\"                             | 1257.0066905218277 |<br />| \"Argentina\"                            | 1256.590368894054  |<br />| \"Dutch\"                                | 1253.7080447443823 |<br />| \"Angiosperms\"                          | 1247.3964328063778 |<br />| \"Taiwan\"                               | 1244.5572462360428 |<br />| \"Native Americans\"                     | 1231.9646926767173 |<br />| \"Egypt\"                                | 1230.2800089879247 |<br />| \"Chinese\"                              | 1226.417515716627  |<br />| \"North America\"                        | 1226.211997093438  |<br />| \"Indonesia\"                            | 1221.68337046196   |<br />| \"Oxford University Press\"              | 1205.4955933795306 |<br />| \"Roman Catholic\"                       | 1205.3842960845823 |<br />| \"Islam\"                                | 1200.4126147456059 |<br />| \"Pakistan\"                             | 1199.2589818906795 |<br />| \"Jews\"                                 | 1187.7942956454976 |<br />| \"Texas\"                                | 1187.3229003531255 |<br />| \"The Guardian\"                         | 1185.9922865148167 |<br />+-------------------------------------------------------------+</code></pre><h3>Try it out</h3></div><div><br /></div><div>Mazerunner is currently in its alpha stages of development. For this  initial release PageRank is the only available graph processing  algorithm.<br /><div><br />Head over to the <a href=\"https://github.com/kbastani/neo4j-mazerunner\" target=\"_blank\">GitHub repository</a> to keep track of the progress of the project as it moves forward to its 1.0.0 release.</div></div><br/><a href=\"https://news.ycombinator.com/submit\" class=\"hn-button\" data-title=\"Using Apache Spark and Neo4j for Big Data Graph Analytics\" data-url=\"http://www.kennybastani.com/2014/11/using-apache-spark-and-neo4j-for-big.html\" data-count=\"horizontal\">Vote on Hacker News</a><script type=\"text/javascript\">var HN=[];HN.factory=function(e){return function(){HN.push([e].concat(Array.prototype.slice.call(arguments,0)))};},HN.on=HN.factory(\"on\"),HN.once=HN.factory(\"once\"),HN.off=HN.factory(\"off\"),HN.emit=HN.factory(\"emit\"),HN.load=function(){var e=\"hn-button.js\";if(document.getElementById(e))return;var t=document.createElement(\"script\");t.id=e,t.src=\"//hn-button.herokuapp.com/hn-button.js\";var n=document.getElementsByTagName(\"script\")[0];n.parentNode.insertBefore(t,n)},HN.load();</script>",
  "link": "https://www.kennybastani.com/2014/11/using-apache-spark-and-neo4j-for-big.html",
  "author": "noreply@blogger.com (Kenny Bastani)",
  "media:thumbnail": "",
  "thr:total": 0
}