{
  "title": "Little Tricky Logic: Misconceptions in the Understanding of LTL. (arXiv:2211.01677v1 [cs.PL])",
  "link": "http://arxiv.org/abs/2211.01677",
  "description": "<p>Context: Linear Temporal Logic (LTL) has been used widely in verification.\nIts importance and popularity have only grown with the revival of temporal\nlogic synthesis, and with new uses of LTL in robotics and planning activities.\nAll these uses demand that the user have a clear understanding of what an LTL\nspecification means.\n</p>\n<p>Inquiry: Despite the growing use of LTL, no studies have investigated the\nmisconceptions users actually have in understanding LTL formulas. This paper\naddresses the gap with a first study of LTL misconceptions. Approach: We study\nresearchers' and learners' understanding of LTL in four rounds (three written\nsurveys, one talk-aloud) spread across a two-year timeframe. Concretely, we\ndecompose \"understanding LTL\" into three questions. A person reading a spec\nneeds to understand what it is saying, so we study the mapping from LTL to\nEnglish. A person writing a spec needs to go in the other direction, so we\nstudy English to LTL. However, misconceptions could arise from two sources: a\nmisunderstanding of LTL's syntax or of its underlying semantics. Therefore, we\nalso study the relationship between formulas and specific traces.\n</p>\n<p>Knowledge: We find several misconceptions that have consequences for\nlearners, tool builders, and designers of new property languages. These\nfindings are already resulting in changes to the Alloy modeling language. We\nalso find that the English to LTL direction was the most common source of\nerrors; unfortunately, this is the critical \"authoring\" direction in which a\nsubtle mistake can lead to a faulty system. We contribute study instruments\nthat are useful for training learners (whether academic or industrial) who are\ngetting acquainted with LTL, and we provide a code book to assist in the\nanalysis of responses to similar-style questions.\n</p>\n<p>Grounding: Our findings are grounded in the responses to our survey rounds.\nRound 1 used Quizius to identify misconceptions among learners in a way that\nreduces the threat of expert blind spots. Rounds 2 and 3 confirm that both\nadditional learners and researchers (who work in formal methods, robotics, and\nrelated fields) make similar errors. Round 4 adds deep support for our\nmisconceptions via talk-aloud surveys.\n</p>\n<p>Importance This work provides useful answers to two critical but unexplored\nquestions: in what ways is LTL tricky and what can be done about it? Our survey\ninstruments can serve as a starting point for other studies.\n</p>",
  "dc:creator": "<a href=\"http://arxiv.org/find/cs/1/au:+Greenman_B/0/1/0/all/0/1\">Ben Greenman</a> (Brown University, USA), <a href=\"http://arxiv.org/find/cs/1/au:+Saarinen_S/0/1/0/all/0/1\">Sam Saarinen</a> (Brown University, USA), <a href=\"http://arxiv.org/find/cs/1/au:+Nelson_T/0/1/0/all/0/1\">Tim Nelson</a> (Brown University, USA), <a href=\"http://arxiv.org/find/cs/1/au:+Krishnamurthi_S/0/1/0/all/0/1\">Shriram Krishnamurthi</a> (Brown University, USA)"
}