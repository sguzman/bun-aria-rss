{
  "title": "Revisiting Hyperparameter Tuning with Differential Privacy. (arXiv:2211.01852v1 [cs.LG])",
  "link": "http://arxiv.org/abs/2211.01852",
  "description": "<p>Hyperparameter tuning is a common practice in the application of machine\nlearning but is a typically ignored aspect in the literature on\nprivacy-preserving machine learning due to its negative effect on the overall\nprivacy parameter. In this paper, we aim to tackle this fundamental yet\nchallenging problem by providing an effective hyperparameter tuning framework\nwith differential privacy. The proposed method allows us to adopt a broader\nhyperparameter search space and even to perform a grid search over the whole\nspace, since its privacy loss parameter is independent of the number of\nhyperparameter candidates. Interestingly, it instead correlates with the\nutility gained from hyperparameter searching, revealing an explicit and\nmandatory trade-off between privacy and utility. Theoretically, we show that\nits additional privacy loss bound incurred by hyperparameter tuning is\nupper-bounded by the squared root of the gained utility. However, we note that\nthe additional privacy loss bound would empirically scale like a squared root\nof the logarithm of the utility term, benefiting from the design of doubling\nstep.\n</p>",
  "dc:creator": "<a href=\"http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1\">Youlong Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xueyang Wu</a>"
}