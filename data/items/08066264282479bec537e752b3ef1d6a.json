{
  "title": "Towards Out-of-core ND-Arrays -- Spilling to Disk",
  "link": "",
  "updated": "2015-01-16T00:00:00+00:00",
  "id": "https://mrocklin.github.io/blog/work/2015/01/16/Towards-OOC-SpillToDisk",
  "content": "<p><em>This work is supported by <a href=\"http://continuum.io\">Continuum Analytics</a>\nand the <a href=\"http://www.darpa.mil/program/XDATA\">XDATA Program</a>\nas part of the <a href=\"http://blaze.pydata.org\">Blaze Project</a></em></p>\n\n<p><strong>tl;dr</strong> We implement a dictionary that spills to disk when we run out of\nmemory.  We connect this to our scheduler.</p>\n\n<h2 id=\"introduction\">Introduction</h2>\n\n<p>This is the fifth in a sequence of posts constructing an out-of-core nd-array\nusing NumPy, Blaze, and dask.  You can view these posts here:</p>\n\n<ol>\n  <li><a href=\"http://matthewrocklin.com/blog/work/2014/12/27/Towards-OOC/\">Simple task scheduling</a>,</li>\n  <li><a href=\"http://matthewrocklin.com/blog/work/2014/12/30/Towards-OOC-Frontend/\">Frontend usability</a></li>\n  <li><a href=\"http://matthewrocklin.com/blog/work/2015/01/06/Towards-OOC-Scheduling/\">A multi-threaded scheduler</a></li>\n  <li><a href=\"http://matthewrocklin.com/blog/work/2015/01/14/Towards-OOC-MatMul/\">Matrix Multiply Benchmark</a></li>\n</ol>\n\n<p>We now present <code class=\"language-plaintext highlighter-rouge\">chest</code> a <code class=\"language-plaintext highlighter-rouge\">dict</code> type that spills to disk when we run out of\nmemory.  We show how it prevents large computations from flooding memory.</p>\n\n<h2 id=\"intermediate-data\">Intermediate Data</h2>\n\n<p><img src=\"https://mrocklin.github.io/blog/images/dask/fail-case.gif\" align=\"right\" width=\"50%\" alt=\"A case where our scheduling algorithm fails to avoid intermediates\" /></p>\n\n<p>If you read the\n<a href=\"http://matthewrocklin.com/blog/work/2015/01/06/Towards-OOC-Scheduling/\">post on scheduling</a>\nyou may recall our goal to minimize intermediate storage during a multi-worker\ncomputation.  The image on the right shows a trace of our scheduler as it\ntraverses a task dependency graph.  We want to compute the entire graph quickly\nwhile keeping only a small amount of data in memory at once.</p>\n\n<p>Sometimes we fail and our scheduler stores many large intermediate results.  In\nthese cases we want to spill excess intermediate data to disk rather than\nflooding local memory.</p>\n\n<h2 id=\"chest\">Chest</h2>\n\n<p>Chest is a dict-like object that writes data to disk once it runs out of\nmemory.</p>\n\n<figure class=\"highlight\">\n  <pre><code class=\"language-python\" data-lang=\"python\"><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">chest</span> <span class=\"kn\">import</span> <span class=\"n\">Chest</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">d</span> <span class=\"o\">=</span> <span class=\"n\">Chest</span><span class=\"p\">(</span><span class=\"n\">available_memory</span><span class=\"o\">=</span><span class=\"mf\">1e9</span><span class=\"p\">)</span>  <span class=\"c1\"># Only use a GigaByte</span></code></pre>\n</figure>\n\n<p>It satisfies the <code class=\"language-plaintext highlighter-rouge\">MutableMapping</code> interface so it looks and feels exactly like\na <code class=\"language-plaintext highlighter-rouge\">dict</code>.  Below we show an example using a chest with only enough data to\nstore one Python integer in memory.</p>\n\n<figure class=\"highlight\">\n  <pre><code class=\"language-python\" data-lang=\"python\"><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">d</span> <span class=\"o\">=</span> <span class=\"n\">Chest</span><span class=\"p\">(</span><span class=\"n\">available_memory</span><span class=\"o\">=</span><span class=\"mi\">24</span><span class=\"p\">)</span>  <span class=\"c1\"># enough space for one Python integer\n</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">d</span><span class=\"p\">[</span><span class=\"s\">'one'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">d</span><span class=\"p\">[</span><span class=\"s\">'two'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"mi\">2</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">d</span><span class=\"p\">[</span><span class=\"s\">'three'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"mi\">3</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">d</span><span class=\"p\">[</span><span class=\"s\">'three'</span><span class=\"p\">]</span>\n<span class=\"mi\">3</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">d</span><span class=\"p\">.</span><span class=\"n\">keys</span><span class=\"p\">()</span>\n<span class=\"p\">[</span><span class=\"s\">'one'</span><span class=\"p\">,</span> <span class=\"s\">'two'</span><span class=\"p\">,</span> <span class=\"s\">'three'</span><span class=\"p\">]</span></code></pre>\n</figure>\n\n<p>We keep some data in memory</p>\n\n<figure class=\"highlight\">\n  <pre><code class=\"language-python\" data-lang=\"python\"><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">d</span><span class=\"p\">.</span><span class=\"n\">inmem</span>\n<span class=\"p\">{</span><span class=\"s\">'three'</span><span class=\"p\">:</span> <span class=\"mi\">3</span><span class=\"p\">}</span></code></pre>\n</figure>\n\n<p>While the rest lives on disk</p>\n\n<figure class=\"highlight\">\n  <pre><code class=\"language-python\" data-lang=\"python\"><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">d</span><span class=\"p\">.</span><span class=\"n\">path</span>\n<span class=\"s\">'/tmp/tmpb5ouAb.chest'</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">os</span><span class=\"p\">.</span><span class=\"n\">listdir</span><span class=\"p\">(</span><span class=\"n\">d</span><span class=\"p\">.</span><span class=\"n\">path</span><span class=\"p\">)</span>\n<span class=\"p\">[</span><span class=\"s\">'one'</span><span class=\"p\">,</span> <span class=\"s\">'two'</span><span class=\"p\">]</span></code></pre>\n</figure>\n\n<p>By default we store data with pickle but <code class=\"language-plaintext highlighter-rouge\">chest</code> supports any protocol\nwith the <code class=\"language-plaintext highlighter-rouge\">dump/load</code> interface (<code class=\"language-plaintext highlighter-rouge\">pickle</code>, <code class=\"language-plaintext highlighter-rouge\">json</code>, <code class=\"language-plaintext highlighter-rouge\">cbor</code>, <code class=\"language-plaintext highlighter-rouge\">joblib</code>, ….)</p>\n\n<p>A quick point about <code class=\"language-plaintext highlighter-rouge\">pickle</code>.  Frequent readers of my blog may know of my\nsadness at how this library\n<a href=\"http://matthewrocklin.com/blog/work/2013/12/05/Parallelism-and-Serialization/\">serializes functions</a>\nand the crippling effect on multiprocessing.\nThat sadness does not extend to normal data.  Pickle is fine for data if you\nuse the <code class=\"language-plaintext highlighter-rouge\">protocol=</code> keyword to <code class=\"language-plaintext highlighter-rouge\">pickle.dump</code> correctly .  Pickle isn’t a good\ncross-language solution, but that doesn’t matter in our application of\ntemporarily storing numpy arrays on disk.</p>\n\n<h2 id=\"recent-tweaks\">Recent tweaks</h2>\n\n<p>In using <code class=\"language-plaintext highlighter-rouge\">chest</code> alongside <code class=\"language-plaintext highlighter-rouge\">dask</code> with any reasonable success I had to make the\nfollowing improvements to the original implementation:</p>\n\n<ol>\n  <li>A basic LRU mechanism to write only infrequently used data</li>\n  <li>A policy to avoid writing the same data to disk twice if it hasn’t changed</li>\n  <li>Thread safety</li>\n</ol>\n\n<p>Now we can execute more dask workflows without risk of flooding memory</p>\n\n<figure class=\"highlight\">\n  <pre><code class=\"language-python\" data-lang=\"python\"><span class=\"n\">A</span> <span class=\"o\">=</span> <span class=\"p\">...</span>\n<span class=\"n\">B</span> <span class=\"o\">=</span> <span class=\"p\">...</span>\n<span class=\"n\">expr</span> <span class=\"o\">=</span> <span class=\"n\">A</span><span class=\"p\">.</span><span class=\"n\">T</span><span class=\"p\">.</span><span class=\"n\">dot</span><span class=\"p\">(</span><span class=\"n\">B</span><span class=\"p\">)</span> <span class=\"o\">-</span> <span class=\"n\">B</span><span class=\"p\">.</span><span class=\"n\">mean</span><span class=\"p\">(</span><span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n\n<span class=\"n\">cache</span> <span class=\"o\">=</span> <span class=\"n\">Chest</span><span class=\"p\">(</span><span class=\"n\">available_memory</span><span class=\"o\">=</span><span class=\"mf\">1e9</span><span class=\"p\">)</span>\n\n<span class=\"n\">into</span><span class=\"p\">(</span><span class=\"s\">'myfile.hdf5::/result'</span><span class=\"p\">,</span> <span class=\"n\">expr</span><span class=\"p\">,</span> <span class=\"n\">cache</span><span class=\"o\">=</span><span class=\"n\">cache</span><span class=\"p\">)</span></code></pre>\n</figure>\n\n<p>Now we incur only moderate slowdown when we schedule poorly and run into large\nquantities of intermediate data.</p>\n\n<h2 id=\"conclusion\">Conclusion</h2>\n\n<p>Chest is only useful when we fail to schedule well.  We can still improve\nscheduling algorithms to avoid keeping data in memory but it’s nice to have\n<code class=\"language-plaintext highlighter-rouge\">chest</code> as a backup for when these algorithms fail.  Resilience is reassuring.</p>"
}