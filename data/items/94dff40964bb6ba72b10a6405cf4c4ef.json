{
  "title": "Single SMPC Invocation DPHelmet: Differentially Private Distributed Learning on a Large Scale. (arXiv:2211.02003v1 [cs.CR])",
  "link": "http://arxiv.org/abs/2211.02003",
  "description": "<p>Distributing machine learning predictors enables the collection of\nlarge-scale datasets while leaving sensitive raw data at trustworthy sites. We\nshow that locally training support vector machines (SVMs) and computing their\naverages leads to a learning technique that is scalable to a large number of\nusers, satisfies differential privacy, and is applicable to non-trivial tasks,\nsuch as CIFAR-10. For a large number of participants, communication cost is one\nof the main challenges. We achieve a low communication cost by requiring only a\nsingle invocation of an efficient secure multiparty summation protocol. By\nrelying on state-of-the-art feature extractors (SimCLR), we are able to utilize\ndifferentially private convex learners for non-trivial tasks such as CIFAR-10.\nOur experimental results illustrate that for $1{,}000$ users with $50$ data\npoints each, our scheme outperforms state-of-the-art scalable distributed\nlearning methods (differentially private federated learning, short DP-FL) while\nrequiring around $500$ times fewer communication costs: For CIFAR-10, we\nachieve a classification accuracy of $79.7\\,\\%$ for an $\\varepsilon = 0.59$\nwhile DP-FL achieves $57.6\\,\\%$. More generally, we prove learnability\nproperties for the average of such locally trained models: convergence and\nuniform stability. By only requiring strongly convex, smooth, and\nLipschitz-continuous objective functions, locally trained via stochastic\ngradient descent (SGD), we achieve a strong utility-privacy tradeoff.\n</p>",
  "dc:creator": "<a href=\"http://arxiv.org/find/cs/1/au:+Kirschte_M/0/1/0/all/0/1\">Moritz Kirschte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meiser_S/0/1/0/all/0/1\">Sebastian Meiser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ardalan_S/0/1/0/all/0/1\">Saman Ardalan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohammadi_E/0/1/0/all/0/1\">Esfandiar Mohammadi</a>"
}