{
  "title": "Beginners Guide: Apache Spark Python — Machine Learning Scenario With A Large Input Dataset",
  "link": "https://fullstackml.com/beginners-guide-apache-spark-python-machine-learning-scenario-with-a-large-input-dataset-3fd1c319bbc?source=rss----46e065078cc1---4",
  "guid": "https://medium.com/p/3fd1c319bbc",
  "category": [
    "dataset",
    "machine-learning",
    "apache-spark",
    "python"
  ],
  "dc:creator": "Dmitry Petrov",
  "pubDate": "Tue, 10 Nov 2015 16:59:19 GMT",
  "atom:updated": "2017-03-06T05:38:09.007Z",
  "content:encoded": "<p>In the previous post <a href=\"http://fullstackml.com/2015/10/29/beginners-guide-apache-spark-machine-learning-scenario-with-a-large-input-dataset/\">“Beginners Guide: Apache Spark Machine Learning Scenario With A Large Input Dataset”</a> we discussed the process of creating predictive model with 34 gigabytes of input data using Apache Spark. I received a request for the Python code as a solution instead of Scala. This is exactly what I will do in this post.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/680/1*BlizS0SYUWuhAU5v5kkLiA.jpeg\" /><figcaption>This Python image was taken from <a href=\"https://realpython.com/learn/python-first-steps/\">this web page</a>.</figcaption></figure><h3>1. Python and Scala difference</h3><p>Python solution looks similar to the last Scala solution because when you look “under the hood” you have the same Spark library and engine. Because of this fact, I don’t anticipate any significant performance change. As there aren’t many difference between Python and Scala, I will highlight only the major ones and you can refer back to the last post for the code in it’s entirety.</p><h4>2. Sources</h4><p>The complete source code of this program could be found <a href=\"https://www.dropbox.com/s/zg50yhju9g1rzxe/beginner_spark_ml.py?dl=0\">here</a>. Scala version from the previous post is <a href=\"https://www.dropbox.com/s/4ljc2jtew6fbgn2/beginner_spark_ml.scala?dl=0\">here</a>. Small 128MB testing dataset is <a href=\"https://www.dropbox.com/s/n2skgloqoadpa30/Posts.small.xml?dl=0\">here</a>.</p><p>Entire 34GB dataset is available here at <a href=\"https://archive.org/details/stackexchange,\">https://archive.org/details/stackexchange,</a> look at file Posts.xml in stackoverflow.com folder. Copy of 34GB Posts.xml file is <a href=\"https://www.dropbox.com/s/ph0wi589mzlqzbe/Posts.xml.zip?dl=0\">here </a>(8GB compressed). This data is licensed under the Creative Commons license (<a href=\"http://creativecommons.org/licenses/by-sa/2.5/\">cc-by-sa</a>).</p><h3>3. Python code</h3><p>In the Python version of code (<a href=\"https://www.dropbox.com/s/zg50yhju9g1rzxe/beginner_spark_ml.py?dl=0\">source file</a>) I create a correct Label column directly without intermediate sqlfunc\\myudf function. Otherwise you should upload code of this function through intermediate python file to a Spark environment (sc.addPyFile() method). For the same reason I do not use xml libraries.</p><iframe src=\"\" width=\"0\" height=\"0\" frameborder=\"0\" scrolling=\"no\"><a href=\"https://medium.com/media/11ec9c23ebc27f466548f1237cc925a4/href\">https://medium.com/media/11ec9c23ebc27f466548f1237cc925a4/href</a></iframe><p>One of the issues of Python version of code - we won't decode xml meta symbols like <strong><</strong>. Let's keep these symbols for now.</p><p>Python code needs couple more temporary variables in the data preparation step (negTrainTmp1 and posTrainTmp1).</p><iframe src=\"\" width=\"0\" height=\"0\" frameborder=\"0\" scrolling=\"no\"><a href=\"https://medium.com/media/514d72ab20d512d0121a4f702d3a9464/href\">https://medium.com/media/514d72ab20d512d0121a4f702d3a9464/href</a></iframe><p>Small changes in the model validation step:</p><iframe src=\"\" width=\"0\" height=\"0\" frameborder=\"0\" scrolling=\"no\"><a href=\"https://medium.com/media/b54d68e4fda968371525d91f7f1e7a9a/href\">https://medium.com/media/b54d68e4fda968371525d91f7f1e7a9a/href</a></iframe><p>That's all the changes that we need.</p><h3>Conclusion</h3><p>Thank you for all the great feedback to the previous post <a href=\"http://fullstackml.com/2015/10/29/beginners-guide-apache-spark-machine-learning-scenario-with-a-large-input-dataset/\">\"Beginners Guide: Apache Spark Machine Learning Scenario With A Large Input Dataset\"</a>. The reception helped me to see where the needs and demands are in this field. I welcome all suggestions so keep the feedback coming and I'll try to address as many as I humanly can.</p><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=3fd1c319bbc\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://fullstackml.com/beginners-guide-apache-spark-python-machine-learning-scenario-with-a-large-input-dataset-3fd1c319bbc\">Beginners Guide: Apache Spark Python — Machine Learning Scenario With A Large Input Dataset</a> was originally published in <a href=\"https://fullstackml.com\">FullStackML</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
}