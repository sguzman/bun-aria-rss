{
  "title": "Using SQL Workbench with Apache Hive",
  "description": "<p>If you’ve spent any non-trivial amount of time working with Hadoop and Hive at the command line, you’ve likely wished that you could interact with Hadoop like you would any other database. If you’re lucky, your Hadoop administrator has already installed the <a href=\"http://gethue.com/\">Apache Hue</a> front-end to your cluster, which allows for <a href=\"http://randyzwitch.com/uploading-data-hadoop-amazon-ec2-cloudera-part-3/\">interacting with Hadoop via an easy-to-use browser interface</a>. However, if you don’t have Hue, Hive also supports access via JDBC; the downside is, setup is not as easy as including a single JDBC driver.</p>",
  "pubDate": "Fri, 25 Apr 2014 14:05:57 +0000",
  "link": "http://randyzwitch.com/sql-workbench-apache-hadoop-hive/",
  "guid": "http://randyzwitch.com/sql-workbench-apache-hadoop-hive/",
  "content": "<p>If you’ve spent any non-trivial amount of time working with Hadoop and Hive at the command line, you’ve likely wished that you could interact with Hadoop like you would any other database. If you’re lucky, your Hadoop administrator has already installed the <a href=\"http://gethue.com/\">Apache Hue</a> front-end to your cluster, which allows for <a href=\"http://randyzwitch.com/uploading-data-hadoop-amazon-ec2-cloudera-part-3/\">interacting with Hadoop via an easy-to-use browser interface</a>. However, if you don’t have Hue, Hive also supports access via JDBC; the downside is, setup is not as easy as including a single JDBC driver.</p>\n\n<p>While there are paid database administration tools such as <a href=\"http://www.aquafold.com/dbspecific/apache_hive_client.html\">Aqua Data Studio</a> that support Hive, I’m an open source kind of guy, so this tutorial will show you how to use <a href=\"http://www.sql-workbench.net/\">SQL Workbench</a> to access Hive via JDBC. This tutorial assumes that you are proficient enough to get SQL Workbench installed on whatever computing platform you are using (Windows, OSX, or Linux).</p>\n\n<h3 id=\"download-hadoop-jars\">Download Hadoop jars</h3>\n\n<p>The hardest part of using Hive via JDBC is getting all of the required jars. At work I am using a <a href=\"http://www.mapr.com/\">MapR distribution of Hadoop</a>, and each Hadoop vendor platform provides drivers for their version of Hadoop. For MapR, all of the required Java .jar files are located at <code class=\"language-plaintext highlighter-rouge\">/opt/mapr/hive/hive-0.1X/lib</code> (where X represents the Hive version number you are using).</p>\n\n<p><img src=\"/wp-content/uploads/2014/04/mapr-hive-jars.png\" alt=\"mapr-hive-jars\" /></p>\n\n<p class=\"wp-caption-text\">\n    Download all the .jar files in one shot, just in case you need them in the future\n </p>\n\n<p>Since it’s not always clear which .jar files are required (especially for other projects/setups you might be doing), I just downloaded the entire set of files and placed them in a directory called <code class=\"language-plaintext highlighter-rouge\">hadoop_jars</code>. If you’re not using MapR, you’ll need to find and download your vendor-specific version of the following .jar files:</p>\n\n<ul>\n  <li>hive-exec.jar</li>\n  <li>hive-jdbc.jar</li>\n  <li>hive-metastore.jar</li>\n  <li>hive-service.jar</li>\n</ul>\n\n<p>Additionally, you will need the following general Hadoop jars (Note: for clarity/long-term applicability of this blog post, I have removed the version number from all of the jars):</p>\n\n<ul>\n  <li>hive-cli.jar</li>\n  <li>libfb303.jar</li>\n  <li>slf4j-api.jar</li>\n  <li>commons-logging.jar</li>\n  <li>hadoop-common.jar</li>\n  <li>httpcore.jar</li>\n  <li>httpclient.jar</li>\n</ul>\n\n<p>Whew. Once you have the Hive JDBC driver and the 10 other .jar files, we can begin the installation process.</p>\n\n<h3 id=\"setting-up-hive-jdbc-driver\">Setting up Hive JDBC driver</h3>\n\n<p>Setting up the JDBC driver is simply a matter of providing SQL Workbench with the location of all 11 of the required .jar files. After clicking <code class=\"language-plaintext highlighter-rouge\">File -&gt; Manage Drivers</code>, you’ll want to click on the white page icon to create a New Driver. Use the Folder icon to add the .jars:</p>\n\n<p><img src=\"/wp-content/uploads/2014/04/sqlworkbench-hive-driver-setup.png\" alt=\"sqlworkbench-hive-driver-setup\" /></p>\n\n<p>For the <code class=\"language-plaintext highlighter-rouge\">Classname</code> box, if you are using a relatively new version of Hive, you’ll be using Hive2 server. In that case, the <code class=\"language-plaintext highlighter-rouge\">Classname</code> for the Hive driver is <code class=\"language-plaintext highlighter-rouge\">org.apache.hive.jdbc.HiveDriver</code> (this should pop up on-screen, you just need to select the value). You are not required to put any value for the Sample URL. Hit <code class=\"language-plaintext highlighter-rouge\">OK</code> and the driver window will close.</p>\n\n<h3 id=\"connection-window\">Connection Window</h3>\n\n<p>With the Hive driver defined, all that’s left is to define the connection string. Assuming your Hadoop administrator didn’t change the default <code class=\"language-plaintext highlighter-rouge\">port</code> from <code class=\"language-plaintext highlighter-rouge\">10000</code>, your connection string should look as follows:</p>\n\n<p><img src=\"/wp-content/uploads/2014/04/sqlworkbench-hive-connectionstring.png\" alt=\"sqlworkbench-hive-connectionstring\" /></p>\n\n<p>As stated above, I’m assuming you are using Hive2 Server; if so, your connection string will be <code class=\"language-plaintext highlighter-rouge\">jdbc:hive2://your-hadoop-cluster-location:10000</code>. After that, type in your Username and Password and you should be all set.</p>\n\n<h3 id=\"using-hive-with-sql-workbench\">Using Hive with SQL Workbench</h3>\n\n<p>Assuming you have achieved success with the instructions above, you’re now ready to use Hive like any other database. You will be able to submit your Hive code via the Query Window, view your schemas/tables (via the ‘Database Explorer’ functionality which opens in a separate tab) and generally use Hive like any other relational database.</p>\n\n<p>Of course, it’s good to remember that Hive isn’t actually a relational database! From my experience, using Hive via SQL Workbench works pretty well, but the underlying processing is still in Hadoop. So you’re not going to get the clean cancelling of queries like you would with an RDBMS , there can be a significant lag to getting answers back (due to the Hive overhead), you can blow up your computer streaming back results larger than available RAM…but it beats working at the command line.</p>"
}