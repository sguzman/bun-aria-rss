{
  "title": "Where will Artificial Intelligence come from?",
  "link": "",
  "published": "2016-04-20T23:30:00+01:00",
  "updated": "2016-04-20T23:30:00+01:00",
  "author": {
    "name": "Sebastian Nowozin"
  },
  "id": "tag:www.nowozin.net,2016-04-20:/sebastian/blog/where-will-artificial-intelligence-come-from.html",
  "summary": "<p>Artificial Intelligence (AI) is making progress in great strides, or at least\nit appears so!\nAlmost no week passes by without some major announcements of new challenges\nsolved by AI technology or new products powered by AI.</p>\n<p>Indeed many quantifiable â€¦</p>",
  "content": "<p>Artificial Intelligence (AI) is making progress in great strides, or at least\nit appears so!\nAlmost no week passes by without some major announcements of new challenges\nsolved by AI technology or new products powered by AI.</p>\n<p>Indeed many quantifiable factors attest an unprecedented level of activity:\ncapital investments, number of academic papers, number of products involving AI technology, they all are on a steep rise in the past five years.</p>\n<p>Computers are already very capable at some specialized tasks that require\nreasoning and other abilities that we typically associate with intelligence.\nFor example, computers can play a decent game of chess or can help us order\nour holiday photos.\nDespite this genuine progress, we are still a long way from human level\nintelligence because our best artificial intelligence systems are not\n<em>general</em> purpose.\nThey cannot quickly adapt to novel tasks the way most humans can do.</p>\n<p>When talking about artificial intelligent systems there is a risk of\nemphasizing humans too much.  Computers are <em>already</em> more capable than any\nhuman at many tasks, for example in numerical computation and search.\nYet, in discussions about artificial intelligence we emphasize the shrinking\nset of abilities where humans still outperform machines.\nFor a nice and more balanced recent discussion on issues surrounding\nartificial intelligence I recommend reading the <a href=\"http://edge.org/responses/q2015\">edge\ncontributions towards the Edge 2015\nquestion</a>.</p>\n<p>As artificial intelligence continues to make progress, I would like to ask the\nfollowing question:</p>\n<p><strong>Where will the next major advance towards general purpose artificial\nintelligence come from?</strong></p>\n<p>Below I list seven possible areas which I believe could be the answer to this\nquestion; these answers are highly subjective and biased and they may be all\nwrong, but hopefully they do contain some interesting pointers for everyone.</p>\n<p>The point of this exercise is to show that there are many strands of active\nresearch that could result in major AI advances.\nSo here are they, the seven areas where a major general purpose AI\nbreakthrough could come from.</p>\n<h1>1. Composable Differentiable Architectures (aka Deep Learning)</h1>\n<p><em>Composable differentiable architectures</em> describes current state-of-the-art\ndeep learning systems.\nFrameworks such as\n<a href=\"http://caffe.berkeleyvision.org/\">Caffe</a>,\n<a href=\"http://deeplearning.net/software/theano/\">Theano</a>,\n<a href=\"http://torch.ch/\">Torch</a>,\n<a href=\"http://chainer.org/\">Chainer</a>, all allow the specification of function\nclasses and to automatically compose and differentiate such functions.\nBecause of this mix-and-match composability there is a frictionless and rapid\ndiffusion of components and (sub-)models across application domains.</p>\n<p>This <em>commoditizes</em> machine learning and allows customization to specific\napplications;\nit commoditizes machine learning because the level of knowledge required to\nleverage modern deep learning frameworks is low.\nThese deep learning frameworks also allow for easy\n<em>customization</em> of the model to the application at hand.\nYears ago, this <em>was</em> the unattained dream for graphical models, but today it\n<em>is</em> achieved by deep learning frameworks where bespoke models are build for\nmost applications.</p>\n<p><img alt=\"Deep tree\" src=\"http://www.nowozin.net/sebastian/blog/images/ai-deep-tree.png\"></p>\n<p>But is it enough for general purpose AI?  What is missing?</p>\n<p>I believe there are two obstacles;\n<em>first</em>, almost all deep learning systems\nrequire large amounts of supervised data to work.\nFor high-value industrial applications this may be okay because the required\nlabel data can be collected.\nHowever, there is a long tail of useful applications where label data is rare\nbut unlabeled data is abundant.\nFuture AI systems need to be able to leverage this abundant data source.</p>\n<p><em>Second</em>, what is missing are general architectures for reasoning, and an\nintense search for such building blocks is currently taking place.  Maybe\nclassic ideas from AI, such as <em>blackboard systems</em>, could be adapted and made\ndifferentiable to enable reasoning, or maybe some entirely unexpected new\nbuilding block will appear.</p>\n<p>Besides better models, the key novel technology to look out for in deep\nlearning is custom hardware and novel engineering abstractions.\nCustom hardware could enable energy savings, or increased speed, or both.\nCurrent deep learning piggybacks on GPU development funded largely by the\ngaming industry.  This is a great thing because developing a new GPU\ngeneration such as Nvidia's new Pascal GPU requires very large research and\ndevelopment budgets.\nNovel engineering abstractions in the form of next generation deep learning\nframeworks could enable automatic scalability, distributed computation, or\noffer help in identifying the right architecture for the task.</p>\n<p><em>Scalability</em> is important beyond just training speed.  For example, consider\n<a href=\"http://people.idsia.ch/~juergen/raw.html\">basic estimates of the computing power of the human\nbrain</a> or the following quote from a\n<a href=\"http://www.macleans.ca/society/science/the-meaning-of-alphago-the-ai-program-that-beat-a-go-champ/\">recent interview with Geoff\nHinton</a>.</p>\n<blockquote>\n<p>\"So in the brain, you have connections between the neurons called synapses,\nand they can change. All your knowledge is stored in those synapses. You\nhave about 1,000-trillion synapses-10 to the 15, it's a very big number. So\nthat's quite unlike the neural networks we have right now. They're far, far\nsmaller, the biggest ones we have right now have about a billion synapses.\nThat's about a million times smaller than the brain.\"</p>\n</blockquote>\n<p>This puts up a ballpark estimate for the number of primitive computational\nunits in the human brain, and it is quite reasonable to attempt to achieve\nthis scale.</p>\n<p>One important fact to consider: the driving force behind applications of deep\nlearning is largely the industry, and this will remain the case as long as it\npays dividends (it does so greatly at the moment).</p>\n<h1>2. Brain Simulations</h1>\n<p>Understanding the brain and simulating it is what I think of as the\n<em>safe route</em> to general AI.\nWe do not know whether it will take 5, 50, or 500 years, but it is likely\nthat we eventually will get there and be able to accurately simulate an\nartificial brain which is functionally indistinguishable from a real human\nbrain.</p>\n<p><img alt=\"Human brain\" src=\"http://www.nowozin.net/sebastian/blog/images/ai-gauss-brain.png\"></p>\n<p>Novel technology and approaches to study neural systems, such as\n<a href=\"http://edge.org/conversation/ed_boyden-how-the-brain-is-computing-the-mind\">optogenetics</a>,\n<a href=\"http://www.nature.com/nnano/journal/v8/n2/full/nnano.2012.265.html\">multi-electrode arrays</a>\nand \n<a href=\"https://en.wikipedia.org/wiki/Connectomics\">connectomics</a>, eventually will\nenable us to obtain a high-fidelity understanding of the brain.\nLikewise, increase in computation and custom hardware will allow accelerated\nsimulation of neural models.</p>\n<p>Most of the investments in this area of research are government funds, for\nexample through the large\nUS <a href=\"https://en.wikipedia.org/wiki/BRAIN_Initiative\">BRAIN initiative</a> and the\n<a href=\"https://en.wikipedia.org/wiki/Human_Brain_Project\">Human Brain Project</a>, and\nmore general neuroscience funding.</p>\n<h1>3. Algorithmic Information Theory and Universal Intelligence</h1>\n<p>Whatever intelligence is, if we were to accept the possibility of a\nmathematical theory for it, the closest contenders for such theory are found\nin a field called algorithmic information theory.\nIf you have not heard of algorithmic information theory before, <a href=\"https://en.wikipedia.org/wiki/Gregory_Chaitin\">Gregory\nChaitin</a> recently wrote <a href=\"http://inference-review.com/article/doing-mathematics-differently\">an\nexcellent essay on the conceptual roots of algorithmic information\ntheory</a> and\nthe general history of notions of complexity in science and mathematics.</p>\n<p>One approach which leverages algorithmic information theory for general\nartificial intelligence is the\n<a href=\"https://en.wikipedia.org/wiki/AIXI\">AIXI agent</a>, a\ntheory put forward by <a href=\"http://www.hutter1.net/\">Marcus Hutter</a> that attempts\nto be universal in the sense that it will successfully and optimally solve any\nsolvable tasks.\nAt its heart it is a <a href=\"http://www.nowpublishers.com/article/Details/MAL-049\">Bayesian reinforcement learning\nagent</a> where the\nhypothesis space are possible programs of a <a href=\"https://en.wikipedia.org/wiki/Turing_machine\">Turing\nmachine</a>.\nIt is an extension of an earlier idea to consider Turing machines for\npredicting future symbols in an observed sequence.  This idea is\n<a href=\"https://en.wikipedia.org/wiki/Solomonoff's_theory_of_inductive_inference\">Solomonoff induction</a> proposed by <a href=\"http://world.std.com/~rjs/tributes/vitanyi.html\">Ray\nSolomonoff</a>.\nBecause Turing machines are universal any computable hypothesis can be\nentertained.\nAIXI extends this idea from mere prediction of symbols to acting in an unknown\nenvironment, that is, to <a href=\"https://en.wikipedia.org/wiki/Reinforcement_learning\">reinforcement\nlearning</a>.</p>\n<p><img alt=\"Alan Turing\" src=\"http://www.nowozin.net/sebastian/blog/images/ai-turing.png\"></p>\n<p>Grounding intelligence in Turing machines is very appealing: not only is it\nuniversal, but allows the <a href=\"http://arxiv.org/abs/0712.3329\">formal <em>definition</em> of universal\nintelligence</a> as well.\nIn essence, reasoning and acting intelligently is reduced to formal\nmanipulation of a notion of complexity defined by programs on a Turing\nmachine.  See also <a href=\"http://people.idsia.ch/~juergen/\">J&uuml;rgen\nSchmidhuber</a>'s <a href=\"http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=48FFC58A49C83119D49EB93C5AA2A975?doi=10.1.1.7.2717&amp;rep=rep1&amp;type=pdf\">speed prior for Turing\nmachines</a>.</p>\n<p>Despite this promise, so far we do not see impressive results achieved by AIXI\nagents.  Why not?\nThere are at least two obstacles:</p>\n<ol>\n<li>\n<p>Universal Turing machines are not practically implementable and\n<a href=\"https://arxiv.org/abs/1510.05572\">approximating AIXI is hard</a>; there have\nbeen some approximation attempts, e.g. in the work of <a href=\"http://www.aaai.org/Papers/JAIR/Vol40/JAIR-4004.pdf\">(Veness et al., JAIR\n2011)</a>, but at best\nresults have matched other reinforcement learning methods without enabling\nnovel applications that were out of reach before.\nMore recently <a href=\"http://people.idsia.ch/~juergen/\">J&uuml;rgen Schmidhuber</a>\nproposed a more practical integration of recurrent neural network models of\nthe world with algorithmic information theory in the form of <a href=\"http://arxiv.org/abs/1511.09249\">RNN-based\nAIs</a>.</p>\n</li>\n<li>\n<p>The choice of Turing machine is not clear.\nThere is an infinite set of possible universal Turing machines and we could\nreasonably hope that the particular choice would not influence the agent\nefficiency except perhaps for some small overhead.\n(For a related example, the <a href=\"https://en.wikipedia.org/wiki/Kolmogorov_complexity\">Kolmogorov\ncomplexity</a> of a sequence\nis defined through a Turing machine, but whatever the choice of a Turing\nmachine there is an invariance property in that only a constant overhead\nintroduced compared to any other Turing machine.)\n<a href=\"https://arxiv.org/abs/1510.04931\">Unfortunately for AIXI this is not the\ncase</a>: the choice of Turing machine\ncan determine the behaviour of the AIXI agent entirely.\n(This may also affects Bayesian reinforcement learning more generally: when\nusing a non-parametric prior process the choice of prior may determine more\nthan intended.)</p>\n</li>\n</ol>\n<p>This recent negative result leaves AIXI in an interesting state at the moment.\nIt is clearly the most complete theory of universal agents we have at the\nmoment, see e.g. <a href=\"https://arxiv.org/abs/1202.6153\">Hutter's own review from\n2012</a>, but it may turn out to be entirely\nsubjective (if no \"<em>natural</em>\" Turing machine can be identified) or practically\nunworkable.</p>\n<h1>4. Artifical Life</h1>\n<p>In the above section on brain simulation I argued that by understanding the\nhuman brain and then simulating it we will eventually be able to attain\nhuman-level intelligence.\nHowever, we can start at a more basic level: by understanding and simulating a\nsynthetic form of chemistry we may be able to simulate artificial life.\nGiven a sufficiently rich environment such life may evolve to become\nintelligent.</p>\n<p>The field of <em>Artificial Life</em> (ALife) studies the formation and dynamics of\nlife itself on top of artifical simulations of life.\nThis life does not need to be intelligent, and in fact, so far no such\nsimulation has produced life with the intelligence beyond that of a simple\norganism.  But it is clear that <a href=\"https://en.wikipedia.org/wiki/Tierra_%28computer_simulation%29\">since the early\n1990'ies</a>, by\nany generally plausible definition of life (of which there are many and there\nis some controversy), artificial life does indeed spontaneously form in\ncomputer simulations and complex evolutionary dynamics such as symbiosis and\nparasites do occur in these simulations.</p>\n<p>For a dated but inspiring introduction to the field of artificial life\nmore generally, see <a href=\"http://adamilab.msu.edu/\">Christoph Adami</a>'s <a href=\"http://www.springer.com/us/book/9781461272311\">book on\nArtificial Life</a>.\nAdami also wrote a recent <a href=\"http://adamilab.blogspot.co.uk/2015/12/evolving-intelligence-with-little-help.html\">article on evolving artificial\nintelligence</a>\nthat highlights current research issues for the goal to evolve artificial\nintelligence.</p>\n<p>More fundamentally, in <a href=\"http://adamilab.blogspot.com/2013/02/your-conscious-you.html\">another\narticle</a> Adami\nargues that from theoretical results in a field called <a href=\"https://en.wikipedia.org/wiki/Integrated_information_theory\"><em>integrated\ninformation\ntheory</em></a> (and\nwhich I have not heard of before), one possible consequence may be that due to\nthe complexity of general intelligence it is not possible to design it but\ninstead an evolutionary approach is needed.</p>\n<p>Given that our goal is to evolve intelligence artifically, fundamentally there\nare the following obstacles in producing useful general artificial\nintelligence through artificial life:</p>\n<p><img alt=\"Anomalocaris\" src=\"http://www.nowozin.net/sebastian/blog/images/ai-anomalocaris.png\"></p>\n<ol>\n<li>\n<p>The <em>big intelligence filter</em> hypothesis.\nThis hypothesis goes as follows: life may be abundant but intelligent life may\nbe exceedingly rare.\nWe currently do not know if intelligent life is rare or abundant in the\nuniverse, but if it is rare, it may also be exceedingly rare in any simulation\nof artificial life.\nA related point is what is known as the <em>Fermi paradox</em>, namely, that what\nscience tells us about astrophysics implies we should have likely observed alien\ncivilizations by now, but this has not happened yet.  (See Tim Urban's\nwonderful article on the <a href=\"http://waitbutwhy.com/2014/05/fermi-paradox.html\">Fermi's\nparadox</a>.)\nEven for life on our own planet we are not sure what triggered intelligence to\nappear; one widely believed hypothesis is that it happened in a short time,\nakin to a phase transition, due to a change in ocean oxygen levels 540 million\nyears ago, leading to the <a href=\"http://www.nature.com/news/what-sparked-the-cambrian-explosion-1.19379\">Cambrian\nexplosion</a>.</p>\n</li>\n<li>\n<p>Harnessing intelligence.\nOne of our closest genetic relatives, the chimpanzee, are clearly intelligent,\nbut harnessing this intelligence for something useful is difficult.\nNow imagine a giant squid, swimming a kilometer deep within the ocean.\nLikely they are also intelligent but we can hardly leverage this for anything\nuseful.\nWho knows which form intelligent artificial life will take?\nWill we be able to recognize this life as intelligent?\nIf we do, such life will likely be similar to encountering an alien species in\nour universe: unlike anything you can imagine or predict beforehand.\nThat is to say, we may be able to achieve intelligent artificial life but may\nstill struggle to make it useful.\nEven with full control over the simulation environment, a god-like state if\nyou will, it seems necessary that to make artificial intelligence life useful\nwe will at least have to decode its representation or ``language'' and\nunderstand the incentives sufficiently well in order to communicate with such\nintelligence and motivate it to work for us.</p>\n</li>\n</ol>\n<p><img alt=\"Giant squid\" src=\"http://www.nowozin.net/sebastian/blog/images/ai-octopus-drawing.png\"></p>\n<p>In summary, the evolutionary approach to constructing AIs is promising in the\nlong run and there are now several labs working on it\n(the labs of <a href=\"http://adamilab.msu.edu/\">Adami</a>,\n<a href=\"http://www.evolvingai.org/\">Clune</a>, and <a href=\"http://hintzelab.msu.edu/\">Hintze</a>).</p>\n<h1>5. Robotics and Autonomous Systems</h1>\n<p>Autonomous robots are rapidly conquering novel applications in industry and\nconsumer space, such as in self-driving cars, agricultural robotics,\n<a href=\"https://en.wikipedia.org/wiki/Industry_4.0\">industry 4.0</a>, and drones.</p>\n<p>The key enablers of this development are improved sensing technology (e.g.\nlow-cost depth sensors), increased compute and memory capacities, and improved\npattern recognition methods.\nAs a result of the maturity of basic required technologies significant\nindustry capital is invested in driving advanced autonomous robotics research.</p>\n<p>Beyond the natural urge to feel scared by autonomous machines, how could this\nlead to a breakthrough in artificial intelligence that cannot be found in one\nof the constituent technologies?</p>\n<p><img alt=\"Humanoid robot\" src=\"http://www.nowozin.net/sebastian/blog/images/ai-robot.png\"></p>\n<p>One line of thought in the field of <a href=\"https://en.wikipedia.org/wiki/Embodied_cognition\">embodied\ncognition</a> argues that\nan intelligent system is conditioned on its environment in a fundamental way,\nshaping the allocation of precious (evolutionary) resources in order to\nmaximally exploit the types of sensors and actuators available to it.\nTherefore the specific nature of sensing and acting abilities is not ancillary\nto intelligence but the main driving force that enables intelligence in the\nfirst place.</p>\n<p>If the above thesis were true, autonomous robots with modern sensors and\nactuators would provide a rich enough <em>embodiment</em> for artificial\nintelligence, and the lack of such an embodiment in other domains would likely\nimpede the emergence of general intelligence.</p>\n<p>In the past decade, the European Union, through its robotics programme in the\n7th Framework Programme (FP7, totalling more than 50 billion Euro for\n2007-2013) has placed an emphasis on <em>combining</em> cognition with robotics at\nthe exclusion of funding research on artificial intelligence not involving\nrobotics.\nHowever, many of the resulting <a href=\"http://cordis.europa.eu/fp7/ict/robotics/projects/understanding/learning_en.html\">large research projects of that\ntime</a>\nare more reflecting the ample funding availability rather than representing\nprogress on fundamental questions of cognition.</p>\n<h1>6. Game Playing</h1>\n<p>Games entertain humans; what could they do to enable artificial intelligence?</p>\n<p>The answer: quite a lot!\nGames are designed to challenge our intellect, involve interactions\nbetween multiple agents, and are sufficiently abstract to be formalized.\nA computer-implemented game can be as simple and abstract as tic-tac-toe,\nChess, or Go, or as sophisticated and close to reality as the latest Grand\nTheft Auto game.</p>\n<p><img alt=\"Dice\" src=\"http://www.nowozin.net/sebastian/blog/images/ai-dice.png\"></p>\n<p>Therefore games are an almost ideal research vehicle to drive artificial\nintelligence research.\n<a href=\"http://engineering.nyu.edu/people/julian-togelius\">Julian Togelius</a> argues\nthis point eloquently in <a href=\"http://togelius.blogspot.co.uk/2016/01/why-video-games-are-essential-for.html\">a recent\narticle</a>.</p>\n<p>In fact, there are now popular game playing competitions and platforms which\ndrive AI research:\nthe Stanford <a href=\"http://games.stanford.edu/\">general game playing competition</a>,\nthe <a href=\"http://www.computerpokercompetition.org/\">Computer Poker Competition</a>,\nthe <a href=\"http://webdocs.cs.ualberta.ca/~cdavid/starcraftaicomp/report2015.shtml\">StarCraft AI Competition</a>,\nthe <a href=\"http://www.arcadelearningenvironment.org/\">Atari 2600 Arcade Learning Environment</a>, and, most recently\n<a href=\"https://blogs.microsoft.com/next/2016/03/13/project-malmo-using-minecraft-build-intelligent-technology/\">Microsoft's Minecraft AI environment\n(Malmo)</a>.</p>\n<p>It is likely that such platforms will provide diverse and challenging\nenvironments for testing the abilities of artificial general intelligence\nagents, thus accelerating research and enabling breakthroughs.  Perhaps the\nnext breakthrough will be in the form of mastering another game.</p>\n<h1>7. Knowledge Bases</h1>\n<p>A knowledge base is a discrete representation of basic facts and relations\nabout entities.\nLarge-scale knowledge bases constructed semi-automatically from the web are\nalready incredibly useful commercially and they power search engine results and\npersonal assistants.</p>\n<p><img alt=\"Couple\" src=\"http://www.nowozin.net/sebastian/blog/images/ai-couple.png\"></p>\n<p>In search results they provide highly accurate results for known entities in\nall major search engines (e.g. <a href=\"https://en.wikipedia.org/wiki/Knowledge_Graph\">Knowledge\nGraph</a> and <a href=\"https://en.wikipedia.org/wiki/Knowledge_Vault\">Knowledge\nVault</a> in Google,\n<a href=\"http://arstechnica.com/information-technology/2012/06/inside-the-architecture-of-googles-knowledge-graph-and-microsofts-satori/\">Satori</a> in Microsoft Bing).\nTo see an example, search for a well-known person, e.g. \"Stanislaw Ulam\"\n(<a href=\"http://www.bing.com/search?q=Stanislaw+Ulam&amp;go=Submit+Query&amp;qs=bs&amp;form=QBLH\">results from Bing</a>, <a href=\"https://www.google.com/?gws_rd=ssl#safe=off&amp;q=Stanislaw+Ulam\">results from Google</a>) and observe that the details about the person displayed.</p>\n<p>In personal intelligent assistants such as\n<a href=\"http://www.apple.com/ios/siri/\">Apple Siri</a>,\n<a href=\"https://www.google.com/landing/now/\">Google Now</a>,\n<a href=\"https://www.microsoft.com/en-us/mobile/experiences/cortana/\">Microsoft Cortana</a>, or\n<a href=\"https://www.amazon.com/gp/help/customer/display.html?nodeId=201549800\">Amazon Alexa</a>\nthey are responsible for providing facts in basic reasoning abilities.  For\nexample, in order to answer queries such as \"Who was the president following\nThomas Jefferson?\" a basic natural language understanding ability and a large\nknowledge base go a long way.</p>\n<p>But can knowledge bases provide the substrate for artificial intelligence?\nThe <a href=\"https://en.wikipedia.org/wiki/Cyc\">Cyc project</a> started in 1984 and the\n<a href=\"https://en.wikipedia.org/wiki/Open_Mind_Common_Sense\">Open Mind Common Sense\nproject</a> started in\n1999 are both based on the belief that in order to enable artificial\nintelligence we need to encode common sense reasoning, particularly the\nentities and relationships of everyday life.\nThe hope was that knowledge, encoded in this way, will make reasoning and\ndiscovery of novel knowledge simpler.</p>\n<p>It is fair to say, that while the (commercial) usefulness of knowledge bases\nfor intelligent applications is now well established, it is too early to say\nwhether general artificial intelligence would require reasoning on top of an\nexplicit symbolic knowledge base.\nPerhaps a more continuous and non-symbolic representation of knowledge that\nsupports reasoning is sufficient.</p>\n<h1>Conclusion</h1>\n<p>The goal of artificial general intelligence (AGI) is challenging and exciting\non many levels.\nIn all likelihood artificial intelligence will make rapid progress in the next\ndecade, perhaps along the directions we just discussed.</p>\n<p><em>Acknowledgements</em>.  I thank\n<a href=\"http://people.idsia.ch/~juergen/\">J&uuml;rgen Schmidhuber</a>,\n<a href=\"http://inverseprobability.com/\">Neil Lawrence</a>,\n<a href=\"http://research.microsoft.com/en-us/um/people/pkohli/\">Pushmeet Kohli</a>,\n<a href=\"http://adamilab.msu.edu/\">Chris Adami</a>, and\n<a href=\"http://www.cs.rhul.ac.uk/home/chrisw/\">Chris Watkins</a>\nfor feedback, pointers to literature, and corrections on\na draft version of the article.</p>\n<p><em>Image credits</em>.\nThe tree image is licensed CC-BY-SA by\n<a href=\"http://adoomer.deviantart.com/art/Tree-of-life-190974117\">adoomer</a>.\nThe brain image is a drawing of the brain of Gauss and is <a href=\"https://commons.wikimedia.org/wiki/File:PSM_V26_D768_Brain_of_gauss.jpg\">public\ndomain</a>.\nThe Anomalocaris image is CC-BY-3.0 licensed art by <a href=\"https://commons.wikimedia.org/wiki/File:Anomalocaris_BW.jpg\">Nobu\nTamura</a>.\nThe octopus image is CC-BY-2.0 licensed art by <a href=\"https://www.flickr.com/photos/bibliodyssey/\">Paul\nK</a>.\nThe robot image is licensed CC-BY-2.0 by\n<a href=\"https://www.flickr.com/photos/striatic/245603625/\">striatic</a>.\nThe dice image is public domain by Personeoneste.\nThe couple image is <a href=\"https://commons.wikimedia.org/wiki/File:Her-aide-de-camp-Early-19thc-Humorous.png\">public\ndomain</a>.</p>",
  "category": ""
}