{
  "title": "coVariance Neural Networks. (arXiv:2205.15856v3 [cs.LG] UPDATED)",
  "link": "http://arxiv.org/abs/2205.15856",
  "description": "<p>Graph neural networks (GNN) are an effective framework that exploit\ninter-relationships within graph-structured data for learning. Principal\ncomponent analysis (PCA) involves the projection of data on the eigenspace of\nthe covariance matrix and draws similarities with the graph convolutional\nfilters in GNNs. Motivated by this observation, we study a GNN architecture,\ncalled coVariance neural network (VNN), that operates on sample covariance\nmatrices as graphs. We theoretically establish the stability of VNNs to\nperturbations in the covariance matrix, thus, implying an advantage over\nstandard PCA-based data analysis approaches that are prone to instability due\nto principal components associated with close eigenvalues. Our experiments on\nreal-world datasets validate our theoretical results and show that VNN\nperformance is indeed more stable than PCA-based statistical approaches.\nMoreover, our experiments on multi-resolution datasets also demonstrate that\nVNNs are amenable to transferability of performance over covariance matrices of\ndifferent dimensions; a feature that is infeasible for PCA-based approaches.\n</p>",
  "dc:creator": "<a href=\"http://arxiv.org/find/cs/1/au:+Sihag_S/0/1/0/all/0/1\">Saurabh Sihag</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mateos_G/0/1/0/all/0/1\">Gonzalo Mateos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McMillan_C/0/1/0/all/0/1\">Corey McMillan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ribeiro_A/0/1/0/all/0/1\">Alejandro Ribeiro</a>"
}