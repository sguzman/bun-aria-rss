<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:cc="http://cyber.law.harvard.edu/rss/creativeCommonsRssModule.html">
    <channel>
        <title><![CDATA[Insight - Medium]]></title>
        <description><![CDATA[Insight - Your bridge to a thriving career - Medium]]></description>
        <link>https://blog.insightdatascience.com?source=rss----d02e65779d7b---4</link>
        <image>
            <url>https://cdn-images-1.medium.com/proxy/1*TGH72Nnw24QL3iV9IOm4VA.png</url>
            <title>Insight - Medium</title>
            <link>https://blog.insightdatascience.com?source=rss----d02e65779d7b---4</link>
        </image>
        <generator>Medium</generator>
        <lastBuildDate>Sat, 05 Nov 2022 16:30:44 GMT</lastBuildDate>
        <atom:link href="https://blog.insightdatascience.com/feed" rel="self" type="application/rss+xml"/>
        <webMaster><![CDATA[yourfriends@medium.com]]></webMaster>
        <atom:link href="http://medium.superfeedr.com" rel="hub"/>
        <item>
            <title><![CDATA[Blockchain for Business and Product]]></title>
            <link>https://blog.insightdatascience.com/blockchain-for-business-and-product-83fa0faf4c25?source=rss----d02e65779d7b---4</link>
            <guid isPermaLink="false">https://medium.com/p/83fa0faf4c25</guid>
            <category><![CDATA[blockchain]]></category>
            <category><![CDATA[decentralized-consensus]]></category>
            <category><![CDATA[cryptocurrency]]></category>
            <dc:creator><![CDATA[Jeremy Karnowski]]></dc:creator>
            <pubDate>Thu, 19 Nov 2020 18:39:03 GMT</pubDate>
            <atom:updated>2020-11-19T18:39:03.447Z</atom:updated>
            <content:encoded><![CDATA[<h4>Part 2: Mining Cryptocurrency</h4><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*Yv1MAKZDXtMuJUczdxQNMg.png" /></figure><p>(<a href="https://blog.insightdatascience.com/blockchain-for-business-and-product-40128eed45b9">Part 1: Mental Models for Blockchain</a>)</p><p>There is currently a lot of hype around cryptocurrencies, blockchain technology, and <a href="https://blog.insightdatascience.com/whats-the-big-deal-about-decentralized-consensus-12876bb80064">decentralized consensus</a> systems. There is also a great deal of confusion around why the hype exists, what the unique value of these systems is, and how one might jump into this ecosystem to try their hand at building something. This, in general, makes it difficult for industry professionals to separate signal from noise.</p><p>This blog series is aimed at describing some of the core businesses and products that have arisen in the tech industry given the recent advances in decentralized consensus mechanisms, so that individuals focused on building new products and businesses can see the landscape quickly, get their hands dirty, and build something new.</p><p>This second article will walk through the system design for one business in this space - cryptocurrency mining. We will discuss what it is, how it fits into the ecosystem, and how the business works.</p><h4>Mining for cryptocurrency is renting your compute power to a bank and getting paid for this service. Understand the profit and loss of this business and how to iterate to improve return on investment.</h4><p>Align your interactions with blockchain and crypto to your values. Mining a cryptocurrency is supporting that economic system and its banking operations, by using your computer systems to be the labor for the banking administrative tasks. Mining many coins is supporting many economic systems and potentially their interactions and dynamics.</p><p>This is similar to using your car to support the transportation system and business operations of companies like Lyft or Uber. For instance, with Lyft you use your car as the hardware, spend money for gas, pay for mechanic fees from upkeep, and invest your time to drive instead of other activities. The profit at the end of the day is how much money you made during the day minus all these costs of using your vehicle for this ride-sharing service. Is it viable?</p><blockquote>Mining cryptocurrency is like installing a solar panel and selling to the grid. The main objective is to turn electricity into money.</blockquote><p>Mining cryptocurrency is also similar to installing a large solar panel array on your house and earning money by selling electricity back to the grid. In this example, you have to buy the array and batteries, pay for installation, and keep the system working. The output at the end of the day is how much money you made from the electricity sale minus the upkeep. Is it viable?</p><p>In the same way, when you are mining for crypto, you are using your computer in a “banking-operation-system”-sharing economy. Is it viable to lend your computer in this way?</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/848/1*v7MN8okGTn5zAqxC7n3gLA.png" /><figcaption>The high-level overview of a mining business. The main objective is to turn electricity into money.</figcaption></figure><p>For the following example, I’ll focus on Monero, a specific cryptocurrency that has a mission and economic system that many people value. Monero is a cryptocurrency that has private accounts, robust security against bad actors, a mining system that is more accessible for people wanting to contribute, and many other advantageous features. For more information on Monero, check out <a href="https://www.goodreads.com/book/show/43307435-mastering-monero">this book</a>.</p><p><strong>The cost to running this Monero mining business includes:</strong></p><ul><li>The original cost of your mining hardware</li><li>Electricity costs, based on your local electricity rates, which are typically measured in kWh/mo</li><li>Mining pool fees. Even though mining by yourself is possible and accessible to more people in Monero, mining as part of a collective creates more stable revenue. Being a part of this collective, however, incurs a small fee to the pool operator.</li><li>(If desired) Conversion fees between your mined currency (here, Monero) and a larger cryptocurrency (e.g. Bitcoin)</li><li>(If desired) Conversion fees between a larger cryptocurrency and USD</li></ul><p><strong>Additional pieces you need to support this business:</strong></p><ul><li>Wallets/accounts for different currencies and for currency exchanges</li><li>The software for mining</li><li>Knowledge about how to transfer funds to different accounts</li></ul><p><strong>Note:</strong> People can hold their assets in many ways. USD, Yen, Euros, real estate, jewelry, art, equity in a company, life insurance contracts, Bitcoin, Monero, etc. For most readers, I&#39;m assuming they keep most of their assets in USD, so I&#39;m also including parts of the business that turn Monero into USD.</p><h4>Conclusion</h4><p>Using your computer as an asset in a blockchain-oriented system is just like leveraging your car and time as a driver for Lyft, or a solar panel system for selling electricity to the grid. How is your computer being used? How is it providing value to you? How much does it cost to let your system be used for this? Is it worth it to you?</p><p>Setting up a business mining a cryptocurrency (in this example, Monero) requires you to think through how you would create, own, and operate a business. What are the system components? How much do they cost? What are the operations and how does the system run? If the business is not profitable, are there ways you can optimize parts of your business to make it run better and head toward profitability?</p><p>I encourage everyone to think through all of these avenues to understand how business in this new era will operate, which ones you should be a part of, and how you can continually make them and yourselves better in the process.</p><p><strong><em>Are you interested in transitioning to a career building new decentralized tools and applications?</em></strong> <a href="https://notify.insightdatascience.com/notify">Sign up to learn more</a> about the <a href="http://insightfellows.com">Insight Fellows programs</a>.</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=83fa0faf4c25" width="1" height="1" alt=""><hr><p><a href="https://blog.insightdatascience.com/blockchain-for-business-and-product-83fa0faf4c25">Blockchain for Business and Product</a> was originally published in <a href="https://blog.insightdatascience.com">Insight</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Predicting long-term user engagement from short-term behavior]]></title>
            <link>https://blog.insightdatascience.com/predicting-long-term-user-engagement-from-short-term-behavior-2d10d64b2c9f?source=rss----d02e65779d7b---4</link>
            <guid isPermaLink="false">https://medium.com/p/2d10d64b2c9f</guid>
            <category><![CDATA[random-forest]]></category>
            <category><![CDATA[user-engagement]]></category>
            <category><![CDATA[data-science]]></category>
            <category><![CDATA[insight-data-science]]></category>
            <dc:creator><![CDATA[Dan Quach]]></dc:creator>
            <pubDate>Tue, 17 Nov 2020 18:00:24 GMT</pubDate>
            <atom:updated>2020-11-17T18:02:32.701Z</atom:updated>
            <content:encoded><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*s9ysmzF8LXh_iYBl" /><figcaption>Photo by <a href="https://unsplash.com/@dbwldo?utm_source=medium&amp;utm_medium=referral">abigail low</a> on <a href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral">Unsplash</a></figcaption></figure><p>User engagement is one of many crucial elements to study and understand deeply for both well-established companies and nascent startups throughout the development of a product. A product’s health can be broadly measured from the delicate balance between new user adoption, engagement, retention, and churn, all of which are closely related. With the fierce competition of the mobile app market today, many developers are vying for the attention of large populations of smartphone users around the world. It is not uncommon for the average person to use an app only a handful of times before quitting once the initial novelty wears off, leaving companies with the very tough problem of finding new ways to increase the level of engagement with their product.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/636/0*QnVzcj0zBINLRl-h" /><figcaption>User engagement with the startup’s platform, the subject of this article</figcaption></figure><p>As an <a href="http://insightfellows.com">Insight Fellow</a>, I partnered with a company that provides a mobile app payment service allowing its users to make simple cash transfers to one another. In addition to its peer-to-peer social transaction features akin to Venmo or Cash App, one of its unique core functionalities is the ability for users to create ‘Pools’ in which many users across the platform may contribute to a central cash pot. These collections can be used for any general purpose: casual outings, event planning, roommate rent payments, betting pools, charities, etc. The platform is seeing a monthly growth in registered users of 2–3% with over 390K current registered users. About 38% (150k) of those users have been active in the last year and 8% (31k) within the last month.</p><h3>The Problem</h3><p>A problem that the company wanted to address was how to derive insights from data on already engaged users to identify any common behavior patterns that can be leveraged to promote the same level of engagement in new users.</p><p>In discussing the problem, they had identified two segments of their long-term engaged user population base that they wanted to understand:</p><ul><li><strong>“Day One” Users </strong>— consistent, regular users from day one</li><li><strong>“Late Bloomer” Users</strong> — sporadic early users, with an increase in engagement at a later date</li></ul><p>The behaviors of these two segments can be seen in the following figures.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*8Go320LXD0yqdgxh" /><figcaption>Usage pattern of example ‘day one’ user — shows consistent, regular usage from day one</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*JlAX3OqT0GTCPr7l" /><figcaption>Usage pattern of a ‘late bloomer’ user — sporadic usage until sudden increase in engagement at a later date</figcaption></figure><p>In these two user segments, “day one” users readily adopt the service with regular and consistent usage upon registration upon the platform. The second class, “late bloomers”, shows sparse, intermittent usage for many months until a pivotal moment where they show a significant increase in engagement in the time that follows.</p><p>This curiosity led to the question of whether a <em>trigger</em> for long-term user engagement can be deduced from actions taken near the moment of increased engagement. If so, this would be more easily deduced from the day one users since the temporal edge of the engagement period for late bloomers is murky and less well-defined. We will therefore focus on studying the early actions of the day one users that potentially led to their continued usage. Such actions may then be actively encouraged to new and existing intermittent users to promote more long-term user engagement with the product.</p><h4>Identifying Day One Users</h4><p>The company provided access to their full PostgreSQL database, which consists largely of timestamped user activity throughout the platform across their years of operation including transactions between users/pools, banking deposit/withdrawals, friendships, comments, pool creation, and pool connections. The time-dependence of these data points is a critical and challenging component in engineering useful features for this analysis.</p><p>Since the users were not labeled, one non-trivial task was isolating the day one users by formulating a set of conditions under which their behavior is appropriately captured.</p><p><strong>We classify a user as a day one user if they have had:</strong></p><ol><li>At least one transaction within the first month of account activation, and</li><li>At least five active months in the first year of usage.</li></ol><p>This choice of definition emerges from the balance of a sufficient long-term average of active engagement in the form of transactions, while avoiding the potential contamination of late bloomer users into the class. We do not impose any condition of consecutive months of usage to provide flexibility and accommodate minimal sporadic early usage behaviors. Of the total population of users with at least one transaction (205,590 users), a total of 13,084 users satisfy this day one criteria, revealing a fairly significant imbalance.</p><p>With the class label defined, we can use a supervised learning algorithm to try and discover underlying patterns within this class. A classification algorithm that can adequately discriminate these particular users from the general population will provide meaningful insight into the problem. In particular, we are interested in identifying key actions that may be occurring in the early stages of their engagement to assess if there are any usage patterns common among this cohort.</p><p>To this end, and to prevent data leakage in the modeling, we restrict our features of the user to the brief time window of one month after first signing up on the platform and use this information to predict the long-term twelve month engagement of the user. It should be noted here that this is an ambitious goal to predict the 12 month aggregated out-of-sample behavior from only the brief actions within the first month.</p><p>As raw data, we have available various actions a user can make within the app including transactional payments or receipts to other users and pools or various social interactions. These time-stamped events can be engineered into interesting basic features of time-aggregated or activity frequency measurements to characterize the user behavior.</p><p>The class definition for the desired cohort uses conditions that appear closely related to the types of features that are engineered, which may lead to concerns of bias. However it is important to emphasize that these features correspond only to the first month behavior of the user, i.e. 4 weeks, whereas the class definition corresponds to the aggregate behavior over 52 weeks.</p><h4><strong>Modeling</strong></h4><p>We have a standard binary classification problem between a ‘day one’ user and a ‘non-day one’ user. A number of algorithms are considered such as logistic regression, support vector machines, random forests, and light GBM. A balanced random forest (RF) classifier with class re-weighting was ultimately chosen using an 80/20 train/test split, which provided the best results. RF provides a relatively simple, but robust, classifier that can handle non-normally distributed data as well as some of the non-linearities that were observed as well.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/309/0*YM6hYoSsn3OwKy9-" /><figcaption>Normalized confusion matrix for RF model</figcaption></figure><p>The corresponding normalized confusion matrix for this classification is shown, which conveys the algorithm’s ability to correctly classify the users according to their classes along the diagonal elements of the matrix with the number of misclassifications along the off-diagonal. The corresponding F1 score for this classifier is 0.343.</p><p>The precision-recall (PR) curve shown below is a useful metric for evaluating a binary classifier as the discrimination threshold between classes for the model is varied. The PR curve is particularly useful for evaluating the performance of a classifier with imbalanced classes, compared to the more traditional receiver operating characteristic (ROC) curve, due to its primary focus on the positive minority class. The area under the curve (AUC) for this model is 0.312 compared to the baseline random classifier AUC of 0.064, which indicates that there is indeed a weak signal that can be detected by the model.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/620/0*R3aYzDm0em8LjORY" /><figcaption>Precision-recall curve for the RF model</figcaption></figure><p>The different metric evaluations of the algorithm indicate that there is a weak but slightly discernible pattern in the actions taken within the first month of account sign up that can predict a twelve month aggregate engagement for that user. We can look at the feature importances for this classification as follows to see which aspects of the user provide the model with the most information when making its decision classifications.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/862/0*2qyE_Q--Tt9PJdZK" /><figcaption>Feature importances from RF classifier</figcaption></figure><p>From these importances, we see that five of the top seven pertain to the user’s frequency and quantity of pool payments made or pools joined. The other two are related to the transactional network connections that are established within the first month-long period, which include the average number of users in the pools joined by the user and the number of unique individuals a user is connected to through these pools. These are all intuitive signs for increasing user engagement on the platform, although it may be difficult to extract actionable insight directly from this. However, we can step back and note that the pool payments show more importance than, say, the direct peer-to-peer transactions, additionally, the rate at which it occurs (i.e. the average time elapsed between transactions) is of high importance as well. Perhaps we can use these pieces of information to create an ‘Aha!’ moment for the company.</p><p>The company was in search for a direction in which to guide their ship, a simple ‘North Star’ metric, similar to Facebook’s simple ‘7 friends in 10 days’. It should be noted that this metric is not a mathematically precise value and not meant to be a rigid, uncompromising rule, but rather a beacon for which the company can direct its efforts toward a common goal to achieve among its users and promote actions that may lead to long-term engagement on the platform. We can derive such a metric by comparing the size of the user body that satisfy the engaged criteria as well as the size of the user body that performed a specific action and evaluate their overlap, as illustrated in the following Venn diagram. Motivated by the feature importances, we use the number of pool payments within the first month as the action criteria to satisfy.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*pc0mhmkvR3hX4n0C" /></figure><p>The result of scanning over <em>N</em>, the number of payments, can be seen in the following bar chart, which plots the overlap percentage (the number of users who satisfy both criteria divided by the union of the two sets) as a function of the minimum number of pool payments made in the first month.</p><figure><img alt="" src="https://cdn-images-1.medium.com/proxy/0*4XsaWyGOulFk-s-P" /><figcaption>Percent overlap of [engaged users] and [users who have made at least N payments in the first month] as a function of the [number of (minimum) pool payments made in the first month]</figcaption></figure><p>We choose the action criteria with the highest overlap percentage, in this case at least two pool payments within the first month. With only 15% overlap, this is not a powerful indicator for converting a user from unengaged to engaged, but it provides a simple and clear direction to focus efforts. This provides an actionable insight in which the company can now strive toward gearing new users toward making at least two pool payments within the first month of signing up onto the platform. With, on average, 10k new registered users monthly, this could increase their long-term user base by around 1,500 users each month, who will use it with some consistency within their first year.</p><p>There are a number of potential reasons for why this may be correlated with long-term retention, for example having multiple uses within a short time frame allows the user to repeatedly experience the user interface and familiarize themselves with the features and acclimate to the platform to more readily incorporate the service into their lifestyle. Additionally, having multiple uses could also be related to having multiple social circles on the platform, which would lend itself toward long-term engagement when there are more parties available with whom to transact. Regardless of the causal explanation for these user actions and long-term engagement, which may be studied more deeply with further experiments and analyses and data collection, the company can work toward incentivizing new users to meet this threshold and perhaps in the long run, hopefully, be able to improve the long-term retention on their platform.</p><p><strong>Assumptions and Limitations</strong></p><p>It is encouraging to see that even when restricting information to the limited time frame immediately following the user sign up date, the potential for long-term engagement can be determined. However, this is not without its caveats, and it is important to be mindful of the assumptions and limitations of the study presented.</p><p>This study does not provide as much insight beyond the twelve month period and does not require users to be presently engaged. The restriction came from an attempt to avoid including late bloomers into the day one sample. However, it would be interesting to perform an analysis that can also incorporate the late bloomers if they can be neatly encapsulated within similarly defined conditions as the day one users. Perhaps a study can be performed with a ‘rolling window’ of time in one month intervals to determine the subsequent year’s behavior as an extension of the analysis described here. Nonetheless, additional studies will be required to prevent churn and improve retention after the scope of a year.</p><p>“Day one” and “late bloomers” may be a useful heuristic description of two types of observed long-term engaged users, but internal variations in the usage patterns between these cohorts and the wide spectrum of possible user behavior led to the difficult challenge of determining the ‘perfect’ definition for such users in order to perform a supervised learning study. Future studies could potentially use unsupervised clustering techniques to more naturally and precisely identify groups of users that better reflect their innate behavior.</p><p>It was assumed that “all social networks are created equal.” A more intricate social network analysis is needed, e.g. the length of time a user’s friends/connections themselves have been on the platform upon the user joining the platform. Essentially, it would also be interesting to quantify the level of engagement of a particular user’s peers to assess the strength of this effect.</p><p>Correlations with app version history were not well-established. While the core functionality of direct peer-to-peer payments and pool payments have existed throughout the lifetime of the product, changes in user interface/experience may also hold insights in usage/discovery of features in the app. A dedicated A/B test study and further analysis of the long-term user behavior as a result may help with disentangling these effects.</p><p><strong>Reflections</strong></p><p>This article presents a strategy to determine the long-term aggregate behavior of an app user based on limited short-term information of their actions taken in their first weeks of use. This posed an interesting but challenging task, particularly in the area of feature engineering and class definition of an engaged user on the platform. However, a binary classifier model was built and trained to identify a select cohort of users who were engaged early on, which provided a set of early action features that correlated with the classification of these engaged users. We used this information to define a ‘magic’ moment for the client company as a guide for further development of their platform as they continue to increase their user base that will hopefully be more engaged in the long term.</p><p><strong><em>Are you ready to make a change &amp; transition to a career in tech? </em></strong><a href="https://notify.insightdatascience.com/notify?utm_source=moneypool&amp;utm_medium=blog"><em>Sign up</em></a><em> to learn more about </em><a href="https://insightfellows.com/?utm_source=moneypool&amp;utm_medium=blog"><em>Insight Fellows programs</em></a><em>.</em></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=2d10d64b2c9f" width="1" height="1" alt=""><hr><p><a href="https://blog.insightdatascience.com/predicting-long-term-user-engagement-from-short-term-behavior-2d10d64b2c9f">Predicting long-term user engagement from short-term behavior</a> was originally published in <a href="https://blog.insightdatascience.com">Insight</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Learning to Think Like a Data Scientist — Part 2]]></title>
            <link>https://blog.insightdatascience.com/learning-to-think-like-a-data-scientist-part-2-67201608083e?source=rss----d02e65779d7b---4</link>
            <guid isPermaLink="false">https://medium.com/p/67201608083e</guid>
            <category><![CDATA[insight-data-science]]></category>
            <category><![CDATA[data-science]]></category>
            <category><![CDATA[product-development]]></category>
            <category><![CDATA[machine-learning]]></category>
            <dc:creator><![CDATA[Esther Richler]]></dc:creator>
            <pubDate>Tue, 10 Nov 2020 18:30:36 GMT</pubDate>
            <atom:updated>2020-11-10T18:30:36.779Z</atom:updated>
            <content:encoded><![CDATA[<h3>Learning to Think Like a Data Scientist — Part 2</h3><figure><a href="https://www.shutterstock.com/home"><img alt="A field of poppies with a few close up poppies in the foreground and a sliver of blue sky in the background." src="https://cdn-images-1.medium.com/max/1024/1*mKEimX3jRnUhEep_YhoRjA.jpeg" /></a></figure><p><em>Originally published in </em><a href="https://themlrebellion.com/blog/Learning-To-Think-Like-Data-Scientist-2/"><em>The ML Rebellion</em></a><em>.</em></p><p>In <a href="https://blog.insightdatascience.com/learning-to-think-like-a-data-scientist-7323ddb17c69?source=friends_link&amp;sk=a152235f44a26cfa408b85f2acc4fb8c">Part 1</a>, I described the planning phase of a data project. The purpose of the planning phase is to identify a business need and develop a roadmap for how to meet it. In this post, I will cover the project execution phase, i.e. putting the plan into action. The goal of this phase is to create a minimum viable product capable of meeting the business need.</p><h3>Project Execution Phase</h3><p>The steps in this phase are not as clear cut as those in the planning phase, because they are more closely related to the individual project needs. To keep things generalizable across projects, I have broken down the workflow into three broad and loosely defined steps:</p><ol><li>Data Preparation</li><li>Machine Learning</li><li>Communication</li></ol><p>Each of these steps has several possible tasks, some of which I will outline throughout this post. These tasks are project-specific, so they can be moved around, eliminated, or added to as needed.</p><p>This is not a deeply technical post, so the ML descriptions are high-level. I’ve included links to deeper write-ups for those wishing to learn more. I also link to code when appropriate. As in <a href="https://blog.insightdatascience.com/learning-to-think-like-a-data-scientist-7323ddb17c69?source=friends_link&amp;sk=a152235f44a26cfa408b85f2acc4fb8c">Part 1</a>, I highlight how the decision making process is shaped by the business needs. But unlike in Part 1, here I focus more on how to think like a scientist, and how to be critical and ask the right questions.</p><h4><strong>1. Data Preparation Step</strong></h4><p>This is a labor intensive step and requires a lot of mental flexibility. In this step, you access and explore the data and then come up with an analysis strategy. This is also the time to diagnose any data issues and figure out how to solve them. Because this is your first chance to really get into the details of the data, in this step you might discover that you need to pivot your project. This is my favorite step because I enjoy creative problem solving.</p><p><strong>1.1 Access and explore the data</strong></p><p>I had pinpointed satellite data as the most appropriate source of poppy information for this project. Fortunately, <a href="https://gisgeography.com/free-satellite-imagery-data-list/">there are many satellites to choose from</a>, so I had the flexibility to select the best one for the job. The main aspects I took into consideration were the spatial resolution of the images, how often the satellite collects data, and data accessibility. I chose the <a href="https://sentinel.esa.int/web/sentinel/missions/sentinel-2">Sentinel-2</a> satellite because it was the best fit overall for my needs.</p><p>The pixel resolution of images acquired by Sentinel-2 ranges from 10 to 60 meters, which for satellite images is considered medium resolution. This is high enough to detect patches of poppies in a field, but low enough to keep file sizes manageable. Sentinel-2 collects data from each location once or twice per 10 day period. While I would have preferred something a little more frequent, poppy season lasts for several weeks, so this frequency is sufficient for monitoring bloom sizes over that period. Sentinel-2 data is free and accessible in a variety of formats, and I used the <a href="https://www.sentinel-hub.com/">Sentinel hub</a> API to <a href="https://github.com/EstherRichler/kaBLOOM/blob/master/notebooks/analysis_pipeline/get_data.ipynb">download the data</a> directly to my hard drive.</p><p>I started out by<a href="https://github.com/EstherRichler/kaBLOOM/blob/master/notebooks/eda/eda_antelope.ipynb"> looking at data</a> acquired during a poppy bloom at the <a href="https://www.parks.ca.gov/?page_id=627">Antelope Valley Poppy Reserve</a>. This served as my ‘positive control’ to make sure I could see blooms when they were present. Sentinel-2 collects data from <a href="https://sentinel.esa.int/web/sentinel/technical-guides/sentinel-2-msi/msi-instrument">13 different bands of light</a>, and I used the three visible bands (red, green, and blue) to reconstruct natural color images. The orange blooms were clearly visible against the background patchwork of fields, roads, and buildings.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*jXCDNKnvQnTNMJFjKpeMAA.jpeg" /><figcaption>Satellite images of the Antelope Valley Poppy Reserve before, during, and after the 2019 poppy season</figcaption></figure><p>The remaining light bands collected by Sentinel-2 are outside of the visible range, but they contain information related to things like moisture, clouds, vegetation, geological makeup, and urban development. This information can be extracted by <a href="https://gisgeography.com/sentinel-2-bands-combinations/">combining the bands in various ways</a>.</p><p><strong>1.2 Develop an analysis strategy</strong></p><p>With access to the key data, it was time to come up with a strategy for translating that data into business value. I had to first think about what kind of metric I was going to present to the user, and then think about a path I could take to extract that metric from the data. I would also have to diagnose any data issues that might get in the way, and figure out how to fix or get around them.</p><p>I had already decided (during the project planning phase) that the output of my minimum viable product would be bloom level (low, medium, or high). To be able to measure the extent of a bloom, I first needed a way to identify which pixels in the image contained poppies and which did not. One way to do this is to use color thresholding to select all the orange pixels. However, this proved problematic because other objects in the image (dead vegetation, buildings, soil, etc.) could have a similar orange color. Also, the intensity and shading of the orange color varied for poppies at different locations and times. I could, however, move beyond the limits of the human eye by taking advantage of information from the invisible satellite bands. More specifically, I could use the data from all 13 satellite bands as features in a model to predict the presence or absence of poppies in each pixel. In short, using supervised machine learning to classify each pixel would let me get a count of how many poppy pixels were in an image.</p><p>To do this, I would need a source of labelled data to train a classifier on. The US Department of Agriculture has a tool called <a href="https://nassgeodata.gmu.edu/CropScape/">CropScape</a>, which provides labelled satellite data for various types of crops and agricultural products. But flowers are not included in the CropScape data, and I could not find a comparable dataset for non-agricultural plants. This was a major technical hurdle. If I had no labelled data, how would I classify the poppy pixels and calculate the size of a bloom?</p><p><strong>1.3 Pivot if necessary</strong></p><p>Solving this problem was crucial to being able to meet the guiding need, and this became the new focus of the project. But now the project was too large to complete in the time I had. I would have to find a way to reduce it while still maintaining its value. My previously defined minimum viable product offered two functionalities: current bloom status and predicted bloom status. But the real value of the product came from its ability to provide these bloom reports for non-park locations. This made me realize that simply providing the current bloom status for a non-park location was sufficient to meet the need at its most minimal level. The prediction functionality could always be added at a later time. It was not needed for the minimum viable product. My updated minimum viable product would provide current bloom status for three California locations for the 2020 bloom season. This was a proof-of-concept product, so I would also include the ability to go back in time to see what the results would have looked like during the 2017, 2018, and 2019 poppy seasons.</p><p>This change was easy because I had prepared for it during the planning phase. I had made sure that the guiding need was not too narrow yet still clearly defined. I had also come up with enough specific product details to allow for future flexibility. Actually, the change I was making here was more of a detour than a pivot, but these types of preparations are also helpful when a larger change or pivot is needed, or when the pivot occurs at a different time point in the product life cycle. In short, anticipating pivots by preparing for them minimizes the need for additional work later on.</p><p><strong>1.4 Update the strategy</strong></p><p>The problem at hand was figuring out how to classify data that was unlabeled. <a href="https://en.wikipedia.org/wiki/Unsupervised_learning">Unsupervised learning</a> is commonly used to find patterns or clusters in unlabeled data. But I already had some prior knowledge of what I was looking for, and it seemed inefficient to disregard that information. I knew that each pixel fell into one of two classes: poppy or non-poppy. I further knew that all of the poppy pixels were orange, but that sometimes non-poppy pixels were also orange. Perhaps I could harness some of that information to manually label a small fraction of the data, and then use <a href="https://en.wikipedia.org/wiki/Semi-supervised_learning">semi-supervised learning</a> to predict the classes for the rest of the data. However, this would heavily bias the model towards using color as a predictor, which is what I was trying to avoid in the first place. I decided to get around this problem by taking an <a href="https://en.wikipedia.org/wiki/Active_learning_(machine_learning)">active learning</a> approach.</p><p>Active learning is a form of semi-supervised learning where prediction mistakes are corrected in an iterative process by an outside decision maker (in this case me). It is used in situations where there is a large amount of unlabelled data and it is too expensive to manually label each data point. On each iteration, a small number of highly informative data points are carefully selected and hand labeled, and the model is updated and retrained. Because all of the labeled data points are so informative, relatively little training data is needed, and model performance improves quickly. At the end of the process, the model is good enough to generate high quality class predictions for the entire dataset. This was exactly what I needed.</p><h4><strong>2. Machine Learning Step</strong></h4><p>In this step you finally get to put all your plans into action and flex your machine learning muscles. As in the data preparation step, the tasks in this step are flexible and can change depending on results. The first task is to test out your analysis strategy on a small subset of the data. If that goes well, it is time to process the rest of your data. If it goes poorly, or produces unexpected results, you will need to troubleshoot or pivot. Pivoting at this late stage is not the end of the world if you are sufficiently prepared. Another task that may be needed in this step is adding more data to your dataset.</p><p><strong>2.1 Execute the analysis strategy on a small-scale</strong></p><p>Ideally, I wanted to build a model that could recognize poppy pixels in images from lots of different settings and locations, but for my minimum viable product I limited the training data to three locations. I used two images from each location, one taken during poppy season and one taken outside of poppy season. Including off-season images was one way to ensure that the model had sufficient non-poppy pixels to learn from. I also limited the training data to images acquired during the 2019 poppy season. To ensure that the model could generalize to unseen data, I would use the 2019 data for testing and training, and use images of blooms from other years for validation.</p><p><a href="https://github.com/EstherRichler/kaBLOOM/blob/master/notebooks/analysis_pipeline/label_initial.ipynb">I started by hand labeling</a> a small percentage of pixels as either poppy or not-poppy. For the poppy pixels, I labeled a few of the easily identifiable (i.e. orange to my eye) pixels from the on-season images. For the non-poppy pixels, I labeled an equal number of randomly chosen pixels from the off-season images. These labeled pixels would serve as the seed data in the initial model.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*ai1T0zgFVU9iUioUyFPVKA.jpeg" /><figcaption>Pixels hand labeled as poppy or non-poppy</figcaption></figure><p>To choose a model, <a href="https://github.com/EstherRichler/kaBLOOM/blob/master/notebooks/eda/model_exploration.ipynb">I tested 4 different classifiers</a> (logistic regression, naive bayes, random forest, and support vector machine) and calculated their precision and recall. I went with the random forest model because it had the best out-of-the-box performance metrics. This was admittedly an unsatisfying way of making this choice, but it was sufficient for the minimum viable product. If I ever decided to take this product further, I would want to put more thought into choosing and tuning a model. But now was not the time for optimization, and I had to hold myself back from spending too much time on it.</p><p>I initialized the <a href="https://github.com/EstherRichler/kaBLOOM/blob/master/notebooks/kabloom_code_demo.ipynb">active learning process</a> by training and testing a random forest model on the hand labeled seed dataset. I then used that model to predict the rest of the pixels in the images. Next I looked for areas where the model was unsure of its predictions, i.e., the prediction probabilities were around 0.5, and I hand labelled a subset of those pixels and added them to the pool of hand labeled pixels. Finally, I used the updated pool of labeled pixels to build a new model in the next iteration of the process.</p><p>As a quick sanity check of model performance on each iteration, I visualized the locations of the predicted poppy pixels and compared those visualizations side-by-side with the natural color images. The off-season images were really useful at this point — large amounts of predicted poppy pixels in these images would have alerted me to a problem with the model. Fortunately the labelling process went well and that did not happen. After just three iterations, I had a model that could confidently and correctly predict the labels of pixels it hadn’t seen before.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*1uQca3JehYB_w0V_Ivs32A.jpeg" /><figcaption>Certainty of pixel predictions (p_poppies = predicted probability that class is poppy)</figcaption></figure><p>Visualizing the predictions at each step also helped me choose which pixels to hand label. In some cases, when the model was unsure of its predictions, it was very clear to me what the correct label should be. For example, pixels that encompassed roads were very obviously not poppy pixels, so I selected them and hand labeled them as non-poppy (see arrows in above figure). But sometimes I was also unsure of the correct label. An example of this is the large yellowish patch in the upper right quadrant of the true color image above. The model seemed to think that some of the pixels in that area had poppies, but it was not sure about all of them. In this case, I did not correct the model or update the labels because it was not clear to me if there were poppies in that area. This could very well have been a case where the model performed better than my eyes because it had access to more information. If this was a higher stakes project, and it was important to get all the labels right, I would probably want to consult with experts in satellite imagery or botany to help me identify those pixels.</p><p><strong>2.2 Augment the dataset and process the new data</strong></p><p>My next steps were to build up a full dataset for use in the app, and then classify the pixels in each additional image. I used the Sentinel hub API to download satellite images from March and April of 2017–2020 for three California locations (Lake Elsinore in Riverside County, and Antelope Valley and Grass Mountain in Los Angeles County). I made sure to exclude images that had too much cloud cover in them. I then used the model that I had generated in the previous step to <a href="https://github.com/EstherRichler/kaBLOOM/blob/master/notebooks/analysis_pipeline/predict_blooms.ipynb">classify all of the pixels</a> in the newly downloaded images.</p><p>I now had all of the information I needed for my minimum viable product. All that remained was to wrap it up in an interactive and user-friendly framework.</p><h4><strong>3. Communication Step</strong></h4><p>In this step, you set up the process to turn your results into a bottom line actionable insight for the user. Tasks in this step include creating a user friendly metric, and building and deploying the app or platform.</p><p><strong>3.1 Translate results into a metric</strong></p><p>Now that I could generate class predictions for all pixels in an image, I had to translate this information into a metric that could easily communicate bloom size to the user. To do this, I first converted the images into binary arrays where the value of each pixel reflected its label. I then used image segmentation techniques to <a href="https://github.com/EstherRichler/kaBLOOM/blob/master/notebooks/analysis_pipeline/get_areas.ipynb">get individual bloom patches</a>, and extracted the area of each bloom patch in square pixels. Finally, rather than using the 3 level scale I had originally planned, I converted the patch sizes from square pixels into something more relatable: football field units.</p><p><strong>3.2 Create and deploy the product</strong></p><p>The final task was to convert the data and results into a product form that the user could interact with. For a small project like this one, this is relatively straightforward. I used <a href="https://www.streamlit.io/">Streamlit</a> to <a href="https://github.com/EstherRichler/kaBLOOM/blob/master/scripts/kabloom.py">create a user facing app</a>, <a href="https://discuss.streamlit.io/t/streamlit-deployment-guide-wiki/5099">deployed the app</a> to the web with <a href="https://aws.amazon.com/">AWS</a>, and uploaded the code to a <a href="https://github.com/EstherRichler/kaBLOOM">GitHub repository</a>. As a finishing touch, I gave the app a punchy and memorable name — ‘kaBLOOM’.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/803/1*TDGVuQRTJ6bHnxfiEfM7xg.png" /><figcaption>Product logo</figcaption></figure><p>My app was now functional and I finally had a minimum viable product!</p><p>Working through the steps of this project gave me valuable insights into what it takes to be a good data scientist. It is not enough to simply understand machine learning techniques, nor even to know how to apply them. Real data science is an art. It is an art in balancing rigor and thoroughness with business needs and bottom-line results. It is an art in recognizing when to be critical and when to be tolerant. And it is an art in setting and meeting goals that align with the larger context of the work. I hope these blog posts have helped shed light on some of these less easily defined aspects of learning to think like a data scientist.</p><p>Hiring managers — I’m on the job market and actively interviewing for Data Scientist positions. Reach out by <a href="mailto:estherrichler@gmail.com">email</a> or on <a href="https://www.linkedin.com/in/esther-richler/">LinkedIn</a> if you think I might be a good fit for a role you are looking to fill.</p><p><strong><em>Are you ready to make a change &amp; transition to a career in tech? </em></strong><a href="https://notify.insightdatascience.com/notify?utm_source=kabloompart2&amp;utm_medium=blog"><em>Sign up</em></a><em> to learn more about </em><a href="https://insightfellows.com/?utm_source=kabloompart2&amp;utm_medium=blog"><em>Insight Fellows programs</em></a><em> and start your application today.</em></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=67201608083e" width="1" height="1" alt=""><hr><p><a href="https://blog.insightdatascience.com/learning-to-think-like-a-data-scientist-part-2-67201608083e">Learning to Think Like a Data Scientist — Part 2</a> was originally published in <a href="https://blog.insightdatascience.com">Insight</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Learning to Think Like a Data Scientist]]></title>
            <link>https://blog.insightdatascience.com/learning-to-think-like-a-data-scientist-7323ddb17c69?source=rss----d02e65779d7b---4</link>
            <guid isPermaLink="false">https://medium.com/p/7323ddb17c69</guid>
            <category><![CDATA[machine-learning]]></category>
            <category><![CDATA[insight-data-science]]></category>
            <category><![CDATA[data-science]]></category>
            <category><![CDATA[product-development]]></category>
            <dc:creator><![CDATA[Esther Richler]]></dc:creator>
            <pubDate>Tue, 10 Nov 2020 18:27:40 GMT</pubDate>
            <atom:updated>2020-11-10T18:32:24.547Z</atom:updated>
            <content:encoded><![CDATA[<figure><a href="https://www.shutterstock.com/home"><img alt="Two rolling hills covered in poppy blooms with the sky and wisps of cloud visible in the background." src="https://cdn-images-1.medium.com/max/1024/1*_tx3ZMZ3aEm1YuSiTDEsMA.jpeg" /></a></figure><p><em>Originally published in </em><a href="https://themlrebellion.com/blog/Learning-To-Think-Like-Data-Scientist/"><em>The ML Rebellion</em></a><em>.</em></p><p>Earlier this year I made the transition from academic neuroscientist to applied data scientist. As part of this process, I had to shift out of my familiar research oriented mindset and into a more business-relevant, product-driven kind of thinking. To ease and guide this adjustment, I participated in the <a href="https://insightfellows.com/data-science">Insight Data Science fellowship</a> where I used a business-minded approach to develop a data product. In this blog, I will share what I learned from the experience by walking through the steps I took to complete this project. Part 1 covers the project planning phase, and <a href="https://blog.insightdatascience.com/learning-to-think-like-a-data-scientist-part-2-67201608083e?source=friends_link&amp;sk=6d5124d9819f21805e92a70e0f51ccdc">Part 2</a> covers the project execution phase. Throughout both, I will highlight key concepts and outline a framework for developing data products in a business setting.</p><h3>Project Planning Phase</h3><p>The main task of this phase is project ideation, and the main goal is to develop a project roadmap. No coding or machine learning is used. The three steps in this phase are:</p><ol><li>Identifying the business need</li><li>Defining a minimum viable product</li><li>Identifying potential data sources</li></ol><p>Properly completed, these steps represent the roots of a healthy project.</p><h4><strong>Step 1. Identify the Need</strong></h4><p>The overarching purpose of any data product is to provide value by filling an unmet need. It is important to define this need right at the start of the project planning phase because it will become the guide by which all subsequent decisions are made. You can think of this guiding need (as I will call it) as a fixed target that you are navigating toward. It begins broad and can be approached from various directions. Then, as you build your product, it narrows and becomes more defined. It may be tempting to try to grow a product around a particular dataset or tool, but without a guiding need you will quickly find yourself directionless and unfocused. This is poor business practice and not recommended.</p><p>I started by brainstorming needs that could be met with data science approaches. I then converted the needs I had generated into a shortlist of potential project ideas. At this point, it was helpful to bounce my ideas off of colleagues and friends, especially those with relevant domain knowledge. I found that some of my project ideas had already been implemented, or did not really solve a need, so I weeded those out. Finally, after some deliberation, I settled on a project that would address a wildflower-related tourism need. More specifically, I would build a product to let users know where and when wildflowers were blooming.</p><p>Some of the factors that I took into consideration when making this choice were scalability potential, impact potential, and user base potential. Because I only had four weeks for this project, the scale had to stay small. I wanted to ensure that my product had enough room for future growth — I wanted to choose a guiding need that, given more time and resources, was broad enough to allow for added functionalities. I also wanted to make sure that the product could be widely relevant across users and use-cases, and that it could provide disruptive value. These factors are not essential in a personal data project, but cultivating this kind of thinking is good preparation for working in a profit-driven environment.</p><p>Another reason that I chose this particular project was that there was a lot of tension and stress in the air at the time (June 2020), and I figured it would do me some good to think about flowers for a little while.</p><p><strong>Wildflower Bloom Season</strong></p><p>Wildflowers bloom in the springtime, and every year visitors flock to state and national parks to see the blooms and enjoy their expansive displays of color. But wildflower season only lasts a few weeks, and the exact timing, location, and quality of the blooms vary from year to year. To help people time their visits, many parks provide periodic bloom status updates. However, updates are not available for blooms outside of these parks. I wanted to explore the needs caused by this lack of information, so I created a few scenarios to get me thinking about the potential end-users of my product:</p><blockquote>Michelle lives in San Francisco and would like a quick last-minute getaway before starting a new job. Her friends have told her about the beautiful fields of wildflowers they saw a week earlier in Yosemite, but she does not want to travel that far. Is there someplace else close by where she can enjoy the bloom season?</blockquote><blockquote>David is planning a three month RV road trip through the western US. He likes painting watercolors of nature scenes, and wants to be able to set up his easel and capture the wildflower scenery at spots along the way. How can he plan a route that gets him to the right places at the right times?</blockquote><blockquote>Emily, an Instagram influencer living in LA, is always on the lookout for good photo-ops. She heard that the nearby Antelope Valley Poppy Reserve is bursting with color, but she wants to avoid the crowds. Besides, she doesn’t want her photos to look like everyone else’s, and she’s willing to travel to remote locations for unique opportunities. Where can she go to get poppy photos that will set her apart from the crowd?</blockquote><figure><img alt="" src="https://cdn-images-1.medium.com/max/720/1*a_nGIYah9skG3kqUeCyYqQ.jpeg" /><figcaption>Crowds at the Antelope Valley California Poppy Reserve (image courtesy of California State Parks, 2019)</figcaption></figure><p>Putting myself into the shoes of the end users helped me explore the need and figure out what kind of value I could provide. I knew I would not be able to solve each individual’s unique need, but I realized that all of their needs had a common theme: difficulty with planning trips to see blooms in non-park locations. I decided I wanted to build a product that would grant users access to more wildflower locations by making bloom information easily available.</p><blockquote>I realized that all of their needs had a common theme: difficulty with planning trips to see blooms in non-park locations.</blockquote><h4><strong>Step 2. Define a minimum viable product</strong></h4><p>Once a guiding need is identified, it is time to define a <strong><em>minimum viable product</em></strong>. A minimum viable product is the most stripped down version of the product that can still fill the guiding need. In other words, it is a proof-of-concept prototype that meets the basic expectations of the end-user. It also serves as a starting point in the product development process, with improvements and functionalities added in an iterative manner.</p><p>Learning about this concept was incredibly freeing for me because it let me circumvent my perfectionist tendencies and rapidly work to produce a deliverable. In academic research, the ultimate goal is to unearth new truths. Results must be accurate and exact, and project timelines are long to allow for multiple validation steps. But I was now on new terrain: the bottom line was business value, and the goal was to get there as fast as possible. Business needs can shift quickly, so it is imperative to maintain maneuverability by identifying problems early and nipping them in the bud. Products are validated by their usefulness, not by their exactness, and the ability to rapidly recognize and discard dead-end directions is far more valuable than the ability to burrow deep into a problem and produce flawless work. It felt strange to abandon the pursuit of perfection, but I soon came to find the fast pace exhilarating and the productivity rewarding. It also helped to know that I could correct errors on subsequent iterations if needed.</p><p><strong>Technique to define a minimum viable product</strong></p><p>I used two techniques to help me define my minimum viable product. <strong>The first was to think about the product in specific detail</strong>: It would be an interactive web application that provides current bloom status and a two week bloom forecast for poppies in California. However, my mentors pointed out that targeting the entire state was too ambitious for a minimally viable version of the product. So I decided to provide information for just three specific California locations. Other regions could be added to later versions of the product if I chose to scale it up and get the necessary data engineering support.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*4316A0n4azEIb0ub_ZmjMg.jpeg" /><figcaption>The three California locations I chose to include in my minimum viable product</figcaption></figure><p>These kinds of specific details serve to focus your efforts — but they are not set in stone. As the project progresses it may become necessary to change them a bit to account for limitations, roadblocks, or shifting demands. This is okay as long as they remain within the scope of the guiding need. And as you will see later, I did in fact have to change some details as I moved through the steps of the project.</p><p>In retrospect, I think it is a good idea to start out with an overly inflated list of specific details, and then whittle them down one by one as you work towards your minimum viable product. This lets you explore the future potential of the product, and gives you wiggle room for pivots, if needed later.</p><p>It can even be useful to think about related products that are beyond the scope of the guiding need. For example, I wondered if there was a need for products to predict fall foliage color changes in the northeastern US, or Jacaranda blossoms in South Africa. I had no intention of building such products, but this kind of thinking helped me establish the boundaries of the product I <em>was </em>building. And who knows, I might find that once I’ve established a data pipeline for my product, it would not be so difficult to build these additional products!</p><p><strong>The second technique I used to define the minimum viable product was to visualize in detail what it would look like</strong>. This helped me dig down even further into specific details. I got out some paper and markers and drew a few sample mockups until I had one I was happy with. This process forced me to think about all the inputs and outputs of the app, and about how I would communicate the results to the user. I decided that the landing page would have two user input boxes — one for location and another for date — and a clickable ‘Find Poppies’ button. The predicted bloom level for the requested location and date would then be outputted in text format as either ‘low’, ‘medium’, or ‘high’. I gave the app a temporary name (PoppyPredictor) as a placeholder until I could come up with something more catchy.</p><p>With these specific goals planted firmly in mind, I was now prepared to start thinking about what data I needed and to identify potential data sources.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*KnDJdlQiFjdOeNIGk-DNng.jpeg" /><figcaption>An early product mockup</figcaption></figure><h4><strong>Step 3. Identify potential data sources</strong></h4><p>The most important data I needed was information about current and past poppy blooms in California. I thought of a few possible ways to get this information:</p><ol><li>Scrape bloom updates from park websites</li><li>Access poppy sighting reports from specialized websites like <a href="https://www.gbif.org/">GBIF</a> or <a href="https://www.inaturalist.org/">iNaturalist</a></li><li>Identify large blooms in satellite images</li><li>Use poppy mentions on Twitter or Instagram as a proxy for bloom occurrences</li></ol><p>I also looked for sources of temperature and precipitation data because these could be useful predictors of poppy growth. Fortunately, current and past California meteorological records were freely available and easy to access.</p><p>Now no data source is perfect, and each comes with its own set of challenges (e.g. accessibility, dirtiness, missing labels, not enough data, etc.). But the top priority when deciding which one to use should be how close it can get you to meeting the guiding need. Technical difficulties can be overcome, but an irrelevant dataset — no matter how clean or big or easy to work with — will do nothing to get you to your goal. Besides, challenges can be fun, and they’re a great way to showcase creativity and problem solving skills!</p><p>With that in mind, I evaluated the usefulness of each of the poppy data sources under consideration. Social media and park websites yield rich and fertile data about poppy blooms in popular locations. That kind of data is useful for building forecasting models, but it lacks the key information needed for my product: data about blooms in non-park locations. A quick perusal of botany-related websites revealed poppy sighting reports in non-park locations, but these reports were sparse and infrequent, and they were limited to the initial poppy sightings of the season. While that information could help predict the start of poppy season in non-park locations, it was still not sufficient to meet the guiding need. Satellite data, on the other hand, is both agnostic about location and not reliant on human observers. These characteristics make it an excellent and consistent source of information about off-the-beaten-path wildflower blooms. And while satellite data can suffer a loss of granularity compared to data from other sources, this deficiency is more than compensated for by the unique value it provides.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*e40PtNrMJHHXUNeto_q2LQ.jpeg" /><figcaption>Artist’s rendition of the Sentinel-2 satellite (image courtesy ESA, EADS Astrium)</figcaption></figure><p>I had now identified two potential streams of data — satellite and weather — and it was time to finally move out of the planning phase and start getting my hands dirty with some actual datasets.</p><p>In <a href="https://blog.insightdatascience.com/learning-to-think-like-a-data-scientist-part-2-67201608083e?source=friends_link&amp;sk=6d5124d9819f21805e92a70e0f51ccdc">Part 2</a> of this blog, I will discuss data preparation and project execution. Spoiler alert: the final product looks different than what I had envisioned in the planning stages. Stay tuned to hear about the plot twists that arose and how I navigated them!</p><p>For more information about the project check out the <a href="https://github.com/EstherRichler/kaBLOOM">GitHub repository</a>.</p><p><strong><em>Are you ready to make a change &amp; transition to a career in tech? </em></strong><a href="https://notify.insightdatascience.com/notify?utm_source=kabloompart1&amp;utm_medium=blog"><em>Sign up</em></a><em> to learn more about </em><a href="https://insightfellows.com/?utm_source=kabloompart1&amp;utm_medium=blog"><em>Insight Fellows programs</em></a><em> and start your application today.</em></p><p><em>A note to my readers: I’d love to get to know you! Just for fun, I planted botany puns throughout this blog post. Hit me up on Twitter </em><a href="https://twitter.com/EstherRichler"><em>@EstherRichler</em></a><em> and tell me which ones you’ve found. Even better, come up with new ones I haven’t thought of!</em></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=7323ddb17c69" width="1" height="1" alt=""><hr><p><a href="https://blog.insightdatascience.com/learning-to-think-like-a-data-scientist-7323ddb17c69">Learning to Think Like a Data Scientist</a> was originally published in <a href="https://blog.insightdatascience.com">Insight</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[A Time Series Anomaly Detection Model for All Types of Time Series]]></title>
            <description><![CDATA[<div class="medium-feed-item"><p class="medium-feed-image"><a href="https://blog.insightdatascience.com/a-time-series-anomaly-detection-model-for-all-types-of-time-series-f17677f8f771?source=rss----d02e65779d7b---4"><img src="https://cdn-images-1.medium.com/max/752/1*2TrcdjdMtVsv4pzIhjNrxA.png" width="752"></a></p><p class="medium-feed-snippet">My Journey to improve Lazy Lantern&#x2019;s automated time series anomaly detection model</p><p class="medium-feed-link"><a href="https://blog.insightdatascience.com/a-time-series-anomaly-detection-model-for-all-types-of-time-series-f17677f8f771?source=rss----d02e65779d7b---4">Continue reading on Insight »</a></p></div>]]></description>
            <link>https://blog.insightdatascience.com/a-time-series-anomaly-detection-model-for-all-types-of-time-series-f17677f8f771?source=rss----d02e65779d7b---4</link>
            <guid isPermaLink="false">https://medium.com/p/f17677f8f771</guid>
            <category><![CDATA[data-modeling]]></category>
            <category><![CDATA[anomaly-detection]]></category>
            <category><![CDATA[insight-data-science]]></category>
            <category><![CDATA[data-science]]></category>
            <category><![CDATA[time-series-analysis]]></category>
            <dc:creator><![CDATA[Yeonjoo Yoo]]></dc:creator>
            <pubDate>Mon, 02 Nov 2020 17:05:11 GMT</pubDate>
            <atom:updated>2020-11-02T17:05:10.976Z</atom:updated>
        </item>
        <item>
            <title><![CDATA[Leveraging the power of Infrastructure as Code & Airflow for testing]]></title>
            <description><![CDATA[<div class="medium-feed-item"><p class="medium-feed-image"><a href="https://blog.insightdatascience.com/shadowops-8d6cc3530c85?source=rss----d02e65779d7b---4"><img src="https://cdn-images-1.medium.com/max/2600/1*phVXhoEpzUTsZCZ3zYJ08Q.jpeg" width="6000"></a></p><p class="medium-feed-snippet">One-Click Ephemeral Test Environment</p><p class="medium-feed-link"><a href="https://blog.insightdatascience.com/shadowops-8d6cc3530c85?source=rss----d02e65779d7b---4">Continue reading on Insight »</a></p></div>]]></description>
            <link>https://blog.insightdatascience.com/shadowops-8d6cc3530c85?source=rss----d02e65779d7b---4</link>
            <guid isPermaLink="false">https://medium.com/p/8d6cc3530c85</guid>
            <category><![CDATA[circleci]]></category>
            <category><![CDATA[devops]]></category>
            <category><![CDATA[insight-devops]]></category>
            <category><![CDATA[aws]]></category>
            <category><![CDATA[airflow]]></category>
            <dc:creator><![CDATA[Saeed Mohajeryami]]></dc:creator>
            <pubDate>Tue, 27 Oct 2020 00:31:36 GMT</pubDate>
            <atom:updated>2020-10-27T00:31:36.256Z</atom:updated>
        </item>
        <item>
            <title><![CDATA[Insight now offers deferred payment loans]]></title>
            <link>https://blog.insightdatascience.com/insight-now-offers-deferred-payment-loans-f00edf9c40dc?source=rss----d02e65779d7b---4</link>
            <guid isPermaLink="false">https://medium.com/p/f00edf9c40dc</guid>
            <category><![CDATA[insight-data-science]]></category>
            <dc:creator><![CDATA[Insight]]></dc:creator>
            <pubDate>Fri, 21 Aug 2020 15:53:49 GMT</pubDate>
            <atom:updated>2020-08-21T15:53:49.617Z</atom:updated>
            <content:encoded><![CDATA[<h4>Insight and Climb Credit partner to lower the barrier to thriving careers</h4><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*cpJMy2cW_Zv0P2LZmAMkTg.png" /></figure><p>At <a href="https://insightfellows.com">Insight</a>, we want to make sure that everyone with the right skills can participate in our programs, regardless of financial challenges. So, in addition to offering <a href="https://insightfellows.com/scholarships">several scholarships</a> to help reduce the barriers that keep you from taking those first steps to launch a thriving career, we are now offering deferred payment loans to Fellows in all of our programs through a partnership with <a href="http://climbcredit.com">Climb Credit</a>. These loans are offered through Climb Credit’s upfront financing, and are financially backed by Insight to support our Fellows during their career transition.</p><iframe src="https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fwww.youtube.com%2Fembed%2F9o8pk1sSi9c%3Ffeature%3Doembed&amp;display_name=YouTube&amp;url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3D9o8pk1sSi9c&amp;image=https%3A%2F%2Fi.ytimg.com%2Fvi%2F9o8pk1sSi9c%2Fhqdefault.jpg&amp;key=a19fcc184b9711e1b4764040d3dc5c07&amp;type=text%2Fhtml&amp;schema=youtube" width="854" height="480" frameborder="0" scrolling="no"><a href="https://medium.com/media/d9331fda6d22a12a0c0ee5ef669d9ebd/href">https://medium.com/media/d9331fda6d22a12a0c0ee5ef669d9ebd/href</a></iframe><h3>Climb Credit Financing</h3><p>Climb allows Fellows to make manageable monthly payments over a few years. Their loan process is simple and fully-online, and the vast majority of applicants receive a funding decision almost immediately. This application process doesn’t do a hard credit check, so applying won’t have a negative impact on your credit score. Climb works with people from all kinds of credit backgrounds, including those without any credit to their name.</p><p><strong>Climb Offers:</strong></p><ul><li>A quick <a href="https://climbcredit.com/apply/insightfellows">online application</a>, which can be completed in as little as 5 minutes with no impact to credit</li><li>High loan approvals — including financing for people with no credit</li><li>Instant decisions 90% of the time, with the ability to accept and e-sign your documents in just a few clicks</li><li>Climb allows you to set up auto-payments, so you don’t have to remember to make your payment each month. <strong>As an added bonus, they will reduce your interest rate by 0.25% if you sign up for autopay.</strong></li><li>You can pay off your loan early without any pre-pay penalties</li><li>No payments until 9 months after you join Insight, ensuring you meet all components of the Insight guarantee</li></ul><h3>Backed by Insight’s Guarantee</h3><p>As with all of Insight’s <a href="http://insightfellows.com/financing">financing options</a>, the Deferred Payment Loan option is backed by our <a href="https://insightfellows.com/guarantee">guarantee</a>: you will only complete the financial commitment if you achieve the high level of success that we expect for our community. When you select financing through a Climb loan, you only pay if you accept an offer for a <a href="https://insightfellows.com/relevant-positions">relevant job</a> earning at least $100,000 (and that offer is dated within 6 months of the end of the program).</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*K0phjQcsB6A1N4BTp0338A.png" /></figure><h3>Helping our Fellows into thriving careers</h3><p>Ultimately, all of our partnerships and initiatives have one goal — the <a href="https://insightfellows.com/outcomes">long-term success</a> of our Fellows. We’ve helped more than 3,000 Fellows start thriving careers at over 700 top teams. 88% of our Fellows join relevant roles within six months of joining the program, and we continue helping every Fellow until they find a good fit.</p><p>And their success continues well beyond the 7 weeks of our program. The same strong drive and collaboration that makes our Fellows successful in our program helps them become leaders in their fields. Our Fellows lead teams at industry pioneers like Amazon, Apple, Bloomberg, Capital One, CVS, Facebook, Google, LinkedIn, Lyft, Microsoft, Netflix, Pinterest, Spotify, Stitch Fix, Tamr, Twitch, Twitter, The New York Times, Uber, Wayfair, and Yelp. Our Fellows also lead teams at hundreds of high-growth startups, and several alumni have gone on to start their own innovative startups.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*ftYNd4xudFg31zy6" /><figcaption>Source: Data reported from Fellows that completed Insight 2017–2019, compared to corresponding market data reported on Glassdoor in May 2020.</figcaption></figure><p>The most rewarding part of our program, and the reason Insight exists, is the experience we provide for our Fellows. We’re incredibly excited to continue helping our Fellows transition to thriving careers with a growing number of financing options.</p><p><strong><em>Interested in transitioning to a thriving career?</em></strong><em> </em><a href="https://insightfellows.com/"><em>Learn more</em></a><em> about the Insight Fellows Program and </em><a href="https://apply.insightdatascience.com/"><em>start your application</em></a><em> today.</em></p><p><em>* While Insight offers all of our other financial aid options to all Fellows, Climb Credit can only offer financing to US citizens or Permanent Residents.</em></p><figure><a href="https://www.insightdatascience.com/experience"><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*ybK-pQFp0MHaLdUASntoIA.png" /></a><figcaption>Learn more about <a href="https://www.insightdatascience.com/experience">the Insight Fellow experience</a> from alums who have started thriving careers at top teams.</figcaption></figure><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=f00edf9c40dc" width="1" height="1" alt=""><hr><p><a href="https://blog.insightdatascience.com/insight-now-offers-deferred-payment-loans-f00edf9c40dc">Insight now offers deferred payment loans</a> was originally published in <a href="https://blog.insightdatascience.com">Insight</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Insight Summer Session 2020 Update]]></title>
            <link>https://blog.insightdatascience.com/insight-summer-session-2020-update-999e20b5b2d0?source=rss----d02e65779d7b---4</link>
            <guid isPermaLink="false">https://medium.com/p/999e20b5b2d0</guid>
            <category><![CDATA[insight-data-science]]></category>
            <dc:creator><![CDATA[Insight]]></dc:creator>
            <pubDate>Mon, 17 Aug 2020 16:09:08 GMT</pubDate>
            <atom:updated>2020-08-28T13:01:13.624Z</atom:updated>
            <content:encoded><![CDATA[<p>Insight recently completed its first totally remote session. This summer, we hosted more than 350 Fellows from across 33 different U.S. states, Canada, and around the world. As they move on to the post-session experience and continue to interview with hiring companies, we thought we’d share a recap of their first 7-weeks with Insight.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/602/1*4b_VA4Qq-f4x5syqL6JYnw.png" /></figure><h3>The Remote Experience</h3><p>While this was the first session for Insight in which all Fellows participated remotely, we’ve been offering a remote data science program since 2015. We’re happy to report that we successfully adapted what we’ve learned during that time to all 7 of our programs across all locations. While certain aspects of the remote experience looked a bit different than the on-site offering, <a href="https://blog.insightdatascience.com/insights-remote-fellows-program-f5d027f237d3">many remained the same</a>, and there are also <a href="https://blog.insightdatascience.com/remote-fellow-superpowers-cb863c1c1ee0">several benefits</a> to a remote program that a more restrictive in-person session simply can’t offer. Insight continues to provide Fellows with full support from our teams:</p><ul><li><strong>Program Directors</strong> work directly with Fellows to provide expert mentorship, advising on project selection, development, and demoing with hiring companies.</li><li><strong>Program Operations Team</strong> provides expertise for managing the crucial program operations (communications, planning, logistics, tracking, etc.) necessary to ensure the success of each Fellow.</li><li><strong>Coaching &amp; Development Team</strong> provides high-quality training, coaching, and feedback via workshops and small group sessions, helping Fellows identify the best roles at this stage of their careers and build the self-awareness and confidence to communicate their unique value-add.</li><li><strong>Interview Strategy Team</strong> is fully dedicated to the post-session experience, providing support and mentorship services through dedicated training and coaching groups in service of helping Fellows build the bridge to thriving careers.</li><li><strong>Partnerships Team </strong>works directly with hiring companies to understand their specific needs and secure exciting opportunities for our Fellows across all programs and locations.</li></ul><figure><img alt="" src="https://cdn-images-1.medium.com/max/690/1*ZG-PX_TxPDLv-5EbE2dTJg.png" /><figcaption>Kim Vo (Coaching &amp; Development Lead, Interview Strategy Team) and Emily Kearney (Program Director, Data Science) during the fall session, September 2019.</figcaption></figure><p>Fellows benefit from the same small cohort sizes that the in-person Fellowship offered. None of our program cohorts have grown beyond 30, with the average being about 20 Fellows. Technical advisor and alumni mentoring meetings provide opportunities for even smaller groups to gain feedback and advice, and personalized interview preparation is conducted on a one-on-one basis, tailored to relevant skills required for that company, and based on the existing skills of the individual Fellow.</p><p>Fellows now also enjoy the technical advantages of using industry-standard distributed tools such as presentations via Zoom, internal messaging platforms (like Slack), and Github to contribute to a shared codebase. The remote session enabled Fellows’ increased flexibility and a more expansive reach. This summer, Fellows reported that they enjoyed the ease of meeting with other Fellows and Insight staff members every day without the wasted time of having to commute. Participating remotely also meant that Fellows were better able to set their own work times, instead of the more strict 9:00am — 6:00pm that is required during the in-person session. The remote experience made it much easier to connect and work with Fellows from other locations, and expanded access to Industry Leader Mentor presentations that are generally restricted to Fellows located in the city where the mentor visit is hosted.</p><h3>Industry Leader Mentor Sessions</h3><p>An exciting aspect of Insight’s Fellows Programs is the opportunity to participate in Industry Leader Mentoring Sessions, in which some of the tech industry’s top professionals visit with Fellows to speak about their experiences, share perspectives, and answer questions.</p><h3></h3><p>hey @jakeklamka, thank you for having me last week for an AMA with your @InsightFellows cohort! pic.twitter.com/6QEL8WW1yH</p><p>During the summer session, Insight was proud to host an impressive lineup of industry leaders, which included:</p><p><a href="https://alexisohanian.com/"><strong>Alexis Ohanian</strong></a><strong>, </strong>the co-founder and managing partner of Initialized Capital. He was the co-founder, and later Executive Chairman, of Reddit. Ohanian is also the best selling author of <em>Without Their Permission</em>.</p><p><a href="https://norvig.com/"><strong>Peter Norvig</strong></a><strong>, </strong>a<strong> </strong>Director of Research at Google. He was previously head of Google’s core search algorithms group, and of NASA Ames’s Computational Sciences Division, making him NASA’s senior computer scientist. Norvig is co-author of <em>Artificial Intelligence: A Modern Approach</em>.</p><p><a href="https://www.linkedin.com/in/dpatil/"><strong>DJ Patil</strong></a><strong>, </strong>who served as the first Chief Data Scientist of the United States Office of Science and Technology Policy, and is currently the Head of Technology at Devoted Health. Patil is credited with coining the term “data science”.</p><p><a href="https://hilarymason.com/"><strong>Hilary Mason</strong></a><strong>, </strong>the co-founder of Hidden Door, founder of Fast Forward Labs, a machine intelligence research company, and the Data Scientist in Residence at Accel. Mason was previously the Chief Scientist at bitly and co-founder of hackNY.</p><p><a href="https://www.linkedin.com/in/solomonhykes/"><strong>Solomon Hykes</strong></a><strong>, </strong>the Founder, Chief Technology Officer and Chief Architect of Docker and the creator of the Docker open source initiative. In his role at Docker, Solomon is focused on building a platform for developers and system administrators to build, ship, run and orchestrate distributed applications.</p><p><a href="http://drewconway.com/"><strong>Drew Conway</strong></a><strong>, </strong>the Senior Vice President at Two Sigma. He was previously the founder and CEO of Alluvium, and is a leading expert in the application of computational methods to social and behavioral problems at large-scale.</p><p><a href="https://www.linkedin.com/in/wiggins/"><strong>Chris Wiggins</strong></a><strong>, </strong>the Chief Data Scientist at The New York Times, and an associate professor of applied mathematics at Columbia University. At Columbia, Wiggins is a founding member of the executive committee of the Data Science Institute, and of the Department of Systems Biology. He is also a co-founder and co-organizer of hackNY.</p><p><a href="https://www.linkedin.com/in/ahbauer/"><strong>Anne Bauer</strong></a><strong>, </strong>the Director of Data Science at The New York Times, leading the team in charge of algorithmic content recommendations. Bauer is also an alum of the 2015 Insight Data Science Fellowship Program.</p><p><a href="https://wesmckinney.com/"><strong>Wes McKinney</strong></a><strong>, </strong>an open source software developer focusing on data analysis tools. He created the Python pandas project and is a co-creator of Apache Arrow. McKinney is currently a director at Ursa Labs, a member of The Apache Software Foundation, and a PMC member for Apache Parquet.</p><h3>Diversity, Equity, and Inclusion Summit</h3><p>This session, Insight hosted a Diversity, Equity, and Inclusion (DEI) Summit, with the goal of facilitating discussions to share insights, challenge perspectives, pose stimulating questions and build community with each other so that Fellows are better able to enact positive change in their new roles. This event brought together Insight Fellows, staff, and thought leaders from our community to discuss a range of social issues that impact how we work together, and society at-large.</p><p>Lightning talks from Insight staff, an alumni panel, and a keynote speaker were utilized to spark conversation for discussing important — and sometimes difficult — topics that we don’t often have the chance to talk about candidly in our day-to-day work; topics that nevertheless tie into how we experience the workplace and interact with each other.</p><p>The event Included:</p><p><strong>Lightning Talks</strong> with Insight Program Directors, who discussed a toolkit for recognizing and addressing your unconscious bias, and reflecting on anti-Black violence.</p><p><strong>Alumni Panel</strong> with Insight alumni Melecia Wright &amp; Che Smith, who discussed the role of companies and technology in building a more equitable and socially just future.</p><p><strong>Keynote Speaker</strong> <a href="https://www.brandeismarshall.com/">Brandeis Marshall</a> presented, Deepfake Technology: The (Mis-) Representation of Data. In this session, Dr. Marshall described deepfake technology and discussed issues related to ethics, privacy, and accountability for companies who use “black box” algorithms to make decisions and the respective societal impacts.</p><iframe src="https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fwww.youtube.com%2Fembed%2FNbedWhzx1rs%3Ffeature%3Doembed&amp;display_name=YouTube&amp;url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DNbedWhzx1rs&amp;image=https%3A%2F%2Fi.ytimg.com%2Fvi%2FNbedWhzx1rs%2Fhqdefault.jpg&amp;key=a19fcc184b9711e1b4764040d3dc5c07&amp;type=text%2Fhtml&amp;schema=youtube" width="854" height="480" frameborder="0" scrolling="no"><a href="https://medium.com/media/4b102d85b0c521351e09d68537aefb73/href">https://medium.com/media/4b102d85b0c521351e09d68537aefb73/href</a></iframe><p>As Fellows prepare to enter the job market and join a professional community, we want to help them think critically about how they can contribute to creating more diverse, equitable, and inclusive work environments. Below are a few reactions that Fellows shared about the event:</p><ul><li>“Thank you to every person for exposing your vulnerability to such a large group. It really helped me to engage with the conversation because I felt safe there.”</li><li>“…I have attended many diversity training workshops in my schools and my previous job. However, this was the best and most genuine of them all. I can see all the effort put in it. Thank you!”</li><li>“I am so grateful to Insight for letting us pause for a moment and think about our mission and responsibilities to make this world a better place through science, tech, education, communication, and reaching out to the congress to hear our voices. And most of all, I found a group of inspiring women during our discussion time through Insight platform.”</li></ul><h3>Fellow Spotlights</h3><p>We have been working with so many incredibly talented Fellows this summer, and spotlighted a few to reflect their wide range of backgrounds, special skills, and experience.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/647/1*nVoNZYd0xvCLyJFRnvwlbw.png" /><figcaption>Top row (left to right): Jayakrishnan Parappalliyali, Paige Chang, Cameron Jones; Middle row (left to right): Karen Larson, Javed, Jaghai, Saba Khalid; bottom row (left to right): Justin Kaseman, Doaa Altarawy, Sarah Uludag</figcaption></figure><p><a href="https://www.linkedin.com/in/parappalliyalil/"><strong>Jayakrishnan Parappalliyali</strong></a>, DevOps Fellow from San Francisco. At Insight, he built an autonomous stateful application in a cost-efficient cloud infrastructure.</p><p><a href="https://www.linkedin.com/in/p-chang/"><strong>Paige Chang</strong></a>, Artificial Intelligence Fellow from NYC. During the session, she applied a cutting-edge approach (reinforcement learning) to a classic data problem (song recommendation), all deployed using AWS and Tensorflow.</p><p><a href="https://www.linkedin.com/in/camantis/"><strong>Cameron Jones</strong></a>, Data Science Fellow in San Francisco. Cameron built an app for streaming positive, relevant news for Black audiences by scraping and processing articles through Natural Language Processing (Google’s BERT model).</p><p><a href="https://www.linkedin.com/in/saba-khalid/"><strong>Saba Khalid</strong></a>, Data Engineering Fellow from New York City. For her project, Saba built an efficient data pipeline to ETL Federal Elections Committee (FEC) data to map changing trends in individual campaign contributions.</p><p><a href="https://www.linkedin.com/in/karenruthlarson/"><strong>Karen Larson</strong></a>, Health Data Science Fellow from Boston. Karen has been consulting for University Hospitals, building a tool to help doctors avoid ordering unnecessary lymph node biopsies for melanoma patients.</p><p><a href="https://www.linkedin.com/in/javed-jaghai/"><strong>Javed Jaghai</strong></a><strong>,</strong> Data Science Fellow based in Washington D.C. Javed leveraged a deep learning RNN model to build the world’s first two-way translator between English and Jamaican Creole.</p><p><a href="https://www.linkedin.com/in/justin-kaseman/"><strong>Justin Kaseman</strong></a>, Decentralized Consensus Fellow based in the Bay Area. At Insight, Justin built a tool to easily bootstrap and deploy a decentralized application to help bring new developers into the space.</p><p><a href="https://www.linkedin.com/in/daltarawy/"><strong>Doaa Altarawy</strong></a>, Data Science Fellow in Toronto. As a Fellow, Doaa applied her strong data and engineering skills to an incredibly timely project: screening chest x-rays for quick detection of COVID-19, using fastai’s deep neural net model.</p><p><a href="https://www.linkedin.com/in/sarah-u/"><strong>Sarah Uludag</strong></a>, Data Engineering Fellow from Los Angeles. Sarah built a tool for finding and marking public keys used in Bitcoin transactions on the Dark Web using Apache Spark, Cassandra, and Neo4J.</p><h3>Post Session Experience</h3><p>The initial 7-week program of the Fellowship has come to an end, but Insight’s work with Fellows has only just begun. Fellows spent the session building projects and demoing their work, and are now engaged in interviewing with hiring companies. As of August 28, there are 356 opportunities from 238 companies, and that list continues to grow. This is a difficult time for the economy, but we’re happy to report that our current growth rate of hiring opportunities is on par with our summer session in 2019. Companies currently interviewing Fellows include Netflix, Amazon, Facebook, Google, Yelp, Apple, Pinterest, The New York Times, Johnson &amp; Johnson, Humana, CVS, ProtonMail, Bolt Labs, and many more!</p><p>Insight’s Interview Strategy Team is currently working with our Fellows on an individual level to provide personalized interview preparation support and mentorship services. We’re investing in our Fellows to honor our <a href="https://insightfellows.com/guarantee">guarantee</a> and ensure they’re hired quickly to launch exciting new careers in tech.</p><p><strong>The Insight Guarantee</strong></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*K0phjQcsB6A1N4BTp0338A.png" /></figure><h3>Looking ahead to our Fall 2020 Session</h3><p>Insight is currently selecting our next Fellow cohort for the fall session, and continuing to work to help reduce the barriers that keep potential Fellows from participating in Insight’s programs, taking those first steps to launch their thriving careers.</p><p><strong>Scholarships</strong></p><p>We’re expanding our current <a href="https://insightfellows.com/scholarships">offering of scholarships</a> beyond our Need-based Scholarship, which has been available for several years to help fund essential day-to-day living needs related to the program. Starting this fall, we will now offer two additional scholarships:</p><ul><li><strong>Scholarship for Underrepresented Minority Groups</strong> — This fund has been established to help remove barriers for our Fellows from racial and ethnic backgrounds that are traditionally underrepresented in tech. Eligible Fellows will have the opportunity to complete a simple application process in order to be considered, and those selected will receive up to $3000.</li><li><strong>Gender Diversity in Tech Scholarship</strong> — Insight is proud to continue our partnership with Clover Health, who is sponsoring this scholarship fund to help remove barriers based on gender in the tech industry. Eligible Fellows who complete the application process will be considered for a $5000 scholarship.</li></ul><p><strong>Mentorship Opportunities</strong></p><p>This fall, Insight is also piloting a mentorship program for candidates who identify as one or more historically underrepresented groups in tech (American Indian, Black/African American, Hispanic, Latinx, or Native Hawaiian/Pacific Islander). The purpose of this mentoring program is to provide an opportunity for applicants to ask questions about the interview process, program, post-program experience, and workforce more broadly. Many applicants do not have existing connections to the Insight network that they can turn to for information that may be available to other applicants. As we learn from this pilot program, we’ll continue to improve upon the offering with the goal of providing a more inclusive experience for all.</p><p>Insight’s core value is to put Fellows first, and we are, first and foremost, committed to the long-term success of our Fellows. As we plan for the future, we’re excited to not only reach the same impressive <a href="https://insightfellows.com/outcomes">outcomes</a>, but to exceed them. We’ll continue to set a high bar for what constitutes success within the program, and maintain the guarantee of a job in a relevant field, earning at least a $100,000 salary within 6 months of the end of the program. In addition to our guarantee, we’re committed to improving upon and expanding our accessibility to an even broader audience.</p><p><strong><em>Are you ready to make a change &amp; transition to a career in tech? </em></strong><a href="https://notify.insightdatascience.com/notify?utm_source=20brecap&amp;utm_medium=blog"><em>Sign up</em></a><em> to learn more about </em><a href="https://insightfellows.com/?utm_source=20brecap&amp;utm_medium=blog"><em>Insight Fellows programs</em></a><em> and </em><a href="https://apply.insightdatascience.com/?utm_source=20brecap&amp;utm_medium=blog"><em>start your application today</em></a><em>.</em></p><p><em>This post was revised on August 28, 2020 to update the number of company opportunities.</em></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=999e20b5b2d0" width="1" height="1" alt=""><hr><p><a href="https://blog.insightdatascience.com/insight-summer-session-2020-update-999e20b5b2d0">Insight Summer Session 2020 Update</a> was originally published in <a href="https://blog.insightdatascience.com">Insight</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Catching Feels]]></title>
            <link>https://blog.insightdatascience.com/catching-feels-2e4df41799d?source=rss----d02e65779d7b---4</link>
            <guid isPermaLink="false">https://medium.com/p/2e4df41799d</guid>
            <category><![CDATA[predictions]]></category>
            <category><![CDATA[mood]]></category>
            <category><![CDATA[classification]]></category>
            <category><![CDATA[insight-data-science]]></category>
            <category><![CDATA[speech-recognition]]></category>
            <dc:creator><![CDATA[Afrah Shafquat]]></dc:creator>
            <pubDate>Wed, 05 Aug 2020 14:27:05 GMT</pubDate>
            <atom:updated>2020-08-05T14:47:01.923Z</atom:updated>
            <content:encoded><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*obeQhM4CSaZ1j70k" /><figcaption>Photo by <a href="https://unsplash.com/@lightrisephotography?utm_source=medium&amp;utm_medium=referral">Devon Divine</a> on <a href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral">Unsplash</a></figcaption></figure><p><em>Originally published in </em><a href="https://medium.com/maslo/catching-feels-162108cd8114"><em>Maslo - Your Virtual Self</em></a><em>. This project was completed during the Summer 2020 session of </em><a href="https://insightfellows.com/"><em>Insight Fellows Program</em></a><em>.</em></p><p>Humans show a myriad of explicit and implicit emotional signals in our behaviors. Our facial expression, posture, and even the music we listen to are types of expressions that tell the overarching story of how we feel. While most of these signals are implicitly communicated during human-to-human interaction, we do not have a method for quantifying feeling and mood through individual behavioral signals expressed on the digital platform. For this reason, signals that could help us understand ourselves and our emotions go unnoticed.</p><p>So I joined <a href="http://maslo.ai">Maslo</a>, whose mission is to increase self-awareness and empathy in the world using technology to capture and analyze emotional signals. My goal was to gain a better understanding of how behavioral signals relate to mood. <strong>Predicting mood from behavioral signals can enable artificially intelligent beings to make better empathy-led decisions</strong> and help Maslo develop state-of-the-art empathetic technology.</p><blockquote>Verbal communication is an extraordinarily rich source of emotional data.</blockquote><p>When people talk, their voice, pitch, tone, rate of speech, pauses, gaps, highs, lows, and jumps are evocative emotional expressions. When you add these audio signals to the textual signals of what is being said — including a sentence’s topic, content, context, syntax, semantics, and complexity — you get a daunting enigma. <strong>You have to wrangle all these implicit emotion-conveying signals to predict one final output: how is this person feeling right now?</strong></p><p>Given the breadth of information required, estimating mood from audio recordings presents an interesting challenge. In the context of Maslo’s products, presumption of mood through audio recording data can not only provide interesting mood-related insights but also supplement and validate current mood prediction pipelines at Maslo.</p><h3>Engineering The Data</h3><p>To predict emotion from speech recordings, I used open datasets containing audio data annotated with mood labels. These datasets are <a href="https://zenodo.org/record/1188976">RAVDESS</a>, <a href="https://github.com/CheyneyComputerScience/CREMA-D">CREMA-D</a>, <a href="https://tspace.library.utoronto.ca/handle/1807/24487">TESS</a>, and <a href="http://kahlan.eps.surrey.ac.uk/savee/">SAVEE</a>. I combined them, creating a dataset of 12,162 audio recordings of actors (57 females and 64 males) speaking words and sentences with specific emotions (angry, happy, sad, surprise, calm, neutral, fearful, and disgust). I predicted 4 emotion labels (‘angry’, ‘happy’, ‘sad’, and ‘neutral’) due to the limited number of samples in the dataset. This resulted in a training dataset of 7472 audio recordings.</p><p>For each audio recording, I used the feature extraction library <a href="https://github.com/librosa/librosa">librosa</a> to estimate audio features (<em>n</em> = 44) including, Mel-frequency cepstral coefficients (MFCCs), root mean square (loudness), and polynomial coefficients (polynomial fitted on spectrogram columns). Speech recordings are time-series data, so these features were computed across several overlapping time windows capturing the temporal changes in their values. This resulted in a 3-D features matrix of 7472 recordings x 44 features x <em>w</em> time windows; where <em>w</em> varies with audio length. Summary statistics (i.e. minimum, maximum, variance, and median) of each feature were computed per audio recording to estimate variation across time. This created a summary features matrix of 7472 recordings x 176 summary features, which was used for training emotion label prediction models.</p><h3>Prediction models</h3><p>An Exploratory Data Analysis showed improved performance was dependent on gender and emotion. To investigate this gender-specific effect further, I trained three emotion label prediction models using Random Forest Classification: (i) gender-nonspecific prediction model using all recordings (female/male), (ii) female-specific prediction model using female recordings only, and (iii) male-specific prediction model using male recordings only. To prevent data-leakage issues, actors in the training dataset did not reappear in the test datasets. Using cross-validation, the performance of each prediction model was estimated using Area under the Receiver Operating Characteristic curve or AUC as the comparison criteria.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*jPx8ERWkFWAlJdS4" /><figcaption>Performance of gender-nonspecific and gender-specific prediction models measured using Area under Receiver Operating Characteristic curve (AUC) for mood labels (‘Angry’, ‘Happy’, ‘Neutral’, and ‘Sad’)</figcaption></figure><p>An improvement of 7%, 6%, 8%, and 2% in median AUC values for predicting ‘angry’, ‘happy’, ‘neutral’, and ‘sad’ emotion labels respectively was observed through the female-specific prediction model over gender-nonspecific prediction model. There was a 4% and 5% improvement in median AUC for ‘angry’ and ‘sad’ emotion labels in the male-specific prediction model, where no improvement was observed for the other emotion labels. Improvements in AUC values across models were also accompanied by increased precision — up to 20% for prediction of ‘happy’ in females — in predictions through gender-specific models over the gender-nonspecific prediction model.</p><p>Across prediction models, summary statistics for features (i) root mean square, (ii) polynomial coefficients, and (iii) MFCCs had the highest feature importance. Here, root mean square is a measure of loudness of the recording, polynomial coefficients are the coefficients of a polynomial fitted on the columns of a spectrogram, and MFCCs are the coefficients derived from an alternate representation of the audio recording (i.e. the Mel-frequency cepstrum). When comparing the feature importance across prediction models, summary statistics for lower MFCCs (e.g. 1st and 2nd MFCCs) had higher feature importance in male-specific prediction models than female-specific prediction models where summary statistics for higher MFCCs were more important (e.g. 17th to 20th MFCCs).</p><figure><img alt="Cluster analysis of subset of features(y) in each prediction model(x), and feature importance (cell color)." src="https://cdn-images-1.medium.com/max/1024/0*7BaDppQCjc9m04av" /><figcaption>Heatmap comparing feature importance (cell color) of subset of features (rows) against prediction models (columns). Higher feature importance = Lighter color.</figcaption></figure><p>These results provide preliminary support for the hypothesis that there might be gender-specificities in the expression of certain emotions (happiness, neutral, and anger) over others (sadness). Female-specific prediction models showed increased performance improvements across different emotion-labels (‘angry’, ‘happy’, ‘neutral’) as compared to male-specific prediction models where improvements were more limited (‘angry’ and ‘sad’) or were not observed (‘happy’ and ‘neutral’). It is important to note that gender-nonspecific models have the advantage of training on a larger sample of audio recordings as compared to the training datasets for the gender-specific prediction models. However, improved performance of gender-specific models for prediction of emotion labels like ‘angry’ even with a reduction in training sample size shows that the gender-specific prediction models benefit from the removal of samples belonging to the other gender. Females and males use different ranges of frequencies, so gender-specific prediction models allow the model to learn the respective weights for the features specific to the range of frequencies. Moreover, gender-specific prediction models may also prevent internal gender-based stratification that might be happening within random forest classification, leading the model to prioritize learning emotion label-specific intricacies rather than gender-based differences.</p><h3>Assumptions and Limitations</h3><p>Though these findings provide encouragement for further investigation, it is important to be mindful of the assumptions made with these models.</p><ul><li><strong>Can I only feel one emotion at a time? </strong>The prediction models assume that each audio recording can only be classified as a single emotion label, where the simultaneous classification of multiple emotions to a particular recording is not considered. Though this assumption holds for the training dataset where actors acted out specific emotions, this might not be the case for ‘real’ audio recordings where a person may have mixed feelings: sad/happy, sad/angry. A potential solution is to leverage the probabilities associated with multiple emotion labels returned by the classification model. Those can be used in conjunction with any content-based insights to create more intelligent emotion/mood insights.</li><li><strong>Is this how people actually talk? </strong>The prediction models assume that the training data audio recordings are good approximations of the Maslo user recordings. However, recordings from Maslo’s products are typically less than or equal to 60 seconds whereas the training data recordings were as short as a word or sentence. Differences in audio length may reduce prediction model performance. For example, summary statistics like median or variance may denote completely different measurements when computed for a short audio recording versus a long audio recording. A possible solution might be to subsample the audio recording at random and create predictions for each sub-sample where the mode of emotion labels predicted may be determined as the final prediction by each model.</li><li><strong>A more<em> valid </em>validation?</strong> Another limitation of the current experiment is that the prediction models were validated on datasets that contained some of the same sentences and words in the training dataset. As validation datasets were created to prevent the same actor from being present in both training and test data, filtering out validation datasets based on statements would have limited the number of training samples drastically. This issue can be addressed by adding other large-scale, emotion-label annotated audio recording datasets such that filtering based on statements and actors would leave sufficient training samples for the prediction models.</li><li><strong>Gender is not binary: </strong>The gender-specific prediction models also assume that gender is binary (i.e. either female or male) where the reality of a gender spectrum may impede with model performance. To partially address this, we have also created a gender-prediction model using Random Forest Classification that is trained on the reported gender and summary features extracted from the audio recordings datasets. As this model predicts the ‘gender’ (Cross-validation median AUC: &gt; 0.9) based on features including those that quantify which part of the frequency spectrum is used by the speaker’s voice. This model may, in fact, be better classified as predicting people who speak at higher frequencies versus lower frequencies rather than actual gender. This gender-prediction model can enable stratification of future datasets based on frequencies which may be a better stratification than that using reported gender. Further study is needed to identify the impact of stratifying datasets using additional categories of gender on model performance.</li></ul><h3>Looking forward</h3><p>Emotion prediction presents a difficult problem where intricacies in defining the ‘true’ emotion label (i.e. self-reported mood vs. third-party mood perception) adds further complexity. The presented framework is an initial attempt to predict emotion labels where additional improvements may evolve into a more robust emotion prediction pipeline. Given results from the current experiment, the following emotion label prediction pipeline is proposed to make future predictions for Maslo products:</p><ul><li>Use reported gender or predict ‘gender’ of audio-recording using the gender-prediction model</li><li>Based on reported gender/predicted ‘gender’, predict emotion labels using the respective gender-specific prediction model</li><li>Predict emotion labels using the gender-nonspecific prediction model</li><li>Aggregate predictions from both models: Prioritize female-specific mood predictions (‘angry’, ‘happy’, ‘neutral’) and male-specific mood predictions (‘angry’, ‘happy’) for females and males respectively. Otherwise, rely on gender-nonspecific predictions</li></ul><p>This pipeline provides a preliminary strategy to produce mood/emotion label predictions and may also be used to supplement mood insights from the existing pipelines at Maslo. Predictions made through this pipeline may also allow analyses into edge cases, where the content-based insights and audio-based insights were incongruent. Besides identifying the robust gender-specificities of happiness and anger, it may also be interesting to isolate other emotions that exhibit a gender-specific effect. The problem of emotion prediction from audio recordings presents a complex, multi-faceted challenge. This project aims to understand the problem and open up the possibilities for further enhancements, including but not limited to those discussed in “Assumptions and Limitations”. Future work may explore simultaneous content and audio-based feature extraction to produce more robust emotion insights and improve predictions using relevant methodologies like Recurrent Neural Networks.</p><p>Explore the code and ideas more here: <a href="https://github.com/HeyMaslo/AllTheFeels">https://github.com/HeyMaslo/AllTheFeels</a></p><p><strong><em>Are you interested in transitioning to a career in data? </em></strong><a href="https://notify.insightdatascience.com/notify?utm_source=catchingfeels&amp;utm_medium=blog&amp;source=post_page">Sign up</a> to learn more about the <a href="https://insightfellows.com/?utm_source=catchingfeels&amp;utm_medium=blog&amp;source=post_page">Insight Fellows</a> programs and start your application today.</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=2e4df41799d" width="1" height="1" alt=""><hr><p><a href="https://blog.insightdatascience.com/catching-feels-2e4df41799d">Catching Feels</a> was originally published in <a href="https://blog.insightdatascience.com">Insight</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Insight Fall Updates: How Insight is adapting in 2020]]></title>
            <link>https://blog.insightdatascience.com/insight-fall-updates-how-insight-is-adapting-in-2020-dee47d01e8d1?source=rss----d02e65779d7b---4</link>
            <guid isPermaLink="false">https://medium.com/p/dee47d01e8d1</guid>
            <dc:creator><![CDATA[Jake Klamka]]></dc:creator>
            <pubDate>Thu, 25 Jun 2020 15:28:45 GMT</pubDate>
            <atom:updated>2020-06-25T15:28:45.500Z</atom:updated>
            <content:encoded><![CDATA[<p>In order for Insight to deliver on our mission, we’re making the following changes in response to the global COVID pandemic and resulting challenges in the job market:</p><ul><li>Many companies are continuing to hire, but have slashed their recruiting budgets. As a result, we are <strong>waiving the Insight sponsorship fee</strong> for companies to maximize job opportunities for Insight Fellows.</li><li>We are increasing our membership dues for Insight Fellows to $24,000 or an Income Share Agreement (ISA) of <strong>12% for 2 years</strong> <strong>with no upfront cost</strong>, to cover the shortfall.</li><li>We are <strong>maintaining our strong job guarantee </strong>for all Insight Fellows: you don’t pay anything unless you accept a relevant offer making <strong>at least $100,000 per year, and receive that offer within 6 months</strong> of finishing the Insight Fellows Program.</li><li>We are working to improve access to Insight by offering <strong>loans </strong>and<strong> expanding scholarships</strong>.</li><li>The Insight Fellows <strong>Fall session that starts on September 14, 2020 will run remotely</strong>, continuing the success we’re seeing in our current remote summer session.</li></ul><p>Delivering on our mission of helping Insight Fellows transition to thriving careers in cutting edge, high impact fields is more important than ever. COVID has accelerated the pace of technology adoption — including data, machine learning, cloud infrastructure, security and various other fields we work in — with medium and long term opportunity in these fields being larger than ever. With that said, the short term environment during this pandemic is challenging, but we are continuing to deliver on our mission of accelerating career transitions by leveraging the Insight network.</p><p>We’re excited to work with a new group of Insight Fellows starting in September, and help you transition careers. You can click here to <a href="https://insightfellows.com">learn more about the Insight network</a> or <a href="https://apply.insightfellows.com/"><strong>apply here</strong></a>.</p><p>More details on each of these points is below.</p><h3>Fellows First: Waiving Hiring Fees</h3><p>While the COVID-19 pandemic — and the repercussions it’s having on the hiring market — is impacting Insight and our community, we remain committed to our mission of helping Insight Fellows find thriving careers. And we are doubly committed to our core value: Fellows First.</p><p>Since 2012, the Insight core value has been to put Fellows First, and we have helped over 3,000 members of our professional network transition to new, cutting-edge fields. We have maintained a business model that tightly aligns the success of our members with the success of Insight, ensuring that the strength of our community is possible only if individual members are benefitting and can pay it forward.</p><p>Insight will continue to put our Fellows First by optimizing for their long-term career success. For example, we’ve always encouraged our Fellows to accept the best offer for their careers, even if it’s not from one of our formal hiring partners. We’re taking this even further now. Given the significant reduction in recruiting budgets (money that is used to promote and source candidates for roles), <strong>we are waiving the sponsorship fee to hire Insight Fellows for all companies</strong> for the time being. By waiving this fee, we’re removing every possible barrier to get hiring teams involved. Members of our network have stepped up over the past month and surfaced several dozens of great roles at top companies. We will continue this fee waiver into the Fall if it allows us to continue getting more opportunities for Insight Fellows.</p><h3>Membership Dues and Guarantee</h3><p>While these core principles are foundational to Insight, we need to adapt to the new reality we’re all facing. Since we can’t rely on the sponsorship fees from companies in the current economic environment, we need to raise our membership dues to $24,000 for Insight Fellows<strong> </strong>who join our community starting this September<strong>. </strong>Alternatively<strong>, </strong>for those who choose to pay via an<strong> </strong>Income Share Agreement (with no upfront costs), we will now ask Insight Fellows to <strong>share 12% of their income for 2 years</strong>.</p><p>We are also partnering with a third-party loan provider to allow Insight Fellows to take out a loan for the membership dues. In particular, those with strong US credit scores can expect interest rates between 8–9%, making this another affordable payment option without upfront costs. <em>Note: details on membership dues for Insight in Toronto, Canada to follow shortly.</em></p><p>The membership dues will continue to fund an extensive post-program experience which includes 1-on-1 coaching through the job search and numerous on-going alumni member benefits.</p><p>Regardless of the payment option, you continue to get our strong career results <strong>guarantee</strong>: you only pay if you accept a <strong>relevant job offer earning at least $100,000 per year, and receive that offer within 6 months</strong> of program completion. If you do not, we refund your membership dues (or cancel your ISA or loan), and you continue to receive all the benefits of being a member of the Insight network.</p><p>By maintaining our guarantee for each membership payment option, we are continuing to stay aligned with Insight Fellows. As always, Insight only succeeds if Insight Fellows succeed in transitioning to their new career.</p><h3>Scholarships</h3><p>One of the most difficult aspects of increasing the commitment for new members of our community is the potential impact on the access to the Insight network. Our network exists to help people from all backgrounds and economic situations advance their careers. We strive to ensure that every member of Insight has the same opportunity to be financially successful, regardless of their background when they start Insight. While these problems aren’t new, we feel that it’s important to take concrete steps given the increased membership dues.</p><p>To address this, we’re increasing the amount we offer through our need-based scholarships to new members of our community. We’re also introducing a diversity-based scholarship of up to $5,000 to help Fellows from backgrounds that have been historically underrepresented at Insight and in the tech community. We’re also organizing ways for our network of experienced members, industry partners, and team members to provide mentorship to new and potential members from underrepresented backgrounds.</p><h3>Insight Fellow Outcomes</h3><p>Insight Fellows are extremely successful in their career, both in their first role and over years of growth in their new specialization. 88% of Insight Fellows receive a relevant offer within 6 months (the median is only 8 weeks), with an average total cash compensation of over $140,000 per year. Furthermore, when you compare starting salaries by location and specialization, <strong>Insight Fellows earn </strong><a href="https://insightfellows.com/outcomes"><strong>24% more than the industry average</strong></a> (as reported by Glassdoor). Beyond the immediate outcomes following the program, the long term benefits of Insight come from the network, where strong connections lead to a career of technical growth and new opportunities. That said, earning 24% more than industry peers means joining Insight is a strong financial decision based on initial salary data alone.</p><figure><a href="https://insightfellows.com/outcomes"><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*v_pN5WJU_gdJCz-Ta7X4Rg.png" /></a><figcaption>Source: Data reported from Fellows that joined Insight since 2017, compared to corresponding market data reported on Glassdoor in May 2020</figcaption></figure><h3>Investing in our remote experience</h3><p>Since it’s unclear when it will be safe to return to Fellows collaborating closely in offices, we are investing more in our remote experience. We launched our remote program in 2015 and that experience has allowed us to successfully transition our summer session, currently in progress, to all-remote for all our locations.</p><p>The remote program has the same level of structured collaboration, mentoring, participation from advisors, and coaching as our in-person programs. As a result, the Fellows in the remote program speak highly of the social and collaborative component, building deep and life-long connections. Finally, our hiring partners are offering remote interviews and are continuing to make job offers to the current Fellows for in-person and remote roles.</p><p>Given this success, <strong>the </strong><a href="https://apply.insightfellows.com/"><strong>next session</strong></a><strong> of Insight, starting on September 14th, will run fully remotely</strong> across all our locations and programs.<strong> </strong>We’re happy that this change allows us to maintain the health and safety of our community, while maintaining the highly collaborative, network-driven experience that the Insight Fellows Programs are known for.</p><h3>Looking Ahead</h3><p>Delivering on our mission of helping Insight Fellows transition to thriving careers in cutting edge, high-impact fields is more important than ever. The strength and support of the Insight community has been nothing short of incredible and on full display in the past months as the COVID pandemic has unfolded. We are leveraging the strength of our community to deliver a phenomenal remote experience and help more Insight Fellows transition to thriving, positive, impactful careers. We’re excited to work with a new group of Insight Fellows starting in September — <a href="https://insightfellows.com">learn more about the Insight network</a> or <a href="https://apply.insightfellows.com/"><strong>apply here</strong></a>.</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=dee47d01e8d1" width="1" height="1" alt=""><hr><p><a href="https://blog.insightdatascience.com/insight-fall-updates-how-insight-is-adapting-in-2020-dee47d01e8d1">Insight Fall Updates: How Insight is adapting in 2020</a> was originally published in <a href="https://blog.insightdatascience.com">Insight</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
    </channel>
</rss>