<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Yanir Seroussi | Data science and beyond</title><link>https://yanirseroussi.com/</link><description>Recent content on Yanir Seroussi | Data science and beyond</description><generator>Hugo -- gohugo.io</generator><language>en-au</language><copyright>Text and figures licensed under [CC BY-NC-ND 4.0](https://creativecommons.org/licenses/by-nc-nd/4.0/) by [Yanir Seroussi](https://yanirseroussi.com/about/), except where noted otherwise&amp;nbsp;&amp;nbsp;|</copyright><lastBuildDate>Mon, 12 Sep 2022 02:45:00 +0000</lastBuildDate><atom:link href="https://yanirseroussi.com/index.xml" rel="self" type="application/rss+xml"/><item><title>Causal Machine Learning is off to a good start, despite some issues</title><link>https://yanirseroussi.com/2022/09/12/causal-machine-learning-book-draft-review/</link><pubDate>Mon, 12 Sep 2022 02:45:00 +0000</pubDate><guid>https://yanirseroussi.com/2022/09/12/causal-machine-learning-book-draft-review/</guid><description>Reviewing the first three chapters of the book Causal Machine Learning by Robert Osazuwa Ness.</description></item><item><title>The mission matters: Moving to climate tech as a data scientist</title><link>https://yanirseroussi.com/2022/06/06/the-mission-matters-moving-to-climate-tech-as-a-data-scientist/</link><pubDate>Mon, 06 Jun 2022 00:00:00 +0000</pubDate><guid>https://yanirseroussi.com/2022/06/06/the-mission-matters-moving-to-climate-tech-as-a-data-scientist/</guid><description>Discussing my recent career move into climate tech as a way of doing more to help mitigate dangerous climate change.</description></item><item><title>Building useful machine learning tools keeps getting easier: A fish ID case study</title><link>https://yanirseroussi.com/2022/03/20/building-useful-machine-learning-tools-keeps-getting-easier-a-fish-id-case-study/</link><pubDate>Sun, 20 Mar 2022 04:30:00 +0000</pubDate><guid>https://yanirseroussi.com/2022/03/20/building-useful-machine-learning-tools-keeps-getting-easier-a-fish-id-case-study/</guid><description>Lessons learned building a fish ID web app with fast.ai and Streamlit, in an attempt to reduce my fear of missing out on the latest deep learning developments.</description></item><item><title>Analysis strategies in online A/B experiments: Intention-to-treat, per-protocol, and other lessons from clinical trials</title><link>https://yanirseroussi.com/2022/01/14/analysis-strategies-in-online-a-b-experiments/</link><pubDate>Fri, 14 Jan 2022 00:05:40 +0000</pubDate><guid>https://yanirseroussi.com/2022/01/14/analysis-strategies-in-online-a-b-experiments/</guid><description>Epidemiologists analyse clinical trials to estimate the intention-to-treat and per-protocol effects. This post applies their strategies to online experiments.</description></item><item><title>Use your human brain to avoid artificial intelligence disasters</title><link>https://yanirseroussi.com/2021/11/22/use-your-human-brain-to-avoid-artificial-intelligence-disasters/</link><pubDate>Mon, 22 Nov 2021 03:45:00 +0000</pubDate><guid>https://yanirseroussi.com/2021/11/22/use-your-human-brain-to-avoid-artificial-intelligence-disasters/</guid><description>Overview of a talk I gave at a deep learning course, focusing on AI ethics as the need for humans to think on the context and consequences of applying AI.</description></item><item><title>Migrating from WordPress.com to Hugo on GitHub + Cloudflare</title><link>https://yanirseroussi.com/2021/11/10/migrating-from-wordpress-com-to-hugo-on-github-cloudflare/</link><pubDate>Wed, 10 Nov 2021 06:30:00 +0000</pubDate><guid>https://yanirseroussi.com/2021/11/10/migrating-from-wordpress-com-to-hugo-on-github-cloudflare/</guid><description>My reasons for switching from WordPress.com to Hugo on GitHub + Cloudflare, along with a summary of the solution components and migration process.</description></item><item><title>Some highlights from 2020</title><link>https://yanirseroussi.com/2021/04/05/some-highlights-from-2020/</link><pubDate>Mon, 05 Apr 2021 06:41:48 +0000</pubDate><guid>https://yanirseroussi.com/2021/04/05/some-highlights-from-2020/</guid><description>My track record of posting here has been pretty poor in 2020, partly because of a bunch of content I&amp;rsquo;ve contributed elsewhere. In general, my guiding principle for posting is to only add stuff I&amp;rsquo;d want to read or cite, e.g., because I haven&amp;rsquo;t seen it discussed elsewhere. Well, no one has compiled a meta-post of my public work from 2020 (that I know of), so it&amp;rsquo;s finally time to publish it myself.</description></item><item><title>Many is not enough: Counting simulations to bootstrap the right way</title><link>https://yanirseroussi.com/2020/08/24/many-is-not-enough-counting-simulations-to-bootstrap-the-right-way/</link><pubDate>Mon, 24 Aug 2020 01:35:17 +0000</pubDate><guid>https://yanirseroussi.com/2020/08/24/many-is-not-enough-counting-simulations-to-bootstrap-the-right-way/</guid><description>Previously, I encouraged readers to test different approaches to bootstrapped confidence interval (CI) estimation. Such testing can done by relying on the definition of CIs: Given an infinite number of independent samples from the same population, we expect a ci_level CI to contain the population parameter in exactly ci_level percent of the samples. Therefore, we run &amp;ldquo;many&amp;rdquo; simulations (num_simulations), where each simulation generates a random sample from the same population and runs the CI algorithm on the sample.</description></item><item><title>Software commodities are eating interesting data science work</title><link>https://yanirseroussi.com/2020/01/11/software-commodities-are-eating-interesting-data-science-work/</link><pubDate>Sat, 11 Jan 2020 09:22:35 +0000</pubDate><guid>https://yanirseroussi.com/2020/01/11/software-commodities-are-eating-interesting-data-science-work/</guid><description>The passage of time makes wizards of us all. Today, any dullard can make bells ring across the ocean by tapping out phone numbers, cause inanimate toys to march by barking an order, or activate remote devices by touching a wireless screen. Thomas Edison couldn&amp;rsquo;t have managed any of this at his peak—and shortly before his time, such powers would have been considered the unique realm of God.
Rob Reid After On Being a data scientist can sometimes feel like a race against software innovations.</description></item><item><title>A day in the life of a remote data scientist</title><link>https://yanirseroussi.com/2019/12/12/a-day-in-the-life-of-a-remote-data-scientist/</link><pubDate>Wed, 11 Dec 2019 22:06:19 +0000</pubDate><guid>https://yanirseroussi.com/2019/12/12/a-day-in-the-life-of-a-remote-data-scientist/</guid><description>Earlier this year, I gave a talk titled A Day in the Life of a Remote Data Scientist at the Data Science Sydney meetup. The talk covered similar ground to a post I published on remote data science work, with additional details on my daily schedule and projects, some gifs and Sydney jokes, heckling by the audience, and a Q&amp;amp;A session. I managed to watch it a few months ago without cringing too much, so it&amp;rsquo;s about time to post it here.</description></item><item><title>Bootstrapping the right way?</title><link>https://yanirseroussi.com/2019/10/06/bootstrapping-the-right-way/</link><pubDate>Sun, 06 Oct 2019 06:48:07 +0000</pubDate><guid>https://yanirseroussi.com/2019/10/06/bootstrapping-the-right-way/</guid><description>Bootstrapping the right way is a talk I gave earlier this year at the YOW! Data conference in Sydney. You can now watch the video of the talk and have a look through the slides. The content of the talk is similar to a post I published on bootstrapping pitfalls, with some additional simulations.
The main takeaways shared in the talk are:
Don&amp;rsquo;t compare single-sample confidence intervals by eye Use enough resamples (15K?</description></item><item><title>How to Increase Retention and Revenue in 1,000 Nontrivial Steps</title><link>https://yanirseroussi.com/2019/02/05/how-to-increase-retention-and-revenue-in-1000-nontrivial-steps/</link><pubDate>Tue, 05 Feb 2019 00:20:35 +0000</pubDate><guid>https://yanirseroussi.com/2019/02/05/how-to-increase-retention-and-revenue-in-1000-nontrivial-steps/</guid><description>One of the main projects I worked on last year.
Recently, Automattic created a Marketing Data team to support marketing efforts with dedicated data capabilities. As we got started, one important question loomed for me and my teammate Demet Dagdelen: What should we data scientists do as part of this team&amp;hellip;?
Read more on data.blog</description></item><item><title>Hackers beware: Bootstrap sampling may be harmful</title><link>https://yanirseroussi.com/2019/01/08/hackers-beware-bootstrap-sampling-may-be-harmful/</link><pubDate>Mon, 07 Jan 2019 21:07:56 +0000</pubDate><guid>https://yanirseroussi.com/2019/01/08/hackers-beware-bootstrap-sampling-may-be-harmful/</guid><description>Bootstrap sampling techniques are very appealing, as they don&amp;rsquo;t require knowing much about statistics and opaque formulas. Instead, all one needs to do is resample the given data many times, and calculate the desired statistics. Therefore, bootstrapping has been promoted as an easy way of modelling uncertainty to hackers who don&amp;rsquo;t have much statistical knowledge. For example, the main thesis of the excellent Statistics for Hackers talk by Jake VanderPlas is: &amp;ldquo;If you can write a for-loop, you can do statistics&amp;rdquo;.</description></item><item><title>The most practical causal inference book I’ve read (is still a draft)</title><link>https://yanirseroussi.com/2018/12/24/the-most-practical-causal-inference-book-ive-read-is-still-a-draft/</link><pubDate>Mon, 24 Dec 2018 02:37:50 +0000</pubDate><guid>https://yanirseroussi.com/2018/12/24/the-most-practical-causal-inference-book-ive-read-is-still-a-draft/</guid><description>I&amp;rsquo;ve been interested in the area of causal inference in the past few years. In my opinion it&amp;rsquo;s more exciting and relevant to everyday life than more hyped data science areas like deep learning. However, I&amp;rsquo;ve found it hard to apply what I&amp;rsquo;ve learned about causal inference to my work. Now, I believe I&amp;rsquo;ve finally found a book with practical techniques that I can use on real problems: Causal Inference by Miguel Hernán and Jamie Robins.</description></item><item><title>Introducing pipe, The Automattic Machine Learning Pipeline</title><link>https://yanirseroussi.com/2018/11/20/introducing-pipe-the-automattic-machine-learning-pipeline/</link><pubDate>Tue, 20 Nov 2018 07:19:01 +0000</pubDate><guid>https://yanirseroussi.com/2018/11/20/introducing-pipe-the-automattic-machine-learning-pipeline/</guid><description>One of the main projects I&amp;rsquo;ve been working on over the past year.
A generalized machine learning pipeline, pipe serves the entire company and helps Automatticians seamlessly build and deploy machine learning models to predict the likelihood that a given event may occur, e.g., installing a plugin, purchasing a plan, or churning&amp;hellip;
Read more on data.blog</description></item><item><title>Reflections on remote data science work</title><link>https://yanirseroussi.com/2018/11/03/reflections-on-remote-data-science-work/</link><pubDate>Sat, 03 Nov 2018 06:33:13 +0000</pubDate><guid>https://yanirseroussi.com/2018/11/03/reflections-on-remote-data-science-work/</guid><description>It&amp;rsquo;s been about a year and a half since I joined Automattic as a remote data scientist. This is the longest I&amp;rsquo;ve been in one position since finishing my PhD in 2012. This is also the first time I&amp;rsquo;ve worked full-time with a fully-distributed team. In this post, I briefly discuss some of the top pluses and minuses of remote work, based on my experience so far.
+ Flexible hours</description></item><item><title>Defining data science in 2018</title><link>https://yanirseroussi.com/2018/07/22/defining-data-science-in-2018/</link><pubDate>Sun, 22 Jul 2018 08:27:43 +0000</pubDate><guid>https://yanirseroussi.com/2018/07/22/defining-data-science-in-2018/</guid><description>I got my first data science job in 2012, the year Harvard Business Review announced data scientist to be the sexiest job of the 21st century. Two years later, I published a post on my then-favourite definition of data science, as the intersection between software engineering and statistics. Unfortunately, that definition became somewhat irrelevant as more and more people jumped on the data science bandwagon – possibly to the point of making data scientist useless as a job title.</description></item><item><title>Engineering Data Science at Automattic</title><link>https://yanirseroussi.com/2018/03/21/engineering-data-science-at-automattic/</link><pubDate>Tue, 20 Mar 2018 21:01:39 +0000</pubDate><guid>https://yanirseroussi.com/2018/03/21/engineering-data-science-at-automattic/</guid><description>A post I&amp;rsquo;ve written on applying some software engineering best practices to data science projects:
Most data scientists have to write code to analyze data or build products. While coding, data scientists act as software engineers. Adopting best practices from software engineering is key to ensuring the correctness, reproducibility, and maintainability of data science projects. This post describes some of our efforts in the area&amp;hellip;
Read more on data.blog</description></item><item><title>Advice for aspiring data scientists and other FAQs</title><link>https://yanirseroussi.com/faq/</link><pubDate>Sun, 15 Oct 2017 09:15:25 +0000</pubDate><guid>https://yanirseroussi.com/faq/</guid><description>Aspiring data scientists and other visitors to this site often repeat the same questions. This post is the definitive collection of my answers to such questions (which may evolve over time).
How do I become a data scientist?
It depends on your situation. Before we get into it, have you thought about why you want to become a data scientist? Hmm&amp;hellip; Not really. Why should I become a data scientist?</description></item><item><title>State of Bandcamp Recommender, Late 2017</title><link>https://yanirseroussi.com/state-of-bandcamp-recommender-september-2017/</link><pubDate>Sat, 02 Sep 2017 10:19:02 +0000</pubDate><guid>https://yanirseroussi.com/state-of-bandcamp-recommender-september-2017/</guid><description>November 2017: Update and goodbye I&amp;rsquo;ve decided to shut down Bandcamp Recommender (BCRecommender), despite hearing back from a few volunteers. The main reasons are:
Bandcamp now shows album recommendations at the bottom of album pages. While this isn&amp;rsquo;t quite the same as BCRecommender, I hope that it will evolve to a more comprehensive recommender system. I tried to contact Bandcamp to get their support for the continued running of BCRecommender. I have not heard back from them.</description></item><item><title>My 10-step path to becoming a remote data scientist with Automattic</title><link>https://yanirseroussi.com/2017/07/29/my-10-step-path-to-becoming-a-remote-data-scientist-with-automattic/</link><pubDate>Sat, 29 Jul 2017 05:39:26 +0000</pubDate><guid>https://yanirseroussi.com/2017/07/29/my-10-step-path-to-becoming-a-remote-data-scientist-with-automattic/</guid><description>About two years ago, I read the book The Year without Pants, which describes the author&amp;rsquo;s experience leading a team at Automattic (the company behind WordPress.com, among other products). Automattic is a fully-distributed company, which means that all of its employees work remotely (hence pants are optional). While the book discusses some of the challenges of working remotely, the author&amp;rsquo;s general experience was very positive. A few months after reading the book, I decided to look for a full-time position after a period of independent work.</description></item><item><title>Exploring and visualising reef life survey data</title><link>https://yanirseroussi.com/2017/06/03/exploring-and-visualising-reef-life-survey-data/</link><pubDate>Sat, 03 Jun 2017 00:49:05 +0000</pubDate><guid>https://yanirseroussi.com/2017/06/03/exploring-and-visualising-reef-life-survey-data/</guid><description>Last year, I wrote about the Reef Life Survey (RLS) project and my experience with offline data collection on the Great Barrier Reef. I found that using auto-generated flashcards with an increasing level of difficulty is a good way to memorise marine species. Since publishing that post, I have improved the flashcards and built a tool for exploring the aggregate survey data. Both tools are now publicly available on the RLS website.</description></item><item><title>Customer lifetime value and the proliferation of misinformation on the internet</title><link>https://yanirseroussi.com/2017/01/08/customer-lifetime-value-and-the-proliferation-of-misinformation-on-the-internet/</link><pubDate>Sun, 08 Jan 2017 20:02:30 +0000</pubDate><guid>https://yanirseroussi.com/2017/01/08/customer-lifetime-value-and-the-proliferation-of-misinformation-on-the-internet/</guid><description>Suppose you work for a business that has paying customers. You want to know how much money your customers are likely to spend to inform decisions on customer acquisition and retention budgets. You&amp;rsquo;ve done a bit of research, and discovered that the figure you want to calculate is commonly called the customer lifetime value. You google the term, and end up on a page with ten results (and probably some ads).</description></item><item><title>Ask Why! Finding motives, causes, and purpose in data science</title><link>https://yanirseroussi.com/2016/09/19/ask-why-finding-motives-causes-and-purpose-in-data-science/</link><pubDate>Mon, 19 Sep 2016 21:28:44 +0000</pubDate><guid>https://yanirseroussi.com/2016/09/19/ask-why-finding-motives-causes-and-purpose-in-data-science/</guid><description>Some people equate predictive modelling with data science, thinking that mastering various machine learning techniques is the key that unlocks the mysteries of the field. However, there is much more to data science than the What and How of predictive modelling. I recently gave a talk where I argued the importance of asking Why, touching on three different topics: stakeholder motives, cause-and-effect relationships, and finding a sense of purpose. A video of the talk is available below.</description></item><item><title>If you don’t pay attention, data can drive you off a cliff</title><link>https://yanirseroussi.com/2016/08/21/seven-ways-to-be-data-driven-off-a-cliff/</link><pubDate>Sun, 21 Aug 2016 21:34:17 +0000</pubDate><guid>https://yanirseroussi.com/2016/08/21/seven-ways-to-be-data-driven-off-a-cliff/</guid><description>You&amp;rsquo;re a hotshot manager. You love your dashboards and you keep your finger on the beating pulse of the business. You take pride in using data to drive your decisions rather than shooting from the hip like one of those old-school 1950s bosses. This is the 21st century, and data is king. You even hired a sexy statistician or data scientist, though you don&amp;rsquo;t really understand what they do. Never mind, you can proudly tell all your friends that you are leading a modern data-driven team.</description></item><item><title>Is Data Scientist a useless job title?</title><link>https://yanirseroussi.com/2016/08/04/is-data-scientist-a-useless-job-title/</link><pubDate>Thu, 04 Aug 2016 22:26:03 +0000</pubDate><guid>https://yanirseroussi.com/2016/08/04/is-data-scientist-a-useless-job-title/</guid><description>Data science can be defined as either the intersection or union of software engineering and statistics. In recent years, the field seems to be gravitating towards the broader unifying definition, where everyone who touches data in some way can call themselves a data scientist. Hence, while many people whose job title is Data Scientist do very useful work, the title itself has become fairly useless as an indication of what the title holder actually does.</description></item><item><title>Making Bayesian A/B testing more accessible</title><link>https://yanirseroussi.com/2016/06/19/making-bayesian-ab-testing-more-accessible/</link><pubDate>Sun, 19 Jun 2016 10:32:15 +0000</pubDate><guid>https://yanirseroussi.com/2016/06/19/making-bayesian-ab-testing-more-accessible/</guid><description>Much has been written in recent years on the pitfalls of using traditional hypothesis testing with online A/B tests. A key issue is that you&amp;rsquo;re likely to end up with many false positives if you repeatedly check your results and stop as soon as you reach statistical significance. One way of dealing with this issue is by following a Bayesian approach to deciding when the experiment should be stopped. While I find the Bayesian view of statistics much more intuitive than the frequentist view, it can be quite challenging to explain Bayesian concepts to laypeople.</description></item><item><title>Diving deeper into causality: Pearl, Kleinberg, Hill, and untested assumptions</title><link>https://yanirseroussi.com/2016/05/15/diving-deeper-into-causality-pearl-kleinberg-hill-and-untested-assumptions/</link><pubDate>Sat, 14 May 2016 19:57:03 +0000</pubDate><guid>https://yanirseroussi.com/2016/05/15/diving-deeper-into-causality-pearl-kleinberg-hill-and-untested-assumptions/</guid><description>Background: I have previously written about the need for real insights that address the why behind events, not only the what and how. This was followed by a fairly popular post on causality, which was heavily influenced by Samantha Kleinberg's book Why: A Guide to Finding and Using Causes. This post continues my exploration of the field, and is primarily based on Kleinberg's previous book: Causality, Probability, and Time.
The study of causality and causal inference is central to science in general and data science in particular.</description></item><item><title>The rise of greedy robots</title><link>https://yanirseroussi.com/2016/03/20/the-rise-of-greedy-robots/</link><pubDate>Sun, 20 Mar 2016 20:33:43 +0000</pubDate><guid>https://yanirseroussi.com/2016/03/20/the-rise-of-greedy-robots/</guid><description>Given the impressive advancement of machine intelligence in recent years, many people have been speculating on what the future holds when it comes to the power and roles of robots in our society. Some have even called for regulation of machine intelligence before it&amp;rsquo;s too late. My take on this issue is that there is no need to speculate – machine intelligence is already here, with greedy robots already dominating our lives.</description></item><item><title>Why you should stop worrying about deep learning and deepen your understanding of causality instead</title><link>https://yanirseroussi.com/2016/02/14/why-you-should-stop-worrying-about-deep-learning-and-deepen-your-understanding-of-causality-instead/</link><pubDate>Sun, 14 Feb 2016 11:04:11 +0000</pubDate><guid>https://yanirseroussi.com/2016/02/14/why-you-should-stop-worrying-about-deep-learning-and-deepen-your-understanding-of-causality-instead/</guid><description>Everywhere you go these days, you hear about deep learning&amp;rsquo;s impressive advancements. New deep learning libraries, tools, and products get announced on a regular basis, making the average data scientist feel like they&amp;rsquo;re missing out if they don&amp;rsquo;t hop on the deep learning bandwagon. However, as Kamil Bartocha put it in his post The Inconvenient Truth About Data Science, 95% of tasks do not require deep learning. This is obviously a made up number, but it&amp;rsquo;s probably an accurate representation of the everyday reality of many data scientists.</description></item><item><title>The joys of offline data collection</title><link>https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/</link><pubDate>Sun, 24 Jan 2016 00:32:25 +0000</pubDate><guid>https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/</guid><description>Many modern data scientists don&amp;rsquo;t get to experience data collection in the offline world. Recently, I spent a month sailing down the northern Great Barrier Reef, collecting data for the Reef Life Survey project. In addition to being a great diving experience, the trip helped me obtain general insights on data collection and machine learning, which are shared in this article.
The Reef Life Survey project Reef Life Survey (RLS) is a citizen scientist project, led by a team from the University of Tasmania.</description></item><item><title>This holiday season, give me real insights</title><link>https://yanirseroussi.com/2015/12/08/this-holiday-season-give-me-real-insights/</link><pubDate>Tue, 08 Dec 2015 06:57:25 +0000</pubDate><guid>https://yanirseroussi.com/2015/12/08/this-holiday-season-give-me-real-insights/</guid><description>Merriam-Webster defines an insight as an understanding of the true nature of something. Many companies seem to define an insight as any piece of data or information, which I would call a pseudo-insight. This post surveys some examples of pseudo-insights, and discusses how these can be built upon to provide real insights.
Exhibit A: WordPress stats This website is hosted on wordpress.com. I&amp;rsquo;m generally happy with WordPress – though it&amp;rsquo;s not as exciting and shiny as newer competitors, it is rock-solid and very feature-rich.</description></item><item><title>The hardest parts of data science</title><link>https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/</link><pubDate>Mon, 23 Nov 2015 04:14:21 +0000</pubDate><guid>https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/</guid><description>Contrary to common belief, the hardest part of data science isn&amp;rsquo;t building an accurate model or obtaining good, clean data. It is much harder to define feasible problems and come up with reasonable ways of measuring solutions. This post discusses some examples of these issues and how they can be addressed.
The not-so-hard parts Before discussing the hardest parts of data science, it&amp;rsquo;s worth quickly addressing the two main contenders: model fitting and data collection/cleaning.</description></item><item><title>Migrating a simple web application from MongoDB to Elasticsearch</title><link>https://yanirseroussi.com/2015/11/04/migrating-a-simple-web-application-from-mongodb-to-elasticsearch/</link><pubDate>Wed, 04 Nov 2015 03:53:18 +0000</pubDate><guid>https://yanirseroussi.com/2015/11/04/migrating-a-simple-web-application-from-mongodb-to-elasticsearch/</guid><description>Bandcamp Recommender (BCRecommender) is a web application that serves music recommendations from Bandcamp. I recently switched BCRecommender&amp;rsquo;s data store from MongoDB to Elasticsearch. This has made it possible to offer a richer search experience to users at a similar cost. This post describes the migration process and discusses some of the advantages and disadvantages of using Elasticsearch instead of MongoDB.
Motivation: Why swap MongoDB for Elasticsearch? I&amp;rsquo;ve written a few posts in the past on BCRecommender&amp;rsquo;s design and implementation.</description></item><item><title>Miscommunicating science: Simplistic models, nutritionism, and the art of storytelling</title><link>https://yanirseroussi.com/2015/10/19/nutritionism-and-the-need-for-complex-models-to-explain-complex-phenomena/</link><pubDate>Mon, 19 Oct 2015 00:02:32 +0000</pubDate><guid>https://yanirseroussi.com/2015/10/19/nutritionism-and-the-need-for-complex-models-to-explain-complex-phenomena/</guid><description>I recently finished reading the book In Defense of Food: An Eater&amp;rsquo;s Manifesto by Michael Pollan. The book criticises nutritionism – the idea that one should eat according to the sum of measured nutrients while ignoring the food that contains these nutrients. The key argument of the book is that since the knowledge derived using food science is still very limited, completely relying on the partial findings and tools provided by this science is likely to lead to health issues.</description></item><item><title>The wonderful world of recommender systems</title><link>https://yanirseroussi.com/2015/10/02/the-wonderful-world-of-recommender-systems/</link><pubDate>Fri, 02 Oct 2015 05:25:57 +0000</pubDate><guid>https://yanirseroussi.com/2015/10/02/the-wonderful-world-of-recommender-systems/</guid><description>I recently gave a talk about recommender systems at the Data Science Sydney meetup (the slides are available here). This post roughly follows the outline of the talk, expanding on some of the key points in non-slide form (i.e., complete sentences and paragraphs!). The first few sections give a broad overview of the field and the common recommendation paradigms, while the final part is dedicated to debunking five common myths about recommender systems.</description></item><item><title>You don’t need a data scientist (yet)</title><link>https://yanirseroussi.com/2015/08/24/you-dont-need-a-data-scientist-yet/</link><pubDate>Mon, 24 Aug 2015 08:25:30 +0000</pubDate><guid>https://yanirseroussi.com/2015/08/24/you-dont-need-a-data-scientist-yet/</guid><description>The hype around big data has caused many organisations to hire data scientists without giving much thought to what these data scientists are going to do and whether they&amp;rsquo;re actually needed. This is a source of frustration for all parties involved. This post discusses some questions you should ask yourself before deciding to hire your first data scientist.
Q1: Do you know what data scientists do? Somewhat surprisingly, there are quite a few companies that hire data scientists without having a clear idea of what data scientists actually do.</description></item><item><title>Goodbye, Parse.com</title><link>https://yanirseroussi.com/2015/07/31/goodbye-parse-com/</link><pubDate>Fri, 31 Jul 2015 03:29:50 +0000</pubDate><guid>https://yanirseroussi.com/2015/07/31/goodbye-parse-com/</guid><description>Over the past year, I&amp;rsquo;ve been using Parse‘s free backend-as-a-service and web hosting to serve BCRecommender (music recommendation service) and Price Dingo (now-closed shopping comparison engine). The main lesson: You get what you pay for. Despite some improvements, Parse remains very unreliable, and any time saved by using their APIs and SDKs tends to be offset by having to work around the restrictions of their sandboxed environment. This post details some of the issues I faced and the transition away from the service.</description></item><item><title>Learning about deep learning through album cover classification</title><link>https://yanirseroussi.com/2015/07/06/learning-about-deep-learning-through-album-cover-classification/</link><pubDate>Mon, 06 Jul 2015 22:21:42 +0000</pubDate><guid>https://yanirseroussi.com/2015/07/06/learning-about-deep-learning-through-album-cover-classification/</guid><description>In the past month, I&amp;rsquo;ve spent some time on my album cover classification project. The goal of this project is for me to learn about deep learning by working on an actual problem. This post covers my progress so far, highlighting lessons that would be useful to others who are getting started with deep learning.
Initial steps summary The following points were discussed in detail in the previous post on this project.</description></item><item><title>Deep learning resources</title><link>https://yanirseroussi.com/deep-learning-resources/</link><pubDate>Mon, 06 Jul 2015 00:38:44 +0000</pubDate><guid>https://yanirseroussi.com/deep-learning-resources/</guid><description>This page summarises the deep learning resources I&amp;rsquo;ve consulted in my album cover classification project.
Tutorials and blog posts Convolutional Neural Networks for Visual Recognition Stanford course notes: an excellent resource, very up-to-date and useful, despite still being a work in progress DeepLearning.net&amp;rsquo;s Theano-based tutorials: not as up-to-date as the Stanford course notes, but still a good introduction to some of the theory and general Theano usage Lasagne&amp;rsquo;s documentation and tutorials: still a bit lacking, but good when you know what you&amp;rsquo;re looking for lasagne4newbs: Lasagne&amp;rsquo;s convnet example with richer comments Using convolutional neural nets to detect facial keypoints tutorial: the resource that made me want to use Lasagne Classifying plankton with deep neural networks: an epic post, which I found while looking for Lasagne examples Various Wikipedia pages: a bit disappointing – the above resources are much better Papers Adam: a method for stochastic optimization (Kingma and Ba, 2015): an improvement over SGD with Nesterov momentum, AdaGrad and RMSProp, which I found to be useful in practice Algorithms for Hyper-Parameter Optimization (Bergstra et al.</description></item><item><title>Hopping on the deep learning bandwagon</title><link>https://yanirseroussi.com/2015/06/06/hopping-on-the-deep-learning-bandwagon/</link><pubDate>Sat, 06 Jun 2015 05:00:22 +0000</pubDate><guid>https://yanirseroussi.com/2015/06/06/hopping-on-the-deep-learning-bandwagon/</guid><description>I&amp;rsquo;ve been meaning to get into deep learning for the last few years. Now, the stars having finally aligned and I have the time and motivation to work on a small project that will hopefully improve my understanding of the field. This is the first in a series of posts that will document my progress on this project.
As mentioned in a previous post on getting started as a data scientist, I believe that the best way of becoming proficient at solving data science problems is by getting your hands dirty.</description></item><item><title>First steps in data science: author-aware sentiment analysis</title><link>https://yanirseroussi.com/2015/05/02/first-steps-in-data-science-author-aware-sentiment-analysis/</link><pubDate>Sat, 02 May 2015 08:31:10 +0000</pubDate><guid>https://yanirseroussi.com/2015/05/02/first-steps-in-data-science-author-aware-sentiment-analysis/</guid><description>People often ask me what&amp;rsquo;s the best way of becoming a data scientist. The way I got there was by first becoming a software engineer and then doing a PhD in what was essentially data science (before it became such a popular term). This post describes my first steps in the field with the goal of helping others who are interested in making the transition from pure software engineering to data science.</description></item><item><title>My divestment from fossil fuels</title><link>https://yanirseroussi.com/2015/04/24/my-divestment-from-fossil-fuels/</link><pubDate>Fri, 24 Apr 2015 00:19:36 +0000</pubDate><guid>https://yanirseroussi.com/2015/04/24/my-divestment-from-fossil-fuels/</guid><description>This post covers recent choices I've made to reduce my exposure to fossil fuels, including practical steps that can be taken by Australians and generally applicable lessons. I recently read Naomi Klein&amp;rsquo;s This Changes Everything, which deeply influenced me. The book describes how the world has been dragging its feet when it comes to reducing carbon emissions, and how we are coming very close to a point where climate change is likely to spin out of control.</description></item><item><title>Research</title><link>https://yanirseroussi.com/phd-work/</link><pubDate>Mon, 30 Mar 2015 03:23:33 +0000</pubDate><guid>https://yanirseroussi.com/phd-work/</guid><description>I did my PhD at Monash University under the supervision of Ingrid Zukerman and Fabian Bohnert. I started in March 2009 and submitted my thesis in August 2012. When excluding time spent on conference trips and three months of an internship with Google, it took about three years of work to complete the PhD, which is not too bad for a 100% research program (no coursework was required at the time).</description></item><item><title>The long road to a lifestyle business</title><link>https://yanirseroussi.com/2015/03/22/the-long-road-to-a-lifestyle-business/</link><pubDate>Sun, 22 Mar 2015 09:43:47 +0000</pubDate><guid>https://yanirseroussi.com/2015/03/22/the-long-road-to-a-lifestyle-business/</guid><description>Almost a year ago, I left my last full-time job and decided to set on an independent path that includes data science consulting and work on my own projects. The ultimate goal is not to have to sell my time for money by generating enough passive income to live comfortably. My five main areas of focus are – in no particular order – personal branding &amp;amp; networking, data science contracting, Bandcamp Recommender, Price Dingo, and marine conservation.</description></item><item><title>Learning to rank for personalised search (Yandex Search Personalisation – Kaggle Competition Summary – Part 2)</title><link>https://yanirseroussi.com/2015/02/11/learning-to-rank-for-personalised-search-yandex-search-personalisation-kaggle-competition-summary-part-2/</link><pubDate>Wed, 11 Feb 2015 06:34:17 +0000</pubDate><guid>https://yanirseroussi.com/2015/02/11/learning-to-rank-for-personalised-search-yandex-search-personalisation-kaggle-competition-summary-part-2/</guid><description>This is the second and last post summarising my team&amp;rsquo;s solution for the Yandex search personalisation Kaggle competition. See the first post for a summary of the dataset, evaluation approach, and some thoughts about search engine optimisation and privacy. This post discusses the algorithms and features we used.
To quickly recap the first post, Yandex released a 16GB dataset of query &amp;amp; click logs. The goal of the competition was to use this data to rerank query results such that the more relevant results appear before less relevant results.</description></item><item><title>Is thinking like a search engine possible? (Yandex search personalisation – Kaggle competition summary – part 1)</title><link>https://yanirseroussi.com/2015/01/29/is-thinking-like-a-search-engine-possible-yandex-search-personalisation-kaggle-competition-summary-part-1/</link><pubDate>Thu, 29 Jan 2015 10:37:39 +0000</pubDate><guid>https://yanirseroussi.com/2015/01/29/is-thinking-like-a-search-engine-possible-yandex-search-personalisation-kaggle-competition-summary-part-1/</guid><description>About a year ago, I participated in the Yandex search personalisation Kaggle competition. I started off as a solo competitor, and then added a few Kaggle newbies to the team as part of a program I was running for the Sydney Data Science Meetup. My team hasn&amp;rsquo;t done too badly, finishing 9th out of 194 teams. As is usually the case with Kaggle competitions, the most valuable part was the lessons learned from the experience.</description></item><item><title>Automating Parse.com bulk data imports</title><link>https://yanirseroussi.com/2015/01/15/automating-parse-com-bulk-data-imports/</link><pubDate>Thu, 15 Jan 2015 04:41:16 +0000</pubDate><guid>https://yanirseroussi.com/2015/01/15/automating-parse-com-bulk-data-imports/</guid><description>Parse is a great backend-as-a-service (BaaS) product. It removes much of the hassle involved in backend devops with its web hosting service, SDKs for all the major mobile platforms, and a generous free tier. Parse does have its share of flaws, including various reliability issues (which seem to be getting rarer), and limitations on what you can do (which is reasonable price to pay for working within a sandboxed environment). One such limitation is the lack of APIs to perform bulk data imports.</description></item><item><title>Stochastic Gradient Boosting: Choosing the Best Number of Iterations</title><link>https://yanirseroussi.com/2014/12/29/stochastic-gradient-boosting-choosing-the-best-number-of-iterations/</link><pubDate>Mon, 29 Dec 2014 02:30:06 +0000</pubDate><guid>https://yanirseroussi.com/2014/12/29/stochastic-gradient-boosting-choosing-the-best-number-of-iterations/</guid><description>In my summary of the Kaggle bulldozer price forecasting competition, I mentioned that part of my solution was based on stochastic gradient boosting. To reduce runtime, the number of boosting iterations was set by minimising the loss on the out-of-bag (OOB) samples, skipping trees where samples are in-bag. This approach was motivated by a bug in scikit-learn, where the OOB loss estimate was calculated on the in-bag samples, meaning that it always improved (and thus was useless for the purpose of setting the number of iterations).</description></item><item><title>SEO: Mostly about showing up?</title><link>https://yanirseroussi.com/2014/12/15/seo-mostly-about-showing-up/</link><pubDate>Mon, 15 Dec 2014 04:25:25 +0000</pubDate><guid>https://yanirseroussi.com/2014/12/15/seo-mostly-about-showing-up/</guid><description>In previous posts about getting traction for my Bandcamp recommendations project (BCRecommender), I mentioned search engine optimisation (SEO) as one of the promising traction channels. Unfortunately, early efforts yielded negligible traffic – most new visitors came from referrals from blogs and Twitter. It turns out that the problem was not showing up for the SEO game: most of BCRecommender&amp;rsquo;s pages were blocked for crawling via robots.txt because I was worried that search engines (=Google) would penalise the website for thin/duplicate content.</description></item><item><title>Fitting noise: Forecasting the sale price of bulldozers (Kaggle competition summary)</title><link>https://yanirseroussi.com/2014/11/19/fitting-noise-forecasting-the-sale-price-of-bulldozers-kaggle-competition-summary/</link><pubDate>Wed, 19 Nov 2014 09:17:34 +0000</pubDate><guid>https://yanirseroussi.com/2014/11/19/fitting-noise-forecasting-the-sale-price-of-bulldozers-kaggle-competition-summary/</guid><description>Messy data, buggy software, but all in all a good learning experience...
Early last year, I had some free time on my hands, so I decided to participate in yet another Kaggle competition. Having never done any price forecasting work before, I thought it would be interesting to work on the Blue Book for Bulldozers competition, where the goal was to predict the sale price of auctioned bulldozers. I&amp;rsquo;ve done alright, finishing 9th out of 476 teams.</description></item><item><title>BCRecommender Traction Update</title><link>https://yanirseroussi.com/2014/11/05/bcrecommender-traction-update/</link><pubDate>Wed, 05 Nov 2014 02:29:35 +0000</pubDate><guid>https://yanirseroussi.com/2014/11/05/bcrecommender-traction-update/</guid><description>This is the fifth part of a series of posts on my Bandcamp recommendations (BCRecommender) project. Check out previous posts on the general motivation behind this project, the system’s architecture, the recommendation algorithms, and initial traction planning. In a previous post, I discussed my plans to apply the Bullseye framework from the Traction Book to BCRecommender, my Bandcamp recommendations project. In that post, I reviewed the 19 traction channels described in the book, and decided to focus on the three most promising ones: blogger outreach, search engine optimisation (SEO), and content marketing.</description></item><item><title>What is data science?</title><link>https://yanirseroussi.com/2014/10/23/what-is-data-science/</link><pubDate>Thu, 23 Oct 2014 03:22:08 +0000</pubDate><guid>https://yanirseroussi.com/2014/10/23/what-is-data-science/</guid><description>Data science has been a hot term in the past few years. Despite this fact (or perhaps because of it), it still seems like there isn't a single unifying definition of data science. This post discusses my favourite definition.
Data Scientist (n.): Person who is better at statistics than any software engineer and better at software engineering than any statistician.
— Josh Wills (@josh_wills) May 3, 2012
One of my reasons for doing a PhD was wanting to do something more interesting than &amp;ldquo;vanilla&amp;rdquo; software engineering.</description></item><item><title>Greek Media Monitoring Kaggle competition: My approach</title><link>https://yanirseroussi.com/2014/10/07/greek-media-monitoring-kaggle-competition-my-approach/</link><pubDate>Tue, 07 Oct 2014 03:21:35 +0000</pubDate><guid>https://yanirseroussi.com/2014/10/07/greek-media-monitoring-kaggle-competition-my-approach/</guid><description>A few months ago I participated in the Kaggle Greek Media Monitoring competition. The goal of the competition was doing multilabel classification of texts scanned from Greek print media. Despite not having much time due to travelling and other commitments, I managed to finish 6th (out of 120 teams). This post describes my approach to the problem.
Data &amp;amp; evaluation The data consists of articles scanned from Greek print media in May-September 2013.</description></item><item><title>Applying the Traction Book’s Bullseye framework to BCRecommender</title><link>https://yanirseroussi.com/2014/09/24/applying-the-traction-books-bullseye-framework-to-bcrecommender/</link><pubDate>Wed, 24 Sep 2014 04:57:39 +0000</pubDate><guid>https://yanirseroussi.com/2014/09/24/applying-the-traction-books-bullseye-framework-to-bcrecommender/</guid><description>This is the fourth part of a series of posts on my Bandcamp recommendations (BCRecommender) project. Check out previous posts on the general motivation behind this project, the system's architecture, and the recommendation algorithms. Having used BCRecommender to find music I like, I&amp;rsquo;m certain that other Bandcamp fans would like it too. It could probably be extended to attract a wider audience of music lovers, but for now, just getting feedback from Bandcamp fans would be enough.</description></item><item><title>Bandcamp recommendation and discovery algorithms</title><link>https://yanirseroussi.com/2014/09/19/bandcamp-recommendation-and-discovery-algorithms/</link><pubDate>Fri, 19 Sep 2014 14:26:55 +0000</pubDate><guid>https://yanirseroussi.com/2014/09/19/bandcamp-recommendation-and-discovery-algorithms/</guid><description>This is the third part of a series of posts on my Bandcamp recommendations (BCRecommender) project. Check out the first part for the general motivation behind this project and the second part for the system architecture. The main goal of the BCRecommender project is to help me find music I like. This post discusses the algorithmic approaches I took towards that goal. I&amp;rsquo;ve kept the descriptions at a fairly high-level, without getting too much into the maths, as all recommendation algorithms essentially try to model simple intuition.</description></item><item><title>Building a recommender system on a shoestring budget (or: BCRecommender part 2 – general system layout)</title><link>https://yanirseroussi.com/2014/09/07/building-a-recommender-system-on-a-shoestring-budget/</link><pubDate>Sun, 07 Sep 2014 10:48:44 +0000</pubDate><guid>https://yanirseroussi.com/2014/09/07/building-a-recommender-system-on-a-shoestring-budget/</guid><description>This is the second part of a series of posts on my BCRecommender – personalised Bandcamp recommendations project. Check out the first part for the general motivation behind this project.
BCRecommender is a hobby project whose main goal is to help me find music I like on Bandcamp. Its secondary goal is to serve as a testing ground for ideas I have and things I&amp;rsquo;d like to explore.
One question I&amp;rsquo;ve been wondering about is: how much money does one need to spend on infrastructure for a simple web-based product before it reaches meaningful traffic?</description></item><item><title>Building a Bandcamp recommender system (part 1 – motivation)</title><link>https://yanirseroussi.com/2014/08/30/building-a-bandcamp-recommender-system-part-1-motivation/</link><pubDate>Sat, 30 Aug 2014 08:11:38 +0000</pubDate><guid>https://yanirseroussi.com/2014/08/30/building-a-bandcamp-recommender-system-part-1-motivation/</guid><description>I&amp;rsquo;ve been a Bandcamp user for a few years now. I love the fact that they pay out a significant share of the revenue directly to the artists, unlike other services. In addition, despite the fact that fans may stream all the music for free and even easily rip it, almost $80M were paid out to artists through Bandcamp to date (including almost $3M in the last month) – serving as strong evidence that the traditional music industry&amp;rsquo;s fight against piracy is a waste of resources and time.</description></item><item><title>How to (almost) win Kaggle competitions</title><link>https://yanirseroussi.com/2014/08/24/how-to-almost-win-kaggle-competitions/</link><pubDate>Sun, 24 Aug 2014 12:40:53 +0000</pubDate><guid>https://yanirseroussi.com/2014/08/24/how-to-almost-win-kaggle-competitions/</guid><description>Last week, I gave a talk at the Data Science Sydney Meetup group about some of the lessons I learned through almost winning five Kaggle competitions. The core of the talk was ten tips, which I think are worth putting in a post (the original slides are here). Some of these tips were covered in my beginner tips post from a few months ago. Similar advice was also recently published on the Kaggle blog – it&amp;rsquo;s great to see that my tips are in line with the thoughts of other prolific kagglers.</description></item><item><title>Data’s hierarchy of needs</title><link>https://yanirseroussi.com/2014/08/17/datas-hierarchy-of-needs/</link><pubDate>Sun, 17 Aug 2014 13:09:30 +0000</pubDate><guid>https://yanirseroussi.com/2014/08/17/datas-hierarchy-of-needs/</guid><description>One of my favourite blog posts in recent times is The Log: What every software engineer should know about real-time data&amp;rsquo;s unifying abstraction by Jay Kreps. That post comprehensively describes how abstracting all the data produced by LinkedIn&amp;rsquo;s various components into a single log pipeline greatly simplified their architecture and enabled advanced data-driven applications. Among the various technical details there are some beautifully-articulated business insights. My favourite one defines data&amp;rsquo;s hierarchy of needs:</description></item><item><title>Kaggle competition tips and summaries</title><link>https://yanirseroussi.com/kaggle/</link><pubDate>Sat, 05 Apr 2014 23:46:10 +0000</pubDate><guid>https://yanirseroussi.com/kaggle/</guid><description>Over the years, I&amp;rsquo;ve participated in a few Kaggle competitions and wrote a bit about my experiences. This page contains pointers to all my posts, and will be updated if/when I participate in more competitions.
General advice posts 10 Steps to Success in Kaggle Data Science Competitions (guest post on KDNuggets) How to (almost) win Kaggle competitions Kaggle beginner tips Solution posts Greek Media Monitoring Multilabel Classification [6th/120] – multi-label classification of pre-tokenised texts Personalised Web Search Challenge [9th/194] – reranking web search results in a personalised manner Blue Book for Bulldozers [9th/476] – forecasting auction sale price of bulldozers ICFHR 2012 – Arabic Writer Identification Competition [3rd/42] – classifying handwritten texts by the identity of the writer (Kaggle blog post) EMC Data Science Global Hackathon (Air Quality Prediction) [6th/110] – forecasting levels of air pollutants (Kaggle forum post)</description></item><item><title>Kaggle beginner tips</title><link>https://yanirseroussi.com/2014/01/19/kaggle-beginner-tips/</link><pubDate>Sun, 19 Jan 2014 10:34:28 +0000</pubDate><guid>https://yanirseroussi.com/2014/01/19/kaggle-beginner-tips/</guid><description>These are few points from an email I sent to members of the Data Science Sydney Meetup. I suppose other Kaggle beginners may find it useful.
My first steps when working on a new competition are:
Read all the instructions carefully to understand the problem. One important thing to look at is what measure is being optimised. For example, minimising the mean absolute error (MAE) may require a different approach from minimising the mean square error (MSE).</description></item><item><title>About</title><link>https://yanirseroussi.com/about/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://yanirseroussi.com/about/</guid><description>Hi!
My name is Yanir Seroussi. This website/blog is mostly meant to group together stuff I write in various places. It&amp;rsquo;s mainly focused on data science.
I&amp;rsquo;m an experienced data scientist and software engineer with a strong background in computer science, programming, machine learning, and statistics. My work spans the full spectrum from solving isolated data problems to building production systems that serve millions of users. I&amp;rsquo;ve produced top results in various areas such as recommender systems, text mining, price forecasting, and personalisation.</description></item><item><title>Causal inference resources</title><link>https://yanirseroussi.com/causal-inference-resources/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://yanirseroussi.com/causal-inference-resources/</guid><description>This is a list of some causal inference resources, which I update from time to time. You can also check out my posts on causal inference and A/B testing.
Books:
Causal Inference: What if by Miguel Hernán and Jamie Robins: The most practical book I&amp;rsquo;ve read. Highly recommended. Trustworthy Online Controlled Experiments : A Practical Guide to A/B Testing by Ron Kohavi, Diane Tang, and Ya Xu: Building on the authors&amp;rsquo; decades of industry experience, this is pretty much the bible of online experiments, which is how causal inference is often done in practice.</description></item><item><title>Talks</title><link>https://yanirseroussi.com/talks/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://yanirseroussi.com/talks/</guid><description>Just a list of some talks I&amp;rsquo;ve given, saved here for future reference and for general public benefit.
Data ethics – beyond curve fitting (given as part of a local fast.ai course in June 2021; see video and post) Moving Automattic to net zero carbon emissions (PublishPress interview from November 2020) Running remote data teams (Data Futurology webinar from June 2020) Bootstrapping the right way (presented at YOW! Data 2019; also available as a video) A day in the life of a remote data scientist (presented at Data Science Sydney meetup 2019; also available as a video) Ask Why!</description></item></channel></rss>