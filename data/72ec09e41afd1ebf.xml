<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:cc="http://cyber.law.harvard.edu/rss/creativeCommonsRssModule.html">
    <channel>
        <title><![CDATA[Stories by Robert Chang on Medium]]></title>
        <description><![CDATA[Stories by Robert Chang on Medium]]></description>
        <link>https://medium.com/@rchang?source=rss-c00b242128fe------2</link>
        <image>
            <url>https://cdn-images-1.medium.com/fit/c/150/150/1*EguVA0HsIGqUy0gaDS1VgA.png</url>
            <title>Stories by Robert Chang on Medium</title>
            <link>https://medium.com/@rchang?source=rss-c00b242128fe------2</link>
        </image>
        <generator>Medium</generator>
        <lastBuildDate>Sat, 05 Nov 2022 16:47:29 GMT</lastBuildDate>
        <atom:link href="https://medium.com/@rchang/feed" rel="self" type="application/rss+xml"/>
        <webMaster><![CDATA[yourfriends@medium.com]]></webMaster>
        <atom:link href="http://medium.superfeedr.com" rel="hub"/>
        <item>
            <title><![CDATA[How Airbnb Achieved Metric Consistency at Scale]]></title>
            <link>https://medium.com/airbnb-engineering/how-airbnb-achieved-metric-consistency-at-scale-f23cc53dea70?source=rss-c00b242128fe------2</link>
            <guid isPermaLink="false">https://medium.com/p/f23cc53dea70</guid>
            <category><![CDATA[data]]></category>
            <category><![CDATA[data-engineering]]></category>
            <category><![CDATA[data-science]]></category>
            <category><![CDATA[software-development]]></category>
            <dc:creator><![CDATA[Robert Chang]]></dc:creator>
            <pubDate>Fri, 30 Apr 2021 18:25:08 GMT</pubDate>
            <atom:updated>2021-08-05T05:37:22.385Z</atom:updated>
            <content:encoded><![CDATA[<h4>Part-I: Introducing Minerva — Airbnb’s Metric Platform</h4><p><strong>By</strong>: <a href="https://www.linkedin.com/in/apahwa/">Amit Pahwa</a>, <a href="https://www.linkedin.com/in/cristianrfr/">Cristian Figueroa</a>, <a href="https://www.linkedin.com/in/donghan-zhang-670990135/">Donghan Zhang</a>, <a href="https://www.linkedin.com/in/haimgrosman/">Haim Grosman</a>, <a href="https://www.linkedin.com/in/john-bodley-a13327133/">John Bodley</a>, <a href="https://www.linkedin.com/in/jonathan-parks-15617820/">Jonathan Parks</a>, <a href="https://www.linkedin.com/in/shengnan-zhu-89403124/">Maggie Zhu</a>, <a href="https://www.linkedin.com/in/philip-weiss-391021b1/">Philip Weiss</a>, <a href="https://www.linkedin.com/in/robert-ih-chang/">Robert Chang</a>, <a href="https://www.linkedin.com/in/shao-xie-0b84b64/">Shao Xie</a>, <a href="https://www.linkedin.com/in/sylviatomiyama/">Sylvia Tomiyama</a>, <a href="https://www.linkedin.com/in/xiaohui-sun-24bb3017/">Xiaohui Sun</a></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*rB53PQsJi73IeA-eIeucIg.png" /><figcaption>Data is the voice of our users at scale. In the midst of the COVID-19 pandemic, we saw that travel with Airbnb has become hyper-local.</figcaption></figure><h3>Introduction</h3><p>At Airbnb, we lean on data to inform our critical decisions. We validate product ideas through randomized controlled experiments, and we track our business performance rigorously to ensure that we maximize values for our stakeholders. To achieve these goals, we needed to build a robust data platform that serves the internal users’ end-to-end needs.</p><p>While we have previously shared how we <a href="https://medium.com/airbnb-engineering/scaling-spark-streaming-for-logging-event-ingestion-4a03141d135d">ingest data</a> into our data warehouse and how to enable users to conduct their own <a href="https://medium.com/airbnb-engineering/supercharging-apache-superset-b1a2393278bd">analyses with contextual data</a>, we have not yet discussed the middle layer: how to properly model and transform data into accurate, analysis-ready datasets.</p><p>In this post, we will share our journey in building Minerva, Airbnb’s metric platform that is used across the company as the single source of truth for analytics, reporting, and experimentation. Specifically, we will set the context on why we built it, describe its core features and the ecosystem of tools it has enabled, and highlight the impact it has had on Airbnb. In upcoming posts, we will deep dive into the <a href="https://medium.com/airbnb-engineering/airbnb-metric-computation-with-minerva-part-2-9afe6695b486">technology behind Minerva</a> and share the lessons we learned along the way. By publishing this series, we hope our readers will appreciate the power of a system like Minerva and be inspired to create something similar for their organizations!</p><h3>A Brief History of Analytics at Airbnb</h3><p>Like many data-driven companies, Airbnb had a humble start at the beginning of its data journey. Circa 2010, there was only one full-time analyst at the company working on data, and his laptop was effectively the company’s data warehouse. Queries were often run directly against the production databases, and expensive queries occasionally caused serious incidents and took down Airbnb.com. In spite of the pitfalls, this simple solution helped Airbnb identify many growth opportunities over the years.</p><p>As Airbnb’s footprint continued to grow in the early 2010s, more data scientists were <a href="https://medium.com/airbnb-engineering/at-airbnb-data-science-belongs-everywhere-917250c6beba">brought on to the company</a> and data kept growing both in terms of size and of variety. It was around then that we went through the first phase of changes, <a href="https://medium.com/airbnb-engineering/data-infrastructure-at-airbnb-8adfb34f169c">upgrading and stabilizing</a> our data infrastructure. We switched from Chronos to our home-grown, now open sourced, Apache <a href="https://medium.com/airbnb-engineering/airflow-a-workflow-management-platform-46318b977fd8">Airflow</a> for workflow orchestration and invested in building a set of highly critical data tables called `core_data`.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*AqJoWcwj7duvOrtr" /><figcaption>Airbnb and the data that fuels it has grown substantially over the years.</figcaption></figure><p>With `core data` serving as the foundation, analytics at Airbnb began to blossom. First, we brought the culture of A/B testing to Airbnb by <a href="https://medium.com/airbnb-engineering/experiment-reporting-framework-4e3fcd29e6c0">building</a> and <a href="https://medium.com/airbnb-engineering/https-medium-com-jonathan-parks-scaling-erf-23fd17c91166">scaling</a> Airbnb’s experimentation platform. We built an in-house data catalog, <a href="https://medium.com/airbnb-engineering/democratizing-data-at-airbnb-852d76c51770">Dataportal</a>, to organize and document our data and created, now open sourced, Apache <a href="https://medium.com/airbnb-engineering/caravel-airbnb-s-data-exploration-platform-15a72aa610e5">Superset</a> so more users could analyze data independently and interactively. Last but not least, we focused on data education by launching <a href="https://medium.com/airbnb-engineering/how-airbnb-democratizes-data-science-with-data-university-3eccc71e073a">Data University</a>, a program to teach non-data scientists useful skills in an effort to democratize data analysis at Airbnb.</p><h3>Growing Pains</h3><p>While `core_data` brought several step-function changes to Airbnb’s data capabilities, our success did not come without some significant cost. In fact, the proliferation of data and use cases caused serious growing pains, both for data producers and for data consumers.</p><p>First, as `core_data` continued to rise in popularity, more data producers wanted to use it for analytics, forecasting, and experimentation. New tables were created manually on top of `core_data` tables every other day, but there was no way to tell if similar tables already existed. The complexity of our warehouse continued to grow, and data lineage became impossible to track. When a data issue upstream was discovered and fixed, there was no guarantee that the fix would propagate to all downstream jobs. As a result, data scientists and engineers spent countless hours debugging data discrepancies, fighting fires, and often feeling unproductive and defeated.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*DGqa6USgQiX21F62" /><figcaption>Proliferation of derived tables built on top of `core_data` caused some serious growing pains.</figcaption></figure><p>For data consumption, we heard complaints from decision makers that different teams reported different numbers for very simple business questions, and there was no easy way to know which number was correct. Years ago, when Brian, our CEO, would ask simple questions like which city had the most bookings in the previous week, Data Science and Finance would sometimes provide diverging answers using slightly different tables, metric definitions, and business logic. Over time, even data scientists started to second guess their own data, confidence in data quality fell, and trust from decision makers degraded.</p><h3>Overcoming Our Growing Pains with Minerva</h3><p>As these pain points worsened, Airbnb embarked on a <a href="https://medium.com/airbnb-engineering/data-quality-at-airbnb-e582465f3ef7">multi-year journey</a> to revamp its data warehouse with the goal of drastically improving data quality at the company. As a first step, our data engineering team rebuilt several key business data models from scratch, which resulted in a set of certified, lean, normalized tables that do not use unnecessary joins. These vetted tables now served as the new foundation for our analytics warehouse.</p><p>Our work hardly stopped there, however. In order to translate these tables into insights, we needed to be able to programmatically join them together to create analysis-friendly datasets. We needed to be able to backfill data whenever business logic changed. Finally, we needed data to be presented consistently and correctly in different consumption tools.</p><p>This is when Minerva — Airbnb’s metric platform — came onto the scene. Minerva takes fact and dimension tables as inputs, performs data denormalization, and serves the aggregated data to downstream applications. The Minerva API bridges the gap between upstream data and downstream consumption, enabling Data Engineering teams the flexibility to modify core tables while maintaining support for various downstream consumers. This API serves a vital role in Airbnb’s next-generation data warehouse architecture.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*SCOkdySJO68BS8OJ" /><figcaption>Minerva, Airbnb’s metric platform, plays a central role in Airbnb’s new data warehouse architecture.</figcaption></figure><p>To date, we have more than 12,000 metrics and 4,000 dimensions in Minerva, with more than 200 data producers spanning across different functions (e.g., Data, Product Management, Finance, Engineering) and teams (e.g., Core Product, Trust, Payments). Most teams now regard Minerva as their preferred framework for analytics, reporting, and experimentation at Airbnb.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*3KyF0UdLxSok8FyF" /><figcaption>Adoption of Minerva at Airbnb has grown tremendously in the past two years.</figcaption></figure><h3>Data Production in Minerva</h3><p>From an infrastructure perspective, Minerva is built on top of open-source projects. It uses Airflow for workflow orchestration, Apache Hive and Apache Spark as the compute engine, and Presto and Apache Druid for consumption. From metric creation through computation, serving, consumption, and eventually deprecation, Minerva covers the full life cycle of a metric.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*MStjNvO4kb-XNNur" /><figcaption>Minerva manages the entire lifecycle of metrics at Airbnb.</figcaption></figure><ul><li><strong>Metrics Definition</strong>: Minerva defines key business metrics, dimensions, and other metadata in a centralized Github repository that can be viewed and updated by anyone at the company.</li><li><strong>Validated Workflow</strong>: The Minerva development flow enforces best data engineering practices such as code review, static validation, and test runs.</li><li><strong>DAG Orchestration: </strong>Minerva performs data denormalization efficiently by maximizing data reuse and intermediate joined results.</li><li><strong>Computation Runtime: </strong>Minerva has a sophisticated computation flow that can<strong> </strong>automatically self-heal after job failures and has built-in checks to ensure data quality.</li><li><strong>Metrics / Metadata Serving: </strong>Minerva provides a unified data API to serve both aggregated and raw metrics on demand.</li><li><strong>Flexible Backfills: </strong>Minerva<strong> </strong>version controls data definitions, so major changes to the datasets are automatically tracked and backfilled.</li><li><strong>Data Management</strong>: Minerva has built-in capabilities such as cost attribution, GDPR selective deletion, data access control, and an auto-deprecation policy.</li><li><strong>Data Retention:</strong> Minerva establishes usage-based retention and garbage collection, so expensive but infrequently utilized datasets are removed.</li></ul><p>The above mentioned features allow us to standardize metric creation, data computation, and data delivering. In the next post, we will deep dive into these features and explain them in more detail!</p><h3>Data Consumption in Minerva</h3><p>Minerva’s product vision is to allow users to “define metrics once, use them everywhere”. That is, a metric created in Minerva should be easily accessed in company dashboarding tools like <a href="https://medium.com/airbnb-engineering/supercharging-apache-superset-b1a2393278b">Superset</a>, tracked in our A/B testing framework <a href="https://medium.com/airbnb-engineering/experiment-reporting-framework-4e3fcd29e6c0">ERF</a>, or processed by our anomaly detection algorithms to spot business anomalies, just to name a few. Over the last few years, we have partnered closely with other teams to create an ecosystem of tools built on top of Minerva.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*3JIcR8l97r90lqf5" /><figcaption>Minerva’s vision is “define once, use everywhere”.</figcaption></figure><h4>Data Catalog</h4><p>First, we partnered closely with the Analytics Product team to index all Minerva metrics and dimensions in the <a href="https://medium.com/airbnb-engineering/democratizing-data-at-airbnb-852d76c51770">Dataportal</a>, Airbnb’s data catalog. When a user interfaces with the Dataportal and searches for a metric, it ranks Minerva metrics at the top of the search results. The Dataportal also surfaces contextual information, such as certification status, ownership, and popularity so that users can gauge the relative importance of metrics. For most non-technical users, the Dataportal is their first entry point to metrics in Minerva.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*o7XX523HFOUjyNrn" /><figcaption>Minerva metrics are indexed and catalogued in the Dataportal UI.</figcaption></figure><h4>Data Exploration</h4><p>Upon selecting a metric, users are redirected to Metric Explorer, a component of the Dataportal that enables out-of-the-box data exploration. On a metric page, users can see trends of a metric with additional slicing and drill down options such as `Group By` and `Filter`. Those who wish to dig deeper can click into the Superset view to perform more advanced analytics. Throughout this experience, Metric Explorer surfaces metadata such as metric owners, historical landing time, and metric description to enrich the data context. This design balances the needs of both technical and non-technical users so they can <a href="https://medium.com/airbnb-engineering/supercharging-apache-superset-b1a2393278bd">uncover data insights in-place seamlessly</a>.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*rxkHxALysVnkzxxz" /><figcaption>Users can investigate trends and anomalies in Metric Explorer and Superset seamlessly.</figcaption></figure><h4>A/B Testing</h4><p>Historically, Airbnb’s Experimentation Reporting Framework (ERF) had its own experiment metrics repository called “metrics repo”. Experimenters could add any business metric to an experiment and compare the results of the control and treatment group. Unfortunately, the metrics repo couldn’t be used for other use cases beyond experimentation, so we decided to integrate Minerva with ERF so all base events for A/B tests are defined and sourced from Minerva. Using the same source across experimentation and analytics means data scientists can be confident in their understanding of <a href="https://medium.com/airbnb-engineering/designing-experimentation-guardrails-ed6a976ec669">how certain experiments could affect the top line business metrics</a>.</p><h4>Executive Reporting</h4><p>Long since Airbnb became a public company, we have adopted a practice of reviewing Airbnb’s business performance on weekly, monthly, and quarterly cadences. In these meetings, leaders across different functions meet and discuss the current state of the business. This type of meeting requires executive reports that are high-level and succinct. Data are often aggregated, trends are analyzed and plotted, and metrics movements are presented as running aggregations (e.g., year to date) and time ratio comparison (e.g., year over year).</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*RWmZcLerJV5JoRtP" /><figcaption>Here is an example of the reporting configuration for COVID-19 dashboard, built on top of Minerva.</figcaption></figure><p>To enable this type of reporting, we built an eXecutive Reporting Framework (XRF). XRF takes a list of user-specified Minerva metrics and dimensions and turns them into aggregated metric time series that are report-friendly. This framework automates a lot of the manual work and allows us to standardize high-fidelity, business-critical reports by leveraging the same Minerva metrics and dimensions used for analysis and experimentation.</p><h4>Data Analysis</h4><p>Last but not least, Minerva data is exposed to Airbnb’s custom R and Python clients through Minerva’s API. This allows data scientists to query Minerva data in a notebook environment with ease. Importantly, the data that’s being surfaced in the notebook environment is computed and surfaced exactly the same way as they were in the aforementioned tools, such as Superset and Metric Explorer. This saves enormous amounts of time for data scientists as they can pick and choose the right tool for the job depending on the complexity of the analysis. Notably, this data API encourages lightweight prototyping of internal tooling, which can later be productionalized and shared across the company. For example, data scientists have built a time series analysis tool and an email reporting framework using this API over the last two years.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/972/0*AvWgz6qImCriZUBn" /><figcaption>A data scientist can use our Python client to retrieve aggregated data in Minerva and conduct analyses.</figcaption></figure><h3>How We Responded To the COVID-19 Crisis with Minerva Data</h3><p>As Minerva became a centerpiece of analytics at Airbnb, we saw again and again the power and productivity gain it has brought to the data community at Airbnb. In this last section, we want to give a concrete example of how Minerva aided the business during the COVID-19 crisis.</p><p>In March 2020, global travel came to a halt due to COVID-19. Almost overnight, Airbnb bookings plummeted and cancellations skyrocketed. This was a scary moment for us, and it raised many important business questions: How was the coronavirus affecting our nights backlog? How was it affecting our occupancy rate? What was the financial impact of rising cancellations? How had the coronavirus altered travel demand in terms of travel distance? We needed to answer all these questions quickly and correctly.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*M0Dzpgwz7633v1SB" /><figcaption>We were able to dramatically shorten the time from data curation to insight discovery and assess the impact of COVID-19 on Airbnb’s business because of Minerva!</figcaption></figure><p>In response to this influx of inquiries, our data science team gathered the questions and started to brainstorm how we could leverage data to answer them. Crucially, since many important business metrics and dimensions for supply, demand, finance, and customer support were already defined in Minerva, our Central Analytics team was able to wireframe an executive dashboard and roll out the initial version in just under a few days. The COVID-19 dashboard quickly became the single authoritative source of truth and was reviewed closely by our executive team in the midst of the crisis. Since then, it has amassed more than 11,000 views and 1,500 distinct viewers. Not surprisingly, the COVID-19 dashboard was the most viewed Superset dashboard at Airbnb in 2020.</p><p>Insights generated from Minerva metrics also allowed the company to confidently pinpoint the rapidly changing landscape. For example, we uncovered market opportunities such as demand shift to local travel and longer-term stays. These findings led us to redesign several important touch points of our product pages to meet the shift in user preference. In moments of crisis, the ability to answer questions and uncover insights is more important than ever. We are able to do this efficiently and effectively, thanks to the single source of truth data in Minerva!</p><h3>Closing</h3><p>In this post, we briefly summarized the history of Airbnb’s analytics journey, the growing pains we faced in the last few years, and why we built Minerva, Airbnb’s metric infrastructure. In particular, we covered how data is produced and consumed via Minerva. Toward the end of the post, we also highlighted a recent example of how Minerva helped Airbnb to react to the COVID-19 crisis.</p><p>In the <a href="https://medium.com/airbnb-engineering/airbnb-metric-computation-with-minerva-part-2-9afe6695b486">next post</a>, we will deep dive into Minerva’s technical architecture, including the design principles, the user development flow, as well as the data computation graph. In the last post of the series, we will introduce Minerva API, which is our single layer of data abstraction that made all the integrations outlined above possible. We will close the series by sharing the lessons that we’ve learned from building Minerva in the hope that these lessons will be helpful for others building similar systems.</p><p>Until then, stay tuned for our next post!</p><h3>Acknowledgments</h3><p>Minerva is made possible only because of the care and dedication from those who worked on it. We would also like to thank <a href="https://www.linkedin.com/in/lchircus/">Lauren Chircus</a>, <a href="https://www.linkedin.com/in/aaronkeys/">Aaron Keys</a>, <a href="https://www.linkedin.com/in/michaelcl/">Mike Lin</a>, <a href="https://www.linkedin.com/in/adriankuhn/">Adrian Kuhn</a>, <a href="https://www.linkedin.com/in/krishna-bhupatiraju-1ba1a524/">Krishna Bhupatiraju</a>, <a href="https://www.linkedin.com/in/michelleethomas/">Michelle Thomas</a>, <a href="https://www.linkedin.com/in/erikrit/">Erik Ritter</a>, <a href="https://www.linkedin.com/in/serena-jiang/">Serena Jiang</a>, <a href="https://www.linkedin.com/in/krist-wongsuphasawat-279b1617/">Krist Wongsuphasawat</a>, <a href="https://www.linkedin.com/in/chris-williams-1bb8b936/">Chris Williams</a>, <a href="https://www.linkedin.com/in/kenchendesign/">Ken Chen</a>, <a href="https://www.linkedin.com/in/yguang11/">Guang Yang</a>, <a href="https://www.linkedin.com/in/jinyang-li-607690143/">Jinyang Li</a>, <a href="https://www.linkedin.com/in/clark-wright-67955537/">Clark Wright</a>, <a href="https://www.linkedin.com/in/vquoss/">Vaughn Quoss</a>, <a href="https://www.linkedin.com/in/zi-jerry-chu/">Jerry Chu</a>, <a href="https://www.linkedin.com/in/palanieppan-muthiah-b7088924/">Pala Muthiah</a>, <a href="https://www.linkedin.com/in/ruiqinyang/">Kevin Yang</a>, <a href="https://www.linkedin.com/in/ellen-huynh/">Ellen Huynh</a>, and many more who partnered with us to make Minerva more accessible across the company. Finally, thank you <a href="https://www.linkedin.com/in/bulam/">Bill Ulammandakh</a> for creating the beautiful visualization so we can use it as our header image!</p><p><em>Apache®, Apache Airflow, Apache Superset, Apache Hive, Apache Spark and Apache druid are either registered trademarks or trademarks of the Apache Software Foundation in the United States and/or other countries.</em></p><p><em>Presto is the registered trademark of LF Projects, LLC.</em></p><p><em>GITHUB® is the exclusive trademark registered in the United States by GitHub, Inc.</em></p><p><em>All trademarks are the properties of their respective owners. Any use of these are for identification purposes only and do not imply sponsorship or endorsement.</em></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=f23cc53dea70" width="1" height="1" alt=""><hr><p><a href="https://medium.com/airbnb-engineering/how-airbnb-achieved-metric-consistency-at-scale-f23cc53dea70">How Airbnb Achieved Metric Consistency at Scale</a> was originally published in <a href="https://medium.com/airbnb-engineering">The Airbnb Tech Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[How I Build Learning Projects — Part II]]></title>
            <link>https://medium.com/@rchang/how-i-build-learning-projects-part-ii-3c5ab4b3dd98?source=rss-c00b242128fe------2</link>
            <guid isPermaLink="false">https://medium.com/p/3c5ab4b3dd98</guid>
            <category><![CDATA[data-science]]></category>
            <category><![CDATA[learning]]></category>
            <category><![CDATA[programming]]></category>
            <category><![CDATA[data]]></category>
            <category><![CDATA[machine-learning]]></category>
            <dc:creator><![CDATA[Robert Chang]]></dc:creator>
            <pubDate>Sun, 29 Mar 2020 01:01:00 GMT</pubDate>
            <atom:updated>2020-03-29T01:01:00.935Z</atom:updated>
            <content:encoded><![CDATA[<h3>How I Build Learning Projects — Part II</h3><h4>Habits Are Too Light To Be Felt Until They Are Too Heavy to Be Broken</h4><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*swL0WOzlj0ycZaC80BSXFg.png" /><figcaption><a href="https://unsplash.com/photos/Oaqk7qqNh_c">Image Credit</a>: Are you ready to build your learning habits?</figcaption></figure><h3>Recap</h3><p>In my <a href="https://medium.com/@rchang/how-i-build-learning-projects-part-i-54dbaad68961">earlier post</a>, I shared my approach to building self-directed learning projects. I emphasized, before jumping into any project, you should pick carefully and strategically what skills to invest in. In particular, prioritizing skills that are foundational, transferrable, and adjacent to your core competency are some of my criteria for acquiring new professional skills.</p><p>I also highlighted the importance of planning — from defining the objectives and key results, decomposing a project into concrete milestones, to surveying and sampling learning materials, these planning exercises can significantly reduce logistical complexity and enable you to deeply focus on learning itself.</p><p>In this second post, I will pick up where we left off and describe how you can develop habits and rituals to reliably execute against your plan. Furthermore, We will cover techniques that will further solidify your learnings such as doing drills for procedural learning, building mental models for conceptual learning, and using free recall and spaced repetition to remember facts. By the end of this post, I hope you will be inspired to develop your learning system as <a href="https://superorganizers.substack.com/">many others</a> have.</p><h3>From Strategy to Execution: Habits and Rituals</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*FGrPgB48KfgP3UJk3vibOw.png" /><figcaption><a href="https://unsplash.com/photos/BfphcCvhl6E">Image Credit</a>: Many high performers (such as in sports) have designed habits and routines to support their high performance</figcaption></figure><p>While most people agreed with “strategy without execution is useless”, many still fall short when it comes to learning project execution. For example, the chart below shows the view progression for some of the most popular online courses on YouTube. In the aggregate, people tend to drop off quickly just a few lectures into the courses, and many people fail to take their studies to the finish line.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*lbHNIKvUhmBt7lvmt_EYmg.png" /><figcaption><a href="https://gist.github.com/robert8138/aa0e08bd56b6597f278d2622397a2505">Code</a>: View trends of free, popular MOOC on Youtube — people rarely pass through the 3rd lecture!</figcaption></figure><p>The key to fighting against the odds, in my opinion, lies in the book “<a href="https://jamesclear.com/books">Atomic Habit</a>”. The author James Clear argues that all great performers, be them athletes, musicians, and any professionals, have rituals and routines designed to support their high performance. I believe, to get the most out of your projects, you too should design <strong>learning habits </strong>to support your deliberate practice. These learning habits are the key to finishing a good project.</p><h4>The Habit Loop</h4><p>Drawing from a wide variety of research and interviews, Clear develops a framework that describes <a href="https://jamesclear.com/three-steps-habit-change">the mechanics of habit formation</a>. In his words:</p><blockquote>The cue triggers a craving, which motivates a response, which provides a reward, which satisfies the craving and, ultimately, becomes associated with the cue. Together, these four steps form a neurological feedback loop — <strong>cue, craving, response, reward</strong>;<strong> cue, craving, response, reward</strong> — that ultimately allows you to create automatic habits.</blockquote><figure><img alt="" src="https://cdn-images-1.medium.com/max/706/1*SBtbix-E4x4CXRNSiaj4dg.png" /><figcaption><a href="https://jamesclear.com/three-steps-habit-change">Image credit</a>: The cue-craving-response-reward habit loop</figcaption></figure><p>If you analyze some of your habits that are seemingly automatic, they all follow the same habit loop described above. For example, early in the morning, the act of waking up is a <em>cue</em> for you to go to the bathroom, and your mere presence in the bathroom triggers a <em>craving</em> to freshen up. You then react to this craving by brushing your teeth or taking a shower. Once you complete these <em>responses</em>, you feel refreshed and <em>rewarded</em>. In the background, this process completes a habit loop and repeats itself the next morning.</p><p>Many high performers understood that this very cycle can be leveraged to design rituals and routines to support their professional pursuits. Michael Phelps trained for 5–6 hours a day in the water, and the consistency made him one of the greatest swimmers in the world. The late Kobe Bryant woke up at 4:30 a.m. every day just so he could get a few extra hours of practice, and this dedication made him one of the most legendary basketball players in NBA history. The pursuit of excellence is never just achieved through will powers, it is also supported by well-designed habits and routines.</p><h4>The Four Laws of Good Habit Formation</h4><p>Certainly, putting habits in place is easier said than done, so what can we do to foster these habits? Clear explains, once you understand how habits work, you can follow a simple set of rules to create good habits and even break bad ones. He called these the<strong> Four Laws of Good Habit Formation:</strong></p><ul><li><strong>Make it obvious: </strong>If you want to reliably kickstart a habit loop, make the <em>cues </em>that remind you about the habit extremely obvious</li><li><strong>Make it attractive: </strong>If the triggered cue is associated with a strong <em>craving</em>, you are more likely to follow through with the habit</li><li><strong>Make it easy: </strong>For you to execute on the habit itself, the action or response needed to fulfill the craving must be very easy to perform</li><li><strong>Make it satisfying: </strong>Finally, to complete the loop, the reward you get from completing the action must be satisfying to satisfy the craving</li></ul><p>By understanding these principles, you can now design tactics to make a good habit stick. If you often forget to do a learning project, find cues to remind you of this priority. If you often don’t have enough motivation to return to a project, find ways to make it more desirable. If your projects are too hard to execute on, simplify and make it easy to do. Finally, if your projects don’t give you enough satisfaction, find alternative ways to make it rewarding.</p><h3>Engineer Habits &amp; Routines For Learning Projects</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*IFo-KtorcGN3uO0NIoTXFQ.png" /><figcaption><a href="https://unsplash.com/photos/Wiu3w-99tNg">Image credit</a>: How will you engineer your habits and routines to support your learnings every day?</figcaption></figure><p>Ever since I learned about the <strong>Four Laws of Good Habit Formation</strong>, I have become more intentional about how I execute my projects. While my previous learnings succeeded because I pushed myself hard, my more recent projects succeeded because of the routines that I designed. To make it concrete, I will use a Machine Learning project that I completed in 2018 as a case study.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*zRhATTkIaLV4DdHdG4tCjA.png" /><figcaption>My <a href="https://github.com/robert8138/deep-learning-deliberate-practice">Project Plan Document</a> — similar to a Product Requirement Document (PRD) in Product Development</figcaption></figure><p>First, I would encourage you to read my <a href="https://github.com/robert8138/deep-learning-deliberate-practice">Project Plan Document</a> to understand the motivation of this project. Next, you can read through my detailed time log to see my learning <a href="https://github.com/robert8138/deep-learning-deliberate-practice/blob/master/TIMELINE.md">progression</a> by the week. With those contexts in mind, I will go beyond what I have written down on Github and highlight the habits and routines that I practiced throughout the project.</p><h4>Make It Obvious: Use Implementation Intention As My Cue</h4><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*9mEja8Y6JnD9ICdG5qGWRQ.png" /><figcaption><a href="https://unsplash.com/photos/XVoyX7l9ocY">Image Credit</a>: I jumpstart my learning projects the moment I hop on a train for 50 minutes</figcaption></figure><p>Like many other brave souls in Silicon Valley, I spend a few hours a day in commuting. Recognizing that my time is valuable, I was determined to not waste it. Each morning, as I stepped onto the waiting platform, I would tell myself that today is a new day, and I will re-engage with my learning projects for 50 minutes until I arrive at San Francisco. The act of pre-committing to a specific action at a specific time and a specific place is a goal-setting technique called <a href="https://jamesclear.com/implementation-intentions"><strong>Implementation Intention</strong></a>.</p><p>This technique has been used widely in many situations and has been proven to be extremely effective. The reason that it works is that it removes the decision making ahead of time and lowers the activation energy to kickstart a routine. When you pair this technique with an environment where you regularly interact, you effectively design a recurring cue that serves as a powerful reminder to prioritize what is important to you in that environment.</p><p>Note, interruptions and disruptions do occur in life: e.g. the train could be late, you could feel sick every once a while, or you might not be able to find a seat on the train because it’s too crowded. These things do happen, and that’s ok. As long as you treat your implementation intention seriously, you can adapt and still follow through your commitments.</p><h4><strong>Make It Attractive: Increase Craving Through Temptation Bundling</strong></h4><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*KrLcvyQQogcHgsnRBi6GLA.png" /><figcaption><a href="https://unsplash.com/photos/6SOc_IqY9mk">Image Credit</a>: Is your learning project attractive enough to get you taking action?</figcaption></figure><p>Suppose the train is on time, and I found a good seat, it can still feel like a struggle to dive right back into the learning materials. In these situations, a technique called <a href="https://jamesclear.com/temptation-bundling"><strong>Temptation Bundling</strong></a> can be very handy. At its core, the idea is to link behavior that you <em>need</em> to do with a behavior that you <em>want</em> to do. By bundling the hard thing with the pleasurable thing together, the hard thing becomes more attractive.</p><p>As a concrete example, grokking intellectually challenging concepts in Deep Learning isn’t always the easiest. On the other hand, I always really enjoy writing a neat learning summary whenever I finish a new concept, as I find that process soothing. By bundling these two activities, I convinced myself that if I could engage with the materials and learn a new concept (what I <em>need to do</em>), I will be able to produce a well-written summary by the end of the session (what I <em>want to do</em>). Furthermore, the fact that these two activities are sequentially related, means that bundling can be particularly effective.</p><p>Not every person struggling with Deep Learning is obsessed with well-written <a href="https://github.com/robert8138/deep-learning-deliberate-practice/tree/master/concepts">documentation</a>. The general lesson here, however, is to identify what things you <em>need</em> to do, what things you <em>want</em> to do and think of ways of linking some of them together. By going through this design exercise, you can drastically improve your motivation to carry your routines forward.</p><h4><strong>Make It Easy: Remove Logistical Complexity Ahead of Time</strong></h4><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*ca-ZuhLYH3YutaC-liYH9A.png" /><figcaption><a href="https://unsplash.com/photos/dCAKIpxs3eE">Image Credit</a>: If the task you need to perform is too hard to do, you won’t do it</figcaption></figure><p>Even when I am already engaging with my learnings during my commute, there could still be challenges. As an example, if I am working through a MOOC, I generally do not like to consume video lectures on my tiny phone screen. In addition, the internet connection can be unstable and the streaming experience can be sporadic, the whole experience can feel inconvenient. These logistical complexities can easily creep up on me and kill productivity. As a result, I decided to simplify and remove these complexities ahead of time.</p><p>For example, to overcome the inconvenience, I always pre-<a href="https://en.savefrom.net/1-youtube-video-downloader-1/">download</a> the video lectures to my laptop before my commute. Once I am on the train, I could then play the lectures in 2X the speed, or even play back and forth without any internet interruptions. Furthermore, the logistics of deciding what materials to download on a given day is also solved, because I can go back to my learning schedule and my time log to identify which lessons to pursue next. The preparation process is lightweight and seamless.</p><p>Depending on the task at hand, there could be many ways to make it easier. Tactics such as <a href="https://jamesclear.com/small-habits">starting small</a>, reducing scope, and leveraging <a href="https://jamesclear.com/akrasia">commitment devices</a> are all worth trying when designing your routines.</p><h4><strong>Make It Satisfying: Using Github to Keep Track of My Progress</strong></h4><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*RynYCpN1X7r0j-tby8RY4g.png" /><figcaption>I used Github’s commit heat map to visually see my progress</figcaption></figure><p>Finally, to celebrate the progress that I made, I used a combination of visual cues and public artifacts to reward myself. For example, I use Github’s commit heat map to visually track my progress. As much as I know the number of commits is a vanity metric, being able to visualize them at a glance is still very powerful. <a href="https://jamesclear.com/stop-procrastinating-seinfeld-strategy">Jerry Seinfeld</a>, the legendary comedian, uses this very same technique to motivate himself to write jokes every day:</p><blockquote>“After a few days, you’ll have a chain. Just keep at it and the chain will grow longer every day. You’ll like seeing that chain, especially when you get a few weeks under your belt. Your only job is to not break the chain.”</blockquote><p>While never breaking the chain is very difficult, Clear proposed a slightly more lenient version called <a href="https://www.youtube.com/watch?v=dMwnQO8MUjw"><strong>Never Miss Twice</strong></a>, which I find both practical and empathetic.<strong> </strong>The idea is the following — it is acceptable to break the chain every once a while, but when you do, never miss your routine twice in a row. It is not just about adhering to a routine, but it is also about how fast and how consistent you can get back on track. Grit is the key to success.</p><p>Designing good learning habits takes time and thoughtful thinking. But once you have the right designs in place, they are not as hard to follow as you originally imagined. By following the strategies derived from the <strong>Four Laws of Good Habit Formation</strong>, you can greatly increase the odds of completing your work to drive high performance.</p><h3>Transform Learnings Into Tools In Your Toolkit</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*Zgsn95NzmKcr_EYAn5DXHQ.png" /><figcaption><a href="https://unsplash.com/photos/IClZBVw5W5A">Image Credit</a>: Are you adding new tools to your toolkit from your learning projects?</figcaption></figure><p>Without continuous training and consistent practice, over time, even the greatest athletes and musicians would experience skill deterioration. This is even more true among knowledge workers, many of whom “practice” and “training” are less tangible and more abstract.</p><p>For example, even for some of my well-executed projects, without further practice, I tend to forget about 30% to 50% of what I initially learned in the following six months. Without more investments, knowledge and skills that are fresh to our memory can go away rather quickly. The good news is, depending on whether you are trying to learn <em>procedures</em>, <em>concepts</em>, or <em>facts</em>, we can adopt different strategies to extend the half-life of our learnings.</p><h4>Procedures: Find Opportunity To Do “Practice Drills” On the Job</h4><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*-wDwkaoZS0qV9K1tTxz8HQ.png" /><figcaption><a href="https://unsplash.com/photos/uvMSarsRHzo">Image Credit</a>: What are some of the ways you can do practice drills on the job?</figcaption></figure><p>One strategy to effectively sharpen your skills is to <em>directly</em> <em>practice</em> and <em>apply</em> that skill on the job. Not only will you be able to correlate your current level of expertise with the quality of your output, but this strategy will also create urgency and accountability that vehemently forces you to do your work better.</p><p>In the early days of my self-directed learning journey, I largely saw these projects as standalone intellectual exercises — whether I applied the skills or not is not that consequential. Nowadays, I see self-directed learning as an investment in my career, and there is no better feedback than to see how well I can deploy these skills to facilitate my work. As an example, after my push to deliberately <a href="https://github.com/robert8138/python-deliberate-practice">improve my Python skills</a>, I forced myself to conduct analyses at work in Python to see how efficient I could be. Similarly, I took on projects where reading and writing Python code is essential to completing the work. I also proactively studied how Object-oriented Python is used to design some of Airbnb’s Data Engineering frameworks. Every activity deepened my muscle memory and made me more familiar with the core skills involved.</p><p>The road to mastery is a long one, and it is only through many practices will we get closer. Given that we spend a disproportionate amount of time at work, identifying work projects that will take your skill to the next level <em>on the job</em> is a high leverage exercise. At times, this might give you a feeling of defeat or a temporary loss in productivity, but by enduring the discomfort and working through the feedback, you will get better at these procedural learnings.</p><h4>Concepts: Build Mental Models And Teach Others</h4><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*AMmDlyZSSMYs7KoY_JxWvg.png" /><figcaption><a href="https://unsplash.com/photos/7e2pe9wjL9M">Image Credit</a>: Have you ever experienced a eureka moment where you started to “get it”?</figcaption></figure><p>Have you ever experienced a eureka moment where, all of a sudden, many ideas and concepts you previously struggled with now started to make sense? I certainly have, and I suppose these “aha moments” are not uncommon among avid learners. When these moments arrive, it is critically important to slow down and capture those thoughts. Here is a process that I recommend:</p><ul><li><strong>Write those insights down: </strong>As it has been said, <a href="https://medium.learningbyshipping.com/writing-is-thinking-an-annotated-twitter-thread-2a75fe07fade?gi=bc12710a469">writing is thinking</a>. By writing things down, it helps you to develop a logical narrative of your understanding, and it helps you to confront fuzzy ideas and half-baked thoughts. Writing is one of the most powerful ways to drive clarity.</li><li><strong>Validate your mental models with experts: </strong>With your mental models written down, share them with subject-matter experts who, in terms, have their mental model of the same subject. By learning and comparing different mental models, you can gut check if you are on the right track.</li><li><strong>Voraciously teach others what you learned: </strong>After confirming your intuition, find opportunities to teach and share your mental models. By articulating and sharing your perspectives, the power of teaching and explaining will help you to refine what you have learned.</li></ul><p>The process above is a powerful way to translate amorphous understanding into concrete mental models. As an example, when things started to click for me for Data Engineering, I wrote down my thoughts and shared them with other experts in the company to get feedback. I summarized them in a series of <a href="https://medium.com/@rchang/a-beginners-guide-to-data-engineering-part-i-4227c5c457d7">blog posts</a> and I found every possible opportunity to teach new hires about this topic. By applying my mental model in various situations, these exercises helped me to draw an increasingly clear mental picture in my mind.</p><h4>Facts: Use Free Recall, Spaced Repetition, and Interleaving</h4><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*51jxxlH9qpmeWQcE6-btRA.png" /><figcaption><a href="https://unsplash.com/photos/hgFY1mZY-Y0">Image Credit</a>: Have you ever used free recall to remember facts you have learned?</figcaption></figure><p>Despite living in a world where facts are just a few keystrokes away, active memory recall can still be very useful in many situations. For example, being able to retrieve known facts from your brain can help you triangulate and validate new information on the spot. In a debate, being able to cite relevant facts can make your argument more compelling. Being able to remember facts well is quite underrated in this information age. When it comes to fact-based learning, I have found the following techniques quite useful:</p><ul><li><strong>Free Recall: </strong>After consuming some new materials, immediately force yourself to summarize the main points from memory without looking at it</li><li><strong>Spaced Repetition</strong>: Spread out your exercises over time, repeat them often and do not force the materials onto yourself in a short cramming session</li><li><a href="https://www.scientificamerican.com/article/the-interleaving-effect-mixing-it-up-boosts-learning/"><strong>Interleaving</strong></a><strong>: </strong>Mix several topics together and use free recall and spaced repetition together. Instead of reviewing topic A &amp; B in a sequence “AAAAAA” and “BBBBBB”, interleave them with “AAA-BBB-AAA-BBB”</li></ul><p>For example, when trying to digest facts and ideas from a book, I often found free recall a more effective technique than sentence highlighting. By closing the book and forcing myself to reiterate the main points, I often realized how incoherent I was or how little I could explain these points the first time around. However, by repeating this retrieval process several times, and connecting them with other related materials (of which I also practice free recall), these spaced-out, interleaved exercises helped me to internalize facts much more effectively.</p><h3>Closing</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*MSYrQzglSdhN7wsXVq4TKA.png" /><figcaption><a href="https://visme.co/blog/amazing-leaders-who-once-had-crippling-stage-fright-and-how-they-overcame-it/">Image credit</a>: Warren Buffett, a creature of habits</figcaption></figure><p><a href="https://www.youtube.com/watch?v=RYHPlLsdW0A">Warren Buffett</a>, also known as the “Oracle of Omaha”, is one of the world’s most renowned investors and philanthropists. In addition to those two public roles, he always considered himself a teacher. Notably, he always advises young people to seek role models whose qualities and traits they admire and encourage them to make those qualities as their own.</p><p>To me, in addition to Buffett’s <a href="https://www.youtube.com/watch?v=ldPh0_zEykU#t=12m15s">whimsical humor</a> and <a href="https://www.youtube.com/watch?v=O0R_9L_D2Yk">strong integrity</a>, what I admire him the most, is not his wealth, but his consistency. He still lives in the modest house he bought in 1958, he still drives by the same McDonald’s for breakfast every day, and he continues to conduct his life with the same principles and philosophies. His long-time investment partner and friend Charlie Munger calls him an absolute “<strong>lifelong learning machine</strong>”, and I suspect he did not become one without his habits for learning. He once said:</p><blockquote><a href="https://www.youtube.com/watch?v=ldPh0_zEykU#t=08m35s">[Chains of habit are] too light to be felt until they are too heavy to be broken</a></blockquote><p>I wrote this series partly because I believe many of us have a strong desire to learn and grow, but I also believe we do not discuss enough how to design and build systems and routines to support our learnings. I hope by sharing some of my own experiences and research from others, you too can be inspired to build your system and become a lifelong learning machine!</p><p>Happy learning!</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=3c5ab4b3dd98" width="1" height="1" alt="">]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[How I Build Learning Projects — Part I]]></title>
            <link>https://medium.com/@rchang/how-i-build-learning-projects-part-i-54dbaad68961?source=rss-c00b242128fe------2</link>
            <guid isPermaLink="false">https://medium.com/p/54dbaad68961</guid>
            <category><![CDATA[learning]]></category>
            <category><![CDATA[programming]]></category>
            <category><![CDATA[data-science]]></category>
            <category><![CDATA[computer-science]]></category>
            <dc:creator><![CDATA[Robert Chang]]></dc:creator>
            <pubDate>Sun, 21 Jul 2019 00:18:28 GMT</pubDate>
            <atom:updated>2019-07-21T00:18:28.468Z</atom:updated>
            <content:encoded><![CDATA[<h3>How I Build Learning Projects — Part I</h3><h4>A Little Bit of Slope Makes Up For A Lot of Y-Intercept</h4><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*PNViZtLN_8qn0oX-55UKig.png" /><figcaption><a href="https://unsplash.com/photos/eMP4sYPJ9x0">Image credit</a>: When was the last time that you built a learning project?</figcaption></figure><h3>Motivation</h3><p>Recently, I came across a<a href="https://sirupsen.com/read/"> blog post</a> written by Simon Hørup Eskildsen on how he approaches reading. It was an inspiring read because I did not know anyone this deliberate about the pursuit of reading. This kind of meticulous, thoughtful, system-level design thinking reminds me of <a href="https://www.principles.com/">Ray Dalio’s Principle</a>:</p><blockquote>Think of yourself as a machine operating within a machine and know that you have the ability to alter your machines to produce better outcomes</blockquote><p>While I do not see myself as a machine, I did examine various aspects of my life and found that I tend to apply this type of thinking more rigorously when it comes to learning. In graduate school, I experimented with various studying strategies to make my day more effective. At work, I have been asked by my coworkers how I managed to find time to pursue learning projects.</p><p>Like many others, I am easily distracted by Netflix and are often bombarded by social media like Twitter and Facebook. Nevertheless, over the years, I have designed a system to make my self-directed learning easier and more effective. In this post, I will share my approach to building technical learning projects, and I hope it will inspire you to design your own as well. If you already have a system that works well for you, I would love to hear it!</p><h3>A Bit of Slope Makes Up For A Lot of Y-Intercept</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*9F4Y91yLWAXOHN4Ff-mdRw.png" /><figcaption><a href="https://unsplash.com/photos/VfUN94cUy4o">image credit</a>: Which slope are you climbing at the moment?</figcaption></figure><p>Before I go into the details of my still-evolving system, it’s useful to first talk about why I even pursue learning projects in the first place. Among my many reasons, the most important one came from Stanford professor<a href="https://web.stanford.edu/~ouster/cgi-bin/home.php"> John Ousterhout</a>. In his “<a href="https://www.quora.com/What-are-the-most-profound-life-lessons-from-Stanford-Professor-John-Ousterhout?share=1">Thoughts for the Weekend</a>” series, Professor Outsterhout once shared with his students a concept called “A little bit of slope makes up for a lot of Y-intercept”.</p><blockquote>If you have two lines, the red line and the blue line, and the red line has a lower Y-intercept but a greater slope […] then eventually the red line will cross the blue line. In a mathematical sense, it’s kind of obvious [a little bit of slope makes up for a lot of Y-intercept].</blockquote><blockquote>I think this is a pretty good guideline for life. What I mean is that how fast you learn is a lot more important than how much you know to begin with. So in general I say that people emphasize too much on how much they know and not how fast they’re learning.</blockquote><p>When I took my first Data Science job in 2012, I barely knew git, SQL, and have never heard the term Data Engineering. I didn’t know how to design good experiments, and I<a href="https://medium.com/@rchang/getting-better-at-machine-learning-16b4dd913a1f"> </a>know very little about Machine Learning beyond math and theory. Arguably, my Y-intercept was pretty low, but I focused on my slope anyway.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*7LhoF1hRs4Ws8xYcIne4Kw.png" /></figure><p>I love this philosophy, because it not only gives me more motivation to keep improving myself, but it also helps me to stay humble when working with less experienced people. We are all working along with our version of the slope, and in the long run, your learning rate is what determines your long-term success.</p><p>In this two-part series, I will talk about various strategies that I adopted along my journey climbing my slope. These include, but are not limited to:</p><ul><li><strong>How to choose a useful learning project</strong></li><li><strong>How to design and iterate on a learning plan</strong></li><li>How to execute on a learning project persistently</li><li>How to internalize my learnings and make it useful for others</li></ul><p>This post, part-I of the series, will explain several criteria I used when it comes to subject picking. Furthermore, I will talk about how to effectively design a learning plan, and explain why it is important to spend time doing so. In Part-II of this series, I will discuss the ingredients of good habits and how to leverage them to learn persistently. Finally, I will discuss why teaching and writing are the best ways to internalize what you have learned.</p><p>Let’s dive right in!</p><h3>1. Choosing a Learning Project</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*FQX_q58GyLogqYhhvuTEyQ.png" /><figcaption><a href="https://unsplash.com/photos/KmGMMxVv0_Q">Image credit</a>: Which learning projects should you choose?</figcaption></figure><p>In an era where learning resources are easily accessible via MOOCs, Youtube, and blog posts, the question is now less about accessibility but more about what subjects to learn. Some advocates to learn what you love until you love learning, others suggest learning skills that can withstand the test of time. My strategy, especially for developing professional skills, is heavily influenced by<a href="http://dilbertblog.typepad.com/the_dilbert_blog/2007/07/career-advice.html"> Scott Adams</a>, the creator of the Dilbert comic strip.</p><blockquote>If you want an average successful life, it doesn’t take much planning. Just stay out of trouble, go to school, and apply for jobs you might like. But if you want something extraordinary, you have two paths:</blockquote><blockquote>1. Become the best at one specific thing.<br>2. Become very good (top 25%) at two or more things.</blockquote><blockquote>The first strategy is difficult to the point of near impossibility. Few people will ever play in the NBA or make a platinum album. I don’t recommend anyone even try. The second strategy is fairly easy. Everyone has at least a few areas in which they could be in the top 25% with some effort […] Capitalism rewards things that are both rare and valuable. You make yourself rare by combining two or more “pretty goods” until no one else has your mix.</blockquote><p>I adopted the second strategy because I enjoy having breath and diversity in my skill sets. As such, I spent a lot of time thinking about what my repertoire of skills should be, and they generally boil down to skills that are foundational, adjacent, and transferable. Let me explain each of them below.</p><h4>Prioritize Foundational Skills</h4><p>In the present world, the rate of technological change is often far too fast for any single person to digest. In a growing field where many people are contributing and competing, there is often an unending streak of new updates and announcements. As an example, in Deep Learning, we often hear debates about which learning framework will be the <em>lingua franca</em> of AI. Many of the technologies in debate today were not even popularized until a few years ago.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*_dpZ4CKk6lSW0BUWQI8fzA.png" /><figcaption>A common mistake for skill building is to focus too much on the tooling and not the workflow underneath it</figcaption></figure><p>With this rate of change, I argue that the ability to use any particular framework or tool is <strong>not</strong> by itself a foundational skill. Instead, it is the <em>workflow patterns</em> that these tools enabled that are foundational. Frameworks and tooling are often useful because they abstract away tedious parts of our workflow, but without knowing why we are following these workflows in the first place, we are simply using the tools mechanically without souls.</p><p>I tried to follow this principle when pursuing my learning projects. For Deep Learning, instead of obsessing over whether to use Keras or PyTorch, I spent most of my time understanding the conceptual difference between shallow models v.s. deep models. I learned why Transfer Learning is a standard workflow in the era of deep modeling, and I investigated why certain embeddings are powerful for different learning tasks. Similarly, when I practiced Data Engineering, I looked beyond Airflow’s simple building blocks such as sensors, operators, and transfers. Instead, I tried to understand the core activities involved in doing good data engineering work — data modeling, backfilling, testing and monitoring, … etc.</p><p>Over time, I learned that by mastering the core concepts associated with a workflow, the mental model one develops can be easily re-applied when picking up new tools and frameworks. This is perhaps why great engineers can typically pick up new languages without too much struggle — they understand the core concepts underneath that are universally foundational.</p><h4>Explore Adjacent Skills</h4><p>Once I feel I have mastered a particular skill, I often expanded it by tapping into <a href="http://www.effectiveengineer.com/blog/master-adjacent-disciplines">adjacent discipline</a>, a term coined by Steven Sinofsky and advocated by Edmond Lau. Accordingly to Steven, adjacent disciplines as those that are immediately to the left or right of your own core expertise. For example, if you are a data scientist, your adjacent disciplines might be Data Engineering or Data Visualization. As a product manager, your adjacent disciplines might be A/B testing or product design. As a musician, your adjacent disciplines might be music composition or music production, so on and so forth.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*WktvV-yPatZddbBBAGgbxg.png" /><figcaption>A few examples of Adjacent disciplines for becoming a <a href="https://blogs.msdn.microsoft.com/techtalk/2005/09/19/the-path-to-gm-some-thoughts-on-becoming-a-general-manager/">GM</a> &amp; <a href="https://mindfulmachines.io/blog/2018/3/17/the-flavors-of-data-science-and-data-engineering">Data Scientist</a></figcaption></figure><p>The first obvious advantage of exploring adjacent skills is that it will make you more self-sufficient on the job. If you are a data scientist who needs a feature pipeline for machine learning, having the skill to build your own ETL pipeline means that you can iterate on feature engineering more efficiently. If you are an analyst who needs to include more dimensional cuts for a report, having the ability to modify table schema can help you to deliver results faster. This is why I believe data scientists who learned <a href="https://medium.com/@rchang/a-beginners-guide-to-data-engineering-part-i-4227c5c457d7">data engineering</a> can usually take on bigger and more ambitious data projects.</p><p>Aside from this first benefit, learning adjacent disciplines often mean your knowledge compounds. Having learned Python and Object-Oriented Programming, these skills enabled me to understand better how different <a href="https://medium.com/@rchang/a-beginners-guide-to-data-engineering-the-series-finale-2cc92ff14b0">Data Engineering frameworks</a> are implemented under the hood. By learning the challenges of building ETL jobs, I can appreciate much better why feature engineering in Machine Learning can be so time-consuming. Adjacent disciplines not only help you to transition into new areas, but it also helps you to connect related knowledge together.</p><p>The last and more subtle advantage of learning adjacent discipline is that it makes you a better cross-functional partner. By understanding the complexities and intricacies of your colleagues’ works, you can better empathize with the challenges that they face on the job.</p><h4>Focus on Transferable Skills</h4><p>A few years ago, I was interested in building a website using Flask and Python. While dabbling into the world of web development, I came across a template engine called<a href="http://jinja.pocoo.org/"> Jinja</a>. I soon learned that it is commonly used by developers because it simplifies writing HTML significantly via control flow and inheritance. I was very impressed by the ingenuity of this template engine at the time, but I never really used it again as a data scientist, not until when I arrived at Airbnb.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*HbedYVY0XqSjq19OkFh7ZA.png" /><figcaption><a href="https://multithreaded.stitchfix.com/blog/2017/07/06/one-weird-trick/">Source</a>: Jinja, originally invented for HTML, can be applied to SQL as well</figcaption></figure><p>At Airbnb, I learned from experienced data engineers that many of the ideas in Jinja can be<a href="https://multithreaded.stitchfix.com/blog/2017/07/06/one-weird-trick/"> applied</a> to Hive queries directly. By leveraging for-loop in Jinja, I can greatly shorten the SELECT statement. By using the if-else control flow, I can incorporate backfilling logic into the same SQL query.</p><p>When thinking about writing HTML and writing SQL, I realize that there’s a lot of similarity between the two activities. Both workflows leverage an expressive language to achieve certain tasks: HTML for rendering web pages, SQL for data computation, so it wasn’t surprising to see that the same technique can be transferred from one domain to another.</p><p>Transferable skills are like superpowers — learned once, and you get to apply it in several places. The initial cost of acquiring those skills might be high, but the variable cost for applying it elsewhere is relatively low. When thinking about what skills to master, focusing on transferable skill.</p><h4>Takeaways</h4><ul><li><strong>Prioritize foundational skills:</strong> you will learn activities associated with a workflow and appreciate how tooling can abstract them away for you</li><li><strong>Explore adjacent disciplines:</strong> you will become more self-sufficient on the job, can take on larger and more ambitious projects, and develop more empathy for your colleagues</li><li><strong>Focus on transferable skills:</strong> you can apply these skills in different domains without much extra costs</li></ul><p>Our society values what’s rare and valuable, and by being selective of what to learn, you are more likely to develop your own <em>mix</em> that is unique and not easily replaceable.</p><h3>2. Designing a Learning Plan</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*VnyMwkgaZuix_CWp2Lau4A.png" /><figcaption><a href="https://unsplash.com/photos/ZSPBhokqDMc">Source</a>: How much time do you spend designing your learning plan before learning something?</figcaption></figure><p>Once you have chosen a specific skill to focus on, the next step is to develop a learning plan. In my opinion, the biggest mind shift here is that you need to treat yourself not only as a student but also as your own teacher. Playing these dual roles can seem a little bit daunting at first, especially if you are used to learning from an authority figure like a teacher or professor.</p><p>However, imagine what a teacher has to do before teaching a course. She has to define learning objectives for her students first. He most likely needs to sample different learning materials and develop a curriculum. Finally, she would need to set milestones to make sure students are held accountable.</p><p>Similarly, as a designer of your learning project, you will also need to go through these exercises to design an effective learning plan. Let us go over each of these activities in more detail.</p><h4>Define Your Learning Objectives</h4><p>One of the mistakes that I made in my earlier learning projects was that I rarely stated upfront what learning objectives I would like to achieve. I dived into one learning project after another haphazardly, with the hope that someday I will apply these skills to some problems — It never happened.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*EqvB-bGuPfPJ4Wu2vV7Z3A.png" /><figcaption>A comparison: (Left) a learning project without clear learning objectives v.s. one that does (Right)</figcaption></figure><p>It does not hurt to be biased to action, but following unguided actions also means you could spend a lot of energy wandering around aimlessly. Reflecting on the lessons learned from earlier failures, I now try to identify one or two learning objectives upfront before diving into a learning project.</p><p>For example, when I pursued my Python learning project, I wrote down the learning objective that I want to eventually converge all my Data Science work from R to Python by the end of the calendar year. When pursuing my Deep Learning project, I set the goal to understand how Airbnb’s<a href="https://www.youtube.com/watch?v=tPb2u9kwh2w"> room classification model</a> works under the hood. The key here is to set concrete, time-bounded, measurable goals. i.e. I can check exactly if I have achieved what I set out to do by a specific deadline.</p><p>For technical learning projects that are aimed to improve my professional skills, my learning objectives usually revolve around:</p><ul><li>adopting or making a specific change in how I work</li><li>achieving a better understanding of a problem or solution, or</li><li>generating learning materials that can be consumed by others</li></ul><p>I will talk more about generating public work in Part-II of this series.</p><h4>Identify Project Milestones</h4><p>If your learning objective is relatively ambitious, then it is important to break down your learning objectives into tangible and achievable milestones. This “divide and conquer” approach has proven to be very effective for me.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*v1XLd2xIrlKHrD257ZEYoA.png" /><figcaption>Source: A truncated list of project milestones that I defined for my Flask learning project (see the full list <a href="https://github.com/robert8138/flask-google-calendar-api-project">here</a>)</figcaption></figure><p>As a concrete example, for my Flask learning project, I defined a learning objective to deploy a website that will render my Google calendar time logs in an interactive<a href="https://d3js.org/"> d3</a> visualization. I identified specific milestones for this goal: from reading the<a href="https://developers.google.com/calendar/"> Google Calendar API</a>, pulling and storing my data in a local database, to finally rendering the data in a d3 visualization. After completing many small milestones, I finally built a website that did exactly what I set out to you. I still remember the day when I rendered all the data on a heat map, it was magical!</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*PNsNIyM4duQKx7Umrd7V8A.png" /><figcaption>Without setting project milestones, I might have never been able to build this beautiful heap map!</figcaption></figure><h4>Develop a Curriculum</h4><p>In my experience, one of the most important but under-appreciated skills in learning is the ability to identify materials that are accessible and approachable to your learning patterns. For most of my learning projects, I usually spent about 2–3 weeks sampling materials until I develop a curriculum that I feel excited about. This is the period where I would browse the internet to identify any free or paid materials that are relevant to my topic — be it blog posts, online courses, books, or the like. I typically do this by creating a<a href="https://help.github.com/en/articles/create-a-repo"> new github repository</a> to keep track of all the materials that I find relevant, and slowly organize them into something more structured like below:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*uDgHRwEhNav5WCP5E7TiDw.png" /><figcaption><a href="https://github.com/robert8138/deep-learning-deliberate-practice">Source</a>: Curriculum that I built for my Deep Learning project. You can find my Python one <a href="https://github.com/robert8138/python-deliberate-practice">here</a>.</figcaption></figure><p>There are two reasons why sampling and developing your curriculum is important. First, without a very strong mental model, it is hard to know exactly what are the important concepts to learn. By standing on the shoulders of people who understand the materials very well, you will start to see the same core concepts emerging again and again. In my opinion, this is the first step toward understanding.</p><p>The second reason is that as a life-long student, you are no longer constrained by the textbook or teaching style of any single teacher. Depending on your background, you might want to mix and match between different learning materials that help you learn better. Over and over again, I have seen how the same concept can be explained horribly but also articulately, and it makes a world of a difference. It’s up to you to find the resources that resonant with your learning patterns.</p><p>As an example, during my Deep Learning project, I simultaneously sample materials from Stanford’s <a href="http://cs231n.stanford.edu/">on-campus course</a>, Coursera’s <a href="https://www.coursera.org/specializations/deep-learning">Deep Learning specialization</a>, and a<a href="http://fast.ai"> fast.ai</a> course. I generally find Coursera’s material great for developing intuition at first, but almost always gravitated toward the Stanford course because I want to understand the math better. Furthermore, to practice with more hands-on exercise, I would usually go to the<a href="http://fast.ai"> fast.ai</a> course, where notebooks and code examples are abundantly available. It was quite common that I would study the same subject using three different materials in a given week.</p><p>One final note, if you are not yet confident in your ability to source your own learning materials, be sure to solicit feedback from friends or coworkers who are knowledgeable on the subject. This is a good way to make sure your curriculum has covered all the basic grounds.</p><h4>Takeaways</h4><p>When it comes to self-directed learning, it is very important to design a learning plan. This includes:</p><ul><li><strong>Define your learning objectives</strong>: set clear goals on what behaviors or outcomes you would like to achieve</li><li><strong>Identify project milestones</strong>: divide and conquer so you can make steady progress without getting intimidated</li><li><strong>Develop a curriculum:</strong> find materials that you would enjoy according to your learning patterns. Consult experts to validate your curriculum</li></ul><p>By the end of this design process, you would have a pretty solid learning plan, and that’s really half of the job done! The common mistake is that people generally do not spend enough time in this step.</p><h3>Conclusion</h3><p>Even if you have a strong desire to learn, it often still feels like a struggle to balance between self-directed learning and other important life priorities, just think about all the responsibilities, obligations, and distractions in life!</p><p>Without a system, chances are, we will not achieve our goals. In this post, I shared my approach to choosing and building a learning project, using my previous successes and failures. I hope by sharing some of my learnings, you will be inspire to design your own learning methods.</p><p>In the next post, I will talk about how to make steady progress on a learning project, and how to internalize your learnings by teaching others and producing public artifacts.</p><p>Happy learning!</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=54dbaad68961" width="1" height="1" alt="">]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[So You Want Become a Data Science Manager?]]></title>
            <link>https://medium.com/deliberate-data-science/so-you-want-become-a-data-science-manager-4ff9544e6827?source=rss-c00b242128fe------2</link>
            <guid isPermaLink="false">https://medium.com/p/4ff9544e6827</guid>
            <category><![CDATA[data-science]]></category>
            <category><![CDATA[careers]]></category>
            <category><![CDATA[software-development]]></category>
            <category><![CDATA[analytics]]></category>
            <category><![CDATA[leadership]]></category>
            <dc:creator><![CDATA[Robert Chang]]></dc:creator>
            <pubDate>Thu, 21 Feb 2019 04:01:00 GMT</pubDate>
            <atom:updated>2019-02-22T06:01:16.003Z</atom:updated>
            <content:encoded><![CDATA[<h3>So You Want to Become a Data Science Manager?</h3><h4>How to think about the IC to Management transition</h4><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*t5x4yrbKc8Tyd24GHQ8w3g.png" /></figure><h3><strong>Motivation</strong></h3><p>I recently came across a great book called “<a href="https://www.amazon.com/Managers-Path-Leaders-Navigating-Growth-ebook/dp/B06XP3GJ7F/ref=as_li_ss_tl?s=books&amp;ie=UTF8&amp;qid=1515860472&amp;sr=1-1&amp;keywords=manager%27s+path&amp;linkCode=sl1&amp;tag=elidebranc-20&amp;linkId=1debd573dbbe4189ff620dff2885a518">The Manager’s Path</a>”, written by <a href="https://medium.com/@skamille">Camille Fournier</a>. In this book, Camille describes the possible career paths of a technical individual contributor (IC) as one continues to grow in her career. I find this book illuminating because it touches on a rather common topic in the tech industry — “Should I transition from IC track to management track? If so, when is the right time?”. If you have been working as an IC for the past few years, chances are, you have pondered on this question already.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*IEDgCjTa-oVlhUw4" /><figcaption>Image Credit (me): Typical career paths in tech</figcaption></figure><p>Given that this topic is discussed so extensively in engineering (see<a href="http://www.camilletalk.com/whilefalse/2015/11/truth-and-consequences-of-technical.html"> here</a>,<a href="https://charity.wtf/2017/05/11/the-engineer-manager-pendulum/"> here</a>, and<a href="https://charity.wtf/2019/01/04/engineering-management-the-pendulum-or-the-ladder/"> here</a>) and design (see<a href="https://medium.com/the-year-of-the-looking-glass/unintuitive-things-i-ve-learned-about-management-f2c42d68604b"> here</a>,<a href="https://medium.com/the-year-of-the-looking-glass/unintuitive-things-i-ve-learned-about-management-part-2-7c22fc9d87ed"> here</a>, and<a href="https://medium.com/the-year-of-the-looking-glass/managing-more-experienced-people-9893f9903649"> here</a>), you would think it is all figured out by now. However, for a field as new as data science, I haven’t seen a whole lot of discussions about this topic just yet. After working in the field for more than half a decade, I have developed my own perspectives on how to think about this topic, so here we go!</p><h3><strong>First, My Experience</strong></h3><p>I am not a data science manager, nor have I ever been one. During the past six years of my data science career, I have definitely considered becoming one, and have even been encouraged to. However, like any other important career decision, I am always convinced that this transition, if made, should be a deliberate one. Far too often, I have seen ICs turned managers for the wrong reasons, which made them and their teams suffer.</p><p>Recently, I worked with our data science leadership team to build the first data science tech lead pilot at Airbnb. Through various discussions with ICs and managers, we debated the pros and cons of staying on the IC track v.s. going into management. These conversations not only helped me to launch the pilot but also helped me to contextualize some of my own, often implicit, preferences.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/960/0*FlgYMcHfDTPdBukw.jpg" /></figure><p>On the one hand, I have always aspired to become a hands-on data scientist, and enjoy doing so from the trenches. On the other hand, I sometimes experience the challenge and inertia of <a href="https://writing.jeanhsu.com/how-do-you-become-a-leader-without-explicit-authority-f0c5001d864b">leading without authority</a>. Some people say that there’s diminishing returns for remaining as an IC for too long, and other managers have lamented how far they are drifted away from technical work. While all of these might ring true, I wanted to dig deeper to my inner compass.</p><h3><strong>The Framework From The Book “Drive”</strong></h3><p>A few years ago, I came across Daniel Pink’s bestselling book “<a href="https://www.youtube.com/watch?v=u6XAPnuFjJc">Drive: The surprising truth of what motivates us</a>“. In his book, Daniel talked about three important ingredients that make our works motivating:</p><ul><li><strong>Purpose: </strong>the goal to do something meaningful</li><li><strong>Mastery: </strong>the urge to get better at stuff</li><li><strong>Autonomy: </strong>the desire to be self-directed</li></ul><p>Since then, I have been using his framework for evaluating projects, jobs, or more generally career opportunities. In the next couple of sections, I will again use this framework to talk about the pros and cons of being an IC v.s. becoming a manager.</p><h4><strong>Purpose</strong></h4><p>In a well-run startup, everyone knows exactly what the company is trying to achieve — the cost of communication is low, and decisions are made swiftly. As the company continues to grow, communication and decision making become more localized, and misalignments could occur among people who do not communicate effectively. This is why we often hear the phrase “the first casualty of growth is communication”.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*QSU-Ocip2c39aRFK6OpOIg.png" /><figcaption><a href="https://pixabay.com/en/chairs-series-sit-row-hall-event-2593531/">Image Source</a>: A manager’s primary responsibility is to build alignment</figcaption></figure><p>In a sufficiently large company, the purpose of managers is to clearly understand the goals of the company and consistently reinforce the company’s vision in order to align teams and individuals to work toward that vision in a fulfilling way. Very different from the role of an IC, a manager’s responsibility is to synthesize information, to provide context, creating the right environment, and do so consistently to create trust.</p><p>As described in Julie Zhou’s “<a href="https://medium.com/the-year-of-the-looking-glass/unintuitive-things-i-ve-learned-about-management-part-2-7c22fc9d87ed">Unintuitive Things I learned About Management</a>”, one of the unintuitive things she learned as a manager is that it’s a lot more important to focus on the “<em>why are we doing X?</em>” rather than “<em>how are we going to execute on X?”</em>. The “why” is built on information sharing, trust, and alignment.</p><p>This is why <strong>management is a career change, not a promotion</strong> (see <a href="https://charity.wtf/2019/01/04/engineering-management-the-pendulum-or-the-ladder/">here</a>). If you are ready to serve the mission by amplifying others, by coordinating with partners, and living by the company’s vision, then the managerial path might be a great fit for you. If not, then you should think carefully if you are serving the right purpose.</p><h4>Mastery</h4><p>This leap and transition from IC to management track is far greater than just a title change. It’s a fundamental shift of one’s core identity and how one functions. Your technical skill is no longer your most valuable currency, trust is. Code is no longer what you produce, it is relationships. Finally, be prepared to spend a lot of time talking, meeting, and writing Google docs with other people.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*ykoL5gAfu9pKopfjJc8GZw.png" /><figcaption><a href="https://pixabay.com/en/adult-artisan-tools-workshop-1866533/">Image Source</a>: Want to become a manager? Time to learn new skills</figcaption></figure><p>To adapt to this new reality, you need to develop soft skills with a higher bar — communication, active listening, empathy, … etc. Many ICs, especially the most effective ones, find this transition challenging, because getting better at these skills is often a lot more amorphous than say, writing more code or conducting more rigorous analyses. The path of mastery is fundamentally different.</p><p>In addition to learning new skills, you have to learn how to let go of skills that you have already mastered. You need to know how to delegate effectively and not spend too much time dwelling on execution. If you cannot change this mindset, you severely limit the potential of your team and their output. Paradoxically, the right behavior of a good manager is not to try to be the most technical person in the room.</p><p>When you learn new skills, you put other skills in the background. This is natural given the shift of focus. Having said that, this combination of needing to let go of the skills you have already mastered and expanding new skills beyond your comfort zone is a bitter pill to swallow. But, if you are ready to embrace new challenges, this can be an incredible opportunity building foundational and transferable skills.</p><h4>Autonomy</h4><p>Finally, as a manager, your schedule will also look fundamentally different. On this topic, I found Paul Graham’s essay “<a href="http://www.paulgraham.com/makersschedule.html">Maker’s Schedule, Manager’s Schedule</a>” extremely relevant. Paul explains that “makers” need concentrated and uninterrupted time to create, usually in half-day chunks. Managers, on the other hand, typically jump in between meetings in hourly chunks.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*2OH-ZPebWQvKaH4zZTzfmg.png" /><figcaption><a href="https://pixabay.com/en/time-timer-clock-watch-hour-371226/">Image Source</a>: Are you on maker’s schedule or manager’s schedule?</figcaption></figure><p>As a manager, you largely need to keep your calendar open so you could have 1:1s, context sharing, communication, alignment, or even fire fighting. This schedule is a pretty big departure from what ICs are used to, and mixing the two schedules can lead to very poor productivity.</p><p>If you are someone who deeply subscribed to the philosophy of<a href="http://calnewport.com/books/deep-work/"> deep work</a>, you probably strongly prefer the maker’s schedule. As a manager, you need to be more creative and creating the equivalent of deep working time for yourself. I have heard stories of how CEOs of large companies typically block off time so they can “think”. Deep work in the context of managerial work is possible, but you need to create that space for yourself.</p><h3><strong>The Concept of a Tour of Duty</strong></h3><p>Reid Hoffman, cofounder of LinkedIn, proposed the concept of a <strong>Tour of Duty</strong> in his 2014 book “<a href="http://www.theallianceframework.com/">The Alliance</a>”. He characterizes a tour of duty as: <em>a commitment by the employer and employee to a specific mission of finite duration.</em> Transitioning to management, unarguably, will be a big shift, but I think when looking through the lens of the concept of a tour of duty, it is actually quite liberating.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*R_cOrUJ5M77VdGha0XWhIQ.png" /><figcaption><a href="https://pixabay.com/en/parachute-skydiving-parachuting-658397/">Image Source</a>: Are you ready to jump right into your next Tour of Duty?</figcaption></figure><p>For young working professionals (myself included), your first rodeo in management does not need to be a permanent one. A much healthier and liberating way to look at this transition is to think of it as a tour of duty. Think of it as a mission that is tailored for you in which you can learn orthogonal skills that are different from the technical skills you already have, and think of it as another way for you to provide value to the organization.</p><p>As you approach the end of the tour, you can work with your manager to analyze if such a tour is the right fit for you and for the company. It might not work out for you, but even then you have eliminate this career path, which is very useful for career planning. But if you do like it, new doors are opened for you.</p><h3><strong>Summary, Not Conclusion</strong></h3><p>It is probably clear by now that I am not being very prescriptive in this post (I myself am still trying to figure out). The lesson I am trying to preach, perhaps, is to recognize that your goals and aspirations will change over time, and that’s completely normal. The important thing is to make deliberate and informed choices that are aligned with your inner compass as transitions are made, and think from first principles on why you want what you want. It’s hard, but it’s worth trying.</p><p>Are you ready to become a data science manager?</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=4ff9544e6827" width="1" height="1" alt=""><hr><p><a href="https://medium.com/deliberate-data-science/so-you-want-become-a-data-science-manager-4ff9544e6827">So You Want Become a Data Science Manager?</a> was originally published in <a href="https://medium.com/deliberate-data-science">Deliberate Data Science</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Getting Better at Machine Learning]]></title>
            <link>https://medium.com/@rchang/getting-better-at-machine-learning-16b4dd913a1f?source=rss-c00b242128fe------2</link>
            <guid isPermaLink="false">https://medium.com/p/16b4dd913a1f</guid>
            <category><![CDATA[data-science]]></category>
            <category><![CDATA[machine-learning]]></category>
            <dc:creator><![CDATA[Robert Chang]]></dc:creator>
            <pubDate>Wed, 26 Sep 2018 02:53:41 GMT</pubDate>
            <atom:updated>2018-09-26T02:53:41.623Z</atom:updated>
            <content:encoded><![CDATA[<h4>Moving Beyond model.fit(X, y)</h4><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*CA_RgxCdZz2ptWmzGaqdpg.png" /><figcaption><a href="https://pixabay.com/en/spot-runs-start-la-stadion-862274/">Image credit</a>: Getting better at machine learning takes time, effort, and practice!</figcaption></figure><h3><strong>Motivation</strong></h3><p>In <a href="https://medium.com/@rchang/a-beginners-guide-to-data-engineering-part-i-4227c5c457d7">A Beginner’s Guide to Data Engineering</a> series, I argued that academic institutions typically do not teach students the proper <em>mental models</em><strong> </strong>when it comes to analytics workflows in real-life. Far too many classes only focus on the mechanics of data analysis without teaching concepts such as ETL or the importance of building robust data pipelines. Unfortunately, I see a similar pattern in machine learning education as well. Surely, studying the <a href="https://blog.ycombinator.com/learning-math-for-machine-learning/">math behind ML</a> and learning <a href="http://scikit-learn.org/stable/tutorial/machine_learning_map/index.html">different algorithms</a> are valuable. Yet, there exist crucial steps beyond model.fit(X, y) that are important in practice. In this post, I will share some of my learnings that I did not learn in school.</p><p>First, I will highlight the rise of Kaggle: why it has transformed our industry, what critical role it plays, but also where it fell short. In particular, I will contrast the workflow Kaggle reinforced with the typical development workflow of a real-life machine learning project. Throughout the post, I will give coloring examples around topics such as problem definition, feature engineering, model debugging, productionization, and feedback loops. By the end of this post, I hope readers will appreciate some of the complexity and challenges, but also joys, of real-life machine learning.</p><h3>The Rise of Kaggle Competition</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*O2jevBVe3vpYGdryMDWEmA.png" /><figcaption>Kaggle’s <a href="https://www.kaggle.com/challenge-yourself">Competition Landing Page</a>: Fancy to Join one?</figcaption></figure><p>Ever since its inception in 2010, <a href="https://www.kaggle.com/">Kaggle</a> has become the platform where data enthusiasts around the world compete to solve a wide variety of problems using machine learning. Over time, Kaggle has built an incredible repository of useful benchmark datasets and example notebooks (called <a href="https://www.kaggle.com/kernels">kernels</a>), turned modeling into a sport, and made some practitioners into Kaggle <a href="https://www.wired.com/story/solve-these-tough-data-problems-and-watch-job-offers-roll-in/">stars</a>.</p><h4>Common Task Framework</h4><p>The model that Kaggle follows, is what Professor David Donoho referred to as the <em>Common Task Framework</em> (CTF) in his paper “<a href="https://courses.csail.mit.edu/18.337/2015/docs/50YearsDataScience.pdf">50 years of Data Science</a>”. Donoho argued that the secret sauce to machine learning’s success is partially driven by competitions:</p><blockquote>It is no exaggeration to say that the combination of a predictive modeling culture together with CTF is the ‘secret sauce’ of machine learning. This combination leads directly to a total focus on optimization of empirical performance, which […] allows large numbers of researchers to compete at any given common task challenge, and allows for efficient […] judging of challenge winners.</blockquote><p>Indeed, from DARPA’s machine translation research in the 1980s, the famous 2009 <a href="https://www.netflixprize.com/">Netflix Prize</a>, to the recent success of deep learning due to <a href="http://www.image-net.org/challenges/LSVRC/">ImageNet</a> challenge, the machine learning community continues to bring innovation to the mass under common task framework.</p><h4>Where Kaggle Competition Fall Short</h4><p>While Kaggle competitions have been tremendously educational, their workflows generally only reflect a small subset of what is involved in real-life machine learning projects. First of all, Kaggle hosts formulate the problems, not the participants. Not only are the loss functions and golden datasets used for evaluation pre-determined, but training labels / data are often handed to the participants on a silver platter. Furthermore, there is very little concern regarding how to integrate models into a decision process or a product. These are all conditions real projects are unlikely to meet in practice. As a result, a lot of the considerations in machine learning projects are lost in translation.</p><h3>Machine Learning Workflow</h3><p>When building a machine learning product, we are no longer developing <em>models </em>in isolation (what people sometimes called “<strong>Laptop Data Science</strong>”). Rather, we are building a <em>system </em>that interacts with real human beings. Not only do we need to think strategically about the problems we are solving for the end users, but we also need to ensure that the user experience is intuitive, predictions are accurate, and inference is efficient.</p><h4>Think and Build a System End-to-End</h4><p>These conditions mean that we almost never jump to modeling immediately, we have to think and build the <em>system</em> end-to-end. In Rachel Thomas’ fantastic post “<a href="http://www.fast.ai/2018/07/12/auto-ml-1/">What do machine learning practitioners actually do?</a>”, she explains the typical workflow of a machine learning project:</p><blockquote>Building a machine learning product is a multi-faceted and complex task […] machine learning practitioners may need to do during the process: <strong>understanding the context, preparing the data, building the model, productionization, </strong>and<strong> monitoring. </strong>[…] Certainly, not every machine learning practitioner needs to do all of the above steps, but components of this process will be a part of many machine learning applications.</blockquote><p>Kaggle is an amazing platform that focuses on model building, but less so on the rest of the steps described above. To help readers to better understand these other topics, I will highlight them using a combination of my personal experience and illuminating examples from other companies that I find useful. Below, I will discuss:</p><ul><li><strong>Problem Definition</strong>: why thinking hard about your problem is crucial</li><li><strong>Data Collection: </strong>why setting up your {X, y} right is half of the job done</li><li><strong>Model Building:</strong> how to debug your model when it does not perform well</li><li><strong>Productionization:</strong> what “putting model into production” really means</li><li><strong>Feedback Loop: </strong>how unintended feedback loop can affect your system</li></ul><h3>1. Defining Problem Is Hard and Not Always Obvious</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*VE8tyll3F_D__s0804H5_g.png" /><figcaption><a href="https://pixabay.com/en/architecture-house-3d-design-1477041/">Image source</a>: Do you think this house can be an Airbnb Plus Home?</figcaption></figure><p>Let’s start with a case study, <a href="https://www.airbnb.com/plus">Airbnb Plus</a>, a product whose mission is to bring high-quality homes to the Airbnb marketplace. While many employees are passionate about finding homes suitable for Plus, doing this at scale can be challenging. On our team, we use a combination of human evaluation and machine learning to identify high potential homes. This type of problem, which involves human evaluations + machine predictions, are becoming increasingly <a href="https://www.slideshare.net/EricColson/blending-human-computing-and-recommender-systems-for-personalized-style-recommendations?ref=https://www.linkedin.com/in/ecolson/detail/treasury/position:283490153/?entityUrn=urn%3Ali%3Afs_treasuryMedia%3A(ACoAAAAgRpcBysMEEbZcn2KCJyUlezpKXYs2nYs%2C50371553)&amp;section=position%3A283490153&amp;treasuryCount=3">common</a>.</p><h4>Your First Iteration of the Model Is Often Not Your Last</h4><p>As our human evaluators assess homes, training labels are generated as a by-product. Given that we already have a lot of features about a listing (price, bookings, reviews … etc), it was rather convenient to combine the two data sources (labels + features) to train our first home targeting model. At first, this approach worked well, and it brought enormous gains to our efficiency.</p><p>However, as the product continued to evolve, we started to experience the limitation of this simple approach. Specifically, as we evolved what <a href="https://www.airbnb.com/plus/host/requirements">qualifies</a> a home to be “Plus” at the program level, the semantic meanings of our outcome labels had also changed. This business evolution posed non-trivial challenges to our learning task because our labels can become outdated rather quickly. We were essentially learning to predict a moving target!</p><h4>Decomposing the Learning Task Requires Thinking</h4><p>To de-risk our modeling effort, we had to re-think the problem formulation. Eventually, we decided to decompose our single, monolithic learning task into several independent modular tasks. This means that instead of directly classifying whether a listing is high potential or not, we focused on predicting more stable attributes that are indicative of high-quality. For example, instead of classifying the label is_home_high_potential directly, we framed the problem as is_home_high_potential = <strong>f</strong>(style, design, ...) , where <strong>f</strong> is our rule-based approach to codify how humans might use these modular predictions to make a final assessment.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*Oe5ojwhM6-YH4BXpCqFXzA.png" /><figcaption><a href="https://pixabay.com/en/hand-rubik-cube-puzzle-game-2208491/">Image credit</a>: It’s useful to decompose a learning task into smaller tasks when the label is not straightforward</figcaption></figure><p>More often than not, problem formulation requires deep domain knowledge, the ability to decompose problems, and a lot of patience. The most convenient training dataset should not drive how we formulate the problem, rather it should be the other way around. This is an important first skill to becoming an effective problem solver in machine learning.</p><p><strong>Takeaway:</strong> <em>Like software engineering, the principle of decomposition can be very important in machine learning as well. It allows us to break a complex problem or system into parts that are easier to conceive, understand, and learn.</em></p><h3>2. Data Collection Is Often Non-trivial</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*1BuvNymrXVgV6GC6MN6mTg.png" /><figcaption><a href="https://pixabay.com/en/assortment-box-collection-container-1868297/">Image source</a>: Data collection for machine learning is analogous to picking ingredients before cooking a great dish</figcaption></figure><p>At work, our data scientists and ML engineers often get together to talk about machine learning ideas passionately. While these discussions are always inspirational, they generally do not translate to project roadmaps immediately due to a common blocker — <em>lack of training labels and feature pipelines.</em></p><h4>Acquiring Quality Labels Is Challenging</h4><p>On Airbnb Plus, we are lucky to have training labels generated as a by-product from our home assessments, but dedicated labelings are often rare because collecting them comes with a hefty time and monetary cost. In the absence of actual training labels, we could use other data as proxies for training labels, but they are not always high fidelity.</p><p>For example, when Airbnb developed its <a href="https://medium.com/airbnb-engineering/categorizing-listing-photos-at-airbnb-f9483f3ab7e3">room classification</a> model, we used image captions as our proxy label for the ground truth. While this approach gave us convenient labels as a head start, the label quality tends to be low for certain room types, especially for smaller spaces. For instance, scenes in a studio tend to be crammed together: a kitchen could be right next to a living room that is adjacent to a bedroom. This makes evaluation of ground truth hard to interpret, sometimes even in the eyes of human labelers.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*98FN1KxORE2kehrC_FgZ2w.png" /><figcaption><a href="http://www.home-designing.com/5-beautiful-studio-apartments">Image source</a>: Should we label the room type of this image as a kitchen or a bedroom?</figcaption></figure><p>In general, labeling in real-life is far trickier than simple tasks like telling apart hotdogs v.s. non-hotdogs. This nuance often makes <a href="https://en.wikipedia.org/wiki/Inter-rater_reliability">inter-rater agreement</a> hard to achieve, and is rather universal for serious modeling pursuits across different domains. Andrej Karpathy, in his talk <a href="https://www.figure-eight.com/building-the-software-2-0-stack-by-andrej-karpathy-from-tesla/">building the software 2.0 stack</a>, highlights some of Tesla’s labeling challenges for building self-driving cars. For example, he explains that labeling traffic lights and traffic lanes can sound simple but in reality difficult because the diversity of how different cities design the roads. More generally, he argues that in the <a href="https://medium.com/@karpathy/software-2-0-a64152b37c35">software 2.0</a> world, we have not yet figure out the right IDEs or labeling tools to build software. These are all real data challenges that are not taught in school.</p><h4>Building Feature Pipelines Is Time Consuming</h4><p>Even when we have high quality labels, building feature pipelines can be a tedious and time-consuming process. For the model described in the previous section, we were lucky to re-use some of the listing-level features from another <a href="https://medium.com/airbnb-engineering/using-machine-learning-to-predict-value-of-homes-on-airbnb-9272d3d4739d">existing project</a>. For problems that involved images as input, the feature engineering work is a lot more complex.</p><p>For example, before our room classification model, there was no image pipeline in place on our team that could be reused. A lot of data engineering work, from data ingestion, resizing images to size 224 x 224, using base64 encoding to storing thumbnails were required before we could build image models. Had this image pipeline not been in place, it would have slowed down a lot of our modeling work significantly. This is precisely why larger companies are building frameworks to make feature engineering easier (see Uber’s <a href="https://eng.uber.com/michelangelo/">Michelangelo</a>, Netflix’s <a href="https://medium.com/netflix-techblog/distributed-time-travel-for-feature-generation-389cccdd3907">Delorean</a>, and Airbnb’s <a href="https://vimeo.com/274397629">Zipline</a>). When planning ML projects, it is always wise to budget time for feature engineering, because training data will not be handed to you on a silver platter.</p><p><strong>Takeaway:</strong> <em>You need to work hard to get your training data, it is often earned rather than given. Acquiring high-quality labels can be non-trivial, and building feature pipelines can be time-consuming. To the extent you can, reuse common features or even labels to solve similar problems in the same domain space.</em></p><h3>3. Debugging and Improving ML Models is Hard</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*PsfnGDdDLrAKjSbpAlcfPg.png" /><figcaption><a href="https://pixabay.com/en/hacking-cyber-blackandwhite-crime-2903156/">Image source</a>: Debugging machine learning models can be a lonely pursuit</figcaption></figure><p>Suppose you have gone through the steps of defining a problem, acquiring labels and building a feature pipeline, you then moved on to build your first iteration of the model only to learn that the result is not so stellar. What would you do in this case to debug and improve your model?</p><h4>Debugging Machine Learning Is Hard</h4><p>The scenario described above is very common and is at the heart of any machine learning project. In his post “<a href="http://ai.stanford.edu/~zayd/why-is-machine-learning-hard.html">Why is Machine Learning Hard?</a>”, Zayd Enam pointed out that machine learning is fundamentally a hard debugging problem because there are many possible paths of exploration and unfortunately the feedback loop is generally very slow.</p><blockquote>Debugging for machine learning happens in two cases: 1) <strong>your algorithm doesn’t work</strong>, or 2) <strong>your algorithm doesn’t work <em>well enough</em>.</strong></blockquote><blockquote>What is unique about machine learning is that it is ‘exponentially’ harder to figure out what is wrong […]. There is often a delay in debugging cycles between implementing a fix or upgrade and seeing the result. Very rarely does an algorithm work the first time and so this ends up being where the time is spent.</blockquote><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*2pP9xcrdl1iKXHvL2n7iqw.png" /><figcaption><a href="http://ai.stanford.edu/~zayd/why-is-machine-learning-hard.html">Image source</a>: Debugging ML models are often slow and convoluted</figcaption></figure><p>Debugging machine learning is a skill, and far too often we just try the most immediate, convenient, or “obvious” thing even though it might not be the right first thing to try. Of all the resources out there, I particularly appreciate Andrew Ng’s book <a href="http://www.mlyearning.org/">Machine Learning Yearning</a>. This approachable reference is very practical and he talks about things that I wish I had known way earlier!</p><h4>Some Basic Debugging Skills</h4><p>While I highly recommend everyone to read Andrew’s book, for the impatient, I will highlight a few tricks that I personally found to be useful in practice:</p><ul><li><strong>Error Analysis: </strong>Learn from your model’s mistake. Specifically, hand picks 100 examples that your model got wrong from the development set and tally up the reasons why it got wrong. This can help you inspire new directions and prioritize improvement plans.</li></ul><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*H0YnmAehpVPMZZ8-IJepoA.png" /><figcaption><a href="http://www.mlyearning.org/">Image Source</a>: For a dog v.s. cat classifier, look at 100 misclassified examples and tally up the reasons</figcaption></figure><p>Error analysis is important because it gives you a very data-informed view of why your model is not performing well. This is something that I used to avoid doing because of its tedious nature, but over time have really come to embrace it as it gives me a lot of insight about the data and my models’ behavior.</p><ul><li><a href="http://scott.fortmann-roe.com/docs/BiasVariance.html"><strong>Understand Bias-Variance</strong></a><strong>: </strong>There are two major sources of error in machine learning: bias and variance. High bias often means that your model is too simple to capture the complexity of the data, and high variance indicates that you have only learned the pattern at hand. To understand bias and variance in your models, the most effective debugging tool here is to plot the <a href="http://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html">learning curve</a>.</li></ul><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*E3fkaAqcZLuuxkwM7JQAmQ.png" /><figcaption><a href="http://www.mlyearning.org/">Image Source</a>: Use the learning curve to understand if you are overfitting or underfitting</figcaption></figure><p>When both your training error and development set error are way higher than the desired performance, you are suffering from a <strong>high bias</strong> problem (under-fitting). In such a case, increasing your model capacity or switching to a more complex algorithm is likely to help you to learn the patterns better.</p><p>On the other hand, when your development set error is way higher than the training error, while the training error is relatively close to the desired performance, you are suffering the <strong>high variance</strong> problem (over-fitting). In such a case, you might want to try a simpler model, or use <a href="https://en.wikipedia.org/wiki/Regularization_(mathematics)">regularization</a>. Alternatively, if the gap between training and development error is closing with more training examples, you might consider adding more training data to your learning task.</p><p><strong>Takeaway: </strong><em>debugging machine learning is hard and the feedback loop is generally slow. Instead of tackling what you think is the next obvious thing, it’s important to be more principled about debugging. Error analysis, learning curve are all good starts, and I strongly encourage you to read Andrew’s </em><a href="http://www.mlyearning.org/"><em>Machine Learning Yearnin</em></a><em>g to improve your debugging skill.</em></p><h3>4. Your Paths to Model Productionization Might Vary</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*f0nBNfi-c86Rz9pTYT66nQ.png" /><figcaption><a href="https://pixabay.com/en/industry-lost-places-factory-1801661/">Image source</a>: Model productionization has been talked about a lot, but what exactly does it mean?</figcaption></figure><p>Assuming that you now have a satisfactory model to deploy, it is time to integrate your model into a decision process or product. This is what we refer to as model productionization. But what exactly does it mean? The answer depends on your use cases. Sometimes, the predictions will live outside of products completely and will be used only for strategic or business decisions. Other times, they will be an integrated part of a product experience.</p><h4>Not Everything is Low Latency &amp; Context Sensitive</h4><p>The most useful framework I learned about this topic came from <a href="https://twitter.com/sharathrao?lang=en">Sharath Rao</a>, who currently leads machine learning efforts for consumer products at Instacart. In his <a href="https://www.youtube.com/watch?v=wG5EyHYrJGE&amp;t=854s">DataEngConf</a> talk, Sharath explains that implementation of machine learning models can usually be considered from two<strong> </strong>dimensions:</p><ul><li><strong>Latency: </strong><em>How fast do the predictions need to be served to the end users?</em></li><li><strong>Context Sensitivity: </strong><em>Will we know the features ahead of inference time?</em></li></ul><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*Kukn5JLFNZztpAjJOy2obg.png" /><figcaption><a href="https://www.slideshare.net/SharathRao6/lessons-from-integrating-machine-learning-models-into-data-products/22">Image source</a>: Sharath Rao’s talk, “lessons from integrating ML models into data products”</figcaption></figure><p>In the simplest case (bottom-left), for applications where predictions are mostly used for offline decisions, the model can be productionized simply as a batch scoring job. On the other hand, for models that are an integrated part of a product experience, e.g. search ranking, input features are generally not available until a user interacts with the product, and results often need to be returned really fast. In this case (top-right), online inference or real-time scoring is needed and <a href="https://en.wikipedia.org/wiki/Service-level_agreement">SLA</a> requirements are generally higher. Knowing the profile of your ML model can directly inform your implementation strategy.</p><h4>Revenue Prediction Model, Illustrated in Multiple Use Cases</h4><p>Let’s use the listing LTV model that I introduced earlier as an illustrative example. Suppose we are interested in using this model to prioritize markets to go after next year. Such an application is not consumer-facing, and we are only using the predictions for offline decision making, not in an online product. For this use case, we only need to productionize the model as an offline training, offline scoring, batch job so other data scientists can easily query the predictions from a table.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*Uwwzj9Xct-3T1y-iU9oCcA.png" /><figcaption><a href="https://www.airbnb.com/host/homes">Image source</a>: How should we productionize the ML model for such a product use case?</figcaption></figure><p>However, suppose we are now interested in showcasing the predicted host payouts in a consumer-facing product in order to inform users their financial potentials. One challenge we need to consider is how to surface the predictions within a product.</p><p>In the case where contextual data is not needed, one common strategy is to store the model results as key-value pairs in a key-value store, e.g. in the form of {key: dim_market, value: revenue prediction}. For this use case, the revenue prediction can be easily looked up based on the market in which the listing is located. A more involved product might allow users to specify their location, room size, and capacity so earning potentials can be personalized. In such a use case, we will not know the features until a user enters the information, so predictions need to be computed in real-time. Depending on the use cases, your path to productionization might vary.</p><p><strong>Takeaway: </strong><em>Taking models to production can mean different things depending on the context, use cases, and infrastructure at the company. Having basic familiarity with concepts such as latency and context sensitivity will greatly inform your implementation strategy.</em></p><h3>5. Feedback Loop Can Help You or Hurt You</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*pGbHGnBVtzhWH_wqXgDJig.png" /><figcaption><a href="https://pixabay.com/en/rollercoaster-looping-amusement-801833/">Image source</a>: Creating and dealing with feedback loops is yet another important topic</figcaption></figure><p>Models that are an integrated part of a product experience, or what we referred to as data products, often involve feedback loops. When done right, feedback loops can help us to create better experiences. However, feedback loops can also create unintended negative consequences, such as bias or inaccurate model performance measurements.</p><h4>User Feedback Can Make Your Model Better</h4><p>One of the most unexpected skills that I learned about real-life machine learning is the ability to spot opportunities for users to provide model feedback via product interactions. These decisions might seem only relevant to UI/UX at first, but they can actually have a profound impact on the quality of the features that the data product offers.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*r0FP1iOEHherdYdbWFkicg.png" /><figcaption><a href="https://chatbotnewsdaily.com/10-more-lessons-learned-from-building-real-life-ml-systems-part-i-b309cafc7b5e">Image source</a>: From <a href="https://chatbotnewsdaily.com/@xamat?source=post_header_lockup">Xavier Amatriain</a>’s post “10 more lessons learned from building real-life ML system”</figcaption></figure><p>For example, Netflix <a href="https://www.theatlantic.com/entertainment/archive/2017/03/netflix-believes-in-the-power-of-thumbs/520242/">decided</a> last year to move away from the star-rating system to a thumbs up/down system, reportedly because its simplicity prompts more users to provide feedback, which in terms help Netflix to make their recommendations better. Similarly, Facebook, Twitter, Quora, and other social networks have long designed features such as likes, retweets, and comments which not only make the product more interactive, but also allow these companies to monetize better via personalization.</p><p>Creating feedback opportunities in product, instrumenting and capturing these feedback, and integrating it back into model development is important for both improving user experience as well as optimizing the companies’ business objectives and bottom lines.</p><h4>Feedback Loops Can Also Bias Model Performance</h4><p>While feedback loops can be powerful, they can also have unintended, negative consequences. One important topic is that models that are biased will amplify the bias the feedback loop introduces (see <a href="https://developers.google.com/machine-learning/fairness-overview/">here</a>). Other times, feedback loop can affect our ability to measure model performance accurately.</p><p>This latter phenomenon is best illustrated by Michael Manapat, who explains this bias based on his experience building fraud models at Stripe. In his example, he pointed out that when a live fraud model enforces certain policy (e.g. block a transaction if its fraud score is above certain threshold), the system never gets to observe the ground truth for those blocked transactions, regardless of whether they are fraudulent or not. This blind spot can affect our ability to measure the effectiveness of a model running live in production.</p><iframe src="https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fwww.youtube.com%2Fembed%2FQWCSxAKR-h0%3Ffeature%3Doembed&amp;display_name=YouTube&amp;url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DQWCSxAKR-h0&amp;image=https%3A%2F%2Fi.ytimg.com%2Fvi%2FQWCSxAKR-h0%2Fhqdefault.jpg&amp;key=a19fcc184b9711e1b4764040d3dc5c07&amp;type=text%2Fhtml&amp;schema=youtube" width="854" height="480" frameborder="0" scrolling="no"><a href="https://medium.com/media/f5fe8b056ddd1cb790ad18921d00ab33/href">https://medium.com/media/f5fe8b056ddd1cb790ad18921d00ab33/href</a></iframe><p>Why? When obvious fraudulent transactions are blocked, the ones that remained with ground truth that we can observe are typically false negative transactions that are harder to get right. When we re-train our models on these “harder” examples, our model performance will necessarily be worse than what it really is performing in production.</p><p>Michael’s solution to this bias is to inject randomness in production traffic to understand the counterfactuals. Specifically, for transactions that are deemed fraudulent, we will let a small percentage of transactions pass, regardless of their scores, so we can observe the ground truth. Using these additional labels, we can then re-adjust the calculation for model performance. This approach is simple but not entirely obvious. In fact, it took me a long while before spotting the same feedback loop in my model, and it is not until I encountered Michael’s talk that I found a solution.</p><p><strong>Takeaway: </strong><em>Feedback loops in machine learning models are subtle. Knowing how to leverage feedback loops can help you to build a better user experience, and being aware of feedback loops can inform you to calculate the performance of your live system more accurately.</em></p><h3>Conclusion</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*XsxocBbIzoQaqwdehmG3XQ.png" /><figcaption><a href="https://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf">Source</a>: From the paper “Hidden Technical Debt in Machine Learning System” by D. Sculley et al</figcaption></figure><p>Throughout this post, I gave concrete examples around topics such as problem definition, feature engineering, model debugging, productionization, and dealing with feedback loops. The main underlying theme here is that building a machine learning system involves a lot more nuances than just fitting a model on a laptop. While the materials that I have covered here are only a <a href="https://github.com/robert8138/deep-learning-deliberate-practice#machine-learning-in-general">subset</a> of the topics that one would encounter in practice, I hope that they have been informative in helping you to move beyond “<strong>Laptop Data Science</strong>”.</p><p>Happy Machine Learning!</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=16b4dd913a1f" width="1" height="1" alt="">]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[A Beginner’s Guide to Data Engineering — The Series Finale]]></title>
            <description><![CDATA[<div class="medium-feed-item"><p class="medium-feed-image"><a href="https://medium.com/@rchang/a-beginners-guide-to-data-engineering-the-series-finale-2cc92ff14b0?source=rss-c00b242128fe------2"><img src="https://cdn-images-1.medium.com/max/1866/1*JsZuJ2aUFgNsZk9cTv_61w.png" width="1866"></a></p><p class="medium-feed-snippet">From ETL Pipelines To Data Engineering Frameworks</p><p class="medium-feed-link"><a href="https://medium.com/@rchang/a-beginners-guide-to-data-engineering-the-series-finale-2cc92ff14b0?source=rss-c00b242128fe------2">Continue reading on Medium »</a></p></div>]]></description>
            <link>https://medium.com/@rchang/a-beginners-guide-to-data-engineering-the-series-finale-2cc92ff14b0?source=rss-c00b242128fe------2</link>
            <guid isPermaLink="false">https://medium.com/p/2cc92ff14b0</guid>
            <category><![CDATA[computer-science]]></category>
            <category><![CDATA[data-engineering]]></category>
            <category><![CDATA[big-data]]></category>
            <category><![CDATA[analytics]]></category>
            <category><![CDATA[data-science]]></category>
            <dc:creator><![CDATA[Robert Chang]]></dc:creator>
            <pubDate>Sun, 24 Jun 2018 22:33:02 GMT</pubDate>
            <atom:updated>2018-06-25T01:10:38.528Z</atom:updated>
        </item>
        <item>
            <title><![CDATA[A Beginner’s Guide to Data Engineering — Part II]]></title>
            <description><![CDATA[<div class="medium-feed-item"><p class="medium-feed-image"><a href="https://medium.com/@rchang/a-beginners-guide-to-data-engineering-part-ii-47c4e7cbda71?source=rss-c00b242128fe------2"><img src="https://cdn-images-1.medium.com/max/2062/1*BC9-kpfjCPtY-w-GOjPBDA.png" width="2062"></a></p><p class="medium-feed-snippet">Data Modeling, Data Partitioning, Airflow, and ETL Best Practices</p><p class="medium-feed-link"><a href="https://medium.com/@rchang/a-beginners-guide-to-data-engineering-part-ii-47c4e7cbda71?source=rss-c00b242128fe------2">Continue reading on Medium »</a></p></div>]]></description>
            <link>https://medium.com/@rchang/a-beginners-guide-to-data-engineering-part-ii-47c4e7cbda71?source=rss-c00b242128fe------2</link>
            <guid isPermaLink="false">https://medium.com/p/47c4e7cbda71</guid>
            <category><![CDATA[big-data]]></category>
            <category><![CDATA[data-science]]></category>
            <category><![CDATA[software-development]]></category>
            <category><![CDATA[coding]]></category>
            <category><![CDATA[startup]]></category>
            <dc:creator><![CDATA[Robert Chang]]></dc:creator>
            <pubDate>Tue, 20 Feb 2018 16:01:01 GMT</pubDate>
            <atom:updated>2018-06-24T22:44:45.771Z</atom:updated>
        </item>
        <item>
            <title><![CDATA[A Beginner’s Guide to Data Engineering — Part I]]></title>
            <description><![CDATA[<div class="medium-feed-item"><p class="medium-feed-image"><a href="https://medium.com/@rchang/a-beginners-guide-to-data-engineering-part-i-4227c5c457d7?source=rss-c00b242128fe------2"><img src="https://cdn-images-1.medium.com/max/1804/1*gjgczPgeWlqWEVHtKYpJUg.png" width="1804"></a></p><p class="medium-feed-snippet">Data Engineering: The Close Cousin of Data Science</p><p class="medium-feed-link"><a href="https://medium.com/@rchang/a-beginners-guide-to-data-engineering-part-i-4227c5c457d7?source=rss-c00b242128fe------2">Continue reading on Medium »</a></p></div>]]></description>
            <link>https://medium.com/@rchang/a-beginners-guide-to-data-engineering-part-i-4227c5c457d7?source=rss-c00b242128fe------2</link>
            <guid isPermaLink="false">https://medium.com/p/4227c5c457d7</guid>
            <category><![CDATA[startup]]></category>
            <category><![CDATA[data-science]]></category>
            <category><![CDATA[coding]]></category>
            <category><![CDATA[software-development]]></category>
            <dc:creator><![CDATA[Robert Chang]]></dc:creator>
            <pubDate>Mon, 08 Jan 2018 14:01:09 GMT</pubDate>
            <atom:updated>2018-06-24T22:44:11.141Z</atom:updated>
        </item>
        <item>
            <title><![CDATA[Advice For New and Junior Data Scientists]]></title>
            <link>https://medium.com/@rchang/advice-for-new-and-junior-data-scientists-2ab02396cf5b?source=rss-c00b242128fe------2</link>
            <guid isPermaLink="false">https://medium.com/p/2ab02396cf5b</guid>
            <category><![CDATA[analytics]]></category>
            <category><![CDATA[technology]]></category>
            <category><![CDATA[data-science]]></category>
            <category><![CDATA[careers]]></category>
            <category><![CDATA[machine-learning]]></category>
            <dc:creator><![CDATA[Robert Chang]]></dc:creator>
            <pubDate>Sun, 08 Oct 2017 01:31:00 GMT</pubDate>
            <atom:updated>2017-10-22T20:22:31.737Z</atom:updated>
            <content:encoded><![CDATA[<h4>What I Would Have Told Myself a Few Years ago</h4><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*n1_oY6S0tqy4QaWVXaAmxQ.png" /><figcaption>Image credit: Alice Truong</figcaption></figure><h3>Motivation</h3><p>Two years ago, I shared my <a href="https://medium.com/@rchang/my-two-year-journey-as-a-data-scientist-at-twitter-f0c13298aee6">experience</a> on doing data science in the industry. The writing was originally meant to be a private reflection for myself to celebrate my two year twitterversary at Twitter, but I instead published it on Medium because I believe it could be very useful for many aspiring data scientists.</p><p>Fast forward to 2017, I have been working at Airbnb for a little bit less than two years and have recently become a senior data scientist — an industry title used to signal that one has acquired a certain level of technical expertise. As I reflect on my journey so far and imagine what’s next to come, I once again wrote down a few lessons that I wish I had known in the earlier days of my career.</p><p>If the intended audience of my previous post was for aspiring data scientists and people who are completely new to the field, then this article is for people who are already in the field but are just starting out. My goal is to not only use this post as a reminder to myself about the important things that I have learned, but also to inspire others as they embark onto their DS careers!</p><h3>Whose Critical Path Are You On?</h3><p>Philip Guo, an outstanding academic and prolific blogger, reflected on his experience interacting with various mentors throughout his years as a student, intern, and researcher. In his blot post “<a href="http://www.pgbovine.net/critical-path.htm">Whose Critical Path Are You On?</a>”, he made the following observation:</p><blockquote>If I was on my mentor’s <strong>critical path</strong> [for career advancement or fulfillment], then they would fight hard to make sure I got the help that I needed to succeed. Conversely, if I wasn’t on my mentor’s critical path, then I was usually left to fend for myself. […] If you get on someone’s critical path, then you force them to tie your success to theirs, which will motivate them to lift you up as hard as they can.</blockquote><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*ev5_ddW1FE367USX2d46zA.png" /><figcaption>Image credit: The Icefields Parkway // Daniel Han</figcaption></figure><p>This work dynamic is pretty intuitive, and I wish I had internalized it earlier in my career when choosing projects, selecting teams, or even evaluating which mentors or companies to work for.</p><p>As an example, while at Twitter, I had always wanted to learn more about machine learning, but my team, despite being very data driven, largely needed data scientists to focus on experiment design and product analytics. Despite my best efforts, I often found it difficult to marry this intellectual desire with the critical projects of my team.</p><p>As a result, when I arrived at Airbnb, I made a conscious decision to focus on joining a project/team where ML is critical to its success. I worked with my manager to identify a few promising opportunities, one of which is to model the lifetime value (LTV) of listings on Airbnb.</p><p>This project was not only critical to the success of our business, but also to the development of my career. I learned so much about the workflow of <a href="https://medium.com/airbnb-engineering/using-machine-learning-to-predict-value-of-homes-on-airbnb-9272d3d4739d">building machine learning model at scale</a>, and there was no better way to learn other than learning in the context of solving a concrete business problem.</p><p>Undoubtedly, I was very lucky to find a project that aligned with my aspirations and where I wanted to build my skills. I believe the framework of picking projects on our mentors’ critical paths can make us increasingly “lucky” over time on matching our aspirations with the right projects at work.</p><p><strong>Principle I learned</strong>: <em>We all have skills that we would like to develop and intellectual interests that we would love to pursue. It’s important to evaluate how well our aspirations align with the critical path of the environment we are in. Find projects, teams, and companies whose critical path best aligned with yours.</em></p><h3>Picking the Right Tools For The Problem</h3><p>Before Airbnb, I had been coding in R and <a href="https://github.com/tidyverse/dplyr">dplyr</a> for most of my professional life. After starting on the LTV project, I soon realized the deliverable was not a piece of analysis code, but rather a production machine learning pipeline. Given that it is much easier to build complex pipelines in <a href="https://medium.com/the-astronomer-journey/airflow-and-the-future-of-data-engineering-a-q-a-266f68d956a9">Airflow</a> using Python, I was faced with a dilemma — should I switch from R to Python?</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/964/1*dZaHst97QwHkKtWd0HlZ4Q.png" /><figcaption>Image source: quickmeme.com (besides R or Python, Excel is also a serious contender 👊)</figcaption></figure><p>This turns out to be a very common question among data scientists, since many struggled to decide which language to choose. For me, there is clearly a switching cost once committed to one or the other. I went through the pros and cons to understand the tradeoffs, but the more I thought about it, the more I fell into the trap of decision paralysis. (Here is an entertaining <a href="https://blog.dominodatalab.com/video-huge-debate-r-vs-python-data-science/">talk</a> that demonstrates this concept). Eventually, I escaped from this paralysis after reading this response on <a href="https://www.reddit.com/r/Python/comments/2tkkxd/considering_putting_my_efforts_into_python/">Reddit</a>:</p><blockquote>Instead of thinking about which programming language to learn, think about which language offers you the right set of Domain Specific Languages (DSL) that fit your problems.</blockquote><p>The appropriateness of a tool is always context dependent and problem specific. It’s not about whether I should learn Python, it’s whether Python is the right tool for the job. To elaborate more on this point, here are a few examples:</p><ul><li>If your goal is to apply the most current, cutting-edge statistical methods, R is likely to be the better choice. Why? Because R is built by statisticians and for statisticians. Nowadays, academics publish their research not only in papers but also in R packages. Each week, there are many interesting new R packages made available on <a href="https://cran.r-project.org/mirrors.html">CRAN</a>, like this <a href="https://github.com/susanathey/causalTree">one</a>.</li><li>On the other hand, Python is great for building production data pipelines, since it is a general-purpose programming language. For example, one can easily wrap a <a href="http://scikit-learn.org/">scikit-learn</a> model using <a href="http://www.florianwilhelm.info/2016/10/python_udf_in_hive/">Python UDF</a> to do distributed scoring in Hive, orchestrate Airflow DAGs with complex logic, or write a Flask web app to showcase the output of the model in a browser.</li></ul><p>For my particular project, I needed to build a production machine learning pipeline, and my life would be a lot easier if I did it in Python. Eventually, I rolled up my sleeves and embraced this new challenge!</p><p><strong>Principle I learned</strong>: <em>Instead of fixating on a single technique or programming language, ask yourself, what is the best set of tools or techniques that will help you to solve your problem? Focus on problem solving, and the tools will come naturally.</em></p><h3>Building A Learning Project</h3><p>Even though I have not used Python to do Data Science work before, I did play with the language in a <a href="https://medium.com/@rchang/learning-how-to-build-a-web-application-c5499bd15c8f">different capacity</a>. However, I never really learned Python fundamentals properly. As a result, I got scared when code was organized into <a href="https://jeffknupp.com/blog/2014/06/18/improve-your-python-python-classes-and-object-oriented-programming/">classes</a>, and I always wondered what <em>__init__.py </em>was <a href="https://stackoverflow.com/questions/448271/what-is-init-py-for">used</a> for<em>.</em></p><p>To really learn the fundamentals properly this time, I took inspiration from Anders Ericsson’s research on <a href="https://www.amazon.com/Peak-Secrets-New-Science-Expertise/dp/1531864880"><strong>Deliberate Practice</strong></a>:</p><blockquote><strong>Deliberate Practice</strong> is activities designed, typically by a teacher, for the sole purpose of effectively improving specific aspects of an individual’s performance.</blockquote><p>Given that I was my own teacher, insights from Dr. Ericsson were very helpful. For example, I kicked off my “learning project” by curating a set of materials that were most relevant for doing ML in Python. This process took me a few weeks until I settled on a personalized <a href="https://github.com/robert8138/python-deliberate-practice">curriculum</a>. I stress tested this curriculum by asking experienced Pythonistas to review my plan. All of this pre-work was meant to ensure I would be on the right learning path.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*JgVutu1PA5x-kh2WjLDJJA.png" /><figcaption>Here is a glimpse of my personalized curriculum</figcaption></figure><p>Once I had a clearly defined curriculum, I used the following strategies to deliberately practice on the job:</p><ul><li><strong>Practice Repeatedly</strong>: I forced myself to carry out mundane, non mission-critical analyses in Python instead of in R. This dragged down my productivity initially, but it forced me to get familiar with the basic API of <a href="http://pandas.pydata.org/">pandas</a>, without the burden of needing to meet an urgent deadline.</li><li><strong>Create Feedback Loop</strong>: I found opportunities to review other people’s code and fix small bugs when appropriate. For example, I tried to understand how our internal Python libraries were designed before using them. When writing my own code, I also tried to refactor it several times and make it more readable for everyone.</li><li><strong>Learn By Chunking and Recalling:</strong> By the end of each week, I wrote down my <a href="https://github.com/robert8138/python-deliberate-practice/blob/master/Planning.md">weekly progress</a>, which included the important resources I studied in that week, concepts I learned, and any major takeaways during that week. By recalling the materials I learned, I was able to internalize the concepts better.</li></ul><p>Slowly and gradually, I got better each week. It certainly wasn’t easy though: there were times when I had to look up basic syntax in both R and Python because I was switching back and forth between the two languages. That said, I kept in mind that this is a long term investment, and dividends will be paid as I dived into the ML project.</p><p><strong>Principle I learned</strong>: <em>As supported by many </em><a href="https://qz.com/978273/a-stanford-professors-15-minute-study-hack-improves-test-grades-by-a-third-of-a-grade/"><em>field experiments</em></a>, <em>before diving into a project, planning ahead helps you to practice more deliberately. Repeating, chunking, recalling, and getting feedback are among the most useful activities to reinforce learning.</em></p><h3>Partnering With Experienced Data Scientists</h3><p>One of the key ingredients of <strong>deliberate practice</strong> is to receive timely and actionable feedback. No great athletes, musicians, or mathematicians are able to achieve greatness without coaching or targeted feedback.</p><p>One common trait I have observed from people who have a strong <a href="https://www.ted.com/talks/carol_dweck_the_power_of_believing_that_you_can_improve">growth mindset</a> is that they are generally not ashamed of acknowledging what they don’t know and they constantly ask for feedback.</p><p>Looking back at my own academic and professional career so far, many times in the past I self-censored my questions because I did not want to appear incapable. However, over time I realized that this attitude was rather detrimental — in the long run, most instances of self-censorship are missed opportunities for learning rather than shame.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/876/1*lgG5Z6FUEdZOVRZ8d1O2WQ.png" /><figcaption>Image source: edutopia — It’s important to have a growth mindset!</figcaption></figure><p>Before this project, I had very little experience putting machine learning models into <a href="https://www.slideshare.net/SharathRao6/lessons-from-integrating-machine-learning-models-into-data-products">production</a>. Of the many decisions that I made for the project, one of the best decisions was to declare early and shamelessly to my collaborators that I know very little about ML infrastructure, but that I wanted to learn. I promised them, however, as I got more knowledgeable, I would make myself useful for the team.</p><p>This turned out to be a pretty good strategy, because people generally love to share their knowledge, especially when they know their mentorship will benefit themselves eventually. Below are a few examples that I would not have learned so quickly without the guidance of my partners:</p><ul><li><a href="http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html"><strong>Scikit-Learn Pipelines</strong></a><strong>: </strong>My collaborator suggested to me that I can make my code more modular by adopting Sklearn’s pipeline construct. Essentially, pipelines define a series of data transformation that are consistent across training and scoring. This tool made my code cleaner, more reusable, and more easily compatible with production models.</li><li><strong>Model Diagnostics</strong>: Given that our prediction problem involves time, my collaborator taught me that typical cross validation will not work, as we could run into the risk of predicting the past using future data. Instead, a better method would be to use <a href="https://robjhyndman.com/hyndsight/tscv/">time series cross validation</a>. I also learned different diagnostic techniques such as <a href="https://www.analyticsvidhya.com/blog/2016/02/7-important-model-evaluation-error-metrics/">lift chart</a> and various other evaluation metrics such as <a href="https://en.wikipedia.org/wiki/Symmetric_mean_absolute_percentage_error">SMAPE</a>.</li><li><strong>Machine Learning Infrastructure</strong>: With the help from ML infra engineers, I learned about managing package dependency via virtualenvs, how to serialize models using <a href="https://docs.python.org/3/library/pickle.html">pickling</a>, and how to make the model available at scoring time using <a href="http://www.florianwilhelm.info/2016/10/python_udf_in_hive/">Python UDFs</a>. All these are data engineering skills that I didn’t know before.</li></ul><p>As I learned more new concepts, not only was I able to apply them for my own project, I was able to drive engaging discussions with the machine learning infrastructure team so they can build better ML tools for data scientists. This creates a virtuous cycle because the knowledge that was shared with me made me a better partner and collaborator.</p><p><strong>Principle I learned</strong>: <em>In the long run, most instances of self-censorship are missed opportunities for learning rather than shame. Declare early and shamelessly your desire to learn, and make yourself useful as you become better.</em></p><h3>Teaching And Evangelizing</h3><p>As I got closer to putting my model into production, I noticed that a lot of the skills that I picked up could be very valuable for other data scientists on our team. Having been a graduate student instructor for years, I always knew I had a passion for teaching, and I always learned more about the subject when I became the teacher. Richard Feynman, the late Nobel Laureate in Physics and a <a href="https://www.youtube.com/watch?v=0KmimDq4cSU">phenomenal teacher</a>, spoke about his view on teaching:</p><blockquote>Richard Feynman was once asked by a Caltech faculty member to explain why spin one-half particles obey Fermi Dirac statistics. Rising to the challenge, he said, “I’ll prepare a freshman lecture on it.” But a few days later he told the faculty member, “You know, I couldn’t do it. I couldn’t reduce it to the freshman level. That means we really don’t understand it.”</blockquote><p>This was really inspiring — if you can’t reduce the subject to its core and make it accessible for others, that means you don’t really understand it. Knowing that teaching these skills can improve my understanding, I seek opportunities to carefully document my model implementations, give learning lunches, and encourage others to try out the tools. This was a win-win because evangelization raises awareness, which in tern helps to drive tool adoption across the team.</p><p>As of late September, I have started collaborating with our internal <a href="https://medium.com/airbnb-engineering/how-airbnb-democratizes-data-science-with-data-university-3eccc71e073a">Data University</a> team to prepare a series of classes on our internal ML tools. I am not exactly sure where this will go, but I am very excited about driving more ML education at Airbnb.</p><p>Finally, I would end this section with a tweet from <a href="https://twitter.com/hadleywickham">Hadley Wickham</a>:</p><h3>Hadley Wickham on Twitter</h3><p>Useful things isn&#39;t just new software but also posts explaining existing tools, case studies, describing your workflow, good bug reports /1 https://t.co/YBZmiFUpNd</p><p><strong>Principle I learned: </strong><em>Teaching is the best way to test your understanding of the subject and the best way to improve your skills. When you learn something valuable, share it with others. You don’t always have to create new software, explaining how existing tools work can also be super valuable.</em></p><h3>At Step K, Think About Your Step K+1</h3><p>From focusing on my own deliverables, to partnering with the ML infrastructure team, to finally teaching and enabling other data scientists to learn more about ML tools, I am really happy that the scope of my original project was much larger than it was a few months ago. Yet, admittedly, I never anticipated this in the first place.</p><p>As I reflected on the evolution of this project, one thing that was different from my previous projects was that I always had a slight dissatisfaction with the current state of things, and I always wanted to make it a little bit better. The most eloquent way to characterize this is from <a href="https://medium.com/the-mission/a-genius-explains-how-to-be-creative-claude-shannons-long-lost-1952-speech-fbbcb2ebe07f">Claude Shannon’s essay</a>:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/450/1*EmbwmvVXC1bV7Jv7ZpOPZw.png" /><figcaption>Image source: Book cover from “A Mind at Play: How Claude Shannon Invented the Information Page” by Jimmy Soni, Rob Goodman</figcaption></figure><blockquote>“There’s the idea of <strong>dissatisfaction</strong>. By this I don’t mean a pessimistic dissatisfaction of the world — we don’t like the way things are — I mean a constructive dissatisfaction. The idea could be expressed in the words, This is OK, but I think things could be done better. I think there is a neater way to do this. I think things could be improved a little. In other words, there is continually a slight irritation when things don’t look quite right; and I think that dissatisfaction in present days is a key driving force in good scientists.”</blockquote><p>By no means I am a qualified scientist (even though that is somehow in my job title), but I do think the characterization of slight dissatisfaction is quite telling for whether you will be able to extend the impact of your project. Throughout my project, whenever I am at step K, I naturally would start thinking about what to do for step K+1 and beyond:</p><ul><li>From “<em>I don’t know how to build a production model, let me figure out how”</em> to “<em>I think the tools can be improved, here are my pain points, suggestion and feedback for how to make the tools better”, </em>I reframed myself from a customer to a partner with ML infrastructure team.</li><li>From “<em>let me learn the tools so I can be good at it” </em>to “<em>let’s make these tools more accessible for all the other Data Scientists interested in ML”, </em>I reframed myself from a partner to an evangelizer.</li></ul><p>I think this mindset is extremely helpful — use your good taste and slight dissatisfaction to fuel your progress with persistence. That said, I do think that this dissatisfaction cannot be manufactured, and can only come from working on a problem you care about, which brings to my last point.</p><p><strong>Principle I learned: </strong><em>Pay attention to your inner dissatisfaction when working on a project. These are clues to how you can improve and scale your project to the next level.</em></p><h3>Parting Thoughts: You And Your Work</h3><p>Recently, I came across a lecture from <a href="https://en.wikipedia.org/wiki/Richard_Hamming">Richard Hamming</a>, who is an American Mathematician well known for many of his scientific contributions, including Hamming code and Hamming distance. The lecture was titled <a href="https://www.youtube.com/watch?v=a1zDuOPkMSw">You And Your Research</a>, where Dr. Hamming said it can very well be renamed as <strong>“You And Your Career”</strong>.</p><iframe src="https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fwww.youtube.com%2Fembed%2Fa1zDuOPkMSw%3Ffeature%3Doembed&amp;url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3Da1zDuOPkMSw&amp;image=https%3A%2F%2Fi.ytimg.com%2Fvi%2Fa1zDuOPkMSw%2Fhqdefault.jpg&amp;key=a19fcc184b9711e1b4764040d3dc5c07&amp;type=text%2Fhtml&amp;schema=youtube" width="640" height="480" frameborder="0" scrolling="no"><a href="https://medium.com/media/70791d910c2b5748671fad34eec86b8c/href">https://medium.com/media/70791d910c2b5748671fad34eec86b8c/href</a></iframe><p>As he shared his stories, a few important points stood out for me.</p><blockquote>If what you are doing is not important, not likely to be important, <strong>why are you doing it?</strong> You must work on important problems. I spent Friday afternoon for years thinking about the important problems in my field [that’s 10% of my working time].</blockquote><blockquote>Let me warn you about important problems, importance is not the consequence, some problems are not important because you haven’t gotten an attack. The importance of problem, to a great extent, depends on if you got a way of attacking the problem.</blockquote><blockquote>This whole course, I am trying to teach you something about <strong>style</strong> and <strong>taste</strong>, so you’ll be able to have some hunch on when the problem is right, what problem is right, how to go about it. The right problem at the right time at the right way counts, and nothing else counts. Nothing.</blockquote><p>When Dr. Hamming speaks about importance, he means problems that are important <strong>to you. </strong>For him, it was scientific problems, and for many of us, it might be something different. He also talked about the importance of having a plan of attack. If you don’t have a plan, the problem does not matter, however big the consequences. Lastly, he mentioned doing it with your own unique style and taste.</p><p>His bar for doing great work is extremely high, but it’s one worth pursuing. When you find your important problem, you will naturally try to make it better and make it more impactful; you will find ways to teach other about its significance; you will spend time to learn from other great people and build your craft.</p><p><strong>What’s a problem that is important to you that is on your critical path?</strong></p><p><em>I would like to thank </em><a href="https://medium.com/u/1f36b16d073e"><em>Jason Goodman</em></a><em> and Tim Kwan for reviewing my post and giving me feedback</em></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=2ab02396cf5b" width="1" height="1" alt="">]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Using Machine Learning to Predict Value of Homes On Airbnb]]></title>
            <link>https://medium.com/airbnb-engineering/using-machine-learning-to-predict-value-of-homes-on-airbnb-9272d3d4739d?source=rss-c00b242128fe------2</link>
            <guid isPermaLink="false">https://medium.com/p/9272d3d4739d</guid>
            <category><![CDATA[ai]]></category>
            <category><![CDATA[data-science]]></category>
            <category><![CDATA[machine-learning]]></category>
            <category><![CDATA[technology]]></category>
            <category><![CDATA[artificial-intelligence]]></category>
            <dc:creator><![CDATA[Robert Chang]]></dc:creator>
            <pubDate>Mon, 17 Jul 2017 15:01:01 GMT</pubDate>
            <atom:updated>2017-07-17T16:07:24.185Z</atom:updated>
            <content:encoded><![CDATA[<p>by <a href="https://twitter.com/_rchang">Robert Chang</a></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*jdUbWGwyIyJJ4wlr1FaSqA.png" /><figcaption><strong>Amazing view from a Airbnb Home in Imerovigli, Egeo, Greece</strong></figcaption></figure><h3>Introduction</h3><p>Data products have always been an instrumental part of Airbnb’s service. However, we have long recognized that it’s costly to make data products. For example, personalized search ranking enables guests to more easily discover homes, and smart pricing allows hosts to set more competitive prices according to supply and demand. However, these projects each required a lot of dedicated data science and engineering time and effort.</p><p>Recently, advances in Airbnb’s machine learning infrastructure have lowered the cost significantly to deploy new machine learning models to production. For example, our ML Infra team built a general feature repository that allows users to leverage high quality, vetted, reusable features in their models. Data scientists have started to incorporate several AutoML tools into their workflows to speed up model selection and performance benchmarking. Additionally, ML infra created a new framework that will automatically translate Jupyter notebooks into Airflow pipelines.</p><p>In this post, I will describe how these tools worked together to expedite the modeling process and hence lower the overall development costs for a specific use case of LTV modeling — predicting the value of homes on Airbnb.</p><h3>What Is LTV?</h3><p>Customer Lifetime Value (LTV), a popular concept among e-commerce and marketplace companies, captures the projected value of a user for a fixed time horizon, often measured in dollar terms.</p><p>At e-commerce companies like Spotify or Netflix, LTV is often used to make pricing decisions like setting subscription fees. At marketplace companies like Airbnb, knowing users’ LTVs enable us to allocate budget across different marketing channels more efficiently, calculate more precise bidding prices for online marketing based on keywords, and create better listing segments.</p><p>While one can use past data to <a href="https://medium.com/swlh/diligence-at-social-capital-part-3-cohorts-and-revenue-ltv-ab65a07464e1">calculate the historical value</a> of existing listings, we took one step further to predict LTV of new listings using machine learning.</p><h3>Machine Learning Workflow For LTV Modeling</h3><p>Data scientists are typically accustomed to machine learning related tasks such as feature engineering, prototyping, and model selection. However, taking a model prototype to production often requires an orthogonal set of data engineering skills that data scientists might not be familiar with.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*zT1gNPErRqizxlngxXCtBA.png" /></figure><p>Luckily, At Airbnb we have machine learning tools that abstract away the engineering work behind productionizing ML models. In fact, we could not have put our model into production without these amazing tools. The remainder of this post is organized into four topics, along with the tools we used to tackle each task:</p><ul><li><strong>Feature Engineering: </strong>Define relevant features</li><li><strong>Prototyping and Training: </strong>Train a model prototype</li><li><strong>Model Selection &amp; Validation: </strong>Perform model selection and tuning</li><li><strong>Productionization: </strong>Take the selected model prototype to production</li></ul><h3>Feature Engineering</h3><blockquote><strong>Tool used: Airbnb’s internal feature repository — Zipline</strong></blockquote><p>One of the first steps of any supervised machine learning project is to define relevant features that are correlated with the chosen outcome variable, a process called feature engineering. For example, in predicting LTV, one might compute the percentage of the next 180 calendar dates that a listing is available or a listing’s price relative to comparable listings in the same market.</p><p>At Airbnb, feature engineering often means writing Hive queries to create features from scratch. However, this work is tedious and time consuming as it requires specific domain knowledge and business logic, which means the feature pipelines are often not easily sharable or even reusable. To make this work more scalable, we developed <strong>Zipline</strong> — a training feature repository that provides features at different levels of granularity, such as at the host, guest, listing, or market level.</p><p>The <strong>crowdsourced </strong>nature of this internal tool allows data scientists to use a wide variety of high quality, vetted features that others have prepared for past projects. If a desired feature is not available, a user can create her own feature with a feature configuration file like the following:</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/1f3554953c0e2a0407f09bedab11809c/href">https://medium.com/media/1f3554953c0e2a0407f09bedab11809c/href</a></iframe><p>When multiple features are required for the construction of a training set, Zipline will automatically perform intelligent key joins and backfill the training dataset behind the scenes. For the listing LTV model, we used existing Zipline features and also added a handful of our own. In sum, there were over 150 features in our model, including:</p><ul><li><strong>Location</strong>: country, market, neighborhood and various geography features</li><li><strong>Price</strong>: nightly rate, cleaning fees, price point relative to similar listings</li><li><strong>Availability</strong>: Total nights available, % of nights manually blocked</li><li><strong>Bookability</strong>: Number of bookings or nights booked in the past X days</li><li><strong>Quality</strong>: Review scores, number of reviews, and amenities</li></ul><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*KYs7WNNfdwKmKcVbgKGkiw.png" /><figcaption>A example training dataset</figcaption></figure><p>With our features and outcome variable defined, we can now train a model to learn from our historical data.</p><h3>Prototyping and Training</h3><blockquote><strong>Tool used: Machine learning Library in Python — </strong><a href="http://scikit-learn.org/stable/"><strong>scikit-learn</strong></a></blockquote><p>As in the example training dataset above, we often need to perform additional data processing before we can fit a model:</p><ul><li><strong>Data Imputation:</strong> We need to check if any data is missing, and whether that data is missing at random. If not, we need to investigate why and understand the root cause. If yes, we should impute the missing values.</li><li><strong>Encoding Categorical Variables</strong>: Often we cannot use the raw categories in the model, since the model doesn’t know how to fit on strings. When the number of categories is low, we may consider using <a href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html">one-hot encoding</a>. However, when the cardinality is high, we might consider using <a href="https://www.kaggle.com/general/16927">ordinal encoding</a>, encoding by frequency count of each category.</li></ul><p>In this step, we don’t quite know what is the best set of features to use, so writing code that allows us to rapidly iterate is essential. The pipeline construct, commonly available in open-source tools like <a href="http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html">Scikit-Learn</a> and <a href="https://spark.apache.org/docs/latest/ml-pipeline.html">Spark</a>, is a very convenient tool for prototyping. Pipelines allow data scientists to specify high-level blueprints that describe how features should be transformed, and which models to train. To make it more concrete, below is a code snippet from our LTV model pipeline:</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/d2b3f53345ad62b5d96a60928da274ab/href">https://medium.com/media/d2b3f53345ad62b5d96a60928da274ab/href</a></iframe><p>At a high level, we use pipelines to specify data transformations for different types of features, depending on whether those features are of type binary, categorical, or numeric. <a href="http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.FeatureUnion.html">FeatureUnion</a> at the end simply combines the features column-wise to create the final training dataset.</p><p>The advantage of writing prototypes with pipelines is that it abstracts away tedious data transformations using <a href="http://scikit-learn.org/stable/data_transforms.html">data transforms</a>. Collectively, these transforms ensure that data will be transformed consistently across training and scoring, which solves a common problem of data transformation inconsistency when translating a prototype into production.</p><p>Furthermore, pipelines also separates data transformations from model fitting. While not shown in the code above, data scientists can add a final step to specify an <a href="http://scikit-learn.org/stable/tutorial/machine_learning_map/index.html">estimator</a> for model fitting. By exploring different estimators, data scientists can perform model selection to pick the best model to improve the model’s out of sample error.</p><h3>Performing Model Selection</h3><blockquote><strong>Tool used: Various </strong><a href="https://medium.com/airbnb-engineering/automated-machine-learning-a-paradigm-shift-that-accelerates-data-scientist-productivity-airbnb-f1f8a10d61f8"><strong>AutoML</strong></a><strong> frameworks</strong></blockquote><p>As mentioned in the previous section, we need to decide which candidate model is the best to put into production. To make such a decision, we need to weigh the tradeoffs between model interpretability and model complexity. For example, a sparse linear model might be very interpretable but not complex enough to generalize well. A tree based model might be flexible enough to capture non-linear patterns but not very interpretable. This is known as the <a href="http://scott.fortmann-roe.com/docs/BiasVariance.html"><strong>Bias-Variance tradeoff</strong></a>.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*tQbBEq6T8ZJ9lFSCbZKFqw.png" /><figcaption>Figure referenced from Introduction to Statistical Learning with R by James, Witten, Hastie, and Tibshirani</figcaption></figure><p>In applications such as insurance or credit screening, a model needs to be interpretable because it’s important for the model to avoid inadvertently discriminating against certain customers. In applications such as image classification, however, it is much more important to have a performant classifier than an interpretable model.</p><p>Given that model selection can be quite time consuming, we experimented with using various <a href="https://medium.com/airbnb-engineering/automated-machine-learning-a-paradigm-shift-that-accelerates-data-scientist-productivity-airbnb-f1f8a10d61f8">AutoML</a> tools to speed up the process. By exploring a wide variety of models, we found which types of models tended to perform best. For example, we learned that <a href="https://github.com/dmlc/xgboost">eXtreme gradient boosted trees</a> (XGBoost) significantly outperformed benchmark models such as mean response models, ridge regression models, and single decision trees.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*y1O7nIxCFmgQamCfsrWfjA.png" /><figcaption>Comparing RMSE allows us to perform model selection</figcaption></figure><p>Given that our primary goal was to predict listing values, we felt comfortable productionizing our final model using XGBoost, which favors flexibility over interpretability.</p><h3>Taking Model Prototypes to Production</h3><blockquote><strong>Tool used: Airbnb’s notebook translation framework — ML Automator</strong></blockquote><p>As we alluded to earlier, building a production pipeline is quite different from building a prototype on a local laptop. For example, how can we perform periodic re-training? How do we score a large number of examples efficiently? How do we build a pipeline to monitor model performance over time?</p><p>At Airbnb, we built a framework called <strong>ML Automator </strong>that automagically translates a Jupyter notebook into an <a href="https://medium.com/airbnb-engineering/airflow-a-workflow-management-platform-46318b977fd8">Airflow</a> machine learning pipeline. This framework is designed specifically for data scientists who are already familiar with writing prototypes in Python, and want to take their model to production with limited experience in data engineering.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*uLCH5Ozfj8mM07bKXIg20Q.png" /><figcaption>A simplified overview of the ML Automator Framework (photo credit: Aaron Keys)</figcaption></figure><ul><li>First, the framework requires a user to specify a model config in the notebook. The purpose of this model config is to tell the framework where to locate the training table, how many compute resources to allocate for training, and how scores will be computed.</li><li>Additionally, data scientists are required to write specific <em>fit </em>and <em>transform </em>functions. The fit function specifies how training will be done exactly, and the transform function will be wrapped as a Python UDF for distributed scoring (if needed).</li></ul><p>Here is a code snippet demonstrating how the <em>fit</em> and <em>transform</em> functions are defined in our LTV model. The fit function tells the framework that a XGBoost model will be trained, and that data transformations will be carried out according to the pipeline we defined previously.</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/8b3a79196e49776cf3c4c5f059dba07f/href">https://medium.com/media/8b3a79196e49776cf3c4c5f059dba07f/href</a></iframe><p>Once the notebook is merged, ML Automator will wrap the trained model inside a <a href="http://www.florianwilhelm.info/2016/10/python_udf_in_hive/">Python UDF</a> and create an <a href="https://airflow.incubator.apache.org/">Airflow</a> pipeline like the one below. Data engineering tasks such as data serialization, scheduling of periodic re-training, and distributed scoring are all encapsulated as a part of this daily batch job. As a result, this framework significantly lowers the cost of model development for data scientists, as if there was a dedicated data engineer working alongside the data scientists to take the model into production!</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*DvPE_V_SoHV3pikOqiZxsg.png" /><figcaption>A graph view of our LTV Airflow DAG, running in production</figcaption></figure><p><strong>Note:</strong> <em>Beyond productionization, there are other topics, such as tracking model performance over time or leveraging elastic compute environment for modeling, which we will not cover in this post. Rest assured, these are all active areas under development.</em></p><h3>Lessons Learned &amp; Looking Ahead</h3><p>In the past few months, data scientists have partnered very closely with ML Infra, and many great patterns and ideas arose out of this collaboration. In fact, we believe that these tools will unlock a new paradigm for how to develop machine learning models at Airbnb.</p><ul><li><strong>First, the cost of model development is significantly lower</strong>: by combining disparate strengths from individual tools: Zipline for feature engineering, Pipeline for model prototyping, AutoML for model selection and benchmarking, and finally ML Automator for productionization, we have shortened the development cycle tremendously.</li><li><strong>Second, the notebook driven design reduces barrier to entry</strong>: data scientists who are not familiar with the framework have immediate access to a plethora of real life examples. Notebooks used in production are guaranteed to be correct, self-documenting, and up-to-date. This design drives strong adoption from new users.</li><li><strong>As a result, teams are more willing to invest in ML product ideas</strong>: At the time of this post’s writing, we have several other teams exploring ML product ideas by following a similar approach: prioritizing the listing inspection queue, predicting the likelihood that listings will add cohosts, and automating flagging of low quality listings.</li></ul><p>We are very excited about the future of this framework and the new paradigm it brought along. By bridging the gap between prototyping and productionization, we can truly enable data scientists and engineers to pursue end-to-end machine learning projects and make our product better.</p><p><em>Want to use or build these ML tools? We’re always looking for </em><a href="https://www.airbnb.com/careers/departments/data-science-analytics"><em>talented people to join our Data Science and Analytics team</em></a><em>!</em></p><p><em>Special thanks to members of Data Science &amp; ML Infra team who were involved in this work: </em><a href="https://www.linkedin.com/in/aaronkeys/"><em>Aaron Keys</em></a><em>, </em><a href="https://www.linkedin.com/in/brad-hunter-497621a/"><em>Brad Hunter</em></a><em>, </em><a href="https://www.linkedin.com/in/hamelhusain/"><em>Hamel Husain</em></a><em>, </em><a href="https://www.linkedin.com/in/jiaying-shi-a2142733/"><em>Jiaying Shi</em></a><em>, </em><a href="https://www.linkedin.com/in/krishnaputtaswamy/"><em>Krishna Puttaswamy</em></a><em>, </em><a href="https://www.linkedin.com/in/michael-m-a37b1932/"><em>Michael Musson</em></a><em>, </em><a href="https://www.linkedin.com/in/nicholashandel/"><em>Nick Handel</em></a><em>, </em><a href="https://www.linkedin.com/in/vzanoyan/"><em>Varant Zanoyan</em></a><em>, </em><a href="https://www.linkedin.com/in/vquoss/"><em>Vaughn Quoss</em></a><em> et al. Additional thanks to </em><a href="https://www.linkedin.com/in/thegarytang/"><em>Gary Tang</em></a><em>, </em><a href="https://medium.com/@jasonkgoodman"><em>Jason Goodman</em></a><em>, </em><a href="https://twitter.com/jtfeng"><em>Jeff Feng</em></a><em>, </em><a href="https://medium.com/@lpettingill"><em>Lindsay Pettingill</em></a><em> for reviewing this blog post.</em></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=9272d3d4739d" width="1" height="1" alt=""><hr><p><a href="https://medium.com/airbnb-engineering/using-machine-learning-to-predict-value-of-homes-on-airbnb-9272d3d4739d">Using Machine Learning to Predict Value of Homes On Airbnb</a> was originally published in <a href="https://medium.com/airbnb-engineering">The Airbnb Tech Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
    </channel>
</rss>