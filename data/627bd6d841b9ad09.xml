<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>Edwin Chen's Blog</title><link>http://blog.echen.me/</link><description></description><lastBuildDate>Sat, 12 Feb 2022 00:00:00 +0100</lastBuildDate><item><title>How Could Facebook Align its ML Systems to Human Values? A Data-Driven Approach</title><link>http://blog.echen.me/2022/02/12/how-could-facebook-align-its-ml-systems-to-human-values-a-data-driven-approach/</link><description>&lt;p&gt;&lt;em&gt;(This is a &lt;a href="https://www.surgehq.ai/blog/what-if-social-media-optimized-for-human-values"&gt;crosspost&lt;/a&gt; from the official Surge AI &lt;a href="https://www.surgehq.ai/blog/what-if-social-media-optimized-for-human-values"&gt;blog&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;For background on this blog post...&lt;/p&gt;
&lt;p&gt;I used to work at Facebook, YouTube, and Twitter. One of the problems I big worked on: what was the right objective function to align our AI systems towards?&lt;/p&gt;
&lt;p&gt;Optimizing for watch time at …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Edwin Chen</dc:creator><pubDate>Sat, 12 Feb 2022 00:00:00 +0100</pubDate><guid isPermaLink="false">tag:blog.echen.me,2022-02-12:/2022/02/12/how-could-facebook-align-its-ml-systems-to-human-values-a-data-driven-approach/</guid><category>misc</category></item><item><title>A Visual Tool for Exploring Word Embeddings</title><link>http://blog.echen.me/2022/02/11/a-visual-tool-for-exploring-word-embeddings/</link><description>&lt;p&gt;I built a visualization to explore embeddings a few years ago, but never posted it more broadly. So here it is! &lt;a href="http://blog.echen.me/embedding-explorer/"&gt;http://blog.echen.me/embedding-explorer/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;These are &lt;a href="https://nlp.stanford.edu/projects/glove/"&gt;GloVe embeddings&lt;/a&gt; projected into 2D, colorized via k-means in the original space.&lt;/p&gt;
&lt;p&gt;You can see, for example, that the cluster in pink …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Edwin Chen</dc:creator><pubDate>Fri, 11 Feb 2022 00:00:00 +0100</pubDate><guid isPermaLink="false">tag:blog.echen.me,2022-02-11:/2022/02/11/a-visual-tool-for-exploring-word-embeddings/</guid><category>misc</category></item><item><title>Surge AI: A New Data Labeling Platform and Workforce for NLP</title><link>http://blog.echen.me/2020/11/30/surge-ai-a-new-data-labeling-platform-and-workforce-for-nlp/</link><description>&lt;p&gt;&lt;em&gt;&lt;strong&gt;tl;dr&lt;/strong&gt; I started &lt;a href="https://www.surgehq.ai"&gt;Surge AI&lt;/a&gt; to fix the problems I've always encountered with getting &lt;em&gt;high-quality, human-labeled data at scale&lt;/em&gt;. Think MTurk 2.0—but with an obsessive focus on quality and speed, and an elite workforce you can trust. If you've ever had problems getting human-annotated data, or wish …&lt;/em&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Edwin Chen</dc:creator><pubDate>Mon, 30 Nov 2020 00:00:00 +0100</pubDate><guid isPermaLink="false">tag:blog.echen.me,2020-11-30:/2020/11/30/surge-ai-a-new-data-labeling-platform-and-workforce-for-nlp/</guid><category>misc</category></item><item><title>Exploring LSTMs</title><link>http://blog.echen.me/2017/05/30/exploring-lstms/</link><description>&lt;script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/gist-embed/2.4/gist-embed.min.js"&gt;&lt;/script&gt;

&lt;p&gt;LSTMs are behind a lot of the amazing achievements deep learning has made in the past few years, and they're a fairly simple extension to neural networks under the right view. So I'll try to present them as intuitively as possible – in such a way that you could have discovered …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Edwin Chen</dc:creator><pubDate>Tue, 30 May 2017 00:00:00 +0200</pubDate><guid isPermaLink="false">tag:blog.echen.me,2017-05-30:/2017/05/30/exploring-lstms/</guid><category>misc</category></item><item><title>Moving Beyond CTR: Better Recommendations Through Human Evaluation</title><link>http://blog.echen.me/2014/10/07/moving-beyond-ctr-better-recommendations-through-human-evaluation/</link><description>&lt;p&gt;Imagine you're building a recommendation algorithm for your new online site. How do you measure its quality, to make sure that it's sending users relevant and personalized content? Click-through rate may be your initial hope…but after a bit of thought, it's not clear that it's the best metric after …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Edwin Chen</dc:creator><pubDate>Tue, 07 Oct 2014 00:00:00 +0200</pubDate><guid isPermaLink="false">tag:blog.echen.me,2014-10-07:/2014/10/07/moving-beyond-ctr-better-recommendations-through-human-evaluation/</guid><category>misc</category></item><item><title>Propensity Modeling, Causal Inference, and Discovering Drivers of Growth</title><link>http://blog.echen.me/2014/08/15/propensity-modeling-causal-inference-and-discovering-drivers-of-growth/</link><description>&lt;p&gt;Imagine you just started a job at a new company. You watched &lt;a href="http://youtu.be/AcNK7M2eCI4?t=1m5s"&gt;World War Z&lt;/a&gt; recently, so you're in a skeptical mood, and given that your last two startups failed from what you believe to be a lack of data, you're giving everything an extra critical eye.&lt;/p&gt;
&lt;p&gt;You start by …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Edwin Chen</dc:creator><pubDate>Fri, 15 Aug 2014 00:00:00 +0200</pubDate><guid isPermaLink="false">tag:blog.echen.me,2014-08-15:/2014/08/15/propensity-modeling-causal-inference-and-discovering-drivers-of-growth/</guid><category>misc</category></item><item><title>Product Insights for Airbnb</title><link>http://blog.echen.me/2014/08/14/product-insights-for-airbnb/</link><description>&lt;p&gt;I love studying users and products, and think data science can be extremely useful in guiding product/strategy as a whole. So I thought it would be fun to depart from the usual machine learning and engineering things I write about, and do a quick study of Airbnb.&lt;/p&gt;
&lt;p&gt;Think of …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Edwin Chen</dc:creator><pubDate>Thu, 14 Aug 2014 00:00:00 +0200</pubDate><guid isPermaLink="false">tag:blog.echen.me,2014-08-14:/2014/08/14/product-insights-for-airbnb/</guid><category>misc</category></item><item><title>Improving Twitter Search with Real-Time Human Computation</title><link>http://blog.echen.me/2013/01/08/improving-twitter-search-with-real-time-human-computation</link><description>
  &lt;div class="entry-content"&gt;&lt;p&gt;&lt;em&gt;(This is a post from the &lt;a href="http://engineering.twitter.com/2013/01/improving-twitter-search-with-real-time.html"&gt;Twitter Engineering Blog&lt;/a&gt; that I wrote with &lt;a href="https://twitter.com/alpa"&gt;Alpa Jain&lt;/a&gt;.)&lt;/em&gt;&lt;/p&gt;

  &lt;p&gt;One of the magical things about Twitter is that it opens a window to the world in &lt;strong&gt;real-time&lt;/strong&gt;. An event happens, and just seconds later, it&amp;#8217;s shared for people across the planet to see …&lt;/p&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Edwin Chen</dc:creator><pubDate>Tue, 08 Jan 2013 04:15:00 +0100</pubDate><guid isPermaLink="false">tag:blog.echen.me,2013-01-08:/2013/01/08/improving-twitter-search-with-real-time-human-computation</guid><category>misc</category></item><item><title>Edge Prediction in a Social Graph: My Solution to Facebook's User Recommendation Contest on Kaggle</title><link>http://blog.echen.me/2012/07/31/edge-prediction-in-a-social-graph-my-solution-to-facebooks-user-recommendation-contest-on-kaggle/</link><description>
  &lt;div class="entry-content"&gt;&lt;p&gt;A couple weeks ago, Facebook launched a &lt;a href="http://www.kaggle.com/c/FacebookRecruiting/"&gt;link prediction contest&lt;/a&gt; on Kaggle, with the goal of recommending missing edges in a social graph. &lt;a href="http://blog.echen.me/2011/09/07/information-transmission-in-a-social-network-dissecting-the-spread-of-a-quora-post/"&gt;I love investigating social networks&lt;/a&gt;, so I dug around a little, and since I did well enough to score one of the coveted prizes, I&amp;#8217;ll share …&lt;/p&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Edwin Chen</dc:creator><pubDate>Tue, 31 Jul 2012 04:15:00 +0200</pubDate><guid isPermaLink="false">tag:blog.echen.me,2012-07-31:/2012/07/31/edge-prediction-in-a-social-graph-my-solution-to-facebooks-user-recommendation-contest-on-kaggle/</guid><category>misc</category></item><item><title>Soda vs. Pop with Twitter</title><link>http://blog.echen.me/2012/07/06/soda-vs-pop-with-twitter/</link><description>
  &lt;div class="entry-content"&gt;&lt;p&gt;One of the great things about Twitter is that it&amp;#8217;s a global conversation anyone can join anytime. Eavesdropping on the world, what what!&lt;/p&gt;

  &lt;p&gt;Of course, it gets even better when you can &lt;em&gt;mine&lt;/em&gt; all this chatter to study the way humans live and interact.&lt;/p&gt;

  &lt;p&gt;For example, &lt;a href="http://blog.echen.me/2011/04/18/twifferences-between-californians-and-new-yorkers/"&gt;how do people …&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Edwin Chen</dc:creator><pubDate>Fri, 06 Jul 2012 04:15:00 +0200</pubDate><guid isPermaLink="false">tag:blog.echen.me,2012-07-06:/2012/07/06/soda-vs-pop-with-twitter/</guid><category>misc</category></item><item><title>Infinite Mixture Models with Nonparametric Bayes and the Dirichlet Process</title><link>http://blog.echen.me/2012/03/20/infinite-mixture-models-with-nonparametric-bayes-and-the-dirichlet-process/</link><description>
  &lt;div class="entry-content"&gt;&lt;p&gt;Imagine you&amp;#8217;re a budding chef. A data-curious one, of course, so you start by taking a set of foods (pizza, salad, spaghetti, etc.) and ask 10 friends how much of each they ate in the past day.&lt;/p&gt;

  &lt;p&gt;Your goal: to find natural &lt;em&gt;groups&lt;/em&gt; of foodies, so that you can …&lt;/p&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Edwin Chen</dc:creator><pubDate>Tue, 20 Mar 2012 04:15:00 +0100</pubDate><guid isPermaLink="false">tag:blog.echen.me,2012-03-20:/2012/03/20/infinite-mixture-models-with-nonparametric-bayes-and-the-dirichlet-process/</guid><category>misc</category></item><item><title>Instant Interactive Visualization with d3 + ggplot2</title><link>http://blog.echen.me/2012/03/05/instant-interactive-visualization-with-d3-and-ggplot2/</link><description>
  &lt;div class="entry-content"&gt;&lt;p&gt;It&amp;#8217;s often easier to understand a chart than a table. So why is it still so hard to make a simple data graphic, and why am I still bombarded by mind-numbing reams of raw &lt;em&gt;numbers&lt;/em&gt;?&lt;/p&gt;

  &lt;p&gt;(Yeah, I love &lt;a href="http://blog.echen.me/2012/01/17/quick-introduction-to-ggplot2/"&gt;ggplot2&lt;/a&gt; to death. But sometimes I want a little more interaction …&lt;/p&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Edwin Chen</dc:creator><pubDate>Mon, 05 Mar 2012 04:15:00 +0100</pubDate><guid isPermaLink="false">tag:blog.echen.me,2012-03-05:/2012/03/05/instant-interactive-visualization-with-d3-and-ggplot2/</guid><category>misc</category></item><item><title>Movie Recommendations and More via MapReduce and Scalding</title><link>http://blog.echen.me/2012/02/09/movie-recommendations-and-more-via-mapreduce-and-scalding/</link><description>
  &lt;div class="entry-content"&gt;&lt;p&gt;&lt;em&gt;Scalding is an in-house MapReduce framework that Twitter recently open-sourced. Like &lt;a href="http://pig.apache.org/"&gt;Pig&lt;/a&gt;, it provides an abstraction on top of MapReduce that makes it easy to write big data jobs in a syntax that&amp;#8217;s simple and concise. Unlike Pig, Scalding is written in pure Scala &amp;#8211; which means all the power …&lt;/em&gt;&lt;/p&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Edwin Chen</dc:creator><pubDate>Thu, 09 Feb 2012 04:15:00 +0100</pubDate><guid isPermaLink="false">tag:blog.echen.me,2012-02-09:/2012/02/09/movie-recommendations-and-more-via-mapreduce-and-scalding/</guid><category>misc</category></item><item><title>Quick Introduction to ggplot2</title><link>http://blog.echen.me/2012/01/17/quick-introduction-to-ggplot2/</link><description>
  &lt;div class="entry-content"&gt;&lt;p&gt;This is a bare-bones introduction to &lt;a href="http://had.co.nz/ggplot2/"&gt;ggplot2&lt;/a&gt;, a visualization package in R. It assumes no knowledge of R.&lt;/p&gt;

  &lt;p&gt;For a better-looking version of this post, see &lt;a href="https://github.com/echen/ggplot2-tutorial"&gt;this Github repository&lt;/a&gt;, which also contains some of the &lt;a href="https://github.com/echen/ggplot2-tutorial/tree/master/data"&gt;example datasets&lt;/a&gt; I use and a &lt;a href="https://github.com/echen/ggplot2-tutorial/blob/master/ggplot2-tutorial.R"&gt;literate programming version&lt;/a&gt; of this tutorial.&lt;/p&gt;

  &lt;h1&gt;Preview&lt;/h1&gt;

  &lt;p&gt;Let&amp;#8217;s …&lt;/p&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Edwin Chen</dc:creator><pubDate>Tue, 17 Jan 2012 04:15:00 +0100</pubDate><guid isPermaLink="false">tag:blog.echen.me,2012-01-17:/2012/01/17/quick-introduction-to-ggplot2/</guid><category>misc</category></item><item><title>Introduction to Conditional Random Fields</title><link>http://blog.echen.me/2012/01/03/introduction-to-conditional-random-fields/</link><description>&lt;p&gt;Imagine you have a sequence of snapshots from a day in Justin Bieber’s life, and you want to label each image with the activity it represents (eating, sleeping, driving, etc.). How can you do this?&lt;/p&gt;
&lt;p&gt;One way is to ignore the sequential nature of the snapshots, and build a …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Edwin Chen</dc:creator><pubDate>Tue, 03 Jan 2012 00:00:00 +0100</pubDate><guid isPermaLink="false">tag:blog.echen.me,2012-01-03:/2012/01/03/introduction-to-conditional-random-fields/</guid><category>misc</category></item><item><title>Winning the Netflix Prize: A Summary</title><link>http://blog.echen.me/2011/10/24/winning-the-netflix-prize-a-summary/</link><description>
  &lt;div class="entry-content"&gt;&lt;p&gt;How was the &lt;a href="http://en.wikipedia.org/wiki/Netflix_Prize"&gt;Netflix Prize&lt;/a&gt; won? I went through a lot of the Netflix Prize papers a couple years ago, so I&amp;#8217;ll try to give an overview of the techniques that went into the winning solution here.&lt;/p&gt;

  &lt;h1&gt;Normalization of Global Effects&lt;/h1&gt;

  &lt;p&gt;Suppose Alice rates Inception 4 stars. We can …&lt;/p&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Edwin Chen</dc:creator><pubDate>Mon, 24 Oct 2011 04:15:00 +0200</pubDate><guid isPermaLink="false">tag:blog.echen.me,2011-10-24:/2011/10/24/winning-the-netflix-prize-a-summary/</guid><category>misc</category></item><item><title>Stuff Harvard People Like</title><link>http://blog.echen.me/2011/09/29/stuff-harvard-people-like/</link><description>
  &lt;div class="entry-content"&gt;&lt;p&gt;What types of students go to which schools? There are, of course, the classic stereotypes:&lt;/p&gt;

  &lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;MIT&lt;/strong&gt; has the hacker engineers.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Stanford&lt;/strong&gt; has the laid-back, social folks.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Harvard&lt;/strong&gt; has the prestigious leaders of the world.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Berkeley&lt;/strong&gt; has the activist hippies.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Caltech&lt;/strong&gt; has the hardcore science nerds.&lt;/li&gt;
  &lt;/ul&gt;


  &lt;p&gt;But how well do these …&lt;/p&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Edwin Chen</dc:creator><pubDate>Thu, 29 Sep 2011 04:15:00 +0200</pubDate><guid isPermaLink="false">tag:blog.echen.me,2011-09-29:/2011/09/29/stuff-harvard-people-like/</guid><category>misc</category></item><item><title>Information Transmission in a Social Network: Dissecting the Spread of a Quora Post</title><link>http://blog.echen.me/2011/09/07/information-transmission-in-a-social-network-dissecting-the-spread-of-a-quora-post/</link><description>
  &lt;div class="entry-content"&gt;&lt;p&gt;&lt;strong&gt;tl;dr&lt;/strong&gt; See &lt;a href="http://www.youtube.com/watch?v=cZ4Ntg4jQHw"&gt;this movie visualization&lt;/a&gt; for a case study on how a post propagates through Quora.&lt;/p&gt;

  &lt;p&gt;How does information spread through a network? Much of Quora&amp;#8217;s appeal, after all, lies in its social graph &amp;#8211; and when you&amp;#8217;ve got a network of users, all broadcasting their activities to …&lt;/p&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Edwin Chen</dc:creator><pubDate>Wed, 07 Sep 2011 04:15:00 +0200</pubDate><guid isPermaLink="false">tag:blog.echen.me,2011-09-07:/2011/09/07/information-transmission-in-a-social-network-dissecting-the-spread-of-a-quora-post/</guid><category>misc</category></item><item><title>Introduction to Latent Dirichlet Allocation</title><link>http://blog.echen.me/2011/08/22/introduction-to-latent-dirichlet-allocation/</link><description>
  &lt;div class="entry-content"&gt;&lt;h1&gt;Introduction&lt;/h1&gt;

  &lt;p&gt;Suppose you have the following set of sentences:&lt;/p&gt;

  &lt;ul&gt;
  &lt;li&gt;I like to eat broccoli and bananas.&lt;/li&gt;
  &lt;li&gt;I ate a banana and spinach smoothie for breakfast.&lt;/li&gt;
  &lt;li&gt;Chinchillas and kittens are cute.&lt;/li&gt;
  &lt;li&gt;My sister adopted a kitten yesterday.&lt;/li&gt;
  &lt;li&gt;Look at this cute hamster munching on a piece of broccoli.&lt;/li&gt;
  &lt;/ul&gt;


  &lt;p&gt;What is latent …&lt;/p&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Edwin Chen</dc:creator><pubDate>Mon, 22 Aug 2011 04:15:00 +0200</pubDate><guid isPermaLink="false">tag:blog.echen.me,2011-08-22:/2011/08/22/introduction-to-latent-dirichlet-allocation/</guid><category>misc</category></item><item><title>Introduction to Restricted Boltzmann Machines</title><link>http://blog.echen.me/2011/07/18/introduction-to-restricted-boltzmann-machines/</link><description>&lt;p&gt;Suppose you ask a bunch of users to rate a set of movies on a 0-100 scale. In classical factor analysis, you could then try to explain each movie and user in terms of a set of latent &lt;strong&gt;factors&lt;/strong&gt;. For example, movies like Star Wars and Lord of the Rings …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Edwin Chen</dc:creator><pubDate>Mon, 18 Jul 2011 00:00:00 +0200</pubDate><guid isPermaLink="false">tag:blog.echen.me,2011-07-18:/2011/07/18/introduction-to-restricted-boltzmann-machines/</guid><category>misc</category></item><item><title>Topic Modeling the Sarah Palin Emails</title><link>http://blog.echen.me/2011/06/27/topic-modeling-the-sarah-palin-emails/</link><description>
  &lt;div class="entry-content"&gt;&lt;h1&gt;LDA-based Email Browser&lt;/h1&gt;

  &lt;p&gt;Earlier this month, several thousand emails from Sarah Palin&amp;#8217;s time as governor of Alaska were &lt;a href="http://sunlightlabs.com/blog/2011/sarahs-inbox/"&gt;released&lt;/a&gt;. The emails weren&amp;#8217;t organized in any fashion, though, so to make them easier to browse, I&amp;#8217;ve been working on some topic modeling (in particular, using latent Dirichlet allocation …&lt;/p&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Edwin Chen</dc:creator><pubDate>Mon, 27 Jun 2011 04:15:00 +0200</pubDate><guid isPermaLink="false">tag:blog.echen.me,2011-06-27:/2011/06/27/topic-modeling-the-sarah-palin-emails/</guid><category>misc</category></item><item><title>Filtering for English Tweets: Unsupervised Language Detection on Twitter</title><link>http://blog.echen.me/2011/05/01/unsupervised-language-detection-algorithms/</link><description>
  &lt;div class="entry-content"&gt;&lt;p&gt;(See a demo &lt;a href="http://babel-fett.heroku.com/"&gt;here&lt;/a&gt;.)&lt;/p&gt;

  &lt;p&gt;While working on a Twitter sentiment analysis project, I ran into the problem of needing to filter out all non-English tweets. (Asking the Twitter API for English-only tweets doesn&amp;#8217;t seem to work, as it nonetheless returns tweets in Spanish, Portuguese, Dutch, Russian, and a couple …&lt;/p&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Edwin Chen</dc:creator><pubDate>Sun, 01 May 2011 04:15:00 +0200</pubDate><guid isPermaLink="false">tag:blog.echen.me,2011-05-01:/2011/05/01/unsupervised-language-detection-algorithms/</guid><category>misc</category></item><item><title>Choosing a Machine Learning Classifier</title><link>http://blog.echen.me/2011/04/27/choosing-a-machine-learning-classifier/</link><description>
  &lt;div class="entry-content"&gt;&lt;p&gt;How do you know what machine learning algorithm to choose for your classification problem? Of course, if you really care about accuracy, your best bet is to test out a couple different ones (making sure to try different parameters within each algorithm as well), and select the best one by …&lt;/p&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Edwin Chen</dc:creator><pubDate>Wed, 27 Apr 2011 04:15:00 +0200</pubDate><guid isPermaLink="false">tag:blog.echen.me,2011-04-27:/2011/04/27/choosing-a-machine-learning-classifier/</guid><category>misc</category></item><item><title>Kickstarter Data Analysis: Success and Pricing</title><link>http://blog.echen.me/2011/04/25/kickstarter-data-analysis-success-and-pricing/</link><description>
  &lt;div class="entry-content"&gt;&lt;p&gt;&lt;a href="http://www.kickstarter.com/"&gt;Kickstarter&lt;/a&gt; is an online crowdfunding platform for launching creative projects. When starting a new project, project owners specify a deadline and the minimum amount of money they need to raise. They receive the money (less a transaction fee) only if they reach or exceed that minimum; otherwise, no money changes …&lt;/p&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Edwin Chen</dc:creator><pubDate>Mon, 25 Apr 2011 04:15:00 +0200</pubDate><guid isPermaLink="false">tag:blog.echen.me,2011-04-25:/2011/04/25/kickstarter-data-analysis-success-and-pricing/</guid><category>misc</category></item><item><title>A Mathematical Introduction to Least Angle Regression</title><link>http://blog.echen.me/2011/04/21/a-mathematical-introduction-to-least-angle-regression/</link><description>
  &lt;div class="entry-content"&gt;&lt;p&gt;(For a layman&amp;#8217;s introduction, see &lt;a href="http://blog.echen.me/2011/03/14/least-angle-regression-for-the-hungry-layman/"&gt;here&lt;/a&gt;.)&lt;/p&gt;

  &lt;p&gt;Least Angle Regression (aka LARS) is a &lt;strong&gt;model selection method&lt;/strong&gt; for linear regression (when you&amp;#8217;re worried about overfitting or want your model to be easily interpretable). To motivate it, let&amp;#8217;s consider some other model selection methods:&lt;/p&gt;

  &lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Forward selection&lt;/strong&gt; starts with no …&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Edwin Chen</dc:creator><pubDate>Thu, 21 Apr 2011 04:15:00 +0200</pubDate><guid isPermaLink="false">tag:blog.echen.me,2011-04-21:/2011/04/21/a-mathematical-introduction-to-least-angle-regression/</guid><category>misc</category></item><item><title>Introduction to Cointegration and Pairs Trading</title><link>http://blog.echen.me/2011/04/16/introduction-to-cointegration-and-pairs-trading/</link><description>
  &lt;div class="entry-content"&gt;&lt;h1&gt;Introduction&lt;/h1&gt;

  &lt;p&gt;Suppose you see two drunks (i.e., two random walks) wandering around. The drunks don&amp;#8217;t know each other (they&amp;#8217;re independent), so there&amp;#8217;s no meaningful relationship between their paths.&lt;/p&gt;

  &lt;p&gt;But suppose instead you have a drunk walking with her dog. This time there &lt;em&gt;is&lt;/em&gt; a connection. What …&lt;/p&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Edwin Chen</dc:creator><pubDate>Sat, 16 Apr 2011 04:15:00 +0200</pubDate><guid isPermaLink="false">tag:blog.echen.me,2011-04-16:/2011/04/16/introduction-to-cointegration-and-pairs-trading/</guid><category>misc</category></item><item><title>Counting Clusters</title><link>http://blog.echen.me/2011/03/14/counting-clusters/</link><description>
  
  &lt;div class="entry-content"&gt;&lt;p&gt;Given a set of datapoints, we often want to know how many clusters the datapoints form. The &lt;strong&gt;gap statistic&lt;/strong&gt; and the &lt;strong&gt;prediction strength&lt;/strong&gt; are two practical algorithms for choosing the number of clusters.&lt;/p&gt;

  &lt;h1&gt;Gap Statistic&lt;/h1&gt;

  &lt;p&gt;The &lt;a href="http://www.stanford.edu/~hastie/Papers/gap.pdf"&gt;gap statistic algorithm&lt;/a&gt; works as follows:&lt;/p&gt;

  &lt;p&gt;For each i from 1 up to some …&lt;/p&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Edwin Chen</dc:creator><pubDate>Mon, 14 Mar 2011 04:15:00 +0100</pubDate><guid isPermaLink="false">tag:blog.echen.me,2011-03-14:/2011/03/14/counting-clusters/</guid><category>misc</category></item><item><title>Hacker News Analysis</title><link>http://blog.echen.me/2011/03/14/hacker-news-analysis/</link><description>
  
  &lt;div class="entry-content"&gt;&lt;p&gt;I was playing around with the &lt;a href="http://api.ihackernews.com/?db"&gt;Hacker News database&lt;/a&gt; &lt;a href="http://ronnieroller.com/"&gt;Ronnie Roller&lt;/a&gt; made (thanks!), so I thought I&amp;#8217;d post some of the things I looked at.&lt;/p&gt;

  &lt;h1&gt;Activity on the Site&lt;/h1&gt;

  &lt;p&gt;My first question was how activity on the site has increased over time. I looked at number of posts, points …&lt;/p&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Edwin Chen</dc:creator><pubDate>Mon, 14 Mar 2011 04:15:00 +0100</pubDate><guid isPermaLink="false">tag:blog.echen.me,2011-03-14:/2011/03/14/hacker-news-analysis/</guid><category>misc</category></item><item><title>Layman's Introduction to Measure Theory</title><link>http://blog.echen.me/2011/03/14/laymans-introduction-to-measure-theory/</link><description>
  
  &lt;div class="entry-content"&gt;&lt;p&gt;Measure theory studies ways of generalizing the notions of length/area/volume. Even in 2 dimensions, it might not be clear how to measure the area of the following fairly tame shape:&lt;/p&gt;

  &lt;p&gt;&lt;img src="http://d2o7bfz2il9cb7.cloudfront.net/main-qimg-809c3bdb18539dfa2917ee766a0a6159" alt="What's the area of this shape?" /&gt;&lt;/p&gt;

  &lt;p&gt;much less the &amp;#8220;area&amp;#8221; of even weirder shapes in higher dimensions or different spaces entirely.&lt;/p&gt;

  &lt;p&gt;For example, suppose …&lt;/p&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Edwin Chen</dc:creator><pubDate>Mon, 14 Mar 2011 04:15:00 +0100</pubDate><guid isPermaLink="false">tag:blog.echen.me,2011-03-14:/2011/03/14/laymans-introduction-to-measure-theory/</guid><category>misc</category></item><item><title>Layman's Introduction to Random Forests</title><link>http://blog.echen.me/2011/03/14/laymans-introduction-to-random-forests/</link><description>
  
  &lt;div class="entry-content"&gt;&lt;p&gt;Suppose you&amp;#8217;re very indecisive, so whenever you want to watch a movie, you ask your friend Willow if she thinks you&amp;#8217;ll like it. In order to answer, Willow first needs to figure out what movies you like, so you give her a bunch of movies and tell her …&lt;/p&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Edwin Chen</dc:creator><pubDate>Mon, 14 Mar 2011 04:15:00 +0100</pubDate><guid isPermaLink="false">tag:blog.echen.me,2011-03-14:/2011/03/14/laymans-introduction-to-random-forests/</guid><category>misc</category></item><item><title>Netflix Prize Summary: Factorization Meets the Neighborhood</title><link>http://blog.echen.me/2011/03/14/netflix-prize-summary-factorization-meets-the-neighborhood/</link><description>
  
  &lt;div class="entry-content"&gt;&lt;p&gt;(Way back when, I went through all the Netflix prize papers. I&amp;#8217;m now (very slowly) trying to clean up my notes and put them online. Eventually, I hope to have a more integrated tutorial, but here&amp;#8217;s a rough draft for now.)&lt;/p&gt;

  &lt;p&gt;This is a summary of Koren&amp;#8217;s …&lt;/p&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Edwin Chen</dc:creator><pubDate>Mon, 14 Mar 2011 04:15:00 +0100</pubDate><guid isPermaLink="false">tag:blog.echen.me,2011-03-14:/2011/03/14/netflix-prize-summary-factorization-meets-the-neighborhood/</guid><category>misc</category></item><item><title>Netflix Prize Summary: Scalable Collaborative Filtering with Jointly Derived Neighborhood Interpolation Weights</title><link>http://blog.echen.me/2011/03/14/netflix-prize-summary-scalable-collaborative-filtering-with-jointly-derived-neighborhood-interpolation-weights/</link><description>
  
  &lt;div class="entry-content"&gt;&lt;p&gt;(Way back when, I went through all the Netflix prize papers. I&amp;#8217;m now (very slowly) trying to clean up my notes and put them online. Eventually, I hope to have a more integrated tutorial, but here&amp;#8217;s a rough draft for now.)&lt;/p&gt;

  &lt;p&gt;This is a summary of Bell and …&lt;/p&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Edwin Chen</dc:creator><pubDate>Mon, 14 Mar 2011 04:15:00 +0100</pubDate><guid isPermaLink="false">tag:blog.echen.me,2011-03-14:/2011/03/14/netflix-prize-summary-scalable-collaborative-filtering-with-jointly-derived-neighborhood-interpolation-weights/</guid><category>misc</category></item><item><title>Prime Numbers and the Riemann Zeta Function</title><link>http://blog.echen.me/2011/03/14/prime-numbers-and-the-riemann-zeta-function/</link><description>
  
  &lt;div class="entry-content"&gt;&lt;p&gt;Lots of people know that the &lt;a href="http://en.wikipedia.org/wiki/Riemann_hypothesis"&gt;Riemann Hypothesis&lt;/a&gt; has &lt;em&gt;something&lt;/em&gt; to do with prime numbers, but most introductions fail to say what or why. I&amp;#8217;ll try to give one angle of explanation.&lt;/p&gt;




  &lt;h1&gt;Layman&amp;#8217;s Terms&lt;/h1&gt;




  &lt;p&gt;Suppose you have a bunch of friends, each with an instrument that plays at …&lt;/p&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Edwin Chen</dc:creator><pubDate>Mon, 14 Mar 2011 04:15:00 +0100</pubDate><guid isPermaLink="false">tag:blog.echen.me,2011-03-14:/2011/03/14/prime-numbers-and-the-riemann-zeta-function/</guid><category>misc</category></item><item><title>Topological Combinatorics and the Evasiveness Conjecture</title><link>http://blog.echen.me/2011/03/14/topological-combinatorics-and-the-evasiveness-conjecture/</link><description>
  
  &lt;div class="entry-content"&gt;&lt;p&gt;The Kahn, Saks, and Sturtevant approach to the Evasiveness Conjecture (see the original paper &lt;a href="http://www.springerlink.com/index/R521072311641L41.pdf"&gt;here&lt;/a&gt;) is an epic application of pure mathematics to computer science. I&amp;#8217;ll give an overview of the approach here, and probably try to add some more information on the problem in other posts.&lt;/p&gt;

  &lt;p&gt;&lt;strong&gt;tl;dr …&lt;/strong&gt;&lt;/p&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Edwin Chen</dc:creator><pubDate>Mon, 14 Mar 2011 04:15:00 +0100</pubDate><guid isPermaLink="false">tag:blog.echen.me,2011-03-14:/2011/03/14/topological-combinatorics-and-the-evasiveness-conjecture/</guid><category>misc</category></item><item><title>Item-to-Item Collaborative Filtering with Amazon's Recommendation System</title><link>http://blog.echen.me/2011/02/15/item-to-item-collaborative-filtering-with-amazons-recommendation-system/</link><description>
  
&lt;div class="entry-content"&gt;&lt;h1&gt;Introduction&lt;/h1&gt;

&lt;p&gt;In making its product recommendations, Amazon makes heavy use of an item-to-item collaborative filtering approach. This essentially means that for each item X, Amazon builds a neighborhood of related items S(X); whenever you buy/look at an item, Amazon then recommends you items from that item&amp;#8217;s neighborhood …&lt;/p&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Edwin Chen</dc:creator><pubDate>Tue, 15 Feb 2011 04:15:00 +0100</pubDate><guid isPermaLink="false">tag:blog.echen.me,2011-02-15:/2011/02/15/item-to-item-collaborative-filtering-with-amazons-recommendation-system/</guid><category>misc</category></item></channel></rss>