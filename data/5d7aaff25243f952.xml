<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	xmlns:georss="http://www.georss.org/georss" xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#" xmlns:media="http://search.yahoo.com/mrss/"
	>

<channel>
	<title>calculated &#124; content</title>
	<atom:link href="https://calculatedcontent.com/feed/" rel="self" type="application/rss+xml" />
	<link>https://calculatedcontent.com</link>
	<description>Thoughts on Data Science, Machine Learning, and AI</description>
	<lastBuildDate>Fri, 04 Nov 2022 22:23:41 +0000</lastBuildDate>
	<language>en</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>http://wordpress.com/</generator>

<image>
	<url>https://charlesmartin14.files.wordpress.com/2018/02/cropped-wordpress-icon-logo2.png?w=32</url>
	<title>calculated &#124; content</title>
	<link>https://calculatedcontent.com</link>
	<width>32</width>
	<height>32</height>
</image> 
<cloud domain='calculatedcontent.com' port='80' path='/?rsscloud=notify' registerProcedure='' protocol='http-post' />
<atom:link rel="search" type="application/opensearchdescription+xml" href="https://calculatedcontent.com/osd.xml" title="calculated &#124; content" />
	<atom:link rel='hub' href='https://calculatedcontent.com/?pushpress=hub'/>
	<item>
		<title>Better than BERT:  Pick your best model</title>
		<link>https://calculatedcontent.com/2022/07/22/better-than-bert-pick-your-best-model/</link>
					<comments>https://calculatedcontent.com/2022/07/22/better-than-bert-pick-your-best-model/#respond</comments>
		
		<dc:creator><![CDATA[Charles H Martin, PhD]]></dc:creator>
		<pubDate>Fri, 22 Jul 2022 19:05:40 +0000</pubDate>
				<category><![CDATA[Uncategorized]]></category>
		<guid isPermaLink="false">http://calculatedcontent.com/?p=14535</guid>

					<description><![CDATA[Have you ever had to sort through HuggingFace to find your best model ? There are over 54,000 models on &#8230; <a class="more-link" href="https://calculatedcontent.com/2022/07/22/better-than-bert-pick-your-best-model/">More</a>]]></description>
										<content:encoded><![CDATA[
<p>Have you ever had to sort through HuggingFace to find your best model ?  There are over 54,000 models on HuggingFace!  So it&#8217;s not an easy task.</p>


<div class="wp-block-image">
<figure class="alignleft size-large is-resized"><a href="https://charlesmartin14.files.wordpress.com/2022/07/image.png"><img loading="lazy" data-attachment-id="14539" data-permalink="https://calculatedcontent.com/2022/07/22/better-than-bert-pick-your-best-model/image-5/" data-orig-file="https://charlesmartin14.files.wordpress.com/2022/07/image.png" data-orig-size="1226,675" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2022/07/image.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2022/07/image.png?w=1024" src="https://charlesmartin14.files.wordpress.com/2022/07/image.png?w=1024" alt="" class="wp-image-14539" width="236" height="129" srcset="https://charlesmartin14.files.wordpress.com/2022/07/image.png?w=234 234w, https://charlesmartin14.files.wordpress.com/2022/07/image.png?w=469 469w, https://charlesmartin14.files.wordpress.com/2022/07/image.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2022/07/image.png?w=300 300w" sizes="(max-width: 236px) 100vw, 236px" /></a></figure></div>


<p>Most people just choose the most popular model&#8211;and this is usually BERT.  Or some BERT variant.  Bert was created by Google, so it must be good.  </p>



<p>But is BERT the really best choice for you ?  </p>



<p>How can you find out ? You can search through the literature, read blogs, ask on Reddit, etc, and try to find a better model.  This is time consuming and imperfect.  Fortunately, there is a better way.</p>



<p class="has-text-align-center">The <a href="https://weightwatcher.ai" target="_blank" rel="noreferrer noopener">weightwatcher</a> tool can tell you.</p>



<p>WeightWatcher is an open-source, data-free diagnostic tool that can estimate the quality of an DNN model like BERT, GPT, etc&#8211;without needing any data!  (No training or test data&#8211;just the weights).   It has been featured in <a rel="noreferrer noopener" href="https://jmlr.org/papers/v22/20-410.html" target="_blank">JMLR</a>, at ICML and KDD, and even in <a rel="noreferrer noopener" href="https://www.nature.com/articles/s41467-021-24025-8" target="_blank">Nature</a>.</p>



<p>Here&#8217;s an example using weightwatcher to compare of 3 NLP models: <mark style="background-color:rgba(0, 0, 0, 0);color:#181fc6;" class="has-inline-color"><strong>BERT</strong></mark>, <mark style="background-color:rgba(0, 0, 0, 0);color:#d51e1e;" class="has-inline-color"><strong>RoBERTa</strong></mark>, and <mark style="background-color:rgba(0, 0, 0, 0);color:#2d820a;" class="has-inline-color"><strong>XNLet</strong></mark> </p>


<div class="wp-block-image">
<figure class="aligncenter size-large is-resized"><a href="https://charlesmartin14.files.wordpress.com/2022/07/image-1.png"><img loading="lazy" data-attachment-id="14541" data-permalink="https://calculatedcontent.com/2022/07/22/better-than-bert-pick-your-best-model/image-1-3/" data-orig-file="https://charlesmartin14.files.wordpress.com/2022/07/image-1.png" data-orig-size="1342,746" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-1" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2022/07/image-1.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2022/07/image-1.png?w=1024" src="https://charlesmartin14.files.wordpress.com/2022/07/image-1.png?w=1024" alt="" class="wp-image-14541" width="528" height="293" srcset="https://charlesmartin14.files.wordpress.com/2022/07/image-1.png?w=1024 1024w, https://charlesmartin14.files.wordpress.com/2022/07/image-1.png?w=528 528w, https://charlesmartin14.files.wordpress.com/2022/07/image-1.png?w=1054 1054w, https://charlesmartin14.files.wordpress.com/2022/07/image-1.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2022/07/image-1.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2022/07/image-1.png?w=768 768w" sizes="(max-width: 528px) 100vw, 528px" /></a></figure></div>


<p>The WeightWatcher Power-Law (PL) metric <em>alpha</em> <img src="https://s0.wp.com/latex.php?latex=%28%5Calpha%29&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28%5Calpha%29&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28%5Calpha%29&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(&#92;alpha)" class="latex" /> is a DNN model quality metric; smaller is better.  This plot above displays all the layer <em>alpha</em> <img src="https://s0.wp.com/latex.php?latex=%28%5Calpha%29&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28%5Calpha%29&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28%5Calpha%29&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(&#92;alpha)" class="latex" /> values for the 3 models.  It is immediately clear that the<mark style="background-color:rgba(0, 0, 0, 0);color:#2d820a;" class="has-inline-color"> <strong>XNLet layers</strong> </mark>look much better than <mark style="background-color:rgba(0, 0, 0, 0);color:#181fc6;" class="has-inline-color"><strong>BERT</strong></mark> or <mark style="background-color:rgba(0, 0, 0, 0);color:#d51e1e;" class="has-inline-color"><strong>RoBERTa</strong></mark>; the <em>alpha</em> <img src="https://s0.wp.com/latex.php?latex=%28%5Calpha%29&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28%5Calpha%29&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28%5Calpha%29&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(&#92;alpha)" class="latex" /> values are smaller on average, and  there are no <em>alpha</em>s larger than 5: <img src="https://s0.wp.com/latex.php?latex=%28%5Calpha+%3C%3D5%29&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28%5Calpha+%3C%3D5%29&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28%5Calpha+%3C%3D5%29&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(&#92;alpha &lt;=5)" class="latex" />.  In contrast, the <mark style="background-color:rgba(0, 0, 0, 0);" class="has-inline-color"><strong style="color:rgb(24, 31, 198);">BERT</strong></mark> and <mark style="background-color:rgba(0, 0, 0, 0);color:#d51e1e;" class="has-inline-color"><strong>RoBERTa</strong></mark> alphas are much larger on average, and both models have too many large <em>alphas</em>.  </p>



<p>This is totally consistent with the published results.: <a rel="noreferrer noopener" href="https://arxiv.org/abs/1906.08237" target="_blank">In the original paper (from Microsoft Research)</a>,  XLNet outperforms BERT on 20 different NLP tasks.  </p>



<p><strong>Do it yourself:</strong></p>



<p>WeightWatcher will work with any HuggingFace Transformer (or CV) model.</p>



<p><a href="https://github.com/CalculatedContent/WeightWatcher/blob/master/examples/WW-BERT-BlogExample.ipynb" target="_blank" rel="noreferrer noopener">Here is a Google Colab notebook that lets you reproduce this yourself</a></p>



<p>Give it a try.   And if you need help with AI, ML, or just Data Science, please reach out. I provide strategy consulting, data science leadership, and hands-on, heads-down development. I will have availability in Q3 2022 for new projects. Reach out today.&nbsp;<a href="https://www.linkedin.com/feed/hashtag/?keywords=talktochuck&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A6941808930264150016">#talkToChuck</a>&nbsp;<a href="https://www.linkedin.com/feed/hashtag/?keywords=theaiguy&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A6941808930264150016">#theAIguy</a></p>
]]></content:encoded>
					
					<wfw:commentRss>https://calculatedcontent.com/2022/07/22/better-than-bert-pick-your-best-model/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		
		<media:thumbnail url="https://charlesmartin14.files.wordpress.com/2022/07/image-1.png" />
		<media:content url="https://charlesmartin14.files.wordpress.com/2022/07/image-1.png" medium="image">
			<media:title type="html">image-1</media:title>
		</media:content>

		<media:content url="https://1.gravatar.com/avatar/1ae78e5099a40f308b172a5a65416cab?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">charlesmartin14</media:title>
		</media:content>

		<media:content url="https://charlesmartin14.files.wordpress.com/2022/07/image.png?w=1024" medium="image" />

		<media:content url="https://charlesmartin14.files.wordpress.com/2022/07/image-1.png?w=1024" medium="image" />
	</item>
		<item>
		<title>Is your layer over-fit? (part 2)</title>
		<link>https://calculatedcontent.com/2022/06/14/is-your-layer-over-trained-part-2/</link>
					<comments>https://calculatedcontent.com/2022/06/14/is-your-layer-over-trained-part-2/#respond</comments>
		
		<dc:creator><![CDATA[Charles H Martin, PhD]]></dc:creator>
		<pubDate>Tue, 14 Jun 2022 20:53:05 +0000</pubDate>
				<category><![CDATA[Uncategorized]]></category>
		<guid isPermaLink="false">http://calculatedcontent.com/?p=14437</guid>

					<description><![CDATA[Say you are training a Deep Neural Network (DNN), and you see your model is over-trained. Or just not performing &#8230; <a class="more-link" href="https://calculatedcontent.com/2022/06/14/is-your-layer-over-trained-part-2/">More</a>]]></description>
										<content:encoded><![CDATA[
<p>Say you are training a Deep Neural Network (DNN), and you see your model is over-trained. Or just not performing well.   Is there a way to detect which layer is actually over-trained?  (or over-fit, as some people call it)</p>



<p>In this post, we will show how to use the open-source weightwatcher tool to answer this.</p>



<p>WeightWatcher is an open-source, data-free diagnostic tool for analyzing (pre-)trained DNNs. It is based on my personal research into Why Deep Learning Works, in collaboration with UC Berkeley. It is based on ideas from the Statistical Mechanics of Learning (i.e theoretical physics and chemistry).</p>



<p class="has-text-align-center"><code>pip install weightwatcher</code></p>



<p>WeightWatcher lets you inspect your layer weight matrices to see if they are converging properly. And in some cases, it can even tell you if the layer is over-trained.  The idea is simple. If you are training a model, and you over-regularize one of the layer, then you any observe the weightwatcher alpha metric drops below 2 (<img src="https://s0.wp.com/latex.php?latex=%5Calpha+%3C+2&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha+%3C+2&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha+%3C+2&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha &lt; 2" class="latex" />).  This is predicted by our HTSR theory of learning (although we have not published this specific result yet). And very unique as no other approach can do this.</p>



<p>To see how this works, we will look at a very specific, carefully-designed experiment where the theory is known to work exactly as advertised.  </p>



<p class="has-text-align-center"><strong>BUT (and here&#8217;s the disclaimer)</strong></p>



<p><em>Please be aware&#8211;training DNNs to State-of-the-Art (SOTA) is not easy, and applying the tool requires designing careful experiments that can isolate the problems you are trying to fix.  It does not work in every case, and you may see unusual results that are difficult to interpret.  In these cases, please feel free <a href="https://www.linkedin.com/in/charlesmartin14/" target="_blank" rel="noreferrer noopener">to reach out to me directly</a>, and<a href="https://join.slack.com/t/weightwatcherai/shared_invite/zt-1511mk1d2-OvauYoot8_gm_YKIRT381Q" target="_blank" rel="noreferrer noopener"> join our Slack channel </a>to get help.</em></p>



<p class="has-text-align-center"><strong>Having said that, let&#8217;s get started</strong></p>



<p>First, <a rel="noreferrer noopener" href="https://github.com/CalculatedContent/WeightWatcher/blob/master/WW_MLP3_BatchSizes.ipynb" target="_blank">here&#8217;s the Google </a><a href="https://github.com/CalculatedContent/WeightWatcher/blob/master/examples/WW_MLP3_BatchSizes.ipynb" target="_blank" rel="noreferrer noopener">Colab</a><a rel="noreferrer noopener" href="https://github.com/CalculatedContent/WeightWatcher/blob/master/WW_MLP3_BatchSizes.ipynb" target="_blank"> notebook</a> for reproducing this post; please try it yourself.</p>



<h2>Experimental Design</h2>



<p>We consider a very simple DNN, a 3-layer MLP (Multi-Layer Perceptron), trained on MNIST.   </p>



<p>To induce the overtraining, we will train this model using different batch sizes, with <code>batch_size in [1,2,4,8,16,32]</code>.  </p>



<p><strong>Why do we vary the batch sizes</strong> ?&#8230; and not a specific regularization hyper-parameter like Weight Decay or Dropout?  The batch size acts like a very strong regularizer, which can induce the Heavy-Tails we see in SOTA models even in this very small model and generally poorly performing model.  This is shown in Figure 25 of <a href="https://jmlr.org/papers/volume22/20-410/20-410.pdf" target="_blank" rel="noreferrer noopener">our JMLR paper describing our theory of Heavy-Tailed Self-Regularization (HT-SR)</a>, the theory behind weightwatcher.</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><a href="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-10.38.14-am.png"><img data-attachment-id="14455" data-permalink="https://calculatedcontent.com/2022/06/14/is-your-layer-over-trained-part-2/screen-shot-2022-06-14-at-10-38-14-am/" data-orig-file="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-10.38.14-am.png" data-orig-size="1262,898" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2022-06-14-at-10.38.14-am" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-10.38.14-am.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-10.38.14-am.png?w=1024" src="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-10.38.14-am.png?w=1024" alt="" class="wp-image-14455" srcset="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-10.38.14-am.png?w=1024 1024w, https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-10.38.14-am.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-10.38.14-am.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-10.38.14-am.png?w=768 768w, https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-10.38.14-am.png 1262w" sizes="(max-width: 1024px) 100vw, 1024px" /></a></figure></div>


<p>Moreover, with extremely small batch sizes, and a long number of epochs, we can even drive the model into a state of over-training.  Which is the goal here.So each model is trained for a very long number of epochs, and until the training loss stabilizes, using a Keras EarlyStopping Callback</p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: python; title: ; notranslate">
tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3, verbose=0, min_delta=0.001, restore_best_weights=True)e()
</pre></div>


<p><strong>In your own models, the situation may be more complex</strong>.   </p>



<p>The weightwatcher metrics work best when applied to SOTA models because this is when the layer weight matrics are best correlated, and the Power Law fits work the best.  It takes some work to design experiments on small models that can flush out these features.  So we choose to use the batch size to induce this effect.  But let me encourage you to try other approaches.</p>



<p>The key to using the HTSR theory is to carefully control the training so that when you adjust some other knob (i.e Dropout, momentum, weight decay) that the training and test error change smoothly and systematically.  If, however,  the training accuracy or loss is unstable, and you are jumping all over the loss landscape, then HTSR theory, is more difficult to apply.  So, here, </p>



<p class="has-text-align-center"><em><strong>I follow the KISS mantra: &#8220;Keep It Super Simple!&#8221;</strong></em></p>



<h3>Reproducibility</h3>



<p>To compare 2 or more models to each other, with different batch sizes, for the purposes here, we need to ensure they have been trained with the exact same initial conditions.  To do this, we have to both set all the random seeds to a default value and tell the framework (here, Keras) to use deterministic options.  This also, nicely, makes the experiments 100% reproducible.  </p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: python; title: ; notranslate">
%env CUBLAS_WORKSPACE_CONFIG=:4096:8

import random
def reset_random_seeds(seed_value=42):
   os.environ&#91;'PYTHONHASHSEED']=str(seed_value)
   tf.random.set_seed(seed_value)
   tf.keras.utils.set_random_seed(seed_value)
   np.random.seed(seed_value)
   random.seed(seed_value)
   tf.config.experimental.enable_op_determinism()

</pre></div>


<p>Every time we build the model, we will first run <code>reset_random_seeds()</code>to ensure that every run, with different batch sizes, regularization, etc, is stated from the same spot and is reproducible.</p>



<h3>Model Size and Shape: The Three (3) Layers</h3>



<p>This model has 3 layers: input, hidden, and output. Note that each layer is initialized in the same way (i.e with GlorotNormalization, with the same seed).  Also, here, to <em>keep it super simple</em>,  no specific regularization is applied to the model (except for the changing of the batch size).</p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: python; title: ; notranslate">
initializer = tf.keras.initializers.GlorotNormal(seed=1)
  model = tf.keras.models.Sequential(&#91;
      tf.keras.layers.Flatten(input_shape = &#91;28,28]),
      tf.keras.layers.Dense(300, activation='relu', kernel_initializer=initializer),
      tf.keras.layers.Dense(100, activation='relu', kernel_initializer=initializer),
      tf.keras.layers.Dense(10, activation='softmax', kernel_initializer=initializer),
  ])escribe()Also, 
</pre></div>


<p>We can inspect the model using weightwatcher to see how the layers are labeled (layer_id), what kind of layer they are (DENSE, Conv2D, etc), and what their shapes are (N, M).  </p>



<div class="is-layout-flow wp-block-group"><div class="wp-block-group__inner-container"><div class="wp-block-syntaxhighlighter-code "><pre class="brush: python; title: ; notranslate">
import weightwatcher as ww
watcher = ww.WeightWatcher(model=model)
watcher.describe()
</pre></div></div></div>


<div class="wp-block-image">
<figure class="aligncenter size-large"><a href="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-10.08.35-am.png"><img data-attachment-id="14444" data-permalink="https://calculatedcontent.com/2022/06/14/is-your-layer-over-trained-part-2/screen-shot-2022-06-14-at-10-08-35-am/" data-orig-file="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-10.08.35-am.png" data-orig-size="1096,288" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2022-06-14-at-10.08.35-am" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-10.08.35-am.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-10.08.35-am.png?w=1024" src="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-10.08.35-am.png?w=1024" alt="" class="wp-image-14444" srcset="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-10.08.35-am.png?w=1024 1024w, https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-10.08.35-am.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-10.08.35-am.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-10.08.35-am.png?w=768 768w, https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-10.08.35-am.png 1096w" sizes="(max-width: 1024px) 100vw, 1024px" /></a><figcaption class="wp-element-caption">WeightWatcher Descirption DataFrame</figcaption></figure></div>


<p>In this experiment, we will analyze layer 1 (the Hidden Layer) and only layer 1.  This layer is a DENSE layer, which has a single weight matrix of dimension 100&#215;300.  It will have 100 eigenvalues, which is a large enough size for weightwatcher to analyze.  And for this super, simple experiment, this is the only later that is trainable; all other layers are held fixed.</p>



<h3>Training the model (with different batch sizes)</h3>



<p>Again, we will train the same model, with the same exact same initial conditions,  in a deterministic way, while changing the batch size.  For each fully trained model, we then compute the weighwatcher Power-Law capacity metric alpha (<img src="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha" class="latex" />).  We will then compare the layer 1 alpha <img src="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha" class="latex" />)  to the model test accuracy for each run.</p>



<p>Notice first that, however, when decreasing the batch size, both the training accuracy and the test accuracy improve both smoothly and systematically, and then drop off suddenly.  For example, below,  see that test accuracy increases from 89.0% at batch size 32 to 89.4% at batch size 4, and then drops off suddenly for batch size 2 down to 88.5%.   (The training accuracy behaves in a similar way when decreases the batch size, as can be seen in the notebook).</p>



<p class="has-text-align-center"><img data-attachment-id="14488" data-permalink="https://calculatedcontent.com/2022/06/14/is-your-layer-over-trained-part-2/screen-shot-2022-06-14-at-1-40-41-pm/" data-orig-file="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-1.40.41-pm.png" data-orig-size="830,570" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen Shot 2022-06-14 at 1.40.41 PM" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-1.40.41-pm.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-1.40.41-pm.png?w=830" class="wp-image-14488" style="width:500px;" src="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-1.40.41-pm.png" alt=""></p>



<p></p>



<p>Likewise, the training loss is varying smoothly, and the optimizer is not jumping all over the energy landscape.  This indicates a clean experiment, amenable to analysis.</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><a href="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-11.13.31-am.png"><img data-attachment-id="14467" data-permalink="https://calculatedcontent.com/2022/06/14/is-your-layer-over-trained-part-2/screen-shot-2022-06-14-at-11-13-31-am/" data-orig-file="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-11.13.31-am.png" data-orig-size="1276,576" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2022-06-14-at-11.13.31-am" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-11.13.31-am.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-11.13.31-am.png?w=1024" src="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-11.13.31-am.png?w=1024" alt="" class="wp-image-14467" srcset="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-11.13.31-am.png?w=1024 1024w, https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-11.13.31-am.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-11.13.31-am.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-11.13.31-am.png?w=768 768w, https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-11.13.31-am.png 1276w" sizes="(max-width: 1024px) 100vw, 1024px" /></a><figcaption class="wp-element-caption">Training and test losses for a sample run training the 3-layer MLP</figcaption></figure></div>


<p> </p>



<p>(Notice that we apply early stopping to the training loss, not the validation loss.  That is because, in this experiment, we are trying to drive the model to a state of over-training by reducing the batch size, and going past the perhaps more common early stopping critera on the validation loss.  Also, since we are changing the batch size, we want to ensure each model runs with enough epochs to the runs can be compared to each other).</p>



<h3>The WeightWatcher Layer Capacity Matric Alpha (<img src="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha" class="latex" />)</h3>



<p>To compute the weightwatcher metrics, at the end of every training cycle, just run</p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: python; title: ; notranslate">
results = watcher.analyze(layers=&#91;1])
</pre></div>


<p>The <code>watcher.analyze() </code>method will generate a pandas dataframe, with layer by layer metrics.</p>



<p><strong>What does alpha mean?  </strong>Alpha (<img src="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha" class="latex" />) is a measure of how Heavy-Tailed the layer is.  It can be found, crudely, by simply plotting a histogram of the eigenvalue of the layer correlation matrix, <code><strong>X</strong>=np.dot(W.T,W)</code>, on a log-log scale, and calculating the slope of this plot in the tail region.  Here is an example where <img src="https://s0.wp.com/latex.php?latex=%5Calpha%3D2.410&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha%3D2.410&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha%3D2.410&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha=2.410" class="latex" />.</p>



<p class="has-text-align-center"><img data-attachment-id="14472" data-permalink="https://calculatedcontent.com/2022/06/14/is-your-layer-over-trained-part-2/screen-shot-2022-06-14-at-11-19-39-am/" data-orig-file="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-11.19.39-am.png" data-orig-size="786,600" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen Shot 2022-06-14 at 11.19.39 AM" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-11.19.39-am.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-11.19.39-am.png?w=786" class="wp-image-14472" style="width:500px;" src="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-11.19.39-am.png" alt=""></p>



<p>The smaller alpha is, the more Heavy-Tailed the layer matrix <strong>X</strong> is, and the better the layer performs for the model.  <em>But only upto a point.</em>  If the layer is too Heavy-Tailed, where <img src="https://s0.wp.com/latex.php?latex=%5Calpha+%3C+2&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha+%3C+2&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha+%3C+2&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha &lt; 2" class="latex" /> (for simple models)  then it may be over-trained.</p>



<h2>Results: detecting an over-trained layer</h2>



<p>We can now plot the alpha vs the test accuracy for layer 1, and the result is quite amazing. </p>



<p class="has-text-align-center"><img data-attachment-id="14487" data-permalink="https://calculatedcontent.com/2022/06/14/is-your-layer-over-trained-part-2/screen-shot-2022-06-14-at-1-38-38-pm/" data-orig-file="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-1.38.38-pm.png" data-orig-size="816,580" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen Shot 2022-06-14 at 1.38.38 PM" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-1.38.38-pm.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-1.38.38-pm.png?w=816" class="wp-image-14487" style="width:500px;" src="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-1.38.38-pm.png" alt=""></p>



<p>Notice 2 key things</p>



<ul>
<li>as the test accuracy increases, the alpha metric decreases (<img src="https://s0.wp.com/latex.php?latex=%5Calpha%5Crightarrow+2&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha%5Crightarrow+2&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha%5Crightarrow+2&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha&#92;rightarrow 2" class="latex" />)</li>



<li>as soon the test accuracy drops (with batch size = 1),  alpha drops below 2 (<img src="https://s0.wp.com/latex.php?latex=%5Calpha+%3C+2&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha+%3C+2&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha+%3C+2&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha &lt; 2" class="latex" />)</li>
</ul>



<p>For simple models like this 3-layer MLP, the weightwatcher approach can, remarkably, detect which layer is over-trained!  No other theory can do this.</p>



<p>For more complex models, with lots of parameters varying, the situation may be more complex. </p>



<p>Let me encourage you to try the weightwatcher tool for yourself, and join our Slack channel to discuss this and other aspects of training large models to SOTA.</p>



<h3>Why does alpha &lt; 2 mean the layer may be over-trained ?</h3>



<p>The weightwatcher alpha $(latex \alpha)$ metric is the exponent found when fitting the empirical spectral density (ESD), or a histogram of the eigenvalues, to a Power-Law distribution.   Moreover, when alpha is between roughly 2 and higher (theoretically 4, practically, upto 6, <img src="https://s0.wp.com/latex.php?latex=%5Calpha%5Cin%5B2%2C6%5D&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha%5Cin%5B2%2C6%5D&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha%5Cin%5B2%2C6%5D&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha&#92;in[2,6]" class="latex" />), <a href="https://jmlr.org/papers/volume22/20-410/20-410.pdf" target="_blank" rel="noreferrer noopener">as shown in our JMLR paper,</a> we can use our HTSR theory to characterize the layer weight matrix as being Moderately Heavy-Tailed. See Table 1:</p>



<figure class="wp-block-image size-large"><a href="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-12.36.24-pm.png"><img data-attachment-id="14476" data-permalink="https://calculatedcontent.com/2022/06/14/is-your-layer-over-trained-part-2/screen-shot-2022-06-14-at-12-36-24-pm/" data-orig-file="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-12.36.24-pm.png" data-orig-size="1418,780" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2022-06-14-at-12.36.24-pm" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-12.36.24-pm.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-12.36.24-pm.png?w=1024" src="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-12.36.24-pm.png?w=1024" alt="" class="wp-image-14476" srcset="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-12.36.24-pm.png?w=1024 1024w, https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-12.36.24-pm.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-12.36.24-pm.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-12.36.24-pm.png?w=768 768w, https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-12.36.24-pm.png 1418w" sizes="(max-width: 1024px) 100vw, 1024px" /></a></figure>



<p>When a Power Law distribution is simply Moderately Heavy-Tailed,  this means that, in the limit, the variance may be unbounded, but the average (or mean) value is well defined.  So, for Deep Learning, this implies that the model has learned a wide variety of correlations, but, on average, the correlations are reasonably bounded, moreover, typical.  Being typical, the layer weight matrix model can be used to describe the information in the training and the test data, as long as they come from the same data distribution,</p>



<p>But when the alpha is very small (<img src="https://s0.wp.com/latex.php?latex=%5Calpha+%3C2&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha+%3C2&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha+%3C2&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha &lt;2" class="latex" />), this means the layer weight matrix is Very Heavy-Tailed, and the layer weight matrix is <strong>atypical.</strong>  That is, the distributions of the correlations do not have a well-defined average of mean value, and the individual elements of W may even themselves be unbounded (ie. when you have <a rel="noreferrer noopener" href="https://calculatedcontent.com/2021/04/04/are-your-models-overtrained/" target="_blank">a Correlation Trap</a>). Therefore, this layer weight matrix can not be used to describe any data except the training data.  </p>



<p class="has-text-align-center"><img data-attachment-id="14509" data-permalink="https://calculatedcontent.com/2022/06/14/is-your-layer-over-trained-part-2/screen-shot-2022-06-24-at-8-18-10-am/" data-orig-file="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-24-at-8.18.10-am.png" data-orig-size="798,576" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen Shot 2022-06-24 at 8.18.10 AM" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-24-at-8.18.10-am.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-24-at-8.18.10-am.png?w=798" class="wp-image-14509" style="width:400px;" src="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-24-at-8.18.10-am.png" alt=""></p>



<p class="has-text-align-center"><strong>A Correlation Trap appears when the batch size = 1</strong></p>



<p>Seeing this in practice is not necessarily easy, and interpreting it is harder.  As here, one may have to design a very careful experiment to flush this out.  Still, we encourage you to try the tool out, try to use it to identify and resolve such problems, and please give feedback.  </p>



<h2>Final Plug</h2>



<p>And if you need help with AI, ML, or just Data Science, please reach out. I provide strategy consulting, data science leadership, and hands-on, heads-down development. I will have availability in Q3 2022 for new projects. Reach out today.&nbsp;<a href="https://www.linkedin.com/feed/hashtag/?keywords=talktochuck&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A6941808930264150016">#talkToChuck</a>&nbsp;<a href="https://www.linkedin.com/feed/hashtag/?keywords=theaiguy&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A6941808930264150016">#theAIguy</a></p>
]]></content:encoded>
					
					<wfw:commentRss>https://calculatedcontent.com/2022/06/14/is-your-layer-over-trained-part-2/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		
		<media:thumbnail url="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-1.38.38-pm.png" />
		<media:content url="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-1.38.38-pm.png" medium="image">
			<media:title type="html">Screen Shot 2022-06-14 at 1.38.38 PM</media:title>
		</media:content>

		<media:content url="https://1.gravatar.com/avatar/1ae78e5099a40f308b172a5a65416cab?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">charlesmartin14</media:title>
		</media:content>

		<media:content url="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-10.38.14-am.png?w=1024" medium="image" />

		<media:content url="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-10.08.35-am.png?w=1024" medium="image" />

		<media:content url="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-1.40.41-pm.png" medium="image" />

		<media:content url="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-11.13.31-am.png?w=1024" medium="image" />

		<media:content url="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-11.19.39-am.png" medium="image" />

		<media:content url="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-14-at-12.36.24-pm.png?w=1024" medium="image" />

		<media:content url="https://charlesmartin14.files.wordpress.com/2022/06/screen-shot-2022-06-24-at-8.18.10-am.png" medium="image" />
	</item>
		<item>
		<title>Fantastic Measures of Generalization — That Actually Work</title>
		<link>https://calculatedcontent.com/2021/10/17/fantastic-measures-of-generalization-that-actually-work-part-1/</link>
					<comments>https://calculatedcontent.com/2021/10/17/fantastic-measures-of-generalization-that-actually-work-part-1/#respond</comments>
		
		<dc:creator><![CDATA[Charles H Martin, PhD]]></dc:creator>
		<pubDate>Sun, 17 Oct 2021 20:28:14 +0000</pubDate>
				<category><![CDATA[Uncategorized]]></category>
		<guid isPermaLink="false">http://calculatedcontent.com/?p=14250</guid>

					<description><![CDATA[In the next few posts, I am going to discuss how to use the generalization metrics included in the open-source &#8230; <a class="more-link" href="https://calculatedcontent.com/2021/10/17/fantastic-measures-of-generalization-that-actually-work-part-1/">More</a>]]></description>
										<content:encoded><![CDATA[
<p>In the next few posts, I am going to discuss how to use the generalization metrics included in the open-source weightwatcher tool.  The goal is to develop a general-purpose tool can that you can use, among other things, to predict (tends in) the test accuracy of a Deep Neural Network — without access to the test data &#8212; or even training data!  </p>



<p>WeightWatcher is a work in progress, based on research into Why Deep Learning Works, and has been featured in venures like ICML, <a rel="noreferrer noopener" href="https://dl.acm.org/doi/10.1145/3292500.3332294" target="_blank">KDD</a>, <a rel="noreferrer noopener" href="https://jmlr.org/papers/v22/20-410.html" target="_blank">JMLR</a> and <a rel="noreferrer noopener" href="https://www.nature.com/articles/s41467-021-24025-8" target="_blank">Nature Communications.</a> </p>



<p>Before we start, let me just say that it is very difficult to develop general-purpose metrics that can work for any arbitrary DNN (DNN), and, also, maintains a tool that is also back comparable with all of our work to be  100% reproducible. I hope the tool is useful to you, and we rely upon your feedback (positive and negative )  to improve the tool. so if it works for you, please let me.  If not, feel free to post an issue on <a rel="noreferrer noopener" href="https://github.com/CalculatedContent/WeightWatcher" target="_blank">the Github site</a>.  Thanks again for the interest!</p>



<p>Given this, the first metrics we will look at will be the</p>



<h3>Random Distance Metrics</h3>



<p>How is it even possible to predict the generalization accuracy of a DNN without even needing the test data ?  Or at least trends ?   The basic idea is simple; for each later weight matrix, measure how non-random it is.  After all, the more information the layer learns, the less random it should be.</p>



<p>What are some choices for such a layer capacity metric:  <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D%28%5Cmathbf%7BW%7D%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D%28%5Cmathbf%7BW%7D%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D%28%5Cmathbf%7BW%7D%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathcal{C}(&#92;mathbf{W})" class="latex" /></p>



<ul><li>Matrix Entropy: <img src="https://s0.wp.com/latex.php?latex=S%28%5Cmathbf%7BW%7D%29%3D-%5Csum_%7Bi%7D%5Clambda_%7Bi%7D%5Clog%5Clambda_%7Bi%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=S%28%5Cmathbf%7BW%7D%29%3D-%5Csum_%7Bi%7D%5Clambda_%7Bi%7D%5Clog%5Clambda_%7Bi%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S%28%5Cmathbf%7BW%7D%29%3D-%5Csum_%7Bi%7D%5Clambda_%7Bi%7D%5Clog%5Clambda_%7Bi%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="S(&#92;mathbf{W})=-&#92;sum_{i}&#92;lambda_{i}&#92;log&#92;lambda_{i} " class="latex" /></li><li>Distance from the initial weight matrix: <img src="https://s0.wp.com/latex.php?latex=%5CVert%5Cmathbf%7BW%7D-%5Cmathbf%7BW%7D_%7Binit%7D%5CVert_%7BF%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5CVert%5Cmathbf%7BW%7D-%5Cmathbf%7BW%7D_%7Binit%7D%5CVert_%7BF%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5CVert%5Cmathbf%7BW%7D-%5Cmathbf%7BW%7D_%7Binit%7D%5CVert_%7BF%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;Vert&#92;mathbf{W}-&#92;mathbf{W}_{init}&#92;Vert_{F} " class="latex" /> (and variants of this)</li><li>DIvergence from the ESD of the randomized weight matrix: <img src="https://s0.wp.com/latex.php?latex=div%5B%5Cmathbf%7BW%7D%2C+%5Cmathbf%7BW%7D_%7Brand%7D%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=div%5B%5Cmathbf%7BW%7D%2C+%5Cmathbf%7BW%7D_%7Brand%7D%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=div%5B%5Cmathbf%7BW%7D%2C+%5Cmathbf%7BW%7D_%7Brand%7D%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="div[&#92;mathbf{W}, &#92;mathbf{W}_{rand}]" class="latex" /></li></ul>



<h4>Matrix Entropy</h4>



<p>We define <img src="https://s0.wp.com/latex.php?latex=S%28%5Cmathbf%7BW%7D%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=S%28%5Cmathbf%7BW%7D%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S%28%5Cmathbf%7BW%7D%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="S(&#92;mathbf{W})" class="latex" /> in terms of the eigenvalues <img src="https://s0.wp.com/latex.php?latex=%5Clambda_%7Bi%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clambda_%7Bi%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda_%7Bi%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lambda_{i}" class="latex" /> of the layer correlation matrix </p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D%3D%5Cfrac%7B1%7D%7BN%7D%5Cmathbf%7BW%7D%5E%7BT%7D%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D%3D%5Cfrac%7B1%7D%7BN%7D%5Cmathbf%7BW%7D%5E%7BT%7D%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D%3D%5Cfrac%7B1%7D%7BN%7D%5Cmathbf%7BW%7D%5E%7BT%7D%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{X}=&#92;frac{1}{N}&#92;mathbf{W}^{T}&#92;mathbf{W}" class="latex" />.  </p>



<p>So the matrix entropy i is both a measure of layer randomness and a measure of correlation.</p>



<p>In <a rel="noreferrer noopener" href="https://jmlr.org/papers/volume22/20-410/20-410.pdf" target="_blank">our JMLR paper</a>, however, we show that while the Matrix Entropy does decrease during training, it is not particularly informative.  Still, I mention it here for completeness.   (And in the next post, I will discuss the Stable Rank; stay tuned)</p>



<figure class="wp-block-image size-large"><a href="https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-17-at-9.30.30-pm.png"><img data-attachment-id="14271" data-permalink="https://calculatedcontent.com/2021/10/17/fantastic-measures-of-generalization-that-actually-work-part-1/screen-shot-2021-10-17-at-9-30-30-pm/" data-orig-file="https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-17-at-9.30.30-pm.png" data-orig-size="2202,1086" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen Shot 2021-10-17 at 9.30.30 PM" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-17-at-9.30.30-pm.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-17-at-9.30.30-pm.png?w=1024" src="https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-17-at-9.30.30-pm.png?w=840" alt="" class="wp-image-14271" srcset="https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-17-at-9.30.30-pm.png?w=840 840w, https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-17-at-9.30.30-pm.png?w=1680 1680w, https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-17-at-9.30.30-pm.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-17-at-9.30.30-pm.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-17-at-9.30.30-pm.png?w=768 768w, https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-17-at-9.30.30-pm.png?w=1024 1024w" sizes="(max-width: 840px) 100vw, 840px" /></a></figure>



<h4>Distance from Init:</h4>



<p>The next metric to consider is the Frobenius norm of the difference between the layer weight matrix <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{W}" class="latex" /> and it&#8217;s specific, initialized, random value <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D_%7Binit%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D_%7Binit%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D_%7Binit%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{W}_{init}" class="latex" />.  Note, however, that this metric requires that you actually have the initial layer matrices (which we did not for our <a href="https://www.nature.com/articles/s41467-021-24025-8" target="_blank" rel="noreferrer noopener">Nature paper</a>)</p>



<p>The weightwatcher tool supports this metric with the distance method:</p>



<p> <pre class="brush: python; title: ; notranslate"> import weightwatcher as ww watcher = ww.watcher(model=your_model) &lt;strong&gt;distance_from_init&lt;/strong&gt; = watcher.distances(your_model, init_model) </pre></p>


<p>
where init_model is your model, with the original, actual, initial weight matrices.
</p>


<p>In <a rel="noreferrer noopener" href="https://arxiv.org/pdf/2106.00734.pdf" target="_blank">our most recent paper,</a> we evaluated the <strong>distance_from_init</strong> method as a generalization metric in great detal, however, in order to cut the paper down to submit (which I really hate doing), we had to remove most of this discussion, and only a table in the appendix remained.  I may redo this paper, and revert it to the long form, at some point.  For now, I will just present some results from that study here, that are unpublished. </p>



<p>These are the raw results for the task1 and task2 sets of models, described in the paper.  Breifly we were given about 100 pretrained models, group into 2 tasks (corresponding to 2 different architectures), and then subgrouped again (by the number of layers in each set).  Here, we see how the <strong>distance_from_init</strong> metric correlates against the given test accuracies&#8211;and it&#8217;s pretty good most of the time.  But&#8217;s not the best metric in general.</p>



<figure class="wp-block-image size-large"><a href="https://charlesmartin14.files.wordpress.com/2021/10/draft_distancemetric_10_0.png"><img data-attachment-id="14286" data-permalink="https://calculatedcontent.com/2021/10/17/fantastic-measures-of-generalization-that-actually-work-part-1/draft_distancemetric_10_0/" data-orig-file="https://charlesmartin14.files.wordpress.com/2021/10/draft_distancemetric_10_0.png" data-orig-size="1045,702" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="draft_DistanceMetric_10_0" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2021/10/draft_distancemetric_10_0.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2021/10/draft_distancemetric_10_0.png?w=1024" src="https://charlesmartin14.files.wordpress.com/2021/10/draft_distancemetric_10_0.png?w=1024" alt="" class="wp-image-14286" srcset="https://charlesmartin14.files.wordpress.com/2021/10/draft_distancemetric_10_0.png?w=1024 1024w, https://charlesmartin14.files.wordpress.com/2021/10/draft_distancemetric_10_0.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2021/10/draft_distancemetric_10_0.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2021/10/draft_distancemetric_10_0.png?w=768 768w, https://charlesmartin14.files.wordpress.com/2021/10/draft_distancemetric_10_0.png 1045w" sizes="(max-width: 1024px) 100vw, 1024px" /></a></figure>


<div class="wp-block-image">
<figure class="aligncenter size-large is-resized"><a href="https://charlesmartin14.files.wordpress.com/2021/10/draft_distancemetric_10_1.png"><img loading="lazy" data-attachment-id="14288" data-permalink="https://calculatedcontent.com/2021/10/17/fantastic-measures-of-generalization-that-actually-work-part-1/draft_distancemetric_10_1/" data-orig-file="https://charlesmartin14.files.wordpress.com/2021/10/draft_distancemetric_10_1.png" data-orig-size="703,702" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="draft_DistanceMetric_10_1" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2021/10/draft_distancemetric_10_1.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2021/10/draft_distancemetric_10_1.png?w=703" src="https://charlesmartin14.files.wordpress.com/2021/10/draft_distancemetric_10_1.png?w=703" alt="" class="wp-image-14288" width="586" height="585" srcset="https://charlesmartin14.files.wordpress.com/2021/10/draft_distancemetric_10_1.png?w=586 586w, https://charlesmartin14.files.wordpress.com/2021/10/draft_distancemetric_10_1.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2021/10/draft_distancemetric_10_1.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2021/10/draft_distancemetric_10_1.png 703w" sizes="(max-width: 586px) 100vw, 586px" /></a></figure></div>


<p>The are a few variants of this distance metric, depending on how one defines the distance.  These include:</p>



<ol><li>Frobenius norm distance.  </li><li>Cosine distance</li><li>CKA distance</li></ol>



<p>Currently, weightwatcher 0.5.5 only supports (1), but in the next minor release, we plan to include both (2) &amp; (3). </p>



<p>The problem with this simple approach is it is not going to be useful if your models are overfit because the distance from init increases over time anyway&#8211;and this is exactly what we think is happening in the <strong>task1</strong> models from this NeurIPS contest. But it is a good sanity check on your models during training, and can be used with other metrics as a diagnostic indicator.</p>



<p>So the question becomes, can we somehow create a distance-from-random metric that compensates for overfitting.  And that leads to&#8230;</p>



<h4>Distance from Random: (rand_distance)</h4>



<p>With the new <strong>rand_distance</strong> metric, we mean something very different from the <strong>distance_from_init. </strong> Above, we used the original instantiation of the <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D_%7Binit%7D%3B&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D_%7Binit%7D%3B&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D_%7Binit%7D%3B&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{W}_{init};" class="latex" />, and constructed an <em>element-wise distance</em> metric.    The <strong>rand_distance</strong> metric, in contrast:</p>



<ul><li>Does not require the original, initial weight matrics</li><li>Is not an element-wise metric, but, instead, is a <strong>distributional metric</strong></li></ul>



<p>So this metric is defined in terms of a distance between the distributions of the eigenvalues (i..e the ESDs) of the layer matrix <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{W}" class="latex" /> and its random counterpart <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D_%7Brand%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D_%7Brand%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D_%7Brand%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{W}_{rand}" class="latex" />. </p>



<p>For weightwatcher, we choose to use the <a rel="noreferrer noopener" href="https://medium.com/@sourcedexter/how-to-find-the-similarity-between-two-probability-distributions-using-python-a7546e90a08d" target="_blank">Jensen-Shannon divergence </a>for this:</p>


<p><!-- /wp:paragraph --></p>
<pre><pre class="brush: python; title: ; notranslate">rand_distance =  jensen_shannon_distance(esd, random_esd)</pre></pre>
<p>where</p>
<p><!-- /wp:paragraph --></p>
<pre><pre class="brush: python; title: ; notranslate">
def jensen_shannon_distance(p, q):
    m = (p + q) / 2
    divergence = (sp.stats.entropy(p, m) + sp.stats.entropy(q, m)) / 2
    distance = np.sqrt(divergence)
    return distance
</pre></pre>
<p><!-- wp:paragraph --></p>
<p>Moreover, there are 2 ways to construct the random layer matrix $\mathbf{W}_{rand}&amp;bg=ffffff$ metric:</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:list {"ordered":true} --></p>
<ol>
<li>Take any (Gaussian) Random Matrix, with the same aspect ratio <img src="https://s0.wp.com/latex.php?latex=Q%3D%5Cfrac%7BN%7D%7BM%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=Q%3D%5Cfrac%7BN%7D%7BM%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=Q%3D%5Cfrac%7BN%7D%7BM%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="Q=&#92;frac{N}{M}" class="latex" /> as the layer weight matrix <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{W}" class="latex" /></li>
<li>Permute (shuffle) the elements of <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{W}" class="latex" /></li>
</ol>
<p><!-- /wp:list --></p>
<p><!-- wp:paragraph --></p>
<p>While at first glance, these may seem the same, in fact, in practice, they can be quite different. This is because while every (Normal) Random Matrix has the same ESD (up to finite size effects), the Marchenko-Pastur (MP) distribution, if the actual <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{W}" class="latex" /> contains any usually large elements <img src="https://s0.wp.com/latex.php?latex=W_%7BIj%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=W_%7BIj%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=W_%7BIj%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="W_{Ij}" class="latex" /> , then it&#8217;s ESD will behave like a Heavy-Tailed Random Matrix, and look very different from it&#8217;s random MP counterpart. For more details, see <a href="https://www.jmlr.org/papers/volume22/20-410/20-410.pdf" target="_blank" rel="noreferrer noopener">our JMLR paper.</a></p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph --></p>
<p>Indeed, when <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{W}" class="latex" /> contains usually large elements, we call these <strong>Correlation Traps. </strong>Now, I have conjectured, in an earlier post, that such Correlation Traps may be a indication of a layer being overtrained. However, some research suggests the opposite, and, that, in-fact, such large elements are needed for large, modern NLP models. The jury is still out on this, however, the weightwatcher tool can be used to resolve this question since it can easily identify such Correlation Traps in every layer. I look forward to seeing the final conclusion.</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph --></p>
<p>The take-a-way here is that, when a layer is well trained, we expect the ESD of the layer to be significantly different from the ESD its randomized, shuffled form. Let&#8217;s compare 2 cases:</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:image {"id":14298,"sizeSlug":"large","linkDestination":"media"} --></p>
<figure class="wp-block-image size-large"><a href="https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-17-at-11.47.59-pm.png"><img data-attachment-id="14298" data-permalink="https://calculatedcontent.com/2021/10/17/fantastic-measures-of-generalization-that-actually-work-part-1/screen-shot-2021-10-17-at-11-47-59-pm/" data-orig-file="https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-17-at-11.47.59-pm.png" data-orig-size="2002,960" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen Shot 2021-10-17 at 11.47.59 PM" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-17-at-11.47.59-pm.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-17-at-11.47.59-pm.png?w=1024" class="wp-image-14298" src="https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-17-at-11.47.59-pm.png?w=1024" alt="" srcset="https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-17-at-11.47.59-pm.png?w=1024 1024w, https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-17-at-11.47.59-pm.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-17-at-11.47.59-pm.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-17-at-11.47.59-pm.png?w=768 768w, https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-17-at-11.47.59-pm.png 2002w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>
<p><!-- /wp:image --></p>
<p><!-- wp:paragraph --></p>
<p style="text-align:center;"><em>The <strong>rand_distance</strong> metric measure the divergence between the <strong><span style="color:#008000;">original</span></strong> and <span style="color:#ff0000;"><strong>random</strong></span> ESDs</em></p>
<p>In case (a), the <span style="color:#008000;"><strong>original ESD</strong> (green)</span> looks significantly different from its <span style="color:#ff0000;"><strong>randomized ESD</strong> (red).</span>&nbsp; In case (b), however, the <span style="color:#008000;"><strong>original</strong></span> the <span style="color:#ff0000;"><strong>randomized</strong></span> ESDs are much more similar.&nbsp;So we expect case (a) to be more well trained than case (b).&nbsp; &nbsp;</p>
<p style="text-align:left;"><em>And <strong>rand_distance</strong> works, presumably, at least in some cases, when the layer is overtrained, as in (b)</em>.</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph --></p>
<p>To compute the <strong>rand_distance</strong> metric, simply specify the randomize=True option, and it will be available as a layer metric in the details dataframe</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph --></p>
<pre><pre class="brush: python; title: ; notranslate">
import weightwatcher as ww
watcher = ww.watcher(model=your_model)
details = watcher.analyze(randomize=True)
avg_rand_distance = details.rand_distance.mean()
</pre></pre>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph --></p>
<p>Finally, let&#8217;s see how well the <strong>rand_distance</strong> metric actually works to predict trends in the test accuracy for a well known set of pretrained models, the VGG series. Similar to the analysis in our Nature paper, we consider how well the <strong>average rand_distance</strong> metric is correlated with the reported top1 errors of the series of VGG models: VGG11, VGG13, VGG16, and VGG19</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:image {"align":"center","id":14301,"width":411,"height":387,"sizeSlug":"large","linkDestination":"media"} --></p>
<div class="wp-block-image">
<figure class="aligncenter size-large is-resized"><a href="https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-13-at-9.06.01-pm.png"><img loading="lazy" data-attachment-id="14301" data-permalink="https://calculatedcontent.com/2021/10/17/fantastic-measures-of-generalization-that-actually-work-part-1/screen-shot-2021-10-13-at-9-06-01-pm/" data-orig-file="https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-13-at-9.06.01-pm.png" data-orig-size="1374,1292" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen Shot 2021-10-13 at 9.06.01 PM" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-13-at-9.06.01-pm.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-13-at-9.06.01-pm.png?w=1024" class="wp-image-14301 aligncenter" src="https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-13-at-9.06.01-pm.png?w=1024" alt="" width="411" height="387" srcset="https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-13-at-9.06.01-pm.png?w=411 411w, https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-13-at-9.06.01-pm.png?w=822 822w, https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-13-at-9.06.01-pm.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-13-at-9.06.01-pm.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-13-at-9.06.01-pm.png?w=768 768w" sizes="(max-width: 411px) 100vw, 411px"></a></figure>
</div>
<p><!-- /wp:image --></p>
<p>Actually this is pretty good, and comparable to the results for the weightwatcher powerlaw metric weighted-alpha (<img src="https://s0.wp.com/latex.php?latex=%5Chat%7B%5Calpha%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Chat%7B%5Calpha%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Chat%7B%5Calpha%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;hat{&#92;alpha}" class="latex" />).&nbsp; But for reasons I don&#8217;t yet understand, however, it does not work so well for the VGG_BN models (VGG with BatchNormalization).&nbsp; Never-the-less, I am hoping it may be useful to you, and I would love to hear if it is working for you or not.&nbsp; To help get started, the above results can be reproduced using weightwatcher 0.5.5 using the <a href="https://github.com/CalculatedContent/WeightWatcher/blob/master/WWVGG-TestRandDistance.ipynb">WWVGG-TestRandDistance.ipynb</a> Jupyter Notebook in the WeightWatcher GitHub repo.</p>
<p><!-- wp:paragraph --></p>
<p>I&#8217;ll end part 1 of this series of blog posts with a comparison between the new <strong>rand_distance</strong> metric and the weighwatcher <strong>alpha</strong> metric, for all the layers VGG19.</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph --></p>
<p>(Note, I am not using the ww2x option for this analysis, but if you want to reproduce the Nature results, use ww2x=True. If you don&#8217;t , you may get crazy-large alphas that are incorrect&#8211;I will show in the next post I will discuss the alpha powerlaw (PL) estimates in more detail.)</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:image {"align":"center","id":14307,"width":485,"height":327,"sizeSlug":"large","linkDestination":"media"} --></p>
<div class="wp-block-image">
<figure class="aligncenter size-large is-resized"><a href="https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-12-at-12.59.20-am.png"><img loading="lazy" data-attachment-id="14307" data-permalink="https://calculatedcontent.com/2021/10/17/fantastic-measures-of-generalization-that-actually-work-part-1/screen-shot-2021-10-12-at-12-59-20-am/" data-orig-file="https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-12-at-12.59.20-am.png" data-orig-size="1316,888" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen Shot 2021-10-12 at 12.59.20 AM" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-12-at-12.59.20-am.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-12-at-12.59.20-am.png?w=1024" class="wp-image-14307" src="https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-12-at-12.59.20-am.png?w=1024" alt="" width="485" height="327" srcset="https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-12-at-12.59.20-am.png?w=485 485w, https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-12-at-12.59.20-am.png?w=970 970w, https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-12-at-12.59.20-am.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-12-at-12.59.20-am.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-12-at-12.59.20-am.png?w=768 768w" sizes="(max-width: 485px) 100vw, 485px"></a></figure>
</div>
<p><!-- /wp:image --></p>
<p><!-- wp:paragraph --></p>
<p>When the weightwatcher <strong>alpha</strong> &lt; 5, this means that the layers are Heavy Tailed and therefore well trained, and, as expected, alpha is correlated with the <strong>rand_distance</strong> metric. As expected!</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph --></p>
<p>I hope this has been useful to you and that you will try out the weightwather tool</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph --></p>
<pre><pre class="brush: bash; title: ; notranslate">
pip install weightwatcher
</pre></pre>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph --></p>
<p>Give it a try. And please give me feedback if it is useful. And, if interested in getting involved or just learning more, ping me to join our Slack channel. And if you need help with AI, reach out. #t<strong>alkToChuck #theAIguy </strong></p>
<p><!-- /wp:paragraph --></p>]]></content:encoded>
					
					<wfw:commentRss>https://calculatedcontent.com/2021/10/17/fantastic-measures-of-generalization-that-actually-work-part-1/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		
		<media:thumbnail url="https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-13-at-9.06.01-pm.png" />
		<media:content url="https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-13-at-9.06.01-pm.png" medium="image">
			<media:title type="html">Screen Shot 2021-10-13 at 9.06.01 PM</media:title>
		</media:content>

		<media:content url="https://1.gravatar.com/avatar/1ae78e5099a40f308b172a5a65416cab?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">charlesmartin14</media:title>
		</media:content>

		<media:content url="https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-17-at-9.30.30-pm.png?w=840" medium="image" />

		<media:content url="https://charlesmartin14.files.wordpress.com/2021/10/draft_distancemetric_10_0.png?w=1024" medium="image" />

		<media:content url="https://charlesmartin14.files.wordpress.com/2021/10/draft_distancemetric_10_1.png?w=703" medium="image" />

		<media:content url="https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-17-at-11.47.59-pm.png?w=1024" medium="image" />

		<media:content url="https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-13-at-9.06.01-pm.png?w=1024" medium="image" />

		<media:content url="https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-12-at-12.59.20-am.png?w=1024" medium="image" />
	</item>
		<item>
		<title>Model Monitoring with WeightWatcher: Data-Free DEEP LEARNING Diagnostics</title>
		<link>https://calculatedcontent.com/2021/08/18/model-monitoring-with-weightwatcher-data-free-deep-learning-diagnostics/</link>
					<comments>https://calculatedcontent.com/2021/08/18/model-monitoring-with-weightwatcher-data-free-deep-learning-diagnostics/#comments</comments>
		
		<dc:creator><![CDATA[Charles H Martin, PhD]]></dc:creator>
		<pubDate>Wed, 18 Aug 2021 15:47:28 +0000</pubDate>
				<category><![CDATA[Uncategorized]]></category>
		<guid isPermaLink="false">http://calculatedcontent.com/?p=14219</guid>

					<description><![CDATA[Weighwatcher is an open-source Model Monitoring tool that provides Data-Free Diagnostics for production-quality Deep Neural Networks (DNNs). It. can tell &#8230; <a class="more-link" href="https://calculatedcontent.com/2021/08/18/model-monitoring-with-weightwatcher-data-free-deep-learning-diagnostics/">More</a>]]></description>
										<content:encoded><![CDATA[
<p>Weighwatcher is an open-source Model Monitoring tool that provides Data-Free Diagnostics for production-quality Deep Neural Networks (DNNs). It. can tell you if your model is over-trained or over-parameterized. And it can it tell you which layers are over-trained or under-trained (over-parameterized). And all without needing training or test data.</p>



<p>Let&#8217;s see how to do this.  First, install the tool.</p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: python; title: ; notranslate">
pip install weightwatcher
</pre></div>


<p>Second, pick a model and get a basic description of it</p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: python; title: ; notranslate">
import weightwatcher as ww
watcher = ww.WeightWatcher(model=my_model)
details = watcher.analyze()
</pre></div>


<p>WeightWatcher produces a pandas dataframe, details, with layer metrics describing your model. In particular, the details dataframe contains layer names, ids, types, and warnings.</p>



<p>Here is an example, an analysis of the OpenAI GPT model (discussed in our recent <a href="https://www.nature.com/articles/s41467-021-24025-8">Nature paper)</a></p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: python; title: ; notranslate">
import transformers
from transformers import OpenAIGPTModel,GPT2Model

gpt_model = OpenAIGPTModel.from_pretrained('openai-gpt')
gpt_model.eval();

watcher = ww.WeightWatcher(model=gpt_model)
details = watcher.analyze()
</pre></div>


<p>The details dataframe now includes a wide range of information, for each layer, including a specific warnings columns</p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: python; title: ; notranslate">
details&#91;details.warning!=""]&#91;&#91;'layer_id','name','warning']]
</pre></div>


<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><a href="https://charlesmartin14.files.wordpress.com/2021/08/screen-shot-2021-08-17-at-11.41.57-pm.png"><img loading="lazy" data-attachment-id="14234" data-permalink="https://calculatedcontent.com/screen-shot-2021-08-17-at-11-41-57-pm/" data-orig-file="https://charlesmartin14.files.wordpress.com/2021/08/screen-shot-2021-08-17-at-11.41.57-pm.png" data-orig-size="516,538" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2021-08-17-at-11.41.57-pm" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2021/08/screen-shot-2021-08-17-at-11.41.57-pm.png?w=288" data-large-file="https://charlesmartin14.files.wordpress.com/2021/08/screen-shot-2021-08-17-at-11.41.57-pm.png?w=516" src="https://charlesmartin14.files.wordpress.com/2021/08/screen-shot-2021-08-17-at-11.41.57-pm.png?w=516" alt="" class="wp-image-14234" width="418" height="437" srcset="https://charlesmartin14.files.wordpress.com/2021/08/screen-shot-2021-08-17-at-11.41.57-pm.png?w=418 418w, https://charlesmartin14.files.wordpress.com/2021/08/screen-shot-2021-08-17-at-11.41.57-pm.png?w=144 144w, https://charlesmartin14.files.wordpress.com/2021/08/screen-shot-2021-08-17-at-11.41.57-pm.png?w=288 288w, https://charlesmartin14.files.wordpress.com/2021/08/screen-shot-2021-08-17-at-11.41.57-pm.png 516w" sizes="(max-width: 418px) 100vw, 418px" /></a><figcaption>weightwatcher layer warnings for GPT</figcaption></figure></div>



<p>For comparison, below we show the same details deatframe, but for GPT2.  GPT2 is the same model as GPT, but trained with more and better data,  Being a much better model, GPT2 has far fewer warnings than GPT.</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><a href="https://charlesmartin14.files.wordpress.com/2021/08/screen-shot-2021-08-18-at-8.24.03-am-1.png"><img loading="lazy" data-attachment-id="14239" data-permalink="https://calculatedcontent.com/screen-shot-2021-08-18-at-8-24-03-am-1/" data-orig-file="https://charlesmartin14.files.wordpress.com/2021/08/screen-shot-2021-08-18-at-8.24.03-am-1.png" data-orig-size="506,190" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2021-08-18-at-8.24.03-am-1" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2021/08/screen-shot-2021-08-18-at-8.24.03-am-1.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2021/08/screen-shot-2021-08-18-at-8.24.03-am-1.png?w=506" src="https://charlesmartin14.files.wordpress.com/2021/08/screen-shot-2021-08-18-at-8.24.03-am-1.png?w=506" alt="" class="wp-image-14239" width="413" height="156" srcset="https://charlesmartin14.files.wordpress.com/2021/08/screen-shot-2021-08-18-at-8.24.03-am-1.png?w=413 413w, https://charlesmartin14.files.wordpress.com/2021/08/screen-shot-2021-08-18-at-8.24.03-am-1.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2021/08/screen-shot-2021-08-18-at-8.24.03-am-1.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2021/08/screen-shot-2021-08-18-at-8.24.03-am-1.png 506w" sizes="(max-width: 413px) 100vw, 413px" /></a><figcaption>weightwatcher layer warnings for GPT2</figcaption></figure></div>



<p>That&#8217;s all there is to it.   WeightWatcher provides simple layer metrics for pre-trained Deep Neural Networks, indicating simple warnings for which layers are over-trained and which layers are under-trained.</p>



<p>Give it a try. We are looking for early adopters needing better, faster, and cheaper AI monitoring. if it is useful to you , please let me know.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://calculatedcontent.com/2021/08/18/model-monitoring-with-weightwatcher-data-free-deep-learning-diagnostics/feed/</wfw:commentRss>
			<slash:comments>6</slash:comments>
		
		
		
		<media:thumbnail url="https://charlesmartin14.files.wordpress.com/2021/08/screen-shot-2021-08-18-at-8.24.03-am-1.png" />
		<media:content url="https://charlesmartin14.files.wordpress.com/2021/08/screen-shot-2021-08-18-at-8.24.03-am-1.png" medium="image">
			<media:title type="html">screen-shot-2021-08-18-at-8.24.03-am-1</media:title>
		</media:content>

		<media:content url="https://1.gravatar.com/avatar/1ae78e5099a40f308b172a5a65416cab?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">charlesmartin14</media:title>
		</media:content>

		<media:content url="https://charlesmartin14.files.wordpress.com/2021/08/screen-shot-2021-08-17-at-11.41.57-pm.png?w=516" medium="image" />

		<media:content url="https://charlesmartin14.files.wordpress.com/2021/08/screen-shot-2021-08-18-at-8.24.03-am-1.png?w=506" medium="image" />
	</item>
		<item>
		<title>How to tell if you have trained your Model with enough data ?</title>
		<link>https://calculatedcontent.com/2021/07/09/how-to-tell-if-you-have-trained-your-model-with-enough-data/</link>
					<comments>https://calculatedcontent.com/2021/07/09/how-to-tell-if-you-have-trained-your-model-with-enough-data/#respond</comments>
		
		<dc:creator><![CDATA[Charles H Martin, PhD]]></dc:creator>
		<pubDate>Sat, 10 Jul 2021 02:12:21 +0000</pubDate>
				<category><![CDATA[Uncategorized]]></category>
		<guid isPermaLink="false">http://calculatedcontent.com/?p=14103</guid>

					<description><![CDATA[Deep Neural Networks (DNN) require a lot of training data. Even fine-tuning a model can require a lot. A LOT. &#8230; <a class="more-link" href="https://calculatedcontent.com/2021/07/09/how-to-tell-if-you-have-trained-your-model-with-enough-data/">More</a>]]></description>
										<content:encoded><![CDATA[
<p>Deep Neural Networks (DNN) require a lot of training data.  Even fine-tuning a model can require a lot.  A LOT.  So how can you know if you have used enough?  For Computer Vision (CV) models, you can always look at the test error.  But what about fine-tuning large, transformer models like BERT or GPT ?</p>



<ul>
<li>What is the best metric to evaluate your model ? </li>



<li>How can you be sure you trained it with enough data ?  </li>



<li>And how can your customers be sure ?</li>
</ul>



<p class="has-text-align-left"><a href="https://github.com/CalculatedContent/WeightWatcher" target="_blank" rel="noreferrer noopener">WeightWatcher</a> can help.</p>



<p class="has-text-align-center"><code>pip install weightwatcher  </code></p>



<p>WeightWatcher is an open-source, diagnostic tool for evaluating the performance of (pre)-trained and fine-tuned Deep Neural Networks.  It is based on state-of-the-art research into <em>Why Deep Learning Works</em>.  Recently,<a href="https://www.nature.com/articles/s41467-021-24025-8"> </a><a rel="noreferrer noopener" href="https://www.nature.com/articles/s41467-021-24025-8" target="_blank">it has been featured in Nature:</a></p>



<figure class="wp-block-image size-large"><a href="https://charlesmartin14.files.wordpress.com/2021/07/screen-shot-2021-07-08-at-10.53.10-pm.png"><img data-attachment-id="14145" data-permalink="https://calculatedcontent.com/screen-shot-2021-07-08-at-10-53-10-pm/" data-orig-file="https://charlesmartin14.files.wordpress.com/2021/07/screen-shot-2021-07-08-at-10.53.10-pm.png" data-orig-size="2914,316" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2021-07-08-at-10.53.10-pm" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2021/07/screen-shot-2021-07-08-at-10.53.10-pm.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2021/07/screen-shot-2021-07-08-at-10.53.10-pm.png?w=1024" src="https://charlesmartin14.files.wordpress.com/2021/07/screen-shot-2021-07-08-at-10.53.10-pm.png?w=1024" alt="" class="wp-image-14145" srcset="https://charlesmartin14.files.wordpress.com/2021/07/screen-shot-2021-07-08-at-10.53.10-pm.png?w=1024 1024w, https://charlesmartin14.files.wordpress.com/2021/07/screen-shot-2021-07-08-at-10.53.10-pm.png?w=2048 2048w, https://charlesmartin14.files.wordpress.com/2021/07/screen-shot-2021-07-08-at-10.53.10-pm.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2021/07/screen-shot-2021-07-08-at-10.53.10-pm.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2021/07/screen-shot-2021-07-08-at-10.53.10-pm.png?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px" /></a></figure>



<p>Here, we show you how to use WeightWatcher to determine if your DNN model has been trained with enough data.  </p>



<p>In the paper, we consider the example of GPT vs GPT2.  GPT is a NLP Transformer model, developed by <a href="https://openai.com/blog/better-language-models/">OpenAI,</a> to generate fake text.   When it was first developed, OpenAI released the GPT model, which had specifically been trained with a small data set, making it unusable to generate fake text. Later, they realized fake text is good business, and they released GPT2, which is just like GPT. but trained with enough data to make it useful.  </p>


<div class="wp-block-image">
<figure class="aligncenter is-resized"><img src="https://charlesmartin14.files.wordpress.com/2021/07/e06a6-gpt2.png" alt="TechViz - The Data Science Guy: Data Augmentation in NLP using GPT2" width="529" height="175" /></figure></div>


<p>We can apply WeightWatcher to GPT and GPT2 and compare the results; we will see that the WeightWatcher <em>log</em> <em>spectral norm </em>and <em>alpha (power law)</em> metrics can immediately tell us that something is wrong with the GPT model.  <a rel="noreferrer noopener" href="https://www.nature.com/articles/s41467-021-24025-8/figures/6" target="_blank">This is shown in Figure 6 of the paper;</a> </p>



<figure class="wp-block-image"><img src="https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41467-021-24025-8/MediaObjects/41467_2021_24025_Fig6_HTML.png" alt="Fig. 6" /></figure>



<p>Here we will walk through exactly how to do this yourself for the WeightWatcher Power Law (PL) alpha metric <img src="https://s0.wp.com/latex.php?latex=%28%5Calpha%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28%5Calpha%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28%5Calpha%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(&#92;alpha)" class="latex" />, and explain how to interpret these plots.</p>



<p>It is recommended to run these calculations in a Jupiter notebook, or Google Colab. (For reference, <a rel="noreferrer noopener" href="https://github.com/CalculatedContent/ww-trends-2020/blob/master/WeightWatcher-OpenAI-GPT.ipynb" target="_blank">you can also view the actual notebook</a> used to create the plots in the paper, however, this uses an older version of weightwatcher)</p>



<p>For this post, <a href="https://github.com/CalculatedContent/WeightWatcher/blob/master/WeightWatcher-GPT.ipynb" target="_blank" rel="noreferrer noopener">we provide a working notebook</a> in the<a href="https://github.com/CalculatedContent/WeightWatcher" target="_blank" rel="noreferrer noopener"> WeightWatcher github repo.</a></p>



<p> WeightWatcher understands the basic Huggingface models. Indeed, WeightWatcher supports:</p>



<ul>
<li>TF2.0 / Keras</li>



<li>pyTorch 1.x</li>



<li>HuggingFace</li>
</ul>



<p>and (soon)</p>



<p>ONNX (in the current trunk)</p>



<p>Currently, we support Dense and Conv2D layers.  Support for more layers is coming.  For our NLP Transformer models, we only need support for the Dense layers.</p>



<p>First, we need the GPT and GPT2 pyTorch models. We will use the popular HuggingFace  transformers package.</p>



<div class="is-layout-constrained wp-block-group"><div class="wp-block-group__inner-container"><div class="wp-block-syntaxhighlighter-code "><pre class="brush: python; title: ; notranslate">
!pip install transformers&lt;
</pre></div></div></div>



<p>Second, we need to import pyTorch and weightwatcher</p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: python; first-line: 2; title: ; notranslate">
import torch
import weightwatcher as ww&lt;
</pre></div>


<p>We will also want the pandas and matplotlib libraries to help us interpret the weightwatcher metrics.  In Jupyter notebooks, this looks like</p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: python; first-line: 4; title: ; notranslate">
import pandas as pd

import matplotlib
import matplotlib.pyplot as plt
%matplotlib inline
</pre></div>


<p>We now import the transformers package and the 2 model classes</p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: python; first-line: 9; title: ; notranslate">
import transformers
from transformers import OpenAIGPTModel,GPT2Model
</pre></div>


<p>We have to get the 2 pretrained models, and run <em>model.eval() </em></p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: plain; first-line: 11; title: ; notranslate">
gpt_model = OpenAIGPTModel.from_pretrained('openai-gpt')
gpt_model.eval();

gpt2_model = GPT2Model.from_pretrained('gpt2')
gpt2_model.eval();
</pre></div>


<p>To analyze our GPT models with WeightWatcher , simply create a watcher instance, and run <em>watcher.analyze(</em>).  This will return a pandas dataframe with the metrics for each layer</p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: python; first-line: 16; title: ; notranslate">
watcher = ww.WeightWatcher(model=gpt_model)
gpt_details = watcher.analyze()
</pre></div>


<p>The details dataframes reports quality metrics that can be used to analyze the model performance&#8211;without needing access to test or training data. The most important metric is our Power Law metric <img src="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha" class="latex" />.  WeightWatcher reports <img src="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha" class="latex" /> for every layer.  The GPT model has nearly 50 layers, so it is convenient to examine all the layer alphas at once as a histogram (using the pandas API).</p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: python; first-line: 18; title: ; notranslate">
gpt_details.alpha.plot.hist(bins=100, color='red', alpha=0.5, density=True, label='gpt')
plt.xlabel(r"alpha $(\alpha)$ PL exponent")
plt.legend()
</pre></div>


<p>This plots the density of the <img src="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha" class="latex" /> values for all layers in the GPT model.</p>



<figure class="wp-block-image size-large"><a href="https://charlesmartin14.files.wordpress.com/2021/07/image-1.png"><img data-attachment-id="14171" data-permalink="https://calculatedcontent.com/image-1/" data-orig-file="https://charlesmartin14.files.wordpress.com/2021/07/image-1.png" data-orig-size="457,333" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-1" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2021/07/image-1.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2021/07/image-1.png?w=457" src="https://charlesmartin14.files.wordpress.com/2021/07/image-1.png?w=457" alt="" class="wp-image-14171" srcset="https://charlesmartin14.files.wordpress.com/2021/07/image-1.png 457w, https://charlesmartin14.files.wordpress.com/2021/07/image-1.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2021/07/image-1.png?w=300 300w" sizes="(max-width: 457px) 100vw, 457px" /></a></figure>



<p>From this histogram, we can immediately see 2 problems with the model</p>



<ul>
<li>The peak <img src="https://s0.wp.com/latex.php?latex=%5Calpha%5Csim+4&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha%5Csim+4&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha%5Csim+4&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha&#92;sim 4" class="latex" />. which is higher than optimal for a well trained model.</li>



<li>There are several outliers with <img src="https://s0.wp.com/latex.php?latex=%5Calpha%3E6&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha%3E6&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha%3E6&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha&gt;6" class="latex" />, indicating several poorly trained layers.</li>



<li>There are no <img src="https://s0.wp.com/latex.php?latex=%5Calpha+%3C+2+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha+%3C+2+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha+%3C+2+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha &lt; 2 " class="latex" />; when alpha is too small, the layer may be overtrained.</li>
</ul>



<p>So knowing nothing about GPT, and having never seen the test or training data, WeightWatcher tells us that this model should never go into production.</p>



<p>Now let&#8217;s look GPT2, which has the same architecture, but trained with more and better data. Again, we make a <em>watche</em>r instance with the model specified, and just run <em>watcher.analyze()</em></p>



<pre class="wp-block-preformatted">watcher = ww.WeightWatcher(model=gpt2_model)
gpt2_details = watcher.analyze()</pre>



<p>Now let&#8217;s compare the Power Law alpha metrics for GPT and GPT2.  We just create 2 histograms, 1 for each model, and overlay them.</p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: python; first-line: 21; title: ; notranslate">
gpt_details.alpha.plot.hist(bins=100, color='red', alpha=0.5, density=True, label='gpt')
gpt2_details.alpha.plot.hist(bins=100, color='green', density=True, label='gpt2')
plt.xlabel(r"alpha $(\alpha)$ PL exponent")
plt.legend()
</pre></div>


<p>The layer alphas for GPT are shown in <font color="red"><strong>red</strong></font>, and for GPT2 in <font color="green"><strong>green</strong></font>, and the histograms differ significantly.  For the GPT2, the peak <span style="font-size:revert;"><img src="https://s0.wp.com/latex.php?latex=%5Calpha+%5Csim+3.5+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha+%5Csim+3.5+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha+%5Csim+3.5+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha &#92;sim 3.5 " class="latex" /></span>, and, more importantly, there are no outlier <span style="font-size:revert;"><span style="font-size:revert;"><img src="https://s0.wp.com/latex.php?latex=%5Calpha+%3E+6++&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha+%3E+6++&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha+%3E+6++&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha &gt; 6  " class="latex" /></span></span>. Smaller alphas are better, and the GPT2 model is much better than GPT because it is trained with significantly more and better data.<br><br>The only caveat here is if <span style="font-size:revert;"><img src="https://s0.wp.com/latex.php?latex=%5Calpha+%3C+2+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha+%3C+2+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha+%3C+2+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha &lt; 2 " class="latex" />;</span> in these cases, the layer is overtrained or overfit in some way.  In GPT and GPT2, we have no alphas that are too small.</p>



<figure class="wp-block-image size-large"><a href="https://charlesmartin14.files.wordpress.com/2021/07/image-2.png"><img data-attachment-id="14174" data-permalink="https://calculatedcontent.com/image-2/" data-orig-file="https://charlesmartin14.files.wordpress.com/2021/07/image-2.png" data-orig-size="457,333" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-2" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2021/07/image-2.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2021/07/image-2.png?w=457" src="https://charlesmartin14.files.wordpress.com/2021/07/image-2.png?w=457" alt="" class="wp-image-14174" srcset="https://charlesmartin14.files.wordpress.com/2021/07/image-2.png 457w, https://charlesmartin14.files.wordpress.com/2021/07/image-2.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2021/07/image-2.png?w=300 300w" sizes="(max-width: 457px) 100vw, 457px" /></a></figure>



<p>WeightWatcher has many features to help you evaluate your models.  It can do things like</p>



<ul>
<li>Help you decide if you have trained it with enough data (as shown here)</li>



<li>Detect potential layers that are overtrained (as shown<a rel="noreferrer noopener" href="https://calculatedcontent.com/2021/04/04/are-your-models-overtrained/" target="_blank"> in a previous blog</a>)</li>



<li>Be used to get early stopping criteria (when you can&#8217;t peek at the test data)</li>



<li>Predict trends in the test accuracies across models and hyperparameters (see <a rel="noreferrer noopener" href="https://www.nature.com/articles/s41467-021-24025-8" target="_blank">our Nature paper</a>, and <a href="https://arxiv.org/abs/2106.00734" target="_blank" rel="noreferrer noopener">our most recent submission</a>).</li>
</ul>



<p>and many other things.</p>



<p>Please give it a try. And if it is useful to you, let me know.</p>



<p><strong>And if your company needs help with AI, reach out. I provide strategy consulting, mentorship, and hands-on development.&nbsp;#talkToChuck,&nbsp;#theAIguy</strong>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://calculatedcontent.com/2021/07/09/how-to-tell-if-you-have-trained-your-model-with-enough-data/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		
		<media:thumbnail url="https://charlesmartin14.files.wordpress.com/2021/07/41467_2021_24025_fig6_html.png" />
		<media:content url="https://charlesmartin14.files.wordpress.com/2021/07/41467_2021_24025_fig6_html.png" medium="image">
			<media:title type="html">41467_2021_24025_fig6_html</media:title>
		</media:content>

		<media:content url="https://1.gravatar.com/avatar/1ae78e5099a40f308b172a5a65416cab?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">charlesmartin14</media:title>
		</media:content>

		<media:content url="https://charlesmartin14.files.wordpress.com/2021/07/screen-shot-2021-07-08-at-10.53.10-pm.png?w=1024" medium="image" />

		<media:content url="https://charlesmartin14.files.wordpress.com/2021/07/e06a6-gpt2.png" medium="image">
			<media:title type="html">TechViz - The Data Science Guy: Data Augmentation in NLP using GPT2</media:title>
		</media:content>

		<media:content url="https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41467-021-24025-8/MediaObjects/41467_2021_24025_Fig6_HTML.png" medium="image">
			<media:title type="html">Fig. 6</media:title>
		</media:content>

		<media:content url="https://charlesmartin14.files.wordpress.com/2021/07/image-1.png?w=457" medium="image" />

		<media:content url="https://charlesmartin14.files.wordpress.com/2021/07/image-2.png?w=457" medium="image" />
	</item>
		<item>
		<title>is your model overtrained ?</title>
		<link>https://calculatedcontent.com/2021/04/04/are-your-models-overtrained/</link>
					<comments>https://calculatedcontent.com/2021/04/04/are-your-models-overtrained/#comments</comments>
		
		<dc:creator><![CDATA[Charles H Martin, PhD]]></dc:creator>
		<pubDate>Sun, 04 Apr 2021 08:51:42 +0000</pubDate>
				<category><![CDATA[Uncategorized]]></category>
		<guid isPermaLink="false">http://calculatedcontent.com/?p=14101</guid>

					<description><![CDATA[Are your models over-trained ? The weightwatcher tool can detect the signatures of overtraining in specific layers of a pre/trained &#8230; <a class="more-link" href="https://calculatedcontent.com/2021/04/04/are-your-models-overtrained/">More</a>]]></description>
										<content:encoded><![CDATA[
<p>Are your models over-trained ? The weightwatcher tool can detect the signatures of overtraining in specific layers of a pre/trained Deep Neural Networks.</p>



<p>In the Figure above, fig (a) is well trained, whereas fig (b) may be over-trained. That orange spike on the far right is the tell-tale clue; it&#8217;s what we call a<em> Correlation Trap.  </em></p>



<p>Weightwatcher can detect the signatures of overtraining in specific layers of a pre/trained Deep Neural Networks.   In this post, we show how to use the weightwatcher tool to do this.</p>



<h3>WeightWatcher</h3>



<p><strong>WeightWatcher</strong>&nbsp;(WW): is an open-source, diagnostic tool for analyzing Deep Neural Networks (DNN), without needing access to training or even test data. It analyzes the weight matrices of a pre/trained DNN, layer-by-layer, to help you detect potential problems.  Problems that can not be seen by just looking at the test accuracy or the training loss.</p>



<p><strong>Installation</strong>:</p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: bash; title: ; notranslate">
pip install weightwatcher
</pre></div>


<p><strong>Usage:</strong></p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: python; title: ; notranslate">
import weightwatcher as ww
import torchvision.models as models

model = models.vgg19_bn(pretrained=True)
watcher = ww.WeightWatcher(model=model)
details = watcher.analyze(plot=True, randomize=True)
</pre></div>


<p>For each layer, Weightwatcher plots the Empirical Spectral Density, or ESD.  This is just a histogram of the eigenvalues of the layer correlation matrix&nbsp;<strong>X=W<sup>T</sup>W</strong>.  </p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: python; title: ; notranslate">
import numpy as np
import matplotlib,pyplot as plt
...
X = np.dot(W,W.T)
evals, evecs = np.linalg.eig(X(
plt.hist(evals, bin=100, density=True)
...

</pre></div>


<p>By specifying the randomize option, WW randomizes elements of the weight matrix <strong>W</strong>, and then computes the it&#8217;s ESD.  This randomized ESD is overlaid on the orginal ESD of <strong>X</strong>, and ploted on a log scale. </p>



<p>This is shown above, in the RHS (right hand side).  The original layer ESD is <mark style="background-color:rgba(0, 0, 0, 0);color:#67bf96;" class="has-inline-color"><strong>green</strong></mark>; the randomized ESD is <strong><mark style="background-color:rgba(0, 0, 0, 0);color:#c43c1a;" class="has-inline-color">red</mark></strong>,  And the <strong><mark style="background-color:rgba(0, 0, 0, 0);color:#dd5533;" class="has-inline-color">orange line </mark></strong>depicts the largest eigenvalue <img src="https://s0.wp.com/latex.php?latex=%5Clambda_%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clambda_%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda_%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lambda_{max}" class="latex" /> of the randomized ESD.</p>



<p><img data-attachment-id="14298" data-permalink="https://calculatedcontent.com/2021/10/17/fantastic-measures-of-generalization-that-actually-work-part-1/screen-shot-2021-10-17-at-11-47-59-pm/" data-orig-file="https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-17-at-11.47.59-pm.png" data-orig-size="2002,960" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen Shot 2021-10-17 at 11.47.59 PM" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-17-at-11.47.59-pm.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-17-at-11.47.59-pm.png?w=1024" class="wp-image-14298" style="width:1000px;" src="https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-17-at-11.47.59-pm.png" alt=""><br>If the layer is  well trained  matrix, then  when <strong>W</strong> is randomized, it&#8217;s ESD will look like that of a normally distributed random matrix.  This is shown in Figure (a), above.  </p>



<p>But if the layer is over-trained, then it&#8217;s weight matrix <strong>W</strong> may have some unusually large elements, where the correlations may concentrate, or become <em>trapped</em>. In this case, the ESD may have 1 or more unusually large eigenvalues.  This is shown in Figure (b) above, with the <strong><mark style="background-color:rgba(0, 0, 0, 0);color:#dd5533;" class="has-inline-color">orange line</mark></strong> extending to the far right of the bulk of the <strong>red</strong> ESD. </p>



<p>Notice also that in Figure (a), the <strong><mark style="background-color:rgba(0, 0, 0, 0);color:#67bf96;" class="has-inline-color">green</mark></strong> ESD is very Heavy-Tailed, with the histogram extending out to log10=2, or the largest eigenvalue of nearly 100:  <img src="https://s0.wp.com/latex.php?latex=%5Clambda%5Csim10%5E%7B2%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clambda%5Csim10%5E%7B2%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda%5Csim10%5E%7B2%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lambda&#92;sim10^{2}" class="latex" />.  But in  Figure (b),, the green ESD has a distinctly different shape and is smaller in scale than in Figure (a).  In fact, in (b), the <strong><mark style="background-color:rgba(0, 0, 0, 0);color:#67bf96;" class="has-inline-color">green</mark></strong> (original) and <strong><mark style="background-color:rgba(0, 0, 0, 0);color:#c43c1a;" class="has-inline-color">red</mark></strong> (randomized) layer ESDs look almost the same, except for a small shelf of larger <mark style="background-color:rgba(0, 0, 0, 0);color:#67bf96;" class="has-inline-color"><strong>green</strong></mark> eigenvalues, extending out to and concentrating around the <strong><mark style="background-color:rgba(0, 0, 0, 0);color:#dd5533;" class="has-inline-color">orange line</mark></strong>.  </p>



<p class="has-text-align-center"><strong>In cases like this, we can identify  the <span style="color:#dd5533;" class="has-inline-color">orange line</span> as a <em>Correlation Trap.</em>  </strong></p>



<p>This indicates that something went wrong in training this layer, and the model did not capture the correlations in this layer in a way that will generalize well to other examples.</p>



<h3>Conclusion</h3>



<p>Using the Weight Watcher tool, you can detect this and other potential problems when training or fine-tuning your Deep Neural Networks.</p>



<p>You can learn more about it on the <a href="http://github.com/CalculatedContent/WeightWatcher">WeightWatcher github website.</a></p>
]]></content:encoded>
					
					<wfw:commentRss>https://calculatedcontent.com/2021/04/04/are-your-models-overtrained/feed/</wfw:commentRss>
			<slash:comments>4</slash:comments>
		
		
		
		<media:thumbnail url="https://charlesmartin14.files.wordpress.com/2021/04/correlation_trap.jpeg" />
		<media:content url="https://charlesmartin14.files.wordpress.com/2021/04/correlation_trap.jpeg" medium="image">
			<media:title type="html">correlation_trap</media:title>
		</media:content>

		<media:content url="https://1.gravatar.com/avatar/1ae78e5099a40f308b172a5a65416cab?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">charlesmartin14</media:title>
		</media:content>

		<media:content url="https://charlesmartin14.files.wordpress.com/2021/10/screen-shot-2021-10-17-at-11.47.59-pm.png" medium="image" />
	</item>
		<item>
		<title>Simpson&#8217;s Paradox and Deep Learning Metrics with Weightwatcher</title>
		<link>https://calculatedcontent.com/2020/11/26/simpsons-paradox-and-deep-learning-metrics-with-weightwatcher/</link>
					<comments>https://calculatedcontent.com/2020/11/26/simpsons-paradox-and-deep-learning-metrics-with-weightwatcher/#comments</comments>
		
		<dc:creator><![CDATA[Charles H Martin, PhD]]></dc:creator>
		<pubDate>Fri, 27 Nov 2020 07:43:27 +0000</pubDate>
				<category><![CDATA[Uncategorized]]></category>
		<guid isPermaLink="false">http://calculatedcontent.com/?p=13878</guid>

					<description><![CDATA[What is WeightWatcher ? The WeightWatcher tool is an open-source python package that can be used to predict the test &#8230; <a class="more-link" href="https://calculatedcontent.com/2020/11/26/simpsons-paradox-and-deep-learning-metrics-with-weightwatcher/">More</a>]]></description>
										<content:encoded><![CDATA[
<h5>What is WeightWatcher ?</h5>



<p>The WeightWatcher tool is an open-source python package that can be used to predict the test accuracy of a series similar of Deep Neural Network (DNN) &#8212; without peeking at the test data.    </p>



<p>WeightWatcher is based on research done in collaboration with UC Berkeley on the foundations of Deep Learning. We built this tool to help you analyze and debug your Deep Neural Networks.  </p>



<p>It is easy to install and run; the tool will analyze your model and return both summary statistics and detailed metrics for each layer:</p>



<figure class="wp-block-image size-large is-resized"><a href="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-25-at-8.28.33-pm.png"><img loading="lazy" data-attachment-id="13907" data-permalink="https://calculatedcontent.com/screen-shot-2020-11-25-at-8-28-33-pm/" data-orig-file="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-25-at-8.28.33-pm.png" data-orig-size="906,766" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2020-11-25-at-8.28.33-pm" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-25-at-8.28.33-pm.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-25-at-8.28.33-pm.png?w=906" src="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-25-at-8.28.33-pm.png?w=906" alt="" class="wp-image-13907" width="408" height="345" srcset="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-25-at-8.28.33-pm.png?w=408 408w, https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-25-at-8.28.33-pm.png?w=816 816w, https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-25-at-8.28.33-pm.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-25-at-8.28.33-pm.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-25-at-8.28.33-pm.png?w=768 768w" sizes="(max-width: 408px) 100vw, 408px" /></a></figure>



<p>The <a href="https://github.com/CalculatedContent/WeightWatcher">WeightWatcher github page</a> lists various papers and online presentations given at UC Berkeley and Stanford, and various conferences like ICML, KDD, etc.  There, and on this blog, you can find examples of how to use it.  </p>



<p>This post describes how to select the metric for your models, and why.</p>



<h5><strong>Different Metrics for Different Models</strong></h5>



<p>You can use WeightWatcher to model a series of DNNs of either increasing size, or with different hyperparameters.  But you need different metrics &#8212; <img src="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha" class="latex" /> vs. <img src="https://s0.wp.com/latex.php?latex=%5Chat%7B%5Calpha%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Chat%7B%5Calpha%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Chat%7B%5Calpha%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;hat{&#92;alpha}" class="latex" /> &#8212; for different cases:</p>



<ul><li><strong>alpha <img src="https://s0.wp.com/latex.php?latex=%5Calpha%5C%3B%5C%3B&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha%5C%3B%5C%3B&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha%5C%3B%5C%3B&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha&#92;;&#92;;" class="latex" /> : </strong> for different hyper-parameters settings (batch size, weight decay, &#8230;) on the same model</li><li><strong>weighted alpha: <img src="https://s0.wp.com/latex.php?latex=%5Chat%7B%5Calpha%7D%5C%3B%5C%3B&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Chat%7B%5Calpha%7D%5C%3B%5C%3B&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Chat%7B%5Calpha%7D%5C%3B%5C%3B&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;hat{&#92;alpha}&#92;;&#92;;" class="latex" /> :</strong> for an architecture series like VGG11, VGG13, VGG16, VGG19 </li></ul>



<p>But why do need 2 different alpha metrics?   To understand this, we need to understand</p>



<h4><strong>Spectral Norms and Deep Learning   </strong></h4>



<p>Traditional machine learning theory suggests that the test performance of a Deep Neural Network is correlated with the average log Spectral Norm. That is, the test error should be bounded by the average Spectral Norm, so the smaller norm, the smaller the test error. </p>



<p>The Spectral Norm <img src="https://s0.wp.com/latex.php?latex=%5CVert%5Cmathbf%7BW%7D%5CVert%5E%7B2%7D_%7B%5Cinfty%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5CVert%5Cmathbf%7BW%7D%5CVert%5E%7B2%7D_%7B%5Cinfty%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5CVert%5Cmathbf%7BW%7D%5CVert%5E%7B2%7D_%7B%5Cinfty%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;Vert&#92;mathbf{W}&#92;Vert^{2}_{&#92;infty}" class="latex" /> of an <img src="https://s0.wp.com/latex.php?latex=N%5Ctimes+M&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=N%5Ctimes+M&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=N%5Ctimes+M&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="N&#92;times M" class="latex" /> matrix <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{W}" class="latex" /> is just the (square root of the ) maximum eigenvalue <img src="https://s0.wp.com/latex.php?latex=%5Clambda_%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clambda_%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda_%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lambda_{max}" class="latex" /> of its correlation matrix <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{X}" class="latex" /></p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D%3A%3D+%5Cdfrac%7B1%7D%7BN%7D%5Cmathbf%7BW%7D%5E%7BT%7D%5Cmathbf%7BW%7D%2C%5C%3B%5C%3B%5C%3B+%5Cmathbf%7BX%7D%5Cmathbf%7Be%7D_%7Bl%7D%3D+%5Clambda_%7Bl%7D%5Cmathbf%7Be%7D_%7Bl%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D%3A%3D+%5Cdfrac%7B1%7D%7BN%7D%5Cmathbf%7BW%7D%5E%7BT%7D%5Cmathbf%7BW%7D%2C%5C%3B%5C%3B%5C%3B+%5Cmathbf%7BX%7D%5Cmathbf%7Be%7D_%7Bl%7D%3D+%5Clambda_%7Bl%7D%5Cmathbf%7Be%7D_%7Bl%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D%3A%3D+%5Cdfrac%7B1%7D%7BN%7D%5Cmathbf%7BW%7D%5E%7BT%7D%5Cmathbf%7BW%7D%2C%5C%3B%5C%3B%5C%3B+%5Cmathbf%7BX%7D%5Cmathbf%7Be%7D_%7Bl%7D%3D+%5Clambda_%7Bl%7D%5Cmathbf%7Be%7D_%7Bl%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{X}:= &#92;dfrac{1}{N}&#92;mathbf{W}^{T}&#92;mathbf{W},&#92;;&#92;;&#92;; &#92;mathbf{X}&#92;mathbf{e}_{l}= &#92;lambda_{l}&#92;mathbf{e}_{l}" class="latex" /></p>



<p>We denote the (squared) Spectal Norm as:</p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=%5CVert%5Cmathbf%7BW%7D%5CVert%5E%7B2%7D_%7B%5Cinfty%7D+%3A%3D+%5Clambda%5E%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5CVert%5Cmathbf%7BW%7D%5CVert%5E%7B2%7D_%7B%5Cinfty%7D+%3A%3D+%5Clambda%5E%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5CVert%5Cmathbf%7BW%7D%5CVert%5E%7B2%7D_%7B%5Cinfty%7D+%3A%3D+%5Clambda%5E%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;Vert&#92;mathbf{W}&#92;Vert^{2}_{&#92;infty} := &#92;lambda^{max}" class="latex" /></p>



<p>Note:<a href="https://arxiv.org/abs/1810.01075"> in earlier papers we (and others) also use:</a> <img src="https://s0.wp.com/latex.php?latex=%5CVert%5Cmathbf%7BW%7D%5CVert%5E%7B2%7D_%7B2%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5CVert%5Cmathbf%7BW%7D%5CVert%5E%7B2%7D_%7B2%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5CVert%5Cmathbf%7BW%7D%5CVert%5E%7B2%7D_%7B2%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;Vert&#92;mathbf{W}&#92;Vert^{2}_{2}" class="latex" /> </p>



<p>WeightWatcher computes the log Spectral Norm for each layer, and defines:</p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=%5Clangle%5Clog_%7B10%7D%5CVert%5Cmathbf%7BW%7D%5CVert%5E%7B2%7D_%7B%5Cinfty%7D%5Crangle+%3A%3D+%5Cdfrac%7B1%7D%7BN_L%7D%5Csum_%7Bl%7D%5E%7BN_L%7D%5Clog_%7B10%7D%5Clambda%5E%7Bmax%7D_%7Bl%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clangle%5Clog_%7B10%7D%5CVert%5Cmathbf%7BW%7D%5CVert%5E%7B2%7D_%7B%5Cinfty%7D%5Crangle+%3A%3D+%5Cdfrac%7B1%7D%7BN_L%7D%5Csum_%7Bl%7D%5E%7BN_L%7D%5Clog_%7B10%7D%5Clambda%5E%7Bmax%7D_%7Bl%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clangle%5Clog_%7B10%7D%5CVert%5Cmathbf%7BW%7D%5CVert%5E%7B2%7D_%7B%5Cinfty%7D%5Crangle+%3A%3D+%5Cdfrac%7B1%7D%7BN_L%7D%5Csum_%7Bl%7D%5E%7BN_L%7D%5Clog_%7B10%7D%5Clambda%5E%7Bmax%7D_%7Bl%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;langle&#92;log_{10}&#92;Vert&#92;mathbf{W}&#92;Vert^{2}_{&#92;infty}&#92;rangle := &#92;dfrac{1}{N_L}&#92;sum_{l}^{N_L}&#92;log_{10}&#92;lambda^{max}_{l}" class="latex" /></p>



<p>which we compute by averaging over all <img src="https://s0.wp.com/latex.php?latex=N_%7BL%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=N_%7BL%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=N_%7BL%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="N_{L}" class="latex" /> layer weight matrices.</p>



<p>We compute the eigenvalues, or the Empirical Spectral Density (ESD), of each layer <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{X}" class="latex" /> by running SVD directly on the layer <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{W}" class="latex" /> or, for Conv2D layers, some matrix slice (see the Appendix).</p>



<h5><strong>Spectral Norm Regularization</strong></h5>



<p><a href="https://arxiv.org/pdf/1705.10941.pdf">It has been suggested by Yoshida and Miyato</a> that the Spectral Norm would make a good regularizer for DNNs.  The basic idea is that the test data should look enough like the training data so that if we can say something about how the DNN performs on <em>perturbed</em> training data, that will also say something about the test performance.  </p>



<p>Here is the text from the paper; let. me explain  how to interpret this in practical terms.</p>



<figure class="wp-block-image size-large"><a href="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-25-at-10.40.43-pm.png"><img data-attachment-id="13926" data-permalink="https://calculatedcontent.com/screen-shot-2020-11-25-at-10-40-43-pm/" data-orig-file="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-25-at-10.40.43-pm.png" data-orig-size="2280,1118" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2020-11-25-at-10.40.43-pm" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-25-at-10.40.43-pm.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-25-at-10.40.43-pm.png?w=1024" src="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-25-at-10.40.43-pm.png?w=1024" alt="" class="wp-image-13926" srcset="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-25-at-10.40.43-pm.png?w=1024 1024w, https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-25-at-10.40.43-pm.png?w=2048 2048w, https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-25-at-10.40.43-pm.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-25-at-10.40.43-pm.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-25-at-10.40.43-pm.png?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px" /></a></figure>



<p>We imagine the test data <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7Bx%7D_%7Btest%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7Bx%7D_%7Btest%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7Bx%7D_%7Btest%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{x}_{test}" class="latex" /> must look like the training data <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7Bx%7D_%7Btrain%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7Bx%7D_%7Btrain%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7Bx%7D_%7Btrain%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{x}_{train}" class="latex" /> with some small perturbation <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7B%5Cxi%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7B%5Cxi%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7B%5Cxi%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{&#92;xi}" class="latex" />.  Let us write this as:</p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7Bx%7D_%7Btest%7D%5Csim%5Cmathbf%7Bx%7D_%7Btrain%7D%2B%5Cmathbf%7B%5Cxi%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7Bx%7D_%7Btest%7D%5Csim%5Cmathbf%7Bx%7D_%7Btrain%7D%2B%5Cmathbf%7B%5Cxi%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7Bx%7D_%7Btest%7D%5Csim%5Cmathbf%7Bx%7D_%7Btrain%7D%2B%5Cmathbf%7B%5Cxi%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{x}_{test}&#92;sim&#92;mathbf{x}_{train}+&#92;mathbf{&#92;xi}" class="latex" /></p>



<p>As we train a DNN, we run several epochs of BackProp, which amounts to multiplying <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7Bx%7D_%7Btrain%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7Bx%7D_%7Btrain%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7Bx%7D_%7Btrain%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{x}_{train}" class="latex" /> by a weight matrix  <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{W}" class="latex" /> at each layer, apply an activation function, and repeat until we get a label <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7By%7D_%7Btrain%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7By%7D_%7Btrain%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7By%7D_%7Btrain%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{y}_{train}" class="latex" /></p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=RELU%28%5Cmathbf%7BW%7D%5Cmathbf%7Bx%7D_%7Btrain%7D%2B%5Cmathbf%7Bb%7D%29%5Crightarrow%5Ccdots%5Crightarrow%5Cmathbf%7By%7D_%7Btrain%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=RELU%28%5Cmathbf%7BW%7D%5Cmathbf%7Bx%7D_%7Btrain%7D%2B%5Cmathbf%7Bb%7D%29%5Crightarrow%5Ccdots%5Crightarrow%5Cmathbf%7By%7D_%7Btrain%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=RELU%28%5Cmathbf%7BW%7D%5Cmathbf%7Bx%7D_%7Btrain%7D%2B%5Cmathbf%7Bb%7D%29%5Crightarrow%5Ccdots%5Crightarrow%5Cmathbf%7By%7D_%7Btrain%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="RELU(&#92;mathbf{W}&#92;mathbf{x}_{train}+&#92;mathbf{b})&#92;rightarrow&#92;cdots&#92;rightarrow&#92;mathbf{y}_{train}" class="latex" /></p>



<p>To get an estimate, or bound, on the  test accuracy, we can then imagine applying the matrix multiply to the perturbed training point</p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=RELU%28%5Cmathbf%7BW%7D%28%5Cmathbf%7Bx%7D_%7Btrain%7D%2B%5Cmathbf%7B%5Cxi%7D%29%2B%5Cmathbf%7Bb%7D%29%5Crightarrow%5Ccdots%5Crightarrow%5Cmathbf%7By%7D_%7Btest%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=RELU%28%5Cmathbf%7BW%7D%28%5Cmathbf%7Bx%7D_%7Btrain%7D%2B%5Cmathbf%7B%5Cxi%7D%29%2B%5Cmathbf%7Bb%7D%29%5Crightarrow%5Ccdots%5Crightarrow%5Cmathbf%7By%7D_%7Btest%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=RELU%28%5Cmathbf%7BW%7D%28%5Cmathbf%7Bx%7D_%7Btrain%7D%2B%5Cmathbf%7B%5Cxi%7D%29%2B%5Cmathbf%7Bb%7D%29%5Crightarrow%5Ccdots%5Crightarrow%5Cmathbf%7By%7D_%7Btest%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="RELU(&#92;mathbf{W}(&#92;mathbf{x}_{train}+&#92;mathbf{&#92;xi})+&#92;mathbf{b})&#92;rightarrow&#92;cdots&#92;rightarrow&#92;mathbf{y}_{test}" class="latex" /></p>



<p>So if we can say something about how the DNN should perform on a perturbed training point <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7Bx%7D_%7Btrain%7D%2B%5Cmathbf%7B%5Cxi%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7Bx%7D_%7Btrain%7D%2B%5Cmathbf%7B%5Cxi%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7Bx%7D_%7Btrain%7D%2B%5Cmathbf%7B%5Cxi%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{x}_{train}+&#92;mathbf{&#92;xi}" class="latex" />, we can say something about the test output <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7By%7D_%7Btest%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7By%7D_%7Btest%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7By%7D_%7Btest%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{y}_{test}" class="latex" />.  </p>



<p><em>What can we say ? </em></p>



<p>  When we apply an activation function <img src="https://s0.wp.com/latex.php?latex=f%7Bx%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%7Bx%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%7Bx%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f{x}" class="latex" />, like a RELU, which acts pointwise on the data vector, and acts like an affine transformation.  So the RELU+weight matrix multiply is a bounded linear operator (at least piecewise) and therefore it can be bounded by it&#8217;s <a href="https://www.youtube.com/watch?v=K-yDVqijSYw">Spectral Radius</a> <img src="https://s0.wp.com/latex.php?latex=%5Csigma%28%5Cmathbf%7BW%7D%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Csigma%28%5Cmathbf%7BW%7D%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Csigma%28%5Cmathbf%7BW%7D%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;sigma(&#92;mathbf{W})" class="latex" />.</p>



<p>So we say that we want to learn a DNN model such that, at each layer, the action of the layer matrix-vector multiply is bounded by the Spectral Norm of its layer weight matrix.  This should, in theory, give good test performance.  By applying a Spectral Norm regularizer, we think we can make a DNN that is more robust to small changes in it&#8217;s input.  That is, we can make it perform better on random  perturbations the of training data , and, therefore, presumably, better on the test data.</p>



<p><strong>From Bounds to a Regularizer</strong></p>



<p>When we develop a mathematical bound , our first instinct is to develop a numerical regularizer <img src="https://s0.wp.com/latex.php?latex=%5COmega%28%5Cmathbf%7BW%7D%2C+%5Cmathbf%7Bb%7D%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5COmega%28%5Cmathbf%7BW%7D%2C+%5Cmathbf%7Bb%7D%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5COmega%28%5Cmathbf%7BW%7D%2C+%5Cmathbf%7Bb%7D%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;Omega(&#92;mathbf{W}, &#92;mathbf{b})" class="latex" />.   That is, when solving our optimization problem&#8211;minimizing the DNN Energy function <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BE%7D_%7BDNN%7D%28%5Cmathbf%7BX%7D%2C+%5Cmathbf%7BY%7D%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BE%7D_%7BDNN%7D%28%5Cmathbf%7BX%7D%2C+%5Cmathbf%7BY%7D%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathcal%7BE%7D_%7BDNN%7D%28%5Cmathbf%7BX%7D%2C+%5Cmathbf%7BY%7D%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathcal{E}_{DNN}(&#92;mathbf{X}, &#92;mathbf{Y})" class="latex" />&#8211;we want to prevent the solution from blowing up. Having a <em>mathematically rigorous</em> bound helps here since it seems to bound the BackProp optimization step on every iteration:</p>



<p class="has-text-align-center"> <img src="https://s0.wp.com/latex.php?latex=%5Cunderset%7B%5Cmathbf%7BW%7D%2C+%5Cmathbf%7Bb%7D%7D%7B%5Cmin%7D%5C%3B%5Cmathcal%7BE%7D_%7BDNN%7D%28%5Cmathbf%7BX%7D%2C+%5Cmathbf%7BY%7D%29%2B%5COmega%28%5Cmathbf%7BW%7D%2C+%5Cmathbf%7Bb%7D%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cunderset%7B%5Cmathbf%7BW%7D%2C+%5Cmathbf%7Bb%7D%7D%7B%5Cmin%7D%5C%3B%5Cmathcal%7BE%7D_%7BDNN%7D%28%5Cmathbf%7BX%7D%2C+%5Cmathbf%7BY%7D%29%2B%5COmega%28%5Cmathbf%7BW%7D%2C+%5Cmathbf%7Bb%7D%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cunderset%7B%5Cmathbf%7BW%7D%2C+%5Cmathbf%7Bb%7D%7D%7B%5Cmin%7D%5C%3B%5Cmathcal%7BE%7D_%7BDNN%7D%28%5Cmathbf%7BX%7D%2C+%5Cmathbf%7BY%7D%29%2B%5COmega%28%5Cmathbf%7BW%7D%2C+%5Cmathbf%7Bb%7D%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;underset{&#92;mathbf{W}, &#92;mathbf{b}}{&#92;min}&#92;;&#92;mathcal{E}_{DNN}(&#92;mathbf{X}, &#92;mathbf{Y})+&#92;Omega(&#92;mathbf{W}, &#92;mathbf{b})" class="latex" /></p>



<p>Notice that since the regularizer <img src="https://s0.wp.com/latex.php?latex=%5COmega%28%5Cmathbf%7BW%7D%2C+%5Cmathbf%7Bb%7D%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5COmega%28%5Cmathbf%7BW%7D%2C+%5Cmathbf%7Bb%7D%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5COmega%28%5Cmathbf%7BW%7D%2C+%5Cmathbf%7Bb%7D%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;Omega(&#92;mathbf{W}, &#92;mathbf{b})" class="latex" /> appears in the optimization problem, it must be differentiable (either directly, or using some trick).</p>



<p>A regularizer must also be easy to implement.  For example, <a href="https://arxiv.org/pdf/1901.11352.pdf">we could also bound the Jacobian</a> <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7B%5Cmathbf%7BJ%7D%7D%28%5Cmathbf%7BW%7D%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathcal%7B%5Cmathbf%7BJ%7D%7D%28%5Cmathbf%7BW%7D%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathcal%7B%5Cmathbf%7BJ%7D%7D%28%5Cmathbf%7BW%7D%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathcal{&#92;mathbf{J}}(&#92;mathbf{W})" class="latex" />, but this very expensive to compute, and it is difficult to apply even a norm bound of this  <img src="https://s0.wp.com/latex.php?latex=%28%5CVert%5Cmathcal%7B%5Cmathbf%7BJ%7D%7D%5Cmathbf%7BW%7D%29%5CVert%5E%7B2%7D_%7BF%7D%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28%5CVert%5Cmathcal%7B%5Cmathbf%7BJ%7D%7D%5Cmathbf%7BW%7D%29%5CVert%5E%7B2%7D_%7BF%7D%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28%5CVert%5Cmathcal%7B%5Cmathbf%7BJ%7D%7D%5Cmathbf%7BW%7D%29%5CVert%5E%7B2%7D_%7BF%7D%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(&#92;Vert&#92;mathcal{&#92;mathbf{J}}&#92;mathbf{W})&#92;Vert^{2}_{F})" class="latex" />, on every step of BackProp.  It might also seem that the Spectral norm is hard to compute because one needs to run SVD, but there is a simple trick.  One can approximate the maximum eigenvalue <img src="https://s0.wp.com/latex.php?latex=%5Clambda%5E%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clambda%5E%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda%5E%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lambda^{max}" class="latex" /> of <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{X}" class="latex" /> using the Power Method, by running it for say steps, and then simply add this to the SGD update step,.  There are many examples on github of this, and <a href="https://github.com/IShengFang/SpectralNormalizationKeras">it has been applied, in particular, to GANs</a> and <a href="https://arxiv.org/pdf/1807.04720.pdf">has been shown to work very well in large scale studies.</a></p>



<div class="wp-block-image"><figure class="aligncenter"><img src="https://discuss.pytorch.org/uploads/default/optimized/2X/d/d648f9e9c6547465033aeefbcaa751da5c461f22_2_690x310.png" alt="image" /></figure></div>



<p>Also, since this expression is linear in <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{W}" class="latex" />, we can also readily plug this into TensorFlow /Keras or PyTorch and use autograd to compute the derivatives.  <a href="https://www.tensorflow.org/addons/api_docs/python/tfa/layers/SpectralNormalization">It is available as a Tensforflow Addon</a>, and is part of the <a href="https://pytorch.org/docs/stable/generated/torch.nn.utils.spectral_norm.html">core pyTorch 1.7 package.</a></p>



<p>Spectral Norm Regularization has not been widely used (outside say GANs) because it only works well for very deep networks.  See, however, this adaption for smaller DNNs called <a href="https://github.com/AntixK/mean-spectral-norm">Mean Spectral Normalization</a>.</p>



<h5><strong>From Worst-Case Bounds to Average Case Behavior</strong></h5>



<p>What do we want from a theory of learning ?   With WeightWatcher, we have never sought. a rigorous bound. That&#8217;s not the goal of our theory. We do not seek a bound because this decribes the<em> worst-case behavior;</em>  we seek to understand <em>the average-case behavior</em> (However, what we can do repair the Spectral Norm as a metric , as shown below.)</p>



<p>With the average-case, we hope to able to predict the generalization error of a DNN (and without peeking at the test data). And we mean this a very practical sense, applying to very large, production quality models, both in training and fine-tuning them.   </p>



<p>So what&#8217;s the difference between having a bound and analyzing average-case behavior ?</p>



<ul><li>With a mathematical bound,  we can bound the error&#8211;for a single model.  So this is alike a prediction, and , as shown above, we can use this to develop better regularizers.</li></ul>



<ul><li>WIth the average-case behavior, we want to predict trends across many different models. Of both different depths (since deeper models usually perform better) and with different hyperparameter settings (batch size, momentum, weight decay, etc.)</li></ul>



<p>It&#8217;s not at all obvious that we can expect a mathematical bound to be correlated with trends in the test accuracy of real-world DNNs.  It turns out, the Spectral Norm works pretty well&#8211;at least across pretrained DNNs of increasing depth.</p>



<p>Here is an example, showing how the Spectral Norm performs on the VGG series</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><a href="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-26-at-10.21.43-pm.png"><img loading="lazy" data-attachment-id="13974" data-permalink="https://calculatedcontent.com/screen-shot-2020-11-26-at-10-21-43-pm/" data-orig-file="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-26-at-10.21.43-pm.png" data-orig-size="782,676" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2020-11-26-at-10.21.43-pm" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-26-at-10.21.43-pm.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-26-at-10.21.43-pm.png?w=782" src="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-26-at-10.21.43-pm.png?w=782" alt="" class="wp-image-13974" width="506" height="438" srcset="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-26-at-10.21.43-pm.png?w=506 506w, https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-26-at-10.21.43-pm.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-26-at-10.21.43-pm.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-26-at-10.21.43-pm.png?w=768 768w, https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-26-at-10.21.43-pm.png 782w" sizes="(max-width: 506px) 100vw, 506px" /></a><figcaption>Average Log Spectral Norm vs Top1 Test Accuracy for several  VGG models <br>(VGG11, VGG13, VGG16, VGG19, with/out Batchnorm, trained on Imagenet-1K)</figcaption></figure></div>



<p>We see that the average log Spectral norm correlates quite well with the test accuracy of the DNN architecture series of the pretrained VGG models.  This is remarkable, since we do not have access to the training or the test data (or other information).  </p>



<p><a href="https://arxiv.org/pdf/2002.06716.pdf">We have used WeightWatcher </a>to analyze hundreds of pretrained models, of increasing depths, and using different data sets. Generally speaking, the average log Spectral Norm correlates well with the test accuracies of many different DNN series and for different data sets.  </p>



<p>But not always. And that&#8217;s the rub.</p>



<h5><strong>Simpson&#8217;s Paradox (or our Spectral surprise) </strong></h5>



<p>Oddly, while the average log Spectral Norm <img src="https://s0.wp.com/latex.php?latex=%5Clangle%5Clog_%7B10%7D%5CVert%5Cmathbf%7BW%7D%5CVert%5E%7B2%7D_%7B%5Cinfty%7D%5Crangle&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clangle%5Clog_%7B10%7D%5CVert%5Cmathbf%7BW%7D%5CVert%5E%7B2%7D_%7B%5Cinfty%7D%5Crangle&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clangle%5Clog_%7B10%7D%5CVert%5Cmathbf%7BW%7D%5CVert%5E%7B2%7D_%7B%5Cinfty%7D%5Crangle&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;langle&#92;log_{10}&#92;Vert&#92;mathbf{W}&#92;Vert^{2}_{&#92;infty}&#92;rangle" class="latex" /> is correlated with test error, when changing the depth of a DNN model,  it turns out to be <em>anti-correlated </em>with test error when varying the optimization hyper-parameters.     This is a classic example of Simpson&#8217;s paradox.</p>



<p>We have noted this, and <a href="https://arxiv.org/abs/1912.02178">it has also pointed by Bengio and co-workers</a>.  Indeed, an entire contest was recently set up to study this issue&#8211;the <a href="https://competitions.codalab.org/competitions/25301">2020 NeurIPS Predicting Generalization challenge</a>.</p>



<p>Below we can see the paradox by looking at predictions for ~100 small, pre-trained  VGG-like models, (provided by contest).  We use WeightWatcher (version ww0.4) to compute the average <code>log_spectral_norm</code>, and compare to. the reported test accuracies for the contest <code><strong>task2_v1</strong></code> set of baseline VVG-like models:</p>



<div class="wp-block-image"><figure class="aligncenter size-large"><a href="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-26-at-9.02.20-pm.png"><img data-attachment-id="13955" data-permalink="https://calculatedcontent.com/screen-shot-2020-11-26-at-9-02-20-pm/" data-orig-file="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-26-at-9.02.20-pm.png" data-orig-size="1330,642" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2020-11-26-at-9.02.20-pm" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-26-at-9.02.20-pm.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-26-at-9.02.20-pm.png?w=1024" src="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-26-at-9.02.20-pm.png?w=1024" alt="" class="wp-image-13955" srcset="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-26-at-9.02.20-pm.png?w=1024 1024w, https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-26-at-9.02.20-pm.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-26-at-9.02.20-pm.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-26-at-9.02.20-pm.png?w=768 768w, https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-26-at-9.02.20-pm.png 1330w" sizes="(max-width: 1024px) 100vw, 1024px" /></a><figcaption><strong>task1_v4</strong>: 96 models trained on CIFAR10:&nbsp;<em>like VGG models</em></figcaption></figure></div>



<p>For more details, please see the contest website details, and/or our <a href="https://charlesmartin14.github.io/contest-postmortem/intro.html">contest post-mortem Jupyter Book </a>and paper on the contest (coming soon). </p>



<p>Notice that the <font color="blue"><code>2xx</code> models</font> have the best test accuracies, and, correspondingly, as a group, the smallest  <code>avg logspectralnorm</code>.  Smaller error correlates with the smaller norm metric.  Likewise, the <font color="teal"><code>6xx</code> models</font> models have. the smallest Test Accuracies as. a group, and also, the largest <code>avg logspectralnorm</code>.  </p>



<div class="wp-block-image"><figure class="aligncenter size-large"><a href="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-21-at-9.21.04-am.png"><img data-attachment-id="13950" data-permalink="https://calculatedcontent.com/screen-shot-2020-11-21-at-9-21-04-am/" data-orig-file="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-21-at-9.21.04-am.png" data-orig-size="1448,1240" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2020-11-21-at-9.21.04-am" data-image-description="&lt;p&gt;Simpson&#8217;s Paradox for the Spectral Norm metric, applied to a series of VGG-like models.&lt;/p&gt;
" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-21-at-9.21.04-am.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-21-at-9.21.04-am.png?w=1024" src="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-21-at-9.21.04-am.png?w=1024" alt="" class="wp-image-13950" srcset="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-21-at-9.21.04-am.png?w=1024 1024w, https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-21-at-9.21.04-am.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-21-at-9.21.04-am.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-21-at-9.21.04-am.png?w=768 768w, https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-21-at-9.21.04-am.png 1448w" sizes="(max-width: 1024px) 100vw, 1024px" /></a></figure></div>



<p class="has-text-align-center"><strong><em>This is a classic example of Simpson&#8217;s Paradox.</em></strong></p>



<p>However, also note that, for each model group (<code>2xx, 10xx, 6xx, &amp; 9xx</code>), we can draw, roughly, a straight line that shows most of the test accuracies in that group are anti-correlated with the <code>avg. log_spectral_norm</code> <img src="https://s0.wp.com/latex.php?latex=%5Clangle%5Clog_%7B10%7D%5CVert%5Cmathbf%7BW%7D%5CVert%5E%7B2%7D_%7B%5Cinfty%7D%5Crangle&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clangle%5Clog_%7B10%7D%5CVert%5Cmathbf%7BW%7D%5CVert%5E%7B2%7D_%7B%5Cinfty%7D%5Crangle&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clangle%5Clog_%7B10%7D%5CVert%5Cmathbf%7BW%7D%5CVert%5E%7B2%7D_%7B%5Cinfty%7D%5Crangle&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;langle&#92;log_{10}&#92;Vert&#92;mathbf{W}&#92;Vert^{2}_{&#92;infty}&#92;rangle" class="latex" />.  Now the regression is not always great, and there are outliers, but we think the general trends hold well enough for this level of discussion (and we will drill into the details in our next paper).</p>



<div class="wp-block-image"><figure class="alignright is-resized"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/f/fb/Simpsons_paradox_-_animation.gif/220px-Simpsons_paradox_-_animation.gif" alt="" width="307" height="218" /><figcaption>Simpson&#8217;s Paradox</figcaption></figure></div>



<p>This is a classic example of <a href="https://en.wikipedia.org/wiki/Simpson%27s_paradox#:~:text=Simpson's%20paradox%2C%20which%20also%20goes,when%20these%20groups%20are%20combined.">Simpon&#8217;s Paradox</a>.  </p>



<p>Here, we see a large trend, across the similar models, trained on the same dataset, but with different, depths. </p>



<p>When looking closely at each model group, however, we see the reverse trend. </p>



<p>This makes the Spectral Norm difficult to use as a general purpose metric for predicting test accuracies. <br></p>



<p><strong>WeightWatcher to the Rescue</strong></p>



<p>Using WeightWatcher, however, we can repair the average log Spectral Norm metric by computing it as a weighted average&#8211;weighted by the WeightWatcher <img src="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha" class="latex" /> metric.</p>



<p>Here is a similar plot on the same<strong> task2_v1 </strong>data,, but this time reporting the WeightWatcher average power law metric <img src="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha" class="latex" />.  Notice that <img src="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha" class="latex" /> is well correlated within each model group, as expected when changing model hyperparameters.  Moreover, the <img src="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha" class="latex" /> is not correlated with the Test Accuracy more broadly across different depths, nor is it correlated with the average log Spectral Norm (not shown).</p>



<div class="wp-block-image"><figure class="aligncenter size-large"><a href="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-21-at-11.26.32-am.png"><img data-attachment-id="13969" data-permalink="https://calculatedcontent.com/screen-shot-2020-11-21-at-11-26-32-am/" data-orig-file="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-21-at-11.26.32-am.png" data-orig-size="1392,1300" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2020-11-21-at-11.26.32-am" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-21-at-11.26.32-am.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-21-at-11.26.32-am.png?w=1024" src="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-21-at-11.26.32-am.png?w=1024" alt="" class="wp-image-13969" srcset="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-21-at-11.26.32-am.png?w=1024 1024w, https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-21-at-11.26.32-am.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-21-at-11.26.32-am.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-21-at-11.26.32-am.png?w=768 768w, https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-21-at-11.26.32-am.png 1392w" sizes="(max-width: 1024px) 100vw, 1024px" /></a></figure></div>



<p>WeightWatcher alpha tells us how correlated a single DNN model is.  And we can use to correct the average <code>log_spectral_norm</code> by simply taking a weighted average (called <code>alpha_weighted</code>):</p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=%5Chat%7B%5Calpha%7D%3A%3D%5Cdfrac%7B1%7D%7BN_L%7D%5Csum_%7Bl%7D%5E%7BN_L%7D%5Calpha_%7Bl%7D%5Clog_%7B10%7D%5Clambda%5E%7Bmax%7D_%7Bl%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Chat%7B%5Calpha%7D%3A%3D%5Cdfrac%7B1%7D%7BN_L%7D%5Csum_%7Bl%7D%5E%7BN_L%7D%5Calpha_%7Bl%7D%5Clog_%7B10%7D%5Clambda%5E%7Bmax%7D_%7Bl%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Chat%7B%5Calpha%7D%3A%3D%5Cdfrac%7B1%7D%7BN_L%7D%5Csum_%7Bl%7D%5E%7BN_L%7D%5Calpha_%7Bl%7D%5Clog_%7B10%7D%5Clambda%5E%7Bmax%7D_%7Bl%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;hat{&#92;alpha}:=&#92;dfrac{1}{N_L}&#92;sum_{l}^{N_L}&#92;alpha_{l}&#92;log_{10}&#92;lambda^{max}_{l}" class="latex" /></p>



<p>If we look closely, we can see more in more detail how the  weighted alpha <img src="https://s0.wp.com/latex.php?latex=%5Chat%7B%5Calpha%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Chat%7B%5Calpha%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Chat%7B%5Calpha%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;hat{&#92;alpha}" class="latex" /> corrects the average <code>log_spectral_norm </code>metric in the VGG architecture series.   Below we use WeightWatcher to plot the different metrics vs. the Top 1 Test Accuracy for the many different pre-trained VGG models.</p>



<figure class="wp-block-image size-large is-resized"><a href="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-26-at-10.28.21-pm.png"><img loading="lazy" data-attachment-id="13978" data-permalink="https://calculatedcontent.com/screen-shot-2020-11-26-at-10-28-21-pm/" data-orig-file="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-26-at-10.28.21-pm.png" data-orig-size="2136,680" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2020-11-26-at-10.28.21-pm" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-26-at-10.28.21-pm.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-26-at-10.28.21-pm.png?w=1024" src="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-26-at-10.28.21-pm.png?w=1024" alt="" class="wp-image-13978" width="767" height="243" srcset="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-26-at-10.28.21-pm.png?w=1024 1024w, https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-26-at-10.28.21-pm.png?w=763 763w, https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-26-at-10.28.21-pm.png?w=1527 1527w, https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-26-at-10.28.21-pm.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-26-at-10.28.21-pm.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-26-at-10.28.21-pm.png?w=768 768w" sizes="(max-width: 767px) 100vw, 767px" /></a><figcaption>WeightWatcher average metrics vs. Top1 Test Accuracy for pretrained VGG models<br>(VGG11, VGG13, VGG16, VGG19, with/out BatchNorm, trained on Imagenet-1K)</figcaption></figure>



<p>Consider the plot on the far right, and, specifically, the <font color="pink"> <strong>pink (BN-VGG-16)</strong> </font> and <font color="red"><strong>red dots (VGG-19)</strong></font>, near test accuracy ~ 26.&nbsp;These are 2 models with both different depths (16 vs 19 layers) and different hyperparameter settings (BatchNorm or not).  The two models have nearly the same accuracy,  but a large variance between their average <code>log_spectral_norm</code>. Now consider the far left plot for average alpha <img src="https://s0.wp.com/latex.php?latex=%5Clangle%5Calpha%5Crangle&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clangle%5Calpha%5Crangle&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clangle%5Calpha%5Crangle&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;langle&#92;alpha&#92;rangle" class="latex" />, which shows that and <font color="red"><strong>red</strong> </font> has a smaller alpha than the <font color="pink"> <strong>pink</strong></font> .  The <font color="red"><strong>VGG-19</strong> </font>  model is more strongly correlated than <font color="pink"> <strong>BN_VGG-16</strong></font>.   The average alpha for the <font color="red"><strong>red dot is ~3.5</strong></font>, whereas the <font color="pink"><strong>pink dot ~ 3.85</strong></font>.  When we combine these 2 metrics, on the middle plot (alpha_weighted), the 2 models now appear much closer together. So <code>alpha_weighted</code> metric corrects the average <code>log_spectral_norm</code>, reducing the variance between similar models, and  making <img src="https://s0.wp.com/latex.php?latex=%5Chat%7B%5Calpha%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Chat%7B%5Calpha%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Chat%7B%5Calpha%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;hat{&#92;alpha}" class="latex" /> more suitable to treating models of different depth and different hyperparameter settings.</p>



<h4><strong>Summary</strong></h4>



<p>The open source WeightWatcher tool provides metrics for Deep Neural Networks that allow the user to predict (trends in) the test accuracies of Deep Neural Networks without needing the test data. The different (power law) metrics, <img src="https://s0.wp.com/latex.php?latex=%5Clangle%5Calpha%5Crangle&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clangle%5Calpha%5Crangle&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clangle%5Calpha%5Crangle&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;langle&#92;alpha&#92;rangle" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%5Chat%7B%5Calpha%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Chat%7B%5Calpha%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Chat%7B%5Calpha%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;hat{&#92;alpha}" class="latex" /> apply to models with different hyperparameter settings, and different depths, resp.  Here, we explain why.</p>



<p>The <img src="https://s0.wp.com/latex.php?latex=%5Clangle%5Calpha%5Crangle&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clangle%5Calpha%5Crangle&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clangle%5Calpha%5Crangle&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;langle&#92;alpha&#92;rangle" class="latex" /> average alpha metric describes the amount of correlation contained in the DNN weight matrices.  Smaller <img src="https://s0.wp.com/latex.php?latex=%5Clangle%5Calpha%5Crangle&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clangle%5Calpha%5Crangle&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clangle%5Calpha%5Crangle&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;langle&#92;alpha&#92;rangle" class="latex" /> correlates with better test accuracy for a single model with different hyperparemeter settings.  It is a unique metric, developed from the theory on strongly correlated systems from theoretical chemistry and physics</p>



<p>The <img src="https://s0.wp.com/latex.php?latex=%5Clangle%5Calpha%5Crangle&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clangle%5Calpha%5Crangle&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clangle%5Calpha%5Crangle&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;langle&#92;alpha&#92;rangle" class="latex" /> average weighted alpha metric is suited for treating a series of models with different depths, like the VGG series: VGG11, VGG13, VGG16, VGG19.  It is a weighted average of the log Spectral Norm. </p>



<p>To explain why  <img src="https://s0.wp.com/latex.php?latex=%5Clangle%5Calpha%5Crangle&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clangle%5Calpha%5Crangle&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clangle%5Calpha%5Crangle&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;langle&#92;alpha&#92;rangle" class="latex" /> works, we have reviewed the theory and application of Spectral Norm Regularization, and the use of the average log Spectral Norm  <img src="https://s0.wp.com/latex.php?latex=%5Clangle%5CVert%5Cmathbf%7BW%7D%5CVert%5E%7B2%7D_%7B%5Cinfty%7D%5Crangle&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clangle%5CVert%5Cmathbf%7BW%7D%5CVert%5E%7B2%7D_%7B%5Cinfty%7D%5Crangle&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clangle%5CVert%5Cmathbf%7BW%7D%5CVert%5E%7B2%7D_%7B%5Cinfty%7D%5Crangle&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;langle&#92;Vert&#92;mathbf{W}&#92;Vert^{2}_{&#92;infty}&#92;rangle" class="latex" /> as a metric for predicting DNN test accuracies.</p>



<p>While theory suggests that  <img src="https://s0.wp.com/latex.php?latex=%5Clangle%5Clog_%7B10%7D%5CVert%5Cmathbf%7BW%7D%5CVert%5E%7B2%7D_%7B%5Cinfty%7D%5Crangle&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clangle%5Clog_%7B10%7D%5CVert%5Cmathbf%7BW%7D%5CVert%5E%7B2%7D_%7B%5Cinfty%7D%5Crangle&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clangle%5Clog_%7B10%7D%5CVert%5Cmathbf%7BW%7D%5CVert%5E%7B2%7D_%7B%5Cinfty%7D%5Crangle&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;langle&#92;log_{10}&#92;Vert&#92;mathbf{W}&#92;Vert^{2}_{&#92;infty}&#92;rangle" class="latex" /> might be able to predict the generalization performance of different pre-trained DNNs, in practice, it is correlated with test error for models with different depths, and anti-correlated for models trained with different hyperparameters.  This is a classic example of Simpson&#8217;s Paradox.</p>



<p>We show that we can fix-up the average <code>log_spectral_norm</code>  (as provided in WeightWatcher) by using a weighted average, weighted by the  WeightWatcher power-law layer alpha <img src="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha" class="latex" /> metric.  And this is exactly the WeightWatcher metric  <code>alpha_weighted</code>:</p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=%5Chat%7B%5Calpha%7D%3A%3D%5Cdfrac%7B1%7D%7BN_L%7D%5Csum_%7Bl%7D%5E%7BN_L%7D%5Calpha_%7Bl%7D%5Clog_%7B10%7D%5Clambda%5E%7Bmax%7D_%7Bl%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Chat%7B%5Calpha%7D%3A%3D%5Cdfrac%7B1%7D%7BN_L%7D%5Csum_%7Bl%7D%5E%7BN_L%7D%5Calpha_%7Bl%7D%5Clog_%7B10%7D%5Clambda%5E%7Bmax%7D_%7Bl%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Chat%7B%5Calpha%7D%3A%3D%5Cdfrac%7B1%7D%7BN_L%7D%5Csum_%7Bl%7D%5E%7BN_L%7D%5Calpha_%7Bl%7D%5Clog_%7B10%7D%5Clambda%5E%7Bmax%7D_%7Bl%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;hat{&#92;alpha}:=&#92;dfrac{1}{N_L}&#92;sum_{l}^{N_L}&#92;alpha_{l}&#92;log_{10}&#92;lambda^{max}_{l}" class="latex" /></p>



<p>Try it yourself on your own DNN models.</p>



<p class="has-text-align-center"><code>pip install weightwatcher </code></p>



<p>And let me know how it goes.</p>



<h4><strong>Appendix</strong></h4>



<p><strong>Spectral Density of 2D Convolutional Layers</strong></p>



<p>We can test this theory numerically using WeightWatcher.  Notice, however, that while it is obvious how to define <img src="https://s0.wp.com/latex.php?latex=%5Clambda%5E%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clambda%5E%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda%5E%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lambda^{max}" class="latex" /> for Dense matrix, there is some ambiguity doing this for a 2DConvolution and to make this work as a useful metric.  </p>



<p>WeightWatcher has 2 methods for computing the SVD  of a Conv2D layer, depending on the version.  For a <img src="https://s0.wp.com/latex.php?latex=k%5Ctimes+k%5Ctimes+N%5Ctimes+M+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k%5Ctimes+k%5Ctimes+N%5Ctimes+M+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k%5Ctimes+k%5Ctimes+N%5Ctimes+M+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k&#92;times k&#92;times N&#92;times M " class="latex" /> Conv2D layer, the options are</p>



<ul><li><strong>new version ww.0.4:</strong>  extract <img src="https://s0.wp.com/latex.php?latex=k%5Ctimes+k&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k%5Ctimes+k&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k%5Ctimes+k&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k&#92;times k" class="latex" /> matrix slices of dimension <img src="https://s0.wp.com/latex.php?latex=N%5Ctimes+M&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=N%5Ctimes+M&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=N%5Ctimes+M&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="N&#92;times M" class="latex" />,  and combine these to define the final <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D%5E%7BConv2D%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D%5E%7BConv2D%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D%5E%7BConv2D%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{W}^{Conv2D}" class="latex" /> matrix, and run SVD on this.  This gives 1 ESD per Conv2D layer.</li><li><strong>old version ww2x</strong>: extract <img src="https://s0.wp.com/latex.php?latex=k%5Ctimes+k&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k%5Ctimes+k&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k%5Ctimes+k&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k&#92;times k" class="latex" /> matricies <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D%5E%7BConv2D%7D_%7Bi%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D%5E%7BConv2D%7D_%7Bi%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D%5E%7BConv2D%7D_%7Bi%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{W}^{Conv2D}_{i}" class="latex" /> of dimension <img src="https://s0.wp.com/latex.php?latex=N%5Ctimes+M&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=N%5Ctimes+M&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=N%5Ctimes+M&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="N&#92;times M" class="latex" /> each, and run SVD on each <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D%5E%7BConv2D%7D_%7Bi%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D%5E%7BConv2D%7D_%7Bi%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D%5E%7BConv2D%7D_%7Bi%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{W}^{Conv2D}_{i}" class="latex" />.  This gives <img src="https://s0.wp.com/latex.php?latex=k%5Ctimes+k&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k%5Ctimes+k&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k%5Ctimes+k&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k&#92;times k" class="latex" />  ESDs per Conv2D layer, and the layer metrics are then averaged over all of these slices.   </li><li><strong>future version (maybe)</strong>:  Run SVD on the linear operator that defines the Conv2D transform.  This requires running SVD on the discrete FFT on each of the Conv2D  input-output channels, and then combining the resulting eigenvalues into 1 very large ESD.  This is quite slow and the numerical results were not as good in early experiments.</li></ul>



<p>All three methods give slightly different layer Spectral Norms,  with ww0.4 being the best estimator so far.  The<code> ww2x=True </code>option is included for back compatibility with earlier papers.</p>



<p></p>



<p><br></p>
]]></content:encoded>
					
					<wfw:commentRss>https://calculatedcontent.com/2020/11/26/simpsons-paradox-and-deep-learning-metrics-with-weightwatcher/feed/</wfw:commentRss>
			<slash:comments>1</slash:comments>
		
		
		
		<media:thumbnail url="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-21-at-9.21.04-am.png" />
		<media:content url="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-21-at-9.21.04-am.png" medium="image">
			<media:title type="html">screen-shot-2020-11-21-at-9.21.04-am</media:title>
		</media:content>

		<media:content url="https://1.gravatar.com/avatar/1ae78e5099a40f308b172a5a65416cab?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">charlesmartin14</media:title>
		</media:content>

		<media:content url="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-25-at-8.28.33-pm.png?w=906" medium="image" />

		<media:content url="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-25-at-10.40.43-pm.png?w=1024" medium="image" />

		<media:content url="https://discuss.pytorch.org/uploads/default/optimized/2X/d/d648f9e9c6547465033aeefbcaa751da5c461f22_2_690x310.png" medium="image">
			<media:title type="html">image</media:title>
		</media:content>

		<media:content url="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-26-at-10.21.43-pm.png?w=782" medium="image" />

		<media:content url="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-26-at-9.02.20-pm.png?w=1024" medium="image" />

		<media:content url="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-21-at-9.21.04-am.png?w=1024" medium="image" />

		<media:content url="https://upload.wikimedia.org/wikipedia/commons/thumb/f/fb/Simpsons_paradox_-_animation.gif/220px-Simpsons_paradox_-_animation.gif" medium="image" />

		<media:content url="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-21-at-11.26.32-am.png?w=1024" medium="image" />

		<media:content url="https://charlesmartin14.files.wordpress.com/2020/11/screen-shot-2020-11-26-at-10.28.21-pm.png?w=1024" medium="image" />
	</item>
		<item>
		<title>Why WeightWatcher Works</title>
		<link>https://calculatedcontent.com/2020/09/14/why-weightwatcher-works/</link>
					<comments>https://calculatedcontent.com/2020/09/14/why-weightwatcher-works/#respond</comments>
		
		<dc:creator><![CDATA[Charles H Martin, PhD]]></dc:creator>
		<pubDate>Tue, 15 Sep 2020 04:10:22 +0000</pubDate>
				<category><![CDATA[Uncategorized]]></category>
		<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[machine learning]]></category>
		<guid isPermaLink="false">http://calculatedcontent.com/?p=13605</guid>

					<description><![CDATA[I am frequently asked, why does weightwatcher work ? The weightwatcher tool uses power law fits to model the eigenvalue &#8230; <a class="more-link" href="https://calculatedcontent.com/2020/09/14/why-weightwatcher-works/">More</a>]]></description>
										<content:encoded><![CDATA[
<p>I am frequently asked, why does <a href="http://github.com/CalculatedContent/WeightWatcher">weightwatcher</a> work ?</p>



<p>The weightwatcher tool uses power law fits to model the eigenvalue density <img src="https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;rho(&#92;lambda)" class="latex" /> of weight matrices of any Deep Neural Network (DNN).  </p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29%5Csim+%5Clambda%5E%7B-%5Calpha%7D%2C%5C%3B%5C%3B%5C%3B%5Clambda%5Cin%5B%5Clambda_%7Bmin%7D%2C%5Clambda_%7Bmax%7D%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29%5Csim+%5Clambda%5E%7B-%5Calpha%7D%2C%5C%3B%5C%3B%5C%3B%5Clambda%5Cin%5B%5Clambda_%7Bmin%7D%2C%5Clambda_%7Bmax%7D%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29%5Csim+%5Clambda%5E%7B-%5Calpha%7D%2C%5C%3B%5C%3B%5C%3B%5Clambda%5Cin%5B%5Clambda_%7Bmin%7D%2C%5Clambda_%7Bmax%7D%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;rho(&#92;lambda)&#92;sim &#92;lambda^{-&#92;alpha},&#92;;&#92;;&#92;;&#92;lambda&#92;in[&#92;lambda_{min},&#92;lambda_{max}]" class="latex" /></p>



<p>The average power-law exponent <img src="https://s0.wp.com/latex.php?latex=%5Clangle%5Calpha%5Crangle+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clangle%5Calpha%5Crangle+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clangle%5Calpha%5Crangle+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;langle&#92;alpha&#92;rangle " class="latex" /> is remarkably well correlated with the test accuracy when changing the number of layers and/or fine-tuning the hyperparameters.   <a href="https://arxiv.org/pdf/2002.06716.pdf">In our latest paper</a>, we demonstrate this using a metaanalysis on hundreds of pre-trained models.  This begs the question:</p>



<p class="has-text-align-center"><strong>Why can we model the weight matrices of DNNs using power law fits ?</strong></p>



<p>In theoretical chemistry and physics, we know that strongly correlated, complex systems frequently display power laws.  </p>



<p>In many machine learning and deep learning models, the correlations also display heavy / power law tails. After all, the whole point of learning is to learn the correlations in the data. Be it a simple clustering algorithm, or a very fancy Deep Neural Network, we want to find the most strongly correlated parts to describe our data and make predictions.</p>



<p>For example, in strongly correlated systems, if you place an electron in a random potential, it will show a transition from delocalized to localized states, and the spectral density will display power law tails.  This is called Anderson Localization, and Anderson won the Nobel Prize in Physics for this in 1977.    In the early 90s, <a href="https://journals.aps.org/pre/abstract/10.1103/PhysRevE.50.1810">Cizeau and Bouchaud </a>argued that a Wigner-Levy matrix will show a  similar localization transition, and since then have modeled the correlation matrices in finance using their variant of heavy tailed random matrix theory (RMT).   Even today this is still an area of active research <a href="https://www.youtube.com/watch?v=1h-SAngNYIA">in mathematics </a>and<a href="https://www.amazon.com/First-Course-Random-Matrix-Theory/dp/1108488080"> in finance</a>.</p>



<p>In my earlier days as a scientist, I worked on strongly correlated multi-reference <em>ab initio</em> methods for quantum chemistry. Here, the trick is to find the right correlated subspace to get a good low order description. I believe, in machine learning, the same issues arise.   For this reason, I also model the correlation matrices in Deep Neural Networks <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D%3D%5Cmathbf%7BW%7D%5E%7BT%7D%5Cmathbf%7BW%7D&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D%3D%5Cmathbf%7BW%7D%5E%7BT%7D%5Cmathbf%7BW%7D&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D%3D%5Cmathbf%7BW%7D%5E%7BT%7D%5Cmathbf%7BW%7D&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{X}=&#92;mathbf{W}^{T}&#92;mathbf{W}" class="latex" /> using heavy tailed RMT. </p>



<p>Here I will show that the simplest machine learning model, Latent Semantic Analysis (LSA), shows a localization transition, and that this can be used to identify and characterize the heavy tail of the LSA correlation matrix.</p>



<h5>Latent Semantic Analysis: a simple example of power law correlations</h5>



<p>Take Latent Semantic Analysis (LSA). How do we select the Latent Space?  We need to select the top-K components of the TF-IDF Term-Document matrix <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BM%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BM%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BM%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{M}" class="latex" />. I believe this can be done by selecting those K eigenvalues that best fit a power law.  Here is an example, using the scikit-learn 20newsgroups data:</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img loading="lazy" data-attachment-id="13817" data-permalink="https://calculatedcontent.com/screen-shot-2020-09-12-at-9-23-41-pm/" data-orig-file="https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-12-at-9.23.41-pm.png" data-orig-size="1104,746" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2020-09-12-at-9.23.41-pm" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-12-at-9.23.41-pm.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-12-at-9.23.41-pm.png?w=1024" src="https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-12-at-9.23.41-pm.png?w=1024" alt="" class="wp-image-13817" width="491" height="332" srcset="https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-12-at-9.23.41-pm.png?w=491 491w, https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-12-at-9.23.41-pm.png?w=982 982w, https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-12-at-9.23.41-pm.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-12-at-9.23.41-pm.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-12-at-9.23.41-pm.png?w=768 768w" sizes="(max-width: 491px) 100vw, 491px" /></figure></div>



<p>We call ths plot the Empirical Spectral Density (ESD). This is just a histogram plot, on a log scale,  of the eigenvalues  <img src="https://s0.wp.com/latex.php?latex=%5Clog_%7B10%7D%5C%3B+%5Clambda+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clog_%7B10%7D%5C%3B+%5Clambda+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clog_%7B10%7D%5C%3B+%5Clambda+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;log_{10}&#92;; &#92;lambda " class="latex" /> of the TF-IDF correlation matrix <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{X}" class="latex" />.   The correlation matrix is the square of the TF-IDF matrix</p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D%3D%5Cmathbf%7BM%5E%7BT%7D%7D%5Cmathbf%7BM%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D%3D%5Cmathbf%7BM%5E%7BT%7D%7D%5Cmathbf%7BM%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D%3D%5Cmathbf%7BM%5E%7BT%7D%7D%5Cmathbf%7BM%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{X}=&#92;mathbf{M^{T}}&#92;mathbf{M}" class="latex" /></p>



<p> and the eigenvalues of <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{X}" class="latex" /> are the singular values of <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BM%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BM%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BM%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{M}" class="latex" />, squared: <img src="https://s0.wp.com/latex.php?latex=%5Clambda_%7Bi%7D%3D%5Csigma_%7Bi%7D%5E%7B2%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clambda_%7Bi%7D%3D%5Csigma_%7Bi%7D%5E%7B2%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda_%7Bi%7D%3D%5Csigma_%7Bi%7D%5E%7B2%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lambda_{i}=&#92;sigma_{i}^{2}" class="latex" />.</p>



<p>We fit the eigenvalues to a power law (PL) using <a href="https://github.com/jeffalstott/powerlaw">the python powerlaw package</a>, which implements a standard MLE estimator. </p>


<pre class="brush: python; collapse: false; title: ; wrap-lines: false; notranslate">
fit = powerlaw.fit(eigenvalues)
</pre>



<p> The fit selects the optimal <code>xmin=</code><img src="https://s0.wp.com/latex.php?latex=%5Clambda_%7Bmin%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clambda_%7Bmin%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda_%7Bmin%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lambda_{min} " class="latex" /> using a brute force search, and returns the best PL exponent <img src="https://s0.wp.com/latex.php?latex=%5Calpha+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha " class="latex" />, and the quality of the fit  <img src="https://s0.wp.com/latex.php?latex=D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="D " class="latex" /> (<a href="https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test">the KS-distance</a>).  The <span style="color:#f58b28;" class="has-inline-color">orange line</span> displays the start of the power law tail, which contains the most strongly correlated eigenpairs.</p>



<p>We can evaluate the quality of the PL fit by comparing the ESD and the actual fit on log-log plot.  </p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img loading="lazy" data-attachment-id="13851" data-permalink="https://calculatedcontent.com/screen-shot-2020-09-14-at-6-09-46-pm/" data-orig-file="https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-6.09.46-pm.png" data-orig-size="838,586" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2020-09-14-at-6.09.46-pm" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-6.09.46-pm.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-6.09.46-pm.png?w=838" src="https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-6.09.46-pm.png?w=838" alt="" class="wp-image-13851" width="495" height="345" srcset="https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-6.09.46-pm.png?w=493 493w, https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-6.09.46-pm.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-6.09.46-pm.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-6.09.46-pm.png?w=768 768w, https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-6.09.46-pm.png 838w" sizes="(max-width: 495px) 100vw, 495px" /><figcaption><strong>Comparison of empirical and fit PDF (blue) and CDF (red)</strong></figcaption></figure></div>



<p>The<span class="has-inline-color has-accent-color"> </span><strong><span style="color:#0a7ba5;" class="has-inline-color">blue solid line</span> </strong>is the ESD on a log-log scale (or the PDF), and the<span class="has-inline-color has-accent-color"> blue dotted line</span> is the PL fit.  (The <strong><span class="has-inline-color has-secondary-color">red solid line</span></strong> is the empirical CDF, and the <span class="has-inline-color has-secondary-color">red dotted line</span> the fit).  The <span class="has-inline-color has-accent-color">PDF (blue) </span>shows a very good linear fit up,  except perhaps for largest eigenvalues,  <img src="https://s0.wp.com/latex.php?latex=%5Clambda%5Clesssim%5Clambda_%7Bmax%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clambda%5Clesssim%5Clambda_%7Bmax%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda%5Clesssim%5Clambda_%7Bmax%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lambda&#92;lesssim&#92;lambda_{max} " class="latex" />.  Likewise, the <span class="has-inline-color has-secondary-color">CDF (red) </span>shows a very good fit, up until the end of the tail.   This is typical of power-law fits on real-world data and is usually best described as a Truncated Power Law (TPL), with some noise in the very far tail *(more on the noise in a future post).  And the reported KS-distance <img src="https://s0.wp.com/latex.php?latex=D%3D0.008&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=D%3D0.008&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=D%3D0.008&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="D=0.008" class="latex" />, which is exceptional. </p>



<p>We can get even more insight into the quality of the fit by examining how the PL method selected <code>xmin</code><img src="https://s0.wp.com/latex.php?latex=%3D%5Clambda_%7Bmin%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%3D%5Clambda_%7Bmin%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%3D%5Clambda_%7Bmin%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="=&#92;lambda_{min}" class="latex" />, the start of the PL.  Below, we plot the KS-distance for each possible choice of <code>xmin</code>:</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img loading="lazy" data-attachment-id="13856" data-permalink="https://calculatedcontent.com/screen-shot-2020-09-14-at-7-09-18-pm/" data-orig-file="https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-7.09.18-pm.png" data-orig-size="850,568" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2020-09-14-at-7.09.18-pm" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-7.09.18-pm.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-7.09.18-pm.png?w=850" src="https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-7.09.18-pm.png?w=850" alt="" class="wp-image-13856" width="517" height="345" srcset="https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-7.09.18-pm.png?w=517 517w, https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-7.09.18-pm.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-7.09.18-pm.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-7.09.18-pm.png?w=768 768w, https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-7.09.18-pm.png 850w" sizes="(max-width: 517px) 100vw, 517px" /></figure></div>



<p>The optimization landscape is convex, with a clear global minimum at the <span style="color:#fa9805;" class="has-inline-color">orange line</span>, which occurs at the <img src="https://s0.wp.com/latex.php?latex=%5Clambda_%7B547%7D%3D%5Clambda%7Bmin%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clambda_%7B547%7D%3D%5Clambda%7Bmin%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda_%7B547%7D%3D%5Clambda%7Bmin%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lambda_{547}=&#92;lambda{min}" class="latex" />.  That is, there are 547 eigenpairs in the tail of the ESD displaying strong power-law behavior.</p>



<p class="has-text-align-center"><em>To form the Latent space, we select these largest 547 eigenpairs, to the right of the <span style="color:#f88725;" class="has-inline-color">orange line</span>, the start of the (truncated) power-law fit</em></p>



<h4>The Localization Transition</h4>



<p>To identify the localization transition in LSA, we can plot localization ratios <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BL%7D%28%5Cmathbf%7Bv%7D%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BL%7D%28%5Cmathbf%7Bv%7D%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathcal%7BL%7D%28%5Cmathbf%7Bv%7D%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathcal{L}(&#92;mathbf{v})" class="latex" /> in the same way, where the localization is defined as in <a href="https://arxiv.org/pdf/1810.01075.pdf">our first paper</a>:</p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BL%7D%28%5Cmathbf%7Bv%7D%29%3D%5Cdfrac%7B%5CVert%5Cmathbf%7Bv%7D%7C%5CVert_%7B1%7D%7D%7B%5CVert%5Cmathbf%7Bv%7D%7C%5CVert_%7B%5Cinfty%7D%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BL%7D%28%5Cmathbf%7Bv%7D%29%3D%5Cdfrac%7B%5CVert%5Cmathbf%7Bv%7D%7C%5CVert_%7B1%7D%7D%7B%5CVert%5Cmathbf%7Bv%7D%7C%5CVert_%7B%5Cinfty%7D%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathcal%7BL%7D%28%5Cmathbf%7Bv%7D%29%3D%5Cdfrac%7B%5CVert%5Cmathbf%7Bv%7D%7C%5CVert_%7B1%7D%7D%7B%5CVert%5Cmathbf%7Bv%7D%7C%5CVert_%7B%5Cinfty%7D%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathcal{L}(&#92;mathbf{v})=&#92;dfrac{&#92;Vert&#92;mathbf{v}|&#92;Vert_{1}}{&#92;Vert&#92;mathbf{v}|&#92;Vert_{&#92;infty}}" class="latex" /></p>


<pre class="brush: python; collapse: false; title: ; wrap-lines: false; notranslate">
def localization_ratio(v):
    return np.linalg.norm(v, ord=1) / np.linalg.norm(v, ord=np.inf)
</pre>



<p>We see that get an elbow curve, and the eigenvalue cutoff appears just to the right of the &#8216;elbow&#8217;:</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img loading="lazy" data-attachment-id="13864" data-permalink="https://calculatedcontent.com/screen-shot-2020-09-14-at-7-49-48-pm/" data-orig-file="https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-7.49.48-pm.png" data-orig-size="796,574" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2020-09-14-at-7.49.48-pm" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-7.49.48-pm.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-7.49.48-pm.png?w=796" src="https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-7.49.48-pm.png?w=796" alt="" class="wp-image-13864" width="501" height="361" srcset="https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-7.49.48-pm.png?w=501 501w, https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-7.49.48-pm.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-7.49.48-pm.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-7.49.48-pm.png?w=768 768w, https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-7.49.48-pm.png 796w" sizes="(max-width: 501px) 100vw, 501px" /></figure></div>



<p>Other methods include looking scree plots or even just the sorted eigenvalues themselves.  </p>



<h5>Comparison with other K-selection methods</h5>



<p>Typically, in unsupervised learning, one selects the top-K clusters, eigenpairs, etc. by looking at some so-called &#8216;elbow curve&#8217;, and identifying the K at the inflection point. We can make these plots too.  A classic way is to plot the explained variance per eigenpair:</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img loading="lazy" data-attachment-id="13822" data-permalink="https://calculatedcontent.com/screen-shot-2020-09-12-at-11-39-31-pm/" data-orig-file="https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-12-at-11.39.31-pm.png" data-orig-size="1112,712" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2020-09-12-at-11.39.31-pm" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-12-at-11.39.31-pm.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-12-at-11.39.31-pm.png?w=1024" src="https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-12-at-11.39.31-pm.png?w=1024" alt="" class="wp-image-13822" width="542" height="347" srcset="https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-12-at-11.39.31-pm.png?w=1024 1024w, https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-12-at-11.39.31-pm.png?w=542 542w, https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-12-at-11.39.31-pm.png?w=1084 1084w, https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-12-at-11.39.31-pm.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-12-at-11.39.31-pm.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-12-at-11.39.31-pm.png?w=768 768w" sizes="(max-width: 542px) 100vw, 542px" /></figure></div>



<p>We see that the power-law <img src="https://s0.wp.com/latex.php?latex=%5Clambda_%7Bmin%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clambda_%7Bmin%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda_%7Bmin%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lambda_{min}" class="latex" />,<span style="color:#f47210;" class="has-inline-color"> the orange line</span>, occurs just to the right of the inflection point.  So these two methods give similar results.  No other method provides a theoretically well-defined way, however, of selecting the K components.</p>



<h5>Conclusion</h5>



<p>I suspect that in these strongly correlated systems, the power law behavior really kicks it right at / before these inflection points.   So we can find the optimal low-rank approximation to these strongly correlated weight matrices by finding that subspace where the correlations follow a power-law / truncated power law distribution.  Moreover, we can detect, and characterize these correlations, by both the power-law exponent <img src="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha" class="latex" />, and the quality of the fit D.  </p>



<p class="has-text-align-center"><em>And AFAIK, this has never been suggested before. </em></p>
]]></content:encoded>
					
					<wfw:commentRss>https://calculatedcontent.com/2020/09/14/why-weightwatcher-works/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		
		<media:thumbnail url="https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-12-at-9.23.41-pm.png" />
		<media:content url="https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-12-at-9.23.41-pm.png" medium="image">
			<media:title type="html">screen-shot-2020-09-12-at-9.23.41-pm</media:title>
		</media:content>

		<media:content url="https://1.gravatar.com/avatar/1ae78e5099a40f308b172a5a65416cab?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">charlesmartin14</media:title>
		</media:content>

		<media:content url="https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-12-at-9.23.41-pm.png?w=1024" medium="image" />

		<media:content url="https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-6.09.46-pm.png?w=838" medium="image" />

		<media:content url="https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-7.09.18-pm.png?w=850" medium="image" />

		<media:content url="https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-14-at-7.49.48-pm.png?w=796" medium="image" />

		<media:content url="https://charlesmartin14.files.wordpress.com/2020/09/screen-shot-2020-09-12-at-11.39.31-pm.png?w=1024" medium="image" />
	</item>
		<item>
		<title>WeightWatcher:  Empirical Quality Metrics for Deep Neural Networks</title>
		<link>https://calculatedcontent.com/2020/02/16/weightwatcher-empirical-quality-metrics-for-deep-neural-networks/</link>
					<comments>https://calculatedcontent.com/2020/02/16/weightwatcher-empirical-quality-metrics-for-deep-neural-networks/#respond</comments>
		
		<dc:creator><![CDATA[Charles H Martin, PhD]]></dc:creator>
		<pubDate>Mon, 17 Feb 2020 00:58:14 +0000</pubDate>
				<category><![CDATA[Uncategorized]]></category>
		<category><![CDATA[AI]]></category>
		<category><![CDATA[DATA SCIENCE]]></category>
		<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[KERAS]]></category>
		<category><![CDATA[machine learning]]></category>
		<category><![CDATA[NLP]]></category>
		<category><![CDATA[PYTORCH]]></category>
		<category><![CDATA[TENSORFLOW]]></category>
		<guid isPermaLink="false">http://calculatedcontent.com/?p=13287</guid>

					<description><![CDATA[We introduce the weightwatcher (ww) , a python tool for a python tool for computing quality metrics of trained, and &#8230; <a class="more-link" href="https://calculatedcontent.com/2020/02/16/weightwatcher-empirical-quality-metrics-for-deep-neural-networks/">More</a>]]></description>
										<content:encoded><![CDATA[
<p></p>



<p>We introduce the <a href="https://github.com/CalculatedContent/WeightWatcher">weightwatcher</a> (ww) , a python tool for a python tool for computing quality metrics of trained, and pretrained, Deep Neural Netwworks.</p>



<p class="has-text-align-center">pip install weightwatcher</p>



<p>This blog describes how to use the tool in practice; <a href="https://arxiv.org/pdf/2002.06716.pdf">see our most recent paper for even more details.</a>  </p>



<p>Here is an example with pretrained VGG11 from pytorch (ww works with keras models also):</p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: python; title: ; notranslate">
&lt;code&gt;import weightwatcher as ww
import torchvision.models as models

model = models.vgg11(pretrained=True)
watcher = ww.WeightWatcher(model=model)
results = watcher.analyze()

summary = watcher.get_summary()
details = watcher.get_details()&lt;/code&gt;
</pre></div>


<p>WeightWatcher generates a dict that summarizes the empirical quality metrics for the model (with the most useful metrics)</p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: python; title: ; notranslate">
&lt;strong&gt;summary:&lt;/strong&gt; = { ...
  alpha: 2.572493
  alpha_weighted: 3.418571
  lognorm: 1.252417   
  logspectralnorm: 1.377540 
  logpnorm: 3.878202
... }&lt;strong&gt;
&lt;/strong&gt;
</pre></div>


<p>The tool also generates a <strong>details</strong> pandas dataframe, with a layer-by-layer analysis (shown below)</p>



<p>The summary contains the Power Law exponent (<img src="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha" class="latex" />), as well as several log norm metrics, as explained in our papers, and below.  Each value represents an empirical quality metric that can be used to gauge the gross effectiveness of the model, as compared to similar models. </p>



<p>(<a href="https://github.com/CalculatedContent/WeightWatcher/blob/master/WeightWatcher.ipynb">The main weightwatcher notebook</a> demonstrates more features )</p>



<p>For example, <strong>lognorm</strong> is the average over all layers L of the log of the Frobenius norm of each layer weight matrix <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{W}" class="latex" /> :</p>



<p class="has-text-align-left"><strong>lognorm</strong>: average log Frobenius Norm := <img src="https://s0.wp.com/latex.php?latex=%5Cdfrac%7B1%7D%7BL%7D%5Csum_%7Bl%7D%5Clog%5CVert%5Cmathbf%7BW_%7Bl%7D%7D%5CVert_%7BF%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdfrac%7B1%7D%7BL%7D%5Csum_%7Bl%7D%5Clog%5CVert%5Cmathbf%7BW_%7Bl%7D%7D%5CVert_%7BF%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdfrac%7B1%7D%7BL%7D%5Csum_%7Bl%7D%5Clog%5CVert%5Cmathbf%7BW_%7Bl%7D%7D%5CVert_%7BF%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;dfrac{1}{L}&#92;sum_{l}&#92;log&#92;Vert&#92;mathbf{W_{l}}&#92;Vert_{F} " class="latex" /></p>



<p>Where the individual layer Frobenius norm, for say a Fully Connected (FC layer,  may be computed as</p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=%5C%5Clog%5CVert%5Cmathbf%7BW%7D%5CVert_%7BF%7D%3D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5C%5Clog%5CVert%5Cmathbf%7BW%7D%5CVert_%7BF%7D%3D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5C%5Clog%5CVert%5Cmathbf%7BW%7D%5CVert_%7BF%7D%3D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;&#92;log&#92;Vert&#92;mathbf{W}&#92;Vert_{F}=" class="latex" /><code>np.log10(np.linalg.norm(W))</code></p>



<h3>Comparing Metrics Across Models:</h3>



<p>We can use these metrics to compare models across a common architecture series, such as the VGG series, the ResNet series, etc.  These can be applied to trained models, pretrained models, and/or even fine-tuned models.</p>



<p>Consider the series of models VGG11, VGG11_BN, &#8230; VGG19, VGG_19, available in pytorch. We can plot the reported the various log norm metrics <img src="https://s0.wp.com/latex.php?latex=%5Clangle%5CVert%5Ccdot%5CVert%5Crangle&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clangle%5CVert%5Ccdot%5CVert%5Crangle&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clangle%5CVert%5Ccdot%5CVert%5Crangle&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;langle&#92;Vert&#92;cdot&#92;Vert&#92;rangle" class="latex" /> vs the reported test accuracies.  </p>



<figure class="wp-block-image size-large"><img data-attachment-id="13647" data-permalink="https://calculatedcontent.com/2020/02/16/weightwatcher-empirical-quality-metrics-for-deep-neural-networks/screen-shot-2020-02-14-at-10-06-20-pm/" data-orig-file="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-14-at-10.06.20-pm.png" data-orig-size="1604,1664" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen Shot 2020-02-14 at 10.06.20 PM" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-14-at-10.06.20-pm.png?w=289" data-large-file="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-14-at-10.06.20-pm.png?w=987" src="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-14-at-10.06.20-pm.png?w=987" alt="" class="wp-image-13647" srcset="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-14-at-10.06.20-pm.png?w=987 987w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-14-at-10.06.20-pm.png?w=145 145w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-14-at-10.06.20-pm.png?w=289 289w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-14-at-10.06.20-pm.png?w=768 768w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-14-at-10.06.20-pm.png 1604w" sizes="(max-width: 987px) 100vw, 987px" /></figure>



<p>For a series of similar, well-trained models, all of the empirical log norm metrics correlate well with the reported test accuracies! Moreover, the Weighted Alpha and Log <img src="https://s0.wp.com/latex.php?latex=%5Calpha-&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha-&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha-&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha-" class="latex" />Norm metrics work best. </p>



<p><em><strong>Smaller is better</strong></em>.</p>



<p>We also run a ordinary linear regression (OLS) and the root mean squared error (RMSE) , and for several other CV models that are available in the pytorch <a href="https://pytorch.org/docs/stable/torchvision/models.html">torchvision.models package.</a></p>


<div class="wp-block-image">
<figure class="aligncenter size-large is-resized"><img loading="lazy" data-attachment-id="13679" data-permalink="https://calculatedcontent.com/2020/02/16/weightwatcher-empirical-quality-metrics-for-deep-neural-networks/screen-shot-2020-02-15-at-10-32-36-am/" data-orig-file="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-15-at-10.32.36-am.png" data-orig-size="942,416" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen Shot 2020-02-15 at 10.32.36 AM" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-15-at-10.32.36-am.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-15-at-10.32.36-am.png?w=942" src="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-15-at-10.32.36-am.png?w=840" alt="" class="wp-image-13679" width="464" height="205" srcset="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-15-at-10.32.36-am.png?w=464 464w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-15-at-10.32.36-am.png?w=928 928w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-15-at-10.32.36-am.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-15-at-10.32.36-am.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-15-at-10.32.36-am.png?w=768 768w" sizes="(max-width: 464px) 100vw, 464px" /></figure></div>


<p>We have tested this on over <a href="https://github.com/osmr/imgclsmob">100 well trained computer vision (CV) pre-trained models on multiple data sets</a> (such as the ImageNet-1K subset of ImageNet).  These trends how for nearly every case of well-trained models.</p>



<p>Notice that the RMSE for ResNet, trained on ImageNet1K, is larger than for ResNet trained on the full ImageNet, even though ResNet-1K has more models in the regression. that (19 vs  5).   For the exact same model, the larger and better data set shows a better OLS fit!  </p>



<h4>How can you use this ?  </h4>



<p>We have several ideas where we hope this would be useful.  These include:</p>



<ul>
<li>comparing different models trained using Auto-ML (in addition to standard cross-validation)</li>



<li>judging the quality of NLP models for generating fake text (in addition to, say, the perplexity)</li>



<li>evaluating different unsupervised clustering models, to determine which (presumably) gives the best clusters</li>



<li>deciding if you have enough data, or need to add more, for your specific model or series of models.</li>
</ul>



<h3>Detailed quality metrics: layer-by-layer</h3>



<p>We can learn even more about a model by looking at the empirical metrics, layer by layer.  The <strong>results</strong> is a dataframe that contains empirical quality metrics for each layer of the model.   An example output, for VGG11, is:</p>



<figure class="wp-block-image size-large"><img data-attachment-id="13633" data-permalink="https://calculatedcontent.com/2020/02/16/weightwatcher-empirical-quality-metrics-for-deep-neural-networks/screen-shot-2020-02-14-at-9-50-36-pm/" data-orig-file="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-14-at-9.50.36-pm.png" data-orig-size="1534,536" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen Shot 2020-02-14 at 9.50.36 PM" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-14-at-9.50.36-pm.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-14-at-9.50.36-pm.png?w=1024" src="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-14-at-9.50.36-pm.png?w=1024" alt="" class="wp-image-13633" srcset="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-14-at-9.50.36-pm.png?w=1024 1024w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-14-at-9.50.36-pm.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-14-at-9.50.36-pm.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-14-at-9.50.36-pm.png?w=768 768w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-14-at-9.50.36-pm.png 1534w" sizes="(max-width: 1024px) 100vw, 1024px" /></figure>



<p>The columns contain both metadata for each layer (id, type, shape, etc), and the values of the empirical quality metrics for that layer matrix.  </p>



<p>These metrics depend on the spectral properties&#8211;singular values <img src="https://s0.wp.com/latex.php?latex=%5Csigma&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Csigma&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Csigma&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;sigma" class="latex" /> of <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{W}" class="latex" /> , or, equivalently, the eigenvalues  <img src="https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lambda" class="latex" /> of the correlation matrix  of <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D%3D%5Cmathbf%7BW%7D%5E%7BT%7D%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D%3D%5Cmathbf%7BW%7D%5E%7BT%7D%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D%3D%5Cmathbf%7BW%7D%5E%7BT%7D%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{X}=&#92;mathbf{W}^{T}&#92;mathbf{W}" class="latex" />.</p>



<h4>The Power Law Exponent <img src="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha" class="latex" /></h4>



<p>WeightWatcher is unique in that it can measure the amount of correlation, or information, that a model contains&#8211;without peeking at the training or test data.  Data Correlation is measured by the Power Law (PL) exponents <img src="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha" class="latex" />.</p>



<p>WeightWatcher computes the eigenvalues (by SVD) for each layer weight matrix <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{W}" class="latex" />, and fits the eigenvalue density (i.e. histogram <img src="https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;rho(&#92;lambda))" class="latex" /> to a truncated Power Law (PL), with PL exponent  <img src="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha" class="latex" /></p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29%5Csim%5Clambda%5E%7B-%5Calpha%7D%2C%5C%3B%5C%3B%5Clambda%5Cle%5Clambda%5E%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29%5Csim%5Clambda%5E%7B-%5Calpha%7D%2C%5C%3B%5C%3B%5Clambda%5Cle%5Clambda%5E%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29%5Csim%5Clambda%5E%7B-%5Calpha%7D%2C%5C%3B%5C%3B%5Clambda%5Cle%5Clambda%5E%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;rho(&#92;lambda)&#92;sim&#92;lambda^{-&#92;alpha},&#92;;&#92;;&#92;lambda&#92;le&#92;lambda^{max}" class="latex" /> </p>



<p>In nearly every pretrained model we have examined, the Empirical Spectral Density can be fit to a truncated PL.    And the PL exponent usually is in the range <img src="https://s0.wp.com/latex.php?latex=%5Calpha%5Cin%5B2%2C5-6%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha%5Cin%5B2%2C5-6%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha%5Cin%5B2%2C5-6%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha&#92;in[2,5-6]" class="latex" />, where smaller is better.</p>



<p>Here is an example of the output of <code>weightwatcher</code> of the second Fully Connected layer (FC2) in VGG11.  These results can be reproduced using the WeightWatcher-VGG.ipynb notebook in the <a href="https://github.com/CalculatedContent/ww-trends-2020">ww-trends-2020 github repo</a>., using the options:</p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: python; title: ; notranslate">
results = watcher.analyze(alphas=True, plot=True)
</pre></div>


<p>The plot below shows the ESD (Empirical Spectral Density <img src="https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;rho(&#92;lambda)" class="latex" />,), of the weight matrix <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{W}" class="latex" />, in layer FC2.  Again, this is a (normalized) histogram of the eigenvalues <img src="https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lambda" class="latex" /> of the correlation matrix <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D%3D%5Cmathbf%7BW%7D%5E%7BT%7D%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D%3D%5Cmathbf%7BW%7D%5E%7BT%7D%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D%3D%5Cmathbf%7BW%7D%5E%7BT%7D%5Cmathbf%7BW%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{X}=&#92;mathbf{W}^{T}&#92;mathbf{W}" class="latex" />. </p>


<div class="wp-block-image">
<figure class="alignleft size-large is-resized"><img loading="lazy" data-attachment-id="13731" data-permalink="https://calculatedcontent.com/2020/02/16/weightwatcher-empirical-quality-metrics-for-deep-neural-networks/screen-shot-2020-02-16-at-11-06-38-am/" data-orig-file="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-11.06.38-am.png" data-orig-size="1406,1114" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen Shot 2020-02-16 at 11.06.38 AM" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-11.06.38-am.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-11.06.38-am.png?w=1024" src="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-11.06.38-am.png?w=840" alt="" class="wp-image-13731" width="340" height="269" srcset="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-11.06.38-am.png?w=340 340w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-11.06.38-am.png?w=680 680w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-11.06.38-am.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-11.06.38-am.png?w=300 300w" sizes="(max-width: 340px) 100vw, 340px" /></figure></div>


<p class="has-text-align-left">The FC2 matrix is square, 512&#215;512, and has an aspect ratio of Q=N/M=1 . The maximum eigenvalue is about 45, which is typical for many heavy tailed ESDs.  And there is a large peak at 0, which is normal for  Q=1.  Because Q= 1, the ESD might look  heavy tailed, but this can be deceiving because a random matrix with Q=1 would look similar.  Still, as with nearly all <em>well-trained</em> DNNS, we expect the FC2 ESD  <img src="https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;rho(&#92;lambda)" class="latex" /> to be well fit by a Power Law model, with an exponent  <img src="https://s0.wp.com/latex.php?latex=%5Calpha%5Cin%5B2%2C4%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha%5Cin%5B2%2C4%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha%5Cin%5B2%2C4%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha&#92;in[2,4]" class="latex" /> (i.e. <a href="https://arxiv.org/abs/1810.01075">in the Fat Tailed Universality class</a>), or at least,  for a model that is not &#8216;flawed&#8217; in some way, <img src="https://s0.wp.com/latex.php?latex=%5Calpha%5Cle+6&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha%5Cle+6&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha%5Cle+6&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha&#92;le 6" class="latex" />.</p>



<p class="has-text-align-center"><strong>alpha</strong> . PL exponent for <img src="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha" class="latex" /> for <strong>W</strong>: <img src="https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29%5Csim%5Clambda%5E%7B-%5Calpha%7D%2C%5C%3B%5C%3B%5Clambda%5Cle%5Clambda%5E%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29%5Csim%5Clambda%5E%7B-%5Calpha%7D%2C%5C%3B%5C%3B%5Clambda%5Cle%5Clambda%5E%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29%5Csim%5Clambda%5E%7B-%5Calpha%7D%2C%5C%3B%5C%3B%5Clambda%5Cle%5Clambda%5E%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;rho(&#92;lambda)&#92;sim&#92;lambda^{-&#92;alpha},&#92;;&#92;;&#92;lambda&#92;le&#92;lambda^{max}" class="latex" /></p>



<p>The smaller <strong>alpha</strong> <img src="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha" class="latex" /> is , for each layer, the more correlation that layer describes. Indeed, in the best performing models, all of the layer <strong>alphas</strong> approach 2 <img src="https://s0.wp.com/latex.php?latex=%28%5Calpha%5Crightarrow+2%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28%5Calpha%5Crightarrow+2%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28%5Calpha%5Crightarrow+2%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(&#92;alpha&#92;rightarrow 2)" class="latex" />.</p>



<p>To check that the ESD is really heavy tailed, we need to check the Power Law (PL) fit.  This is done by inspecting the weightwatcher plots.</p>


<div class="wp-block-image">
<figure class="alignright size-large is-resized"><img loading="lazy" data-attachment-id="13730" data-permalink="https://calculatedcontent.com/2020/02/16/weightwatcher-empirical-quality-metrics-for-deep-neural-networks/screen-shot-2020-02-16-at-11-06-44-am/" data-orig-file="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-11.06.44-am.png" data-orig-size="1454,1130" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen Shot 2020-02-16 at 11.06.44 AM" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-11.06.44-am.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-11.06.44-am.png?w=1024" src="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-11.06.44-am.png?w=840" alt="" class="wp-image-13730" width="376" height="292" srcset="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-11.06.44-am.png?w=376 376w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-11.06.44-am.png?w=752 752w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-11.06.44-am.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-11.06.44-am.png?w=300 300w" sizes="(max-width: 376px) 100vw, 376px" /></figure></div>


<p>The plot on the right shows the output of the <a href="https://arxiv.org/abs/1305.0215">powerlaw</a> package, which is used to do the PL fit of the ESD.  The PL exponent <img src="https://s0.wp.com/latex.php?latex=%5Calpha%3D3.41&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha%3D3.41&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha%3D3.41&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha=3.41" class="latex" />, which is a typical value for (moderately, i.e. Fat) Heavy Tailed ESDs.   Also, the KS distance is small <img src="https://s0.wp.com/latex.php?latex=%28%5Cle+0.1%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28%5Cle+0.1%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28%5Cle+0.1%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(&#92;le 0.1)" class="latex" />, which is good.  We can also see this visually.  The dots are the actual data, and the lines are the fits.  If the lines are reasonably straight, and match the dots, and in the range <img src="https://s0.wp.com/latex.php?latex=0%3C%5Clambda%5Cle%5Clambda%5E%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=0%3C%5Clambda%5Cle%5Clambda%5E%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0%3C%5Clambda%5Cle%5Clambda%5E%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="0&lt;&#92;lambda&#92;le&#92;lambda^{max}" class="latex" /> the fit is good.  <em>And they are.</em> This is a good PL fit.</p>



<p></p>



<h4>Good Model, Bad Data ?</h4>



<p>As shown above, with  ResNet vs ResNet-1K, the <code>weightwatcher</code> tool can help you decide if you have enough data, or your model/architecture would benefit from more data.  Indeed, poorly trained models, with very bad data sets, show strange behavior that you can detect using <code>weightwatcher</code></p>



<p>Here is an example of the infamous <strong>OpenAI GPT</strong> model, originally released as a poorly-trained model &#8211;so it would not be misused.  <a href="https://techcrunch.com/2019/02/17/openai-text-generator-dangerous/">It was too dangerous to release <img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f61b.png" alt="😛" class="wp-smiley" style="height: 1em; max-height: 1em;" /></a> We can compare this deficient GPT with the new and improved <strong>GPT2-small</strong> model, which has basically the same architecture, but has been trained as well as possible.  <a href="https://www.theverge.com/2019/11/7/20953040/openai-text-generation-ai-gpt-2-full-model-release-1-5b-parameters">Yes, they gave in an released it! </a>  (Both are in the popular <code>huggingface</code> package, and <code>weightwatcher</code> can read and analyze these models)  Below, we plot a histogram of the PL exponents <img src="https://s0.wp.com/latex.php?latex=%28%5Calpha%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28%5Calpha%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28%5Calpha%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(&#92;alpha)" class="latex" />, as well as histogram of the log Spectral Norms <img src="https://s0.wp.com/latex.php?latex=%28%5Clog%5CVert%5Cmathbf%7BW%7D%5CVert_%7Binfty%7D+%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28%5Clog%5CVert%5Cmathbf%7BW%7D%5CVert_%7Binfty%7D+%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28%5Clog%5CVert%5Cmathbf%7BW%7D%5CVert_%7Binfty%7D+%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(&#92;log&#92;Vert&#92;mathbf{W}&#92;Vert_{infty} )" class="latex" /> for each layer in GPT (blue) and GPT2 (red)</p>


<div class="wp-block-image">
<figure class="aligncenter size-large is-resized"><img loading="lazy" data-attachment-id="13683" data-permalink="https://calculatedcontent.com/2020/02/16/weightwatcher-empirical-quality-metrics-for-deep-neural-networks/screen-shot-2020-02-15-at-10-50-16-am/" data-orig-file="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-15-at-10.50.16-am.png" data-orig-size="1934,1140" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen Shot 2020-02-15 at 10.50.16 AM" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-15-at-10.50.16-am.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-15-at-10.50.16-am.png?w=1024" src="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-15-at-10.50.16-am.png?w=840" alt="" class="wp-image-13683" width="521" height="306" srcset="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-15-at-10.50.16-am.png?w=519 519w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-15-at-10.50.16-am.png?w=1038 1038w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-15-at-10.50.16-am.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-15-at-10.50.16-am.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-15-at-10.50.16-am.png?w=768 768w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-15-at-10.50.16-am.png?w=1024 1024w" sizes="(max-width: 521px) 100vw, 521px" /></figure></div>


<p>These results can be reproduced using the WeightWatcher-OpenAI-GPT.ipynb notebook in the <a href="https://github.com/CalculatedContent/ww-trends-2020">ww-trends-2020 github repo</a>.</p>



<p>Notice that the poorly-trained GPT model has many unusually high values of <strong>alpha</strong> <img src="https://s0.wp.com/latex.php?latex=%28%5Calpha%5Cgg+6%29+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28%5Calpha%5Cgg+6%29+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28%5Calpha%5Cgg+6%29+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(&#92;alpha&#92;gg 6) " class="latex" />. Many are be above 6, and even range upto 10 or 12 ! This is typical of poorly trained and/or overparameterized models.</p>



<p>Notice that the new and improved GPT2-small does not have the unusually high PL exponents any more, and, also, the peak of the histogram distribtion is farther to the left (smaller).<strong>  </strong></p>



<p class="has-text-align-center"><strong>Smaller <strong>alpha</strong> <img src="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha" class="latex" />  is always better.</strong></p>



<p>If you have a poorly trained model. and  you fix your model by adding more and better data, the <strong>alphas</strong> will generally settle down to below 6. Note: this can not be seen in a total average because the large values will throw the average off&#8211;to see this, make a histogram plot of <strong>alpha</strong></p>



<p>What about the log Spectral Norm <img src="https://s0.wp.com/latex.php?latex=%5Clog%5CVert%5Cmathbf%7BW%7D%5CVert_%7B%5Cinfty%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clog%5CVert%5Cmathbf%7BW%7D%5CVert_%7B%5Cinfty%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clog%5CVert%5Cmathbf%7BW%7D%5CVert_%7B%5Cinfty%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;log&#92;Vert&#92;mathbf{W}&#92;Vert_{&#92;infty}" class="latex" /> ?  It seems to show inconsistent behavior. Above, we saw that smaller <img src="https://s0.wp.com/latex.php?latex=%5Clog%5CVert%5Cmathbf%7BW%7D%5CVert_%7B%5Cinfty%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clog%5CVert%5Cmathbf%7BW%7D%5CVert_%7B%5Cinfty%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clog%5CVert%5Cmathbf%7BW%7D%5CVert_%7B%5Cinfty%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;log&#92;Vert&#92;mathbf{W}&#92;Vert_{&#92;infty}" class="latex" /> is better.  But now it looks as if smaller <img src="https://s0.wp.com/latex.php?latex=%5Clog%5CVert%5Cmathbf%7BW%7D%5CVert_%7B%5Cinfty%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clog%5CVert%5Cmathbf%7BW%7D%5CVert_%7B%5Cinfty%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clog%5CVert%5Cmathbf%7BW%7D%5CVert_%7B%5Cinfty%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;log&#92;Vert&#92;mathbf{W}&#92;Vert_{&#92;infty}" class="latex" /> is worse ?  What is going on with this&#8230;and the other empirical Norm metrics ?  </p>



<p>Now let&#8217;s take a deeper look at how to use the empirical log Norm metrics:</p>



<h4>Norm Metrics:  <img src="https://s0.wp.com/latex.php?latex=%5CVert%5Cmathbf%7BW%7D%5CVert_%7BF%7D%2C+%5CVert%5Cmathbf%7BW%7D%5CVert_%7B%5Cinfty%7D%2C%5CVert%5Cmathbf%7BX%7D%5CVert%5E%7B%5Calpha%7D_%7B%5Calpha%7D%2C+...+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5CVert%5Cmathbf%7BW%7D%5CVert_%7BF%7D%2C+%5CVert%5Cmathbf%7BW%7D%5CVert_%7B%5Cinfty%7D%2C%5CVert%5Cmathbf%7BX%7D%5CVert%5E%7B%5Calpha%7D_%7B%5Calpha%7D%2C+...+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5CVert%5Cmathbf%7BW%7D%5CVert_%7BF%7D%2C+%5CVert%5Cmathbf%7BW%7D%5CVert_%7B%5Cinfty%7D%2C%5CVert%5Cmathbf%7BX%7D%5CVert%5E%7B%5Calpha%7D_%7B%5Calpha%7D%2C+...+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;Vert&#92;mathbf{W}&#92;Vert_{F}, &#92;Vert&#92;mathbf{W}&#92;Vert_{&#92;infty},&#92;Vert&#92;mathbf{X}&#92;Vert^{&#92;alpha}_{&#92;alpha}, ... " class="latex" /></h4>



<p>Unlike the PL exponent <strong>alpha</strong>, the empirical Norm metrics depend strongly on the <em>scale of the weight matrix</em> <strong>W</strong>.  As such, they are highly sensitive to problems like <em>Scale Collapse</em>&#8211;and examining these metrics can tell us when something is potentially very wrong with our models.</p>



<p>First, what are we looking at ?  These empirical (log) Norm metrics reported are defined using the raw eigenvalues. We can compute the eigenvalues of <strong>X</strong> pretty easily (although actually in the code we compute the singular values of <strong>W</strong> using the sklearn TruncatedSVD&nbsp;method.)</p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: python; title: ; notranslate">
M = np.min(W.shape)
svd = TruncatedSVD(n_components=M-1)
svd.fit(W)
sv = svd.singular_values_
eigen_values = sv*sv
</pre></div>


<p>Recall that the Frobenius norm (squared) for matrix <strong>W</strong> is also the  sum of the eigenvalues of <strong>X</strong>.  The Spectral Norm (squared) is just the maximum eigenvalue <img src="https://s0.wp.com/latex.php?latex=%5Clambda%5E%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clambda%5E%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda%5E%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lambda^{max}" class="latex" /> of <strong>X</strong>.   The weighted alpha <img src="https://s0.wp.com/latex.php?latex=%5Chat%7B%5Calpha%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Chat%7B%5Calpha%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Chat%7B%5Calpha%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;hat{&#92;alpha}" class="latex" /> and  the log <img src="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha" class="latex" /> (or Shatten) Norm  are computed after fitting the PL exponent <img src="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha" class="latex" /> for the layer.  In math, these are:</p>



<div class="is-layout-flow wp-block-group"><div class="wp-block-group__inner-container">
<ul>
<li><strong>lognorm</strong>: <img src="https://s0.wp.com/latex.php?latex=%5Clog%5CVert%5Cmathbf%7BW%7D%5CVert_%7BF%7D%3D%5Cfrac%7B1%7D%7B2%7D%5Clog%5Csum_%7Bl%7D%5Clambda_%7Bl%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clog%5CVert%5Cmathbf%7BW%7D%5CVert_%7BF%7D%3D%5Cfrac%7B1%7D%7B2%7D%5Clog%5Csum_%7Bl%7D%5Clambda_%7Bl%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clog%5CVert%5Cmathbf%7BW%7D%5CVert_%7BF%7D%3D%5Cfrac%7B1%7D%7B2%7D%5Clog%5Csum_%7Bl%7D%5Clambda_%7Bl%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;log&#92;Vert&#92;mathbf{W}&#92;Vert_{F}=&#92;frac{1}{2}&#92;log&#92;sum_{l}&#92;lambda_{l}" class="latex" /></li>



<li><strong>logspectralnorm</strong>: <img src="https://s0.wp.com/latex.php?latex=%5Clog%5CVert%5Cmathbf%7BW%7D%5CVert_%7B%5Cinfty%7D%3D%5Cfrac%7B1%7D%7B2%7D%5Clog%5Clambda%5E%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clog%5CVert%5Cmathbf%7BW%7D%5CVert_%7B%5Cinfty%7D%3D%5Cfrac%7B1%7D%7B2%7D%5Clog%5Clambda%5E%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clog%5CVert%5Cmathbf%7BW%7D%5CVert_%7B%5Cinfty%7D%3D%5Cfrac%7B1%7D%7B2%7D%5Clog%5Clambda%5E%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;log&#92;Vert&#92;mathbf{W}&#92;Vert_{&#92;infty}=&#92;frac{1}{2}&#92;log&#92;lambda^{max}" class="latex" /></li>



<li><strong>alpha_weighted:</strong>    <img src="https://s0.wp.com/latex.php?latex=%5Chat%7B%5Calpha%7D%3D%5Calpha%5Clog%5Clambda%5E%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Chat%7B%5Calpha%7D%3D%5Calpha%5Clog%5Clambda%5E%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Chat%7B%5Calpha%7D%3D%5Calpha%5Clog%5Clambda%5E%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;hat{&#92;alpha}=&#92;alpha&#92;log&#92;lambda^{max}" class="latex" /></li>



<li><strong>logpnorm:</strong> <img src="https://s0.wp.com/latex.php?latex=%5Clog%5CVert%5Cmathbf%7BX%7D%5CVert%5E%7B%5Calpha%7D_%7B%5Calpha%7D%3D%5Clog%5Csum_%7Bl%7D%5Clambda_%7Bl%7D%5E%7B%5Calpha%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clog%5CVert%5Cmathbf%7BX%7D%5CVert%5E%7B%5Calpha%7D_%7B%5Calpha%7D%3D%5Clog%5Csum_%7Bl%7D%5Clambda_%7Bl%7D%5E%7B%5Calpha%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clog%5CVert%5Cmathbf%7BX%7D%5CVert%5E%7B%5Calpha%7D_%7B%5Calpha%7D%3D%5Clog%5Csum_%7Bl%7D%5Clambda_%7Bl%7D%5E%7B%5Calpha%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;log&#92;Vert&#92;mathbf{X}&#92;Vert^{&#92;alpha}_{&#92;alpha}=&#92;log&#92;sum_{l}&#92;lambda_{l}^{&#92;alpha}" class="latex" /></li>
</ul>
</div></div>



<p>The <code>weightwatcher</code> code computes the necessary eigenvalues, does the PowerLaw (PL) fits, and reports these, and other, empirical quality metrics, for you, both for the average (summary) and layer-by-layer (details) of each.  The details dataframe has many more metrics as well, but, for now we will focus on these four.   </p>



<p> Now,  what can we do with them?  We are going to look at 3 ways to identify potential problems in a DNN, which can not be seen by just looking at the test accuracy</p>



<div class="is-layout-flow wp-block-group"><div class="wp-block-group__inner-container">
<ul>
<li><strong>Correlation Flow</strong> : comparing different architectures</li>



<li><strong>Alpha Spikes</strong> : Identifying overparameterized models</li>



<li><strong>Scale Collapse</strong> : potential problems when distilling models</li>
</ul>
</div></div>



<h4>Correlation Flow :  comparing different architectures</h4>



<p>Using the <code>weighwatcher details dataframe</code>, we can plot the PL exponent <strong>alpha</strong> vs. the layer Id to get what is called a<em> Correlation Flow</em> plot:</p>



<p>Let us do this, by comparing 3 common (pretrained) computer vision models: VGG, ResNet, and DenseNet.</p>


<div class="wp-block-image">
<figure class="aligncenter size-large is-resized"><img loading="lazy" data-attachment-id="13755" data-permalink="https://calculatedcontent.com/2020/02/16/weightwatcher-empirical-quality-metrics-for-deep-neural-networks/screen-shot-2020-02-16-at-1-06-12-pm/" data-orig-file="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.06.12-pm.png" data-orig-size="1818,1722" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen Shot 2020-02-16 at 1.06.12 PM" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.06.12-pm.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.06.12-pm.png?w=1024" src="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.06.12-pm.png?w=840" alt="" class="wp-image-13755" width="520" height="491" srcset="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.06.12-pm.png?w=1037 1037w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.06.12-pm.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.06.12-pm.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.06.12-pm.png?w=768 768w" sizes="(max-width: 520px) 100vw, 520px" /></figure></div>

<div class="wp-block-image">
<figure class="aligncenter size-large is-resized"><img loading="lazy" data-attachment-id="13752" data-permalink="https://calculatedcontent.com/2020/02/16/weightwatcher-empirical-quality-metrics-for-deep-neural-networks/screen-shot-2020-02-16-at-12-00-03-pm/" data-orig-file="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-12.00.03-pm.png" data-orig-size="2304,572" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen Shot 2020-02-16 at 12.00.03 PM" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-12.00.03-pm.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-12.00.03-pm.png?w=1024" src="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-12.00.03-pm.png?w=840" alt="" class="wp-image-13752" width="635" height="157" srcset="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-12.00.03-pm.png?w=632 632w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-12.00.03-pm.png?w=1265 1265w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-12.00.03-pm.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-12.00.03-pm.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-12.00.03-pm.png?w=768 768w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-12.00.03-pm.png?w=1024 1024w" sizes="(max-width: 635px) 100vw, 635px" /></figure></div>


<p>These results can be reproduced using the following notebooks:</p>



<ul>
<li><a href="https://github.com/CalculatedContent/ww-trends-2020/blob/master/WeightWatcher-VGG.ipynb">WeightWatcher-VGG.ipynb</a></li>



<li><a href="https://github.com/CalculatedContent/ww-trends-2020/blob/master/WeightWatcher-ResNet.ipynb">WeightWatcher-ResNet.ipynb</a></li>



<li><a href="https://github.com/CalculatedContent/ww-trends-2020/blob/master/WeightWatcher-DenseNet.ipynb">WeightWatcher-DenseNet.ipynb</a></li>
</ul>



<p>Recall that good models have  average PL exponents <img src="https://s0.wp.com/latex.php?latex=%5Calpha%5Cin%5B2%2C4%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha%5Cin%5B2%2C4%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha%5Cin%5B2%2C4%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha&#92;in[2,4]" class="latex" />, in the Fat Tailed Universality class.  Likewise, we find  that, if we plot <strong>alpha</strong> vs layer_id, then good models also have stable <strong>alphas</strong>, in this range.  </p>



<p>The VGG11 and 19 models have good <strong>alphas</strong>, all within the Fat Tailed Universality class, or smaller.  And both the smaller and larger models show similar behavior.  Also, noitce that the last 3 and FC layers in the VGG models all have final smaller <strong>alphas</strong>, <img src="https://s0.wp.com/latex.php?latex=%5Calpha%5Cin%5B2%2C3%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha%5Cin%5B2%2C3%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha%5Cin%5B2%2C3%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha&#92;in[2,3]" class="latex" />.  So while the <strong>alphas</strong> are increasing as we move down the model, the final FC layers seem to capture and concentrate the information, leading to more correlated layer weight matrices at the end.</p>



<p>ResNet152 is an even better example of good Correlation Flow.   It has a large number of <strong>alphas</strong> near 2, contiguously, for over 200 layers.  Indeed, ResNet models have been trained with over 1000 layers; clearly the ResNet architecture supports a good flow of information.</p>



<p>Good <em>Correlation Flow </em> shows that the DNN architecture is learning the correlations in the data at every layer, and implies (*informally) that  information is flowing smoothly through the network.</p>



<p class="has-text-align-center"><strong>Good DNNs show good Correlation Flow</strong></p>



<p>We also find that models in an architecture series (VGG, ResNet, DenseNet, etc) all have similar Correlation Flow patterns, when adjusting for the model depth.</p>



<p>Bad models, however, have <strong>alphas</strong> that increase with layer_id,  or behave erratically.  This means that the information is not flowing well through the network, and the final layers are not fully correlated.  For example, the older VGG models have <strong>alphas</strong> in a good range, <em><strong>but</strong></em>, as we go down the network, the <strong>alphas</strong> are systematically increasing.  The final FC layers fix the problem, although, maybe a few residual connections, like in ResNet, might improve these old models even more.</p>



<p>You might think adding a lot of residual connections would improve  Correlation Flow&#8211;but too many connections is also bad.  The DenseNet series is an example of an architecture with too many residual connections.  Here, both with the pretrained DenseNet126 and 161 we see the many <img src="https://s0.wp.com/latex.php?latex=%5Calpha%5Cgg&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha%5Cgg&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha%5Cgg&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha&#92;gg" class="latex" />, and, looking down the network layers,  the are scattered all over.  The Correlation Flow is poor and even chaotic, and, we conjecture,  less than optimal.  </p>



<p class="has-text-align-left">Curiously, the ResNet models show good flow internally, as shown when we zoom-in, in (d) above. But the last few layers have unusually large <strong>alphas</strong>; we will discuss this phenomena now.</p>



<p><strong>Advice</strong>: If you are training or finetuning a DNN model for production use, use <code>weightwatcher</code> to plot the Correlation Flow.  If you see alphas increasing with depth, behaving chaotically, or there are just a lot of alphas &gt;&gt; 6, revisit your architecture and training procedures.  </p>



<h4> Alpha Spikes : Identifying overparameterized models</h4>



<p class="has-text-align-center"><em>When is a DNN is over-parameterized, once trained on some data ?</em></p>



<p>Easy&#8230;just look at <strong>alphas</strong>.  We have found that well-trained, or perhaps fully-trained, models, should have <img src="https://s0.wp.com/latex.php?latex=%5Calpha%5Cin%5B2%2C4%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha%5Cin%5B2%2C4%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha%5Cin%5B2%2C4%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha&#92;in[2,4]" class="latex" />.  And the best CV models have most of their <strong>alphas</strong> just above 2.0.  However, some models, such as NLP OpenAI GPT2 and BERT models, have a wider <img src="https://s0.wp.com/latex.php?latex=%5Calpha%5Cin%5B2%2C6%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha%5Cin%5B2%2C6%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha%5Cin%5B2%2C6%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha&#92;in[2,6]" class="latex" />.  And many models have several unusually large <strong>alphas</strong>, with latex \alpha\gg 6$.  What is going on ?  And how is it useful ?</p>



<p>The current batch of NLP Transformer models are great examples. We suspect that many models, like BERT and GPT-xl,  are over-parameterized, and that to fully use them in production, they need to be fine-tuned.  Indeed, that is the whole point of these models; NLP transfer learning.</p>



<p>Let&#8217;s take a look the current crop of pretrained OpenAI GPT-2 models, provided by the <code>huggingface</code> package.   We call these &#8220;good-better-best&#8221; series.</p>


<div class="wp-block-image">
<figure class="aligncenter size-large is-resized"><img loading="lazy" data-attachment-id="13760" data-permalink="https://calculatedcontent.com/2020/02/16/weightwatcher-empirical-quality-metrics-for-deep-neural-networks/screen-shot-2020-02-16-at-1-53-23-pm/" data-orig-file="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.53.23-pm.png" data-orig-size="1752,720" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen Shot 2020-02-16 at 1.53.23 PM" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.53.23-pm.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.53.23-pm.png?w=1024" src="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.53.23-pm.png?w=840" alt="" class="wp-image-13760" width="587" height="241" srcset="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.53.23-pm.png?w=587 587w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.53.23-pm.png?w=1174 1174w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.53.23-pm.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.53.23-pm.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.53.23-pm.png?w=768 768w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.53.23-pm.png?w=1024 1024w" sizes="(max-width: 587px) 100vw, 587px" /></figure></div>


<figure class="wp-block-image size-large is-resized"><img loading="lazy" data-attachment-id="13759" data-permalink="https://calculatedcontent.com/2020/02/16/weightwatcher-empirical-quality-metrics-for-deep-neural-networks/screen-shot-2020-02-16-at-1-53-26-pm/" data-orig-file="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.53.26-pm.png" data-orig-size="2502,262" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen Shot 2020-02-16 at 1.53.26 PM" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.53.26-pm.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.53.26-pm.png?w=1024" src="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.53.26-pm.png?w=840" alt="" class="wp-image-13759" width="681" height="70" srcset="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.53.26-pm.png?w=668 668w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.53.26-pm.png?w=1337 1337w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.53.26-pm.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.53.26-pm.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.53.26-pm.png?w=768 768w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.53.26-pm.png?w=1024 1024w" sizes="(max-width: 681px) 100vw, 681px" /></figure>



<p>These results can be reproduced using the <a href="https://github.com/CalculatedContent/ww-trends-2020/blob/master/WeightWatcher-OpenAI-GPT2.ipynb">WeightWatcher-OpenAI-GPT2.ipynb</a> notebook.</p>



<p>For both the PL exponent (a) and our Log Alpha Norm (b) , <em>Smaller is Better.  </em>The latest and greatest <a href="https://openai.com/blog/gpt-2-1-5b-release/">OpenAI GPT2-xl </a>model (in red) has both smaller <strong>alphas</strong> and smaller empirical log norm metrics, compared to the earlier GP2-large (orange) and GPT2-medium (green) models.  </p>



<p>But the GPT2-xl model also has more outlier <strong>alphas</strong>: <img src="https://s0.wp.com/latex.php?latex=%5Calpha%5Cgg+6&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha%5Cgg+6&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha%5Cgg+6&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha&#92;gg 6" class="latex" /></p>



<p>We have seen similar behavior in other NLP models, such as comparing OpenAI GPT to GPT2-small, and the original BERT, as compared to the Distilled Bert (as discussed in <a href="https://www.youtube.com/watch?v=PQUItQi-B-I">my recent Stanford Lecture</a>).  We suspect that when these large NLP Trasnformer models are fine-tuned or distilled, the <strong>alphas</strong> will get smaller, and performance will improve.    </p>



<p><strong>Advice</strong>: So when you fine-tune your models, monitor the <strong>alphas</strong> with <code>weightwatcher</code>.    If they do not decrease enough, add more data, and/or try to improve the training protocols.</p>



<p>But you also have to be careful not to break your model, as have found that some distillation methods may do this.</p>



<h4>Scale Collapse : When Models Go Bad</h4>



<p>Frequently one may finetune a model, for transfer learning, distillation, or just to add more data.  </p>



<p class="has-text-align-center"><em>How can we know if we broke the model ?</em></p>



<p>We have found that poorly trained models frequently exhibit Scale Collapse, in which 1 or more layers have unusually small Spectral and/or Frobenius Norms.    </p>



<p>This can be seen in your models by running plotting a histogram of the <strong>logspectralnorm</strong> column from the <code>details dataframe</code></p>


<div class="wp-block-image">
<figure class="alignleft size-large is-resized"><img loading="lazy" data-attachment-id="13775" data-permalink="https://calculatedcontent.com/scale-collapse-1/" data-orig-file="https://charlesmartin14.files.wordpress.com/2020/02/scale-collapse-1.png" data-orig-size="960,720" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="scale-collapse-1" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2020/02/scale-collapse-1.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2020/02/scale-collapse-1.png?w=960" src="https://charlesmartin14.files.wordpress.com/2020/02/scale-collapse-1.png?w=960" alt="" class="wp-image-13775" width="373" height="280" srcset="https://charlesmartin14.files.wordpress.com/2020/02/scale-collapse-1.png?w=373 373w, https://charlesmartin14.files.wordpress.com/2020/02/scale-collapse-1.png?w=746 746w, https://charlesmartin14.files.wordpress.com/2020/02/scale-collapse-1.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2020/02/scale-collapse-1.png?w=300 300w" sizes="(max-width: 373px) 100vw, 373px" /></figure></div>


<p class="has-text-align-left">Recall earlier we noted the poorly-trained in the OpenAI GPT model. This is typical of many porly-trained models.  Because of this, log norm metrics can not be reliable used to predict trends in accuracies on poorly-trained models. </p>



<p class="has-text-align-left">However, we can use the empirical log Norm metrics to detect problems that can not be seen by simply looking at the training and test accuracies.</p>



<h4>Distillation may break models: be careful out there</h4>



<p>We have also observed this in some distilled models.  Below we look at the ResNet20 model, before and after distillation using the Group Regularization method (as described in the <a href="https://github.com/NervanaSystems/distiller">Intel distiller package</a> and provided in the <a href="https://nervanasystems.github.io/distiller/model_zoo.html">model zoo</a>).  We plot the Spectral Norm (maximum eigenvalue) and PL exponent alpha vs. the layer_id (depth) for both the baseline (green) and finetuned /distiller (red) ResNet20 models.</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img data-attachment-id="13777" data-permalink="https://calculatedcontent.com/screen-shot-2020-02-16-at-4-33-46-pm/" data-orig-file="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-4.33.46-pm.png" data-orig-size="1678,888" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2020-02-16-at-4.33.46-pm" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-4.33.46-pm.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-4.33.46-pm.png?w=1024" src="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-4.33.46-pm.png?w=1024" alt="" class="wp-image-13777" srcset="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-4.33.46-pm.png?w=1024 1024w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-4.33.46-pm.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-4.33.46-pm.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-4.33.46-pm.png?w=768 768w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-4.33.46-pm.png 1678w" sizes="(max-width: 1024px) 100vw, 1024px" /></figure></div>

<div class="wp-block-image">
<figure class="aligncenter size-large is-resized"><img loading="lazy" data-attachment-id="13778" data-permalink="https://calculatedcontent.com/screen-shot-2020-02-16-at-4-33-50-pm/" data-orig-file="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-4.33.50-pm.png" data-orig-size="2482,368" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2020-02-16-at-4.33.50-pm" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-4.33.50-pm.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-4.33.50-pm.png?w=1024" src="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-4.33.50-pm.png?w=1024" alt="" class="wp-image-13778" width="644" height="96" srcset="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-4.33.50-pm.png?w=1024 1024w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-4.33.50-pm.png?w=644 644w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-4.33.50-pm.png?w=1288 1288w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-4.33.50-pm.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-4.33.50-pm.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-4.33.50-pm.png?w=768 768w" sizes="(max-width: 644px) 100vw, 644px" /></figure></div>


<p>These results can be reproduced by installing the distiller package, downloading the model zoo pretrained models, and running the <a href="https://github.com/CalculatedContent/ww-trends-2020/blob/master/distiller/WeightWatcher-Intel-Distiller-ResNet20.ipynb">WeightWatcher-Intel-Distiller-ResNet20.ipynb</a> notebook in the distiller folder. <small>(We do note that these are older results, and we used older versions of both <code>distiller</code> and <code>weighwatcher</code>, which used a different normalization on the Conv2D layers.  Current results may differ although we expect to see similar trends.)</small></p>



<p>Notice that the baseline and finetuned ResNet20 have similar PL exponents (b) for all layers, but for several layers in (a), the Spectral Norm (maximum eigenvalue) collapses in value. That is, the <em>Scale Collapse</em>s.  This is bad, and characteristic of a poorly trained model like the original GPT.  </p>



<p><strong>Advice</strong>: if you finetune a model, use <code>weighwatcher</code> to monitor the <strong>log Spectral Norms</strong>.  If you see unusually small values, something is wrong.</p>



<h2>Learn More about the WeightWatcher tool</h2>



<p><a href="https://arxiv.org/pdf/2002.06716.pdf">Our latest paper</a> is now on archive.</p>



<p>Please check out the <a href="https://github.com/CalculatedContent/WeightWatcher">github webpage for WeightWatcher </a>and the associated papers and online talks at Stanford, UC Berkeley, and the wonderful podcasts that have invited us on to speak about the work.</p>



<p></p>



<p>If you want to get more involved, reach out to me directly at <em>charles@calculationconsulting.com</em></p>



<p>And remember&#8211;if you need help at your company with AI, Deep learning, and Machine Learning, please reach out.    <a href="https://calculationconsulting.com/">Calculation Consulting</a></p>



<p></p>
]]></content:encoded>
					
					<wfw:commentRss>https://calculatedcontent.com/2020/02/16/weightwatcher-empirical-quality-metrics-for-deep-neural-networks/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		
		<media:thumbnail url="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-15-at-10.50.16-am-1.png" />
		<media:content url="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-15-at-10.50.16-am-1.png" medium="image">
			<media:title type="html">WeightWatcher Metrics</media:title>
		</media:content>

		<media:content url="https://1.gravatar.com/avatar/1ae78e5099a40f308b172a5a65416cab?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">charlesmartin14</media:title>
		</media:content>

		<media:content url="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-14-at-10.06.20-pm.png?w=987" medium="image" />

		<media:content url="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-15-at-10.32.36-am.png?w=840" medium="image" />

		<media:content url="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-14-at-9.50.36-pm.png?w=1024" medium="image" />

		<media:content url="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-11.06.38-am.png?w=840" medium="image" />

		<media:content url="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-11.06.44-am.png?w=840" medium="image" />

		<media:content url="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-15-at-10.50.16-am.png?w=840" medium="image" />

		<media:content url="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.06.12-pm.png?w=840" medium="image" />

		<media:content url="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-12.00.03-pm.png?w=840" medium="image" />

		<media:content url="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.53.23-pm.png?w=840" medium="image" />

		<media:content url="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-1.53.26-pm.png?w=840" medium="image" />

		<media:content url="https://charlesmartin14.files.wordpress.com/2020/02/scale-collapse-1.png?w=960" medium="image" />

		<media:content url="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-4.33.46-pm.png?w=1024" medium="image" />

		<media:content url="https://charlesmartin14.files.wordpress.com/2020/02/screen-shot-2020-02-16-at-4.33.50-pm.png?w=1024" medium="image" />
	</item>
		<item>
		<title>Towards a new Theory of Learning: Statistical Mechanics of Deep Neural Networks</title>
		<link>https://calculatedcontent.com/2019/12/03/towards-a-new-theory-of-learning-statistical-mechanics-of-deep-neural-networks/</link>
					<comments>https://calculatedcontent.com/2019/12/03/towards-a-new-theory-of-learning-statistical-mechanics-of-deep-neural-networks/#comments</comments>
		
		<dc:creator><![CDATA[Charles H Martin, PhD]]></dc:creator>
		<pubDate>Tue, 03 Dec 2019 16:14:04 +0000</pubDate>
				<category><![CDATA[Uncategorized]]></category>
		<guid isPermaLink="false">http://calculatedcontent.com/?p=13259</guid>

					<description><![CDATA[Introduction For the past few years, we have talked a lot about how we can understand the properties of Deep &#8230; <a class="more-link" href="https://calculatedcontent.com/2019/12/03/towards-a-new-theory-of-learning-statistical-mechanics-of-deep-neural-networks/">More</a>]]></description>
										<content:encoded><![CDATA[
<h2>Introduction</h2>



<p>For the past few years, we have talked a lot about how we can understand the properties of Deep Neural Networks by examining the spectral properties of the layer weight matrices <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{W} " class="latex" />. Specifically, we can form the correlation matrix </p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D+%3D%5Cfrac%7B1%7D%7BN%7D%5Cmathbf%7BW%7D%5E%7BT%7D%5Cmathbf%7BW%7D++&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D+%3D%5Cfrac%7B1%7D%7BN%7D%5Cmathbf%7BW%7D%5E%7BT%7D%5Cmathbf%7BW%7D++&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D+%3D%5Cfrac%7B1%7D%7BN%7D%5Cmathbf%7BW%7D%5E%7BT%7D%5Cmathbf%7BW%7D++&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{X} =&#92;frac{1}{N}&#92;mathbf{W}^{T}&#92;mathbf{W}  " class="latex" />, </p>



<p>and compute the eigenvalues <img src="https://s0.wp.com/latex.php?latex=%5Clambda++&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clambda++&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda++&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lambda  " class="latex" /></p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D%7B%5Cmathbf%7Be%7D%7D%3D%5Clambda%7B%5Cmathbf%7Be%7D%7D++&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D%7B%5Cmathbf%7Be%7D%7D%3D%5Clambda%7B%5Cmathbf%7Be%7D%7D++&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D%7B%5Cmathbf%7Be%7D%7D%3D%5Clambda%7B%5Cmathbf%7Be%7D%7D++&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{X}{&#92;mathbf{e}}=&#92;lambda{&#92;mathbf{e}}  " class="latex" />.</p>



<p>By plotting the histogram of the eigenvalues (i.e the spectral density <img src="https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;rho(&#92;lambda) " class="latex" />), we can monitor the training process and gain insight into the implicit regularization and convergence properties of DNN. Indeed, we have identified </p>



<h3>5+1 Phases of Training</h3>



<figure class="wp-block-image size-large"><img data-attachment-id="13381" data-permalink="https://calculatedcontent.com/screen-shot-2019-11-29-at-10-28-02-pm/" data-orig-file="https://charlesmartin14.files.wordpress.com/2019/11/screen-shot-2019-11-29-at-10.28.02-pm.png" data-orig-size="1278,734" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2019-11-29-at-10.28.02-pm" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2019/11/screen-shot-2019-11-29-at-10.28.02-pm.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2019/11/screen-shot-2019-11-29-at-10.28.02-pm.png?w=1024" src="https://charlesmartin14.files.wordpress.com/2019/11/screen-shot-2019-11-29-at-10.28.02-pm.png?w=1024" alt="" class="wp-image-13381" srcset="https://charlesmartin14.files.wordpress.com/2019/11/screen-shot-2019-11-29-at-10.28.02-pm.png?w=1024 1024w, https://charlesmartin14.files.wordpress.com/2019/11/screen-shot-2019-11-29-at-10.28.02-pm.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2019/11/screen-shot-2019-11-29-at-10.28.02-pm.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2019/11/screen-shot-2019-11-29-at-10.28.02-pm.png?w=768 768w, https://charlesmartin14.files.wordpress.com/2019/11/screen-shot-2019-11-29-at-10.28.02-pm.png 1278w" sizes="(max-width: 1024px) 100vw, 1024px" /></figure>



<p>Each of these phases roughly corresponds to a Universality class from Random matrix Theory (RMT).   And as we shall see below, we can use RMT to develop a new theory of learning.</p>



<p>First, however, we note that for nearly every pretrained DNNs we have examined (and we have examined thousands of them), the phase appears to be in somewhere between Bulk-Decay and/or Heavy-Tailed .</p>



<h3>Heavy Tailed Implicit Regularization</h3>



<p> Moreover, for nearly all layers in all well trained, production quality DNNs, the layer spectral density <img src="https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;rho(&#92;lambda) " class="latex" /> can be fit to a truncated power law,  with exponents frequently lying in the Fat Tailed range  [2-4], and the maximum eigenvalue no larger than say 100</p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29%5Csim%5Clambda%5E%7B-%5Calpha%7D%2C+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29%5Csim%5Clambda%5E%7B-%5Calpha%7D%2C+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Crho%28%5Clambda%29%5Csim%5Clambda%5E%7B-%5Calpha%7D%2C+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;rho(&#92;lambda)&#92;sim&#92;lambda^{-&#92;alpha}, " class="latex" /></p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=%5Ctext%7Bwhere%7D%5C%3B%5C%3B+%5Calpha%5Cin%5B2%2C4%5D+%2C%5C%3B%5C%3B%5Clambda_%7Bmax%7D%3C100+++&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext%7Bwhere%7D%5C%3B%5C%3B+%5Calpha%5Cin%5B2%2C4%5D+%2C%5C%3B%5C%3B%5Clambda_%7Bmax%7D%3C100+++&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext%7Bwhere%7D%5C%3B%5C%3B+%5Calpha%5Cin%5B2%2C4%5D+%2C%5C%3B%5C%3B%5Clambda_%7Bmax%7D%3C100+++&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text{where}&#92;;&#92;; &#92;alpha&#92;in[2,4] ,&#92;;&#92;;&#92;lambda_{max}&lt;100   " class="latex" />,</p>



<p>Most importantly,  in 80-90% of the DNN architectures studied, on average, smaller exponents <img src="https://s0.wp.com/latex.php?latex=%5Calpha+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha " class="latex" /> correspond to smaller test errors.    </p>



<h3> DNN Quality Metrics in Practice</h3>



<p>Our empirical results suggest that the power law exponent can be used as (part of) a practical quality metric.  This led us to propose the <img src="https://s0.wp.com/latex.php?latex=%5Chat%7B%5Calpha%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Chat%7B%5Calpha%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Chat%7B%5Calpha%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;hat{&#92;alpha}" class="latex" /> metric for DNNs:</p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=%5Chat%7B%5Calpha%7D%3A%3D%5Csum%5Calpha_%7Bi%7D%5Clog%5Clambda_%7Bi%2Cmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Chat%7B%5Calpha%7D%3A%3D%5Csum%5Calpha_%7Bi%7D%5Clog%5Clambda_%7Bi%2Cmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Chat%7B%5Calpha%7D%3A%3D%5Csum%5Calpha_%7Bi%7D%5Clog%5Clambda_%7Bi%2Cmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;hat{&#92;alpha}:=&#92;sum&#92;alpha_{i}&#92;log&#92;lambda_{i,max}" class="latex" /></p>



<p>where we compute the exponent <img src="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha" class="latex" /> and maximum eigenvalue <img src="https://s0.wp.com/latex.php?latex=%5Clambda_%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clambda_%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda_%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lambda_{max}" class="latex" /> for each layer weight matrix (and Conv2D feature maps), and then form the total DNN quality as a simple weighted average of the exponents.  Amazingly, this metric correlates very well with the reported test accuracy of pretrained DNNs (such as the VGG models,  the ResNet models, etc)</p>


<div class="wp-block-image">
<figure class="aligncenter is-resized"><img src="https://github.com/CalculatedContent/PredictingTestAccuracies/raw/master/img/vgg-w_alphas.png" alt="alt text" width="460" height="460" /></figure></div>


<h4>WeightWatcher</h4>



<p>We have even built a open source, python command line tool&#8211;<a href="https://github.com/CalculatedContent/WeightWatcher">weightwatcher</a>&#8211;so that other researchers can both reproduce and leverage our results </p>



<p class="has-text-align-center"><code>pip install weightwatcher</code></p>



<p>And we have a Slack Channel for those who want to ask questions, dig deeper, and/or contribute to the work.  Email me, or <a href="https://www.linkedin.com/in/charlesmartin14/">ping me on LinkedIn,</a> to join our vibrant group.</p>



<p><br>All of this leads to a very basic question:  </p>



<h2 class="has-text-align-center"><strong><em>Why does this work ?</em></strong></h2>



<p>To answer this, we will go back to the foundations of the theory of learning, from the physics perspective, and rebuild the theory using in both our experimental observations, some older results from Theoretical Physics,  and (fairly) recent results in Random Matrix Theory.</p>



<h2>Statistical Mechanics of Learning</h2>



<p>Here, I am going to sketch out the ideas we are currently researching to develop a new theory of generalization for Deep Neural Networks.  We have a lot of work to do, but I think we have made enough progress to present these ideas, informally, to flush out the basics.</p>



<p><strong>What do we seek ? </strong> A practical theory that can be used to predict the generalization accuracy of a DNN solely by looking at the trained weight matrices, without looking at the test data.  </p>



<p><strong>Why ? </strong>  Do you test a bridge by driving cars over it until it collapses ?  Of course not!  So why do we build DNNs and only rely on brute force testing ?  Surely we can do better.</p>



<p><strong>What is the approach ?</strong> We start with the classic Perceptron Student-Teacher model from Statistical Mechanics of the 1990s.  The setup is similar, but the motivations are a bit different.  We have discussed this model earlier here  <a href="https://calculatedcontent.com/2018/04/01/rethinking-or-remembering-generalization-in-neural-networks/">Remembering Generalization in DNNs.</a>  from our paper <a rel="noreferrer noopener" href="https://arxiv.org/abs/1611.03530" target="_blank">Understanding Deep Learning Requires Rethinking Generalization</a><a href="https://arxiv.org/abs/1611.03530">.</a>  </p>



<p>Here, let us review the mathematical setup in some detail:</p>



<h3>the Student-Teacher model</h3>



<p>We start with the simple model presented in chapter 2, <a href="https://books.google.com/books/about/Statistical_Mechanics_of_Learning.html?id=qVo4IT9ByfQC">Engel and Van der Brock</a>, interpreted in a modern context.   See also this classic 1992 paper, <em>Statistical Mechanics of Learning from Examples</em>.</p>



<p>Here, we want to do something a little different, and use the formalism of Statistical Mechanics to both compute the average generalization error, and to interpret the global convergence properties of DNNs in light of this ,  giving us more insight into and to provide a new theory of <a href="https://calculatedcontent.com/2015/03/25/why-does-deep-learning-work/">Why Deep Learning Works  (as proposed in 2015)</a>.</p>



<p>Suppose we have some trained or pretrained DNN (i.e. like VGG19).  We want to compute the average or typical error that our Teacher DNN could make, just by examining the layer weight matrices.  <em>Without peeking at the data.</em></p>



<p><strong>A Simple Layer Approach:</strong><em> We assume all layers are statistically independent, so that the average generalization quality </em><img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BQ%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BQ%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathcal%7BQ%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathcal{Q} " class="latex" />&nbsp;<em>(i.e. 1.0-error) is just the product of the contributions of from each layer weight matrix </em><img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D_l+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D_l+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D_l+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{W}_l " class="latex" />&nbsp;.</p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BQ%7D%3A%3D%5Cunderset%7Bl%7D%7B%5Cprod%7D%5C%3B%5Cmathcal%7BQ%7D%28%5Cmathbf%7BW%7D_l%29+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BQ%7D%3A%3D%5Cunderset%7Bl%7D%7B%5Cprod%7D%5C%3B%5Cmathcal%7BQ%7D%28%5Cmathbf%7BW%7D_l%29+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathcal%7BQ%7D%3A%3D%5Cunderset%7Bl%7D%7B%5Cprod%7D%5C%3B%5Cmathcal%7BQ%7D%28%5Cmathbf%7BW%7D_l%29+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathcal{Q}:=&#92;underset{l}{&#92;prod}&#92;;&#92;mathcal{Q}(&#92;mathbf{W}_l) " class="latex" />&nbsp;</p>



<p><strong>Example:</strong>  The Product Norm is a Capacity (or Quality) measure for DNNs from<a href="https://arxiv.org/abs/1808.01174"> traditional ML theory</a>.</p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BQ%7D%5Csim%5Cunderset%7Bl%7D%7B%5Cprod%7D%5C%3B%5CVert%5Cmathbf%7BW%7D_l%5CVert%3D%5CVert%5Cmathbf%7BW%7D_%7B1%7D%5CVert%5CVert%5Cmathbf%7BW%7D_%7B2%7D%5CVert%5Ccdots%5CVert%5Cmathbf%7BW%7D_%7BL%7D%5CVert+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BQ%7D%5Csim%5Cunderset%7Bl%7D%7B%5Cprod%7D%5C%3B%5CVert%5Cmathbf%7BW%7D_l%5CVert%3D%5CVert%5Cmathbf%7BW%7D_%7B1%7D%5CVert%5CVert%5Cmathbf%7BW%7D_%7B2%7D%5CVert%5Ccdots%5CVert%5Cmathbf%7BW%7D_%7BL%7D%5CVert+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathcal%7BQ%7D%5Csim%5Cunderset%7Bl%7D%7B%5Cprod%7D%5C%3B%5CVert%5Cmathbf%7BW%7D_l%5CVert%3D%5CVert%5Cmathbf%7BW%7D_%7B1%7D%5CVert%5CVert%5Cmathbf%7BW%7D_%7B2%7D%5CVert%5Ccdots%5CVert%5Cmathbf%7BW%7D_%7BL%7D%5CVert+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathcal{Q}&#92;sim&#92;underset{l}{&#92;prod}&#92;;&#92;Vert&#92;mathbf{W}_l&#92;Vert=&#92;Vert&#92;mathbf{W}_{1}&#92;Vert&#92;Vert&#92;mathbf{W}_{2}&#92;Vert&#92;cdots&#92;Vert&#92;mathbf{W}_{L}&#92;Vert " class="latex" />&nbsp;</p>



<p>The Norm may be  Frobenius Norm, the Spectral Norm, or even their ratio, the Stable Rank.</p>



<p>This independence assumption is probably not a great approximation  but it gets us closer to a realistic theory. Indeed, even traditional ML theory recognizes this, and may use Path Norm to correct for this. For now, this will suffice.</p>



<p><strong>A Log Product Norm </strong>If we take the logarithm of each side, we can write the log Quality as the sum of the layer contributions.  More generally, we will express the log Quality as a weighted average of some (as yet unspecified) log norm of the weight matrix. </p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=%5Clog%5Cmathcal%7BQ%7D%5Csim%5Csum%5Climits_%7Bl%7Da_%7Bl%7D%5Clog%5CVert%5Cmathbf%7BW%7D_%7Bl%7D%5CVert+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clog%5Cmathcal%7BQ%7D%5Csim%5Csum%5Climits_%7Bl%7Da_%7Bl%7D%5Clog%5CVert%5Cmathbf%7BW%7D_%7Bl%7D%5CVert+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clog%5Cmathcal%7BQ%7D%5Csim%5Csum%5Climits_%7Bl%7Da_%7Bl%7D%5Clog%5CVert%5Cmathbf%7BW%7D_%7Bl%7D%5CVert+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;log&#92;mathcal{Q}&#92;sim&#92;sum&#92;limits_{l}a_{l}&#92;log&#92;Vert&#92;mathbf{W}_{l}&#92;Vert " class="latex" />&nbsp;</p>



<h4>Quality for a Single Layer: Perceptron model</h4>



<p>We now set up the classic Student-Teacher model for a Perceptron&#8211;with a slight twist.  That is, from now on, we assume our models have 1 layer, like a Perceptron. </p>



<p>Let&#8217;s call our trained or pretrained DNN the Teacher <strong>T</strong>.  The Teacher maps data to labels.  Of course, there could be many Teachers which map the same data to the same labels.  For <strong>our</strong> specific purposes here, <strong><em>we just fix the Teacher T</em></strong>.  We imagine that the learning process is for us to learn all possible Student Perceptrons <strong>J</strong> that also map the data to the labels, in the same way as the Teacher.</p>



<p> But for a pretrained model,  we have no data, and we have no labels.   And that&#8217;s ok.  Following Engle and Van der Brock (and also Engle&#8217;s 2001 paper ), consider the following Figure, which depicts the vector space representations of <strong>T</strong> and <strong>J</strong>.</p>


<div class="wp-block-image">
<figure class="aligncenter size-large is-resized"><img loading="lazy" data-attachment-id="13295" data-permalink="https://calculatedcontent.com/student-teacher/" data-orig-file="https://charlesmartin14.files.wordpress.com/2019/11/student-teacher.png" data-orig-size="1126,664" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="student-teacher" data-image-description="" data-image-caption="" data-medium-file="https://charlesmartin14.files.wordpress.com/2019/11/student-teacher.png?w=300" data-large-file="https://charlesmartin14.files.wordpress.com/2019/11/student-teacher.png?w=1024" src="https://charlesmartin14.files.wordpress.com/2019/11/student-teacher.png?w=1024" alt="" class="wp-image-13295" width="591" height="349" srcset="https://charlesmartin14.files.wordpress.com/2019/11/student-teacher.png?w=1024 1024w, https://charlesmartin14.files.wordpress.com/2019/11/student-teacher.png?w=591 591w, https://charlesmartin14.files.wordpress.com/2019/11/student-teacher.png?w=150 150w, https://charlesmartin14.files.wordpress.com/2019/11/student-teacher.png?w=300 300w, https://charlesmartin14.files.wordpress.com/2019/11/student-teacher.png?w=768 768w, https://charlesmartin14.files.wordpress.com/2019/11/student-teacher.png 1126w" sizes="(max-width: 591px) 100vw, 591px" /></figure></div>


<p>To compute the average generalization error for a given model, we write first need the Student-Teacher (ST) error function <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon%28R%29&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cepsilon%28R%29&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cepsilon%28R%29&#038;bg=%23ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;epsilon(R)" class="latex" />.  This is simply the L2 loss between the 2 models, averaged over a random data set.</p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=%5Cepsilon%28R%29%3D%5Clangle%5Cfrac%7B1%7D%7B2%7D%5By_%7BT%7D-y_%7BS%7D%5D%5E%7B2%7D%5Crangle_%7Bdata%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cepsilon%28R%29%3D%5Clangle%5Cfrac%7B1%7D%7B2%7D%5By_%7BT%7D-y_%7BS%7D%5D%5E%7B2%7D%5Crangle_%7Bdata%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cepsilon%28R%29%3D%5Clangle%5Cfrac%7B1%7D%7B2%7D%5By_%7BT%7D-y_%7BS%7D%5D%5E%7B2%7D%5Crangle_%7Bdata%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;epsilon(R)=&#92;langle&#92;frac{1}{2}[y_{T}-y_{S}]^{2}&#92;rangle_{data} " class="latex" /></p>



<p>where   <img src="https://s0.wp.com/latex.php?latex=y_%7BS%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y_%7BS%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y_%7BS%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y_{S} " class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=y_%7BT%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y_%7BT%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y_%7BT%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y_{T} " class="latex" /> are the Student and Teacher labels, respectively.</p>



<p>For a Linear Perceptron,  the labels are given by</p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=y_%7BS%7D%3D%5Cmathbf%7BS%7D%5E%7BT%7D%5Cmathbf%7Bx%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y_%7BS%7D%3D%5Cmathbf%7BS%7D%5E%7BT%7D%5Cmathbf%7Bx%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y_%7BS%7D%3D%5Cmathbf%7BS%7D%5E%7BT%7D%5Cmathbf%7Bx%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y_{S}=&#92;mathbf{S}^{T}&#92;mathbf{x} " class="latex" /></p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=y_%7BT%7D%3D%5Cmathbf%7BT%7D%5E%7BT%7D%5Cmathbf%7Bx%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y_%7BT%7D%3D%5Cmathbf%7BT%7D%5E%7BT%7D%5Cmathbf%7Bx%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y_%7BT%7D%3D%5Cmathbf%7BT%7D%5E%7BT%7D%5Cmathbf%7Bx%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y_{T}=&#92;mathbf{T}^{T}&#92;mathbf{x} " class="latex" />  </p>



<p>and the ST error function is simply 1 minus the ST overlap</p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=%5Cepsilon%3D1-R%2C%5C%3B%5C%3BR+%3D+%5Cdfrac%7B1%7D%7BN%7D%5Cmathbf%7BS%7D%5E%7BT%7D%5Cmathbf%7BT%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cepsilon%3D1-R%2C%5C%3B%5C%3BR+%3D+%5Cdfrac%7B1%7D%7BN%7D%5Cmathbf%7BS%7D%5E%7BT%7D%5Cmathbf%7BT%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cepsilon%3D1-R%2C%5C%3B%5C%3BR+%3D+%5Cdfrac%7B1%7D%7BN%7D%5Cmathbf%7BS%7D%5E%7BT%7D%5Cmathbf%7BT%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;epsilon=1-R,&#92;;&#92;;R = &#92;dfrac{1}{N}&#92;mathbf{S}^{T}&#92;mathbf{T} " class="latex" /></p>



<p>For the classic Boolean (Rosenblatt) Perceptron, the ST error  function is with the inverse (arc cosine) of the vector dot product between <strong>S </strong>and <strong>T</strong>:</p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=%5Cepsilon%3D%5Cfrac%7B1%7D%7B%5Cpi%7D%5Carccos%5C%3BR%2C%5C%3B%5C%3BR+%3D+%5Cdfrac%7B1%7D%7BN%7D%5Cmathbf%7BS%7D%5E%7BT%7D%5Cmathbf%7BT%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cepsilon%3D%5Cfrac%7B1%7D%7B%5Cpi%7D%5Carccos%5C%3BR%2C%5C%3B%5C%3BR+%3D+%5Cdfrac%7B1%7D%7BN%7D%5Cmathbf%7BS%7D%5E%7BT%7D%5Cmathbf%7BT%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cepsilon%3D%5Cfrac%7B1%7D%7B%5Cpi%7D%5Carccos%5C%3BR%2C%5C%3B%5C%3BR+%3D+%5Cdfrac%7B1%7D%7BN%7D%5Cmathbf%7BS%7D%5E%7BT%7D%5Cmathbf%7BT%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;epsilon=&#92;frac{1}{&#92;pi}&#92;arccos&#92;;R,&#92;;&#92;;R = &#92;dfrac{1}{N}&#92;mathbf{S}^{T}&#92;mathbf{T} " class="latex" /></p>



<p> If we just use the linear error model, then the quality of the Teacher is simply 1 minus the error, or, trivially , the ST overlap </p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BQ%7D_%7BT%7D%28R%29%3DR+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BQ%7D_%7BT%7D%28R%29%3DR+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathcal%7BQ%7D_%7BT%7D%28R%29%3DR+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathcal{Q}_{T}(R)=R " class="latex" />&nbsp;</p>



<p>To estimate the average total generalization quality of the Teacher, we write the total Quality as an integral over all possible Student matrices <strong>S</strong></p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BQ%7D_%7B%5Cmathbf%7BT%7D%7D%5Csimeq%5Cint+d%5Cmu%28%5Cmathbf%7BS%7D%29R%2C+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BQ%7D_%7B%5Cmathbf%7BT%7D%7D%5Csimeq%5Cint+d%5Cmu%28%5Cmathbf%7BS%7D%29R%2C+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathcal%7BQ%7D_%7B%5Cmathbf%7BT%7D%7D%5Csimeq%5Cint+d%5Cmu%28%5Cmathbf%7BS%7D%29R%2C+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathcal{Q}_{&#92;mathbf{T}}&#92;simeq&#92;int d&#92;mu(&#92;mathbf{S})R, " class="latex" /> </p>



<p>(and this will turn out to be an approximation to the Annealed Free Energy of the matrix-generalized Linear Percepton&#8230;stay tuned!)</p>



<p><strong>Fixing the Teacher:</strong> That&#8217;s it.  What&#8217;s so hard about this ?  Normally in Statistical Mechanics, one also has to average over all possible Teachers (T) that look the same &#8212; this complicates the story immensely.  What we have described this for a fixed Teacher, we will use this as a general formalism to derive the weightwatcher AlphaHat metric.</p>



<p><strong>Our Proposal:</strong>&nbsp; We let <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BS%7D%2C+%5Cmathbf%7BT%7D%5C&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BS%7D%2C+%5Cmathbf%7BT%7D%5C&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BS%7D%2C+%5Cmathbf%7BT%7D%5C&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{S}, &#92;mathbf{T}&#92;" class="latex" /> be strongly correlated (NxM) real matrices, with truncated, Heavy Tailed ESDs.  Specifically, we assume that we know the Teacher <strong>T</strong> weight matrices exactly, and seek all Student matrices <strong>S</strong> that have the same shape as <strong>T</strong> and the same average spectral properties as <strong>T</strong>.  That is still a lot of Students.</p>



<p>We can think of the class of Student matrices <strong>S</strong> as all matrices that are close to <strong>T</strong>.  What we really want is the best method for doing this, that has been tested experimentally.  Fortunately, Hinton and coworkers have recently revisited <a href="https://arxiv.org/abs/1905.00414">Similarity of Neural Network Representations</a>, and found the best matrix similarity method is</p>



<p class="has-text-align-left"><strong>Canonical Correlation Analysis (CCA):&nbsp;</strong> <img src="https://s0.wp.com/latex.php?latex=R%3D%5CVert%5Cmathbf%7BS%7D%5E%7BT%7D%5Cmathbf%7BT%7D%5CVert%5E%7B2%7D_%7BF%7D%3DTr%5B%28%5Cmathbf%7BS%7D%5E%7BT%7D%5Cmathbf%7BT%7D%29%5E%7B2%7D%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=R%3D%5CVert%5Cmathbf%7BS%7D%5E%7BT%7D%5Cmathbf%7BT%7D%5CVert%5E%7B2%7D_%7BF%7D%3DTr%5B%28%5Cmathbf%7BS%7D%5E%7BT%7D%5Cmathbf%7BT%7D%29%5E%7B2%7D%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=R%3D%5CVert%5Cmathbf%7BS%7D%5E%7BT%7D%5Cmathbf%7BT%7D%5CVert%5E%7B2%7D_%7BF%7D%3DTr%5B%28%5Cmathbf%7BS%7D%5E%7BT%7D%5Cmathbf%7BT%7D%29%5E%7B2%7D%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="R=&#92;Vert&#92;mathbf{S}^{T}&#92;mathbf{T}&#92;Vert^{2}_{F}=Tr[(&#92;mathbf{S}^{T}&#92;mathbf{T})^{2}]" class="latex" /> </p>



<p>Using CCA, we can formulate our new, Semi-Empirical Theory with the following conjectures</p>



<p><strong>Conjecture 1:</strong><em>  We can write the layer matrix contribution to the total average generalization error as an integral over all possible (random) matrices <strong>S</strong> that resemble the actual (pre-)trained weight matrices </em><strong>T</strong> (as given above),, such that</p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BQ%7D_%7B%5Cmathbf%7BT%7D%7D%5Csimeq%5Cint+d%5Cmu%28%5Cmathbf%7BS%7D%29%5Cleft%28Tr%5B%5Cmathbf%7BS%7D%5E%7BT%7D%5Cmathbf%7BT%7D%5D%5E%7B2%7D%5Cright%29%2C+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BQ%7D_%7B%5Cmathbf%7BT%7D%7D%5Csimeq%5Cint+d%5Cmu%28%5Cmathbf%7BS%7D%29%5Cleft%28Tr%5B%5Cmathbf%7BS%7D%5E%7BT%7D%5Cmathbf%7BT%7D%5D%5E%7B2%7D%5Cright%29%2C+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathcal%7BQ%7D_%7B%5Cmathbf%7BT%7D%7D%5Csimeq%5Cint+d%5Cmu%28%5Cmathbf%7BS%7D%29%5Cleft%28Tr%5B%5Cmathbf%7BS%7D%5E%7BT%7D%5Cmathbf%7BT%7D%5D%5E%7B2%7D%5Cright%29%2C+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathcal{Q}_{&#92;mathbf{T}}&#92;simeq&#92;int d&#92;mu(&#92;mathbf{S})&#92;left(Tr[&#92;mathbf{S}^{T}&#92;mathbf{T}]^{2}&#92;right), " class="latex" />&nbsp;</p>



<p><strong>Conjecture 2:</strong><em>  We </em>can express this integral in the Annealed Approximation (AA) which lets us re-express the log Quality in exponential form</p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BQ%7D_%7B%5Cmathbf%7BT%7D%7D%5Csimeq%5Clog%5Cint+d%5Cmu%28%5Cmathbf%7BS%7D%29%5Cexp%5Cleft%28Tr%5B%5Cmathbf%7BS%7D%5E%7BT%7D%5Cmathbf%7BT%7D%5D%5E%7B2%7D%5Cright%29%2C+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BQ%7D_%7B%5Cmathbf%7BT%7D%7D%5Csimeq%5Clog%5Cint+d%5Cmu%28%5Cmathbf%7BS%7D%29%5Cexp%5Cleft%28Tr%5B%5Cmathbf%7BS%7D%5E%7BT%7D%5Cmathbf%7BT%7D%5D%5E%7B2%7D%5Cright%29%2C+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathcal%7BQ%7D_%7B%5Cmathbf%7BT%7D%7D%5Csimeq%5Clog%5Cint+d%5Cmu%28%5Cmathbf%7BS%7D%29%5Cexp%5Cleft%28Tr%5B%5Cmathbf%7BS%7D%5E%7BT%7D%5Cmathbf%7BT%7D%5D%5E%7B2%7D%5Cright%29%2C+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathcal{Q}_{&#92;mathbf{T}}&#92;simeq&#92;log&#92;int d&#92;mu(&#92;mathbf{S})&#92;exp&#92;left(Tr[&#92;mathbf{S}^{T}&#92;mathbf{T}]^{2}&#92;right), " class="latex" />&nbsp;</p>



<p><strong>Conjecture 3:</strong><em>  We ca</em>n evaluate this integral over an Effective Correlation Space, spanned by the tail of the ESD, and such that we can replace the integral over all Student weight matrices <img src="https://s0.wp.com/latex.php?latex=d%5Cmu%28%5Cmathbf%7BS%7D%29+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d%5Cmu%28%5Cmathbf%7BS%7D%29+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d%5Cmu%28%5Cmathbf%7BS%7D%29+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d&#92;mu(&#92;mathbf{S}) " class="latex" /> with an integral over all Student Correlation matrices <img src="https://s0.wp.com/latex.php?latex=d%5Cmu%28%5Cmathbf%7BA%7D%29+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d%5Cmu%28%5Cmathbf%7BA%7D%29+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d%5Cmu%28%5Cmathbf%7BA%7D%29+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d&#92;mu(&#92;mathbf{A}) " class="latex" />, where <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BA%7D%3D%5Cmathbf%7BS%7D%5E%7BT%7D%5Cmathbf%7BS%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BA%7D%3D%5Cmathbf%7BS%7D%5E%7BT%7D%5Cmathbf%7BS%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BA%7D%3D%5Cmathbf%7BS%7D%5E%7BT%7D%5Cmathbf%7BS%7D+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{A}=&#92;mathbf{S}^{T}&#92;mathbf{S} " class="latex" /> giving</p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BQ%7D_%7B%5Cmathbf%7BT%7D%7D%5Csimeq%5Clog%5Cint+d%5Cmu%28%5Cmathbf%7BA%7D%29%5Cexp%5Cleft%28Tr%5B%5Cmathbf%7BT%7D%5E%7BT%7D%5Cmathbf%7BA%7D%5Cmathbf%7BT%7D%5D%5Cright%29%2C+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BQ%7D_%7B%5Cmathbf%7BT%7D%7D%5Csimeq%5Clog%5Cint+d%5Cmu%28%5Cmathbf%7BA%7D%29%5Cexp%5Cleft%28Tr%5B%5Cmathbf%7BT%7D%5E%7BT%7D%5Cmathbf%7BA%7D%5Cmathbf%7BT%7D%5D%5Cright%29%2C+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathcal%7BQ%7D_%7B%5Cmathbf%7BT%7D%7D%5Csimeq%5Clog%5Cint+d%5Cmu%28%5Cmathbf%7BA%7D%29%5Cexp%5Cleft%28Tr%5B%5Cmathbf%7BT%7D%5E%7BT%7D%5Cmathbf%7BA%7D%5Cmathbf%7BT%7D%5D%5Cright%29%2C+&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathcal{Q}_{&#92;mathbf{T}}&#92;simeq&#92;log&#92;int d&#92;mu(&#92;mathbf{A})&#92;exp&#92;left(Tr[&#92;mathbf{T}^{T}&#92;mathbf{A}&#92;mathbf{T}]&#92;right), " class="latex" />&nbsp;</p>



<p>We explain these in more detail below</p>



<h3>RMT and HCIZ Integrals</h3>



<p>These kinds of integrals traditionally appeared in Quantum Field Theory and String Theory, but also in the context of<a href="https://arxiv.org/abs/cond-mat/9801209"> Random Matrix applied to Levy Spin Glasses</a>,  And it is this early work on Heavy-Tailed Random Matrices that has motivated our empirical work. Here, to complement and extend our studies, we lay out an (incomplete) overview of the Theory.</p>



<p>These integrals are called Harish Chandra&#8211;Itzykson&#8211;Zuber (<em>HCIZ</em>)&nbsp;integrals.  A good introductory reference on both RMT and HCIZ integrals the recent book <a href="https://physics-complex-systems.fr/wp-content/uploads/2019/03/Notes_chap1-13.pdf">&#8220;A First Course in Random Matrix Theory&#8221;</a>, although we will base our analysis here on the results of the <a href="https://iopscience.iop.org/article/10.1088/1742-6596/95/1/012002/pdf">2008 paper by Tanaka,</a> </p>



<p>First, we need to re-arrange a little of the algebra. We will call <strong>A</strong> the Student correlation matrix:</p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BA%7D+%3D%5Cfrac%7B1%7D%7BN%7D%5Cmathbf%7BS%7D%5E%7BT%7D%5Cmathbf%7BS%7D++&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BA%7D+%3D%5Cfrac%7B1%7D%7BN%7D%5Cmathbf%7BS%7D%5E%7BT%7D%5Cmathbf%7BS%7D++&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BA%7D+%3D%5Cfrac%7B1%7D%7BN%7D%5Cmathbf%7BS%7D%5E%7BT%7D%5Cmathbf%7BS%7D++&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{A} =&#92;frac{1}{N}&#92;mathbf{S}^{T}&#92;mathbf{S}  " class="latex" /></p>



<p>and let <strong>W</strong>, <strong>X</strong> be the original weight and correlation matrices for our pretrained DNN, as above:</p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D+%3D%5Cfrac%7B1%7D%7BN%7D%5Cmathbf%7BW%7D%5E%7BT%7D%5Cmathbf%7BW%7D%2C%5C%3B%5C%3B%5Cmathbf%7BX%7D%7B%5Cmathbf%7Be%7D%7D%3D%5Clambda%7B%5Cmathbf%7Be%7D%7D++&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D+%3D%5Cfrac%7B1%7D%7BN%7D%5Cmathbf%7BW%7D%5E%7BT%7D%5Cmathbf%7BW%7D%2C%5C%3B%5C%3B%5Cmathbf%7BX%7D%7B%5Cmathbf%7Be%7D%7D%3D%5Clambda%7B%5Cmathbf%7Be%7D%7D++&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D+%3D%5Cfrac%7B1%7D%7BN%7D%5Cmathbf%7BW%7D%5E%7BT%7D%5Cmathbf%7BW%7D%2C%5C%3B%5C%3B%5Cmathbf%7BX%7D%7B%5Cmathbf%7Be%7D%7D%3D%5Clambda%7B%5Cmathbf%7Be%7D%7D++&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{X} =&#92;frac{1}{N}&#92;mathbf{W}^{T}&#92;mathbf{W},&#92;;&#92;;&#92;mathbf{X}{&#92;mathbf{e}}=&#92;lambda{&#92;mathbf{e}}  " class="latex" />,  </p>



<p>and then expand the CCA Similarity metric as</p>



<p class="has-text-align-center"> <img src="https://s0.wp.com/latex.php?latex=Tr%5B%28%5Cmathbf%7BS%7D%5E%7BT%7D%5Cmathbf%7BW%7D%29%5E%7B2%7D%5D%3DTr%5B%5Cmathbf%7BW%7D%5E%7BT%7D%5Cmathbf%7BA%7D%5Cmathbf%7BW%7D%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=Tr%5B%28%5Cmathbf%7BS%7D%5E%7BT%7D%5Cmathbf%7BW%7D%29%5E%7B2%7D%5D%3DTr%5B%5Cmathbf%7BW%7D%5E%7BT%7D%5Cmathbf%7BA%7D%5Cmathbf%7BW%7D%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=Tr%5B%28%5Cmathbf%7BS%7D%5E%7BT%7D%5Cmathbf%7BW%7D%29%5E%7B2%7D%5D%3DTr%5B%5Cmathbf%7BW%7D%5E%7BT%7D%5Cmathbf%7BA%7D%5Cmathbf%7BW%7D%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="Tr[(&#92;mathbf{S}^{T}&#92;mathbf{W})^{2}]=Tr[&#92;mathbf{W}^{T}&#92;mathbf{A}&#92;mathbf{W}]" class="latex" /> </p>



<p>We can now express the log HCIZ integral, in using Tanaka&#8217;s result, as an expectation value of all random Student correlations matrices <strong>A</strong> that <em>resemble</em> <strong>X</strong>.  </p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=%5Cunderset%7BN%5Crightarrow%5Cinfty%7D%7Blim%7D%5Cdfrac%7B1%7D%7BN%7D%5Clog%5C%3B%5Cmathbb%7BE%7D_%7BA%7D%5Cleft%5Bexp%5Cleft%28%5Cdfrac%7B%5Cbeta%7D%7B2%7DTr%5B%5Cmathbf%7BW%7D%5E%7BT%7D%5Cmathbf%7BA%7D%5Cmathbf%7BW%7D%5D%5Cright%29%5Cright%5D%3D%5Cdfrac%7B%5Cbeta%7D%7B2%7D%5Csum%5Climits_%7Bi%3D1%7D%5E%7BM%7D%5C%3BG_%7BA%7D%28%5Clambda_i%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cunderset%7BN%5Crightarrow%5Cinfty%7D%7Blim%7D%5Cdfrac%7B1%7D%7BN%7D%5Clog%5C%3B%5Cmathbb%7BE%7D_%7BA%7D%5Cleft%5Bexp%5Cleft%28%5Cdfrac%7B%5Cbeta%7D%7B2%7DTr%5B%5Cmathbf%7BW%7D%5E%7BT%7D%5Cmathbf%7BA%7D%5Cmathbf%7BW%7D%5D%5Cright%29%5Cright%5D%3D%5Cdfrac%7B%5Cbeta%7D%7B2%7D%5Csum%5Climits_%7Bi%3D1%7D%5E%7BM%7D%5C%3BG_%7BA%7D%28%5Clambda_i%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cunderset%7BN%5Crightarrow%5Cinfty%7D%7Blim%7D%5Cdfrac%7B1%7D%7BN%7D%5Clog%5C%3B%5Cmathbb%7BE%7D_%7BA%7D%5Cleft%5Bexp%5Cleft%28%5Cdfrac%7B%5Cbeta%7D%7B2%7DTr%5B%5Cmathbf%7BW%7D%5E%7BT%7D%5Cmathbf%7BA%7D%5Cmathbf%7BW%7D%5D%5Cright%29%5Cright%5D%3D%5Cdfrac%7B%5Cbeta%7D%7B2%7D%5Csum%5Climits_%7Bi%3D1%7D%5E%7BM%7D%5C%3BG_%7BA%7D%28%5Clambda_i%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;underset{N&#92;rightarrow&#92;infty}{lim}&#92;dfrac{1}{N}&#92;log&#92;;&#92;mathbb{E}_{A}&#92;left[exp&#92;left(&#92;dfrac{&#92;beta}{2}Tr[&#92;mathbf{W}^{T}&#92;mathbf{A}&#92;mathbf{W}]&#92;right)&#92;right]=&#92;dfrac{&#92;beta}{2}&#92;sum&#92;limits_{i=1}^{M}&#92;;G_{A}(&#92;lambda_i)" class="latex" /> </p>



<p>And this can be expressed as a sum over Generating functions <img src="https://s0.wp.com/latex.php?latex=G_%7BA%7D%28%5Clambda%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=G_%7BA%7D%28%5Clambda%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=G_%7BA%7D%28%5Clambda%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="G_{A}(&#92;lambda)" class="latex" />  that depends only the statistical properties of the random Student weight matrices <strong>A</strong>.  Specifically</p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=G_%7BA%7D%28%5Clambda%29%3A%3D%5Cint%5Climits_%7B0%7D%5E%7B%5Clambda%7DR_%7BA%7D%28z%29dz&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=G_%7BA%7D%28%5Clambda%29%3A%3D%5Cint%5Climits_%7B0%7D%5E%7B%5Clambda%7DR_%7BA%7D%28z%29dz&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=G_%7BA%7D%28%5Clambda%29%3A%3D%5Cint%5Climits_%7B0%7D%5E%7B%5Clambda%7DR_%7BA%7D%28z%29dz&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="G_{A}(&#92;lambda):=&#92;int&#92;limits_{0}^{&#92;lambda}R_{A}(z)dz" class="latex" /></p>



<p>where <img src="https://s0.wp.com/latex.php?latex=R_%7BA%7D%28%5Clambda%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=R_%7BA%7D%28%5Clambda%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=R_%7BA%7D%28%5Clambda%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="R_{A}(&#92;lambda)" class="latex" /> is the R-Transform from RMT.  </p>



<p><strong>The R Transform</strong> is like an inverse Green&#8217;s function (i.e a Contour Integral), and is also a cumulant generating function.  As such, we can write <img src="https://s0.wp.com/latex.php?latex=R%28z%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=R%28z%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=R%28z%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="R(z)" class="latex" />  as a series expansion</p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=R%28z%29%3D%5Csum%5Climits_%7Bk%3D1%7D%5E%7B%5Cinfty%7Dc_%7Bk%7Dz%5E%7Bk-1%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=R%28z%29%3D%5Csum%5Climits_%7Bk%3D1%7D%5E%7B%5Cinfty%7Dc_%7Bk%7Dz%5E%7Bk-1%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=R%28z%29%3D%5Csum%5Climits_%7Bk%3D1%7D%5E%7B%5Cinfty%7Dc_%7Bk%7Dz%5E%7Bk-1%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="R(z)=&#92;sum&#92;limits_{k=1}^{&#92;infty}c_{k}z^{k-1}" class="latex" /> </p>



<p>where <img src="https://s0.wp.com/latex.php?latex=c_%7Bk%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c_%7Bk%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c_%7Bk%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c_{k}" class="latex" />  are <strong><em>Generalized Cumulants </em></strong>from RMT.</p>



<p>Now, since we expect the best  Students matrices <em>resemble</em> the  Teacher matrices, we expect the Student correlation matrix <strong>A</strong> to have similar spectral properties as our actual correlation matrices <strong>X</strong>.  And this where we can use our classification of the<em><strong> 5+1 Phases of Training</strong></em>.  Whatever phase <strong>X</strong> is in, we expect all the <strong>A</strong> to be in as well, and we therefore expect the R-Transform of <strong>A</strong> to have the same functional form as <strong>X</strong>.  </p>



<p>That is, if our DNN weight matrix has a Heavy Tailed ESD</p>



<p class="has-text-align-center"> <img src="https://s0.wp.com/latex.php?latex=%5Crho_%7BX%7D%28%5Clambda%29%5Csim%5Clambda%5E%7B-%5Calpha%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Crho_%7BX%7D%28%5Clambda%29%5Csim%5Clambda%5E%7B-%5Calpha%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Crho_%7BX%7D%28%5Clambda%29%5Csim%5Clambda%5E%7B-%5Calpha%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;rho_{X}(&#92;lambda)&#92;sim&#92;lambda^{-&#92;alpha}" class="latex" /> </p>



<p>then we expect all of the students to likewise have a Heavy Tailed ESD, and with the same exponent (at least for now).</p>



<p class="has-text-align-center"> <img src="https://s0.wp.com/latex.php?latex=%5Crho_%7BA%7D%28%5Clambda%29%5Csim%5Clambda%5E%7B-%5Calpha%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Crho_%7BA%7D%28%5Clambda%29%5Csim%5Clambda%5E%7B-%5Calpha%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Crho_%7BA%7D%28%5Clambda%29%5Csim%5Clambda%5E%7B-%5Calpha%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;rho_{A}(&#92;lambda)&#92;sim&#92;lambda^{-&#92;alpha}" class="latex" /> </p>



<p><strong>Quenched </strong> <strong>vs Annealed Averages</strong></p>



<p>Formally, we just say we are averaging over all Students <strong>A</strong>.  More technically, what really want to do is fix some Student matrix (i.e. say <strong>A</strong> =  diagonal <strong>X</strong>), and then  integrate over all possible Orthogonal transformations <strong>O </strong>of <strong>A</strong> (see 6.2.3 of Potters and Bouchaud)</p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BE%7D%5Cleft%5B%5Clog%5Cleft%5Clangle%5Cexp%5Cleft%28%5Cdfrac%7B%5Cbeta%7D%7B2%7DTr%5B%5Cmathbf%7BW%7D%5E%7BT%7D%5Cmathbf%7BO%7D%5E%7BT%7D%5Cmathbf%7BA%7D%5Cmathbf%7BOW%7D%5D%5Cright%29%5Cright%5Crangle_%7B%5Cmathbf%7BO%7D%7D%5Cright%5D_%7B%5Cmathbf%7BA%7D%7D%5Csimeq%5Clog%5Cmathbb%7BE%7D%5Cleft%5B%5Cexp%5Cleft%28%5Cdfrac%7B%5Cbeta%7D%7B2%7DTr%5B%5Cmathbf%7BW%7D%5E%7BT%7D%5Cmathbf%7BA%7D%5Cmathbf%7BW%7D%5D%5Cright%29%5Cright%5D_%7B%5Cmathbf%7BA%7D%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BE%7D%5Cleft%5B%5Clog%5Cleft%5Clangle%5Cexp%5Cleft%28%5Cdfrac%7B%5Cbeta%7D%7B2%7DTr%5B%5Cmathbf%7BW%7D%5E%7BT%7D%5Cmathbf%7BO%7D%5E%7BT%7D%5Cmathbf%7BA%7D%5Cmathbf%7BOW%7D%5D%5Cright%29%5Cright%5Crangle_%7B%5Cmathbf%7BO%7D%7D%5Cright%5D_%7B%5Cmathbf%7BA%7D%7D%5Csimeq%5Clog%5Cmathbb%7BE%7D%5Cleft%5B%5Cexp%5Cleft%28%5Cdfrac%7B%5Cbeta%7D%7B2%7DTr%5B%5Cmathbf%7BW%7D%5E%7BT%7D%5Cmathbf%7BA%7D%5Cmathbf%7BW%7D%5D%5Cright%29%5Cright%5D_%7B%5Cmathbf%7BA%7D%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb%7BE%7D%5Cleft%5B%5Clog%5Cleft%5Clangle%5Cexp%5Cleft%28%5Cdfrac%7B%5Cbeta%7D%7B2%7DTr%5B%5Cmathbf%7BW%7D%5E%7BT%7D%5Cmathbf%7BO%7D%5E%7BT%7D%5Cmathbf%7BA%7D%5Cmathbf%7BOW%7D%5D%5Cright%29%5Cright%5Crangle_%7B%5Cmathbf%7BO%7D%7D%5Cright%5D_%7B%5Cmathbf%7BA%7D%7D%5Csimeq%5Clog%5Cmathbb%7BE%7D%5Cleft%5B%5Cexp%5Cleft%28%5Cdfrac%7B%5Cbeta%7D%7B2%7DTr%5B%5Cmathbf%7BW%7D%5E%7BT%7D%5Cmathbf%7BA%7D%5Cmathbf%7BW%7D%5D%5Cright%29%5Cright%5D_%7B%5Cmathbf%7BA%7D%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb{E}&#92;left[&#92;log&#92;left&#92;langle&#92;exp&#92;left(&#92;dfrac{&#92;beta}{2}Tr[&#92;mathbf{W}^{T}&#92;mathbf{O}^{T}&#92;mathbf{A}&#92;mathbf{OW}]&#92;right)&#92;right&#92;rangle_{&#92;mathbf{O}}&#92;right]_{&#92;mathbf{A}}&#92;simeq&#92;log&#92;mathbb{E}&#92;left[&#92;exp&#92;left(&#92;dfrac{&#92;beta}{2}Tr[&#92;mathbf{W}^{T}&#92;mathbf{A}&#92;mathbf{W}]&#92;right)&#92;right]_{&#92;mathbf{A}}" class="latex" /> </p>



<p>Then, we integrate over all possible<strong> A</strong>~diag(<strong>X</strong>) , which would account for fluctuations in the eigenvalues.  We conceptually assume this is the same as integrating over all possible Students <strong>A</strong>, and then taking the log.  </p>



<p>The LHS is called the Quenched Average, and the RHS is the Annealed.  Technically, they are not the same, and in traditional Stat Mech theory, this makes a big difference.  In fact, in the original Student-Teacher model, we would also average over all Teachers, chosen uniformly (to satisfy the spherical constraints)</p>



<p>Here, we are doing RMT a little differently, which may not be obvious until the end of the calculation. We do not assume a priori a model for the Student matrices.  That is, instead of fixing <strong>A</strong>=diag(<strong>X</strong>), we will fit the  ESD of <strong>X</strong> to a <em>continuous</em> (power law) distribution <img src="https://s0.wp.com/latex.php?latex=%5Crho_%7BX%7D%28%5Clambda%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Crho_%7BX%7D%28%5Clambda%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Crho_%7BX%7D%28%5Clambda%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;rho_{X}(&#92;lambda)" class="latex" /> , and then <em>effectively sample</em> over all <strong>A</strong> as if we had drawn the eigenvalues of <strong>A</strong> from <img src="https://s0.wp.com/latex.php?latex=%5Crho_%7BX%7D%28%5Clambda%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Crho_%7BX%7D%28%5Clambda%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Crho_%7BX%7D%28%5Clambda%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;rho_{X}(&#92;lambda)" class="latex" />. (In fact, I suppose we could actually do this numerically instead of doing all this fancy math&#8211;but what fun is that?).</p>



<p>The point is, we want to find an expression for the HCIZ integral (i.e the layer / matrix contribution to the Generalization Error) that only depends on observations of <strong>W</strong>, the weight matrix of the pretrained DNN (our Teacher network).  The result only depends on the eigenvalues of <strong>X</strong>, and the R-transform of <strong>A</strong> , which is parameterized by statistical information from<strong> X</strong>.  </p>



<p>In principle, I supposed we could measure the generalized cumulants <img src="https://s0.wp.com/latex.php?latex=%28c_%7Bk%7D%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28c_%7Bk%7D%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28c_%7Bk%7D%29&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(c_{k})" class="latex" /> of <strong>X</strong>,. and assume we can plug these in for <img src="https://s0.wp.com/latex.php?latex=R_%7BA%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=R_%7BA%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=R_%7BA%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="R_{A}" class="latex" />.  We will do something a little easier.</p>



<p>Let us consider 2 classes of matrices as models for <strong>X.</strong>  </p>



<p><strong>Gaussian (Wigner) Random Matrix:  </strong>Random-Like Phase</p>



<p>The R-Transform for Gaussian Random matrix is well known:</p>



<p class="has-text-align-center"> <img src="https://s0.wp.com/latex.php?latex=R%28z%29%3Dz&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=R%28z%29%3Dz&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=R%28z%29%3Dz&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="R(z)=z" class="latex" /> </p>



<p>Taking the integral and plugging this into the Generating function, we get</p>



<p class="has-text-align-center"> <img src="https://s0.wp.com/latex.php?latex=G_%7BA%7D%28%5Clambda_%7Bi%7D%29%3D%5Cfrac%7B1%7D%7B2%7Dz%5E%7B2%7D%5Cbigg%7C_%7Bz%3D0%7D%5E%7Bz%3D%5Clambda_i%7D%3D%5Cfrac%7B1%7D%7B2%7D%5Clambda%5E%7B2%7D_%7Bi%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=G_%7BA%7D%28%5Clambda_%7Bi%7D%29%3D%5Cfrac%7B1%7D%7B2%7Dz%5E%7B2%7D%5Cbigg%7C_%7Bz%3D0%7D%5E%7Bz%3D%5Clambda_i%7D%3D%5Cfrac%7B1%7D%7B2%7D%5Clambda%5E%7B2%7D_%7Bi%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=G_%7BA%7D%28%5Clambda_%7Bi%7D%29%3D%5Cfrac%7B1%7D%7B2%7Dz%5E%7B2%7D%5Cbigg%7C_%7Bz%3D0%7D%5E%7Bz%3D%5Clambda_i%7D%3D%5Cfrac%7B1%7D%7B2%7D%5Clambda%5E%7B2%7D_%7Bi%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="G_{A}(&#92;lambda_{i})=&#92;frac{1}{2}z^{2}&#92;bigg|_{z=0}^{z=&#92;lambda_i}=&#92;frac{1}{2}&#92;lambda^{2}_{i}" class="latex" /> </p>



<p class="has-text-align-center"> <img src="https://s0.wp.com/latex.php?latex=%5Csum%5Climits_%7Bi%3D1%7D%5E%7BM%7D%5C%3BG_%7BA%7D%28%5Clambda_i%29%3D%5Cfrac%7B1%7D%7B2%7D%5Csum%5Climits_%7Bi%3D1%7D%5E%7BM%7D%5Clambda%5E%7B2%7D_%7Bi%7D%3D%5Cfrac%7B1%7D%7B2%7DTr%5B%5Cmathbf%7BA%7D%5E%7B2%7D%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Csum%5Climits_%7Bi%3D1%7D%5E%7BM%7D%5C%3BG_%7BA%7D%28%5Clambda_i%29%3D%5Cfrac%7B1%7D%7B2%7D%5Csum%5Climits_%7Bi%3D1%7D%5E%7BM%7D%5Clambda%5E%7B2%7D_%7Bi%7D%3D%5Cfrac%7B1%7D%7B2%7DTr%5B%5Cmathbf%7BA%7D%5E%7B2%7D%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Csum%5Climits_%7Bi%3D1%7D%5E%7BM%7D%5C%3BG_%7BA%7D%28%5Clambda_i%29%3D%5Cfrac%7B1%7D%7B2%7D%5Csum%5Climits_%7Bi%3D1%7D%5E%7BM%7D%5Clambda%5E%7B2%7D_%7Bi%7D%3D%5Cfrac%7B1%7D%7B2%7DTr%5B%5Cmathbf%7BA%7D%5E%7B2%7D%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;sum&#92;limits_{i=1}^{M}&#92;;G_{A}(&#92;lambda_i)=&#92;frac{1}{2}&#92;sum&#92;limits_{i=1}^{M}&#92;lambda^{2}_{i}=&#92;frac{1}{2}Tr[&#92;mathbf{A}^{2}]" class="latex" /> </p>



<p>So when <strong>X</strong> is Random-Like , the layer / matrix contribution is like the Frobenius Norm (but squared), and thus average Generalization Error is given by a Frobenius Product Norm (squared).  Thing is, this is never observed in any production model, as every single model we have examined has a Heavy-Tailed ESD.  So we need something else.</p>



<p><strong>Levy Random Matrix:  </strong> Very Heavy Tailed Phase&#8211;but with <img src="https://s0.wp.com/latex.php?latex=%5Calpha+%3C+3&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha+%3C+3&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha+%3C+3&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha &lt; 3" class="latex" /></p>



<p><a href="https://arxiv.org/abs/1901.08278">Aswe have argued previously</a>, due to finite size effects, we expect that the Very Heavy Tailed matrices appearing in DNNs will more resemble Levy Random matrices that the Random-Like Phase.  So for now, we will close one eye and extend the results for <img src="https://s0.wp.com/latex.php?latex=%5Calpha+%3C+3&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha+%3C+3&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha+%3C+3&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha &lt; 3" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=%5Calpha%5Cin%5B2%2C6%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha%5Cin%5B2%2C6%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha%5Cin%5B2%2C6%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha&#92;in[2,6]" class="latex" />.  </p>



<p>The R-Transform for a Levy Random Matrix has been given by <a href="https://arxiv.org/abs/0909.5228">Burda</a></p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=R%28z%29%3Dz%5E%7B%5Calpha-1%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=R%28z%29%3Dz%5E%7B%5Calpha-1%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=R%28z%29%3Dz%5E%7B%5Calpha-1%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="R(z)=z^{&#92;alpha-1}" class="latex" /> </p>



<p class="has-text-align-left">Taking the integral and plugging this into the Generating function, we get</p>



<p class="has-text-align-center"> <img src="https://s0.wp.com/latex.php?latex=G_%7BA%7D%28%5Clambda_%7Bi%7D%29%3D%5Cfrac%7B1%7D%7B%5Calpha%7Dz%5E%7B%5Calpha%7D%5Cbigg%7C_%7Bz%3D0%7D%5E%7Bz%3D%5Clambda_i%7D%3D%5Cfrac%7B1%7D%7B%5Calpha%7D%5Clambda%5E%7B%5Calpha%7D_%7Bi%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=G_%7BA%7D%28%5Clambda_%7Bi%7D%29%3D%5Cfrac%7B1%7D%7B%5Calpha%7Dz%5E%7B%5Calpha%7D%5Cbigg%7C_%7Bz%3D0%7D%5E%7Bz%3D%5Clambda_i%7D%3D%5Cfrac%7B1%7D%7B%5Calpha%7D%5Clambda%5E%7B%5Calpha%7D_%7Bi%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=G_%7BA%7D%28%5Clambda_%7Bi%7D%29%3D%5Cfrac%7B1%7D%7B%5Calpha%7Dz%5E%7B%5Calpha%7D%5Cbigg%7C_%7Bz%3D0%7D%5E%7Bz%3D%5Clambda_i%7D%3D%5Cfrac%7B1%7D%7B%5Calpha%7D%5Clambda%5E%7B%5Calpha%7D_%7Bi%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="G_{A}(&#92;lambda_{i})=&#92;frac{1}{&#92;alpha}z^{&#92;alpha}&#92;bigg|_{z=0}^{z=&#92;lambda_i}=&#92;frac{1}{&#92;alpha}&#92;lambda^{&#92;alpha}_{i}" class="latex" /> </p>



<p class="has-text-align-center"> <img src="https://s0.wp.com/latex.php?latex=%5Csum%5Climits_%7Bi%3D1%7D%5E%7BM%7D%5C%3BG_%7BA%7D%28%5Clambda_i%29%3D%5Cfrac%7B1%7D%7B%5Calpha%7DTr%5B%5Cmathbf%7BA%7D%5E%7B%5Calpha%7D%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Csum%5Climits_%7Bi%3D1%7D%5E%7BM%7D%5C%3BG_%7BA%7D%28%5Clambda_i%29%3D%5Cfrac%7B1%7D%7B%5Calpha%7DTr%5B%5Cmathbf%7BA%7D%5E%7B%5Calpha%7D%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Csum%5Climits_%7Bi%3D1%7D%5E%7BM%7D%5C%3BG_%7BA%7D%28%5Clambda_i%29%3D%5Cfrac%7B1%7D%7B%5Calpha%7DTr%5B%5Cmathbf%7BA%7D%5E%7B%5Calpha%7D%5D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;sum&#92;limits_{i=1}^{M}&#92;;G_{A}(&#92;lambda_i)=&#92;frac{1}{&#92;alpha}Tr[&#92;mathbf{A}^{&#92;alpha}]" class="latex" /></p>



<p><strong>Towards our Heavy Tailed Quality Metric</strong></p>



<p>1. Let us pull the power law exponent <img src="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha" class="latex" />  out of the Trace, effectively ignoring cross terms in the sum over <img src="https://s0.wp.com/latex.php?latex=%5Clambda%5E%7B%5Calpha%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clambda%5E%7B%5Calpha%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda%5E%7B%5Calpha%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lambda^{&#92;alpha}" class="latex" />  </p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=Tr%5B%5Cmathbf%7BA%7D%5E%7B%5Calpha%7D%5D%5Csimeq+Tr%5B%5Cmathbf%7BA%7D%5D%5E%7B%5Calpha%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=Tr%5B%5Cmathbf%7BA%7D%5E%7B%5Calpha%7D%5D%5Csimeq+Tr%5B%5Cmathbf%7BA%7D%5D%5E%7B%5Calpha%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=Tr%5B%5Cmathbf%7BA%7D%5E%7B%5Calpha%7D%5D%5Csimeq+Tr%5B%5Cmathbf%7BA%7D%5D%5E%7B%5Calpha%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="Tr[&#92;mathbf{A}^{&#92;alpha}]&#92;simeq Tr[&#92;mathbf{A}]^{&#92;alpha}" class="latex" /></p>



<p>2. We also assume we can replace the Trace of <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BA%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BA%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbf%7BA%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbf{A}" class="latex" />   with its largest eigenvalue <img src="https://s0.wp.com/latex.php?latex=%5Clambda_%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clambda_%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda_%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lambda_{max}" class="latex" /> , which is  actually a good approximation for very heavy tailed Levy matrices, when <img src="https://s0.wp.com/latex.php?latex=%5Calpha%5Cll+2&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha%5Cll+2&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha%5Cll+2&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha&#92;ll 2" class="latex" />  </p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=Tr%5B%5Cmathbf%7BA%7D%5D%3D%5Csum%5Clambda_%7Bi%7D%5Csimeq+%5Clambda_%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=Tr%5B%5Cmathbf%7BA%7D%5D%3D%5Csum%5Clambda_%7Bi%7D%5Csimeq+%5Clambda_%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=Tr%5B%5Cmathbf%7BA%7D%5D%3D%5Csum%5Clambda_%7Bi%7D%5Csimeq+%5Clambda_%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="Tr[&#92;mathbf{A}]=&#92;sum&#92;lambda_{i}&#92;simeq &#92;lambda_{max}" class="latex" /></p>



<p>This gives an simple expression for the HCIZ integral expression for the layer contribution to the generalization error</p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=%5Csum%5Climits_%7Bi%3D1%7D%5E%7BM%7D%5C%3BG_%7BA%7D%28%5Clambda_i%29%5Csimeq%5Clambda_%7Bmax%7D%5E%7B%5Calpha%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Csum%5Climits_%7Bi%3D1%7D%5E%7BM%7D%5C%3BG_%7BA%7D%28%5Clambda_i%29%5Csimeq%5Clambda_%7Bmax%7D%5E%7B%5Calpha%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Csum%5Climits_%7Bi%3D1%7D%5E%7BM%7D%5C%3BG_%7BA%7D%28%5Clambda_i%29%5Csimeq%5Clambda_%7Bmax%7D%5E%7B%5Calpha%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;sum&#92;limits_{i=1}^{M}&#92;;G_{A}(&#92;lambda_i)&#92;simeq&#92;lambda_{max}^{&#92;alpha}" class="latex" /></p>



<p>Taking the logarithm  of both sides, gives our expression</p>



<p class="has-text-align-center has-normal-font-size"><img src="https://s0.wp.com/latex.php?latex=log%5Csum%5Climits_%7Bi%3D1%7D%5E%7BM%7D%5C%3BG_%7BA%7D%28%5Clambda_i%29%5Csimeq%5C%3B%5Calpha%5Clog%5Clambda_%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=log%5Csum%5Climits_%7Bi%3D1%7D%5E%7BM%7D%5C%3BG_%7BA%7D%28%5Clambda_i%29%5Csimeq%5C%3B%5Calpha%5Clog%5Clambda_%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=log%5Csum%5Climits_%7Bi%3D1%7D%5E%7BM%7D%5C%3BG_%7BA%7D%28%5Clambda_i%29%5Csimeq%5C%3B%5Calpha%5Clog%5Clambda_%7Bmax%7D&#038;bg=ffffff&#038;fg=%23000000&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="log&#92;sum&#92;limits_{i=1}^{M}&#92;;G_{A}(&#92;lambda_i)&#92;simeq&#92;;&#92;alpha&#92;log&#92;lambda_{max}" class="latex" /></p>



<p>We have now derived the our Heavy Tailed Quality metric using a matrix generalization of the classic Student Teacher model, with the help of some modern Random Matrix Theory.  </p>



<p><strong>QED</strong></p>



<p>I hope this has convince you that there is still a lot of very interesting theory to develop for AI / Deep Neural Networks.   And that you will stay tuned for the published form of this work.  And remember&#8230;</p>



<p class="has-text-align-center"><code>pip install weightwatcher</code></p>



<p>A big thanks to <a href="https://www.stat.berkeley.edu/~mmahoney/">Michael Mahoney at UC Berkeley</a> for collaborating with me on this work , and to <a href="https://www.linkedin.com/in/mircomilletari/">Mirco Milletari’</a> (Microsoft), who has been extremely helpful.  And to my good friend <a href="https://www.linkedin.com/in/matthew-w-lee/">Matt Lee</a> (Triaxiom Capital, LLC) for long discussions about theoretical physics, RMT, quant finance, etc., , and for encouraging me to publish this.</p>



<p></p>



<p>And here&#8217;s the Empirical Evidence that this actually works:</p>



<p> <a href="https://www.nature.com/articles/s41467-021-24025-8" rel="nofollow">https://www.nature.com/articles/s41467-021-24025-8</a></p>



<p class="has-text-align-left"><strong>If you have gotten this far,</strong></p>



<p>and would be willing to read the draft of the real theory paper, that would be great.  Please just email me or ping me on Linkedin</p>



<p></p>
]]></content:encoded>
					
					<wfw:commentRss>https://calculatedcontent.com/2019/12/03/towards-a-new-theory-of-learning-statistical-mechanics-of-deep-neural-networks/feed/</wfw:commentRss>
			<slash:comments>1</slash:comments>
		
		
		
		<media:thumbnail url="https://charlesmartin14.files.wordpress.com/2019/11/screen-shot-2019-11-29-at-10.28.02-pm.png" />
		<media:content url="https://charlesmartin14.files.wordpress.com/2019/11/screen-shot-2019-11-29-at-10.28.02-pm.png" medium="image">
			<media:title type="html">screen-shot-2019-11-29-at-10.28.02-pm</media:title>
		</media:content>

		<media:content url="https://1.gravatar.com/avatar/1ae78e5099a40f308b172a5a65416cab?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">charlesmartin14</media:title>
		</media:content>

		<media:content url="https://charlesmartin14.files.wordpress.com/2019/11/screen-shot-2019-11-29-at-10.28.02-pm.png?w=1024" medium="image" />

		<media:content url="https://github.com/CalculatedContent/PredictingTestAccuracies/raw/master/img/vgg-w_alphas.png" medium="image">
			<media:title type="html">alt text</media:title>
		</media:content>

		<media:content url="https://charlesmartin14.files.wordpress.com/2019/11/student-teacher.png?w=1024" medium="image" />
	</item>
	</channel>
</rss>
