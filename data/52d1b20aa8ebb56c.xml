<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	xmlns:georss="http://www.georss.org/georss" xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#" xmlns:media="http://search.yahoo.com/mrss/"
	>

<channel>
	<title>wellecks</title>
	<atom:link href="https://wellecks.wordpress.com/feed/" rel="self" type="application/rss+xml" />
	<link>https://wellecks.wordpress.com</link>
	<description>some thoughts &#38; ideas</description>
	<lastBuildDate>Mon, 22 Jul 2019 14:36:11 +0000</lastBuildDate>
	<language>en</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>http://wordpress.com/</generator>
<cloud domain='wellecks.wordpress.com' port='80' path='/?rsscloud=notify' registerProcedure='' protocol='http-post' />
<image>
		<url>https://s0.wp.com/i/buttonw-com.png</url>
		<title>wellecks</title>
		<link>https://wellecks.wordpress.com</link>
	</image>
	<atom:link rel="search" type="application/opensearchdescription+xml" href="https://wellecks.wordpress.com/osd.xml" title="wellecks" />
	<atom:link rel='hub' href='https://wellecks.wordpress.com/?pushpress=hub'/>
	<item>
		<title>Evolving Networks</title>
		<link>https://wellecks.wordpress.com/2019/07/21/evolving-networks/</link>
					<comments>https://wellecks.wordpress.com/2019/07/21/evolving-networks/#respond</comments>
		
		<dc:creator><![CDATA[wellecks]]></dc:creator>
		<pubDate>Sun, 21 Jul 2019 18:35:21 +0000</pubDate>
				<category><![CDATA[machine learning]]></category>
		<category><![CDATA[HyperNEAT]]></category>
		<category><![CDATA[maching learning]]></category>
		<category><![CDATA[NEAT]]></category>
		<category><![CDATA[neuroevolution]]></category>
		<guid isPermaLink="false">http://wellecks.wordpress.com/?p=1190</guid>

					<description><![CDATA[Finding neural network topologies is a problem with a rich history in evolutionary computing, or neuroevolution. This post will revisit some of the key ideas and outgoing research paths. Code related to this post is found here: [code link]. NEAT In their 2002 paper, Kenneth Stanley &#38; Risto Miikkulainen proposed the foundational algorithm NeuroEvolution of Augmenting [&#8230;]]]></description>
										<content:encoded><![CDATA[<p>Finding neural network topologies is a problem with a rich history in evolutionary computing, or neuroevolution. This post will revisit some of the key ideas and outgoing research paths. Code related to this post is found here: [<a href="https://gist.github.com/wellecks/226dab0ff0dde625b097869fb932cff9">code link</a>].</p>
<h2>NEAT</h2>
<p>In their <a href="http://Evolving Neural Networks through Augmenting Topologies">2002 paper</a>, Kenneth Stanley &amp; Risto Miikkulainen proposed the foundational algorithm NeuroEvolution of Augmenting Topologies (NEAT). I&#8217;ll focus on this algorithm as a starting point; for earlier developments please see <a href="https://link.springer.com/article/10.1007/s00521-019-04160-6">Section 5.2 of this great review,</a> <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=273950">Schaffer&#8217;s 1992 review</a>, and <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=784219">Yao&#8217;s 1999 review</a>. The NEAT paper introduces the ideas clearly and there are other great <a href="http://blog.otoro.net/2016/05/07/backprop-neat/">NEAT</a> <a href="https://www.cs.ucf.edu/~kstanley/neat.html">overviews</a>, so to change it up I will try to present the algorithm with generic notation, which is perhaps useful for thinking about how to modify the algorithm or apply it to a new problem setting.</p>
<p>I&#8217;ve also made an implementation [<a href="https://gist.github.com/wellecks/226dab0ff0dde625b097869fb932cff9">code link</a>] contained in a single python file; you might find it useful to see the entire algorithm in one place, or as a comparison if you also implement NEAT as an exercise. For a more robust implementation, see <a href="https://github.com/CodeReclaimers/neat-python">NEAT-Python</a> (which the code is based on) and its extension <a href="https://github.com/uber-research/PyTorch-NEAT">PyTorch-NEAT</a>.</p>
<h4><strong>Problem</strong></h4>
<p>NEAT addresses the problem of finding a computation graph <img src="https://s0.wp.com/latex.php?latex=G+%3D+%28V%2C+E%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=G+%3D+%28V%2C+E%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=G+%3D+%28V%2C+E%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="G = (V, E)" class="latex" />. Each node <img src="https://s0.wp.com/latex.php?latex=v%5Cin+V&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=v%5Cin+V&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=v%5Cin+V&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="v&#92;in V" class="latex" /> has a bias, activation, and aggregation function, written <img src="https://s0.wp.com/latex.php?latex=%28b%2C+a%2C+%5Ctext%7Bagg%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28b%2C+a%2C+%5Ctext%7Bagg%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28b%2C+a%2C+%5Ctext%7Bagg%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(b, a, &#92;text{agg})" class="latex" />, and each edge <img src="https://s0.wp.com/latex.php?latex=e%5Cin+E&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=e%5Cin+E&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=e%5Cin+E&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="e&#92;in E" class="latex" /> has a source and destination, a weight, and may be active or inactive, written  <img src="https://s0.wp.com/latex.php?latex=%28u%2C+v%2C+w%2C+%5Ctext%7Bactive%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28u%2C+v%2C+w%2C+%5Ctext%7Bactive%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28u%2C+v%2C+w%2C+%5Ctext%7Bactive%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(u, v, w, &#92;text{active})" class="latex" />.</p>
<p>Searching through the space of these graphs amounts to searching through a space of neural networks. NEAT conducts this search using a few generic neuroevolution concepts, which I&#8217;ll focus on below, and often implements them with design decisions that can be relaxed or modified for different problems.</p>
<h4><strong>High-Level Method</strong></h4>
<p>NEAT iteratively produces a set of candidates <img src="https://s0.wp.com/latex.php?latex=P%3D%5C%7BG_1%2C%5Cldots%2CG_N%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=P%3D%5C%7BG_1%2C%5Cldots%2CG_N%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=P%3D%5C%7BG_1%2C%5Cldots%2CG_N%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="P=&#92;{G_1,&#92;ldots,G_N&#92;}" class="latex" />, using a candidate partitioning <img src="https://s0.wp.com/latex.php?latex=S%3D%5C%7BS_1%2C%5Cldots%2CS_M%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=S%3D%5C%7BS_1%2C%5Cldots%2CS_M%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S%3D%5C%7BS_1%2C%5Cldots%2CS_M%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="S=&#92;{S_1,&#92;ldots,S_M&#92;}" class="latex" /> where <img src="https://s0.wp.com/latex.php?latex=S_j+%5Csubseteq+P&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=S_j+%5Csubseteq+P&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S_j+%5Csubseteq+P&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="S_j &#92;subseteq P" class="latex" /> and a given function <img src="https://s0.wp.com/latex.php?latex=f%3A%5Cmathcal%7BG%7D%5Crightarrow%5Cmathbb%7BR%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3A%5Cmathcal%7BG%7D%5Crightarrow%5Cmathbb%7BR%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3A%5Cmathcal%7BG%7D%5Crightarrow%5Cmathbb%7BR%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:&#92;mathcal{G}&#92;rightarrow&#92;mathbb{R}" class="latex" /> which measures a candidate&#8217;s quality. The candidates, partitions, and quality function are known as &#8216;population&#8217;, &#8216;species&#8217;, and &#8216;fitness&#8217;, respectively.</p>
<div data-shortcode="caption" id="attachment_1198" style="width: 367px" class="wp-caption aligncenter"><img loading="lazy" aria-describedby="caption-attachment-1198" data-attachment-id="1198" data-permalink="https://wellecks.wordpress.com/2019/07/21/evolving-networks/objects/#main" data-orig-file="https://wellecks.files.wordpress.com/2019/07/objects.png" data-orig-size="312,91" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="objects" data-image-description="" data-image-caption="&lt;p&gt;The candidate set (&#8220;population&#8221;, rectangle) contains partitions (&#8220;species&#8221;, circles), each containing candidate graphs (&#8220;genomes&#8221;, diamonds).&lt;/p&gt;
" data-medium-file="https://wellecks.files.wordpress.com/2019/07/objects.png?w=300" data-large-file="https://wellecks.files.wordpress.com/2019/07/objects.png?w=312" class="alignnone wp-image-1198" src="https://wellecks.files.wordpress.com/2019/07/objects.png?w=357&#038;h=104" alt="objects" width="357" height="104" srcset="https://wellecks.files.wordpress.com/2019/07/objects.png 312w, https://wellecks.files.wordpress.com/2019/07/objects.png?w=150&amp;h=44 150w, https://wellecks.files.wordpress.com/2019/07/objects.png?w=300&amp;h=88 300w" sizes="(max-width: 357px) 100vw, 357px" /><p id="caption-attachment-1198" class="wp-caption-text">The candidate set (&#8220;population&#8221;, rectangle) contains partitions (&#8220;species&#8221;, circles), each containing candidate graphs (diamonds).</p></div>
<p>Each NEAT iteration returns a new candidate set and new partitioning, denoted as <img src="https://s0.wp.com/latex.php?latex=E%28P%5E%7B%28i%29%7D%2C+S%5E%7B%28i%29%7D%2C+f%29%5Crightarrow+P%5E%7B%28i%2B1%29%7D%2CS%5E%7B%28i%2B1%29%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=E%28P%5E%7B%28i%29%7D%2C+S%5E%7B%28i%29%7D%2C+f%29%5Crightarrow+P%5E%7B%28i%2B1%29%7D%2CS%5E%7B%28i%2B1%29%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=E%28P%5E%7B%28i%29%7D%2C+S%5E%7B%28i%29%7D%2C+f%29%5Crightarrow+P%5E%7B%28i%2B1%29%7D%2CS%5E%7B%28i%2B1%29%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="E(P^{(i)}, S^{(i)}, f)&#92;rightarrow P^{(i+1)},S^{(i+1)}" class="latex" />. Intuitively E is an &#8216;evolution step&#8217; that produces a new &#8216;generation&#8217;. NEAT&#8217;s goal is to eventually output a &#8216;good&#8217; candidate set <img src="https://s0.wp.com/latex.php?latex=P%5E%7B%28i%29%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=P%5E%7B%28i%29%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=P%5E%7B%28i%29%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="P^{(i)}" class="latex" />. Typically <em>good</em> means that the best candidate has quality exceeding a goal threshold, <img src="https://s0.wp.com/latex.php?latex=%5Cmax_j+f%28G%5E%7B%28i%29%7D_j%29+%3E+%5Ctau&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmax_j+f%28G%5E%7B%28i%29%7D_j%29+%3E+%5Ctau&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmax_j+f%28G%5E%7B%28i%29%7D_j%29+%3E+%5Ctau&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;max_j f(G^{(i)}_j) &gt; &#92;tau" class="latex" />. We then use this high-performing neural network on a task.</p>
<h3>Evolution Steps</h3>
<p>Each evolution step <img src="https://s0.wp.com/latex.php?latex=E%28P%5E%7B%28i%29%7D%2C+S%5E%7B%28i%29%7D%2C+f%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=E%28P%5E%7B%28i%29%7D%2C+S%5E%7B%28i%29%7D%2C+f%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=E%28P%5E%7B%28i%29%7D%2C+S%5E%7B%28i%29%7D%2C+f%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="E(P^{(i)}, S^{(i)}, f)" class="latex" /> produces a new population using four ideas: mutation, crossover, fitness ranking, and partitioning.</p>
<p><strong>Mutation</strong> <img src="https://s0.wp.com/latex.php?latex=m%28G%29%5Crightarrow+G&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=m%28G%29%5Crightarrow+G&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=m%28G%29%5Crightarrow+G&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="m(G)&#92;rightarrow G" class="latex" /> randomly perturbs a candidate graph. In NEAT, mutations consist of adding or deleting a node, adding or deleting an edge, or perturbing a node or edge property (such as an edge&#8217;s weight or a node&#8217;s activation). Each mutation type occurs with a pre-specified probability, and involves a random perturbation; for instance an add-edge randomly chooses an edge location and weights are adjusted with Gaussian noise. One can design other mutations, such as resetting a weight to a new value.</p>
<div data-shortcode="caption" id="attachment_1194" style="width: 402px" class="wp-caption aligncenter"><img aria-describedby="caption-attachment-1194" data-attachment-id="1194" data-permalink="https://wellecks.wordpress.com/2019/07/21/evolving-networks/mutation/#main" data-orig-file="https://wellecks.files.wordpress.com/2019/07/mutation.png" data-orig-size="392,131" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="mutation" data-image-description="" data-image-caption="" data-medium-file="https://wellecks.files.wordpress.com/2019/07/mutation.png?w=300" data-large-file="https://wellecks.files.wordpress.com/2019/07/mutation.png?w=392" class="aligncenter size-full wp-image-1194" src="https://wellecks.files.wordpress.com/2019/07/mutation.png?w=525" alt="mutation" srcset="https://wellecks.files.wordpress.com/2019/07/mutation.png 392w, https://wellecks.files.wordpress.com/2019/07/mutation.png?w=150 150w, https://wellecks.files.wordpress.com/2019/07/mutation.png?w=300 300w" sizes="(max-width: 392px) 100vw, 392px"   /><p id="caption-attachment-1194" class="wp-caption-text">An add-node mutation followed by an add-edge mutation. The add-node mutation splits an existing edge into two edges.</p></div>
<p style="text-align:left;"><strong>Crossover</strong> <img src="https://s0.wp.com/latex.php?latex=c%28G_i%2CG_j%29%5Crightarrow+G&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c%28G_i%2CG_j%29%5Crightarrow+G&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c%28G_i%2CG_j%29%5Crightarrow+G&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c(G_i,G_j)&#92;rightarrow G" class="latex" /> produces a new candidate by swapping properties of two existing candidates. In NEAT, roughly speaking if <img src="https://s0.wp.com/latex.php?latex=G_i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=G_i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=G_i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="G_i" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=G_j&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=G_j&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=G_j&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="G_j" class="latex" /> have a matching node <img src="https://s0.wp.com/latex.php?latex=v_i%2C+v_j&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=v_i%2C+v_j&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=v_i%2C+v_j&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="v_i, v_j" class="latex" />, then <img src="https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="G" class="latex" /> receives one of them randomly (similarly for edges). <img src="https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="G" class="latex" /> simply inherits non-matching nodes or edges. The notion of &#8216;matching&#8217; is tricky due to isomorphic graph structures, so NEAT assigns an ID to each new node and edge, then uses these IDs for comparison (see 2.2 and 3.2 of the NEAT paper for details).  In part due to the added complexity, some papers leave out crossover completely.</p>
<div data-shortcode="caption" id="attachment_1195" style="width: 381px" class="wp-caption aligncenter"><img loading="lazy" aria-describedby="caption-attachment-1195" data-attachment-id="1195" data-permalink="https://wellecks.wordpress.com/2019/07/21/evolving-networks/crossover/#main" data-orig-file="https://wellecks.files.wordpress.com/2019/07/crossover.png" data-orig-size="820,806" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="crossover" data-image-description="" data-image-caption="" data-medium-file="https://wellecks.files.wordpress.com/2019/07/crossover.png?w=300" data-large-file="https://wellecks.files.wordpress.com/2019/07/crossover.png?w=525" class="alignnone wp-image-1195" src="https://wellecks.files.wordpress.com/2019/07/crossover.png?w=371&#038;h=364" alt="crossover" width="371" height="364" srcset="https://wellecks.files.wordpress.com/2019/07/crossover.png?w=371&amp;h=364 371w, https://wellecks.files.wordpress.com/2019/07/crossover.png?w=742&amp;h=728 742w, https://wellecks.files.wordpress.com/2019/07/crossover.png?w=150&amp;h=147 150w, https://wellecks.files.wordpress.com/2019/07/crossover.png?w=300&amp;h=295 300w" sizes="(max-width: 371px) 100vw, 371px" /><p id="caption-attachment-1195" class="wp-caption-text">NEAT crossover mechanism (diagram from the <a href="http://nn.cs.utexas.edu/downloads/papers/stanley.ec02.pdf">NEAT paper</a>)</p></div>
<p><strong>Fitness Ranking</strong> follows its name, first ranking candidates according to fitness, <img src="https://s0.wp.com/latex.php?latex=%28G_%7B1%27%7D%2C%5Cldots%2CG_%7BN%27%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28G_%7B1%27%7D%2C%5Cldots%2CG_%7BN%27%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28G_%7B1%27%7D%2C%5Cldots%2CG_%7BN%27%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(G_{1&#039;},&#92;ldots,G_{N&#039;})" class="latex" /> where <img src="https://s0.wp.com/latex.php?latex=i%27%3Ej%27&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i%27%3Ej%27&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i%27%3Ej%27&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i&#039;&gt;j&#039;" class="latex" /> means <img src="https://s0.wp.com/latex.php?latex=f%28G_%7Bi%27%7D%29%3Ef%28G_%7Bj%27%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%28G_%7Bi%27%7D%29%3Ef%28G_%7Bj%27%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%28G_%7Bi%27%7D%29%3Ef%28G_%7Bj%27%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f(G_{i&#039;})&gt;f(G_{j&#039;})" class="latex" />. Only the top (e.g. 20%) candidates are used for crossover and mutation. This locally biases the search towards candidates with high relative fitness.</p>
<p><strong>Partitioning</strong>, or speciation, groups candidates according to a distance function <img src="https://s0.wp.com/latex.php?latex=d%28G_i%2CG_j%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d%28G_i%2CG_j%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d%28G_i%2CG_j%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d(G_i,G_j)" class="latex" />. One use of the partitions is to promote diversity in the solution space by modifying each candidate&#8217;s fitness. To do so, NEAT defines a distance function and adjusts each candidate&#8217;s fitness based on its partition size. Each partition is guaranteed a certain number of candidates in the next generation based on the adjusted fitnesses.</p>
<p>Intuitively, a small partition contains graphs with relatively unique characteristics which might ultimately be useful in a final solution, even if they do not yield immediate fitness. To avoid erasing these characteristics from the search during fitness ranking, the small partition candidates receive guaranteed spots in the next phase.</p>
<div data-shortcode="caption" id="attachment_1197" style="width: 1378px" class="wp-caption alignnone"><img aria-describedby="caption-attachment-1197" data-attachment-id="1197" data-permalink="https://wellecks.wordpress.com/2019/07/21/evolving-networks/partition-2/#main" data-orig-file="https://wellecks.files.wordpress.com/2019/07/partition-1.jpg" data-orig-size="1368,446" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="partition" data-image-description="" data-image-caption="&lt;p&gt;Novel structures (diamonds, triangles) may ultimately yield a performance gain after further development, despite initially having lower fitness (light green) compared to common structures with high fitness (dark green).&lt;/p&gt;
" data-medium-file="https://wellecks.files.wordpress.com/2019/07/partition-1.jpg?w=300" data-large-file="https://wellecks.files.wordpress.com/2019/07/partition-1.jpg?w=525" class="alignnone size-full wp-image-1197" src="https://wellecks.files.wordpress.com/2019/07/partition-1.jpg?w=525" alt="partition" srcset="https://wellecks.files.wordpress.com/2019/07/partition-1.jpg?w=525 525w, https://wellecks.files.wordpress.com/2019/07/partition-1.jpg?w=1050 1050w, https://wellecks.files.wordpress.com/2019/07/partition-1.jpg?w=150 150w, https://wellecks.files.wordpress.com/2019/07/partition-1.jpg?w=300 300w, https://wellecks.files.wordpress.com/2019/07/partition-1.jpg?w=768 768w, https://wellecks.files.wordpress.com/2019/07/partition-1.jpg?w=1024 1024w" sizes="(max-width: 525px) 100vw, 525px"   /><p id="caption-attachment-1197" class="wp-caption-text">Novel structures (diamonds, triangles) may ultimately yield a performance gain after further development, despite initially having lower fitness (light green) compared to common, developed structures with high fitness (dark green).</p></div>
<p>We can write this step as <img src="https://s0.wp.com/latex.php?latex=f_%7B%5Ctext%7Bpartition%7D%7D%28P%2Cf_1%2C%5Cldots%2Cf_N%2CS%29%5Crightarrow+%28f_1%27%2C%5Cldots%2Cf_N%27%2C+S%27%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f_%7B%5Ctext%7Bpartition%7D%7D%28P%2Cf_1%2C%5Cldots%2Cf_N%2CS%29%5Crightarrow+%28f_1%27%2C%5Cldots%2Cf_N%27%2C+S%27%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f_%7B%5Ctext%7Bpartition%7D%7D%28P%2Cf_1%2C%5Cldots%2Cf_N%2CS%29%5Crightarrow+%28f_1%27%2C%5Cldots%2Cf_N%27%2C+S%27%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f_{&#92;text{partition}}(P,f_1,&#92;ldots,f_N,S)&#92;rightarrow (f_1&#039;,&#92;ldots,f_N&#039;, S&#039;)" class="latex" />. We might alternatively view this step as just fitness re-ranking, <img src="https://s0.wp.com/latex.php?latex=f_%7B%5Ctext%7Bre-rank%7D%7D%28P%2Cf_1%2C%5Cldots%2Cf_N%29%5Crightarrow+%28f_1%27%2C%5Cldots%2Cf_N%27%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f_%7B%5Ctext%7Bre-rank%7D%7D%28P%2Cf_1%2C%5Cldots%2Cf_N%29%5Crightarrow+%28f_1%27%2C%5Cldots%2Cf_N%27%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f_%7B%5Ctext%7Bre-rank%7D%7D%28P%2Cf_1%2C%5Cldots%2Cf_N%29%5Crightarrow+%28f_1%27%2C%5Cldots%2Cf_N%27%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f_{&#92;text{re-rank}}(P,f_1,&#92;ldots,f_N)&#92;rightarrow (f_1&#039;,&#92;ldots,f_N&#039;)" class="latex" />, without requiring actual partitions, though without partitions it may be tricky to achieve the exact &#8216;guaranteed spots&#8217; behavior.</p>
<p>The partitions <img src="https://s0.wp.com/latex.php?latex=S%27&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=S%27&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S%27&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="S&#039;" class="latex" /> could also be useful in problems requiring a <em>collection</em> of solutions rather than a single optimal solution. For instance, rather than just selecting the highest performing candidate, we might consider the <em>best candidate in each partition</em> as the final output of NEAT, thus producing a <em>collection</em> of networks, each maximizing fitness in a different way than the others (assuming a partitioning scheme that promotes diverse solutions).</p>
<h3>Example Results</h3>
<p>Let&#8217;s use the implementation [<a href="https://gist.github.com/wellecks/226dab0ff0dde625b097869fb932cff9"><strong>code link</strong></a>] to solve an xor problem and the Cartpole and Lunar-Lander gym environments.</p>
<p style="text-align:left;">To solve <strong>xor</strong>, NEAT finds a network with a single hidden node:</p>
<div data-shortcode="caption" id="attachment_1207" style="width: 559px" class="wp-caption aligncenter"><img loading="lazy" aria-describedby="caption-attachment-1207" data-attachment-id="1207" data-permalink="https://wellecks.wordpress.com/2019/07/21/evolving-networks/xor-2/#main" data-orig-file="https://wellecks.files.wordpress.com/2019/07/xor-1.png" data-orig-size="1280,960" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="xor" data-image-description="" data-image-caption="&lt;p&gt;An xor network, including input (green), hidden (blue), and output (red) nodes. Labels show edge weights, node biases, and node activations. &lt;/p&gt;
" data-medium-file="https://wellecks.files.wordpress.com/2019/07/xor-1.png?w=300" data-large-file="https://wellecks.files.wordpress.com/2019/07/xor-1.png?w=525" class="alignnone wp-image-1207" src="https://wellecks.files.wordpress.com/2019/07/xor-1.png?w=549&#038;h=412" alt="xor" width="549" height="412" srcset="https://wellecks.files.wordpress.com/2019/07/xor-1.png?w=549&amp;h=412 549w, https://wellecks.files.wordpress.com/2019/07/xor-1.png?w=1098&amp;h=824 1098w, https://wellecks.files.wordpress.com/2019/07/xor-1.png?w=150&amp;h=113 150w, https://wellecks.files.wordpress.com/2019/07/xor-1.png?w=300&amp;h=225 300w, https://wellecks.files.wordpress.com/2019/07/xor-1.png?w=768&amp;h=576 768w, https://wellecks.files.wordpress.com/2019/07/xor-1.png?w=1024&amp;h=768 1024w" sizes="(max-width: 549px) 100vw, 549px" /><p id="caption-attachment-1207" class="wp-caption-text">An xor network, including input (green), hidden (blue), and output (red) nodes. Labels show edge weights and node activations.</p></div>
<p><strong>CartPole-v0</strong> is easy to solve (<a href="http://kvfrans.com/simple-algoritms-for-solving-cartpole/">even random search is sufficient</a>), and NEAT finds a simple network without hidden units (for fun we&#8217;ll also construct an artificially complicated solution in the <strong>Variations</strong> section below):</p>
<p>&nbsp;</p>
<div data-shortcode="caption" id="attachment_1206" style="width: 514px" class="wp-caption aligncenter"><img loading="lazy" aria-describedby="caption-attachment-1206" data-attachment-id="1206" data-permalink="https://wellecks.wordpress.com/2019/07/21/evolving-networks/cartpole-2/#main" data-orig-file="https://wellecks.files.wordpress.com/2019/07/cartpole-1.png" data-orig-size="1280,960" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="cartpole" data-image-description="" data-image-caption="&lt;p&gt;CartPole-v0 network.&lt;/p&gt;
" data-medium-file="https://wellecks.files.wordpress.com/2019/07/cartpole-1.png?w=300" data-large-file="https://wellecks.files.wordpress.com/2019/07/cartpole-1.png?w=525" class="alignnone wp-image-1206" src="https://wellecks.files.wordpress.com/2019/07/cartpole-1.png?w=504&#038;h=378" alt="cartpole" width="504" height="378" srcset="https://wellecks.files.wordpress.com/2019/07/cartpole-1.png?w=504&amp;h=378 504w, https://wellecks.files.wordpress.com/2019/07/cartpole-1.png?w=1008&amp;h=756 1008w, https://wellecks.files.wordpress.com/2019/07/cartpole-1.png?w=150&amp;h=113 150w, https://wellecks.files.wordpress.com/2019/07/cartpole-1.png?w=300&amp;h=225 300w, https://wellecks.files.wordpress.com/2019/07/cartpole-1.png?w=768&amp;h=576 768w" sizes="(max-width: 504px) 100vw, 504px" /><p id="caption-attachment-1206" class="wp-caption-text">A CartPole-v0 network.</p></div>
<p><strong>LunarLander-v2</strong> is more difficult, and NEAT finds a network with non-trivial structure:</p>
<div data-shortcode="caption" id="attachment_1205" style="width: 1290px" class="wp-caption alignnone"><img aria-describedby="caption-attachment-1205" data-attachment-id="1205" data-permalink="https://wellecks.wordpress.com/2019/07/21/evolving-networks/lunar-2/#main" data-orig-file="https://wellecks.files.wordpress.com/2019/07/lunar-1.png" data-orig-size="1280,960" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="lunar" data-image-description="" data-image-caption="&lt;p&gt;LunarLander-v2 network. Input nodes are green, output nodes are red. Biases are not shown due to clutter.&lt;/p&gt;
" data-medium-file="https://wellecks.files.wordpress.com/2019/07/lunar-1.png?w=300" data-large-file="https://wellecks.files.wordpress.com/2019/07/lunar-1.png?w=525" class="alignnone size-full wp-image-1205" src="https://wellecks.files.wordpress.com/2019/07/lunar-1.png?w=525" alt="lunar" srcset="https://wellecks.files.wordpress.com/2019/07/lunar-1.png?w=525 525w, https://wellecks.files.wordpress.com/2019/07/lunar-1.png?w=1050 1050w, https://wellecks.files.wordpress.com/2019/07/lunar-1.png?w=150 150w, https://wellecks.files.wordpress.com/2019/07/lunar-1.png?w=300 300w, https://wellecks.files.wordpress.com/2019/07/lunar-1.png?w=768 768w, https://wellecks.files.wordpress.com/2019/07/lunar-1.png?w=1024 1024w" sizes="(max-width: 525px) 100vw, 525px"   /><p id="caption-attachment-1205" class="wp-caption-text">A LunarLander-v2 network.</p></div>
<p>On the xor environment, NEAT creates around 10 partitions, on Cartpole just 1, and on LunarLander it tends to create 2-3 partitions. On these simple environments NEAT also performs similarly <em>without crossover</em>.</p>
<p><strong>Variations</strong> As mentioned before, we may want NEAT to produce a <em>diverse set</em> of solutions rather than a single solution. To manually demonstrate this intuition, suppose I want NEAT to find a network that uses sigmoid activations, and one that uses tanh. To do so, I increased the activation parameter in the node distance function (the <img src="https://s0.wp.com/latex.php?latex=d%28%5Ccdot%2C%5Ccdot%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d%28%5Ccdot%2C%5Ccdot%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d%28%5Ccdot%2C%5Ccdot%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d(&#92;cdot,&#92;cdot)" class="latex" /> used in partitioning), then chose the highest scoring network from each partition. On Cartpole, the partitions now naturally separate into sigmoid and tanh networks:</p>

<a href='https://wellecks.wordpress.com/2019/07/21/evolving-networks/sigmoid/#main'><img width="150" height="113" src="https://wellecks.files.wordpress.com/2019/07/sigmoid.png?w=150&#038;h=113" class="attachment-thumbnail size-thumbnail" alt="" loading="lazy" srcset="https://wellecks.files.wordpress.com/2019/07/sigmoid.png?w=150 150w, https://wellecks.files.wordpress.com/2019/07/sigmoid.png?w=300 300w" sizes="(max-width: 150px) 100vw, 150px" data-attachment-id="1199" data-permalink="https://wellecks.wordpress.com/2019/07/21/evolving-networks/sigmoid/#main" data-orig-file="https://wellecks.files.wordpress.com/2019/07/sigmoid.png" data-orig-size="1280,960" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="sigmoid" data-image-description="" data-image-caption="" data-medium-file="https://wellecks.files.wordpress.com/2019/07/sigmoid.png?w=300" data-large-file="https://wellecks.files.wordpress.com/2019/07/sigmoid.png?w=525" /></a>
<a href='https://wellecks.wordpress.com/2019/07/21/evolving-networks/tanh/#main'><img width="150" height="113" src="https://wellecks.files.wordpress.com/2019/07/tanh.png?w=150&#038;h=113" class="attachment-thumbnail size-thumbnail" alt="" loading="lazy" srcset="https://wellecks.files.wordpress.com/2019/07/tanh.png?w=150 150w, https://wellecks.files.wordpress.com/2019/07/tanh.png?w=300 300w" sizes="(max-width: 150px) 100vw, 150px" data-attachment-id="1200" data-permalink="https://wellecks.wordpress.com/2019/07/21/evolving-networks/tanh/#main" data-orig-file="https://wellecks.files.wordpress.com/2019/07/tanh.png" data-orig-size="1280,960" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="tanh" data-image-description="" data-image-caption="" data-medium-file="https://wellecks.files.wordpress.com/2019/07/tanh.png?w=300" data-large-file="https://wellecks.files.wordpress.com/2019/07/tanh.png?w=525" /></a>

<p>While Cartpole is evidently simple enough for a network with no hidden layers, perhaps we want to follow a trend of using large networks even for easy problems. We can modify the fitness function to &#8216;reject&#8217; networks without a certain number of connections, and NEAT will yield more complicated solutions:</p>
<div data-shortcode="caption" id="attachment_1201" style="width: 2142px" class="wp-caption alignnone"><img aria-describedby="caption-attachment-1201" data-attachment-id="1201" data-permalink="https://wellecks.wordpress.com/2019/07/21/evolving-networks/complex20/#main" data-orig-file="https://wellecks.files.wordpress.com/2019/07/complex20.png" data-orig-size="2132,1546" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="complex20" data-image-description="" data-image-caption="&lt;p&gt;A more complicated way to play Cartpole.&lt;/p&gt;
" data-medium-file="https://wellecks.files.wordpress.com/2019/07/complex20.png?w=300" data-large-file="https://wellecks.files.wordpress.com/2019/07/complex20.png?w=525" class="alignnone size-full wp-image-1201" src="https://wellecks.files.wordpress.com/2019/07/complex20.png?w=525" alt="complex20" srcset="https://wellecks.files.wordpress.com/2019/07/complex20.png?w=525 525w, https://wellecks.files.wordpress.com/2019/07/complex20.png?w=1050 1050w, https://wellecks.files.wordpress.com/2019/07/complex20.png?w=150 150w, https://wellecks.files.wordpress.com/2019/07/complex20.png?w=300 300w, https://wellecks.files.wordpress.com/2019/07/complex20.png?w=768 768w, https://wellecks.files.wordpress.com/2019/07/complex20.png?w=1024 1024w" sizes="(max-width: 525px) 100vw, 525px"   /><p id="caption-attachment-1201" class="wp-caption-text">A more complicated way to play Cartpole.</p></div>
<p>In particular, I added -1000 to the fitness when the network had less than <em>k</em> connections, starting with <em>k=5</em> and incrementing <em>k</em> each time a candidate achieved max fitness at the current <em>k </em>(stopping at k=20).</p>
<h2>Discussion &amp; Extensions</h2>
<p>Vanilla NEAT attempts to find both a network structure and the corresponding weights from scratch. This approach is very flexible and involves minimal assumptions, but could limit NEAT to problems requiring small networks. However, the key idea can still be applied or modified in creative ways.</p>
<h3>Minimal Assumptions</h3>
<p>NEAT represents an extreme on the spectrum of learned versus hand-crafted architectural biases, by placing few assumptions on graph structure or learning algorithm. At a very speculative level, such flexibility may be useful for networks with <a href="https://www.sciencedirect.com/science/article/pii/S1053811908013050?via%3Dihub">backward or long-range</a> <a href="https://www.frontiersin.org/articles/10.3389/fnhum.2015.00253/full">connections</a> that may be difficult to hand design, or as part of a learning <a href="https://www.sciencedirect.com/science/article/abs/pii/S0940960211802554">process</a> <a href="https://www.sciencedirect.com/science/article/pii/S0896627311009184">which involves</a> <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5649212/pdf/fpsyg-08-01657.pdf">removing or adding connections</a> rather than optimizing weights of a fixed architecture.</p>
<p>A more concrete example is the recent Weight Agnostic Neural Networks paper (<a href="https://weightagnostic.github.io/">Gaier &amp; Ha 2019</a>), where the authors aimed to find a model for a task by <em>finding good network structures</em>, rather than finding good weights for a fixed network structure; they use a <em>single shared weight value</em> in each network and evaluate fitness on multiple rollouts, with a randomly selected weight value for each rollout. In this case, a NEAT variant allowed finding exotic network structures from scratch, without requiring prior knowledge such as hand-designed layer types.</p>
<p class="p1">As a rough approximation, I modified the NEAT implementation so that each network only has a single shared weight value, and included more activation functions (sin, cos, arctan, abs, floor). Each run of evaluation sets the network&#8217;s shared weight to a randomly sampled value (<img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BU%7D%28%5B-2%2C2%5D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BU%7D%28%5B-2%2C2%5D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathcal%7BU%7D%28%5B-2%2C2%5D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathcal{U}([-2,2])" class="latex" /> excluding <img src="https://s0.wp.com/latex.php?latex=%5B-0.1%2C0.1%5D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5B-0.1%2C0.1%5D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5B-0.1%2C0.1%5D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="[-0.1,0.1]" class="latex" />), and the network&#8217;s overall fitness is the average fitness over 10 runs. On XOR, NEAT finds a network with similar structure as before:</p>
<div data-shortcode="caption" id="attachment_1218" style="width: 455px" class="wp-caption aligncenter"><img loading="lazy" aria-describedby="caption-attachment-1218" data-attachment-id="1218" data-permalink="https://wellecks.wordpress.com/2019/07/21/evolving-networks/screen-shot-2019-07-21-at-3-56-44-pm/#main" data-orig-file="https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-21-at-3.56.44-pm.png" data-orig-size="1234,930" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="xor_shared" data-image-description="" data-image-caption="&lt;p&gt;XOR network with random shared weight value&lt;/p&gt;
" data-medium-file="https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-21-at-3.56.44-pm.png?w=300" data-large-file="https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-21-at-3.56.44-pm.png?w=525" class="alignnone  wp-image-1218" src="https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-21-at-3.56.44-pm.png?w=445&#038;h=335" alt="xor_shared" width="445" height="335" srcset="https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-21-at-3.56.44-pm.png?w=445&amp;h=335 445w, https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-21-at-3.56.44-pm.png?w=890&amp;h=670 890w, https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-21-at-3.56.44-pm.png?w=150&amp;h=113 150w, https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-21-at-3.56.44-pm.png?w=300&amp;h=226 300w, https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-21-at-3.56.44-pm.png?w=768&amp;h=579 768w" sizes="(max-width: 445px) 100vw, 445px" /><p id="caption-attachment-1218" class="wp-caption-text">XOR network with a random shared weight value</p></div>
<p class="p1">This was just an initial experiment to give intuition, so check out the <a href="https://weightagnostic.github.io/"><span class="s1">WANN paper</span></a> for a good way of doing this for non-trivial tasks.</p>
<h3>Scalability</h3>
<p>One could also consider improving NEAT&#8217;s scalability. A high level strategy is to reduce the search space by restricting the search to topologies, searching at a higher abstraction level, or introducing hierarchy.</p>
<p>An example is DeepNEAT (<a href="https://arxiv.org/pdf/1703.00548.pdf">Miikkulainen et al 2017</a>), which evolves graph structures using NEAT, but with nodes representing <em>layers</em> rather than single neurons, and edges specifying layer connectivity. Weight and bias values are learned with back-propagation. The authors further extend DeepNEAT to CoDeepNEAT, which represents graphs with a two level hierarchy defined by a <em>blueprint</em> specifying connectivity of <em>modules</em>. Separate blueprint and module populations are evolved, with the full graph (module + blueprint) assembled for fitness evaluation.</p>
<div data-shortcode="caption" id="attachment_1208" style="width: 2610px" class="wp-caption alignnone"><img aria-describedby="caption-attachment-1208" data-attachment-id="1208" data-permalink="https://wellecks.wordpress.com/2019/07/21/evolving-networks/codeepneat/#main" data-orig-file="https://wellecks.files.wordpress.com/2019/07/codeepneat.png" data-orig-size="2600,2072" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="" data-image-description="" data-image-caption="&lt;p&gt;Blueprint and Module populations. Each node in a Blueprint (hexagon) is a Module.&lt;/p&gt;
" data-medium-file="https://wellecks.files.wordpress.com/2019/07/codeepneat.png?w=300" data-large-file="https://wellecks.files.wordpress.com/2019/07/codeepneat.png?w=525" class="alignnone size-full wp-image-1208" src="https://wellecks.files.wordpress.com/2019/07/codeepneat.png?w=525" alt="" srcset="https://wellecks.files.wordpress.com/2019/07/codeepneat.png?w=525 525w, https://wellecks.files.wordpress.com/2019/07/codeepneat.png?w=1050 1050w, https://wellecks.files.wordpress.com/2019/07/codeepneat.png?w=150 150w, https://wellecks.files.wordpress.com/2019/07/codeepneat.png?w=300 300w, https://wellecks.files.wordpress.com/2019/07/codeepneat.png?w=768 768w, https://wellecks.files.wordpress.com/2019/07/codeepneat.png?w=1024 1024w" sizes="(max-width: 525px) 100vw, 525px"   /><p id="caption-attachment-1208" class="wp-caption-text">Blueprint and Module populations. Each node in a Blueprint (hexagon) is a Module.</p></div>
<p>This view is quite general, allowing learning the internal structure of reusable modules as well as how they are composed. In the experiments the authors begin with modules involving known components such as convolutional layers or LSTM cells and evolve only specific parts (e.g. connections between LSTM layers), but one might imagine searching for completely novel, reusable modules.</p>
<h3>Indirect Encodings</h3>
<p>NEAT essentially writes down a description, or <em>direct encoding</em>, of every node and edge and their properties, then evolves these descriptions. The description size grows as the network grows, making the search space prohibitively large.</p>
<p>An alternative is to <span style="font-style:italic;">use a function to describe a network</span>. For instance, we can evaluate a function <img src="https://s0.wp.com/latex.php?latex=f%3A%5Cmathbb%7BR%7D%5E4%5Crightarrow+%5Cmathbb%7BR%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3A%5Cmathbb%7BR%7D%5E4%5Crightarrow+%5Cmathbb%7BR%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3A%5Cmathbb%7BR%7D%5E4%5Crightarrow+%5Cmathbb%7BR%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:&#92;mathbb{R}^4&#92;rightarrow &#92;mathbb{R}" class="latex" /> at pairs of points from a <img src="https://s0.wp.com/latex.php?latex=V%5Ctimes+V&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=V%5Ctimes+V&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=V%5Ctimes+V&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="V&#92;times V" class="latex" /> grid to obtain a weighted adjacency matrix. This function is an example of an <span style="font-style:italic;">indirect encoding </span>of the graph. Assuming the description of <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> is small, we can describe very large networks by evaluating a suitable <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> using a large grid or coordinate pattern. A neural network with a variety of activations that is evaluated in this manner is called a <a href="http://eplex.cs.ucf.edu/papers/stanley_gpem07.pdf">compositional pattern producing network</a> (CPPN) [<a href="http://blog.otoro.net/2016/03/25/generating-abstract-patterns-with-tensorflow/">see</a>,<a href="https://distill.pub/2018/differentiable-parameterizations/?spm=a2c4e.11153940.blogcont683655.53.1e195250rLB3BI&amp;utm_source=mybridge&amp;utm_medium=blog&amp;utm_campaign=read_more#section-xy2rgb"> also</a>].</p>
<p><a href="http://axon.cs.byu.edu/~dan/778/papers/NeuroEvolution/stanley3**.pdf">HyperNEAT (Stanley et al. 2009)</a> uses this idea to find network weights by <span style="font-style:italic;">evolving an indirect encoding function</span>. HyperNEAT uses NEAT to evolve a (small) CPPN to act as <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" />, then evaluates <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> at coordinates from a hyper-cube, resulting in weights of a (larger) network used for fitness evaluation.</p>
<p>Several works have adopted or extended ideas from HyperNEAT for a deep learning setting. <a href="https://arxiv.org/pdf/1606.02580.pdf">Fernando et al. 2016</a> proposed the Differentiable Pattern Producing Network (DPPN) which evolves the structure of a weight-generating CPPN <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> while using back-propagation for its weights. The authors evolve a 200 parameter <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> that generates weights for a fully connected auto-encoder with ~150,000 weights, though it is for a small-scale MNIST image de-noising task. Interestingly the weight generating function <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> learns to produce convolution-esque filters embedded in the fully connected network.</p>
<p><div data-shortcode="caption" id="attachment_1211" style="width: 2814px" class="wp-caption alignnone"><img aria-describedby="caption-attachment-1211" data-attachment-id="1211" data-permalink="https://wellecks.wordpress.com/2019/07/21/evolving-networks/screen-shot-2019-07-20-at-4-48-49-pm/#main" data-orig-file="https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-20-at-4.48.49-pm.png" data-orig-size="2804,1402" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen Shot 2019-07-20 at 4.48.49 PM" data-image-description="" data-image-caption="&lt;p&gt;From [Fernando et al 2016]&lt;/p&gt;
" data-medium-file="https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-20-at-4.48.49-pm.png?w=300" data-large-file="https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-20-at-4.48.49-pm.png?w=525" class="alignnone size-full wp-image-1211" src="https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-20-at-4.48.49-pm.png?w=525" alt="Screen Shot 2019-07-20 at 4.48.49 PM" srcset="https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-20-at-4.48.49-pm.png?w=525 525w, https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-20-at-4.48.49-pm.png?w=1050 1050w, https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-20-at-4.48.49-pm.png?w=150 150w, https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-20-at-4.48.49-pm.png?w=300 300w, https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-20-at-4.48.49-pm.png?w=768 768w, https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-20-at-4.48.49-pm.png?w=1024 1024w" sizes="(max-width: 525px) 100vw, 525px"   /><p id="caption-attachment-1211" class="wp-caption-text">From [Fernando et al 2016]</p></div><a href="https://arxiv.org/pdf/1609.09106.pdf">HyperNetworks (Ha et al 2016)</a> further scales HyperNEAT&#8217;s notion of indirect encodings to more complex tasks by learning a weight generation function with end-to-end training, including an extension that can generate time-varying weights for recurrent networks:</p>
<div data-shortcode="caption" id="attachment_1212" style="width: 3198px" class="wp-caption alignnone"><img aria-describedby="caption-attachment-1212" data-attachment-id="1212" data-permalink="https://wellecks.wordpress.com/2019/07/21/evolving-networks/screen-shot-2019-07-20-at-5-02-39-pm/#main" data-orig-file="https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-20-at-5.02.39-pm.png" data-orig-size="3188,1310" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen Shot 2019-07-20 at 5.02.39 PM" data-image-description="" data-image-caption="&lt;p&gt;From [Ha et al. 2016]&lt;/p&gt;
" data-medium-file="https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-20-at-5.02.39-pm.png?w=300" data-large-file="https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-20-at-5.02.39-pm.png?w=525" class="alignnone size-full wp-image-1212" src="https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-20-at-5.02.39-pm.png?w=525" alt="Screen Shot 2019-07-20 at 5.02.39 PM" srcset="https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-20-at-5.02.39-pm.png?w=525 525w, https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-20-at-5.02.39-pm.png?w=1050 1050w, https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-20-at-5.02.39-pm.png?w=150 150w, https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-20-at-5.02.39-pm.png?w=300 300w, https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-20-at-5.02.39-pm.png?w=768 768w, https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-20-at-5.02.39-pm.png?w=1024 1024w" sizes="(max-width: 525px) 100vw, 525px"   /><p id="caption-attachment-1212" class="wp-caption-text">From [Ha et al. 2016]</p></div>
<h3>Wrapping Up</h3>
<p>In this post we revisited a core technique for generating neural network topologies, and briefly traced some of its outgoing research paths. We took a brief step back from the constraints of pre-defined-layer architectures and searched through a space of very general (albeit small-scale) topologies. It was interesting to see how this generality has been refined towards some <a href="https://arxiv.org/pdf/1703.01041.pdf">larger scale</a> tasks, but also <a href="https://weightagnostic.github.io/">revisited</a>.  We briefly saw how fitness re-ranking and partitioning can be used to yield <em>a set of distinct solutions, </em>which connects to <a href="https://arxiv.org/pdf/1504.04909.pdf">other</a> <a href="http://eplex.cs.ucf.edu/papers/lehman_ecj11.pdf">concepts</a> that I may discuss further in future posts.</p>
<p style="text-align:center;">[<a href="https://gist.github.com/wellecks/226dab0ff0dde625b097869fb932cff9">Code</a>]</p>
<h2>Further Reading</h2>
<ul>
<li><a href="http://www.evolvingai.org/files/s42256-018-0006-z.pdf">Designing Neural Networks through Neuroevolution</a></li>
<li><a href="https://link.springer.com/article/10.1007/s00521-019-04160-6">On the automated, evolutionary design of neural networks: past, present, and future</a></li>
</ul>
<p><span id="more-1190"></span></p>
]]></content:encoded>
					
					<wfw:commentRss>https://wellecks.wordpress.com/2019/07/21/evolving-networks/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		
		<media:content url="https://0.gravatar.com/avatar/f7546f57a5fd69bc99ff1640cc4a4853?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">wellecks</media:title>
		</media:content>

		<media:content url="https://wellecks.files.wordpress.com/2019/07/objects.png" medium="image">
			<media:title type="html">objects</media:title>
		</media:content>

		<media:content url="https://wellecks.files.wordpress.com/2019/07/mutation.png" medium="image">
			<media:title type="html">mutation</media:title>
		</media:content>

		<media:content url="https://wellecks.files.wordpress.com/2019/07/crossover.png" medium="image">
			<media:title type="html">crossover</media:title>
		</media:content>

		<media:content url="https://wellecks.files.wordpress.com/2019/07/partition-1.jpg" medium="image">
			<media:title type="html">partition</media:title>
		</media:content>

		<media:content url="https://wellecks.files.wordpress.com/2019/07/xor-1.png" medium="image">
			<media:title type="html">xor</media:title>
		</media:content>

		<media:content url="https://wellecks.files.wordpress.com/2019/07/cartpole-1.png" medium="image">
			<media:title type="html">cartpole</media:title>
		</media:content>

		<media:content url="https://wellecks.files.wordpress.com/2019/07/lunar-1.png" medium="image">
			<media:title type="html">lunar</media:title>
		</media:content>

		<media:content url="https://wellecks.files.wordpress.com/2019/07/sigmoid.png?w=150" medium="image" />

		<media:content url="https://wellecks.files.wordpress.com/2019/07/tanh.png?w=150" medium="image" />

		<media:content url="https://wellecks.files.wordpress.com/2019/07/complex20.png" medium="image">
			<media:title type="html">complex20</media:title>
		</media:content>

		<media:content url="https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-21-at-3.56.44-pm.png" medium="image">
			<media:title type="html">xor_shared</media:title>
		</media:content>

		<media:content url="https://wellecks.files.wordpress.com/2019/07/codeepneat.png" medium="image" />

		<media:content url="https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-20-at-4.48.49-pm.png" medium="image">
			<media:title type="html">Screen Shot 2019-07-20 at 4.48.49 PM</media:title>
		</media:content>

		<media:content url="https://wellecks.files.wordpress.com/2019/07/screen-shot-2019-07-20-at-5.02.39-pm.png" medium="image">
			<media:title type="html">Screen Shot 2019-07-20 at 5.02.39 PM</media:title>
		</media:content>
	</item>
		<item>
		<title>ECIR 2016 Paper and Presentation</title>
		<link>https://wellecks.wordpress.com/2016/04/23/ecir-2016-paper-and-presentation/</link>
					<comments>https://wellecks.wordpress.com/2016/04/23/ecir-2016-paper-and-presentation/#respond</comments>
		
		<dc:creator><![CDATA[wellecks]]></dc:creator>
		<pubDate>Sat, 23 Apr 2016 23:49:14 +0000</pubDate>
				<category><![CDATA[machine learning]]></category>
		<category><![CDATA[projects]]></category>
		<category><![CDATA[ECIR]]></category>
		<category><![CDATA[information retrieval]]></category>
		<category><![CDATA[LambdaMART]]></category>
		<category><![CDATA[Machine learning]]></category>
		<guid isPermaLink="false">http://wellecks.wordpress.com/?p=1129</guid>

					<description><![CDATA[I recently presented a paper entitled Efficient AUC Optimization for Information Ranking Applications at the European Conference for Information Retrieval (ECIR) in Padua, Italy. In the paper, we derive gradient approximations for optimizing area under an ROC curve (AUC) and multi-class AUC using the LambdaMART algorithm. Here are slides for the talk, which give an overview of [&#8230;]]]></description>
										<content:encoded><![CDATA[<p>I recently presented a paper entitled <a href="https://arxiv.org/abs/1511.05202" target="_blank">Efficient AUC Optimization for Information Ranking Applications</a> at the <a href="http://www.springer.com/us/book/9783319306704?wt_mc=GoogleBooks.GoogleBooks.3.EN&amp;token=gbgen#otherversion=9783319306711">European Conference for Information Retrieval</a> (ECIR) in Padua, Italy.</p>
<p>In the paper, we derive gradient approximations for optimizing area under an ROC curve (AUC) and multi-class AUC using the LambdaMART algorithm. Here are slides for the talk, which give an overview of the paper and a brief review of Learning to Rank and LambdaMART:</p>
<ul>
<li><a title="ecir2016_welleck" href="https://wellecks.files.wordpress.com/2016/04/ecir2016_welleck.pdf">ECIR 2016 Presentation</a></li>
<li><a title="ecir2016_welleck_notes" href="https://wellecks.files.wordpress.com/2016/04/ecir2016_welleck_notes.pdf">ECIR 2016 Presentation (with notes)</a></li>
<li><a title="welleck_auc" href="https://wellecks.files.wordpress.com/2016/04/welleck_auc.pdf">Paper</a></li>
</ul>
<p>The goal was to expand LambdaMART to optimize AUC in order to add to the portfolio of metrics that the algorithm is currently used for. The approach was to derive a &#8220;λ-gradient&#8221; analogous to those that have been defined for other metrics such as NDCG and Mean Average Precision.</p>
<p>This in turn required an efficient way of computing a key quantity, namely the change in the AUC from swapping two items in the ranked list. One contribution of the paper is a simple, efficient formula for computing this quantity (along with a proof), which appears in the paper as:</p>
<p style="text-align:center;"><img data-attachment-id="1158" data-permalink="https://wellecks.wordpress.com/2016/04/23/ecir-2016-paper-and-presentation/delta_auc_theorem/#main" data-orig-file="https://wellecks.files.wordpress.com/2016/04/delta_auc_theorem.png" data-orig-size="2214,434" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="delta_auc_theorem" data-image-description="" data-image-caption="" data-medium-file="https://wellecks.files.wordpress.com/2016/04/delta_auc_theorem.png?w=300" data-large-file="https://wellecks.files.wordpress.com/2016/04/delta_auc_theorem.png?w=525" class="alignnone size-full wp-image-1158" src="https://wellecks.files.wordpress.com/2016/04/delta_auc_theorem.png?w=525" alt="delta_auc_theorem" srcset="https://wellecks.files.wordpress.com/2016/04/delta_auc_theorem.png?w=525 525w, https://wellecks.files.wordpress.com/2016/04/delta_auc_theorem.png?w=1050 1050w, https://wellecks.files.wordpress.com/2016/04/delta_auc_theorem.png?w=150 150w, https://wellecks.files.wordpress.com/2016/04/delta_auc_theorem.png?w=300 300w, https://wellecks.files.wordpress.com/2016/04/delta_auc_theorem.png?w=768 768w, https://wellecks.files.wordpress.com/2016/04/delta_auc_theorem.png?w=1024 1024w" sizes="(max-width: 525px) 100vw, 525px"   /></p>
<p>The paper also contains experimental results measuring the performance of LambdaMART using the derived gradients.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://wellecks.wordpress.com/2016/04/23/ecir-2016-paper-and-presentation/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		
		<media:content url="https://0.gravatar.com/avatar/f7546f57a5fd69bc99ff1640cc4a4853?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">wellecks</media:title>
		</media:content>

		<media:content url="https://wellecks.files.wordpress.com/2016/04/delta_auc_theorem.png" medium="image">
			<media:title type="html">delta_auc_theorem</media:title>
		</media:content>
	</item>
		<item>
		<title>Peering into the Black Box : Visualizing LambdaMART</title>
		<link>https://wellecks.wordpress.com/2015/02/21/peering-into-the-black-box-visualizing-lambdamart/</link>
					<comments>https://wellecks.wordpress.com/2015/02/21/peering-into-the-black-box-visualizing-lambdamart/#respond</comments>
		
		<dc:creator><![CDATA[wellecks]]></dc:creator>
		<pubDate>Sat, 21 Feb 2015 22:13:29 +0000</pubDate>
				<category><![CDATA[artificial intelligence]]></category>
		<category><![CDATA[machine learning]]></category>
		<category><![CDATA[d3.js]]></category>
		<category><![CDATA[heatmap tree]]></category>
		<category><![CDATA[jforests]]></category>
		<category><![CDATA[LambdaMART]]></category>
		<category><![CDATA[learning to rank]]></category>
		<category><![CDATA[Machine learning]]></category>
		<category><![CDATA[visualization]]></category>
		<guid isPermaLink="false">http://wellecks.wordpress.com/?p=1045</guid>

					<description><![CDATA[In the last post, I gave a broad overview of the Learning to Rank domain of machine learning that has applications in web search, machine translation, and question-answering systems. In this post, we&#8217;ll look at a state of the art model used in Learning to Rank called LambdaMART. We&#8217;ll take a look at some math underlying LambdaMART, then focus [&#8230;]]]></description>
										<content:encoded><![CDATA[<p>In the <span style="color:#808080;"><a style="color:#808080;" title="Learning to Rank Overview" href="https://wellecks.wordpress.com/2015/01/15/learning-to-rank-overview/">last post</a></span>, I gave a broad overview of the Learning to Rank domain of machine learning that has applications in web search, machine translation, and question-answering systems. In this post, we&#8217;ll look at a state of the art model used in Learning to Rank called LambdaMART. We&#8217;ll take a look at some math underlying LambdaMART, then focus on developing ways to visualize the model.</p>
<p>LambdaMART produces a tree ensemble model, a class of models traditionally viewed as &#8216;black boxes&#8217; since they take into account predictions of 10&#8217;s or 100&#8217;s of underlying trees. While viewing a single decision tree is intuitive and interpretable, viewing 100 at once would be overwhelming and uninformative:</p>
<p><a href="https://wellecks.files.wordpress.com/2015/02/tree.png"><img loading="lazy" data-attachment-id="1049" data-permalink="https://wellecks.wordpress.com/2015/02/21/peering-into-the-black-box-visualizing-lambdamart/tree/#main" data-orig-file="https://wellecks.files.wordpress.com/2015/02/tree.png" data-orig-size="1378,1284" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="tree" data-image-description="" data-image-caption="" data-medium-file="https://wellecks.files.wordpress.com/2015/02/tree.png?w=300" data-large-file="https://wellecks.files.wordpress.com/2015/02/tree.png?w=525" class="aligncenter wp-image-1049" src="https://wellecks.files.wordpress.com/2015/02/tree.png?w=285&#038;h=266" alt="tree" width="285" height="266" srcset="https://wellecks.files.wordpress.com/2015/02/tree.png?w=285&amp;h=266 285w, https://wellecks.files.wordpress.com/2015/02/tree.png?w=570&amp;h=532 570w, https://wellecks.files.wordpress.com/2015/02/tree.png?w=150&amp;h=140 150w, https://wellecks.files.wordpress.com/2015/02/tree.png?w=300&amp;h=280 300w" sizes="(max-width: 285px) 100vw, 285px" /></a></p>
<p>&nbsp;</p>
<p style="text-align:center;"><span style="color:#999999;">Single Tree</span></p>
<p>&nbsp;</p>
<p><a href="https://wellecks.files.wordpress.com/2015/02/ensemble1.png"><img loading="lazy" data-attachment-id="1051" data-permalink="https://wellecks.wordpress.com/2015/02/21/peering-into-the-black-box-visualizing-lambdamart/ensemble-2/#main" data-orig-file="https://wellecks.files.wordpress.com/2015/02/ensemble1.png" data-orig-size="2788,2082" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ensemble" data-image-description="" data-image-caption="&lt;p&gt;Ensemble of Trees&lt;/p&gt;
" data-medium-file="https://wellecks.files.wordpress.com/2015/02/ensemble1.png?w=300" data-large-file="https://wellecks.files.wordpress.com/2015/02/ensemble1.png?w=525" class="aligncenter wp-image-1051" src="https://wellecks.files.wordpress.com/2015/02/ensemble1.png?w=316&#038;h=236" alt="Ensemble of Trees" width="316" height="236" srcset="https://wellecks.files.wordpress.com/2015/02/ensemble1.png?w=316&amp;h=236 316w, https://wellecks.files.wordpress.com/2015/02/ensemble1.png?w=632&amp;h=472 632w, https://wellecks.files.wordpress.com/2015/02/ensemble1.png?w=150&amp;h=112 150w, https://wellecks.files.wordpress.com/2015/02/ensemble1.png?w=300&amp;h=224 300w" sizes="(max-width: 316px) 100vw, 316px" /></a></p>
<p style="text-align:center;"><span style="color:#999999;"> Ensemble of Trees</span></p>
<p>By moving from a single tree to an ensemble of trees, we tradeoff interpretability for performance.</p>
<p>In this post, we&#8217;ll take a look at the trees produced by the LambdaMART training process, and develop a visualization to view the ensemble of trees as a single collective unit. By doing so, we&#8217;ll gain back some of the intuitive interpretability that make tree models appealing. Through the visualization, we&#8217;ll peer into the black box model and gain some sense of the factors that the model uses to make predictions.</p>
<p>We use Java and the <span style="color:#808080;"><a style="color:#808080;" href="https://code.google.com/p/jforests/">JForests</a></span> library to train LambdaMART and parse its output, and d3.js for visualization. To get a sneak peek, the <span style="color:#808080;"><a style="color:#808080;" title="Heatmap Tree" href="http://heatmap-tree.herokuapp.com">final visualization is here</a></span>.</p>
<p style="text-align:center;"><strong>LambdaMART Overview</strong></p>
<p>Let&#8217;s take a look at some details of LambdaMART. For the full story, check out <span style="color:#808080;"><a style="color:#808080;" href="http://research-srv.microsoft.com/pubs/132652/MSR-TR-2010-82.pdf">this paper</a></span> from Microsoft Research.</p>
<p>At a high level, LambdaMART is an algorithm that uses gradient boosting to directly optimize Learning to Rank specific cost functions such as NDCG. To understand LambdaMART we&#8217;ll look at two aspects: Lambda and MART.</p>
<p><strong>MART</strong></p>
<p>LambdaMART is a specific instance of Gradient Boosted Regression Trees, also referred to as Multiple Additive Regression Trees (MART). Gradient Boosting is a technique for forming a model that is a weighted combination of an ensemble of &#8220;weak learners&#8221;. In our case, each &#8220;weak learner&#8221; is a decision tree.</p>
<p>Our goal is to find a function <img src="https://s0.wp.com/latex.php?latex=f%28x%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%28x%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%28x%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f(x)" class="latex" /> that minimizes the expected loss <img src="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L" class="latex" />:</p>
<p style="text-align:center;"><img src="https://s0.wp.com/latex.php?latex=%5Chat%7Bf%7D%28x%29+%3D+%5Carg%5Cmin_%7Bf%28x%29%7DE%5BL%28y%2C+f%28x%29%29%7Cx%5D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Chat%7Bf%7D%28x%29+%3D+%5Carg%5Cmin_%7Bf%28x%29%7DE%5BL%28y%2C+f%28x%29%29%7Cx%5D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Chat%7Bf%7D%28x%29+%3D+%5Carg%5Cmin_%7Bf%28x%29%7DE%5BL%28y%2C+f%28x%29%29%7Cx%5D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;hat{f}(x) = &#92;arg&#92;min_{f(x)}E[L(y, f(x))|x]" class="latex" /></p>
<p style="text-align:left;">for feature vectors <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> and labels <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" />.</p>
<p style="text-align:left;">To do so we first view <img src="https://s0.wp.com/latex.php?latex=%5Chat%7Bf%7D%28x%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Chat%7Bf%7D%28x%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Chat%7Bf%7D%28x%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;hat{f}(x)" class="latex" /> as a sum of weak learners <img src="https://s0.wp.com/latex.php?latex=f_m&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f_m&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f_m&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f_m" class="latex" />:</p>
<p style="text-align:center;"><img src="https://s0.wp.com/latex.php?latex=%5Chat%7Bf%7D%28x%29%3D%5Csum_%7Bm%3D1%7D%5EM+f_%7Bm%7D%28x%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Chat%7Bf%7D%28x%29%3D%5Csum_%7Bm%3D1%7D%5EM+f_%7Bm%7D%28x%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Chat%7Bf%7D%28x%29%3D%5Csum_%7Bm%3D1%7D%5EM+f_%7Bm%7D%28x%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;hat{f}(x)=&#92;sum_{m=1}^M f_{m}(x)" class="latex" /></p>
<p style="text-align:left;">Since we are dealing with decision trees, evaluating <img src="https://s0.wp.com/latex.php?latex=f_%7Bm%7D%28x%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f_%7Bm%7D%28x%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f_%7Bm%7D%28x%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f_{m}(x)" class="latex" /> corresponds to passing <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> down the tree <img src="https://s0.wp.com/latex.php?latex=f_%7Bm%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f_%7Bm%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f_%7Bm%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f_{m}" class="latex" /> until it reaches a leaf node <img src="https://s0.wp.com/latex.php?latex=l&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=l&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=l&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="l" class="latex" />. The predicted value is then equal to a parameter <img src="https://s0.wp.com/latex.php?latex=%5Cgamma_l&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cgamma_l&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cgamma_l&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;gamma_l" class="latex" />.</p>
<p style="text-align:left;">Decision trees consist of two types of parameters: region assignments <img src="https://s0.wp.com/latex.php?latex=R_i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=R_i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=R_i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="R_i" class="latex" /> that assign a training example <img src="https://s0.wp.com/latex.php?latex=x_i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x_i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x_i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x_i" class="latex" /> to a leaf node <img src="https://s0.wp.com/latex.php?latex=l&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=l&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=l&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="l" class="latex" />, and leaf outputs <img src="https://s0.wp.com/latex.php?latex=%5Cgamma_l&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cgamma_l&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cgamma_l&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;gamma_l" class="latex" /> that represent the tree&#8217;s output for all examples assigned to region <img src="https://s0.wp.com/latex.php?latex=R_l&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=R_l&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=R_l&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="R_l" class="latex" />. Hence we can write each weak learner <img src="https://s0.wp.com/latex.php?latex=f_%7Bm%7D%28x%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f_%7Bm%7D%28x%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f_%7Bm%7D%28x%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f_{m}(x)" class="latex" /> as a parameterized tree <img src="https://s0.wp.com/latex.php?latex=h_%7Bm%7D%28x%3BR_%7Bm%7D%2C+%5Cgamma_%7Bm%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=h_%7Bm%7D%28x%3BR_%7Bm%7D%2C+%5Cgamma_%7Bm%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=h_%7Bm%7D%28x%3BR_%7Bm%7D%2C+%5Cgamma_%7Bm%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="h_{m}(x;R_{m}, &#92;gamma_{m})" class="latex" />, giving:</p>
<p style="text-align:center;"><img src="https://s0.wp.com/latex.php?latex=%5Chat%7Bf%7D%28x%29%3D%5Csum_%7Bm%3D1%7D%5EM+f_%7Bm%7D%28x%29%3D%5Csum_%7Bm%3D1%7D%5EM+h_%7Bm%7D%28x%3B+R_%7Bm%7D%2C+%5Cgamma_%7Bm%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Chat%7Bf%7D%28x%29%3D%5Csum_%7Bm%3D1%7D%5EM+f_%7Bm%7D%28x%29%3D%5Csum_%7Bm%3D1%7D%5EM+h_%7Bm%7D%28x%3B+R_%7Bm%7D%2C+%5Cgamma_%7Bm%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Chat%7Bf%7D%28x%29%3D%5Csum_%7Bm%3D1%7D%5EM+f_%7Bm%7D%28x%29%3D%5Csum_%7Bm%3D1%7D%5EM+h_%7Bm%7D%28x%3B+R_%7Bm%7D%2C+%5Cgamma_%7Bm%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;hat{f}(x)=&#92;sum_{m=1}^M f_{m}(x)=&#92;sum_{m=1}^M h_{m}(x; R_{m}, &#92;gamma_{m})" class="latex" /></p>
<p style="text-align:left;">Gradient Boosting finds each tree in a stepwise fashion. We start with an initial tree <img src="https://s0.wp.com/latex.php?latex=f_1&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f_1&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f_1&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f_1" class="latex" />, then step to another tree <img src="https://s0.wp.com/latex.php?latex=f_2&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f_2&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f_2&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f_2" class="latex" />, and so on:</p>
<p style="text-align:center;"><img src="https://s0.wp.com/latex.php?latex=%5Chat%7Bf%7D_%7B1%7D%28x%29+%3D+f_%7B1%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Chat%7Bf%7D_%7B1%7D%28x%29+%3D+f_%7B1%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Chat%7Bf%7D_%7B1%7D%28x%29+%3D+f_%7B1%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;hat{f}_{1}(x) = f_{1}" class="latex" /></p>
<p style="text-align:center;"><img src="https://s0.wp.com/latex.php?latex=%5Chat%7Bf%7D_%7B2%7D%28x%29+%3D+f_%7B1%7D+%2B+f_%7B2%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Chat%7Bf%7D_%7B2%7D%28x%29+%3D+f_%7B1%7D+%2B+f_%7B2%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Chat%7Bf%7D_%7B2%7D%28x%29+%3D+f_%7B1%7D+%2B+f_%7B2%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;hat{f}_{2}(x) = f_{1} + f_{2}" class="latex" /></p>
<p style="text-align:center;">&#8230;</p>
<p style="text-align:center;"><img src="https://s0.wp.com/latex.php?latex=%5Chat%7Bf%7D_%7BM%7D%28x%29+%3D+%5Csum_%7Bm%3D1%7D%5E%7BM%7Df_%7Bm%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Chat%7Bf%7D_%7BM%7D%28x%29+%3D+%5Csum_%7Bm%3D1%7D%5E%7BM%7Df_%7Bm%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Chat%7Bf%7D_%7BM%7D%28x%29+%3D+%5Csum_%7Bm%3D1%7D%5E%7BM%7Df_%7Bm%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;hat{f}_{M}(x) = &#92;sum_{m=1}^{M}f_{m}" class="latex" /></p>
<p style="text-align:left;">How do we determine the steps? At each step, we&#8217;d like the model to change such that the loss decreases as much as possible. The locally optimal decrease corresponds to the gradient of the loss with respect to the current model <img src="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="m" class="latex" />:</p>
<p style="text-align:center;"><img src="https://s0.wp.com/latex.php?latex=g_%7Bim%7D%3D%5Cfrac%7B%5Cpartial+L%5Bf%28x_i%29%2C+y_i%5D%7D%7B%5Cpartial+f%28x_i%29%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g_%7Bim%7D%3D%5Cfrac%7B%5Cpartial+L%5Bf%28x_i%29%2C+y_i%5D%7D%7B%5Cpartial+f%28x_i%29%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g_%7Bim%7D%3D%5Cfrac%7B%5Cpartial+L%5Bf%28x_i%29%2C+y_i%5D%7D%7B%5Cpartial+f%28x_i%29%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g_{im}=&#92;frac{&#92;partial L[f(x_i), y_i]}{&#92;partial f(x_i)}" class="latex" /></p>
<p style="text-align:left;">Hence we define the step as <img src="https://s0.wp.com/latex.php?latex=f_m%3D-%5Crho_mg_m&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f_m%3D-%5Crho_mg_m&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f_m%3D-%5Crho_mg_m&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f_m=-&#92;rho_mg_m" class="latex" />. This gives us insight into how Gradient Boosting solves the minimization &#8211; the algorithm is performing Gradient Descent in function space.</p>
<p style="text-align:left;">Now, we know that we want to take a gradient step, but still haven&#8217;t said how that translates to finding a tree. To do so, we build a tree that <em>models the gradient</em>; by adding such a tree to the ensemble, we effectively take a gradient step from the previous model. To fit the tree, we use squared error loss, giving the minimization problem:</p>
<p style="text-align:center;"><img src="https://s0.wp.com/latex.php?latex=argmin_%7BR%2C+%5Cgamma%7D%5Csum_%7Bi%3D1%7D%5EN%28-g_%7Bim%7D-F%28x_i%3BR%2C+%5Cgamma%29%29%5E2&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=argmin_%7BR%2C+%5Cgamma%7D%5Csum_%7Bi%3D1%7D%5EN%28-g_%7Bim%7D-F%28x_i%3BR%2C+%5Cgamma%29%29%5E2&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=argmin_%7BR%2C+%5Cgamma%7D%5Csum_%7Bi%3D1%7D%5EN%28-g_%7Bim%7D-F%28x_i%3BR%2C+%5Cgamma%29%29%5E2&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="argmin_{R, &#92;gamma}&#92;sum_{i=1}^N(-g_{im}-F(x_i;R, &#92;gamma))^2" class="latex" /></p>
<p style="text-align:left;">Where <img src="https://s0.wp.com/latex.php?latex=F%28x_i%3BR%2C+%5Cgamma%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=F%28x_i%3BR%2C+%5Cgamma%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=F%28x_i%3BR%2C+%5Cgamma%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="F(x_i;R, &#92;gamma)" class="latex" /> denotes a regression tree with parameters <img src="https://s0.wp.com/latex.php?latex=R%2C+%5Cgamma&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=R%2C+%5Cgamma&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=R%2C+%5Cgamma&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="R, &#92;gamma" class="latex" />.</p>
<p style="text-align:left;">Let&#8217;s take a step back. We&#8217;ve just set up a framework for finding an ensemble of trees that, when added together, minimizes a loss function. It&#8217;s a &#8220;framework&#8221; in the sense that we can use it if we merely supply gradients of the loss function at each training point. This is where the &#8220;Lambda&#8221; part of LambdaMART comes into play.</p>
<p><span style="color:#999999;">For further reading, Chapter 10 of <a style="color:#999999;" href="http://statweb.stanford.edu/~tibs/ElemStatLearn/">Elements of Statistical Learning</a> provides a great and thorough overview. <span style="color:#808080;"><a style="color:#808080;" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3885826/">This paper</a> </span>also provides a good intro of Gradient Boosting.</span></p>
<p style="text-align:left;"><strong>Lambda</strong></p>
<p style="text-align:left;">In ranking, the loss function that we&#8217;ll most likely care about optimizing is probably either NDCG, MAP, or MRR. Unfortunately, these loss functions aren&#8217;t differentiable at all points, so we can&#8217;t use them directly in our Gradient Boosting &#8220;framework&#8221;, since it&#8217;s unclear how we can provide the gradients at each training point.</p>
<p style="text-align:left;">To address this, LambdaMART uses an idea from a model called <span style="color:#808080;"><a style="color:#808080;" href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.180.634">LambdaRank</a></span>. For each training point pair <img src="https://s0.wp.com/latex.php?latex=i%2Cj&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i%2Cj&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i%2Cj&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i,j" class="latex" />, we compute a value <img src="https://s0.wp.com/latex.php?latex=%5Clambda_%7Bi%2Cj%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clambda_%7Bi%2Cj%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda_%7Bi%2Cj%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lambda_{i,j}" class="latex" /> that acts as the gradient we need. Intuitively, <img src="https://s0.wp.com/latex.php?latex=%5Clambda_%7Bi%2Cj%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clambda_%7Bi%2Cj%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda_%7Bi%2Cj%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lambda_{i,j}" class="latex" /> can be thought of as a force that moves documents up and down the ranked list. For instance, if document <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> is ranked lower than document <img src="https://s0.wp.com/latex.php?latex=j&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=j&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=j&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="j" class="latex" />, then document <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> will receive a push of size <img src="https://s0.wp.com/latex.php?latex=%7C%5Clambda_%7Bi%2Cj%7D%7C&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7C%5Clambda_%7Bi%2Cj%7D%7C&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7C%5Clambda_%7Bi%2Cj%7D%7C&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|&#92;lambda_{i,j}|" class="latex" /> downwards in the ranked list, and <img src="https://s0.wp.com/latex.php?latex=j&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=j&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=j&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="j" class="latex" /> will be pushed upwards the same amount. The LambdaMART <span style="color:#808080;"><a style="color:#808080;" href="http://research-srv.microsoft.com/pubs/132652/MSR-TR-2010-82.pdf">paper</a></span> reports that empirically, the <img src="https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lambda" class="latex" />&#8216;s have been used successfully to optimize NDCG, MAP, and MRR.</p>
<p style="text-align:left;">Hence in LambdaMART we use the Gradient Boosting framework with the <img src="https://s0.wp.com/latex.php?latex=%5Clambda_i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clambda_i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda_i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lambda_i" class="latex" />&#8216;s acting as the gradients <img src="https://s0.wp.com/latex.php?latex=g_i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g_i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g_i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g_i" class="latex" />. This leads to update rules for the leaf values <img src="https://s0.wp.com/latex.php?latex=%5Cgamma_l&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cgamma_l&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cgamma_l&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;gamma_l" class="latex" /> that depend on the <img src="https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lambda" class="latex" /> values of the training instances that fall in leaf <img src="https://s0.wp.com/latex.php?latex=l&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=l&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=l&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="l" class="latex" />.</p>
<h2 style="text-align:center;">Visualizing Gradient Boosting</h2>
<p>We&#8217;ve observed that LambdaMART trains an ensemble of trees sequentially. What does this sequence of trees look like? Let&#8217;s look at an ensemble of 19 trees trained with LambdaMART on the OHSUMED dataset:</p>
<p><a href="https://wellecks.files.wordpress.com/2015/02/ensemble.gif"><img loading="lazy" data-attachment-id="1075" data-permalink="https://wellecks.wordpress.com/2015/02/21/peering-into-the-black-box-visualizing-lambdamart/ensemble-3/#main" data-orig-file="https://wellecks.files.wordpress.com/2015/02/ensemble.gif" data-orig-size="855,666" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ensemble" data-image-description="" data-image-caption="" data-medium-file="https://wellecks.files.wordpress.com/2015/02/ensemble.gif?w=300" data-large-file="https://wellecks.files.wordpress.com/2015/02/ensemble.gif?w=525" class="aligncenter size-full wp-image-1075" src="https://wellecks.files.wordpress.com/2015/02/ensemble.gif?w=525&#038;h=409" alt="ensemble" width="525" height="409" /></a></p>
<p>At each inner node, the small number denotes the feature label, and the larger number denotes the threshold. The number at each leaf node denotes the leaf output.</p>
<p>We can see that each tree is somewhat similar to the previous tree. This makes sense given that each tree <img src="https://s0.wp.com/latex.php?latex=t_i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t_i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t_i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t_i" class="latex" /> is dependent on the model state <img src="https://s0.wp.com/latex.php?latex=F_%7Bi-1%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=F_%7Bi-1%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=F_%7Bi-1%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="F_{i-1}" class="latex" /> since it is fit to the gradient with respect to that model&#8217;s gradient.</p>
<p>The step-by-step animation gives us insight into what is happening during training. It&#8217;s a great way to visualize and gain an intuition of the gradient boosting process &#8211; we see consecutive trees being produced that depend on the previous tree. However, we are still viewing the LambdaMART model as a group of <em>separate</em> trees; we still need to develop a way of viewing the final model cohesively.</p>
<p>Does the sequence animation tell us anything that could help with developing a single, cohesive model view? We can start with the observation that often, the trees look &#8220;roughly similar&#8221;.</p>
<p>Sometimes two trees will have the same feature at a given node position; for instance the root favors features 7, 9, and 11. Trees may not even change from step-to-step or may share a similar overall structure, such as trees #3 and #4 &#8211; notice how the numbers change, but the structure remains the same. Finally, all of the trees only draw from a subset of the total feature set; for instance feature 4 is never used by any of the trees.</p>
<p><strong>Grouping Similar Nodes</strong></p>
<p>Given these observations, we can think about how to build a unified visualization that takes advantage of reused features and similar structure between trees. Let&#8217;s consider the root node. We can count the frequency of each feature that occurs as the root node across the entire ensemble, leading to a single node that shows that feature 7 was used as the feature for the root node for 3 trees, feature 9 for 5 trees, and so on:</p>
<p style="text-align:center;"><a href="https://wellecks.files.wordpress.com/2015/02/node1.png"><img loading="lazy" data-attachment-id="1077" data-permalink="https://wellecks.wordpress.com/2015/02/21/peering-into-the-black-box-visualizing-lambdamart/node1/#main" data-orig-file="https://wellecks.files.wordpress.com/2015/02/node1.png" data-orig-size="622,564" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="node1" data-image-description="" data-image-caption="" data-medium-file="https://wellecks.files.wordpress.com/2015/02/node1.png?w=300" data-large-file="https://wellecks.files.wordpress.com/2015/02/node1.png?w=525" class="aligncenter  wp-image-1077" src="https://wellecks.files.wordpress.com/2015/02/node1.png?w=174&#038;h=142" alt="node1" width="174" height="142" /></a></p>
<p>At each tree level <em>h</em>, there are <img src="https://s0.wp.com/latex.php?latex=2%5Eh&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=2%5Eh&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2%5Eh&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="2^h" class="latex" /> possible node positions. We can collect the feature frequencies for each of these positions across the ensemble. If a position doesn&#8217;t appear in a tree, we mark it as &#8216;DNE&#8217;, and if a position is a leaf, we mark it as &#8216;Leaf&#8217;, such as position (3, 6):</p>
<p style="text-align:center;"><a href="https://wellecks.files.wordpress.com/2015/02/node2.png"><img loading="lazy" data-attachment-id="1078" data-permalink="https://wellecks.wordpress.com/2015/02/21/peering-into-the-black-box-visualizing-lambdamart/node2/#main" data-orig-file="https://wellecks.files.wordpress.com/2015/02/node2.png" data-orig-size="600,562" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="node2" data-image-description="" data-image-caption="" data-medium-file="https://wellecks.files.wordpress.com/2015/02/node2.png?w=300" data-large-file="https://wellecks.files.wordpress.com/2015/02/node2.png?w=525" class="aligncenter  wp-image-1078" src="https://wellecks.files.wordpress.com/2015/02/node2.png?w=150&#038;h=141" alt="node2" width="150" height="141" srcset="https://wellecks.files.wordpress.com/2015/02/node2.png?w=150&amp;h=141 150w, https://wellecks.files.wordpress.com/2015/02/node2.png?w=300&amp;h=282 300w" sizes="(max-width: 150px) 100vw, 150px" /></a></p>
<p style="text-align:center;"><strong>Heatmap Tree</strong></p>
<p>At each node, we have a list of feature (or DNE or Leaf) counts. Heatmaps provide a natural way of visualizing this count information. We can make each node of the ordered-pair-tree into a heatmap, giving rise to the &#8220;Heatmap Tree&#8221;:</p>
<p style="text-align:center;"><a href="http://heatmap-tree.herokuapp.com/"><img data-attachment-id="1086" data-permalink="https://wellecks.wordpress.com/2015/02/21/peering-into-the-black-box-visualizing-lambdamart/ohsumed_10_1_1_1/#main" data-orig-file="https://wellecks.files.wordpress.com/2015/02/ohsumed_10_1_1_1.png" data-orig-size="1529,367" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ohsumed_10_1_1_1" data-image-description="" data-image-caption="" data-medium-file="https://wellecks.files.wordpress.com/2015/02/ohsumed_10_1_1_1.png?w=300" data-large-file="https://wellecks.files.wordpress.com/2015/02/ohsumed_10_1_1_1.png?w=525" class="aligncenter wp-image-1086 size-full" src="https://wellecks.files.wordpress.com/2015/02/ohsumed_10_1_1_1.png?w=525" alt="ohsumed_10_1_1_1" srcset="https://wellecks.files.wordpress.com/2015/02/ohsumed_10_1_1_1.png?w=525 525w, https://wellecks.files.wordpress.com/2015/02/ohsumed_10_1_1_1.png?w=1050 1050w, https://wellecks.files.wordpress.com/2015/02/ohsumed_10_1_1_1.png?w=150 150w, https://wellecks.files.wordpress.com/2015/02/ohsumed_10_1_1_1.png?w=300 300w, https://wellecks.files.wordpress.com/2015/02/ohsumed_10_1_1_1.png?w=768 768w, https://wellecks.files.wordpress.com/2015/02/ohsumed_10_1_1_1.png?w=1024 1024w" sizes="(max-width: 525px) 100vw, 525px"   /></a></p>
<p style="text-align:center;"><span style="color:#808080;">The Heatmap Tree</span></p>
<p>To view the interactive d3.js visualization, see <span style="color:#808080;"><a style="color:#808080;" title="Heatmap Tree" href="http://heatmap-tree.herokuapp.com/">this link</a></span>.</p>
<p>The Heatmap Tree shows the entire ensemble as a single unit. Each number is a feature, and the color scale tells us how many trees use that feature at the given node:</p>
<p style="text-align:center;"><a href="http://heatmap-tree.herokuapp.com/"><img data-attachment-id="1120" data-permalink="https://wellecks.wordpress.com/2015/02/21/peering-into-the-black-box-visualizing-lambdamart/screen-shot-2015-02-19-at-9-07-21-pm/#main" data-orig-file="https://wellecks.files.wordpress.com/2015/02/screen-shot-2015-02-19-at-9-07-21-pm.png" data-orig-size="404,103" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Heatmap Detail" data-image-description="" data-image-caption="" data-medium-file="https://wellecks.files.wordpress.com/2015/02/screen-shot-2015-02-19-at-9-07-21-pm.png?w=300" data-large-file="https://wellecks.files.wordpress.com/2015/02/screen-shot-2015-02-19-at-9-07-21-pm.png?w=404" class="aligncenter size-full wp-image-1120" src="https://wellecks.files.wordpress.com/2015/02/screen-shot-2015-02-19-at-9-07-21-pm.png?w=525" alt="Heatmap Detail" srcset="https://wellecks.files.wordpress.com/2015/02/screen-shot-2015-02-19-at-9-07-21-pm.png 404w, https://wellecks.files.wordpress.com/2015/02/screen-shot-2015-02-19-at-9-07-21-pm.png?w=150 150w, https://wellecks.files.wordpress.com/2015/02/screen-shot-2015-02-19-at-9-07-21-pm.png?w=300 300w" sizes="(max-width: 404px) 100vw, 404px"   /></a></p>
<p>By looking at the Heatmap Tree we can get a sense of which features the tree uses when it classifies instances. The ensemble uses features 7, 9, 11, 25, and 29 to perform the initial split, with 11 being used the most often. Further down the tree, we see features 7 and 9 again, along with common features such as 33 and 37. We can easily see that most of the trees in the ensemble are between 5 and 7 levels deep, and that while there are 46 total features, at a given node location the most variation we see is 9 features.</p>
<p>The Heatmap Tree can bring together hundreds of trees, such as this visualization of a 325 tree ensemble:</p>
<p style="text-align:center;"><a href="https://wellecks.files.wordpress.com/2015/02/325.png"><img loading="lazy" data-attachment-id="1091" data-permalink="https://wellecks.wordpress.com/2015/02/21/peering-into-the-black-box-visualizing-lambdamart/attachment/325/#main" data-orig-file="https://wellecks.files.wordpress.com/2015/02/325.png" data-orig-size="1538,443" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="325" data-image-description="" data-image-caption="" data-medium-file="https://wellecks.files.wordpress.com/2015/02/325.png?w=300" data-large-file="https://wellecks.files.wordpress.com/2015/02/325.png?w=525" class="aligncenter size-full wp-image-1091" src="https://wellecks.files.wordpress.com/2015/02/325.png?w=525&#038;h=151" alt="325" width="525" height="151" srcset="https://wellecks.files.wordpress.com/2015/02/325.png?w=525&amp;h=151 525w, https://wellecks.files.wordpress.com/2015/02/325.png?w=1050&amp;h=302 1050w, https://wellecks.files.wordpress.com/2015/02/325.png?w=150&amp;h=43 150w, https://wellecks.files.wordpress.com/2015/02/325.png?w=300&amp;h=86 300w, https://wellecks.files.wordpress.com/2015/02/325.png?w=768&amp;h=221 768w, https://wellecks.files.wordpress.com/2015/02/325.png?w=1024&amp;h=295 1024w" sizes="(max-width: 525px) 100vw, 525px" /></a></p>
<p><strong>Tuning Parameters</strong></p>
<p>The Heatmap Tree also lets us see how tuning parameters affect the final model. For instance, as we decrease the learning rate from 0.10 to 0.001, we see the ensemble size fluctuate:</p>
<p style="text-align:center;"><a href="https://wellecks.files.wordpress.com/2015/02/ohsumed_10_1_1_1.png"><img loading="lazy" data-attachment-id="1086" data-permalink="https://wellecks.wordpress.com/2015/02/21/peering-into-the-black-box-visualizing-lambdamart/ohsumed_10_1_1_1/#main" data-orig-file="https://wellecks.files.wordpress.com/2015/02/ohsumed_10_1_1_1.png" data-orig-size="1529,367" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ohsumed_10_1_1_1" data-image-description="" data-image-caption="" data-medium-file="https://wellecks.files.wordpress.com/2015/02/ohsumed_10_1_1_1.png?w=300" data-large-file="https://wellecks.files.wordpress.com/2015/02/ohsumed_10_1_1_1.png?w=525" class="aligncenter size-full wp-image-1086" src="https://wellecks.files.wordpress.com/2015/02/ohsumed_10_1_1_1.png?w=525&#038;h=126" alt="ohsumed_10_1_1_1" width="525" height="126" srcset="https://wellecks.files.wordpress.com/2015/02/ohsumed_10_1_1_1.png?w=525&amp;h=126 525w, https://wellecks.files.wordpress.com/2015/02/ohsumed_10_1_1_1.png?w=1050&amp;h=252 1050w, https://wellecks.files.wordpress.com/2015/02/ohsumed_10_1_1_1.png?w=150&amp;h=36 150w, https://wellecks.files.wordpress.com/2015/02/ohsumed_10_1_1_1.png?w=300&amp;h=72 300w, https://wellecks.files.wordpress.com/2015/02/ohsumed_10_1_1_1.png?w=768&amp;h=184 768w, https://wellecks.files.wordpress.com/2015/02/ohsumed_10_1_1_1.png?w=1024&amp;h=246 1024w" sizes="(max-width: 525px) 100vw, 525px" /></a></p>
<p style="text-align:center;"><span style="color:#808080;">Learning Rate 0.10</span></p>
<p style="text-align:center;"><a href="https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_01_1_1.png"><img loading="lazy" data-attachment-id="1080" data-permalink="https://wellecks.wordpress.com/2015/02/21/peering-into-the-black-box-visualizing-lambdamart/ohsumed_fold2_10_01_1_1/#main" data-orig-file="https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_01_1_1.png" data-orig-size="1533,449" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ohsumed_fold2_10_01_1_1" data-image-description="" data-image-caption="" data-medium-file="https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_01_1_1.png?w=300" data-large-file="https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_01_1_1.png?w=525" class="aligncenter size-full wp-image-1080" src="https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_01_1_1.png?w=525&#038;h=154" alt="ohsumed_fold2_10_01_1_1" width="525" height="154" srcset="https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_01_1_1.png?w=525&amp;h=154 525w, https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_01_1_1.png?w=1050&amp;h=308 1050w, https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_01_1_1.png?w=150&amp;h=44 150w, https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_01_1_1.png?w=300&amp;h=88 300w, https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_01_1_1.png?w=768&amp;h=225 768w, https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_01_1_1.png?w=1024&amp;h=300 1024w" sizes="(max-width: 525px) 100vw, 525px" /></a></p>
<p style="text-align:center;"><span style="color:#808080;">Learning Rate 0.01</span></p>
<p style="text-align:center;"><a href="https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_001_1_1.png"><img loading="lazy" data-attachment-id="1081" data-permalink="https://wellecks.wordpress.com/2015/02/21/peering-into-the-black-box-visualizing-lambdamart/ohsumed_fold2_10_001_1_1/#main" data-orig-file="https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_001_1_1.png" data-orig-size="1506,418" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ohsumed_fold2_10_001_1_1" data-image-description="" data-image-caption="" data-medium-file="https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_001_1_1.png?w=300" data-large-file="https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_001_1_1.png?w=525" class="aligncenter size-full wp-image-1081" src="https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_001_1_1.png?w=525&#038;h=146" alt="ohsumed_fold2_10_001_1_1" width="525" height="146" srcset="https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_001_1_1.png?w=525&amp;h=146 525w, https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_001_1_1.png?w=1050&amp;h=292 1050w, https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_001_1_1.png?w=150&amp;h=42 150w, https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_001_1_1.png?w=300&amp;h=83 300w, https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_001_1_1.png?w=768&amp;h=213 768w, https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_001_1_1.png?w=1024&amp;h=284 1024w" sizes="(max-width: 525px) 100vw, 525px" /></a></p>
<p style="text-align:center;"><span style="color:#808080;">Learning Rate 0.001</span></p>
<p>Notice how in the 0.01 case, the Heatmap Tree concisely summarized a 111-tree ensemble.</p>
<p>When we use feature subsampling, we see the number of features at each node increase (in general). Each tree has a different limited subset of features to choose from, leading to a spread in the overall distribution of chosen features:</p>
<p style="text-align:center;"><a href="https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_05_1_06.png"><img loading="lazy" data-attachment-id="1083" data-permalink="https://wellecks.wordpress.com/2015/02/21/peering-into-the-black-box-visualizing-lambdamart/ohsumed_fold2_10_05_1_06/#main" data-orig-file="https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_05_1_06.png" data-orig-size="1566,441" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ohsumed_fold2_10_05_1_06" data-image-description="" data-image-caption="" data-medium-file="https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_05_1_06.png?w=300" data-large-file="https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_05_1_06.png?w=525" class="aligncenter size-full wp-image-1083" src="https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_05_1_06.png?w=525&#038;h=148" alt="ohsumed_fold2_10_05_1_06" width="525" height="148" srcset="https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_05_1_06.png?w=525&amp;h=148 525w, https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_05_1_06.png?w=1050&amp;h=296 1050w, https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_05_1_06.png?w=150&amp;h=42 150w, https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_05_1_06.png?w=300&amp;h=84 300w, https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_05_1_06.png?w=768&amp;h=216 768w, https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_05_1_06.png?w=1024&amp;h=288 1024w" sizes="(max-width: 525px) 100vw, 525px" /></a></p>
<p style="text-align:center;"><span style="color:#808080;">Feature subsampling 0.6</span></p>
<p>Feature subsampling <em>and</em> training data subsampling makes this ensemble more crowded:</p>
<p style="text-align:center;"><a href="https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_05_06_06.png"><img loading="lazy" data-attachment-id="1084" data-permalink="https://wellecks.wordpress.com/2015/02/21/peering-into-the-black-box-visualizing-lambdamart/ohsumed_fold2_10_05_06_06/#main" data-orig-file="https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_05_06_06.png" data-orig-size="1550,438" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ohsumed_fold2_10_05_06_06" data-image-description="" data-image-caption="" data-medium-file="https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_05_06_06.png?w=300" data-large-file="https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_05_06_06.png?w=525" class="aligncenter size-full wp-image-1084" src="https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_05_06_06.png?w=525&#038;h=148" alt="ohsumed_fold2_10_05_06_06" width="525" height="148" srcset="https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_05_06_06.png?w=525&amp;h=148 525w, https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_05_06_06.png?w=1047&amp;h=296 1047w, https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_05_06_06.png?w=150&amp;h=42 150w, https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_05_06_06.png?w=300&amp;h=85 300w, https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_05_06_06.png?w=768&amp;h=217 768w, https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_05_06_06.png?w=1024&amp;h=289 1024w" sizes="(max-width: 525px) 100vw, 525px" /></a></p>
<p style="text-align:center;"><span style="color:#808080;">Feature subsampling 0.6, Data subsampling 0.6</span></p>
<p>Note that these parameter trends do not necessarily generalize. However, the Heatmap Tree captures all of the trees and features in a single structure, and gives us insight into the structural results of our parameter choices.</p>
<p><strong>Limitations</strong></p>
<p>The Heatmap Tree, unfortunately, has its limits. With wide variation of features and many leaves, the tree becomes crowded:</p>
<p style="text-align:center;"><a href="https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_25.png"><img loading="lazy" data-attachment-id="1085" data-permalink="https://wellecks.wordpress.com/2015/02/21/peering-into-the-black-box-visualizing-lambdamart/ohsumed_fold2_25/#main" data-orig-file="https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_25.png" data-orig-size="1599,869" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ohsumed_fold2_25" data-image-description="" data-image-caption="" data-medium-file="https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_25.png?w=300" data-large-file="https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_25.png?w=525" class="aligncenter size-full wp-image-1085" src="https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_25.png?w=525&#038;h=285" alt="ohsumed_fold2_25" width="525" height="285" srcset="https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_25.png?w=525&amp;h=285 525w, https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_25.png?w=1050&amp;h=570 1050w, https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_25.png?w=150&amp;h=82 150w, https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_25.png?w=300&amp;h=163 300w, https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_25.png?w=768&amp;h=417 768w, https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_25.png?w=1024&amp;h=557 1024w" sizes="(max-width: 525px) 100vw, 525px" /></a></p>
<p>Since the number of possible node locations at a given level increases exponentially with height, the tree also suffers when trying to visualize deep trees.</p>
<p><strong>Expansions</strong></p>
<p>Another nice aspect of decision trees is that we can visualize how a test instance gets classified; we simply show the path it takes from root to leaf.</p>
<p>How could we visualize the classification process in an ensemble, via the Heatmap Tree or otherwise? With the Heatmap Tree, we would need to be able to simultaneously visualize 10&#8217;s or 100&#8217;s of paths, since there would be an individual path for every tree in the ensemble. One idea is to have weighted edges on the Heatmap Tree; an edge would become thicker each time the edge is used when classifying an instance.</p>
<p>Another next step is to test the generalizability of this visualization; could it work for any gradient boosting model? What would a Heatmap Tree of a random forest look like?</p>
<p><strong>Conclusion</strong></p>
<p>We&#8217;ve taken a close look at LambdaMART and gradient boosting. We&#8217;ve devised a way to capture the complexity of gradient boosted tree ensembles in a cohesive way. In doing so we bought back some of the interpretability that we lost by moving from a single tree to an ensemble, gained insight into the training process, and made the black box LambdaMART model a bit more transparent.</p>
<p>To see an interactive d3 Heatmap Tree, visit <span style="color:#808080;"><a style="color:#808080;" title="Heatmap Tree" href="http://heatmap-tree.herokuapp.com">this link</a></span>.</p>
<p><strong>References and Further Reading</strong></p>
<p><span style="color:#808080;"><a style="color:#808080;" href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.180.634">From RankNet to LambdaRank to LambdaMART: An Overview</a></span></p>
<p><span style="color:#808080;"><a style="color:#808080;" title="Gradient boosting machines, a tutorial" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3885826/">Gradient Boosting Machines: A Tutorial</a></span></p>
<p>“Tree Ensembles for Learning to Rank”, Yasser Ganjisaffar 2011 PhD Thesis</p>
]]></content:encoded>
					
					<wfw:commentRss>https://wellecks.wordpress.com/2015/02/21/peering-into-the-black-box-visualizing-lambdamart/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		
		<media:content url="https://0.gravatar.com/avatar/f7546f57a5fd69bc99ff1640cc4a4853?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">wellecks</media:title>
		</media:content>

		<media:content url="https://wellecks.files.wordpress.com/2015/02/tree.png?w=525" medium="image">
			<media:title type="html">tree</media:title>
		</media:content>

		<media:content url="https://wellecks.files.wordpress.com/2015/02/ensemble1.png" medium="image">
			<media:title type="html">Ensemble of Trees</media:title>
		</media:content>

		<media:content url="https://wellecks.files.wordpress.com/2015/02/ensemble.gif" medium="image">
			<media:title type="html">ensemble</media:title>
		</media:content>

		<media:content url="https://wellecks.files.wordpress.com/2015/02/node1.png" medium="image">
			<media:title type="html">node1</media:title>
		</media:content>

		<media:content url="https://wellecks.files.wordpress.com/2015/02/node2.png" medium="image">
			<media:title type="html">node2</media:title>
		</media:content>

		<media:content url="https://wellecks.files.wordpress.com/2015/02/ohsumed_10_1_1_1.png" medium="image">
			<media:title type="html">ohsumed_10_1_1_1</media:title>
		</media:content>

		<media:content url="https://wellecks.files.wordpress.com/2015/02/screen-shot-2015-02-19-at-9-07-21-pm.png" medium="image">
			<media:title type="html">Heatmap Detail</media:title>
		</media:content>

		<media:content url="https://wellecks.files.wordpress.com/2015/02/325.png" medium="image">
			<media:title type="html">325</media:title>
		</media:content>

		<media:content url="https://wellecks.files.wordpress.com/2015/02/ohsumed_10_1_1_1.png" medium="image">
			<media:title type="html">ohsumed_10_1_1_1</media:title>
		</media:content>

		<media:content url="https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_01_1_1.png" medium="image">
			<media:title type="html">ohsumed_fold2_10_01_1_1</media:title>
		</media:content>

		<media:content url="https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_001_1_1.png" medium="image">
			<media:title type="html">ohsumed_fold2_10_001_1_1</media:title>
		</media:content>

		<media:content url="https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_05_1_06.png" medium="image">
			<media:title type="html">ohsumed_fold2_10_05_1_06</media:title>
		</media:content>

		<media:content url="https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_10_05_06_06.png" medium="image">
			<media:title type="html">ohsumed_fold2_10_05_06_06</media:title>
		</media:content>

		<media:content url="https://wellecks.files.wordpress.com/2015/02/ohsumed_fold2_25.png" medium="image">
			<media:title type="html">ohsumed_fold2_25</media:title>
		</media:content>
	</item>
		<item>
		<title>Learning to Rank Overview</title>
		<link>https://wellecks.wordpress.com/2015/01/15/learning-to-rank-overview/</link>
					<comments>https://wellecks.wordpress.com/2015/01/15/learning-to-rank-overview/#respond</comments>
		
		<dc:creator><![CDATA[wellecks]]></dc:creator>
		<pubDate>Thu, 15 Jan 2015 23:18:27 +0000</pubDate>
				<category><![CDATA[artificial intelligence]]></category>
		<category><![CDATA[machine learning]]></category>
		<guid isPermaLink="false">http://wellecks.wordpress.com/?p=930</guid>

					<description><![CDATA[How does a search engine rank the results that it returns? How does a question and answering system select a final answer? How does a translation system ultimately choose a translation for some text? In the next few posts, we will gain insight into these questions by exploring a sub-domain of machine learning called Learning to Rank. Each [&#8230;]]]></description>
										<content:encoded><![CDATA[<p style="text-align:center;">How does a search engine rank the results that it returns?</p>
<p style="text-align:center;">How does a question and answering system select a final answer?</p>
<p style="text-align:center;">How does a translation system ultimately choose a translation for some text?</p>
<p>In the next few posts, we will gain insight into these questions by exploring a sub-domain of machine learning called <strong>Learning to Rank</strong>. Each of the three questions has a common last step, where an algorithm takes a list of &#8216;candidates&#8217; and produces a ranked list of results.</p>
<p>In the translation case, we give a system of string of text to translate, and it produces, say, 20 potential candidate translations. Then a Learning to Rank model steps in, ranks those 20 candidates, and returns the top candidate.</p>
<p>In the question-answering case, we give a system a query string, and it produces, say, 100 potential answers. Again we use a Learning to Rank model to produce a ranking of the potential answers, and select the top one as the final answer.</p>
<p>In the search engine case, we type in a search query, and the search engine produces, say, 1000 candidate search results. The order of the final results that you eventually see are produced by a Learning to Rank model that ranks those 1000 candidate results.</p>
<p>To explore the details, we&#8217;ll first define the problem addressed in the Learning to Rank domain and survey the methods, datasets, and metrics that are used. Then in the next posts, we&#8217;ll look in depth at a state of the art model called LambdaMART, and devise a way of visualizing its training process and the resulting model. Along the way we&#8217;ll also develop wrapper code for running a major learning to rank library called JForests and discuss other problems tackled by the field.</p>
<h1 style="text-align:center;">Learning to Rank</h1>
<p>As a first step, we&#8217;ll define the problem. While learning to rank has numerous applications including machine translation, QA, and even spell checking, we&#8217;ll use search engine document ranking as a running example, mainly due to availability of datasets.</p>
<h2 style="text-align:center;">Problem definition</h2>
<p>In the context of document retrieval, consider a search engine that accepts a query, and produces a ranking of documents related to the query using a technique such as TF-IDF scoring. Suppose we take the top 100 documents. The goal of learning to rank is to produce a better ranking of these 100 candidate documents for the given query.</p>
<p>Most research has posed learning to rank as a supervised learning problem, although there has been <a href="http://ssli.ee.washington.edu/people/duh/thesis/uwthesis.pdf">work</a> in semi-supervised ranking. We&#8217;ll only focus on the supervised problem here. Given a list of queries and candidate documents with annotated relevance scores, the learning to rank model learns to predict the relevance of candidate documents for a new query, and derives a ranking from the predictions. Let&#8217;s define that a bit more precisely.</p>
<h2 style="text-align:center;">More precise problem definition</h2>
<p>The data consists of queries, documents, and relevance scores. Let <img src="https://s0.wp.com/latex.php?latex=Q&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=Q&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=Q&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="Q" class="latex" /> denote the set of queries, <img src="https://s0.wp.com/latex.php?latex=D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="D" class="latex" /> denote the set of documents, and <img src="https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="Y" class="latex" /> denote the set of relevance scores.</p>
<p>For each query <img src="https://s0.wp.com/latex.php?latex=q_%7Bi%7D+%5Cin+Q&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q_%7Bi%7D+%5Cin+Q&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q_%7Bi%7D+%5Cin+Q&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q_{i} &#92;in Q" class="latex" /> we have a list of <img src="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="m" class="latex" /> candidate documents <img src="https://s0.wp.com/latex.php?latex=D_%7Bi%7D%3D%7Bd_%7Bi%2C1%7D%2Cd_%7Bi%2C2%7D%2C...%2Cd_%7Bi%2Cm%7D%7D+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=D_%7Bi%7D%3D%7Bd_%7Bi%2C1%7D%2Cd_%7Bi%2C2%7D%2C...%2Cd_%7Bi%2Cm%7D%7D+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=D_%7Bi%7D%3D%7Bd_%7Bi%2C1%7D%2Cd_%7Bi%2C2%7D%2C...%2Cd_%7Bi%2Cm%7D%7D+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="D_{i}={d_{i,1},d_{i,2},...,d_{i,m}} " class="latex" />. We want to produce a ranking for the documents <img src="https://s0.wp.com/latex.php?latex=D_%7Bi%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=D_%7Bi%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=D_%7Bi%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="D_{i}" class="latex" />, specifically a permutation <img src="https://s0.wp.com/latex.php?latex=%5Cpi_%7Bi%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cpi_%7Bi%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cpi_%7Bi%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;pi_{i}" class="latex" /> of the document indices <img src="https://s0.wp.com/latex.php?latex=%5C%7B1%2C2%2C...%2Cm%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5C%7B1%2C2%2C...%2Cm%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5C%7B1%2C2%2C...%2Cm%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;{1,2,...,m&#92;}" class="latex" />. To do so, we want to learn a function <img src="https://s0.wp.com/latex.php?latex=f%28q%2CD%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%28q%2CD%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%28q%2CD%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f(q,D)" class="latex" /> that produces an optimal permutation <img src="https://s0.wp.com/latex.php?latex=%5Cpi_%7Bi%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cpi_%7Bi%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cpi_%7Bi%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;pi_{i}" class="latex" />.</p>
<p>As we&#8217;ll see, this ranking is produced in different ways; for instance, some models derive the rankings by producing a score for each <img src="https://s0.wp.com/latex.php?latex=%28q_%7Bi%7D%2Cd_%7Bi%2Cj%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28q_%7Bi%7D%2Cd_%7Bi%2Cj%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28q_%7Bi%7D%2Cd_%7Bi%2Cj%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(q_{i},d_{i,j})" class="latex" /> pair, while others learn to tell whether the rank of <img src="https://s0.wp.com/latex.php?latex=%28q_%7Bi%7D%2Cd_%7Bi%2Cj%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28q_%7Bi%7D%2Cd_%7Bi%2Cj%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28q_%7Bi%7D%2Cd_%7Bi%2Cj%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(q_{i},d_{i,j})" class="latex" /> is higher than <img src="https://s0.wp.com/latex.php?latex=%28q_%7Bi%7D%2Cd_%7Bi%2Ck%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28q_%7Bi%7D%2Cd_%7Bi%2Ck%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28q_%7Bi%7D%2Cd_%7Bi%2Ck%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(q_{i},d_{i,k})" class="latex" />.</p>
<h2 style="text-align:center;">Training Set</h2>
<p>In the standard training set, each document <img src="https://s0.wp.com/latex.php?latex=d_%7Bi%2Cj%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d_%7Bi%2Cj%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d_%7Bi%2Cj%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d_{i,j}" class="latex" /> is assigned a relevance score <img src="https://s0.wp.com/latex.php?latex=y_%7Bi%2Cj%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y_%7Bi%2Cj%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y_%7Bi%2Cj%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y_{i,j}" class="latex" /> that says how relevant the document is to query <img src="https://s0.wp.com/latex.php?latex=q_%7Bi%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q_%7Bi%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q_%7Bi%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q_{i}" class="latex" />. These scores can be assigned by human annotators, or derived implicitly from sources such as click through data.</p>
<p>We can think of the training set as consisting of 3-tuples <img src="https://s0.wp.com/latex.php?latex=%28q_%7Bi%7D%2C+d_%7Bi%2Cj%7D%2C+y_%7Bi%2Cj%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28q_%7Bi%7D%2C+d_%7Bi%2Cj%7D%2C+y_%7Bi%2Cj%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28q_%7Bi%7D%2C+d_%7Bi%2Cj%7D%2C+y_%7Bi%2Cj%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(q_{i}, d_{i,j}, y_{i,j})" class="latex" />; one training example consists of a query, a candidate document, and a measure of how relevant that document is to the query. An example labeling is <img src="https://s0.wp.com/latex.php?latex=y_%7Bi%2Cj%7D+%5Cin+%5C%7B1%2C+2%2C+3%2C+4%2C+5%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y_%7Bi%2Cj%7D+%5Cin+%5C%7B1%2C+2%2C+3%2C+4%2C+5%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y_%7Bi%2Cj%7D+%5Cin+%5C%7B1%2C+2%2C+3%2C+4%2C+5%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y_{i,j} &#92;in &#92;{1, 2, 3, 4, 5&#92;}" class="latex" />, where 1 means &#8220;not relevant&#8221; and 5 means &#8220;very relevant&#8221;.</p>
<p>For instance, we could have a query <img src="https://s0.wp.com/latex.php?latex=q_%7B1%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q_%7B1%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q_%7B1%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q_{1}" class="latex" /> = &#8220;Leo Tolstoy famous novel&#8221;, with candidate documents <img src="https://s0.wp.com/latex.php?latex=D_%7B1%7D%3D%5C%7Bd_%7B1%2C1%7D%3DSteppenwolf%2C+d_%7B1%2C2%7D%3DWar%5C+and%5C+Peace%2C+d_%7B1%2C3%7D%3DThe%5C+Cossacks%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=D_%7B1%7D%3D%5C%7Bd_%7B1%2C1%7D%3DSteppenwolf%2C+d_%7B1%2C2%7D%3DWar%5C+and%5C+Peace%2C+d_%7B1%2C3%7D%3DThe%5C+Cossacks%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=D_%7B1%7D%3D%5C%7Bd_%7B1%2C1%7D%3DSteppenwolf%2C+d_%7B1%2C2%7D%3DWar%5C+and%5C+Peace%2C+d_%7B1%2C3%7D%3DThe%5C+Cossacks%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="D_{1}=&#92;{d_{1,1}=Steppenwolf, d_{1,2}=War&#92; and&#92; Peace, d_{1,3}=The&#92; Cossacks&#92;}" class="latex" />, and relevance labels <img src="https://s0.wp.com/latex.php?latex=y_%7B1%2C1%7D%3D1%2Cy_%7B1%2C2%7D%3D5%2Cy_%7B1%2C3%7D%3D3&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y_%7B1%2C1%7D%3D1%2Cy_%7B1%2C2%7D%3D5%2Cy_%7B1%2C3%7D%3D3&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y_%7B1%2C1%7D%3D1%2Cy_%7B1%2C2%7D%3D5%2Cy_%7B1%2C3%7D%3D3&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y_{1,1}=1,y_{1,2}=5,y_{1,3}=3" class="latex" />.</p>
<p>Each pair <img src="https://s0.wp.com/latex.php?latex=%28q_%7Bi%7D%2C+d_%7Bi%2C+j%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28q_%7Bi%7D%2C+d_%7Bi%2C+j%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28q_%7Bi%7D%2C+d_%7Bi%2C+j%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(q_{i}, d_{i, j})" class="latex" /> is actually a feature vector <img src="https://s0.wp.com/latex.php?latex=%5Cphi%28q_%7Bi%7D%2C+d_%7Bi%2C+j%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi%28q_%7Bi%7D%2C+d_%7Bi%2C+j%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi%28q_%7Bi%7D%2C+d_%7Bi%2C+j%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi(q_{i}, d_{i, j})" class="latex" />, so the final training set is defined as <img src="https://s0.wp.com/latex.php?latex=T%3D%5C%7B%28%5Cphi%28q_%7Bi%7D%2C+d_%7Bi%2C+j%7D%29%2Cy_%7Bi%2Cj%7D%29%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=T%3D%5C%7B%28%5Cphi%28q_%7Bi%7D%2C+d_%7Bi%2C+j%7D%29%2Cy_%7Bi%2Cj%7D%29%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=T%3D%5C%7B%28%5Cphi%28q_%7Bi%7D%2C+d_%7Bi%2C+j%7D%29%2Cy_%7Bi%2Cj%7D%29%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="T=&#92;{(&#92;phi(q_{i}, d_{i, j}),y_{i,j})&#92;}" class="latex" /> for <img src="https://s0.wp.com/latex.php?latex=i%3D1...n%2C%5C+j%3D1...m&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i%3D1...n%2C%5C+j%3D1...m&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i%3D1...n%2C%5C+j%3D1...m&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i=1...n,&#92; j=1...m" class="latex" />, where <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> is the number of queries, and <img src="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="m" class="latex" /> is the number of candidate documents for each query.</p>
<h2 style="text-align:center;">A concrete training set</h2>
<p>To make this concrete, here&#8217;s a few training examples taken from the <a href="http://research.microsoft.com/en-us/um/beijing/projects/letor/letor3dataset.aspx">OHSUMED</a> dataset:</p>
<pre class="brush: plain; title: ; notranslate">
0 qid:1 1:1.000000 2:1.000000 3:0.833333 4:0.871264 5:0 6:0 7:0 8:0.941842 9:1.000000 10:1.000000 11:1.000000 12:1.000000 13:1.000000 14:1.000000 15:1.000000 16:1.000000 17:1.000000 18:0.719697 19:0.729351 20:0 21:0 22:0 23:0.811565 24:1.000000 25:0.972730 26:1.000000 27:1.000000 28:0.922374 29:0.946654 30:0.938888 31:1.000000 32:1.000000 33:0.711276 34:0.722202 35:0 36:0 37:0 38:0.798002 39:1.000000 40:1.000000 41:1.000000 42:1.000000 43:0.959134 44:0.963919 45:0.971425 #docid = 244338
2 qid:1 1:0.600000 2:0.600000 3:1.000000 4:1.000000 5:0 6:0 7:0 8:1.000000 9:0.624834 10:0.767301 11:0.816099 12:0.934805 13:0.649685 14:0.680222 15:0.686762 16:0.421053 17:0.680904 18:1.000000 19:1.000000 20:0 21:0 22:0 23:1.000000 24:0.401391 25:0.938966 26:0.949446 27:0.984769 28:0.955266 29:1.000000 30:0.997786 31:0.441860 32:0.687033 33:1.000000 34:1.000000 35:0 36:0 37:0 38:1.000000 39:0.425450 40:0.975968 41:0.928785 42:0.978524 43:0.979553 44:1.000000 45:1.000000 #docid = 143821
0 qid:1 1:0.400000 2:0.400000 3:0.555555 4:0.563658 5:0 6:0 7:0 8:0.545844 9:0.380576 10:0.427356 11:0.468244 12:0.756579 13:0.366316 14:0.360838 15:0.373909 16:0.210526 17:0.479859 18:0.595237 19:0.608701 20:0 21:0 22:0 23:0.613865 24:0.184562 25:0.791539 26:0.863833 27:0.957024 28:0.896468 29:0.941132 30:0.946305 31:0.232558 32:0.507810 33:0.603068 34:0.616847 35:0 36:0 37:0 38:0.614004 39:0.202374 40:0.812801 41:0.868091 42:0.958879 43:0.926045 44:0.944576 45:0.963753 #docid = 285257

...

0 qid:63 1:0.142857 2:0.162076 3:0.250000 4:0.250000 5:0 6:0 7:0 8:0.167856 9:0.078385 10:0.103707 11:0.132891 12:0.419191 13:0.027399 14:0.027300 15:0.027300 16:0.000000 17:0.000000 18:0.000000 19:0.000000 20:0 21:0 22:0 23:0.000000 24:0.000000 25:0.000000 26:0.000000 27:0.000000 28:0.000000 29:0.000000 30:0.000000 31:0.026316 32:0.063236 33:0.444444 34:0.407079 35:0 36:0 37:0 38:0.189973 39:0.011360 40:0.068814 41:0.066431 42:0.287984 43:0.188175 44:0.000000 45:0.046177 #docid = 173315
2 qid:63 1:0.000000 2:0.000000 3:0.000000 4:0.000000 5:0 6:0 7:0 8:0.000000 9:0.000000 10:0.000000 11:0.000000 12:0.000000 13:0.000000 14:0.000000 15:0.000000 16:0.000000 17:0.000000 18:0.000000 19:0.000000 20:0 21:0 22:0 23:0.000000 24:0.000000 25:0.000000 26:0.000000 27:0.000000 28:0.000000 29:0.000000 30:0.000000 31:0.000000 32:0.000000 33:0.000000 34:0.000000 35:0 36:0 37:0 38:0.000000 39:0.000000 40:0.000000 41:0.000000 42:0.000000 43:0.000000 44:0.000000 45:0.000000 #docid = 9897

</pre>
<p>We can see that the relevance scores <img src="https://s0.wp.com/latex.php?latex=y_%7Bi%2Cj%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y_%7Bi%2Cj%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y_%7Bi%2Cj%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y_{i,j}" class="latex" /> (the first number of each line) are between 0 and 2. Looking at the<a title="OHSUMED" href="http://ir.ohsu.edu/ohsumed/"> original OHSUMED text</a>, we see that the first example is <img src="https://s0.wp.com/latex.php?latex=%28y_%7B1%2C1%7D%2C%5Cphi%28q_%7B1%7D%2C+d_%7B1%2C+1%7D%29%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28y_%7B1%2C1%7D%2C%5Cphi%28q_%7B1%7D%2C+d_%7B1%2C+1%7D%29%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28y_%7B1%2C1%7D%2C%5Cphi%28q_%7B1%7D%2C+d_%7B1%2C+1%7D%29%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(y_{1,1},&#92;phi(q_{1}, d_{1, 1}))" class="latex" /> with:</p>
<p style="padding-left:30px;"><img src="https://s0.wp.com/latex.php?latex=q_%7B1%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q_%7B1%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q_%7B1%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q_{1}" class="latex" />: &#8220;Are there adverse effects on lipids when progesterone is given with estrogen replacement therapy&#8221;</p>
<p style="padding-left:30px;"><img src="https://s0.wp.com/latex.php?latex=d_%7B1%2C1%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d_%7B1%2C1%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d_%7B1%2C1%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d_{1,1}" class="latex" />= #docid 244338 = &#8220;Effects on bone of surgical menopause and estrogen therapy with or without progesterone replacement in cynomolgus monkeys.&#8221;</p>
<p style="padding-left:30px;"><img src="https://s0.wp.com/latex.php?latex=y_%7B1%2C1%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y_%7B1%2C1%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y_%7B1%2C1%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y_{1,1}" class="latex" /> = <i>0</i> = not relevant</p>
<p>and the second example is <img src="https://s0.wp.com/latex.php?latex=%28y_%7B1%2C2%7D%2C%5Cphi%28q_%7B1%7D%2C+d_%7B1%2C+2%7D%29%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28y_%7B1%2C2%7D%2C%5Cphi%28q_%7B1%7D%2C+d_%7B1%2C+2%7D%29%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28y_%7B1%2C2%7D%2C%5Cphi%28q_%7B1%7D%2C+d_%7B1%2C+2%7D%29%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(y_{1,2},&#92;phi(q_{1}, d_{1, 2}))" class="latex" /> with:</p>
<p style="padding-left:30px;"><img src="https://s0.wp.com/latex.php?latex=d_%7B1%2C2%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d_%7B1%2C2%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d_%7B1%2C2%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d_{1,2}" class="latex" />= #docid 143821 = &#8220;Cardiovascular benefits of estrogen replacement therapy.&#8221;</p>
<p style="padding-left:30px;"><img src="https://s0.wp.com/latex.php?latex=y_%7B1%2C1%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y_%7B1%2C1%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y_%7B1%2C1%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y_{1,1}" class="latex" /> = <i>2</i> = very relevant</p>
<p>The text has been converted into the features described on <a href="http://research.microsoft.com/en-us/um/beijing/projects/letor/LETOR3.0/letor.pdf">pg.11 of this paper</a>. Note that I only showed the document title here and omitted the body text.</p>
<h2 style="text-align:center;">Test Instance</h2>
<p>At test time, we receive a query <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q" class="latex" /> and a list of <img src="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="m" class="latex" /> candidate documents <img src="https://s0.wp.com/latex.php?latex=D%3D%7Bd_%7B1%7D%2Cd_%7B2%7D%2C...%2Cd_%7Bm%7D%7D+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=D%3D%7Bd_%7B1%7D%2Cd_%7B2%7D%2C...%2Cd_%7Bm%7D%7D+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=D%3D%7Bd_%7B1%7D%2Cd_%7B2%7D%2C...%2Cd_%7Bm%7D%7D+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="D={d_{1},d_{2},...,d_{m}} " class="latex" />. We evaluate <img src="https://s0.wp.com/latex.php?latex=f%28q%2CD%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%28q%2CD%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%28q%2CD%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f(q,D)" class="latex" /> and return a ranking of the documents <img src="https://s0.wp.com/latex.php?latex=D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="D" class="latex" />, specifically a permutation <img src="https://s0.wp.com/latex.php?latex=%5Cpi&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cpi&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cpi&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;pi" class="latex" /> of the document indices <img src="https://s0.wp.com/latex.php?latex=%5C%7B1%2C2%2C...%2Cm%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5C%7B1%2C2%2C...%2Cm%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5C%7B1%2C2%2C...%2Cm%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;{1,2,...,m&#92;}" class="latex" />.</p>
<h1 style="text-align:center;">Learning to Rank Datasets</h1>
<p>There are several benchmark datasets for Learning to Rank that can be used to evaluate models.</p>
<p>Microsoft Research released the <a href="http://research.microsoft.com/en-us/um/beijing/projects/letor/letor3dataset.aspx">LETOR 3.0</a> and <a href="http://research.microsoft.com/en-us/um/beijing/projects/letor/letor4dataset.aspx">LETOR 4.0</a> datasets. LETOR 3.0 contains data from a 2002 crawl of .gov web pages and associated queries, as well as medical search queries and medical journal documents from the <a href="http://ir.ohsu.edu/ohsumed/ohsumed.html">OHSUMED</a> dataset. LETOR 4.0 contains queries from the <a href="http://ir.cis.udel.edu/million/index.html">Million Query Track</a> from TREC and document ids from Gov2, another crawl of .gov web pages. Data is represented as raw feature vectors; information about the features used and the datasets is found <a href="http://research.microsoft.com/en-us/um/beijing/projects/letor/LETOR3.0/letor.pdf">here</a>. One thing that I like about the OHSUMED data is that the <a href="http://ir.ohsu.edu/ohsumed/">original text</a> of the queries and documents is available, which can be helpful for interpreting model output or deriving new features. Unfortunately obtaining the original GOV data <a href="http://ir.dcs.gla.ac.uk/test_collections/access_to_data.html">is nontrivial</a>.</p>
<p>Microsoft Research also released <a title="MSLR WEB Datasets" href="http://research.microsoft.com/en-us/projects/mslr/">a larger scale dataset</a> consisting 30,000 queries, candidate features, and relevance judgements derived from the Bing search engine. The MSLR-WEB30K dataset contains all of the queries, while a smaller MSLR-WEB10K dataset contains a 10,000 query sample of MSLR-WEB30K. Unfortunately, we are unable to retrieve the original query text and URLs to further interpret results, but the dataset is nevertheless very useful for evaluating a model and producing metrics.</p>
<p>Yahoo sponsored a <a href="http://jmlr.csail.mit.edu/proceedings/papers/v14/">Learning to Rank competition</a> in 2010 and released a dataset consisting of 36,000 queries and 883,000 document IDs. The datasets are available <a href="http://webscope.sandbox.yahoo.com/catalog.php?datatype=c">here</a>, but require a university email to download. Similar to MSLR-WEB, we receive the raw features and relevance scores, and are unable to see the text of the query or URL.</p>
<h1 style="text-align:center;">Learning to Rank Evaluation Metrics</h1>
<p>When we run a learning to rank model on a test set to predict rankings, we evaluate the performance using metrics that compare the predicted rankings to the annotated gold-standard labels. Before reviewing the popular learning to rank metrics, let&#8217;s introduce notation.</p>
<p>We&#8217;ll assume that there are <em>n</em> queries, and that for each query <img src="https://s0.wp.com/latex.php?latex=q_%7Bi%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q_%7Bi%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q_%7Bi%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q_{i}" class="latex" /> we have a list of <em>m</em> candidates <img src="https://s0.wp.com/latex.php?latex=D_%7Bi%7D+%3D%5C%7Bd_%7Bi%2C1%7D%2C...d_%7Bi%2Cm%7D%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=D_%7Bi%7D+%3D%5C%7Bd_%7Bi%2C1%7D%2C...d_%7Bi%2Cm%7D%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=D_%7Bi%7D+%3D%5C%7Bd_%7Bi%2C1%7D%2C...d_%7Bi%2Cm%7D%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="D_{i} =&#92;{d_{i,1},...d_{i,m}&#92;}" class="latex" /> with annotated relevance scores <img src="https://s0.wp.com/latex.php?latex=y_%7Bi%2C1%7D%2C...y_%7Bi%2Cm%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y_%7Bi%2C1%7D%2C...y_%7Bi%2Cm%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y_%7Bi%2C1%7D%2C...y_%7Bi%2Cm%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y_{i,1},...y_{i,m}" class="latex" />. The ranker produces a ranking <img src="https://s0.wp.com/latex.php?latex=%5Cpi_i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cpi_i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cpi_i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;pi_i" class="latex" />, so that <img src="https://s0.wp.com/latex.php?latex=%5Cpi_%7Bi%2Cj%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cpi_%7Bi%2Cj%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cpi_%7Bi%2Cj%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;pi_{i,j}" class="latex" /> represents the predicted ranking of document <img src="https://s0.wp.com/latex.php?latex=d_%7Bi%2Cj%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d_%7Bi%2Cj%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d_%7Bi%2Cj%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d_{i,j}" class="latex" />.</p>
<p>Intuitively, we would like our ranking to have high relevance scores, with the highest scores receiving the highest rankings. Now we&#8217;ll look at several metrics that capture these intuitions.</p>
<h2 style="text-align:center;">Normalized Discounted Cumulative Gain (NDCG)</h2>
<p><a href="http://en.wikipedia.org/wiki/Discounted_cumulative_gain">Normalized Discounted Cumulative Gain</a> (NDCG) is a popular learning to rank metric that relies on Cumulative Gain and Discounted Cumulative Gain.</p>
<p><strong>Cumulative Gain</strong></p>
<p>First we&#8217;ll look at Cumulative Gain. Suppose we have:</p>
<p style="padding-left:30px;"><img src="https://s0.wp.com/latex.php?latex=%5Cpi_i+%3D+%5C%7Bd_%7Bi%2C1%7D%2C+d_%7Bi%2C2%7D%2C+d_%7Bi%2C3%7D%2C+d_%7Bi%2C4%7D%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cpi_i+%3D+%5C%7Bd_%7Bi%2C1%7D%2C+d_%7Bi%2C2%7D%2C+d_%7Bi%2C3%7D%2C+d_%7Bi%2C4%7D%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cpi_i+%3D+%5C%7Bd_%7Bi%2C1%7D%2C+d_%7Bi%2C2%7D%2C+d_%7Bi%2C3%7D%2C+d_%7Bi%2C4%7D%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;pi_i = &#92;{d_{i,1}, d_{i,2}, d_{i,3}, d_{i,4}&#92;}" class="latex" /></p>
<p style="padding-left:30px;"><img src="https://s0.wp.com/latex.php?latex=y_%7Bi%7D%3D+%5C%7B5%2C+2%2C+5%2C+0%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y_%7Bi%7D%3D+%5C%7B5%2C+2%2C+5%2C+0%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y_%7Bi%7D%3D+%5C%7B5%2C+2%2C+5%2C+0%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y_{i}= &#92;{5, 2, 5, 0&#92;}" class="latex" /></p>
<p>That is, the top ranked document has a relevance score of 5, the second ranked document has a relevance score of 2, and so on.</p>
<p>The cumulative gain is simply the sum of the relevance scores:</p>
<p style="padding-left:30px;"><img src="https://s0.wp.com/latex.php?latex=%5Csum_%7Bi%7Dy_%7Bi%7D%3D5%2B2%2B5%2B0%3D12&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Csum_%7Bi%7Dy_%7Bi%7D%3D5%2B2%2B5%2B0%3D12&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Csum_%7Bi%7Dy_%7Bi%7D%3D5%2B2%2B5%2B0%3D12&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;sum_{i}y_{i}=5+2+5+0=12" class="latex" />.</p>
<p style="text-align:left;">Notice that this doesn&#8217;t take ranking order into account; if our ranking was reversed:</p>
<p style="text-align:left;padding-left:30px;"><img src="https://s0.wp.com/latex.php?latex=%5Cpi_i+%3D+%5C%7Bd_%7Bi%2C4%7D%2C+d_%7Bi%2C3%7D%2C+d_%7Bi%2C2%7D%2C+d_%7Bi%2C1%7D%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cpi_i+%3D+%5C%7Bd_%7Bi%2C4%7D%2C+d_%7Bi%2C3%7D%2C+d_%7Bi%2C2%7D%2C+d_%7Bi%2C1%7D%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cpi_i+%3D+%5C%7Bd_%7Bi%2C4%7D%2C+d_%7Bi%2C3%7D%2C+d_%7Bi%2C2%7D%2C+d_%7Bi%2C1%7D%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;pi_i = &#92;{d_{i,4}, d_{i,3}, d_{i,2}, d_{i,1}&#92;}" class="latex" /></p>
<p style="text-align:left;">it would receive the same cumulative gain score:</p>
<p style="text-align:left;padding-left:30px;"><img src="https://s0.wp.com/latex.php?latex=%5Csum_%7Bi%7Dy_%7Bi%7D%3D0%2B5%2B2%2B5%3D12&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Csum_%7Bi%7Dy_%7Bi%7D%3D0%2B5%2B2%2B5%3D12&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Csum_%7Bi%7Dy_%7Bi%7D%3D0%2B5%2B2%2B5%3D12&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;sum_{i}y_{i}=0+5+2+5=12" class="latex" />.</p>
<p><strong>Discounted Cumulative Gain</strong></p>
<p>Discounted Cumulative Gain (DCG) takes order into account by &#8216;rewarding&#8217; high relevance scores that appear in high ranks. A high relevance score appearing at a low rank receives a lower &#8216;reward&#8217;. To compute the metric, we use:</p>
<p style="padding-left:30px;"><img src="https://s0.wp.com/latex.php?latex=DCG_k+%3D+%5Csum_%7Bj%3D1%7D%5E%7Bk%7D+%5Cfrac%7B2%5E%7By_%7Bi%2C%5Cpi_%7Bi%2Cj%7D%7D%7D-1%7D%7Blog%28i%2B1%29%7D%3D31%2B1.9%2B15.5%2B0%3D48.4&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=DCG_k+%3D+%5Csum_%7Bj%3D1%7D%5E%7Bk%7D+%5Cfrac%7B2%5E%7By_%7Bi%2C%5Cpi_%7Bi%2Cj%7D%7D%7D-1%7D%7Blog%28i%2B1%29%7D%3D31%2B1.9%2B15.5%2B0%3D48.4&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=DCG_k+%3D+%5Csum_%7Bj%3D1%7D%5E%7Bk%7D+%5Cfrac%7B2%5E%7By_%7Bi%2C%5Cpi_%7Bi%2Cj%7D%7D%7D-1%7D%7Blog%28i%2B1%29%7D%3D31%2B1.9%2B15.5%2B0%3D48.4&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="DCG_k = &#92;sum_{j=1}^{k} &#92;frac{2^{y_{i,&#92;pi_{i,j}}}-1}{log(i+1)}=31+1.9+15.5+0=48.4" class="latex" /></p>
<p>We can see that in position 1, the high relevance score 5 is worth 31, while in position 3 it&#8217;s worth 15.5. The lower relevance score 2 is only worth 1.9 in position 2. With DCG order matters; the score would increase if we swapped the rankings of <img src="https://s0.wp.com/latex.php?latex=d_%7Bi%2C2%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d_%7Bi%2C2%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d_%7Bi%2C2%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d_{i,2}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=d_%7Bi%2C3%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d_%7Bi%2C3%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d_%7Bi%2C3%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d_{i,3}" class="latex" />.</p>
<p><strong>Normalized Discounted Cumulative Gain</strong></p>
<p><img src="https://s0.wp.com/latex.php?latex=NDCG_k&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=NDCG_k&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=NDCG_k&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="NDCG_k" class="latex" /> is just a normalized version of <img src="https://s0.wp.com/latex.php?latex=DCG_k&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=DCG_k&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=DCG_k&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="DCG_k" class="latex" />. The normalization is done by finding the <img src="https://s0.wp.com/latex.php?latex=DCG_k&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=DCG_k&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=DCG_k&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="DCG_k" class="latex" /> of an &#8216;ideal&#8217; ranking. In our example, the ideal ranking would be:</p>
<p style="padding-left:30px;"><img src="https://s0.wp.com/latex.php?latex=%5Cpi_i+%3D+%5C%7Bd_%7Bi%2C1%7D%2C+d_%7Bi%2C3%7D%2C+d_%7Bi%2C2%7D%2C+d_%7Bi%2C4%7D%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cpi_i+%3D+%5C%7Bd_%7Bi%2C1%7D%2C+d_%7Bi%2C3%7D%2C+d_%7Bi%2C2%7D%2C+d_%7Bi%2C4%7D%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cpi_i+%3D+%5C%7Bd_%7Bi%2C1%7D%2C+d_%7Bi%2C3%7D%2C+d_%7Bi%2C2%7D%2C+d_%7Bi%2C4%7D%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;pi_i = &#92;{d_{i,1}, d_{i,3}, d_{i,2}, d_{i,4}&#92;}" class="latex" /></p>
<p>giving:</p>
<p style="padding-left:30px;"><img src="https://s0.wp.com/latex.php?latex=DCG_%7Bk_%7Bideal%7D%7D%3D%5Csum_%7Bj%3D1%7D%5E%7Bk%7D+%5Cfrac%7B2%5E%7By_%7Bi%2C%5Cpi_%7Bi%2Cj%7D%7D%7D-1%7D%7Blog%28i%2B1%29%7D%3D31%2B19.5%2B1.5%2B0%3D52&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=DCG_%7Bk_%7Bideal%7D%7D%3D%5Csum_%7Bj%3D1%7D%5E%7Bk%7D+%5Cfrac%7B2%5E%7By_%7Bi%2C%5Cpi_%7Bi%2Cj%7D%7D%7D-1%7D%7Blog%28i%2B1%29%7D%3D31%2B19.5%2B1.5%2B0%3D52&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=DCG_%7Bk_%7Bideal%7D%7D%3D%5Csum_%7Bj%3D1%7D%5E%7Bk%7D+%5Cfrac%7B2%5E%7By_%7Bi%2C%5Cpi_%7Bi%2Cj%7D%7D%7D-1%7D%7Blog%28i%2B1%29%7D%3D31%2B19.5%2B1.5%2B0%3D52&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="DCG_{k_{ideal}}=&#92;sum_{j=1}^{k} &#92;frac{2^{y_{i,&#92;pi_{i,j}}}-1}{log(i+1)}=31+19.5+1.5+0=52" class="latex" /></p>
<p>so:</p>
<p style="padding-left:30px;"><img src="https://s0.wp.com/latex.php?latex=NDCG_k%3D+%5Cfrac%7BDCG_k%7D%7BDCG_%7Bk_%7Bideal%7D%7D%7D%3D%5Cfrac%7B48.4%7D%7B52%7D%3D0.93&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=NDCG_k%3D+%5Cfrac%7BDCG_k%7D%7BDCG_%7Bk_%7Bideal%7D%7D%7D%3D%5Cfrac%7B48.4%7D%7B52%7D%3D0.93&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=NDCG_k%3D+%5Cfrac%7BDCG_k%7D%7BDCG_%7Bk_%7Bideal%7D%7D%7D%3D%5Cfrac%7B48.4%7D%7B52%7D%3D0.93&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="NDCG_k= &#92;frac{DCG_k}{DCG_{k_{ideal}}}=&#92;frac{48.4}{52}=0.93" class="latex" /></p>
<p>We can see that if our predicted rankings were ideal, they would receive an <img src="https://s0.wp.com/latex.php?latex=NDCG_k&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=NDCG_k&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=NDCG_k&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="NDCG_k" class="latex" /> score of <img src="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1" class="latex" />.</p>
<h2 style="text-align:center;">Mean Average Precision (MAP)</h2>
<p style="text-align:left;"><a href="http://en.wikipedia.org/wiki/Information_retrieval#Mean_average_precision">Mean average precision</a> (MAP) is another popular metric for learning to rank, specifically for applications with binary relevance scores, e.g. &#8220;correct&#8221; and &#8220;incorrect&#8221; in question-answering.</p>
<p style="text-align:left;"><strong> P@k</strong></p>
<p style="text-align:left;">MAP relies on Precision at k (P@k), which involves counting the number of relevant (or &#8220;correct&#8221;) documents in the first k ranked positions, and dividing by k:</p>
<p style="text-align:left;padding-left:30px;"><img src="https://s0.wp.com/latex.php?latex=P%40k%3D%5Cfrac%7B1%7D%7Bk%7D%5Csum_%7Bi%3D1%7D%5E%7Bk%7DI%28relevance_i%3D%3D1%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=P%40k%3D%5Cfrac%7B1%7D%7Bk%7D%5Csum_%7Bi%3D1%7D%5E%7Bk%7DI%28relevance_i%3D%3D1%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=P%40k%3D%5Cfrac%7B1%7D%7Bk%7D%5Csum_%7Bi%3D1%7D%5E%7Bk%7DI%28relevance_i%3D%3D1%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="P@k=&#92;frac{1}{k}&#92;sum_{i=1}^{k}I(relevance_i==1)" class="latex" /></p>
<p> <strong>AP</strong></p>
<p>Average precision is then defined as:</p>
<p style="padding-left:30px;"><img src="https://s0.wp.com/latex.php?latex=AP+%3D+%5Cfrac%7B%5Csum_%7Bk%3D1%7D%5E%7Bn%7D%28P%40k+%5Ctimes+I%28relevance_k%3D%3D1%29%29%7D%7B%5Csum_%7Bk%3D1%7D%5E%7Bn%7DI%28relevance_k%3D%3D1%29%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=AP+%3D+%5Cfrac%7B%5Csum_%7Bk%3D1%7D%5E%7Bn%7D%28P%40k+%5Ctimes+I%28relevance_k%3D%3D1%29%29%7D%7B%5Csum_%7Bk%3D1%7D%5E%7Bn%7DI%28relevance_k%3D%3D1%29%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=AP+%3D+%5Cfrac%7B%5Csum_%7Bk%3D1%7D%5E%7Bn%7D%28P%40k+%5Ctimes+I%28relevance_k%3D%3D1%29%29%7D%7B%5Csum_%7Bk%3D1%7D%5E%7Bn%7DI%28relevance_k%3D%3D1%29%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="AP = &#92;frac{&#92;sum_{k=1}^{n}(P@k &#92;times I(relevance_k==1))}{&#92;sum_{k=1}^{n}I(relevance_k==1)}" class="latex" /></p>
<p style="text-align:left;"><strong>MAP</strong></p>
<p style="text-align:left;">Notice that <img src="https://s0.wp.com/latex.php?latex=AP&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=AP&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=AP&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="AP" class="latex" /> is computed for a <em>single query</em>.  <img src="https://s0.wp.com/latex.php?latex=MAP&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=MAP&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=MAP&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="MAP" class="latex" /> is the mean <img src="https://s0.wp.com/latex.php?latex=AP&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=AP&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=AP&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="AP" class="latex" /> value over <em>all queries</em>:</p>
<p style="text-align:left;padding-left:30px;"><img src="https://s0.wp.com/latex.php?latex=MAP+%3D+%5Cfrac%7B1%7D%7BnumQueries%7D%5Csum_%7Bq%3D1%7D%5E%7BnumQueries%7DAP_%7Bq%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=MAP+%3D+%5Cfrac%7B1%7D%7BnumQueries%7D%5Csum_%7Bq%3D1%7D%5E%7BnumQueries%7DAP_%7Bq%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=MAP+%3D+%5Cfrac%7B1%7D%7BnumQueries%7D%5Csum_%7Bq%3D1%7D%5E%7BnumQueries%7DAP_%7Bq%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="MAP = &#92;frac{1}{numQueries}&#92;sum_{q=1}^{numQueries}AP_{q}" class="latex" />.</p>
<h1 style="text-align:center;">Learning to Rank Models</h1>
<p>Learning to Rank models can be broadly classified into three groups: scorewise, pairwise, and listwise. We&#8217;ll introduce and provide an example of each group. There are <em>many</em> more learning to rank models than the ones covered here.</p>
<h2 style="text-align:center;">Pointwise Models</h2>
<p>Pointwise models, also known as &#8216;scorewise&#8217; models, create rankings by computing a real-valued score for each example <img src="https://s0.wp.com/latex.php?latex=%5Cphi%28q_%7Bi%7D%2Cd_%7Bi%2Cj%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi%28q_%7Bi%7D%2Cd_%7Bi%2Cj%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi%28q_%7Bi%7D%2Cd_%7Bi%2Cj%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi(q_{i},d_{i,j})" class="latex" />, then sort by the score.</p>
<p>An advantage of pointwise models is that they have an interpretable confidence score for each query-document pair. Possible disadvantages are that there is not a notion of grouping the training instances (e.g. by query), and that the prediction target is exact relevance rather than relative position.</p>
<p>Logistic regression, <a href="http://papers.nips.cc/paper/2023-pranking-with-ranking.pdf">PRank</a>, and <a href="http://papers.nips.cc/paper/3270-mcrank-learning-to-rank-using-multiple-classification-and-gradient-boosting.pdf">MCRank</a> are examples of pointwise models.</p>
<h2 style="text-align:center;">Pairwise Models</h2>
<p>Pairwise models learn to decide which of two documents is ranked higher. The models rely on the observation that in learning to rank problems we ultimately care about the relative <em>position</em> of documents rather than exact <em>distances</em> between document scores.</p>
<p>Pairwise models first isolate the documents for each query, then form a training set consisting of pairs of documents, and a label for whether the first document has a higher rank than the second document. So each training example is of the form <img src="https://s0.wp.com/latex.php?latex=%28%5Cphi%28q_%7Bi%7D%2Cd_%7Bi%2Cj%7D%29%2C%5Cphi%28q_%7Bi%7D%2Cd_%7Bi%2Ck%7D%29%2C%5C%7B%2B1%2C-1%5C%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28%5Cphi%28q_%7Bi%7D%2Cd_%7Bi%2Cj%7D%29%2C%5Cphi%28q_%7Bi%7D%2Cd_%7Bi%2Ck%7D%29%2C%5C%7B%2B1%2C-1%5C%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28%5Cphi%28q_%7Bi%7D%2Cd_%7Bi%2Cj%7D%29%2C%5Cphi%28q_%7Bi%7D%2Cd_%7Bi%2Ck%7D%29%2C%5C%7B%2B1%2C-1%5C%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(&#92;phi(q_{i},d_{i,j}),&#92;phi(q_{i},d_{i,k}),&#92;{+1,-1&#92;})" class="latex" />. Model-wise, we find <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> such that <img src="https://s0.wp.com/latex.php?latex=f%28d_%7Bi%2Cj%7D%29%3Ef%28d_%7Bi%2Ck%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%28d_%7Bi%2Cj%7D%29%3Ef%28d_%7Bi%2Ck%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%28d_%7Bi%2Cj%7D%29%3Ef%28d_%7Bi%2Ck%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f(d_{i,j})&gt;f(d_{i,k})" class="latex" /> when <img src="https://s0.wp.com/latex.php?latex=y_%7Bi%2Cj%7D%3Ey_%7Bi%2Ck%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y_%7Bi%2Cj%7D%3Ey_%7Bi%2Ck%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y_%7Bi%2Cj%7D%3Ey_%7Bi%2Ck%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y_{i,j}&gt;y_{i,k}" class="latex" />.</p>
<p>The problem is transformed into a binary classification problem; we train a binary classifier to minimize the number of incorrectly ordered pairs.</p>
<p>Several pairwise models exist, each taking different approaches to the problem. Examples include <a href="http://research-srv.microsoft.com/pubs/132652/MSR-TR-2010-82.pdf">RankNet</a>, <a href="http://www.cs.cornell.edu/people/tj/svm_light/svm_rank.html#References">SVMRank</a>, and <a href="http://research.microsoft.com/en-us/people/hangli/xu-sigir07.pdf">AdaRank</a>. Another model called LambdaMART will be the focus of the next post.</p>
<h2 style="text-align:center;">Listwise Models</h2>
<p>Listwise models are trained by optimizing a loss function that measures predicted ranks versus actual ranks for a query&#8217;s <em>entire</em> candidate list. A loss function such as MAP or NDCG can be directly optimized by listwise models. Examples include coordinate ascent and LambdaRank.</p>
<h2 style="text-align:center;">Up Next</h2>
<p>We&#8217;ve introduced the problem of Learning to Rank, and briefly surveyed its algorithms. In the next post, we&#8217;ll examine the LambdaMART model, and develop a way of visualizing its training process.</p>
<p><strong>Sources and Further Reading</strong></p>
<p><a href="http://research.microsoft.com/en-us/people/hangli/l2r.pdf">A Short Introduction to Learning to Rank</a></p>
<p><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.149.3355&amp;rep=rep1&amp;type=pdf">Learning to Rank QA Data</a></p>
<p>&#8220;Tree Ensembles for Learning to Rank&#8221;, Yasser Ganjisaffar 2011 PhD Thesis</p>
<p><a href="http://en.wikipedia.org/wiki/Learning_to_rank">Learning to Rank Wikipedia</a></p>
]]></content:encoded>
					
					<wfw:commentRss>https://wellecks.wordpress.com/2015/01/15/learning-to-rank-overview/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		
		<media:content url="https://0.gravatar.com/avatar/f7546f57a5fd69bc99ff1640cc4a4853?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">wellecks</media:title>
		</media:content>
	</item>
		<item>
		<title>Scala Coursera Highlights</title>
		<link>https://wellecks.wordpress.com/2014/11/27/scala-coursera-highlights/</link>
					<comments>https://wellecks.wordpress.com/2014/11/27/scala-coursera-highlights/#respond</comments>
		
		<dc:creator><![CDATA[wellecks]]></dc:creator>
		<pubDate>Thu, 27 Nov 2014 21:05:25 +0000</pubDate>
				<category><![CDATA[programming]]></category>
		<category><![CDATA[coursera]]></category>
		<category><![CDATA[functional programming]]></category>
		<category><![CDATA[scala]]></category>
		<guid isPermaLink="false">http://wellecks.wordpress.com/?p=906</guid>

					<description><![CDATA[I recently completed the Functional Programming Principles in Scala course on Coursera. Along the way, I learned some interesting things ranging from small tidbits to major language features. I&#8217;m going to use this post as a chance to highlight and review my favorite things that I learned about Scala from the course. This is meant to [&#8230;]]]></description>
										<content:encoded><![CDATA[<p>I recently completed the <a title="Functional Programming Principles in Scala" href="https://www.coursera.org/course/progfun" target="_blank">Functional Programming Principles in Scala</a> course on Coursera. Along the way, I learned some interesting things ranging from small tidbits to major language features. I&#8217;m going to use this post as a chance to highlight and review my favorite things that I learned about Scala from the course. This is meant to be more of a quick review than a set of tutorials, so I&#8217;ll provide links to actual tutorials and further reading for each section.</p>
<p style="text-align:center;"><b>Variance</b></p>
<p>One thing I liked was seeing abstract programming language concepts concretely being used in Scala. An example of this is the idea of variance, namely <a href="http://en.wikipedia.org/wiki/Covariance_and_contravariance_%28computer_science%29">covariance and contravariance</a>. Covariance and contravariance appear when investigating whether one type is a subtype of another type. This question comes up concretely in several places, such as deciding whether a type is a valid argument parameter, or deciding which types can be held by a data structure.</p>
<p><strong>Argument Parameters</strong></p>
<p>Functions accept subtypes as arguments. For instance, a function requiring an <code>Animal</code> type will accept <code>Cat</code> or <code>Dog</code> subtypes as arguments. An interesting (and tricky) case is when a function takes a function as an argument, e.g.</p>
<pre>def fun[T] (animal: Animal, paramFun: Animal =&gt; T) : T</pre>
<p>What are valid arguments for <code>fun</code>? The <code>animal</code> argument is clear; it&#8217;s just any subtype of <code>Animal</code>. But which functions could we pass in for <code>paramFun</code>? This requires determining the subtype of a function.</p>
<p>A natural guess may be that a function <img src="https://s0.wp.com/latex.php?latex=f1%3A+A+%3D%3E+B&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f1%3A+A+%3D%3E+B&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f1%3A+A+%3D%3E+B&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f1: A =&gt; B" class="latex" /> is a subtype of a function <img src="https://s0.wp.com/latex.php?latex=f2%3A+C+%3D%3E+D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f2%3A+C+%3D%3E+D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f2%3A+C+%3D%3E+D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f2: C =&gt; D" class="latex" /> when <em>A</em> is a subtype of <em>C</em> and <em>B</em> is a subtype of <em>D</em>. However, this is incorrect!</p>
<p>It turns out that we need to &#8216;reverse&#8217; the argument subtyping; <em>C</em> must be a subtype of <em>A. </em>Specifically, we have:</p>
<p><img src="https://s0.wp.com/latex.php?latex=f1%3A+A+%3D%3E+B&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f1%3A+A+%3D%3E+B&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f1%3A+A+%3D%3E+B&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f1: A =&gt; B" class="latex" /> is a subtype of <img src="https://s0.wp.com/latex.php?latex=f2%3A+C+%3D%3E+D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f2%3A+C+%3D%3E+D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f2%3A+C+%3D%3E+D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f2: C =&gt; D" class="latex" /> when:</p>
<ul>
<li><em>C</em> is a subtype of <em>A</em></li>
<li><em>B</em> is a subtype of <em>D</em></li>
</ul>
<p>For instance, the function</p>
<pre>def f1(animal: Animal) : Cat</pre>
<p>is a subtype of</p>
<pre>def f2(cat: Cat) : Animal</pre>
<p>In terms of variances, we describe the above by saying that functions are <em>contravariant in their argument types</em>, and <em>covariant in their return types</em>.</p>
<p>The intuition for this is derived from the <a href="http://en.wikipedia.org/wiki/Liskov_substitution_principle">Liskov Substitution Principle</a>, which is (paraphrased) the idea that a subtype should be expected to do everything that its supertypes can do. We should be able to use <code>f1</code> in all of the ways that we can use <code>f2</code>.</p>
<p>To connect it back with this post&#8217;s topic, it turns out that defining and enforcing variance rules is a language feature in Scala! Scala provides the <code>-</code> and <code>+</code> type annotations for contravariance and covariance, respectively. Thus we can implement, for instance, a one parameter function class, and bake the variance rules into the type parameters:</p>
<pre>class Function1[-V, +W] { ... }</pre>
<p>The type tells us that <code>Function1</code> is contravariant in <code>V</code> and covariant in <code>W</code>, as desired.</p>
<p style="text-align:left;"><strong>Type Bounds</strong></p>
<p>Another type-related feature is type bounding. We can create a parameterized function and specify that its parameterized type is a subtype (or supertype) of another type, e.g:</p>
<pre>def foo[T :&gt; String] (t: T)</pre>
<p>says that T must be a supertype of String, and</p>
<pre>def foo[String &lt;: T &lt;: Object] (t: T)</pre>
<p>says that T must be a supertype of String and a subtype of Object.</p>
<p><strong>An Example</strong></p>
<p>As an example of where we would use variance and type bounds, suppose we want to add a <code>prepend</code> function to the <code>List</code> class. Looking at Scala&#8217;s documentation, we can see that the <code>List</code> are parameterized by a covariant type <code>A</code>:</p>
<pre id="signature" class="signature"><span class="modifier_kind"><span class="modifier">sealed abstract </span><span class="kind">class </span></span><span class="symbol"><span class="name">List</span><span class="tparams">[+A] ...</span></span></pre>
<p style="text-align:left;">Now, &#8220;`prepend&#8220;` will add an element to the front of the list; a first guess at its type signature might be:</p>
<pre style="text-align:left;">// compile error
def prepend[A] (a: A) : List[A]</pre>
<p style="text-align:left;">We are attempting to pass a covariant type as a function argument; since function arguments are contravariant this will result in a <a href="http://stackoverflow.com/questions/9619121/why-is-parameter-in-contravariant-position">compile error</a>.</p>
<p style="text-align:left;">To fix this, we can use a type bound to tell the compiler that we&#8217;d like to be able to pass in any supertype B of A, and produce a new list of B&#8217;s:</p>
<pre style="text-align:left;">// compiles
def prepend[B &gt;: A] (b: B) : List[B]</pre>
<p style="text-align:center;"><strong>For Comprehensions</strong></p>
<p>The functions <code>map</code>, <code>flatMap</code>, and <code>filter</code> are used commonly in functional programming. A common pattern is to chain these functions together, which can lead to bloated and unreadable (albeit effective) code. A simple example:</p>
<pre>(1 until 10).flatMap(x =&gt; 
   (1 until 20).filter(y =&gt; y &gt;= 10)
   .map(y =&gt; (x,y)))</pre>
<p>Scala provides <code>for</code> comprehensions as a way of chaining <code>map</code>, <code>flatMap</code>, and <code>filter</code> operations together. Broadly stated, <code>for</code> comprehensions are syntactic sugar that map &#8216;arrow&#8217;, &#8216;if&#8217;, and &#8216;yield&#8217; to <code>map</code>, <code>filterWith</code>, and <code>flatMap</code>, leading to more concise and readable code:</p>
<pre>for {
  x &lt;- (1 until 10)
  y &lt;- (1 until 20)
  if y &gt;= 10 
} yield (x, y)</pre>
<p>Any type that supports <code>map</code>,<code>filter</code>, and <code>flatMap</code> is eligible to be used in a <code>for</code> comprehension, such as <code>List</code>, <code>Future</code>, <code>Map</code>, and many many more. For those familiar with Haskell, Scala&#8217;s <code>for</code> comprehensions are analogous to Haskell&#8217;s <code>do</code> notation, which eliminates the clutter of explicitly writing binds.</p>
<p style="text-align:center;"><strong>Call by Optional</strong></p>
<p>By default, Scala functions are call by value, meaning that function parameters will be reduced prior to evaluating the function body. However, Scala let&#8217;s you override this default by adding =&gt; before a parameter&#8217;s type:</p>
<pre>// x is call by value
// y is call by value
def fun1(x: Int, y: Int)

// x is call by value
// y is call by name
def fun2(x: Int, y: =&gt; Int)</pre>
<p>The <code>y</code> parameter in <code>fun2</code> will be call by name, meaning that it will only be evaluated if and when it&#8217;s used in the function body.</p>
<p>While this is a relatively minor feature, it speaks to a general theme that I&#8217;ve noticed with Scala: the language provides you with <em>many</em> tools, opening up multiple ways to solve a problem. While this flexibility can be misused or confusing, so far I&#8217;ve found that it contributes to Scala being a great practical language. Code can be structured using functional ideas, while still incorporating object-oriented ideas and allowing access to the extensive ecosystem of Java libraries.</p>
<p>Here are some links with more details on these areas:</p>
<p>Variance and Type Bounds:</p>
<ul>
<li><a href="http://en.wikipedia.org/wiki/Covariance_and_contravariance_%28computer_science%29" target="_blank">Wikipedia article</a></li>
<li><a href="http://stackoverflow.com/questions/663254/scala-covariance-contravariance-question" target="_blank">Relevant Stack Overflow question</a></li>
<li><a href="http://docs.scala-lang.org/tutorials/tour/lower-type-bounds.html">Variances in the Scala Tour</a></li>
<li><a href="https://twitter.github.io/scala_school/type-basics.html" target="_blank">A longer tutorial about Scala types</a></li>
</ul>
<p>For Comprehensions:</p>
<ul>
<li><a href="http://stackoverflow.com/questions/1052476/what-is-scalas-yield/1052510#1052510">Relevant Stack Overflow post (specifically the top 2 answers)</a></li>
</ul>
<p>There are also some good general Scala resources that the course pointed to:</p>
<ul>
<li><a href="https://github.com/lampepfl/progfun-wiki/blob/gh-pages/CheatSheet.md">Scala Cheat Sheet</a></li>
<li><a href="http://stackoverflow.com/tags/scala/info">List of Scala questions by Topic</a></li>
<li><a href="http://twitter.github.io/scala_school/">Twitter&#8217;s Scala School</a></li>
<li>Scala&#8217;s <a href="http://docs.scala-lang.org/tutorials/">Tutorials</a> and <a href="http://docs.scala-lang.org/overviews/">Overviews</a></li>
</ul>
]]></content:encoded>
					
					<wfw:commentRss>https://wellecks.wordpress.com/2014/11/27/scala-coursera-highlights/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		
		<media:content url="https://0.gravatar.com/avatar/f7546f57a5fd69bc99ff1640cc4a4853?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">wellecks</media:title>
		</media:content>
	</item>
		<item>
		<title>LDAOverflow with Online LDA</title>
		<link>https://wellecks.wordpress.com/2014/10/26/ldaoverflow-with-online-lda/</link>
					<comments>https://wellecks.wordpress.com/2014/10/26/ldaoverflow-with-online-lda/#respond</comments>
		
		<dc:creator><![CDATA[wellecks]]></dc:creator>
		<pubDate>Sun, 26 Oct 2014 01:45:48 +0000</pubDate>
				<category><![CDATA[artificial intelligence]]></category>
		<category><![CDATA[machine learning]]></category>
		<category><![CDATA[technology]]></category>
		<category><![CDATA[Latent Dirichlet Allocation]]></category>
		<category><![CDATA[Machine learning]]></category>
		<category><![CDATA[Online LDA]]></category>
		<category><![CDATA[topic modeling]]></category>
		<guid isPermaLink="false">http://wellecks.wordpress.com/?p=847</guid>

					<description><![CDATA[In the past two posts (part I and part II), we used Latent Dirichlet Allocation (LDA) to discover topics for tweets, and visualized them. In this post, we&#8217;ll investigate using LDA on an 8gb dataset of around 8 million Stack Overflow posts. We&#8217;ll need to take a different approach; for the tweets we used a batch algorithm that worked [&#8230;]]]></description>
										<content:encoded><![CDATA[<p>In the past two posts (<a href="https://wellecks.wordpress.com/2014/09/04/these-are-your-tweets-on-lda-part-i/">part I</a> and <a href="https://wellecks.wordpress.com/2014/09/06/these-are-your-tweets-on-lda-part-ii/">part II</a>), we used <a href="http://en.wikipedia.org/wiki/Latent_Dirichlet_allocation">Latent Dirichlet Allocation</a> (LDA) to discover topics for tweets, and visualized them. In this post, we&#8217;ll investigate using LDA on an 8gb dataset of around 8 million <a href="http://stackoverflow.com/">Stack Overflow</a> posts.</p>
<p>We&#8217;ll need to take a different approach; for the tweets we used a batch algorithm that worked well for the relatively small dataset of around 5000 tweets, but would likely introduce performance issues when running on massive datasets. The batch algorithm also assumed that we have the entire training set at the start of training, making the approach unviable for streaming data, which we may receive <em>during</em> training. It&#8217;d be nice to train the model incrementally, so that we can train on a chunk of data, then resume training if we receive more data <em>without</em> have to retrain on the original chunk.</p>
<p>In this post, we&#8217;ll look at <a href="https://www.cs.princeton.edu/~blei/papers/HoffmanBleiBach2010b.pdf">Online LDA</a>, a variation of &#8216;vanilla&#8217; LDA that can be trained incrementally in small batches. Online LDA is a good choice for large datasets since we only need to hold a very small subset of the dataset in memory at a given time, and a good fit for streaming data since we can continually feed in new data batches as we receive them. We&#8217;re also able to save the model state at a point in training, then resume later when we want to train on more data.</p>
<p>First, we&#8217;ll jump into the math and look at the differences between online and batch LDA. Then we&#8217;ll use a python implementation of online LDA to discover topics for the Stack Overflow dataset. As usual, all of the associated code is <a href="https://github.com/wellecks/online_lda_python">available on GitHub</a>.</p>
<p><strong>Variations on Variational Bayes</strong></p>
<p>For brevity this part will assume that you&#8217;ve read through the math background in the <a href="https://wellecks.wordpress.com/2014/09/04/these-are-your-tweets-on-lda-part-i/">first LDA post</a>. I&#8217;ll also only highlight major parts; for the full story check out <a href="https://www.cs.princeton.edu/~blei/papers/HoffmanBleiBach2010b.pdf">Hoffman&#8217;s online LDA paper</a>.</p>
<p>In LDA, our ultimate goal is to find the posterior distribution of latent topic variables after observing training data. However, computing this distribution is intractable, so we&#8217;re forced to approximate. One approximation approach is to use an optimization method called <a href="http://en.wikipedia.org/wiki/Variational_Bayesian_methods">Variational Bayes</a>.</p>
<p>In short, we approximate the true distribution by a simple distribution <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q" class="latex" />, and associate parameters <img src="https://s0.wp.com/latex.php?latex=%5Cphi%2C%5C+%5Cgamma%2C%5C+%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi%2C%5C+%5Cgamma%2C%5C+%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi%2C%5C+%5Cgamma%2C%5C+%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi,&#92; &#92;gamma,&#92; &#92;lambda" class="latex" /> with the original parameters <img src="https://s0.wp.com/latex.php?latex=z%2C%5C+%5Ctheta%2C%5C+%5Cbeta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=z%2C%5C+%5Ctheta%2C%5C+%5Cbeta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=z%2C%5C+%5Ctheta%2C%5C+%5Cbeta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="z,&#92; &#92;theta,&#92; &#92;beta" class="latex" /> respectively. Recall that <img src="https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="z" class="latex" /> gives the topic assignments for each word in each document , <img src="https://s0.wp.com/latex.php?latex=%5Ctheta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctheta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctheta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;theta" class="latex" /> gives the topic composition of each document, and <img src="https://s0.wp.com/latex.php?latex=%5Cbeta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbeta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;beta" class="latex" /> gives the word-topic probabilities for each word and each topic.</p>
<p>Specifically, we have:</p>
<p style="text-align:center;"><img src="https://s0.wp.com/latex.php?latex=q%28z_%7Bdi%7D%3Dk%29+%3D+%5Cphi_%7Bdw_%7Bdi%7Dk%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q%28z_%7Bdi%7D%3Dk%29+%3D+%5Cphi_%7Bdw_%7Bdi%7Dk%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q%28z_%7Bdi%7D%3Dk%29+%3D+%5Cphi_%7Bdw_%7Bdi%7Dk%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q(z_{di}=k) = &#92;phi_{dw_{di}k}" class="latex" /></p>
<p style="text-align:center;"><img src="https://s0.wp.com/latex.php?latex=q%28%5Ctheta_%7Bd%7D%29+%3D+dirichlet%28%5Ctheta_%7Bd%7D%3B+%5Cgamma_%7Bd%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q%28%5Ctheta_%7Bd%7D%29+%3D+dirichlet%28%5Ctheta_%7Bd%7D%3B+%5Cgamma_%7Bd%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q%28%5Ctheta_%7Bd%7D%29+%3D+dirichlet%28%5Ctheta_%7Bd%7D%3B+%5Cgamma_%7Bd%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q(&#92;theta_{d}) = dirichlet(&#92;theta_{d}; &#92;gamma_{d})" class="latex" /></p>
<p style="text-align:center;"><img src="https://s0.wp.com/latex.php?latex=q%28%5Cbeta_%7Bk%7D%29+%3D+dirichlet%28%5Cbeta_%7Bk%7D%3B+%5Clambda_%7Bk%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q%28%5Cbeta_%7Bk%7D%29+%3D+dirichlet%28%5Cbeta_%7Bk%7D%3B+%5Clambda_%7Bk%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q%28%5Cbeta_%7Bk%7D%29+%3D+dirichlet%28%5Cbeta_%7Bk%7D%3B+%5Clambda_%7Bk%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q(&#92;beta_{k}) = dirichlet(&#92;beta_{k}; &#92;lambda_{k})" class="latex" /></p>
<p style="text-align:left;">Our goal is to estimate <img src="https://s0.wp.com/latex.php?latex=%5Cphi%2C%5C+%5Cgamma%2C%5C+%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi%2C%5C+%5Cgamma%2C%5C+%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi%2C%5C+%5Cgamma%2C%5C+%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi,&#92; &#92;gamma,&#92; &#92;lambda" class="latex" />. In both batch and online LDA, we alternate between two steps:</p>
<p style="text-align:left;padding-left:30px;">1. <em>E-Step</em>: Estimate <img src="https://s0.wp.com/latex.php?latex=%5Cphi%2C%5C+%5Cgamma&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi%2C%5C+%5Cgamma&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi%2C%5C+%5Cgamma&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi,&#92; &#92;gamma" class="latex" /> using the current value of <img src="https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lambda" class="latex" /></p>
<p style="text-align:left;padding-left:30px;">2. <em>M-Step</em>: Update <img src="https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lambda" class="latex" /> , using the current value of <img src="https://s0.wp.com/latex.php?latex=%5Cphi&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi" class="latex" /></p>
<p>The core difference between batch and online LDA is in how these steps are carried out at the algorithmic level.</p>
<p><b>Starting with Batch</b></p>
<p>In batch Variational Bayes, we perform multiple passes over the <em>entire</em> dataset, checking each time for convergence. During each pass, the algorithm does an E-Step using the <em>entire</em> dataset. At a high level:</p>
<pre><span style="text-decoration:underline;"><b>E-Step</b></span>
for d = 1 to numDocs
    initialize <img src="https://s0.wp.com/latex.php?latex=%5Cgamma&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cgamma&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cgamma&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;gamma" class="latex" />
    repeat until change in <img src="https://s0.wp.com/latex.php?latex=%5Cphi+%3C+%5Cepsilon&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi+%3C+%5Cepsilon&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi+%3C+%5Cepsilon&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi &lt; &#92;epsilon" class="latex" />
        update <img src="https://s0.wp.com/latex.php?latex=%5Cphi&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi" class="latex" />
        update <img src="https://s0.wp.com/latex.php?latex=%5Cgamma&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cgamma&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cgamma&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;gamma" class="latex" /></pre>
<p>Then the M-Step updates <img src="https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lambda" class="latex" /> using <img src="https://s0.wp.com/latex.php?latex=%5Cphi&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi" class="latex" /> values from <em>every</em> document:</p>
<pre><span style="text-decoration:underline;"><strong>M-Step
</strong></span>update <img src="https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lambda" class="latex" /></pre>
<p>The specific updates are:</p>
<p style="text-align:center;"><img src="https://s0.wp.com/latex.php?latex=%5Cphi_%7Bd%2Cword_%7Bi%7D%2Ck%7D+%5Cpropto+e%5E%7BE_%7Bq%7D%28log+%5Ctheta_%7Bd%2Ck%7D%29%2BE_%7Bq%7D%28log%5Cbeta_%7Bk%2Cword_%7Bi%7D%7D%29%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi_%7Bd%2Cword_%7Bi%7D%2Ck%7D+%5Cpropto+e%5E%7BE_%7Bq%7D%28log+%5Ctheta_%7Bd%2Ck%7D%29%2BE_%7Bq%7D%28log%5Cbeta_%7Bk%2Cword_%7Bi%7D%7D%29%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi_%7Bd%2Cword_%7Bi%7D%2Ck%7D+%5Cpropto+e%5E%7BE_%7Bq%7D%28log+%5Ctheta_%7Bd%2Ck%7D%29%2BE_%7Bq%7D%28log%5Cbeta_%7Bk%2Cword_%7Bi%7D%7D%29%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi_{d,word_{i},k} &#92;propto e^{E_{q}(log &#92;theta_{d,k})+E_{q}(log&#92;beta_{k,word_{i}})}" class="latex" /></p>
<p style="text-align:center;"><img src="https://s0.wp.com/latex.php?latex=%5Cgamma_%7Bd%2Ck%7D+%3D+%5Calpha+%2B+%5Csum_%7Bword_%7Bi%7D%7D%5Cphi_%7Bd%2Cword_%7Bi%7D%2Ck%7Dn_%7Bd%2Cword_%7Bi%7D%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cgamma_%7Bd%2Ck%7D+%3D+%5Calpha+%2B+%5Csum_%7Bword_%7Bi%7D%7D%5Cphi_%7Bd%2Cword_%7Bi%7D%2Ck%7Dn_%7Bd%2Cword_%7Bi%7D%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cgamma_%7Bd%2Ck%7D+%3D+%5Calpha+%2B+%5Csum_%7Bword_%7Bi%7D%7D%5Cphi_%7Bd%2Cword_%7Bi%7D%2Ck%7Dn_%7Bd%2Cword_%7Bi%7D%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;gamma_{d,k} = &#92;alpha + &#92;sum_{word_{i}}&#92;phi_{d,word_{i},k}n_{d,word_{i}}" class="latex" /></p>
<p style="text-align:center;"><img src="https://s0.wp.com/latex.php?latex=%5Clambda_%7Bk%2Cword_%7Bi%7D%7D%3D%5Ceta+%2B%5Csum_%7Bd%7Dn_%7Bd%2Cword_%7Bi%7D%7D%5Cphi_%7Bd%2Cword_%7Bi%7D%2Ck%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clambda_%7Bk%2Cword_%7Bi%7D%7D%3D%5Ceta+%2B%5Csum_%7Bd%7Dn_%7Bd%2Cword_%7Bi%7D%7D%5Cphi_%7Bd%2Cword_%7Bi%7D%2Ck%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda_%7Bk%2Cword_%7Bi%7D%7D%3D%5Ceta+%2B%5Csum_%7Bd%7Dn_%7Bd%2Cword_%7Bi%7D%7D%5Cphi_%7Bd%2Cword_%7Bi%7D%2Ck%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lambda_{k,word_{i}}=&#92;eta +&#92;sum_{d}n_{d,word_{i}}&#92;phi_{d,word_{i},k}" class="latex" /></p>
<p style="text-align:left;">Where <img src="https://s0.wp.com/latex.php?latex=n_%7Bd%2Cword_%7Bi%7D%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n_%7Bd%2Cword_%7Bi%7D%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n_%7Bd%2Cword_%7Bi%7D%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n_{d,word_{i}}" class="latex" /> is the number of occurrences of <img src="https://s0.wp.com/latex.php?latex=word_%7Bi%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=word_%7Bi%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=word_%7Bi%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="word_{i}" class="latex" /> in document <em>d</em>.</p>
<p style="text-align:left;"><strong>Going Online</strong></p>
<p style="text-align:left;">In online Variational Bayes, we only make a single sweep of the entire dataset, analyzing a chunk of documents at a time. A &#8216;chunk&#8217; could be a single document, 42 documents, or even the entire dataset. Let&#8217;s let a &#8216;chunk&#8217; be 1000 documents.</p>
<p style="text-align:left;">The online E-Step only uses the current chunk; instead of 8 million posts we now only have to hold 1000 in memory. The E-Step finds locally optimal values for <img src="https://s0.wp.com/latex.php?latex=%5Cphi&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%5Cgamma%3A&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cgamma%3A&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cgamma%3A&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;gamma:" class="latex" /></p>
<pre><span style="text-decoration:underline;"><b>E-Step</b></span>
initialize <img src="https://s0.wp.com/latex.php?latex=%5Cgamma&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cgamma&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cgamma&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;gamma" class="latex" />
repeat until change in <img src="https://s0.wp.com/latex.php?latex=%5Cphi+%3C+%5Cepsilon&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi+%3C+%5Cepsilon&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi+%3C+%5Cepsilon&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi &lt; &#92;epsilon" class="latex" />
    update <img src="https://s0.wp.com/latex.php?latex=%5Cphi&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi" class="latex" />
    update <img src="https://s0.wp.com/latex.php?latex=%5Cgamma&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cgamma&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cgamma&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;gamma" class="latex" /></pre>
<p>In the M-Step, we first compute <img src="https://s0.wp.com/latex.php?latex=%5Clambda%27&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clambda%27&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda%27&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lambda&#039;" class="latex" />, which is the value of <img src="https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lambda" class="latex" /> if we imagined that the entire dataset is made up of <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7BnumDocs%7D%7BchunkSize%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cfrac%7BnumDocs%7D%7BchunkSize%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cfrac%7BnumDocs%7D%7BchunkSize%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;frac{numDocs}{chunkSize}" class="latex" /> copies of the current chunk. Then <img src="https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lambda" class="latex" /> is updated using a weighted sum of <img src="https://s0.wp.com/latex.php?latex=%5Clambda%27&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clambda%27&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda%27&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lambda&#039;" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%5Clambda%3A&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clambda%3A&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda%3A&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lambda:" class="latex" /></p>
<pre><span style="text-decoration:underline;"><strong>M-Step
</strong></span>compute <img src="https://s0.wp.com/latex.php?latex=%5Clambda%27&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clambda%27&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda%27&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lambda&#039;" class="latex" />
update <img src="https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lambda" class="latex" /></pre>
<p>The specific updates are:</p>
<p style="text-align:center;"><img src="https://s0.wp.com/latex.php?latex=%5Cphi_%7Biter%2Cword_%7Bi%7D%2Ck%7D+%5Cpropto+e%5E%7BE_%7Bq%7D%28log+%5Ctheta_%7Biter%2Ck%7D%29%2BE_%7Bq%7D%28log%5Cbeta_%7Bk%2Cword_%7Bi%7D%7D%29%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi_%7Biter%2Cword_%7Bi%7D%2Ck%7D+%5Cpropto+e%5E%7BE_%7Bq%7D%28log+%5Ctheta_%7Biter%2Ck%7D%29%2BE_%7Bq%7D%28log%5Cbeta_%7Bk%2Cword_%7Bi%7D%7D%29%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi_%7Biter%2Cword_%7Bi%7D%2Ck%7D+%5Cpropto+e%5E%7BE_%7Bq%7D%28log+%5Ctheta_%7Biter%2Ck%7D%29%2BE_%7Bq%7D%28log%5Cbeta_%7Bk%2Cword_%7Bi%7D%7D%29%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi_{iter,word_{i},k} &#92;propto e^{E_{q}(log &#92;theta_{iter,k})+E_{q}(log&#92;beta_{k,word_{i}})}" class="latex" /></p>
<p style="text-align:center;"><img src="https://s0.wp.com/latex.php?latex=%5Cgamma_%7Biter%2Ck%7D+%3D+%5Calpha+%2B+%5Csum_%7Bword_%7Bi%7D%7D%5Cphi_%7Biter%2Cword_%7Bi%7D%2Ck%7Dn_%7Biter%2Cword_%7Bi%7D%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cgamma_%7Biter%2Ck%7D+%3D+%5Calpha+%2B+%5Csum_%7Bword_%7Bi%7D%7D%5Cphi_%7Biter%2Cword_%7Bi%7D%2Ck%7Dn_%7Biter%2Cword_%7Bi%7D%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cgamma_%7Biter%2Ck%7D+%3D+%5Calpha+%2B+%5Csum_%7Bword_%7Bi%7D%7D%5Cphi_%7Biter%2Cword_%7Bi%7D%2Ck%7Dn_%7Biter%2Cword_%7Bi%7D%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;gamma_{iter,k} = &#92;alpha + &#92;sum_{word_{i}}&#92;phi_{iter,word_{i},k}n_{iter,word_{i}}" class="latex" /></p>
<p style="text-align:center;"><img src="https://s0.wp.com/latex.php?latex=%5Clambda%27_%7Bk%2Cword_%7Bi%7D%7D%3D%5Ceta+%2BbatchSize%2An_%7Biter%2Cword_%7Bi%7D%7D%5Cphi_%7Biter%2Cword_%7Bi%7D%2Ck%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clambda%27_%7Bk%2Cword_%7Bi%7D%7D%3D%5Ceta+%2BbatchSize%2An_%7Biter%2Cword_%7Bi%7D%7D%5Cphi_%7Biter%2Cword_%7Bi%7D%2Ck%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda%27_%7Bk%2Cword_%7Bi%7D%7D%3D%5Ceta+%2BbatchSize%2An_%7Biter%2Cword_%7Bi%7D%7D%5Cphi_%7Biter%2Cword_%7Bi%7D%2Ck%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lambda&#039;_{k,word_{i}}=&#92;eta +batchSize*n_{iter,word_{i}}&#92;phi_{iter,word_{i},k}" class="latex" /></p>
<p style="text-align:center;"><img src="https://s0.wp.com/latex.php?latex=%5Clambda+%3D+%281-%5Crho_t%29%5Clambda%2B%5Crho_t%5Clambda%27&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clambda+%3D+%281-%5Crho_t%29%5Clambda%2B%5Crho_t%5Clambda%27&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda+%3D+%281-%5Crho_t%29%5Clambda%2B%5Crho_t%5Clambda%27&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lambda = (1-&#92;rho_t)&#92;lambda+&#92;rho_t&#92;lambda&#039;" class="latex" /></p>
<p style="text-align:left;">Where <img src="https://s0.wp.com/latex.php?latex=n_%7Biter%2Cword_%7Bi%7D%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n_%7Biter%2Cword_%7Bi%7D%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n_%7Biter%2Cword_%7Bi%7D%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n_{iter,word_{i}}" class="latex" /> is the number of occurrences of <img src="https://s0.wp.com/latex.php?latex=word_%7Bi%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=word_%7Bi%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=word_%7Bi%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="word_{i}" class="latex" /> in the current iteration&#8217;s chunk of documents, and <img src="https://s0.wp.com/latex.php?latex=%5Crho_t+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Crho_t+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Crho_t+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;rho_t " class="latex" /> is a weighting parameter.</p>
<p style="text-align:left;">We can see that unlike batch LDA, in online LDA we only need to hold a small chunk of the data at a time, and once we&#8217;re done analyzing it, we never need it again. As with batch, once we&#8217;ve estimated <img src="https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lambda" class="latex" />, we can find the most probable words for each topic by looking at the word probabilities in each row of <img src="https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lambda" class="latex" />.</p>
<p style="text-align:left;"><strong>Intuitions of the Inference</strong></p>
<p style="text-align:left;">If we squint and step back, LDA consists of using simple word counts in a clever way. The two parameters we ultimately care about are <img src="https://s0.wp.com/latex.php?latex=%5Cgamma&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cgamma&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cgamma&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;gamma" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lambda" class="latex" />. How do these get updated during training?</p>
<p style="text-align:left;">Updates of <img src="https://s0.wp.com/latex.php?latex=%5Cgamma&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cgamma&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cgamma&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;gamma" class="latex" /> (the topic compositions for each document) are the prior <img src="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha" class="latex" /> plus a weighted sum of word counts. The word counts are weighted by <img src="https://s0.wp.com/latex.php?latex=%5Cphi_%7Bword%2Ctopic%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi_%7Bword%2Ctopic%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi_%7Bword%2Ctopic%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi_{word,topic}" class="latex" />, the probability of assigning the word to the topic. Intuitively, if we count a lot of instances of &#8220;potato&#8221; in a document, and &#8220;potato&#8221; is likely to be assigned to topic 2, then it makes sense that the document has more of topic 2 in it than we previously thought.</p>
<p style="text-align:left;">Updates of <img src="https://s0.wp.com/latex.php?latex=%5Clambda_%7Btopic%2Cword%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clambda_%7Btopic%2Cword%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda_%7Btopic%2Cword%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lambda_{topic,word}" class="latex" /> (the word-topic probabilities) use word counts weighted by the probability that the word will be assigned to the given topic. If &#8220;potato&#8221; shows up a lot in the dataset is likely to be assigned to topic 2, then it makes sense that <img src="https://s0.wp.com/latex.php?latex=%5Clambda_%7B2%2C+potato%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clambda_%7B2%2C+potato%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda_%7B2%2C+potato%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lambda_{2, potato}" class="latex" /> should increase.</p>
<p style="text-align:left;"><strong>LDA Overflow</strong></p>
<p style="text-align:left;">Now it&#8217;s time to run Online LDA on the Stack Overflow dataset to discover topics without overflowing our memory. Stack Exchange kindly provides (and updates) <a href="https://archive.org/details/stackexchange">a data dump of all of its user generated content</a>; I chose the <em>stackoverflow.com-Posts.7z</em> dataset.</p>
<p style="text-align:left;"><strong>Read, Clean, Parse, Repeat</strong></p>
<p style="text-align:left;">The data arrives as a 27gb XML behemoth. The first step is isolating the text from the <em>Title</em> and <em>Body</em> fields for each row. These fields will comprise a &#8216;document&#8217;, and our dataset will be formatted as a text file with one document per line.</p>
<p style="text-align:left;">Since the file is so large, we need to incrementally read the XML. We also filter out non alpha-numeric characters. Details for this process can be found in <a href="https://github.com/wellecks/online_lda_python/blob/master/xml_parse.py">xml_parse.py</a>.</p>
<p style="text-align:left;">Once <a href="https://github.com/wellecks/online_lda_python/blob/master/xml_parse.py">xml_parse.py</a> runs, we get an 8gb text file containing around 8,000,000 stack overflow documents (title and body content). A couple examples:</p>
<pre style="text-align:left;">Throw an error in a MySQL trigger If I have a trigger before the update on a table how can I throw an error that prevents the update on that table

Compressing Decompressing Folders Files Does anyone know of a good way to compress or decompress files and folders in C quickly Handling large files might be necessary</pre>
<p style="text-align:left;"><strong>LDA by Hoffman</strong></p>
<p style="text-align:left;">We&#8217;ll use a Python implementation of online LDA written by Matt Hoffman, available on <a href="http://www.cs.princeton.edu/~mdhoffma/">his webpage</a>. We need to adapt the high-level running script for our application; to do so I created a wrapper for running LDA called <a href="https://github.com/wellecks/online_lda_python/blob/master/online_lda.py">online_lda.py</a>. Use</p>
<pre style="text-align:left;">python online_lda.py -h</pre>
<p style="text-align:left;">to see the various command line arguments.</p>
<p style="text-align:left;">I&#8217;ve also added more comments to <a href="https://github.com/wellecks/online_lda_python/blob/master/onlineldavb.py">onlineldavb.py</a> on the repo in case you&#8217;d like to further inspect how the actual Online LDA algorithm is implemented.</p>
<p style="text-align:left;"><strong>Building a Vocabulary</strong></p>
<p style="text-align:left;">The LDA implementation assumes that we have a vocabulary file prior to training so that it can compactly represent documents as numeric word IDs. The vocabulary also allows us the algorithm to associate an index of <img src="https://s0.wp.com/latex.php?latex=%5Cbeta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbeta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;beta" class="latex" /> with a word ID and hence with a word.</p>
<p style="text-align:left;">We can generate a domain-specific vocabulary using the first 100,000 Stack Overflow posts, and supplement it with the vocabulary provided by Hoffman, which contains the most frequent English words. <a href="http://radimrehurek.com/gensim/">Gensim</a> has a nice library for creating vocabularies. We filter out words that appear in fewer than 10 documents, since they are often &#8216;junk&#8217; words, and would probably not appear in the top words for a topic anyways since they appear so infrequently. Code for the vocabulary generation is found in <a href="https://github.com/wellecks/online_lda_python/blob/master/dictionary.py">dictionary.py</a>.</p>
<p style="text-align:left;"><strong>Running</strong></p>
<p style="text-align:left;">Let&#8217;s kick it off!</p>
<pre style="text-align:left;">python online_lda.py dataset.txt vocabulary.txt</pre>
<p style="text-align:left;">The training took ~12 hours for a 100 topic model on my MacBook. The values of <img src="https://s0.wp.com/latex.php?latex=%5Cgamma&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cgamma&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cgamma&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;gamma" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lambda" class="latex" /> are output to files every 10,000 iterations and when the training completes. We can then use one of the <img src="https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lambda" class="latex" /> files to see the top 20 words for the top N topics. For instance, to print the top 2 topics with the final model, use:</p>
<pre style="text-align:left;">python printtopics.py vocabulary.txt lambda-final.dat 2</pre>
<p style="text-align:left;">giving:</p>
<pre style="text-align:left;"><span style="text-decoration:underline;"><strong>topic 0</strong></span>
suspended:0.8356
authorization:0.0215
entityset:0.0128
treemap:0.0094
professionals:0.0086
best:0.0084
facts:0.0072
special:0.0062
syntax:0.0056
listing:0.0051
forwarding:0.0049
webparts:0.0047
duration:0.0045
valued:0.0039
halts:0.0038
baggage:0.0034
yeah:0.0034
ltaspdropdownlistgt:0.0033
twitter:0.0031
liable:0.0030

<strong><span style="text-decoration:underline;">topic 1</span></strong>
support:0.7800
quarter:0.0380
fig:0.0278
luck:0.0160
1gb:0.0142
funeral:0.0124
visiting:0.0109
xiv:0.0071
screen:0.0063
commons:0.0046
monster:0.0040
flash:0.0039
faculty:0.0037
desire:0.0031
detached:0.0030
handler:0.0028
say:0.0028
everyday:0.0025
darker:0.0025
screen:0.0024</pre>
<p style="text-align:left;">The numbers are the word-topic probabilities from <img src="https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lambda" class="latex" />.</p>
<p style="text-align:left;">We&#8217;ll use the approach from the first LDA post to create word clouds for two different topics:</p>
<p style="text-align:left;"><img loading="lazy" data-attachment-id="873" data-permalink="https://wellecks.wordpress.com/2014/10/26/ldaoverflow-with-online-lda/topic_cloud2/#main" data-orig-file="https://wellecks.files.wordpress.com/2014/10/topic_cloud2.png" data-orig-size="1656,828" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="topic_cloud2" data-image-description="" data-image-caption="" data-medium-file="https://wellecks.files.wordpress.com/2014/10/topic_cloud2.png?w=300" data-large-file="https://wellecks.files.wordpress.com/2014/10/topic_cloud2.png?w=525" class="aligncenter size-large wp-image-873" src="https://wellecks.files.wordpress.com/2014/10/topic_cloud2.png?w=525&#038;h=262" alt="topic_cloud2" width="525" height="262" srcset="https://wellecks.files.wordpress.com/2014/10/topic_cloud2.png?w=525&amp;h=262 525w, https://wellecks.files.wordpress.com/2014/10/topic_cloud2.png?w=1048&amp;h=524 1048w, https://wellecks.files.wordpress.com/2014/10/topic_cloud2.png?w=150&amp;h=75 150w, https://wellecks.files.wordpress.com/2014/10/topic_cloud2.png?w=300&amp;h=150 300w, https://wellecks.files.wordpress.com/2014/10/topic_cloud2.png?w=768&amp;h=384 768w, https://wellecks.files.wordpress.com/2014/10/topic_cloud2.png?w=1024&amp;h=512 1024w" sizes="(max-width: 525px) 100vw, 525px" /></p>
<p style="text-align:left;"><a href="https://wellecks.files.wordpress.com/2014/10/topic_cloud1.png"><img loading="lazy" data-attachment-id="872" data-permalink="https://wellecks.wordpress.com/2014/10/26/ldaoverflow-with-online-lda/topic_cloud1/#main" data-orig-file="https://wellecks.files.wordpress.com/2014/10/topic_cloud1.png" data-orig-size="1466,1100" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="topic_cloud1" data-image-description="" data-image-caption="" data-medium-file="https://wellecks.files.wordpress.com/2014/10/topic_cloud1.png?w=300" data-large-file="https://wellecks.files.wordpress.com/2014/10/topic_cloud1.png?w=525" class="aligncenter size-large wp-image-872" src="https://wellecks.files.wordpress.com/2014/10/topic_cloud1.png?w=525&#038;h=393" alt="topic_cloud1" width="525" height="393" srcset="https://wellecks.files.wordpress.com/2014/10/topic_cloud1.png?w=525&amp;h=393 525w, https://wellecks.files.wordpress.com/2014/10/topic_cloud1.png?w=1048&amp;h=786 1048w, https://wellecks.files.wordpress.com/2014/10/topic_cloud1.png?w=150&amp;h=113 150w, https://wellecks.files.wordpress.com/2014/10/topic_cloud1.png?w=300&amp;h=225 300w, https://wellecks.files.wordpress.com/2014/10/topic_cloud1.png?w=768&amp;h=576 768w, https://wellecks.files.wordpress.com/2014/10/topic_cloud1.png?w=1024&amp;h=768 1024w" sizes="(max-width: 525px) 100vw, 525px" /></a><strong>Conclusion</strong></p>
<p style="text-align:left;">We managed to find topics on a dataset of 8 million Stack Overflow posts by using Online LDA. Feel free to download the code and try it out on other datasets!</p>
<p style="text-align:left;"><strong>Credits &amp; Links</strong></p>
<p style="text-align:left;">Much of the material is derived from <a href="https://www.cs.princeton.edu/~blei/papers/HoffmanBleiBach2010b.pdf">Hoffman&#8217;s paper</a> and his online LDA implementation. <a href="http://radimrehurek.com/gensim/models/ldamodel.html">Gensim</a> and <a href="https://github.com/JohnLangford/vowpal_wabbit/wiki/Latent-Dirichlet-Allocation">Vowpal Wabbit</a> also have implementations of online LDA.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://wellecks.wordpress.com/2014/10/26/ldaoverflow-with-online-lda/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		
		<media:content url="https://0.gravatar.com/avatar/f7546f57a5fd69bc99ff1640cc4a4853?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">wellecks</media:title>
		</media:content>

		<media:content url="https://wellecks.files.wordpress.com/2014/10/topic_cloud2.png?w=525" medium="image">
			<media:title type="html">topic_cloud2</media:title>
		</media:content>

		<media:content url="https://wellecks.files.wordpress.com/2014/10/topic_cloud1.png?w=525" medium="image">
			<media:title type="html">topic_cloud1</media:title>
		</media:content>
	</item>
		<item>
		<title>These Are Your Tweets on LDA (Part II)</title>
		<link>https://wellecks.wordpress.com/2014/09/06/these-are-your-tweets-on-lda-part-ii/</link>
					<comments>https://wellecks.wordpress.com/2014/09/06/these-are-your-tweets-on-lda-part-ii/#respond</comments>
		
		<dc:creator><![CDATA[wellecks]]></dc:creator>
		<pubDate>Sat, 06 Sep 2014 20:32:05 +0000</pubDate>
				<category><![CDATA[artificial intelligence]]></category>
		<category><![CDATA[machine learning]]></category>
		<category><![CDATA[d3.js]]></category>
		<category><![CDATA[Latent Dirichlet Allocation]]></category>
		<category><![CDATA[LDA]]></category>
		<category><![CDATA[Machine learning]]></category>
		<category><![CDATA[topic modeling]]></category>
		<guid isPermaLink="false">http://wellecks.wordpress.com/?p=830</guid>

					<description><![CDATA[In the last post, I gave an overview of Latent Dirichlet Allocation (LDA), and walked through an application of LDA on @BarackObama&#8217;s tweets. The final product was a set of word clouds, one per topic, that showed the weighted words that defined the topic. In this post, we&#8217;ll develop a dynamic visualization that incorporates multiple topics, allowing [&#8230;]]]></description>
										<content:encoded><![CDATA[<p><a href="https://wellecks.wordpress.com/2014/09/03/these-are-your-tweets-on-lda-part-i/">In the last post</a>, I gave an overview of Latent Dirichlet Allocation (LDA), and walked through an application of LDA on @BarackObama&#8217;s tweets. The final product was a set of word clouds, one per topic, that showed the weighted words that defined the topic.</p>
<p>In this post, we&#8217;ll develop a dynamic visualization that incorporates <em>multiple</em> topics, allowing us to gain of a high level view of the topics and also drill down to see the words that define each topic. Through a simple web interface, we&#8217;ll also be able to view data from different twitter users.</p>
<p><a title="LDA Visualization" href="http://ldaviz.herokuapp.com/">Click here for an example of the finished product</a>.</p>
<p>As before, all of the code is <a href="https://github.com/wellecks/lda_tweets">available on GitHub</a>. The visualization-related code is found in the <a href="https://github.com/wellecks/lda_tweets/tree/master/viz/static"><em>viz/static</em></a> directory.</p>
<p style="text-align:center;"><strong>Harnessing the Data</strong></p>
<p>In the last post, we downloaded tweets for a user and found 50 topics that occur in the user&#8217;s tweets along with the top 20 words for each topic. We also found the composition of topics across all of the tweets, allowing us to rank the topics by prominence. For our visualization, we&#8217;ll choose to display the 10 highest ranked topics for a given twitter user name.</p>
<p>We need a visualization that can show multiple groupings of data. Each of the 10 groupings has 20 words, so we&#8217;d also like one that avoids the potential information overload. Finally, we&#8217;d like to incorporate the frequencies that we have for each word.</p>
<p style="text-align:center;"><b>d3</b></p>
<p>A good fit for these requirements is <a href="http://d3js.org/">d3.js</a>&#8216;s <a href="http://mbostock.github.io/d3/talk/20111116/pack-hierarchy.html">Zoomable Pack Layout</a>, which gives us a high level view of each grouping as a bubble. Upon clicking a bubble, we can see the data that comprises the bubble, as well as each data point&#8217;s relative weight:</p>
<p>&nbsp;</p>
<div data-shortcode="caption" id="attachment_834" style="width: 535px" class="wp-caption aligncenter"><img loading="lazy" aria-describedby="caption-attachment-834" data-attachment-id="834" data-permalink="https://wellecks.wordpress.com/2014/09/06/these-are-your-tweets-on-lda-part-ii/screen-shot-2014-09-06-at-2-38-24-pm/#main" data-orig-file="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-06-at-2-38-24-pm.png" data-orig-size="1798,1576" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="d3" data-image-description="" data-image-caption="&lt;p&gt;d3 to the rescue&lt;/p&gt;
" data-medium-file="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-06-at-2-38-24-pm.png?w=300" data-large-file="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-06-at-2-38-24-pm.png?w=525" class="size-large wp-image-834" src="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-06-at-2-38-24-pm.png?w=525&#038;h=460" alt="d3 to the rescue" width="525" height="460" srcset="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-06-at-2-38-24-pm.png?w=525&amp;h=460 525w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-06-at-2-38-24-pm.png?w=1050&amp;h=920 1050w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-06-at-2-38-24-pm.png?w=150&amp;h=131 150w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-06-at-2-38-24-pm.png?w=300&amp;h=263 300w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-06-at-2-38-24-pm.png?w=768&amp;h=673 768w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-06-at-2-38-24-pm.png?w=1024&amp;h=898 1024w" sizes="(max-width: 525px) 100vw, 525px" /><p id="caption-attachment-834" class="wp-caption-text">d3 Zoomable Pack Layout</p></div>
<p>In our case, each top-level bubble is a topic, and each inner bubble is a word, with its relative size determined by the word&#8217;s frequency.</p>
<p>Since the d3 visualization takes JSON as input, in order to plug in our LDA output data we simply create a <em>toJSON()</em> method in <a href="https://github.com/wellecks/lda_tweets/blob/master/src/lda/TopicModel.java">TopicModel.java</a> that outputs the data associated with the top 10 topics to a JSON file. The &#8216;name&#8217; of each topic is simply the most probably word in the topic.</p>
<p>Now, when the LDA process (the main() method in TopicModel.java) is run for a twitter user, the code will create a corresponding JSON file in <em>viz/json</em>. The JSON structure:</p>
<pre>{
 "name":"",
 "children":[
    {
     "name": {topic_1_name},
     "children":[
       {
        "name": {topic_1_word_1},
        "size": {topic_1_word_1_freq}
       },
       {
        "name": {topic_1_word_2},
        "size": {topic_1_word_2_freq}
       },
       {
        "name": {topic_1_word_3},
        "size": {topic_1_word_3_freq}
       },
....</pre>
<p style="text-align:center;"><b>Javascripting</b></p>
<p style="text-align:left;">Now, we make slight modifications to the javascript code embedded in the given d3 visualization. Our goal is to be able to toggle between results for different twitter users; we&#8217;d like to switch from investigating the <a href="https://twitter.com/nytimes">@nytimes</a> topics to getting a sense of what <a href="https://twitter.com/KingJames">@KingJames</a> tweets about.</p>
<p style="text-align:left;">To do so, we add a drop-down to index.html, such that each time a user is selected on the drop-down, their corresponding JSON is loaded by the <em>show()</em> function in <a href="https://github.com/wellecks/lda_tweets/blob/master/viz/static/js/viz.js">viz.js</a>. Hence we also change the <em>show()</em> function to reload the visualization each time it is called.</p>
<p style="text-align:center;"><strong>Making The Visualizations Visible</strong></p>
<p style="text-align:left;">To run the code locally, navigate to the <em>viz/static</em> directory and start an HTTP server to serve the content, e.g.</p>
<pre style="text-align:left;">cd {project_root}/viz/static
python -m SimpleHTTPServer</pre>
<p style="text-align:left;">then navigate to <a href="http://localhost:8000/index.html">http://localhost:8000/index.html</a> to see the visualization.</p>
<p style="text-align:left;">By selecting nytimes, we see the following visualization which gives a sense of the topics:</p>
<p style="text-align:left;"><a href="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-06-at-3-25-21-pm.png"><img loading="lazy" data-attachment-id="840" data-permalink="https://wellecks.wordpress.com/2014/09/06/these-are-your-tweets-on-lda-part-ii/screen-shot-2014-09-06-at-3-25-21-pm/#main" data-orig-file="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-06-at-3-25-21-pm.png" data-orig-size="1798,1596" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="@nytimes topics" data-image-description="" data-image-caption="" data-medium-file="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-06-at-3-25-21-pm.png?w=300" data-large-file="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-06-at-3-25-21-pm.png?w=525" class="aligncenter size-large wp-image-840" src="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-06-at-3-25-21-pm.png?w=525&#038;h=466" alt="@nytimes topics" width="525" height="466" srcset="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-06-at-3-25-21-pm.png?w=525&amp;h=466 525w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-06-at-3-25-21-pm.png?w=1050&amp;h=932 1050w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-06-at-3-25-21-pm.png?w=150&amp;h=133 150w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-06-at-3-25-21-pm.png?w=300&amp;h=266 300w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-06-at-3-25-21-pm.png?w=768&amp;h=682 768w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-06-at-3-25-21-pm.png?w=1024&amp;h=909 1024w" sizes="(max-width: 525px) 100vw, 525px" /></a></p>
<p style="text-align:left;">Upon clicking the &#8216;gaza&#8217; topic, we see the top words that comprise the topic:</p>
<p style="text-align:left;"><a href="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-06-at-3-22-07-pm.png"><img loading="lazy" data-attachment-id="839" data-permalink="https://wellecks.wordpress.com/2014/09/06/these-are-your-tweets-on-lda-part-ii/screen-shot-2014-09-06-at-3-22-07-pm/#main" data-orig-file="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-06-at-3-22-07-pm.png" data-orig-size="1618,1538" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="&#8216;gaza&#8217; topic" data-image-description="" data-image-caption="" data-medium-file="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-06-at-3-22-07-pm.png?w=300" data-large-file="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-06-at-3-22-07-pm.png?w=525" class="aligncenter size-large wp-image-839" src="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-06-at-3-22-07-pm.png?w=525&#038;h=499" alt="'gaza' topic" width="525" height="499" srcset="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-06-at-3-22-07-pm.png?w=525&amp;h=499 525w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-06-at-3-22-07-pm.png?w=1050&amp;h=998 1050w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-06-at-3-22-07-pm.png?w=150&amp;h=143 150w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-06-at-3-22-07-pm.png?w=300&amp;h=285 300w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-06-at-3-22-07-pm.png?w=768&amp;h=730 768w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-06-at-3-22-07-pm.png?w=1024&amp;h=973 1024w" sizes="(max-width: 525px) 100vw, 525px" /></a></p>
<p style="text-align:left;">I&#8217;ve also used Heroku to put an example of the finished visualization with data from 10 different twitter usernames here:</p>
<p style="text-align:center;"><a title="LDA Visualization" href="http://ldaviz.herokuapp.com/">http://ldaviz.herokuapp.com/</a></p>
<p style="text-align:left;">Have fun exploring the various topics!</p>
]]></content:encoded>
					
					<wfw:commentRss>https://wellecks.wordpress.com/2014/09/06/these-are-your-tweets-on-lda-part-ii/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		
		<media:content url="https://0.gravatar.com/avatar/f7546f57a5fd69bc99ff1640cc4a4853?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">wellecks</media:title>
		</media:content>

		<media:content url="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-06-at-2-38-24-pm.png?w=525" medium="image">
			<media:title type="html">d3 to the rescue</media:title>
		</media:content>

		<media:content url="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-06-at-3-25-21-pm.png?w=525" medium="image">
			<media:title type="html">@nytimes topics</media:title>
		</media:content>

		<media:content url="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-06-at-3-22-07-pm.png?w=525" medium="image">
			<media:title type="html">&#039;gaza&#039; topic</media:title>
		</media:content>
	</item>
		<item>
		<title>These Are Your Tweets on LDA (Part I)</title>
		<link>https://wellecks.wordpress.com/2014/09/03/these-are-your-tweets-on-lda-part-i/</link>
					<comments>https://wellecks.wordpress.com/2014/09/03/these-are-your-tweets-on-lda-part-i/#comments</comments>
		
		<dc:creator><![CDATA[wellecks]]></dc:creator>
		<pubDate>Thu, 04 Sep 2014 03:09:32 +0000</pubDate>
				<category><![CDATA[artificial intelligence]]></category>
		<category><![CDATA[machine learning]]></category>
		<category><![CDATA[Artificial intelligence]]></category>
		<category><![CDATA[Latent Dirichlet Allocation]]></category>
		<category><![CDATA[LDA]]></category>
		<category><![CDATA[Machine learning]]></category>
		<category><![CDATA[mallet]]></category>
		<category><![CDATA[topic modeling]]></category>
		<category><![CDATA[tutorial]]></category>
		<category><![CDATA[tweets]]></category>
		<category><![CDATA[twitter]]></category>
		<category><![CDATA[wordle]]></category>
		<guid isPermaLink="false">http://wellecks.wordpress.com/?p=723</guid>

					<description><![CDATA[How can we get a sense of what someone tweets about? One way would be to identify themes, or topics, that tend to occur in a user&#8217;s tweets. Perhaps we can look through the user&#8217;s profile, continually scrolling down and getting a feel for the different topics that they tweet about. But what if we could [&#8230;]]]></description>
										<content:encoded><![CDATA[<p>How can we get a sense of what someone tweets about? One way would be to identify themes, or topics, that tend to occur in a user&#8217;s tweets. Perhaps we can look through the user&#8217;s profile, continually scrolling down and getting a feel for the different topics that they tweet about.</p>
<p>But what if we could use machine learning to discover topics <em>automatically</em>, to measure<em> how much</em> each topic occurs, and even tell us the words that make up the topic?</p>
<p>In this post, we&#8217;ll do just that. We&#8217;ll retrieve users&#8217; tweets, and use an unsupervised machine learning technique called <a title="Wikipedia - Latent Dirichlet Allocation" href="http://en.wikipedia.org/wiki/Latent_Dirichlet_allocation">Latent Dirichlet Allocation</a> (LDA) to uncover topics within the tweets. Then we&#8217;ll create visualizations for the topics based on the words that define them. Our tools will be Java, <a title="Twitter4J" href="http://twitter4j.org/en/">Twitter4J</a>, and <a title="MALLET" href="http://mallet.cs.umass.edu/">Mallet</a>. All of the code is available on <a href="https://github.com/wellecks/lda_tweets">GitHub</a> for reference.</p>
<p>As a sneak preview, here&#8217;s a visualization of a topic from <a title="@gvanrossum" href="https://twitter.com/gvanrossum">@gvanrossum</a>:</p>
<p style="text-align:center;"><a href="https://wellecks.files.wordpress.com/2014/08/screen-shot-2014-08-30-at-10-04-54-pm.png"><img loading="lazy" data-attachment-id="733" data-permalink="https://wellecks.wordpress.com/2014/09/03/these-are-your-tweets-on-lda-part-i/screen-shot-2014-08-30-at-10-04-54-pm/#main" data-orig-file="https://wellecks.files.wordpress.com/2014/08/screen-shot-2014-08-30-at-10-04-54-pm.png" data-orig-size="1636,1088" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen Shot 2014-08-30 at 10.04.54 PM" data-image-description="" data-image-caption="" data-medium-file="https://wellecks.files.wordpress.com/2014/08/screen-shot-2014-08-30-at-10-04-54-pm.png?w=300" data-large-file="https://wellecks.files.wordpress.com/2014/08/screen-shot-2014-08-30-at-10-04-54-pm.png?w=525" class="alignnone size-medium wp-image-733" src="https://wellecks.files.wordpress.com/2014/08/screen-shot-2014-08-30-at-10-04-54-pm.png?w=300&#038;h=199" alt="Screen Shot 2014-08-30 at 10.04.54 PM" width="300" height="199" srcset="https://wellecks.files.wordpress.com/2014/08/screen-shot-2014-08-30-at-10-04-54-pm.png?w=300&amp;h=199 300w, https://wellecks.files.wordpress.com/2014/08/screen-shot-2014-08-30-at-10-04-54-pm.png?w=598&amp;h=398 598w, https://wellecks.files.wordpress.com/2014/08/screen-shot-2014-08-30-at-10-04-54-pm.png?w=150&amp;h=100 150w" sizes="(max-width: 300px) 100vw, 300px" /></a></p>
<p>First I&#8217;ll give an intuitive background of LDA, then explain some of the underlying math, and finally move to the code and applications.</p>
<p style="text-align:center;"><strong>What&#8217;s LDA?</strong></p>
<p style="text-align:left;">Intuitively, Latent Dirichlet Allocation provides a thematic summary of a set of documents (in our case, a set of tweets). It gives this summary by discovering &#8216;topics&#8217;, and telling us the proportion of each topic found in a document.</p>
<p style="text-align:left;">To do so, LDA attempts to model how a document was &#8216;generated&#8217; by assuming that a document is a mixture of different topics, and assuming that each word is &#8216;generated&#8217; by one of the topics.</p>
<p style="text-align:left;">As a simple example, consider the following tweets:</p>
<blockquote>
<p class="p1">(1) Fruits and vegetables are healthy.</p>
<p class="p1">(2) I like apples, oranges, and avocados. I don&#8217;t like the flu or colds.</p>
</blockquote>
<p style="text-align:left;">Let&#8217;s remove stop words, giving:</p>
<blockquote>
<p class="p1">(1) fruits vegetables healthy</p>
<p class="p1">(2) apples oranges avocados flu colds</p>
</blockquote>
<p style="text-align:left;">We&#8217;ll let <img src="https://s0.wp.com/latex.php?latex=k+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k " class="latex" /> denote the number of topics that we think these tweets are generated from. Let&#8217;s say there are <img src="https://s0.wp.com/latex.php?latex=k+%3D+2+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k+%3D+2+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k+%3D+2+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k = 2 " class="latex" /> topics. Note that there are <img src="https://s0.wp.com/latex.php?latex=V+%3D+8&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=V+%3D+8&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=V+%3D+8&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="V = 8" class="latex" /> words in our corpus. LDA would tell us that:</p>
<pre style="text-align:left;">Topic 1 = Fruits, Vegetables, Apples, Oranges, Avocados
Topic 2 = Healthy, Flu, Colds</pre>
<p style="text-align:left;">And that:</p>
<pre style="text-align:left;">Tweet 1 = (2/3) Topic 1, (1/3) Topic 2
Tweet 2 = (3/5) Topic 1, (2/5) Topic 2</pre>
<p style="text-align:left;">We can conclude that there&#8217;s a <em>food</em> topic and a <em>health </em>topic, see words that define those topics, and view the topic composition of each tweet.</p>
<p style="text-align:left;">Each topic in LDA is a probability distribution over the words. In our case, LDA would give <img src="https://s0.wp.com/latex.php?latex=k+%3D+2&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k+%3D+2&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k+%3D+2&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k = 2" class="latex" /> distributions of size <img src="https://s0.wp.com/latex.php?latex=V+%3D+8&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=V+%3D+8&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=V+%3D+8&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="V = 8" class="latex" />. Each item of the distribution corresponds to a word in the vocabulary. For instance, let&#8217;s call one of these distributions <img src="https://s0.wp.com/latex.php?latex=%5Cbeta_%7B1%7D.+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbeta_%7B1%7D.+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta_%7B1%7D.+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;beta_{1}. " class="latex" /> It might look something like:</p>
<p style="text-align:center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbeta_%7B1%7D+%3D+%5B0.4%2C+0.2%2C+0.15%2C+0.05%2C+0.05%2C+0.05%2C+0.05%5D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbeta_%7B1%7D+%3D+%5B0.4%2C+0.2%2C+0.15%2C+0.05%2C+0.05%2C+0.05%2C+0.05%5D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta_%7B1%7D+%3D+%5B0.4%2C+0.2%2C+0.15%2C+0.05%2C+0.05%2C+0.05%2C+0.05%5D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;beta_{1} = [0.4, 0.2, 0.15, 0.05, 0.05, 0.05, 0.05]" class="latex" /></p>
<p style="text-align:left;"><img src="https://s0.wp.com/latex.php?latex=%5Cbeta_%7B1%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbeta_%7B1%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta_%7B1%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;beta_{1}" class="latex" /> lets us answer questions such as: given that our topic is Topic #1 (&#8216;Food&#8217;), what is the probability of generating word #1 (&#8216;Fruits&#8217;)?</p>
<p style="text-align:left;">Now, I&#8217;ll jump into the math underlying LDA to explore specifically what LDA does and how it works. If you still need some more intuition-building, see <a href="http://blog.echen.me/2011/08/22/introduction-to-latent-dirichlet-allocation/">Edwin Chen&#8217;s great blog post</a>. Or feel free to skip to the application if you&#8217;d like, but I&#8217;d encourage you to read on!</p>
<p style="text-align:center;"><strong>A Bit More Formal</strong></p>
<p style="text-align:left;">LDA assumes that documents (assumed to be bags of words) are generated by a mixture of topics (distributions over words). We define the following variables and notation:</p>
<pre style="text-align:left;"><img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" /> is the number of topics.

<img src="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="V" class="latex" /> is the number of unique words in the vocabulary.

<img src="https://s0.wp.com/latex.php?latex=%5Ctheta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctheta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctheta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;theta " class="latex" /> is the topic distribution (of length <img src="https://s0.wp.com/latex.php?latex=k+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k " class="latex" />) for a document, drawn from a uniform Dirichlet distribution with parameter <img src="https://s0.wp.com/latex.php?latex=%5Calpha+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha " class="latex" />.

<img src="https://s0.wp.com/latex.php?latex=z_%7Bn%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=z_%7Bn%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=z_%7Bn%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="z_{n}" class="latex" /> is a topic 'assignment' for word <img src="https://s0.wp.com/latex.php?latex=w_%7Bn%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=w_%7Bn%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w_%7Bn%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="w_{n}" class="latex" />, sampled from <img src="https://s0.wp.com/latex.php?latex=p%28z_%7Bn%7D+%3D+i%7C%5Ctheta%29+%3D+%5Ctheta_%7Bi%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p%28z_%7Bn%7D+%3D+i%7C%5Ctheta%29+%3D+%5Ctheta_%7Bi%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p%28z_%7Bn%7D+%3D+i%7C%5Ctheta%29+%3D+%5Ctheta_%7Bi%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p(z_{n} = i|&#92;theta) = &#92;theta_{i}" class="latex" />.

<img src="https://s0.wp.com/latex.php?latex=%5Ctextbf%7Bw%7D+%3D+%28w_%7B1%7D%2C+...+%2C+w_%7BN%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctextbf%7Bw%7D+%3D+%28w_%7B1%7D%2C+...+%2C+w_%7BN%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctextbf%7Bw%7D+%3D+%28w_%7B1%7D%2C+...+%2C+w_%7BN%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;textbf{w} = (w_{1}, ... , w_{N})" class="latex" /> is a document with N words.

<img src="https://s0.wp.com/latex.php?latex=w_%7Bn%7D%5E%7Bi%7D+%3D+1&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=w_%7Bn%7D%5E%7Bi%7D+%3D+1&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w_%7Bn%7D%5E%7Bi%7D+%3D+1&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="w_{n}^{i} = 1" class="latex" /> means that the word <img src="https://s0.wp.com/latex.php?latex=w_%7Bn%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=w_%7Bn%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w_%7Bn%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="w_{n}" class="latex" /> is the i'th word of the vocabulary.

<img src="https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;beta " class="latex" /> is a <img src="https://s0.wp.com/latex.php?latex=k+%5Ctimes+V&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k+%5Ctimes+V&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k+%5Ctimes+V&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k &#92;times V" class="latex" /> matrix, where each row <img src="https://s0.wp.com/latex.php?latex=%5Cbeta_%7Bi%7D+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbeta_%7Bi%7D+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta_%7Bi%7D+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;beta_{i} " class="latex" /> is the multinomial distribution for the <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />th topic. That is, <img src="https://s0.wp.com/latex.php?latex=%5Cbeta_%7Bij%7D+%3D+p%28w%5E%7Bj%7D+%3D+1+%7C+z_%7Bj%7D+%3D+i%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbeta_%7Bij%7D+%3D+p%28w%5E%7Bj%7D+%3D+1+%7C+z_%7Bj%7D+%3D+i%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta_%7Bij%7D+%3D+p%28w%5E%7Bj%7D+%3D+1+%7C+z_%7Bj%7D+%3D+i%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;beta_{ij} = p(w^{j} = 1 | z_{j} = i)" class="latex" />.

</pre>
<p style="text-align:left;">LDA then posits that a document is generated according to the following process:</p>
<p style="text-align:left;">1. Fix <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=N&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=N&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=N&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="N" class="latex" />.</p>
<p style="text-align:left;">2. Sample a topic distribution <img src="https://s0.wp.com/latex.php?latex=%5Ctheta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctheta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctheta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;theta " class="latex" /> from <img src="https://s0.wp.com/latex.php?latex=Dir%28%5Calpha_%7B1%7D%2C+...+%2C+%5Calpha_%7Bk%7D%29+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=Dir%28%5Calpha_%7B1%7D%2C+...+%2C+%5Calpha_%7Bk%7D%29+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=Dir%28%5Calpha_%7B1%7D%2C+...+%2C+%5Calpha_%7Bk%7D%29+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="Dir(&#92;alpha_{1}, ... , &#92;alpha_{k}) " class="latex" />.</p>
<p style="text-align:left;padding-left:30px;"><img src="https://s0.wp.com/latex.php?latex=%5Ctheta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctheta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctheta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;theta " class="latex" /> defines the topic mixture of the document, so intuitively <img src="https://s0.wp.com/latex.php?latex=%5Ctheta_%7Bi%7D+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctheta_%7Bi%7D+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctheta_%7Bi%7D+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;theta_{i} " class="latex" /> is the degree to which <img src="https://s0.wp.com/latex.php?latex=topic_%7Bi%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=topic_%7Bi%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=topic_%7Bi%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="topic_{i}" class="latex" /> appears in the document.</p>
<p style="text-align:left;">3. For each word index <img src="https://s0.wp.com/latex.php?latex=n+%5Cin+%5Cleft%5C%7B1%2C...%2C+N%5Cright%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n+%5Cin+%5Cleft%5C%7B1%2C...%2C+N%5Cright%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n+%5Cin+%5Cleft%5C%7B1%2C...%2C+N%5Cright%5C%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n &#92;in &#92;left&#92;{1,..., N&#92;right&#92;}" class="latex" />:</p>
<p style="text-align:left;padding-left:30px;">4. Draw <img src="https://s0.wp.com/latex.php?latex=z_%7Bn%7D+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=z_%7Bn%7D+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=z_%7Bn%7D+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="z_{n} " class="latex" /> from <img src="https://s0.wp.com/latex.php?latex=%5Ctheta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctheta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctheta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;theta" class="latex" />.</p>
<p style="text-align:left;padding-left:60px;"><img src="https://s0.wp.com/latex.php?latex=z_%7Bn%7D+%3D+i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=z_%7Bn%7D+%3D+i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=z_%7Bn%7D+%3D+i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="z_{n} = i" class="latex" /> tells us that the word we are about to generate will be generated by topic <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />.</p>
<p style="text-align:left;padding-left:30px;">5. Draw a word <img src="https://s0.wp.com/latex.php?latex=w_%7Bn%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=w_%7Bn%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w_%7Bn%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="w_{n}" class="latex" /> from <img src="https://s0.wp.com/latex.php?latex=%5Cbeta_%7Bz_%7Bn%7D%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbeta_%7Bz_%7Bn%7D%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta_%7Bz_%7Bn%7D%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;beta_{z_{n}}" class="latex" />.</p>
<p style="text-align:left;padding-left:60px;">In other words, we choose the row of <img src="https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;beta " class="latex" /> based on our value of <img src="https://s0.wp.com/latex.php?latex=z_%7Bn%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=z_%7Bn%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=z_%7Bn%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="z_{n}" class="latex" /> from (4), then sample from the distribution that this row defines. Going back to our example, if we drew the &#8220;Food&#8221; row in step (4), then it&#8217;s more likely that we&#8217;ll generate &#8220;Fruits&#8221; than &#8220;Flu&#8221; in step (5).</p>
<p style="text-align:left;">We can see that this does in fact generate a document based on the topic mixture <img src="https://s0.wp.com/latex.php?latex=%5Ctheta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctheta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctheta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;theta " class="latex" />, the topic-word assignments <strong><em>z</em></strong>, and the probability matrix <img src="https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;beta " class="latex" />.</p>
<p style="text-align:left;">However, we <strong>observe</strong><strong> the document</strong>, and must <strong>infer the latent topic mixture and topic-word assignments</strong>. Hence LDA aims to infer:</p>
<p style="text-align:center;"><img src="https://s0.wp.com/latex.php?latex=p%28%5Ctheta%2C+%5Ctextbf%7Bz%7D+%7C%5Ctextbf%7Bw%7D%2C+%5Calpha%2C+%5Cbeta%29+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p%28%5Ctheta%2C+%5Ctextbf%7Bz%7D+%7C%5Ctextbf%7Bw%7D%2C+%5Calpha%2C+%5Cbeta%29+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p%28%5Ctheta%2C+%5Ctextbf%7Bz%7D+%7C%5Ctextbf%7Bw%7D%2C+%5Calpha%2C+%5Cbeta%29+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p(&#92;theta, &#92;textbf{z} |&#92;textbf{w}, &#92;alpha, &#92;beta) " class="latex" />.</p>
<p style="text-align:center;"><strong>Coupling Problems</strong></p>
<p style="text-align:left;">The story&#8217;s not over quite yet, though. We have:</p>
<p style="text-align:center;"><img src="https://s0.wp.com/latex.php?latex=p%28%5Ctheta%2C+%5Ctextbf%7Bz%7D+%7C%5Ctextbf%7Bw%7D%2C+%5Calpha%2C+%5Cbeta%29+%3D+%5Cfrac%7Bp%28%5Ctheta%2C+%5Ctextbf%7Bz%7D%2C+%5Ctextbf%7Bw%7D+%7C+%5Calpha%2C+%5Cbeta%29%7D%7Bp%28%5Ctextbf%7Bw%7D+%7C+%5Calpha%2C+%5Cbeta%29%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p%28%5Ctheta%2C+%5Ctextbf%7Bz%7D+%7C%5Ctextbf%7Bw%7D%2C+%5Calpha%2C+%5Cbeta%29+%3D+%5Cfrac%7Bp%28%5Ctheta%2C+%5Ctextbf%7Bz%7D%2C+%5Ctextbf%7Bw%7D+%7C+%5Calpha%2C+%5Cbeta%29%7D%7Bp%28%5Ctextbf%7Bw%7D+%7C+%5Calpha%2C+%5Cbeta%29%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p%28%5Ctheta%2C+%5Ctextbf%7Bz%7D+%7C%5Ctextbf%7Bw%7D%2C+%5Calpha%2C+%5Cbeta%29+%3D+%5Cfrac%7Bp%28%5Ctheta%2C+%5Ctextbf%7Bz%7D%2C+%5Ctextbf%7Bw%7D+%7C+%5Calpha%2C+%5Cbeta%29%7D%7Bp%28%5Ctextbf%7Bw%7D+%7C+%5Calpha%2C+%5Cbeta%29%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p(&#92;theta, &#92;textbf{z} |&#92;textbf{w}, &#92;alpha, &#92;beta) = &#92;frac{p(&#92;theta, &#92;textbf{z}, &#92;textbf{w} | &#92;alpha, &#92;beta)}{p(&#92;textbf{w} | &#92;alpha, &#92;beta)}" class="latex" /></p>
<p style="text-align:left;">Let&#8217;s consider the denominator. I&#8217;m going to skip the derivation here (see <a href="http://obphio.us/pdfs/lda_tutorial.pdf">pg. 5 of Reed</a> for the full story), but we have:</p>
<p style="text-align:left;"><img src="https://s0.wp.com/latex.php?latex=p%28%5Ctextbf%7Bw%7D+%7C+%5Calpha%2C+%5Cbeta%29+%3D+%5Cfrac%7B%5CGamma%28%5Csum_%7Bi%3D1%7D%5E%7Bk%7D%5Calpha_%7Bi%7D%29%7D%7B%5Cprod_%7Bi%3D1%7D%5E%7Bk%7D%5CGamma%28%5Calpha_%7Bi%7D%29%7D+%5Cint+%28%5Cprod_%7Bi%3D1%7D%5E%7Bk%7D%5Ctheta_%7Bi%7D%5E%7B%5Calpha_%7Bi%7D-1%7D%29%28%5Cprod_%7Bn%3D1%7D%5E%7BN%7D%5Csum_%7Bi%3D1%7D%5E%7Bk%7D%5Cprod_%7Bj%3D1%7D%5E%7BV%7D%28%5Ctheta_%7Bi%7D%5Cbeta_%7Bij%7D%29%5E%7Bw_%7Bn%7D%5E%7Bj%7D%7D%29%5C%2Cd%5Ctheta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p%28%5Ctextbf%7Bw%7D+%7C+%5Calpha%2C+%5Cbeta%29+%3D+%5Cfrac%7B%5CGamma%28%5Csum_%7Bi%3D1%7D%5E%7Bk%7D%5Calpha_%7Bi%7D%29%7D%7B%5Cprod_%7Bi%3D1%7D%5E%7Bk%7D%5CGamma%28%5Calpha_%7Bi%7D%29%7D+%5Cint+%28%5Cprod_%7Bi%3D1%7D%5E%7Bk%7D%5Ctheta_%7Bi%7D%5E%7B%5Calpha_%7Bi%7D-1%7D%29%28%5Cprod_%7Bn%3D1%7D%5E%7BN%7D%5Csum_%7Bi%3D1%7D%5E%7Bk%7D%5Cprod_%7Bj%3D1%7D%5E%7BV%7D%28%5Ctheta_%7Bi%7D%5Cbeta_%7Bij%7D%29%5E%7Bw_%7Bn%7D%5E%7Bj%7D%7D%29%5C%2Cd%5Ctheta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p%28%5Ctextbf%7Bw%7D+%7C+%5Calpha%2C+%5Cbeta%29+%3D+%5Cfrac%7B%5CGamma%28%5Csum_%7Bi%3D1%7D%5E%7Bk%7D%5Calpha_%7Bi%7D%29%7D%7B%5Cprod_%7Bi%3D1%7D%5E%7Bk%7D%5CGamma%28%5Calpha_%7Bi%7D%29%7D+%5Cint+%28%5Cprod_%7Bi%3D1%7D%5E%7Bk%7D%5Ctheta_%7Bi%7D%5E%7B%5Calpha_%7Bi%7D-1%7D%29%28%5Cprod_%7Bn%3D1%7D%5E%7BN%7D%5Csum_%7Bi%3D1%7D%5E%7Bk%7D%5Cprod_%7Bj%3D1%7D%5E%7BV%7D%28%5Ctheta_%7Bi%7D%5Cbeta_%7Bij%7D%29%5E%7Bw_%7Bn%7D%5E%7Bj%7D%7D%29%5C%2Cd%5Ctheta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p(&#92;textbf{w} | &#92;alpha, &#92;beta) = &#92;frac{&#92;Gamma(&#92;sum_{i=1}^{k}&#92;alpha_{i})}{&#92;prod_{i=1}^{k}&#92;Gamma(&#92;alpha_{i})} &#92;int (&#92;prod_{i=1}^{k}&#92;theta_{i}^{&#92;alpha_{i}-1})(&#92;prod_{n=1}^{N}&#92;sum_{i=1}^{k}&#92;prod_{j=1}^{V}(&#92;theta_{i}&#92;beta_{ij})^{w_{n}^{j}})&#92;,d&#92;theta" class="latex" /></p>
<p style="text-align:left;">We cannot separate the <img src="https://s0.wp.com/latex.php?latex=%5Ctheta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctheta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctheta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;theta" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%5Cbeta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbeta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;beta" class="latex" />, so computing this term is intractable; we must find another approach to infer the hidden variables.</p>
<p style="text-align:center;"><strong>A Simpler Problem</strong></p>
<p style="text-align:left;">A workaround is to find a convex distribution that lower-bounds the distribution that we want to estimate. Then we can find an optimal lower bound to estimate the distribution that is intractable to compute. We simplify the problem to:</p>
<p style="text-align:center;"><img src="https://s0.wp.com/latex.php?latex=q%28%5Ctheta%2C+%5Ctextbf%7Bz%7D%7C%5Cgamma%2C+%5Cphi%29+%3D+q%28%5Ctheta%7C%5Cgamma%29%5Cprod_%7Bn%3D1%7D%5E%7BN%7Dq%28z_%7Bn%7D%7C%5Cphi_%7Bn%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q%28%5Ctheta%2C+%5Ctextbf%7Bz%7D%7C%5Cgamma%2C+%5Cphi%29+%3D+q%28%5Ctheta%7C%5Cgamma%29%5Cprod_%7Bn%3D1%7D%5E%7BN%7Dq%28z_%7Bn%7D%7C%5Cphi_%7Bn%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q%28%5Ctheta%2C+%5Ctextbf%7Bz%7D%7C%5Cgamma%2C+%5Cphi%29+%3D+q%28%5Ctheta%7C%5Cgamma%29%5Cprod_%7Bn%3D1%7D%5E%7BN%7Dq%28z_%7Bn%7D%7C%5Cphi_%7Bn%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q(&#92;theta, &#92;textbf{z}|&#92;gamma, &#92;phi) = q(&#92;theta|&#92;gamma)&#92;prod_{n=1}^{N}q(z_{n}|&#92;phi_{n})" class="latex" /></p>
<p style="text-align:left;">And minimize the <a href="http://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence">KL-Divergence</a> between this distribution and the actual distribution <img src="https://s0.wp.com/latex.php?latex=p%28%5Ctheta%2C+%5Ctextbf%7Bz%7D+%7C%5Ctextbf%7Bw%7D%2C+%5Calpha%2C+%5Cbeta%29+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p%28%5Ctheta%2C+%5Ctextbf%7Bz%7D+%7C%5Ctextbf%7Bw%7D%2C+%5Calpha%2C+%5Cbeta%29+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p%28%5Ctheta%2C+%5Ctextbf%7Bz%7D+%7C%5Ctextbf%7Bw%7D%2C+%5Calpha%2C+%5Cbeta%29+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p(&#92;theta, &#92;textbf{z} |&#92;textbf{w}, &#92;alpha, &#92;beta) " class="latex" />, resulting in the problem:</p>
<p style="text-align:center;"><img src="https://s0.wp.com/latex.php?latex=%28%5Cgamma%5E%7B%2A%7D%2C+%5Cphi%5E%7B%2A%7D%29+%3D+argmin_%7B%5Cgamma%2C+%5Cphi%7D+D_%7BKL%7D%28q%28%5Ctheta%2C+z%7C%5Cgamma%2C+%5Cphi%29%7C%7Cp%28%5Ctheta%2C+z%7Cw%2C+%5Calpha%2C+%5Cbeta%29%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28%5Cgamma%5E%7B%2A%7D%2C+%5Cphi%5E%7B%2A%7D%29+%3D+argmin_%7B%5Cgamma%2C+%5Cphi%7D+D_%7BKL%7D%28q%28%5Ctheta%2C+z%7C%5Cgamma%2C+%5Cphi%29%7C%7Cp%28%5Ctheta%2C+z%7Cw%2C+%5Calpha%2C+%5Cbeta%29%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28%5Cgamma%5E%7B%2A%7D%2C+%5Cphi%5E%7B%2A%7D%29+%3D+argmin_%7B%5Cgamma%2C+%5Cphi%7D+D_%7BKL%7D%28q%28%5Ctheta%2C+z%7C%5Cgamma%2C+%5Cphi%29%7C%7Cp%28%5Ctheta%2C+z%7Cw%2C+%5Calpha%2C+%5Cbeta%29%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(&#92;gamma^{*}, &#92;phi^{*}) = argmin_{&#92;gamma, &#92;phi} D_{KL}(q(&#92;theta, z|&#92;gamma, &#92;phi)||p(&#92;theta, z|w, &#92;alpha, &#92;beta))" class="latex" /></p>
<p style="text-align:left;">Since we also do not know <img src="https://s0.wp.com/latex.php?latex=%5Cbeta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbeta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;beta" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha" class="latex" />, we use <a href="http://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm">Expectation Maximization</a> (EM) to alternate between estimating <img src="https://s0.wp.com/latex.php?latex=%5Cbeta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbeta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;beta" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha" class="latex" /> using our current estimates of <img src="https://s0.wp.com/latex.php?latex=%5Cgamma&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cgamma&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cgamma&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;gamma" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%5Cphi&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi" class="latex" />, and estimating <img src="https://s0.wp.com/latex.php?latex=%5Cgamma&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cgamma&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cgamma&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;gamma" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%5Cphi&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi" class="latex" /> using our current estimates of <img src="https://s0.wp.com/latex.php?latex=%5Cbeta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbeta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;beta" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha" class="latex" />.</p>
<p style="text-align:left;">More specifically, in the E-step, we solve for <img src="https://s0.wp.com/latex.php?latex=%28%5Cgamma%5E%7B%2A%7D%2C+%5Cphi%5E%7B%2A%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28%5Cgamma%5E%7B%2A%7D%2C+%5Cphi%5E%7B%2A%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28%5Cgamma%5E%7B%2A%7D%2C+%5Cphi%5E%7B%2A%7D%29&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(&#92;gamma^{*}, &#92;phi^{*})" class="latex" />, and in the M-step, we perform the updates:</p>
<p style="text-align:center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbeta_%7Bij%7D+%5Cpropto%5Csum_%7Bd%3D1%7D%5E%7BM%7D%5Csum_%7Bn%3D1%7D%5E%7BN_%7Bd%7D%7D%5Cphi%5E%7B%2A%7D_%7Bdni%7Dw%5E%7Bj%7D_%7Bdn%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbeta_%7Bij%7D+%5Cpropto%5Csum_%7Bd%3D1%7D%5E%7BM%7D%5Csum_%7Bn%3D1%7D%5E%7BN_%7Bd%7D%7D%5Cphi%5E%7B%2A%7D_%7Bdni%7Dw%5E%7Bj%7D_%7Bdn%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta_%7Bij%7D+%5Cpropto%5Csum_%7Bd%3D1%7D%5E%7BM%7D%5Csum_%7Bn%3D1%7D%5E%7BN_%7Bd%7D%7D%5Cphi%5E%7B%2A%7D_%7Bdni%7Dw%5E%7Bj%7D_%7Bdn%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;beta_{ij} &#92;propto&#92;sum_{d=1}^{M}&#92;sum_{n=1}^{N_{d}}&#92;phi^{*}_{dni}w^{j}_{dn}" class="latex" /></p>
<p style="text-align:left;">and</p>
<p style="text-align:center;"><img src="https://s0.wp.com/latex.php?latex=log%28%5Calpha%5E%7Bt%2B1%7D%29+%3D+log%28%5Calpha%5E%7Bt%7D%29+-+%5Cfrac%7B%5Cfrac%7BdL%7D%7Bd%5Calpha%7D%7D%7B%5Cfrac%7Bd%5E%7B2%7DL%7D%7Bd%5Calpha%5E%7B2%7D%5Calpha%7D%2B%5Cfrac%7BdL%7D%7Bd%5Calpha%7D%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=log%28%5Calpha%5E%7Bt%2B1%7D%29+%3D+log%28%5Calpha%5E%7Bt%7D%29+-+%5Cfrac%7B%5Cfrac%7BdL%7D%7Bd%5Calpha%7D%7D%7B%5Cfrac%7Bd%5E%7B2%7DL%7D%7Bd%5Calpha%5E%7B2%7D%5Calpha%7D%2B%5Cfrac%7BdL%7D%7Bd%5Calpha%7D%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=log%28%5Calpha%5E%7Bt%2B1%7D%29+%3D+log%28%5Calpha%5E%7Bt%7D%29+-+%5Cfrac%7B%5Cfrac%7BdL%7D%7Bd%5Calpha%7D%7D%7B%5Cfrac%7Bd%5E%7B2%7DL%7D%7Bd%5Calpha%5E%7B2%7D%5Calpha%7D%2B%5Cfrac%7BdL%7D%7Bd%5Calpha%7D%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="log(&#92;alpha^{t+1}) = log(&#92;alpha^{t}) - &#92;frac{&#92;frac{dL}{d&#92;alpha}}{&#92;frac{d^{2}L}{d&#92;alpha^{2}&#92;alpha}+&#92;frac{dL}{d&#92;alpha}}" class="latex" /></p>
<p style="text-align:left;">I&#8217;ve glossed over this part a bit, but the takeaway is that we must compute a lower bound of the actual distribution, and we use EM to do so since we have two sets of unknown parameters. And in the end, we end up with estimates of <img src="https://s0.wp.com/latex.php?latex=%5Ctheta%2C+%5Ctextbf%7Bz%7D%2C+%5Cbeta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctheta%2C+%5Ctextbf%7Bz%7D%2C+%5Cbeta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctheta%2C+%5Ctextbf%7Bz%7D%2C+%5Cbeta&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;theta, &#92;textbf{z}, &#92;beta" class="latex" /> as desired.</p>
<p style="text-align:left;">For more in depth coverage, see <a href="http://obphio.us/pdfs/lda_tutorial.pdf">Reed&#8217;s LDA Tutorial</a> or the <a href="http://jmlr.org/papers/volume3/blei03a/blei03a.pdf">original LDA paper</a>.</p>
<p style="text-align:left;">Now, let&#8217;s move to the code.</p>
<p style="text-align:center;"><strong>The Plan</strong></p>
<p style="text-align:left;">We&#8217;ll use <a href="https://twitter.com/BarackObama">@BarackObama</a> as the running example. First we&#8217;ll download @BarackObama&#8217;s tweets, which will be our corpus, with each tweet representing a &#8216;document&#8217;.</p>
<p style="text-align:left;">Then, we&#8217;ll run LDA on the corpus in order to discover 50 topics and the top 20 words associated with each topic. Next, we will infer the topic distribution over the <em>entire</em> set of tweets. Hence we&#8217;ll be able to see topics and the degree to which they appear in @BarackObama&#8217;s tweets.</p>
<p style="text-align:left;">Finally, we&#8217;ll visualize the top 20 words for a given topic based on the relative frequency of the words.</p>
<p style="text-align:left;">I&#8217;ll walk through the important parts of the code, but I&#8217;ll skip the details in the interest of brevity. For the whole picture, check out the code on <a href="https://github.com/wellecks/lda_tweets">GitHub</a>; running the <em>main() </em>method of <a href="https://github.com/wellecks/lda_tweets/blob/master/src/lda/TopicModel.java">TopicModel.java</a> will run the entire process and produce similar results to those shown below.</p>
<p style="text-align:center;"><strong>Getting the Tweets</strong></p>
<p style="text-align:left;">To retrieve the tweets, we&#8217;ll rely on the <a title="Twitter4J" href="http://twitter4j.org/en/">Twitter4J</a> library, an unofficial Java library for the Java API. The code found in <a href="https://github.com/wellecks/lda_tweets/blob/master/src/lda/TwitterClient.java">TwitterClient.java</a> is a wrapper that helps out with the things we need. The method that does the &#8216;work&#8217; is</p>
<pre class="p1"><span class="s1">public</span> List&lt;String&gt; getUserTweetsText(String <span class="s2">username</span>, <span class="s1">int</span> <span class="s2">n</span>)</pre>
<p class="p1">which retrieves the last <em>n</em> of a user&#8217;s tweets and returns them as a List of Strings. In this method we access 1 page (200 tweets) at a time, so the main loop has <em>n/200</em> iterations.</p>
<p class="p1"><span class="s1">The highest-level method is</span></p>
<pre class="p1"><span class="s1">public</span> <span class="s1">void</span> downloadTweetsFromUser(String <span class="s2">username</span>, <span class="s1">int</span> <span class="s2">numTweets</span>)</pre>
<p class="p1">which calls <em>getUserTweetsText()</em> and saves the output to files. For organization&#8217;s sake, it saves the user&#8217;s tweets to</p>
<ul>
<li class="p1"><em>./data/{username}/{username}_tweets.txt</em>, which contains one tweet per line</li>
<li class="p1"><em>./data/{username}/{username}_tweets_single.txt</em>, which contains all of the tweets on a single line. This second file will be used later to infer the topic distribution over the user&#8217;s <em>entire</em> set of tweets.</li>
</ul>
<p class="p1">Hence we can download 3000 of @BarackObama&#8217;s tweets like so:</p>
<pre class="p1">TwitterClient <span class="s1">tc</span> = <span class="s2">new</span> TwitterClient();
<span class="s1">tc</span>.downloadTweetsFromUser(<span class="s3">"BarackObama"</span>, 3000);</pre>
<p class="p1" style="text-align:center;"><strong>Hammering Out Some Topics</strong></p>
<p class="p1">Now it&#8217;s time to take a <a title="MALLET" href="http://mallet.cs.umass.edu/">Mallet</a> to the tweets in order to mine some topics. Mallet is a powerful library for text-based machine learning; we can use its topic modeling through its <a href="http://mallet.cs.umass.edu/api/">Java API</a> to load and clean the tweet data, train an LDA model, and output results. In order to use the Mallet API, you&#8217;ll have to follow the <a href="http://mallet.cs.umass.edu/download.php">download instructions</a> and build a jar file, or get it from this post&#8217;s <a href="https://github.com/wellecks/lda_tweets">GitHub</a> repo.</p>
<p class="p1">The Mallet-related code that I&#8217;ll discuss next is found in <a href="https://github.com/wellecks/lda_tweets/blob/master/src/lda/TopicModel.java">TopicModel.java</a>.</p>
<p class="p1" style="text-align:center;"><strong>Loading the Data</strong></p>
<p class="p1">The first step is to prepare and load the data. Our goal is to get the data in the <em>{username}_tweets.txt</em> file into an <a href="http://mallet.cs.umass.edu/api/cc/mallet/types/InstanceList.html"><em>InstanceList</em></a> object, i.e. a form that can be used by Mallet models.</p>
<p class="p1">To do so, we first create a series of &#8220;<em><a href="http://mallet.cs.umass.edu/api/cc/mallet/pipe/Pipe.html">Pipe</a></em>s&#8221; to feed the data through. The idea is that each <em><a href="http://mallet.cs.umass.edu/api/cc/mallet/pipe/Pipe.html">Pipe</a></em> performs some transformation of the data and feeds it to the next <em>Pipe</em>. In our case, in</p>
<pre class="p1"><span class="s1">static</span> ArrayList&lt;Pipe&gt; makePipeList()</pre>
<p class="p1">we create a series of <em>Pipe</em>s that will lowercase and tokenize the tweets, remove stop words, and convert the tweets to a sequence of features.</p>
<p class="p1">Then, in</p>
<pre class="p1"><span class="s1">static</span> InstanceList fileToInstanceList(String <span class="s2">filename</span>)</pre>
<p class="p1">we iterate through the input file, and use our <em>Pipe</em> list to modify and prepare the data, returning the <em>InstanceList</em> that we set out to build.</p>
<p class="p1" style="text-align:center;"> <strong>Training Time</strong></p>
<p class="p1">It&#8217;s training time. Using</p>
<pre class="p1"><span class="s1">public</span> <span class="s1">static</span> ParallelTopicModel trainModel(InstanceList <span class="s2">instances</span>,
<span class="s1">                                      int</span> <span class="s2">numTopics</span>, <span class="s1">int</span> <span class="s2">numIters</span>,
<span class="s1">                                      double</span> <span class="s2">alphaT</span>, <span class="s1">double</span> <span class="s2">betaW</span>)</pre>
<p style="text-align:left;">we train an LDA model called <em>ParallelTopicModel</em> on the <em>InstanceList</em> data. The <em>betaW</em> parameter is a uniform prior for <img src="https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;beta " class="latex" />, and the <em>alphaT</em> parameter is the sum of the <img src="https://s0.wp.com/latex.php?latex=%5Calpha+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha " class="latex" /> parameter; recall from the math section that <img src="https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;beta " class="latex" /> is the <img src="https://s0.wp.com/latex.php?latex=numtopics+%5Ctimes+vocabsize+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=numtopics+%5Ctimes+vocabsize+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=numtopics+%5Ctimes+vocabsize+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="numtopics &#92;times vocabsize " class="latex" /> matrix that gives word probabilities given a topic, and <img src="https://s0.wp.com/latex.php?latex=%5Calpha+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha " class="latex" /> is the parameter for the distribution over topics.</p>
<p style="text-align:center;"><strong>Looking at the Output, Part I</strong></p>
<p style="text-align:left;">With a trained model, we can now look at the words that make up the topics using <img src="https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;beta " class="latex" />, and the composition <img src="https://s0.wp.com/latex.php?latex=%5Ctheta_i+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctheta_i+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctheta_i+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;theta_i " class="latex" /> for <img src="https://s0.wp.com/latex.php?latex=tweet_i+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=tweet_i+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=tweet_i+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="tweet_i " class="latex" />.</p>
<p style="text-align:left;">Printed to stdout, we see the 50 topics, with the top 20 words for each topic. The number attached to each word is the number of occurrences:</p>
<pre class="p1"><strong>Topic 0</strong> 
families:13 republican:11 read:7 fast:5 ed:5 op:5 family:5 marine:4 democrat:4 efforts:4 policies:4 story:4 pendleton:3 camp:3 explains:3 military:3 #cir:3 california:3 #familiessucceed:3 workplace:3</pre>
<pre class="p1"><strong>Topic 1</strong> 
president:175 obama:165 middle:61 class:59 jobs:47 #abetterbargain:37 economy:37 good:32 growing:20 #opportunityforall:20 isn:19 #rebuildamerica:18 today:18 create:17 watch:17 infrastructure:16 americans:16 plan:15 live:15 american:15</pre>
<p class="p1">&#8230;</p>
<pre class="p1"><strong>Topic 48</strong> 
president:72 address:62 obama:57 watch:56 weekly:49 opportunity:15 economic:15 discusses:14 issue:11 importance:10 working:10 week:10 speak:9 budget:8 discuss:8 congress:7 calls:6 building:6 #opportunityforall:6 lady:5</pre>
<pre class="p1"><strong>Topic 49</strong> 
discrimination:19 lgbt:17 rights:15 #enda:15 americans:14 law:10 act:10 today:10 thedreamisnow:7 screening:7 voting:7 protections:7 basic:7 stand:7 add:7 american:7 anniversary:6 workplace:6 workers:6 support:6</pre>
<p style="text-align:left;">Each box corresponds to taking a row of <img src="https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;beta " class="latex" />, finding the indices with the 20 highest probabilities, and choosing the words that correspond to these indices.</p>
<p style="text-align:left;">Since each tweet is a document, the model also contains the topic distribution for each tweet. However, our goal is to get a sense of the <em>overall topic </em><em>distribution</em> for <em>all</em> of the user&#8217;s tweets, which will require an additional step. In other words, we&#8217;d like to see a summary of the major topics that the user tends to tweet about.</p>
<p style="text-align:center;"><strong>Getting An Overall Picture</strong></p>
<p style="text-align:left;">To do so, we will use our trained model to <em>infer</em> the distribution over <em>all</em> of the user&#8217;s tweets. We create a single <a href="http://mallet.cs.umass.edu/api/cc/mallet/types/Instance.html">Instance</a> containing all of the tweets using</p>
<pre style="text-align:left;"><em>singleLineFile = {username}_tweets_single.txt</em></pre>
<p style="text-align:left;">and find the topic distribution:</p>
<pre class="p1"><span class="s1">double</span>[] <span class="s2">dist</span> = inferTopicDistribution(<span class="s2">model</span>, 
                    TopicModel.fileToInstanceList(<span class="s2">singleLineFile</span>));</pre>
<p style="text-align:left;">We can then look at the distribution in  ./data/{username}/<em>{username}_composition.txt:</em></p>
<pre class="p1"><strong>0</strong> 0.006840685214902167
<strong>1</strong> 0.048881207831654686
...
<strong>29</strong> 0.09993216645340489
...
<strong>48</strong> 0.022192334924649955
<strong>49</strong> 0.01473112438501846</pre>
<p class="p1">We see, for instance, that topic 29 is more prominent than topic 0; specifically, the model inferred that more words were generated by topic 29 than topic 0.</p>
<p class="p1">In <em>./data/{username}/{username}_ranked.txt</em> we have the top 10 topics, ranked by composition, along with each topic&#8217;s top words. For instance, at the top of the file is:</p>
<pre class="p1" style="text-align:center;"><strong>Topic 29</strong>:
obama:474
president:474
america:77
...
action:23
making:21
job:21</pre>
<p class="p1" style="text-align:left;">This topic could probably be labeled as &#8220;presidential&#8221;; a topic we&#8217;d expect to find near the top for @BarackObama.</p>
<p class="p1" style="text-align:left;">Looking on, we see a topic that is clearly about healthcare:</p>
<pre class="p1" style="text-align:center;"><strong>Topic 24
</strong>health:103
insurance:94
americans:56
#obamacare:55
...
uninsured:21
covered:21</pre>
<p class="p1" style="text-align:left;">and one about climate change:</p>
<pre class="p1" style="text-align:center;"><strong>Topic 28
</strong>change:125
climate:90
#actonclimate:59
#climate:39
...
time:19
#sciencesaysso:14
act:14
call:13
science:13</pre>
<p style="text-align:left;">The inferred topics are pretty amazing; a job well done by LDA. But while viewing words and their frequencies may be fun, let&#8217;s visualize a topic in a nicer way.</p>
<p style="text-align:center;"><strong>Into the Clouds</strong></p>
<p style="text-align:left;">We now have the words that make up the most prominent topics, along with the frequency of each word. A natural visualization for a topic is a <a href="http://en.wikipedia.org/wiki/Tag_cloud">word cloud</a>, which allows us to easily see the words and their relative weights.</p>
<p style="text-align:left;">It turns out that a word-cloud generator named Wordle <a title="Wordle Advanced" href="http://www.wordle.net/advanced">can create word clouds given a list of weighted words</a>&#8230;exactly the format found in ./data/{username}/{username}_ranked.txt !</p>
<p style="text-align:left;">Let&#8217;s copy the <em>word:frequency</em> list for Topic 29 and throw it into Wordle (dialing down <em>obama</em> and <em>president</em> to 200):</p>
<p style="text-align:center;"><a href="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-48-pm.png"><img loading="lazy" data-attachment-id="820" data-permalink="https://wellecks.wordpress.com/2014/09/03/these-are-your-tweets-on-lda-part-i/screen-shot-2014-09-03-at-8-48-48-pm/#main" data-orig-file="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-48-pm.png" data-orig-size="1250,686" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="" data-image-description="" data-image-caption="" data-medium-file="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-48-pm.png?w=300" data-large-file="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-48-pm.png?w=525" class="aligncenter size-large wp-image-820" src="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-48-pm.png?w=525&#038;h=288" alt="" width="525" height="288" srcset="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-48-pm.png?w=525&amp;h=288 525w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-48-pm.png?w=1050&amp;h=576 1050w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-48-pm.png?w=150&amp;h=82 150w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-48-pm.png?w=300&amp;h=165 300w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-48-pm.png?w=768&amp;h=421 768w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-48-pm.png?w=1024&amp;h=562 1024w" sizes="(max-width: 525px) 100vw, 525px" /></a></p>
<p style="text-align:left;">and the results:</p>
<div data-shortcode="caption" id="attachment_817" style="width: 535px" class="wp-caption alignleft"><a href="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-46-24-pm.png"><img loading="lazy" aria-describedby="caption-attachment-817" data-attachment-id="817" data-permalink="https://wellecks.wordpress.com/2014/09/03/these-are-your-tweets-on-lda-part-i/screen-shot-2014-09-03-at-8-46-24-pm/#main" data-orig-file="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-46-24-pm.png" data-orig-size="1628,1086" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="" data-image-description="" data-image-caption="" data-medium-file="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-46-24-pm.png?w=300" data-large-file="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-46-24-pm.png?w=525" class="wp-image-817 size-large" src="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-46-24-pm.png?w=525&#038;h=350" alt="" width="525" height="350" srcset="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-46-24-pm.png?w=525&amp;h=350 525w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-46-24-pm.png?w=1050&amp;h=700 1050w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-46-24-pm.png?w=150&amp;h=100 150w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-46-24-pm.png?w=300&amp;h=200 300w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-46-24-pm.png?w=768&amp;h=512 768w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-46-24-pm.png?w=1024&amp;h=683 1024w" sizes="(max-width: 525px) 100vw, 525px" /></a><p id="caption-attachment-817" class="wp-caption-text">Topic 29 &#8211; &#8220;Presidential&#8221;</p></div>
<div data-shortcode="caption" id="attachment_818" style="width: 535px" class="wp-caption aligncenter"><a href="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-14-pm.png"><img loading="lazy" aria-describedby="caption-attachment-818" data-attachment-id="818" data-permalink="https://wellecks.wordpress.com/2014/09/03/these-are-your-tweets-on-lda-part-i/screen-shot-2014-09-03-at-8-47-20-pm/#main" data-orig-file="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-47-20-pm.png" data-orig-size="1604,1078" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="" data-image-description="" data-image-caption="" data-medium-file="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-47-20-pm.png?w=300" data-large-file="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-47-20-pm.png?w=525" class="wp-image-818 size-large" src="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-47-20-pm.png?w=525&#038;h=352" alt="" width="525" height="352" srcset="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-47-20-pm.png?w=525&amp;h=352 525w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-47-20-pm.png?w=1048&amp;h=704 1048w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-47-20-pm.png?w=150&amp;h=101 150w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-47-20-pm.png?w=300&amp;h=202 300w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-47-20-pm.png?w=768&amp;h=516 768w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-47-20-pm.png?w=1024&amp;h=688 1024w" sizes="(max-width: 525px) 100vw, 525px" /></a><p id="caption-attachment-818" class="wp-caption-text">Topic 24 &#8211; &#8220;Healthcare&#8221;</p></div>
<div data-shortcode="caption" id="attachment_819" style="width: 535px" class="wp-caption aligncenter"><a href="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-14-pm.png"><img loading="lazy" aria-describedby="caption-attachment-819" data-attachment-id="819" data-permalink="https://wellecks.wordpress.com/2014/09/03/these-are-your-tweets-on-lda-part-i/screen-shot-2014-09-03-at-8-48-14-pm/#main" data-orig-file="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-14-pm.png" data-orig-size="1534,1084" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="" data-image-description="" data-image-caption="" data-medium-file="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-14-pm.png?w=300" data-large-file="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-14-pm.png?w=525" class="wp-image-819 size-large" src="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-14-pm.png?w=525&#038;h=370" alt="" width="525" height="370" srcset="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-14-pm.png?w=525&amp;h=370 525w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-14-pm.png?w=1047&amp;h=740 1047w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-14-pm.png?w=150&amp;h=106 150w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-14-pm.png?w=300&amp;h=212 300w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-14-pm.png?w=768&amp;h=543 768w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-14-pm.png?w=1024&amp;h=724 1024w" sizes="(max-width: 525px) 100vw, 525px" /></a><p id="caption-attachment-819" class="wp-caption-text">Topic 28 &#8211; &#8220;Climate Change&#8221;</p></div>
<p style="text-align:center;"><strong>A Brief Pause</strong></p>
<p style="text-align:left;">Let&#8217;s pause for a second. This is a nice moment and a beautiful result.</p>
<p style="text-align:left;">Take a look at the words : LDA inferred a relationship between &#8220;country&#8221;, &#8220;america&#8221;, and &#8220;obama&#8221;. It grouped &#8220;insurance&#8221;, &#8220;#obamacare&#8221;, and &#8220;health&#8221;. It discovered a link between &#8220;climate&#8221;, &#8220;deniers&#8221;, and &#8220;#sciencesaysso&#8221;.</p>
<p style="text-align:left;">Glance back up at the math section. We never told it about presidents, countries, or healthcare. Nowhere in there is there a hard-coded link between climate words and science hash tags. In fact, it didn&#8217;t even know it would be dealing with words or tweets.</p>
<p style="text-align:left;">It&#8217;s &#8216;just&#8217; an optimization problem, but when applied it can discover complex relationships that have real meaning. This is an aspect that I personally find fascinating about LDA and, more generally, about machine learning.</p>
<p style="text-align:left;">As a next step, feel free to download the code and try out other usernames to get a sense of LDA&#8217;s generality; its not just limited to @BarackObama, climate, or healthcare.</p>
<p style="text-align:center;"><b>Next Steps: From One to Many<br />
</b></p>
<p style="text-align:left;">Currently, we have a nice way of viewing the content of one topic, in isolation. In the next post, we&#8217;ll develop a visualization using <a title="d3.js" href="http://d3js.org/">d3.js</a> for <em>all</em> of the top topics at once. We&#8217;ll be able to see and compare topics side by side, and obtain a higher level view of the overall topic distribution. As a sneak preview, here&#8217;s a visualization of the top 10 topics from <a title="@nytimes" href="https://twitter.com/nytimes">@nytimes</a>:</p>
<p><a href="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-7-34-09-pm1.png"><img loading="lazy" data-attachment-id="824" data-permalink="https://wellecks.wordpress.com/2014/09/03/these-are-your-tweets-on-lda-part-i/screen-shot-2014-09-03-at-7-34-09-pm-2/#main" data-orig-file="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-7-34-09-pm1.png" data-orig-size="1862,1544" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="@nytimes top 10" data-image-description="" data-image-caption="" data-medium-file="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-7-34-09-pm1.png?w=300" data-large-file="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-7-34-09-pm1.png?w=525" class="aligncenter size-large wp-image-824" src="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-7-34-09-pm1.png?w=525&#038;h=435" alt="@nytimes top 10" width="525" height="435" srcset="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-7-34-09-pm1.png?w=525&amp;h=435 525w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-7-34-09-pm1.png?w=1050&amp;h=870 1050w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-7-34-09-pm1.png?w=150&amp;h=124 150w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-7-34-09-pm1.png?w=300&amp;h=249 300w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-7-34-09-pm1.png?w=768&amp;h=637 768w, https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-7-34-09-pm1.png?w=1024&amp;h=849 1024w" sizes="(max-width: 525px) 100vw, 525px" /></a></p>
<p style="text-align:center;"><strong>Credits and Links</strong></p>
<p style="text-align:left;">Much of the mathematical content is derived from <a href="http://obphio.us/pdfs/lda_tutorial.pdf">Reed&#8217;s Tutorial</a> and the<a href="http://machinelearning.wustl.edu/mlpapers/paper_files/BleiNJ03.pdf"> LDA Paper</a> (or the <a href="http://ai.stanford.edu/~ang/papers/nips01-lda.pdf">shorter version</a>). These are also great resources for learning more. Edwin Chen&#8217;s <a href="http://blog.echen.me/2011/08/22/introduction-to-latent-dirichlet-allocation/">blog post</a> also provides a good introduction and an intuition-building example. The Mallet <a href="http://mallet.cs.umass.edu/topics-devel.php">developer&#8217;s guide</a> and data <a href="http://mallet.cs.umass.edu/import.php">importing guide</a> provide good examples of using the Mallet API. The Programming Historian has a <a href="http://programminghistorian.org/lessons/topic-modeling-and-mallet">great intro</a> to using Mallet for LDA from the command line.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://wellecks.wordpress.com/2014/09/03/these-are-your-tweets-on-lda-part-i/feed/</wfw:commentRss>
			<slash:comments>1</slash:comments>
		
		
		
		<media:content url="https://0.gravatar.com/avatar/f7546f57a5fd69bc99ff1640cc4a4853?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">wellecks</media:title>
		</media:content>

		<media:content url="https://wellecks.files.wordpress.com/2014/08/screen-shot-2014-08-30-at-10-04-54-pm.png?w=300" medium="image">
			<media:title type="html">Screen Shot 2014-08-30 at 10.04.54 PM</media:title>
		</media:content>

		<media:content url="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-48-pm.png?w=525" medium="image" />

		<media:content url="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-46-24-pm.png?w=525" medium="image" />

		<media:content url="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-47-20-pm.png?w=525" medium="image" />

		<media:content url="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-8-48-14-pm.png?w=525" medium="image" />

		<media:content url="https://wellecks.files.wordpress.com/2014/09/screen-shot-2014-09-03-at-7-34-09-pm1.png?w=525" medium="image">
			<media:title type="html">@nytimes top 10</media:title>
		</media:content>
	</item>
		<item>
		<title>Portfolio Optimization with Python</title>
		<link>https://wellecks.wordpress.com/2014/03/23/portfolio-optimization-with-python/</link>
					<comments>https://wellecks.wordpress.com/2014/03/23/portfolio-optimization-with-python/#comments</comments>
		
		<dc:creator><![CDATA[wellecks]]></dc:creator>
		<pubDate>Sun, 23 Mar 2014 05:38:51 +0000</pubDate>
				<category><![CDATA[artificial intelligence]]></category>
		<category><![CDATA[Artificial intelligence]]></category>
		<category><![CDATA[convex optimization]]></category>
		<category><![CDATA[finance]]></category>
		<category><![CDATA[optimization]]></category>
		<category><![CDATA[python]]></category>
		<category><![CDATA[stocks]]></category>
		<guid isPermaLink="false">http://wellecks.wordpress.com/?p=604</guid>

					<description><![CDATA[There are a lot of interesting applications of convex optimization; in this post I&#8217;ll explore an application of convex optimization in finance. I&#8217;ll walk through using convex optimization to allocate a stock portfolio so that it maximizes return for a given risk level. We&#8217;ll use real data for a mock portfolio, and solve the problem [&#8230;]]]></description>
										<content:encoded><![CDATA[<p><span style="line-height:1.6;">There are a lot of interesting applications of </span><a style="line-height:1.6;" href="http://en.wikipedia.org/wiki/Convex_optimization">convex optimization</a><span style="line-height:1.6;">; in this post I&#8217;ll explore an application of convex optimization in finance. I&#8217;ll walk through using convex optimization to allocate a stock portfolio so that it maximizes return for a given risk level. We&#8217;ll use real data for a mock portfolio, and solve the problem using Python. All of the code can be found on </span><a style="line-height:1.6;" title="GitHub - Portfolio Optimization" href="https://github.com/wellecks/port_opt">GitHub</a><span style="line-height:1.6;"> </span><span style="line-height:1.6;">&#8211;</span><span style="line-height:1.6;"> the code shown here is from </span><a href="https://github.com/wellecks/port_opt/blob/master/portfolio_opt.py"><strong style="line-height:1.6;">portfolio_opt.py</strong></a><span style="line-height:1.6;"> and uses code in </span><a href="https://github.com/wellecks/port_opt/blob/master/stocks.py"><strong style="line-height:1.6;">stocks.py</strong></a><span style="line-height:1.6;">, which pulls stock data</span><span style="line-height:1.6;"> from Yahoo Finance.</span></p>
<h3>Motivation</h3>
<p>Let&#8217;s say you want to invest some money in the stock market. You choose a set of stocks and have a sum of money to invest. How should you distribute the money into the different stocks? There is a general tradeoff between risk and return; with higher potential return we often face higher risk. If we have a goal return in mind, then we should choose the portfolio allocation that minimizes the risk for that return. How can we do this?</p>
<p>Borrowing ideas from <a title="Wikipedia" href="http://en.wikipedia.org/wiki/Modern_portfolio_theory">modern portfolio theory</a>, we can view the return of each stock as a random variable, and estimate the variable&#8217;s parameters &#8211; namely the mean return and covariance &#8211; with past data. Then we solve an optimization problem to find the combination of stocks that maximizes expected return for a given risk level.</p>
<p>We&#8217;ll choose <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> different assets, viewing the portfolio as a vector <img src="https://s0.wp.com/latex.php?latex=x+%5Cin+R%5E%7Bn%7D.+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x+%5Cin+R%5E%7Bn%7D.+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x+%5Cin+R%5E%7Bn%7D.+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x &#92;in R^{n}. " class="latex" /> Each <img src="https://s0.wp.com/latex.php?latex=x_%7Bi%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x_%7Bi%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x_%7Bi%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x_{i}" class="latex" /> will represent the percentage of our budget invested in asset <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />. As a running example, we&#8217;ll have <img src="https://s0.wp.com/latex.php?latex=n%3D10&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%3D10&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%3D10&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n=10" class="latex" /> different stocks, identified by their ticker symbols:</p>
<pre>symbols = ['GOOG', 'AIMC', 'GS', 'BH', 'TM', 
           'F', 'HLS', 'DIS', 'LUV', 'MSFT']</pre>
<p>So for instance, <img src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%3D0.14&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x_%7B1%7D%3D0.14&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x_%7B1%7D%3D0.14&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x_{1}=0.14" class="latex" /> would mean that we invested 14% of our budget in Google. A naive allocation could be investing equal amounts (10%) into each stock, so that <img src="https://s0.wp.com/latex.php?latex=x%3D%5B0.10%2C0.10%2C0.10%2C0.10%2C0.10%2C0.10%2C0.10%2C0.10%2C0.10%2C0.10%5D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%3D%5B0.10%2C0.10%2C0.10%2C0.10%2C0.10%2C0.10%2C0.10%2C0.10%2C0.10%2C0.10%5D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%3D%5B0.10%2C0.10%2C0.10%2C0.10%2C0.10%2C0.10%2C0.10%2C0.10%2C0.10%2C0.10%5D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x=[0.10,0.10,0.10,0.10,0.10,0.10,0.10,0.10,0.10,0.10]" class="latex" />. Our goal is to do better, and choose the best possible <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" />.</p>
<h3>Looking to the Past</h3>
<p>First we need an estimate of the expected returns and covariance for the portfolio, which will be used in our optimization. A simple way of estimating a stock&#8217;s expected return is to look to its past performance; we&#8217;ll use average yearly return from the past four years. Four is somewhat arbitrary, but the emphasis here is illustrating the optimization approach rather than the estimation of a stock&#8217;s return. The average historical return will be an <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> dimensional vector <img src="https://s0.wp.com/latex.php?latex=r_%7Bavg%7D+%5Cin+R%5E%7Bn%7D+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=r_%7Bavg%7D+%5Cin+R%5E%7Bn%7D+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=r_%7Bavg%7D+%5Cin+R%5E%7Bn%7D+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="r_{avg} &#92;in R^{n} " class="latex" />, where <img src="https://s0.wp.com/latex.php?latex=r_%7Bavg_%7Bi%7D%7D+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=r_%7Bavg_%7Bi%7D%7D+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=r_%7Bavg_%7Bi%7D%7D+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="r_{avg_{i}} " class="latex" /> is the average return of asset <em>i</em><span style="line-height:1.6;">. </span></p>
<p>Using <code>avg_return()</code> from <a title="Github - stocks.py" href="https://github.com/wellecks/port_opt/blob/master/stocks.py"><strong>stocks.py</strong></a>, we have:</p>
<pre id="LC46">start = '1/1/2010'
end = '1/1/2014'

# average yearly return for each stock
r_avg = map(lambda s: stocks.avg_return(s, start, end, 'y'), symbols)</pre>
<p><span style="line-height:1.6;">Similarly, we can find the portfolio&#8217;s </span><span style="line-height:1.6;">covariance using past data; the covariance of asset returns is <img src="https://s0.wp.com/latex.php?latex=%5CSigma+%5Cin+R%5E%7Bn+%5Ctimes+n%7D+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5CSigma+%5Cin+R%5E%7Bn+%5Ctimes+n%7D+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5CSigma+%5Cin+R%5E%7Bn+%5Ctimes+n%7D+&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;Sigma &#92;in R^{n &#92;times n} " class="latex" />. Using <code>cov_matrix()</code> from <strong><a title="Github - stocks.py" href="https://github.com/wellecks/port_opt/blob/master/stocks.py">stocks.py</a></strong>:<br />
</span></p>
<pre># covariance of asset returns
sigma = numpy.array(stocks.cov_matrix(symbols, start, end, 'y'))</pre>
<p><span style="line-height:1.6;">The last parameter is our goal return threshold, <img src="https://s0.wp.com/latex.php?latex=r_%7Bmin%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=r_%7Bmin%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=r_%7Bmin%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="r_{min}" class="latex" />:</span></p>
<pre># minimum expected return threshold
r_min = 0.10</pre>
<p><span style="line-height:1.6;">With these quantities in mind, we can now formulate a convex optimization problem to find the optimal portfolio allocation; that is, the portfolio that achieves the lowest amount of risk while meeting our return goal <img src="https://s0.wp.com/latex.php?latex=r_%7Bmin%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=r_%7Bmin%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=r_%7Bmin%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="r_{min}" class="latex" />.</span></p>
<h3>The problem</h3>
<p>We can use the quantity <img src="https://s0.wp.com/latex.php?latex=x%5E%7BT%7D+%5CSigma+x&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%5E%7BT%7D+%5CSigma+x&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%5E%7BT%7D+%5CSigma+x&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x^{T} &#92;Sigma x" class="latex" /> as a measure of risk for a given portfolio allocation <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> with covariance <img src="https://s0.wp.com/latex.php?latex=%5CSigma&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5CSigma&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5CSigma&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;Sigma" class="latex" />. Our objective is to minimize <img src="https://s0.wp.com/latex.php?latex=x%5E%7BT%7D+%5CSigma+x&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%5E%7BT%7D+%5CSigma+x&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%5E%7BT%7D+%5CSigma+x&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x^{T} &#92;Sigma x" class="latex" />. This<span style="line-height:1.6;"> objective function is a convex function, meaning that we&#8217;re able to formulate a convex optimization problem, specifically a quadratic program (QP), to find its minimum. To start out, we have the problem:</span></p>
<p style="text-align:left;padding-left:150px;"><strong>minimize <img src="https://s0.wp.com/latex.php?latex=x%5E%7BT%7D+%5CSigma+x&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%5E%7BT%7D+%5CSigma+x&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%5E%7BT%7D+%5CSigma+x&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x^{T} &#92;Sigma x" class="latex" /></strong><code><br />
</code></p>
<p>We can build in our goal return as a constraint <img src="https://s0.wp.com/latex.php?latex=r_%7Bavg%7D%5E%7BT%7Dx+%5Cgeq+r_%7Bmin%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=r_%7Bavg%7D%5E%7BT%7Dx+%5Cgeq+r_%7Bmin%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=r_%7Bavg%7D%5E%7BT%7Dx+%5Cgeq+r_%7Bmin%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="r_{avg}^{T}x &#92;geq r_{min}" class="latex" />. Since we want each <img src="https://s0.wp.com/latex.php?latex=x_%7Bi%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x_%7Bi%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x_%7Bi%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x_{i}" class="latex" /> to be a percentage (of the budget), we can also add the constraints <img src="https://s0.wp.com/latex.php?latex=%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+x_%7Bi%7D%3D1&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+x_%7Bi%7D%3D1&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+x_%7Bi%7D%3D1&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;sum_{i=1}^{n} x_{i}=1" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=x+%5Cgeq+0&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x+%5Cgeq+0&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x+%5Cgeq+0&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x &#92;geq 0" class="latex" />. These are simple linear constraints, maintaining convexity of the new problem:</p>
<p style="text-align:left;padding-left:150px;"><strong>minimize   <img src="https://s0.wp.com/latex.php?latex=x%5E%7BT%7D+%5CSigma+x&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%5E%7BT%7D+%5CSigma+x&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%5E%7BT%7D+%5CSigma+x&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x^{T} &#92;Sigma x" class="latex" /></strong></p>
<p style="text-align:left;padding-left:150px;"><strong>subject to  <img src="https://s0.wp.com/latex.php?latex=r_%7Bavg%7D%5E%7BT%7Dx+%5Cgeq+r_%7Bmin%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=r_%7Bavg%7D%5E%7BT%7Dx+%5Cgeq+r_%7Bmin%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=r_%7Bavg%7D%5E%7BT%7Dx+%5Cgeq+r_%7Bmin%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="r_{avg}^{T}x &#92;geq r_{min}" class="latex" /></strong></p>
<p style="text-align:left;padding-left:210px;"><strong>     <img src="https://s0.wp.com/latex.php?latex=%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+x_%7Bi%7D+%3D+1&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+x_%7Bi%7D+%3D+1&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+x_%7Bi%7D+%3D+1&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;sum_{i=1}^{n} x_{i} = 1" class="latex" /></strong></p>
<p style="text-align:left;padding-left:210px;"><strong>     <img src="https://s0.wp.com/latex.php?latex=x+%5Cgeq+0&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x+%5Cgeq+0&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x+%5Cgeq+0&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x &#92;geq 0" class="latex" /></strong></p>
<h3>Solving with Python</h3>
<p>Now it&#8217;s time to translate the math into code. In order to setup and solve the problem in Python, we&#8217;ll use the <a title="CVXOPT" href="http://cvxopt.org/">CVXOPT library</a>. CVXOPT allows us to solve a convex optimization problem as long as we can put it into the proper form. First, we convert the covariance and average return arrays into CVXOPT matrices:</p>
<pre>r_avg = matrix(r_avg)
sigma = matrix(sigma)
# that was easy</pre>
<p>Since the portfolio allocation problem is a quadratic program, we need to put our problem <a href="http://abel.ee.ucla.edu/cvxopt/userguide/coneprog.html#quadratic-programming">into the form</a>:</p>
<p style="padding-left:150px;"><strong>minimize   <img src="https://s0.wp.com/latex.php?latex=x%5E%7BT%7D+P+x+%2B+q%5E%7BT%7Dx&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%5E%7BT%7D+P+x+%2B+q%5E%7BT%7Dx&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%5E%7BT%7D+P+x+%2B+q%5E%7BT%7Dx&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x^{T} P x + q^{T}x" class="latex" /></strong></p>
<p style="padding-left:150px;"><strong>subject to  <img src="https://s0.wp.com/latex.php?latex=Gx+%5Cleq+h&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=Gx+%5Cleq+h&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=Gx+%5Cleq+h&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="Gx &#92;leq h" class="latex" /></strong></p>
<p style="padding-left:210px;"><strong>     <img src="https://s0.wp.com/latex.php?latex=Ax+%3D+b&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=Ax+%3D+b&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=Ax+%3D+b&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="Ax = b" class="latex" /></strong></p>
<p style="text-align:left;">In our case, <em>P = sigma</em>, and <em>q = 0</em>:</p>
<pre>P = sigma
q = matrix(numpy.zeros((n, 1)))</pre>
<p style="text-align:left;">The inequality constraints <img src="https://s0.wp.com/latex.php?latex=x+%5Cgeq+r_%7Bmin%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x+%5Cgeq+r_%7Bmin%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x+%5Cgeq+r_%7Bmin%7D&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x &#92;geq r_{min}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=x+%5Cgeq+0&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x+%5Cgeq+0&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x+%5Cgeq+0&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x &#92;geq 0" class="latex" /> are captured using <img src="https://s0.wp.com/latex.php?latex=Gx+%5Cleq+h&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=Gx+%5Cleq+h&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=Gx+%5Cleq+h&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="Gx &#92;leq h" class="latex" />:</p>
<pre># inequality constraints Gx &lt;= h
# captures the constraints (avg_ret'x &gt;= r_min) and (x &gt;= 0)
G = matrix(numpy.concatenate((
             -numpy.transpose(numpy.array(avg_ret)), 
             -numpy.identity(n)), 0))
h = matrix(numpy.concatenate((
             -numpy.ones((1,1))*r_min, 
              numpy.zeros((n,1))), 0))</pre>
<p>And the equality constraint <img src="https://s0.wp.com/latex.php?latex=%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+x_%7Bi%7D%3D1&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+x_%7Bi%7D%3D1&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+x_%7Bi%7D%3D1&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;sum_{i=1}^{n} x_{i}=1" class="latex" /> is captured using <img src="https://s0.wp.com/latex.php?latex=Ax+%3D+b&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=Ax+%3D+b&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=Ax+%3D+b&#038;bg=ffffff&#038;fg=404040&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="Ax = b" class="latex" />:</p>
<pre># equality constraint Ax = b; captures the constraint sum(x) == 1
A = matrix(1.0, (1,n))
b = matrix(1.0)</pre>
<p>We&#8217;re ready to solve! Throw it into the solver and brace yourself for optimality:</p>
<pre>sol = solvers.qp(P, q, G, h, A, b)</pre>
<h2></h2>
<h2><strong>The Results and the Expansions</strong></h2>
<p>Here&#8217;s the result:</p>
<pre>Optimal solution found.
[0.0, 0.0, 0.0, 0.7, 0.16, 0.0, 0.0, 0.0, 0.0, 0.13]</pre>
<p>Surprisingly, we should only invest in the 3 of the stocks! Keep in mind that the model that we&#8217;ve used here contains <em>many</em> simplifying assumptions; the emphasis here is outlining the approach to casting the problem as a convex optimization problem using real stock data. T<span style="line-height:1.6;">he great thing is that we can easily change the estimation of expected return, use a different objective function, or introduce new constraints that better reflect our goals, and more generally, the real-world.</span></p>
<h3>Credits</h3>
<p>This post was originally inspired by content from Stephen Boyd&#8217;s great book <a href="http://www.stanford.edu/~boyd/">Convex Optimization</a>. Boyd is also teaching an ongoing online-course called <a href="https://class.stanford.edu/courses/Engineering/CVX101/Winter2014/about">CVX 101</a> if you are interested in learning more about convex optimization.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://wellecks.wordpress.com/2014/03/23/portfolio-optimization-with-python/feed/</wfw:commentRss>
			<slash:comments>5</slash:comments>
		
		
		
		<media:content url="https://0.gravatar.com/avatar/f7546f57a5fd69bc99ff1640cc4a4853?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">wellecks</media:title>
		</media:content>
	</item>
		<item>
		<title>Microsoft Speech Recognition and Machine Translation</title>
		<link>https://wellecks.wordpress.com/2014/02/01/microsoft-speech-recognition-and-machine-translation/</link>
					<comments>https://wellecks.wordpress.com/2014/02/01/microsoft-speech-recognition-and-machine-translation/#respond</comments>
		
		<dc:creator><![CDATA[wellecks]]></dc:creator>
		<pubDate>Sat, 01 Feb 2014 02:10:24 +0000</pubDate>
				<category><![CDATA[artificial intelligence]]></category>
		<category><![CDATA[Artificial intelligence]]></category>
		<category><![CDATA[machine translation]]></category>
		<guid isPermaLink="false">http://wellecks.wordpress.com/?p=591</guid>

					<description><![CDATA[This semester I&#8217;m taking a course in Machine Translation, a fascinating application of artificial intelligence and machine learning. I ran across this video from Microsoft Research, giving a short historical overview of Machine Translation, and demoing an end-to-end system that recognizes speech, translates it, and speaks back the translation in the user&#8217;s voice. While the [&#8230;]]]></description>
										<content:encoded><![CDATA[<p>This semester I&#8217;m taking a course in Machine Translation, a fascinating application of artificial intelligence and machine learning. I ran across this video from Microsoft Research, giving a short historical overview of Machine Translation, and demoing an end-to-end system that recognizes speech, translates it, and speaks back the translation in the user&#8217;s voice. While the video is non-technical, the speaker briefly mentions that the system uses deep neural nets. It&#8217;s a quick and exciting watch.</p>
<div class="jetpack-video-wrapper"><iframe class="youtube-player" width="525" height="296" src="https://www.youtube.com/embed/Nu-nlQqFCKg?version=3&#038;rel=1&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;fs=1&#038;hl=en&#038;autohide=2&#038;wmode=transparent" allowfullscreen="true" style="border:0;" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></div>
]]></content:encoded>
					
					<wfw:commentRss>https://wellecks.wordpress.com/2014/02/01/microsoft-speech-recognition-and-machine-translation/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		
		<media:content url="https://0.gravatar.com/avatar/f7546f57a5fd69bc99ff1640cc4a4853?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">wellecks</media:title>
		</media:content>
	</item>
	</channel>
</rss>
