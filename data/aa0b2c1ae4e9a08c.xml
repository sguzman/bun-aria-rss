<?xml version='1.0' encoding='UTF-8'?><rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:openSearch="http://a9.com/-/spec/opensearchrss/1.0/" xmlns:blogger="http://schemas.google.com/blogger/2008" xmlns:georss="http://www.georss.org/georss" xmlns:gd="http://schemas.google.com/g/2005" xmlns:thr="http://purl.org/syndication/thread/1.0" version="2.0"><channel><atom:id>tag:blogger.com,1999:blog-6300367579216018061</atom:id><lastBuildDate>Sun, 30 Oct 2022 09:33:37 +0000</lastBuildDate><category>neo4j</category><category>graph database</category><category>spring boot</category><category>microservices</category><category>spring cloud</category><category>apache spark</category><category>docker</category><category>PageRank</category><category>cloud native java</category><category>data science</category><category>docker compose</category><category>Mazerunner</category><category>big data</category><category>graph analytics</category><category>graphx</category><category>open source software</category><category>analytics</category><category>event sourcing</category><category>graph processing</category><category>pattern recognition</category><category>cqrs</category><category>cypher</category><category>event-driven microservices</category><category>github</category><category>graph data modeling</category><category>graphs</category><category>information theory</category><category>meetup</category><category>natural language processing</category><category>node.js</category><category>open source</category><category>reporting</category><category>serverless</category><category>text classification</category><category>twitter</category><category>PCF dev</category><category>algorithms</category><category>apache hadoop</category><category>api gateway</category><category>architecture</category><category>artificial intelligence</category><category>c#</category><category>cloud foundry</category><category>coding rocks</category><category>computable numbers</category><category>data</category><category>data import</category><category>declarative query language</category><category>deep learning</category><category>delete duplicate records</category><category>design</category><category>discovery service</category><category>docker swarm</category><category>document classification</category><category>eventual consistency</category><category>execution planning</category><category>feature learning</category><category>gephi</category><category>google cloud</category><category>google cloud natural language</category><category>graph algorithms</category><category>graph analysis</category><category>graph theory</category><category>graphify</category><category>heroku scheduler</category><category>james gleick</category><category>jeff hawkins</category><category>legacy modernization</category><category>legacy systems</category><category>machine learning</category><category>monoliths</category><category>mysql</category><category>nodes</category><category>polyglot persistence</category><category>rabbitmq</category><category>ray kurzweil</category><category>reactive streaming</category><category>reactor</category><category>recommendation engine</category><category>sentiment analysis</category><category>service block architecture</category><category>service blocks</category><category>soa</category><category>spark neo4j</category><category>spring cloud function</category><category>spring data</category><category>time scales</category><category>triangle count</category><category>tutorial</category><category>ubigraph</category><category>universal turing machine</category><category>visualization</category><category>wikipedia</category><title>Kenny Bastani</title><description>I write and talk about building software. I also tweet things @kennybastani</description><link>https://www.kennybastani.com/</link><managingEditor>noreply@blogger.com (Kenny Bastani)</managingEditor><generator>Blogger</generator><openSearch:totalResults>24</openSearch:totalResults><openSearch:startIndex>1</openSearch:startIndex><openSearch:itemsPerPage>25</openSearch:itemsPerPage><item><guid isPermaLink="false">tag:blogger.com,1999:blog-6300367579216018061.post-363020128279112356</guid><pubDate>Thu, 19 Sep 2019 16:36:00 +0000</pubDate><atom:updated>2019-09-19T13:42:33.447-07:00</atom:updated><category domain="http://www.blogger.com/atom/ns#">design</category><category domain="http://www.blogger.com/atom/ns#">google cloud</category><category domain="http://www.blogger.com/atom/ns#">google cloud natural language</category><category domain="http://www.blogger.com/atom/ns#">graph algorithms</category><category domain="http://www.blogger.com/atom/ns#">graph data modeling</category><category domain="http://www.blogger.com/atom/ns#">graph processing</category><category domain="http://www.blogger.com/atom/ns#">neo4j</category><category domain="http://www.blogger.com/atom/ns#">PageRank</category><category domain="http://www.blogger.com/atom/ns#">twitter</category><title>Sentiment Analysis on Twitter Data Using Neo4j and Google Cloud</title><description> &lt;style&gt;.hljs-title, .hljs-id, .scss .hljs-preprocessor {    font-weight: 400 !important; } .hljs-class .hljs-title, .hljs-type, .vhdl .hljs-literal, .tex .hljs-command {    font-weight: 400 !important; } .hljs-keyword, .css .rule .hljs-keyword, .hljs-winutils, .nginx .hljs-title, .hljs-subst, .hljs-request, .hljs-status {    font-weight: 400 !important; } .sect1{padding-bottom:0!important} .sect1+.sect1{border:0!important} .conum[data-value]{display:inline-block;color:#fff!important;background-color:rgba(0,0,0,.8);-webkit-border-radius:100px;border-radius:100px;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:&quot;Open Sans&quot;,&quot;DejaVu Sans&quot;,sans-serif;font-style:normal;font-weight:bold} .conum[data-value] *{color:#fff!important} .conum[data-value]+b{display:none} .conum[data-value]:after{content:attr(data-value)} .fa-caret-up {     color: green;     text-shadow: 1px 1px 1px #ccc;     font-size: 1.75em !important; }  .fa-caret-down {     color: red;     text-shadow: 1px 1px 1px #ccc;     font-size: 1.75em !important; }  .fa-minus {     color: #999;     text-shadow: 1px 1px 1px #ccc;     font-size: 1em !important; }  .fa-plus {     font-size: 1em !important;     color: green;     text-shadow: 1px 1px 1px #ccc; }   @media screen and (min-width: 768px) { .table-responsive { font-size: 0.8em; max-width: 50em; } }  @media screen and (max-width: 768px) {     .table-responsive {     font-size: 0.65em; } }  .table-responsive th, .table-responsive tr, .table-responsive td { padding: 4px 4px 4px 4px !important; } p {     margin-bottom: 1.25em !important; line-height: 1.4; } li p { line-height: 1.4 !important; margin: 0 !important; } .blog-post-asciidoc .content img {  max-height: none;  width: 100% !important; } .admonitionblock &gt; table {     background: rgba(0, 0, 0, 0) none repeat scroll 0 0;     border: 0 none;     border-collapse: separate;     width: 100%; } table {     background: #fff none repeat scroll 0 0;     border: 1px solid #dedede;     margin-bottom: 1.25em; } pre .conum[data-value]{position:relative;top:-.125em} b.conum *{color:inherit!important} .conum:not([data-value]):empty{display:none} .hdlist&gt;table,.colist&gt;table{border:0;background:none} .hdlist&gt;table&gt;tbody&gt;tr,.colist&gt;table&gt;tbody&gt;tr{background:none} td.hdlist1{padding-right:.75em;font-weight:bold} td.hdlist1,td.hdlist2{vertical-align:top} .literalblock+.colist,.listingblock+.colist{margin-top:-.5em} .colist&gt;table tr&gt;td:first-of-type{padding:0 .75em;line-height:1} .colist&gt;table tr&gt;td:last-of-type{padding:.25em 0} h1,h2,h3,#toctitle,.sidebarblock&gt;.content&gt;.title,h3,h4,h6{font-family:&quot;Open Sans&quot;,sans-serif;font-style:normal;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;} .blog-post-asciidoc p{margin-bottom:1.25rem} @media only screen and (min-width:768px){.sect1{padding-bottom:1.25em}}.sect1+.sect1{border-top:1px solid #efefed} pre, pre &gt; code {     -moz-osx-font-smoothing: auto;     color: rgba(0, 0, 0, 0.9);     font-family: monospace,monospace;     font-weight: 400;     line-height: 1.45;     text-rendering: optimizelegibility; } .blog-post-asciidoc code,kbd,pre,samp{font-size:.9em;font-weight:400;} .blog-post-asciidoc .admonitionblock&gt;table{border-collapse:separate;border:0;background:none;width:100%} .blog-post-asciidoc .admonitionblock&gt;table td.icon{text-align:center;width:80px} .blog-post-asciidoc .admonitionblock&gt;table td.icon img{max-width:none} .blog-post-asciidoc .admonitionblock&gt;table td.icon .title{font-weight:bold;font-family:&quot;Open Sans&quot;,&quot;DejaVu Sans&quot;,sans-serif;text-transform:uppercase} .blog-post-asciidoc .admonitionblock&gt;table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #ddddd8;color:rgba(0,0,0,.6)} .blog-post-asciidoc .admonitionblock&gt;table td.content&gt;:last-child&gt;:last-child{margin-bottom:0} .blog-post-asciidoc .admonitionblock td.icon [class^=&quot;fa icon-&quot;]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default} .blog-post-asciidoc .admonitionblock td.icon .icon-note:before{content:&quot;\f05a&quot;;color:#19407c} .blog-post-asciidoc .admonitionblock td.icon .icon-tip:before{content:&quot;\f0eb&quot;;text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111} .blog-post-asciidoc .admonitionblock td.icon .icon-warning:before{content:&quot;\f071&quot;;color:#bf6900} .blog-post-asciidoc .admonitionblock td.icon .icon-caution:before{content:&quot;\f06d&quot;;color:#bf3400} .blog-post-asciidoc .admonitionblock td.icon .icon-important:before{content:&quot;\f06a&quot;;color:#bf0000} #personDataTable td {     vertical-align: middle; } .rank-col {     text-align: center; } #personDataTable img {     max-width: 35px;     padding: 0; } .table-responsive {     font-weight: 400; } .table &gt; thead &gt; tr &gt; th {     border-bottom: 2px solid #ddd;     font-weight: 400;     padding: 8px !important;     vertical-align: bottom; } .table-responsive {     font-family: Helvetica,sans-serif; } .exampleblock pre {     margin-top: auto; } .exampleblock .content {     margin-top: auto; } blockquote {     border-left: 5px solid #eee;     color: #666;     font-size: 16px;     margin: 0;     padding: 10px 20px; } .attribution {     font-size: small;     text-align: right; } .table-responsive p { margin: 0 !important; } p.tableblock {   font-size: 14px;   margin: 0 !important; } table.tableblock { max-width: 100%; border-collapse: separate; } table.tableblock td &gt; .paragraph:last-child p &gt; p:last-child, table.tableblock th &gt; p:last-child, table.tableblock td &gt; p:last-child { margin-bottom: 0; }  table.tableblock, th.tableblock, td.tableblock { border: 0 solid #dddddd; }  table.grid-all th.tableblock, table.grid-all td.tableblock { border-width: 0 1px 1px 0; }  table.grid-all tfoot &gt; tr &gt; th.tableblock, table.grid-all tfoot &gt; tr &gt; td.tableblock { border-width: 1px 1px 0 0; }  table.grid-cols th.tableblock, table.grid-cols td.tableblock { border-width: 0 1px 0 0; }  table.grid-all * &gt; tr &gt; .tableblock:last-child, table.grid-cols * &gt; tr &gt; .tableblock:last-child { border-right-width: 0; }  table.grid-rows th.tableblock, table.grid-rows td.tableblock { border-width: 0 0 1px 0; }  table.grid-all tbody &gt; tr:last-child &gt; th.tableblock, table.grid-all tbody &gt; tr:last-child &gt; td.tableblock, table.grid-all thead:last-child &gt; tr &gt; th.tableblock, table.grid-rows tbody &gt; tr:last-child &gt; th.tableblock, table.grid-rows tbody &gt; tr:last-child &gt; td.tableblock, table.grid-rows thead:last-child &gt; tr &gt; th.tableblock { border-bottom-width: 0; }  table.grid-rows tfoot &gt; tr &gt; th.tableblock, table.grid-rows tfoot &gt; tr &gt; td.tableblock { border-width: 1px 0 0 0; }  table.frame-all { border-width: 1px; }  table.frame-sides { border-width: 0 1px; }  table.frame-topbot { border-width: 1px 0; }  th.halign-left, td.halign-left { text-align: left; }  th.halign-right, td.halign-right { text-align: right; }  th.halign-center, td.halign-center { text-align: center; }  th.valign-top, td.valign-top { vertical-align: top; }  th.valign-bottom, td.valign-bottom { vertical-align: bottom; }  th.valign-middle, td.valign-middle { vertical-align: middle; }  table thead th, table tfoot th { font-weight: bold; }  tbody tr th { display: table-cell; line-height: 1.4; background: whitesmoke; }  tbody tr th, tbody tr th p, tfoot tr th, tfoot tr th p { color: #222222; font-weight: bold; }  p.tableblock &gt; code:only-child { background: none; padding: 0; }  table tr.even, table tr.alt, table tr:nth-of-type(2n) {     background: #f9f9f9 none repeat scroll 0 0; } div.table-responsive {  border: 0; }  .sql p {  font-family: courier; } .big{font-size:larger} .small{font-size:smaller} .underline{text-decoration:underline} .overline{text-decoration:overline} .line-through{text-decoration:line-through} .aqua{color:#00bfbf} .aqua-background{background:#00fafa} .black{color:#000} .black-background{background:#000} .blue{color:#0000bf} .blue-background{background:#0000fa} .fuchsia{color:#bf00bf} .fuchsia-background{background:#fa00fa} .gray{color:#606060} .gray-background{background:#7d7d7d} .green{color:#006000} .green-background{background:#007d00} .lime{color:#00bf00} .lime-background{background:#00fa00} .maroon{color:#600000} .maroon-background{background:#7d0000} .navy{color:#000060} .navy-background{background:#00007d} .olive{color:#606000} .olive-background{background:#7d7d00} .purple{color:#600060} .purple-background{background:#7d007d} .red{color:#bf0000} .red-background{background:#fa0000} .silver{color:#909090} .silver-background{background:#bcbcbc} .teal{color:#006060} .teal-background{background:#007d7d} .white{color:#bfbfbf} .white-background{background:#fafafa} .yellow{color:#bfbf00} .yellow-background{background:#fafa00} span.icon&gt;.fa{cursor:default} a span.icon&gt;.fa{cursor:inherit} .admonitionblock td.icon [class^=&quot;fa icon-&quot;]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default} .admonitionblock td.icon .icon-note::before{content:&quot;\f05a&quot;;color:#19407c} .admonitionblock td.icon .icon-tip::before{content:&quot;\f0eb&quot;;text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111} .admonitionblock td.icon .icon-warning::before{content:&quot;\f071&quot;;color:#bf6900} .admonitionblock td.icon .icon-caution::before{content:&quot;\f06d&quot;;color:#bf3400} .admonitionblock td.icon .icon-important::before{content:&quot;\f06a&quot;;color:#bf0000} .conum[data-value]{display:inline-block;color:#fff!important;background:rgba(0,0,0,.8);-webkit-border-radius:100px;border-radius:100px;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:&quot;Open Sans&quot;,&quot;DejaVu Sans&quot;,sans-serif;font-style:normal;font-weight:bold} .conum[data-value] *{color:#fff!important} .conum[data-value]+b{display:none} .conum[data-value]::after{content:attr(data-value)} &lt;/style&gt;&lt;div class=&quot;blog-post-asciidoc&quot; id=&quot;wrapper&quot;&gt;        &lt;div class=&quot;article&quot;&gt;          &lt;div id=&quot;preamble&quot;&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div id=&quot;__asciidoctor-preview-1__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;In this blog post, we&amp;#8217;re going to walk through designing a &lt;a href=&quot;https://blog.acolyer.org/2015/05/26/pregel-a-system-for-large-scale-graph-processing/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;graph processing algorithm&lt;/a&gt; on top of &lt;a href=&quot;https://neo4j.com/developer/graph-database/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Neo4j&lt;/a&gt; that discovers the influence and sentiment of tweets in your Twitter network.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-2__&quot; class=&quot;admonitionblock tip&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;icon&quot;&gt;&lt;i class=&quot;fa icon-tip&quot; title=&quot;Tip&quot;&gt;&lt;/i&gt;&lt;/td&gt;&lt;td class=&quot;content&quot;&gt;The source code for this reference application is open source. You can find the  &lt;a href=&quot;https://github.com/kbastani/sentiment-analysis-twitter-microservices-example&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;GitHub project here&lt;/a&gt;. &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_graph_data_modeling&quot;&gt;Graph Data Modeling&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div id=&quot;__asciidoctor-preview-3__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;The first thing we&amp;#8217;ll need to do is to design a data model for analyzing the sentiments and influences of users on Twitter. This example iterates from an &lt;a href=&quot;https://www.kennybastani.com/2016/01/spring-boot-graph-processing-microservices.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;earlier graph processing example&lt;/a&gt; described in another blog post. I recommend taking a look at that post to better understand the concepts I talk about in this one.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-4__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;The diagram below is the &lt;a href=&quot;https://www.youtube.com/watch?v=3w_ih8_9rVY&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;graph data model&lt;/a&gt; that we will use to import, analyze, and query data from Twitter.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;imageblock&quot; style=&quot;display: block;&quot;&gt;&lt;div class=&quot;content&quot; style=&quot;text-align: center;&quot;&gt;&lt;img alt=&quot;Twitter graph data model&quot; src=&quot;https://i.imgur.com/U1eK3vi.png&quot; style=&quot;max-width: 50em; margin: auto !important;&quot; width=&quot;100%&quot;/&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-6__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;In the diagram above, the following relationships are described.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-7__&quot; class=&quot;ulist&quot;&gt;&lt;ul&gt;&lt;li id=&quot;__asciidoctor-preview-8__&quot;&gt;&lt;p&gt;&lt;code&gt;Users&lt;/code&gt; follow other &lt;code&gt;users&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li id=&quot;__asciidoctor-preview-9__&quot;&gt;&lt;p&gt;&lt;code&gt;Users&lt;/code&gt; create &lt;code&gt;tweets&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li id=&quot;__asciidoctor-preview-10__&quot;&gt;&lt;p&gt;&lt;code&gt;Tweets&lt;/code&gt; contain &lt;code&gt;phrases&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li id=&quot;__asciidoctor-preview-11__&quot;&gt;&lt;p&gt;&lt;code&gt;Phrases&lt;/code&gt; are categorized into &lt;code&gt;topics&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_twitter_user_ranking&quot;&gt;Twitter User Ranking&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div id=&quot;__asciidoctor-preview-12__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;For this first blog post we&amp;#8217;re going to focus on generating a rank of influential Twitter users in my social network that tells me which topics a user tweets about.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;imageblock&quot; style=&quot;display: block;&quot;&gt;&lt;div class=&quot;content&quot; style=&quot;text-align: center;&quot;&gt;&lt;img alt=&quot;Twitter influencer ranking with topic&quot; src=&quot;https://i.imgur.com/tq5Pqzo.png&quot; style=&quot;max-width: 50em; margin: auto !important;&quot; width=&quot;100%&quot;/&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-14__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;The screenshot above is from the results of a &lt;a href=&quot;https://neo4j.com/developer/cypher-query-language/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Neo4j cypher query&lt;/a&gt;. Here we find a list of Twitter users that were discovered using a &lt;a href=&quot;https://en.wikipedia.org/wiki/Web_crawler&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;crawling algorithm&lt;/a&gt; based on &lt;a href=&quot;https://en.wikipedia.org/wiki/PageRank&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;PageRank&lt;/a&gt;. This output is similar to the dashboard that was created in an earlier blog post, but adds in a top category, top phrase, and a sentiment score.&lt;/p&gt;&lt;/div&gt;&lt;a name=&#39;more&#39;&gt;&lt;/a&gt;&lt;div id=&quot;__asciidoctor-preview-15__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;Let&amp;#8217;s figure out how graph processing on Neo4j is used to generate this ranking of users.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_natural_language_processing&quot;&gt;Natural Language Processing&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div id=&quot;__asciidoctor-preview-16__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;We&amp;#8217;re going to use &lt;a href=&quot;https://en.wikipedia.org/wiki/Sentiment_analysis&quot;&gt;sentiment analysis&lt;/a&gt; to enhance the graph data model described earlier. We will use &lt;a href=&quot;https://cloud.google.com/natural-language/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Google Cloud&amp;#8217;s Natural Language API&lt;/a&gt; to do this.  Every time a user&amp;#8217;s tweet is fetched from the Twitter API, its text is submitted to multiple Natural Language API endpoints, which enhances data in our graph data model.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-17__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;The diagram below is an example pathway between a &lt;code&gt;User&lt;/code&gt; and a &lt;code&gt;Topic&lt;/code&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;imageblock&quot; style=&quot;display: block;&quot;&gt;&lt;div class=&quot;content&quot; style=&quot;text-align: center;&quot;&gt;&lt;img alt=&quot;Twitter graph pathway from user to topic&quot; src=&quot;https://i.imgur.com/LkdSk6p.png&quot; style=&quot;max-width: 50em; margin: auto !important;&quot; width=&quot;100%&quot;/&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-19__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;The Twitter crawling algorithm in our application iteratively imports a set of tweets from each ranked user. We&amp;#8217;ll lean on the Google Cloud&amp;#8217;s Natural Language API to help us structure the semantic relationships between users, tweets, phrases, and topics.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_sentiment_analysis&quot;&gt;Sentiment analysis&lt;/h3&gt;&lt;div id=&quot;__asciidoctor-preview-20__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;The first Google Cloud Natural Language API we&amp;#8217;ll use is the &lt;em&gt;sentiment analysis&lt;/em&gt; endpoint. The sentiment analysis API endpoint is described in the Google Cloud developer documentation, and is explained below.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-21__&quot; class=&quot;quoteblock&quot;&gt;&lt;blockquote&gt;&lt;div id=&quot;__asciidoctor-preview-22__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://cloud.google.com/natural-language/docs/analyzing-sentiment&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;em&gt;Sentiment analysis&lt;/em&gt;&lt;/a&gt; inspects the given text and identifies the prevailing emotional opinion within the text, especially to determine a writer&amp;#8217;s attitude as positive, negative, or neutral.&lt;/p&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;div class=&quot;imageblock&quot; style=&quot;display: block;&quot;&gt;&lt;div class=&quot;content&quot; style=&quot;text-align: center;&quot;&gt;&lt;img alt=&quot;Twitter graph sentiment analysis data model&quot; src=&quot;https://i.imgur.com/ziSiCzw.png&quot; style=&quot;max-width: 50em; margin: auto !important;&quot; width=&quot;100%&quot;/&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-24__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;The sentiment analysis endpoint allows us to add a sentiment score on each &lt;code&gt;Tweet&lt;/code&gt;. The next step is to extract phrases, shown in the diagram above, and to fetch the sentiment score in relation to a tweet&amp;#8217;s text.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_entity_sentiment_analysis&quot;&gt;Entity sentiment analysis&lt;/h3&gt;&lt;div id=&quot;__asciidoctor-preview-25__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;Entity sentiment analysis is a Cloud Natural Language endpoint that provides us with a collection of phrases and their sentiment scores in context to a tweet&amp;#8217;s text.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-26__&quot; class=&quot;quoteblock&quot;&gt;&lt;blockquote&gt;&lt;div id=&quot;__asciidoctor-preview-27__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://cloud.google.com/natural-language/docs/analyzing-entity-sentiment&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;em&gt;Entity sentiment analysis&lt;/em&gt;&lt;/a&gt; inspects the given text for known entities (proper nouns and common nouns), returns information about those entities, and identifies the prevailing emotional opinion of the entity within the text, especially to determine a writer&amp;#8217;s attitude toward the entity as positive, negative, or neutral.&lt;/p&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;div class=&quot;imageblock&quot; style=&quot;display: block;&quot;&gt;&lt;div class=&quot;content&quot; style=&quot;text-align: center;&quot;&gt;&lt;img alt=&quot;Twitter graph entity sentiment analysis data model&quot; src=&quot;https://i.imgur.com/cCISagY.png&quot; style=&quot;max-width: 50em; margin: auto !important;&quot; width=&quot;100%&quot;/&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-29__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;Here we can see that the entity sentiment analysis endpoint will return back a collection of phrases. The endpoint provides a sentiment score for each phrase in context to the text it was extracted from. We store this calculation in the relationship that connects a &lt;code&gt;Tweet&lt;/code&gt; to a &lt;code&gt;Phrase&lt;/code&gt;, as shown in the diagram above.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_content_classification&quot;&gt;Content classification&lt;/h3&gt;&lt;div id=&quot;__asciidoctor-preview-30__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;Content classification is an API provided by GCP that will allow you to provide a string of text as a document, and be returned a set of categories that classifies the content.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-31__&quot; class=&quot;quoteblock&quot;&gt;&lt;blockquote&gt;&lt;div id=&quot;__asciidoctor-preview-32__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://cloud.google.com/natural-language/docs/classifying-text&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;em&gt;Content classification&lt;/em&gt;&lt;/a&gt; analyzes text content and returns a content category for the content.&lt;/p&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-33__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;The diagram below shows how a &lt;code&gt;Tweet&lt;/code&gt; contains certain phrases that share a topic, and can be linked back to a &lt;code&gt;User&lt;/code&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;imageblock&quot; style=&quot;display: block;&quot;&gt;&lt;div class=&quot;content&quot; style=&quot;text-align: center;&quot;&gt;&lt;img alt=&quot;Twitter graph content classification topic data model&quot; src=&quot;https://i.imgur.com/6yJTJuE.png&quot; style=&quot;max-width: 50em; margin: auto !important;&quot; width=&quot;100%&quot;/&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-35__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;Categorizing a group of tweets into a set of topics is a difficult proposition. More so, the computation required to categorically segment topics is cost prohibitive. Tweets, by themselves, do not always contain enough text to meaningfully classify their content. Meanings also vary widely in context to the audience and author of a tweet.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-36__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;To generate an index of topics for groups of tweets, we can use PageRank scoring on phrases mentioned in imported tweets. By doing this, we can group together batches of tweets for the top ranked phrases. Further, this allows us to ask questions related to a user&amp;#8217;s sentiment for particular topics, in addition to phrases.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-37__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;For example, the crawling algorithm will schedule an analysis on the phrases &lt;code&gt;metrics&lt;/code&gt;, &lt;code&gt;database&lt;/code&gt;, and &lt;code&gt;serverless&lt;/code&gt;. For each of these terms, we&amp;#8217;ll select each &lt;code&gt;Tweet&lt;/code&gt; and join together the text into a single document. The resulting document contains much more text that will be useful for content classification on Google Cloud.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-38__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;In the next section I&amp;#8217;ll describe how PageRank is used to optimize the crawling algorithm&amp;#8217;s import and analysis of Twitter data.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_graph_processing&quot;&gt;Graph Processing&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div id=&quot;__asciidoctor-preview-39__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;How do you find the most influential users in your Twitter network without having access to all of the data? To do this, we need to iteratively rank and then discover profiles using the PageRank algorithm.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_user_rank&quot;&gt;User Rank&lt;/h3&gt;&lt;div id=&quot;__asciidoctor-preview-40__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;The diagram below describes the follower graph of relationships between &lt;code&gt;Users&lt;/code&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;imageblock&quot; style=&quot;display: block;&quot;&gt;&lt;div class=&quot;content&quot; style=&quot;text-align: center;&quot;&gt;&lt;img alt=&quot;Twitter graph user follows PageRank example&quot; src=&quot;https://i.imgur.com/UwNsBPQ.png&quot; style=&quot;max-width: 50em; margin: auto !important;&quot; width=&quot;100%&quot;/&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-42__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;On a scheduled interval, PageRank will be run on this subgraph. The result will be used to select the next highest ranked user that has not yet been imported. By doing this, we can walk towards more influential sources of content. The added benefit is that we only focus on importing follower and friend relationships from the most influential users. This allows us to hop towards the influential center of gravity of tweets in a network without importing retweets or favorites.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_phrase_rank&quot;&gt;Phrase Rank&lt;/h3&gt;&lt;div id=&quot;__asciidoctor-preview-43__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;The diagram below describes the semantic relationships between &lt;code&gt;Tweets&lt;/code&gt; and &lt;code&gt;Phrases&lt;/code&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;imageblock&quot; style=&quot;display: block;&quot;&gt;&lt;div class=&quot;content&quot; style=&quot;text-align: center;&quot;&gt;&lt;img alt=&quot;Twitter graph phrase PageRank example&quot; src=&quot;https://i.imgur.com/P4W2kAN.png&quot; style=&quot;max-width: 50em; margin: auto !important;&quot; width=&quot;100%&quot;/&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-45__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;On a scheduled interval, PageRank is calculated on the phrases of this subgraph. The results are used to classify groups of &lt;code&gt;Tweets&lt;/code&gt;, as shown in the example below.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;imageblock&quot; style=&quot;display: block;&quot;&gt;&lt;div class=&quot;content&quot; style=&quot;text-align: center;&quot;&gt;&lt;img alt=&quot;Twitter graph infer topic example&quot; src=&quot;https://i.imgur.com/72XPhnm.png&quot; style=&quot;max-width: 50em; margin: auto !important;&quot; width=&quot;100%&quot;/&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_answering_questions_with_neo4j&quot;&gt;Answering Questions with Neo4j&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div id=&quot;__asciidoctor-preview-47__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;In this first blog post we&amp;#8217;re going to keep things relatively short by focusing on answering questions using the graph data model. In later blog posts, I will focus more on operations and application development with &lt;a href=&quot;https://spring.io/projects/spring-boot&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Spring Boot&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-48__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;In the next sections I&amp;#8217;ll summarize some of the queries that I formulated to answer questions related to &lt;a href=&quot;https://en.wikipedia.org/wiki/Emotional_contagion&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;emotional contagion&lt;/a&gt;, &lt;a href=&quot;https://en.wikipedia.org/wiki/Social_influence&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;influence&lt;/a&gt;, and &lt;a href=&quot;https://en.wikipedia.org/wiki/Meme&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;memes&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_ranking_users_by_topic_and_influence&quot;&gt;Ranking users by topic and influence&lt;/h3&gt;&lt;div id=&quot;__asciidoctor-preview-49__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;One of the queries that I wanted to create was for a ranking dashboard based on topic and sentiment. It took me numerous iterations to come up with a Neo4j Cypher query that accurately extracts the most relevant category and phrase for each ranked user.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;imageblock&quot; style=&quot;display: block;&quot;&gt;&lt;div class=&quot;content&quot; style=&quot;text-align: center;&quot;&gt;&lt;img alt=&quot;Twitter user ranking with topic example&quot; src=&quot;https://i.imgur.com/tq5Pqzo.png&quot; style=&quot;max-width: 50em; margin: auto !important;&quot; width=&quot;100%&quot;/&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-51__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;In the screenshot above, I run a Cypher query in the Neo4j browser to infer the top phrase and category for a user&amp;#8217;s tweets. Since I follow all of these users, I can honestly say that the query is fairly accurate. I will dive deeper into this subject in a later blog post.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_diving_into_the_meme_pool&quot;&gt;Diving into the meme pool&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div id=&quot;__asciidoctor-preview-52__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;Next, I&amp;#8217;ll explain some of my recent tweets, which I posted over the course of building this application.&lt;/p&gt;&lt;/div&gt;&lt;blockquote class=&quot;twitter-tweet&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;I built a sentiment analysis tool that can learn stuff by reading tweets. It figured out what a container is.&lt;br&gt;&lt;br&gt;Well, kind of. 😁 &lt;a href=&quot;https://t.co/tRiHexLoL9&quot;&gt;pic.twitter.com/tRiHexLoL9&lt;/a&gt;&lt;/p&gt;&amp;mdash; Kenny Bastani (@kennybastani) &lt;a href=&quot;https://twitter.com/kennybastani/status/1170709276811284480?ref_src=twsrc%5Etfw&quot;&gt;September 8, 2019&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;&lt;div id=&quot;__asciidoctor-preview-54__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;In the tweet above, I was excited to discover a graph visualization that demonstrated how &lt;a href=&quot;https://en.wikipedia.org/wiki/LXC&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Linux containers&lt;/a&gt; were related to different phrases. I call this Neo4j Cypher query: a &lt;em&gt;meme graph&lt;/em&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-55__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;em&gt;Memes&lt;/em&gt; are patterns or templates in natural language text that evolve and change over time. Twitter users will post variations of a meme, which will contain variable and static parts. The variable parts of a meme are limited to a subset of possible terms. To discover a meme in the Twitter graph, I can query for &lt;code&gt;phrases&lt;/code&gt; that have multiple connections to &lt;code&gt;tweets&lt;/code&gt;. By traversing tweets and their extracted phrases, I discovered potential memes by matching cycles and loops in entity relationships.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;imageblock&quot; style=&quot;display: block;&quot;&gt;&lt;div class=&quot;content&quot; style=&quot;text-align: center;&quot;&gt;&lt;img alt=&quot;Twitter meme graph Neo4j screenshot&quot; src=&quot;https://i.imgur.com/1oF0bJj.png&quot; style=&quot;max-width: 50em; margin: auto !important;&quot; width=&quot;100%&quot;/&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-57__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;In the screenshot above, you&amp;#8217;ll see a flow of looped connections between tweets and phrases. I&amp;#8217;ve set a criteria on the results so that only phrases mentioned twice in the same tweet are displayed. This proved to be a really clever way to determine the most relevant phrases in the network. As it turns out, people do not often use the same phrase more than once in the same tweet. Which means, that for the users who do, they are conveying something of topical importance.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-58__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;Memes seem to tell a story about a network of users on Twitter.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;sect3&quot;&gt;&lt;h4 id=&quot;_visualizing_the_emotion_of_words&quot;&gt;Visualizing the emotion of words&lt;/h4&gt;&lt;div id=&quot;__asciidoctor-preview-59__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;Next, I&amp;#8217;ve decided to utilize the sentiment scoring from Google Cloud Natural Language to generate a visualization of popular phrases in their emotional context.&lt;/p&gt;&lt;/div&gt;&lt;blockquote class=&quot;twitter-tweet&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;I used graph algorithms and sentiment analysis to infer and predict the &amp;quot;emotional feels 🤷‍♂️&amp;quot; for 20,000+ phrases &amp;amp; mentions in my Twitter network.&lt;br&gt;&lt;br&gt;Blue/green phrases: 🙂&lt;br&gt;Yellow phrases: 😶&lt;br&gt;Orange/red phrases: ☹️ &lt;a href=&quot;https://t.co/ADbprmeZne&quot;&gt;pic.twitter.com/ADbprmeZne&lt;/a&gt;&lt;/p&gt;&amp;mdash; Kenny Bastani (@kennybastani) &lt;a href=&quot;https://twitter.com/kennybastani/status/1171910575066157057?ref_src=twsrc%5Etfw&quot;&gt;September 11, 2019&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;&lt;div id=&quot;__asciidoctor-preview-61__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;The tweet referenced above is a ranked extract of phrases that are colored and sized depending on their emotional context. Simply, I exported the graph of phrases and tweets into a visualization tool named &lt;a href=&quot;https://gephi.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Gephi&lt;/a&gt;. Gephi has a set of features that you can use to rank and visualize graph datasets. For me, this was a good proof of concept for understanding whether or not sentiment analysis could be used to infer the larger emotional context of important phrases in my Twitter network.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect3&quot;&gt;&lt;h4 id=&quot;_visualizing_the_virulence_of_words&quot;&gt;Visualizing the virulence of words&lt;/h4&gt;&lt;div id=&quot;__asciidoctor-preview-62__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;While putting together this blog post, I wanted to focus on determining how viral text could spread emotions. It turns out, there are &lt;a href=&quot;https://www.pnas.org/content/pnas/111/24/8788.full.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;academic papers&lt;/a&gt; that prove that emotional contagion can spread in social networks. This will be the topic of future blog posts, but I wanted to end this blog post with a quote from the father of memes, &lt;a href=&quot;https://en.wikipedia.org/wiki/Richard_Dawkins&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Richard Dawkins&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-dnt=&quot;true&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;The shape of viral text on Twitter. 🦠🦠🦠 &lt;a href=&quot;https://t.co/QeRSb78ZmI&quot;&gt;pic.twitter.com/QeRSb78ZmI&lt;/a&gt;&lt;/p&gt;&amp;mdash; Kenny Bastani (@kennybastani) &lt;a href=&quot;https://twitter.com/kennybastani/status/1173207206503878656?ref_src=twsrc%5Etfw&quot;&gt;September 15, 2019&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;&lt;div id=&quot;__asciidoctor-preview-64__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;The most interesting thing I discovered from the data so far was related to memes. It turns out, that people construct and use memes to easily deliver meaningful information on Twitter without knowing. Memes serve as a template where static and variable parts of text provide a familiar backbone for understanding many different aspects of the intended meaning of a tweet. There are the memes we, of course, know and intend to use. There are also memes that we often use that convey meaning but are not intentional, and are not obvious.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-65__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;The shape of the connected data appears to also show that &lt;a href=&quot;https://en.wikipedia.org/wiki/Pattern_formation&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;biological patterns&lt;/a&gt; evolve from the variations of memes that connect tweets and phrases together. This was first predicted by Dawkins, in his book &lt;a href=&quot;https://en.wikipedia.org/wiki/The_Selfish_Gene&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;The Selfish Gene&lt;/a&gt;, where he coins the term &lt;em&gt;meme&lt;/em&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-66__&quot; class=&quot;quoteblock&quot;&gt;&lt;blockquote&gt;I believe that, given the right conditions, replicators automatically band together to create systems, or machines, that carry them around and work to favour their continued replication. &lt;/blockquote&gt;&lt;div class=&quot;attribution&quot;&gt;&amp;#8212; Richard Dawkins&lt;br&gt;&lt;cite&gt;The Selfish Gene (1976)&lt;/cite&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-67__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;There is an interesting body of work behind this idea, thanks to Dawkins. But we should ask, why would there be biologically mimetic patterns in the graph structure that I queried?&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-68__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;Because memes use natural selection to reproduce and evolve in the same way that biological organisms do, using genes. Both mechanisms are based on the translation and expression of information in the form of graphs, which Dawkins first wrote about over 40 years ago. Information is at the core of gene expression into molecular proteins, with organisms as the driver. Information is also at the core of language&amp;#8217;s expression into meaningful behavior, with emotion as the driver.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-69__&quot; class=&quot;quoteblock&quot;&gt;&lt;blockquote&gt;With only a little imagination we can see the gene as sitting at the centre of a radiating web of extended phenotypic power. And an object in the world is the centre of a converging web of influences from many genes sitting in many organisms. The long reach of the gene knows no obvious boundaries. The whole world is criss-crossed with causal arrows joining genes to phenotypic effects, far and near. &lt;/blockquote&gt;&lt;div class=&quot;attribution&quot;&gt;&amp;#8212; Richard Dawkins&lt;br&gt;&lt;cite&gt;The Selfish Gene (1976)&lt;/cite&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-70__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;These are the final words of Dawkin&amp;#8217;s book. No world-wide web as we know it today had yet existed in 1976. No Twitter existed. I did not exist. And today, we find ourselves diving into the meme pool and doing so without a full understanding how our brains work. So, what do you think? What is influencing your behavior on Twitter?&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_summary&quot;&gt;Summary&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div id=&quot;__asciidoctor-preview-71__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;In this blog post I&amp;#8217;ve introduced you to a graph data model for analyzing the influences and sentiments of users on Twitter. To better understand the code behind the architecture, I recommend reading a previously posted tutorial that describes the predecessor to this blog post.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-72__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;In an upcoming blog post we will focus on building a news feed that balances the negative and positive content of popular tweets, using Spring Boot. We&amp;#8217;ll also focus on a feature for understanding how emotional content balances a user&amp;#8217;s behavior over time. I&amp;#8217;ll also focus more on explaining the operational implications of running and scaling the Twitter crawling algorithm and Neo4j.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_running_the_example&quot;&gt;Running the example&lt;/h3&gt;&lt;div id=&quot;__asciidoctor-preview-73__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;The code for this blog post is free and openly available, but is still in active flux—as I design towards a more meaningful community project. I highly recommend &lt;a href=&quot;https://github.com/kbastani/sentiment-analysis-twitter-microservices-example/blob/master/twitter-rank-crawler/src/main/java/org/kbastani/processor/RankProcessor.java&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;exploring the code&lt;/a&gt; that is commented in the &lt;a href=&quot;https://github.com/kbastani/sentiment-analysis-twitter-microservices-example/tree/master/twitter-rank-crawler&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;em&gt;Twitter Rank Crawler&lt;/em&gt; service&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-74__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;Feel free to post questions here or on the GitHub issue tracker. I&amp;#8217;ve included the directions on running the sample application &lt;a href=&quot;https://github.com/kbastani/sentiment-analysis-twitter-microservices-example&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;in the GitHub repository&lt;/a&gt; for this example.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;        &lt;/div&gt;      &lt;/div&gt;</description><enclosure type='image/png' url='https://i.imgur.com/tq5Pqzo.png' length='0'/><link>https://www.kennybastani.com/2019/09/sentiment-analysis-on-twitter-data.html</link><author>noreply@blogger.com (Kenny Bastani)</author><thr:total>0</thr:total></item><item><guid isPermaLink="false">tag:blogger.com,1999:blog-6300367579216018061.post-4292285671140210900</guid><pubDate>Fri, 07 Jul 2017 04:35:00 +0000</pubDate><atom:updated>2017-07-06T21:37:21.236-07:00</atom:updated><category domain="http://www.blogger.com/atom/ns#">cloud native java</category><category domain="http://www.blogger.com/atom/ns#">cqrs</category><category domain="http://www.blogger.com/atom/ns#">event sourcing</category><category domain="http://www.blogger.com/atom/ns#">event-driven microservices</category><category domain="http://www.blogger.com/atom/ns#">serverless</category><category domain="http://www.blogger.com/atom/ns#">service block architecture</category><category domain="http://www.blogger.com/atom/ns#">service blocks</category><category domain="http://www.blogger.com/atom/ns#">spring boot</category><category domain="http://www.blogger.com/atom/ns#">spring cloud</category><category domain="http://www.blogger.com/atom/ns#">spring cloud function</category><title>From Microservices to Service Blocks using Spring Cloud Function and AWS Lambda</title><description>&lt;link rel=&quot;stylesheet&quot; href=&quot;https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans:400,700&quot;&gt;&lt;style&gt;.hljs-title, .hljs-id, .scss .hljs-preprocessor {    font-weight: 400 !important; } .hljs-class .hljs-title, .hljs-type, .vhdl .hljs-literal, .tex .hljs-command {    font-weight: 400 !important; } .hljs-keyword, .css .rule .hljs-keyword, .hljs-winutils, .nginx .hljs-title, .hljs-subst, .hljs-request, .hljs-status {    font-weight: 400 !important; } .sect1{padding-bottom:0!important} .sect1+.sect1{border:0!important} .conum[data-value]{display:inline-block;color:#fff!important;background-color:rgba(0,0,0,.8);-webkit-border-radius:100px;border-radius:100px;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:&quot;Open Sans&quot;,&quot;DejaVu Sans&quot;,sans-serif;font-style:normal;font-weight:bold} .conum[data-value] *{color:#fff!important} .conum[data-value]+b{display:none} .conum[data-value]:after{content:attr(data-value)} .fa-caret-up {     color: green;     text-shadow: 1px 1px 1px #ccc;     font-size: 1.75em !important; }  .fa-caret-down {     color: red;     text-shadow: 1px 1px 1px #ccc;     font-size: 1.75em !important; }  .fa-minus {     color: #999;     text-shadow: 1px 1px 1px #ccc;     font-size: 1em !important; }  .fa-plus {     font-size: 1em !important;     color: green;     text-shadow: 1px 1px 1px #ccc; }   @media screen and (min-width: 768px) { .table-responsive { font-size: 0.8em; max-width: 50em; } }  @media screen and (max-width: 768px) {     .table-responsive {     font-size: 0.65em; } }  .table-responsive th, .table-responsive tr, .table-responsive td { padding: 4px 4px 4px 4px !important; } p {     margin-bottom: 1.25em !important; line-height: 1.4; } li p { line-height: 1.4 !important; margin: 0 !important; } .blog-post-asciidoc .content img {  max-height: none;  width: 100% !important; } .admonitionblock &gt; table {     background: rgba(0, 0, 0, 0) none repeat scroll 0 0;     border: 0 none;     border-collapse: separate;     width: 100%; } table {     background: #fff none repeat scroll 0 0;     border: 1px solid #dedede;     margin-bottom: 1.25em; } pre .conum[data-value]{position:relative;top:-.125em} b.conum *{color:inherit!important} .conum:not([data-value]):empty{display:none} .hdlist&gt;table,.colist&gt;table{border:0;background:none} .hdlist&gt;table&gt;tbody&gt;tr,.colist&gt;table&gt;tbody&gt;tr{background:none} td.hdlist1{padding-right:.75em;font-weight:bold} td.hdlist1,td.hdlist2{vertical-align:top} .literalblock+.colist,.listingblock+.colist{margin-top:-.5em} .colist&gt;table tr&gt;td:first-of-type{padding:0 .75em;line-height:1} .colist&gt;table tr&gt;td:last-of-type{padding:.25em 0} h1,h2,h3,#toctitle,.sidebarblock&gt;.content&gt;.title,h3,h4,h6{font-family:&quot;Open Sans&quot;,sans-serif;font-style:normal;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;} .blog-post-asciidoc p{margin-bottom:1.25rem} @media only screen and (min-width:768px){.sect1{padding-bottom:1.25em}}.sect1+.sect1{border-top:1px solid #efefed} pre, pre &gt; code {     -moz-osx-font-smoothing: auto;     color: rgba(0, 0, 0, 0.9);     font-family: monospace,monospace;     font-weight: 400;     line-height: 1.45;     text-rendering: optimizelegibility; } .blog-post-asciidoc code,kbd,pre,samp{font-size:.9em;font-weight:400;} .blog-post-asciidoc .admonitionblock&gt;table{border-collapse:separate;border:0;background:none;width:100%} .blog-post-asciidoc .admonitionblock&gt;table td.icon{text-align:center;width:80px} .blog-post-asciidoc .admonitionblock&gt;table td.icon img{max-width:none} .blog-post-asciidoc .admonitionblock&gt;table td.icon .title{font-weight:bold;font-family:&quot;Open Sans&quot;,&quot;DejaVu Sans&quot;,sans-serif;text-transform:uppercase} .blog-post-asciidoc .admonitionblock&gt;table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #ddddd8;color:rgba(0,0,0,.6)} .blog-post-asciidoc .admonitionblock&gt;table td.content&gt;:last-child&gt;:last-child{margin-bottom:0} .blog-post-asciidoc .admonitionblock td.icon [class^=&quot;fa icon-&quot;]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default} .blog-post-asciidoc .admonitionblock td.icon .icon-note:before{content:&quot;\f05a&quot;;color:#19407c} .blog-post-asciidoc .admonitionblock td.icon .icon-tip:before{content:&quot;\f0eb&quot;;text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111} .blog-post-asciidoc .admonitionblock td.icon .icon-warning:before{content:&quot;\f071&quot;;color:#bf6900} .blog-post-asciidoc .admonitionblock td.icon .icon-caution:before{content:&quot;\f06d&quot;;color:#bf3400} .blog-post-asciidoc .admonitionblock td.icon .icon-important:before{content:&quot;\f06a&quot;;color:#bf0000} #personDataTable td {     vertical-align: middle; } .rank-col {     text-align: center; } #personDataTable img {     max-width: 35px;     padding: 0; } .table-responsive {     font-weight: 400; } .table &gt; thead &gt; tr &gt; th {     border-bottom: 2px solid #ddd;     font-weight: 400;     padding: 8px !important;     vertical-align: bottom; } .table-responsive {     font-family: Helvetica,sans-serif; } .exampleblock pre {     margin-top: auto; } .exampleblock .content {     margin-top: auto; } blockquote {     border-left: 5px solid #eee;     color: #666;     font-size: 16px;     margin: 0;     padding: 10px 20px; } .attribution {     font-size: small;     text-align: right; } .table-responsive p { margin: 0 !important; } p.tableblock {   font-size: 14px;   margin: 0 !important; } table.tableblock { max-width: 100%; border-collapse: separate; } table.tableblock td &gt; .paragraph:last-child p &gt; p:last-child, table.tableblock th &gt; p:last-child, table.tableblock td &gt; p:last-child { margin-bottom: 0; }  table.tableblock, th.tableblock, td.tableblock { border: 0 solid #dddddd; }  table.grid-all th.tableblock, table.grid-all td.tableblock { border-width: 0 1px 1px 0; }  table.grid-all tfoot &gt; tr &gt; th.tableblock, table.grid-all tfoot &gt; tr &gt; td.tableblock { border-width: 1px 1px 0 0; }  table.grid-cols th.tableblock, table.grid-cols td.tableblock { border-width: 0 1px 0 0; }  table.grid-all * &gt; tr &gt; .tableblock:last-child, table.grid-cols * &gt; tr &gt; .tableblock:last-child { border-right-width: 0; }  table.grid-rows th.tableblock, table.grid-rows td.tableblock { border-width: 0 0 1px 0; }  table.grid-all tbody &gt; tr:last-child &gt; th.tableblock, table.grid-all tbody &gt; tr:last-child &gt; td.tableblock, table.grid-all thead:last-child &gt; tr &gt; th.tableblock, table.grid-rows tbody &gt; tr:last-child &gt; th.tableblock, table.grid-rows tbody &gt; tr:last-child &gt; td.tableblock, table.grid-rows thead:last-child &gt; tr &gt; th.tableblock { border-bottom-width: 0; }  table.grid-rows tfoot &gt; tr &gt; th.tableblock, table.grid-rows tfoot &gt; tr &gt; td.tableblock { border-width: 1px 0 0 0; }  table.frame-all { border-width: 1px; }  table.frame-sides { border-width: 0 1px; }  table.frame-topbot { border-width: 1px 0; }  th.halign-left, td.halign-left { text-align: left; }  th.halign-right, td.halign-right { text-align: right; }  th.halign-center, td.halign-center { text-align: center; }  th.valign-top, td.valign-top { vertical-align: top; }  th.valign-bottom, td.valign-bottom { vertical-align: bottom; }  th.valign-middle, td.valign-middle { vertical-align: middle; }  table thead th, table tfoot th { font-weight: bold; }  tbody tr th { display: table-cell; line-height: 1.4; background: whitesmoke; }  tbody tr th, tbody tr th p, tfoot tr th, tfoot tr th p { color: #222222; font-weight: bold; }  p.tableblock &gt; code:only-child { background: none; padding: 0; }  table tr.even, table tr.alt, table tr:nth-of-type(2n) {     background: #f9f9f9 none repeat scroll 0 0; } div.table-responsive {  border: 0; }  .sql p {  font-family: courier; } &lt;/style&gt;&lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.2.0/css/font-awesome.min.css&quot;&gt;&lt;div id=&quot;content&quot; class=&quot;blog-post-asciidoc&quot;&gt;&lt;div class=&quot;article&quot;&gt;           &lt;div id=&quot;preamble&quot;&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div id=&quot;__asciidoctor-preview-472__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;This blog post will introduce you to building service block architectures using &lt;a href=&quot;https://spring.io/blog/2017/07/05/introducing-spring-cloud-function&quot; target=&quot;_blank&quot;&gt;Spring Cloud Function&lt;/a&gt; and &lt;a href=&quot;https://en.wikipedia.org/wiki/AWS_Lambda&quot; target=&quot;_blank&quot;&gt;AWS Lambda&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_what_is_spring_cloud_function&quot;&gt;What is Spring Cloud Function?&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div id=&quot;__asciidoctor-preview-494__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/spring-cloud/spring-cloud-function&quot; target=&quot;_blank&quot;&gt;Spring Cloud Function&lt;/a&gt; is a project from &lt;a href=&quot;https://pivotal.io/&quot; target=&quot;_blank&quot;&gt;Pivotal&lt;/a&gt; that brings the same popular fundamentals behind &lt;a href=&quot;https://projects.spring.io/spring-boot/&quot; target=&quot;_blank&quot;&gt;Spring Boot&lt;/a&gt; to &lt;a href=&quot;https://martinfowler.com/articles/serverless.html&quot; target=&quot;_blank&quot;&gt;serverless functions&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_service_block_architecture&quot;&gt;Service Block Architecture&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div id=&quot;__asciidoctor-preview-512__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;One of the most important considerations in software design is modularity. If we think about modularity in the mechanical sense, components of a system are designed as modules that can be replaced in the event of a mechanical failure. In the engine of a car, for example, you do not need to replace the entire engine if a single spark plug fails.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-516__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;In software, modularity allows you to &lt;em&gt;design&lt;/em&gt; for change.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-520__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;Modularity also gives developers a shared map that can be used to &lt;em&gt;reason&lt;/em&gt; about the functionality of an application. By being able to visualize and map out the complex processes that are orchestrated by an application’s source code, developers and architects alike can more easily visualize where to make a change with surgical precision.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_changing_software&quot;&gt;Changing software&lt;/h3&gt;&lt;div id=&quot;__asciidoctor-preview-534__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;In many ways, we should consider ourselves lucky to be building software instead of cars. Some of today’s most valuable companies are created using bits and bytes instead of plastic and metal. But despite these advances, the very best car company releases less often than the world’s very worst software company.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-538__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;An application’s source code is a system of connected bits and bytes that is always evolving—one change after another. But, as the source code of a system expands or contracts, small changes require us to build and deploy entire applications.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-542__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;To make one small code change to a production environment, we are required to deploy everything else we didn’t change.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-546__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;When teams share a deployment pipeline for an application, teams become forced to plan around a schedule they have little or no control over. For this reason, innovation is stifled—as developers must wait for the next bus before they can get any feedback about their changes.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-550__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;The result of building microservices is an ever increasing number of pathways to production. With more and more microservices, the amount of unchanged code per deployment decreases when measured across all applications. It’s the decomposition in microservices that ends up breeding lower unchanged code deployed over time—an &lt;em&gt;important&lt;/em&gt; metric. Serverless functions can help to get this number even lower—as the unit of change becomes the function. But, how do microservices and serverless functions fit together?&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_service_blocks&quot;&gt;Service Blocks&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div id=&quot;__asciidoctor-preview-568__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;Service blocks are &lt;a href=&quot;https://pivotal.io/cloud-native&quot; target=&quot;_blank&quot;&gt;cloud-native applications&lt;/a&gt; that share many characteristics with microservices. The key difference with microservices is that a service block is a &lt;a href=&quot;http://scs-architecture.org/&quot; target=&quot;_blank&quot;&gt;self-contained system&lt;/a&gt; that has &lt;em&gt;multiple&lt;/em&gt; independently deployable units—mixing together serverless functions with &lt;a href=&quot;https://linuxcontainers.org/&quot; target=&quot;_blank&quot;&gt;containers&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-572__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;div class=&quot;imageblock&quot; style=&quot;display: block; padding: inherit; max-width:30em;&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;img alt=&quot;Service Block Spring Cloud Function&quot; src=&quot;http://imgur.com/yLwadYi.png&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-576__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;While microservices can be created entirely as serverless functions, a service block focuses on a contextual model that combines together traditional &quot;always-on&quot; applications with portable on-demand functions.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_the_patterns&quot;&gt;The Patterns&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div id=&quot;__asciidoctor-preview-592__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;The basic pattern of a service block combines a core application running in a container with a collection of serverless functions.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-596__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;div class=&quot;imageblock&quot; style=&quot;display: block; padding: inherit; max-width:60em;&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;img alt=&quot;Service Block Patterns Spring Cloud Function&quot; src=&quot;http://imgur.com/iWAEQBw.png&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;a name=&#39;more&#39;&gt;&lt;/a&gt;&lt;p&gt;&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-600__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;A basic service block will contain a single Spring Boot application (service core) that communicates with serverless functions.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-604__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;In this post we will focus on a basic service block, which are composed of two things:&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-610__&quot; class=&quot;ulist&quot;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Service Cores&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Functions&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_service_cores&quot;&gt;Service Cores&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div id=&quot;__asciidoctor-preview-644__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;Each service block will have a primary application container that communicates with other &lt;a href=&quot;https://12factor.net/backing-services&quot; target=&quot;_blank&quot;&gt;backing services&lt;/a&gt;, such as a database or a message broker. These application containers are called &lt;em&gt;service cores&lt;/em&gt;. Cores are responsible for dispatching events to serverless functions that are deployed inside of the boundary of a service block.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-658__&quot; class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 1. The core of a service block&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div id=&quot;__asciidoctor-preview-664__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;div class=&quot;imageblock&quot; style=&quot;display: block; padding: inherit; max-width:40em;&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;img alt=&quot;Service Block Cores Spring Cloud Function&quot; src=&quot;http://i.imgur.com/bHe0D5p.png&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-668__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;In the diagram above, you’ll see a service core that is sending events to two different functions deployed to &lt;a href=&quot;https://aws.amazon.com/lambda/&quot; target=&quot;_blank&quot;&gt;AWS Lambda&lt;/a&gt;. For this example, the functions contain the business logic for most of the application. The &lt;em&gt;State Machine Function&lt;/em&gt; includes the recipe for each domain aggregate. This function will use event sourcing to replicate the current state of domain aggregates from a stream of events, which is an approach called &lt;a href=&quot;http://www.kennybastani.com/2016/04/event-sourcing-microservices-spring-cloud.html&quot; target=&quot;_blank&quot;&gt;event sourcing&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-672__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;The &lt;em&gt;Metrics Function&lt;/em&gt; does something similar. Each instance of a service core will emit operational events to the &lt;em&gt;Metrics Function&lt;/em&gt;. These metrics can then be event sourced into reactive views that are exposed as a REST API to service consumers. You can also feed these events into an operational matrix of functions that can be used to automate tasks that keep each application instance healthy.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_anatomy_of_a_function&quot;&gt;Anatomy of a Function&lt;/h3&gt;&lt;div id=&quot;__asciidoctor-preview-690__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;The anatomy of a basic Spring Cloud Function project is quite simple.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-702__&quot; class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 2. A simple metrics function&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div id=&quot;__asciidoctor-preview-716__&quot; class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-java hljs&quot; data-lang=&quot;java&quot;&gt;&lt;span class=&quot;hljs-meta&quot;&gt;@SpringBootApplication&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-class&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;MetricsFunction&lt;/span&gt; &lt;/span&gt;{&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(String[] args)&lt;/span&gt; &lt;/span&gt;{&lt;br /&gt;        SpringApplication.run(MetricsFunction.class, args);&lt;br /&gt;    }&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-meta&quot;&gt;@Bean&lt;/span&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; Function&amp;lt;MetricEvent, View&amp;gt; &lt;span class=&quot;hljs-title&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(MongoTemplate mongoTemplate)&lt;/span&gt; &lt;/span&gt;{&lt;br /&gt;        &lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; metricEvent -&amp;gt; {&lt;br /&gt;            &lt;span class=&quot;hljs-comment&quot;&gt;// Get the event&#39;s key to lookup a view&lt;/span&gt;&lt;br /&gt;            String key = metricEvent.getKey();&lt;br /&gt;&lt;br /&gt;            &lt;span class=&quot;hljs-comment&quot;&gt;// Find the view&#39;s document if it exists, if not, insert a new one&lt;/span&gt;&lt;br /&gt;            Query updateQuery = &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; Query(Criteria.where(&lt;span class=&quot;hljs-string&quot;&gt;&quot;_id&quot;&lt;/span&gt;).is(key));&lt;br /&gt;&lt;br /&gt;            &lt;span class=&quot;hljs-comment&quot;&gt;// Increment the event&#39;s match count&lt;/span&gt;&lt;br /&gt;            Update update = &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; Update().inc(&lt;span class=&quot;hljs-string&quot;&gt;&quot;matches&quot;&lt;/span&gt;, &lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;)&lt;br /&gt;                    .set(&lt;span class=&quot;hljs-string&quot;&gt;&quot;lastModified&quot;&lt;/span&gt;, metricEvent.getLastModified());&lt;br /&gt;&lt;br /&gt;            &lt;span class=&quot;hljs-comment&quot;&gt;// Apply the increment or insert a new document and return the result&lt;/span&gt;&lt;br /&gt;            View viewResult = mongoTemplate.findAndModify(updateQuery, update,&lt;br /&gt;                    &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; FindAndModifyOptions().returnNew(&lt;span class=&quot;hljs-keyword&quot;&gt;true&lt;/span&gt;).upsert(&lt;span class=&quot;hljs-keyword&quot;&gt;true&lt;/span&gt;), View.class);&lt;br /&gt;&lt;br /&gt;            &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (viewResult.getMatches() &amp;lt;= &lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;) {&lt;br /&gt;                mongoTemplate.save(viewResult);&lt;br /&gt;            }&lt;br /&gt;&lt;br /&gt;            &lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; viewResult;&lt;br /&gt;        };&lt;br /&gt;    }&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-720__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;The example above is a Spring Boot application that uses Spring Cloud Function to collect metric events from a service core and update a view in a &lt;a href=&quot;https://en.wikipedia.org/wiki/MongoDB&quot; target=&quot;_blank&quot;&gt;MongoDB&lt;/a&gt; database. Now, going back to the diagram from earlier, we can begin to connect the dots on how events get generated from the service core.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-724__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;div class=&quot;imageblock&quot; style=&quot;display: block; padding: inherit; max-width:40em;&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;img alt=&quot;Service Block Cores Spring Cloud Function&quot; src=&quot;http://i.imgur.com/bHe0D5p.png&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-728__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;Incoming requests to the service core will come in the form of commands. These commands map to &lt;a href=&quot;https://docs.spring.io/spring/docs/current/spring-framework-reference/html/mvc.html&quot; target=&quot;_blank&quot;&gt;Spring MVC controllers&lt;/a&gt; that will emit events to functions that are deployed to AWS Lambda. The service core in this example shares a MongoDB database with its functions. By sharing this data source, view updates can be subscribed to without waiting for a response to return from a Lambda function.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-732__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;Further, with &lt;a href=&quot;https://github.com/spring-projects/spring-data-examples/tree/master/mongodb/reactive&quot; target=&quot;_blank&quot;&gt;reactive repository support&lt;/a&gt; in MongoDB, consumers can reactively monitor for events in real-time from AWS Lambda functions.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-744__&quot; class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 3. Reactive stream of metric events from MongoDB&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div id=&quot;__asciidoctor-preview-758__&quot; class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-java hljs&quot; data-lang=&quot;java&quot;&gt;&lt;span class=&quot;hljs-meta&quot;&gt;@GetMapping&lt;/span&gt;(value = &lt;span class=&quot;hljs-string&quot;&gt;&quot;/metricEvents&quot;&lt;/span&gt;, produces = MediaType.TEXT_EVENT_STREAM_VALUE)&lt;br /&gt;    &lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; Flux&amp;lt;ServerSentEvent&amp;lt;MetricView&amp;gt;&amp;gt; streamEvents(&lt;span class=&quot;hljs-meta&quot;&gt;@PathVariable&lt;/span&gt; String key,&lt;br /&gt;      HttpServletRequest request) {&lt;br /&gt;        &lt;span class=&quot;hljs-comment&quot;&gt;// Stream the events from MongoDB&lt;/span&gt;&lt;br /&gt;        Flux&amp;lt;MetricView&amp;gt; events = eventRepository.findByKey(key);&lt;br /&gt;&lt;br /&gt;        &lt;span class=&quot;hljs-comment&quot;&gt;// Check if this is an SSE reconnection from a client&lt;/span&gt;&lt;br /&gt;        String lastEventId = request.getHeader(&lt;span class=&quot;hljs-string&quot;&gt;&quot;Last-Event-Id&quot;&lt;/span&gt;);&lt;br /&gt;&lt;br /&gt;        &lt;span class=&quot;hljs-comment&quot;&gt;// On SSE client reconnect, skip ahead in the stream to play back only new events&lt;/span&gt;&lt;br /&gt;        &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (lastEventId != &lt;span class=&quot;hljs-keyword&quot;&gt;null&lt;/span&gt;)&lt;br /&gt;            events = events.skipUntil(e -&amp;gt; e.getId().equals(lastEventId)).skip(&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;);&lt;br /&gt;&lt;br /&gt;        &lt;span class=&quot;hljs-comment&quot;&gt;// Subscribe to the tailing events from the reactive repository query&lt;/span&gt;&lt;br /&gt;        &lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; events.map(event -&amp;gt; ServerSentEvent.builder(event)&lt;br /&gt;                .event(s.getCreatedDate().toString())&lt;br /&gt;                .id(event.getId())&lt;br /&gt;                .build())&lt;br /&gt;                .delayElements(Duration.ofMillis(&lt;span class=&quot;hljs-number&quot;&gt;100&lt;/span&gt;));&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-762__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;In the example above, you’ll see a controller method that returns a &lt;code&gt;Flux&lt;/code&gt; of &lt;code&gt;ServerSentEvent&amp;lt;MetricView&amp;gt;&lt;/code&gt;. This method sits on the service core, and will monitor a MongoDB collection for new events and emit them every 100ms. A &lt;a href=&quot;https://en.wikipedia.org/wiki/Server-sent_events&quot; target=&quot;_blank&quot;&gt;Server-Sent Event&lt;/a&gt; is a technology that allows consumers to subscribe to events emitted by an HTTP server. In the case that an HTTP disconnect occurs, which is a frequent scenario, the client will send another request with the &lt;code&gt;Last-Event-Id&lt;/code&gt; field in the headers. This allows the reactive event stream to resume where it last left off.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_example_project&quot;&gt;Example Project&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div id=&quot;__asciidoctor-preview-780__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;I’ve put together an &lt;a href=&quot;https://github.com/kbastani/service-block-samples/tree/master/basic-block&quot; target=&quot;_blank&quot;&gt;example project&lt;/a&gt; that demonstrates the basics of a service block architecture with Spring Cloud Function. This will be the first of &lt;a href=&quot;https://github.com/kbastani/service-block-samples&quot; target=&quot;_blank&quot;&gt;multiple examples&lt;/a&gt;, each demonstrating a different service block pattern. For this first service block, we’ll create an account service that dispatches events to a Spring Cloud Function app on AWS Lambda.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-784__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;The concerns we’ll be going over in this post:&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-790__&quot; class=&quot;ulist&quot;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Service Core&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Functions&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Deployment&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Lambda Invocation&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_service_core&quot;&gt;Service Core&lt;/h3&gt;&lt;div id=&quot;__asciidoctor-preview-842__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;In this example, an &lt;a href=&quot;https://github.com/kbastani/service-block-samples/tree/master/basic-block/account-core&quot; target=&quot;_blank&quot;&gt;account service core&lt;/a&gt; allows consumers to manage records using a workflow that is common to &lt;a href=&quot;https://martinfowler.com/bliki/CQRS.html&quot; target=&quot;_blank&quot;&gt;CQRS&lt;/a&gt; and Event Sourcing applications.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-856__&quot; class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 4. Events and commands are attached to an account aggregate&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div id=&quot;__asciidoctor-preview-862__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;div class=&quot;imageblock&quot; style=&quot;display: block; padding: inherit; max-width:40em;&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;img alt=&quot;CQRS Hypermedia Resource&quot; src=&quot;http://imgur.com/2R2w79p.png&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-866__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;In the diagram above you’ll see an account resource that is connected to a set of &lt;em&gt;commands&lt;/em&gt; and &lt;em&gt;events&lt;/em&gt;. One of the goals in the &lt;em&gt;account service core&lt;/em&gt; is to enable a CQRS workflow for interacting with &lt;a href=&quot;https://martinfowler.com/bliki/DDD_Aggregate.html&quot; target=&quot;_blank&quot;&gt;domain aggregates&lt;/a&gt;. To make it easy for other microservices to consume this &lt;a href=&quot;https://en.wikipedia.org/wiki/Event-driven_architecture&quot; target=&quot;_blank&quot;&gt;event-driven&lt;/a&gt; workflow, we can conveniently embed hypermedia links to both the event log and commands.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;sect3&quot;&gt;&lt;h4 id=&quot;_creating_an_account&quot;&gt;Creating an Account&lt;/h4&gt;&lt;div id=&quot;__asciidoctor-preview-882__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;The first concern we should address in the service core is to create an endpoint for creating new accounts.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-894__&quot; class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 5. Snippet from the &lt;code&gt;AccountController&lt;/code&gt; class&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div id=&quot;__asciidoctor-preview-908__&quot; class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-java hljs&quot; data-lang=&quot;java&quot;&gt;&lt;span class=&quot;hljs-meta&quot;&gt;@RestController&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;hljs-meta&quot;&gt;@RequestMapping&lt;/span&gt;(&lt;span class=&quot;hljs-string&quot;&gt;&quot;/v1&quot;&lt;/span&gt;)&lt;br /&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-class&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;AccountController&lt;/span&gt; &lt;/span&gt;{&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-meta&quot;&gt;@PostMapping&lt;/span&gt;(path = &lt;span class=&quot;hljs-string&quot;&gt;&quot;/accounts&quot;&lt;/span&gt;)&lt;br /&gt;    &lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; ResponseEntity &lt;span class=&quot;hljs-title&quot;&gt;createAccount&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(@RequestBody Account account)&lt;/span&gt; &lt;/span&gt;{&lt;br /&gt;        &lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; Optional.ofNullable(createAccountResource(account))&lt;br /&gt;                .map(e -&amp;gt; &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; ResponseEntity&amp;lt;&amp;gt;(e, HttpStatus.CREATED))&lt;br /&gt;                .orElseThrow(() -&amp;gt; &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; RuntimeException(&lt;span class=&quot;hljs-string&quot;&gt;&quot;Account creation failed&quot;&lt;/span&gt;));&lt;br /&gt;    }&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-912__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;The snippet above is from the service core’s &lt;a href=&quot;https://github.com/kbastani/service-block-samples/blob/master/basic-block/account-core/src/main/java/demo/account/AccountController.java&quot; target=&quot;_blank&quot;&gt;AccountController&lt;/a&gt; class. Let’s see what happens when we try to create a new &lt;code&gt;Account&lt;/code&gt; over HTTP.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-924__&quot; class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 6. HTTP POST request to &lt;code&gt;/v1/accounts&lt;/code&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div id=&quot;__asciidoctor-preview-938__&quot; class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-bash hljs&quot; data-lang=&quot;bash&quot;&gt;HTTP POST /v1/accounts&lt;br /&gt;&lt;br /&gt;{&lt;br /&gt;  &lt;span class=&quot;hljs-string&quot;&gt;&quot;firstName&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-string&quot;&gt;&quot;Taylor&quot;&lt;/span&gt;,&lt;br /&gt;  &lt;span class=&quot;hljs-string&quot;&gt;&quot;lastName&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-string&quot;&gt;&quot;Swift&quot;&lt;/span&gt;,&lt;br /&gt;  &lt;span class=&quot;hljs-string&quot;&gt;&quot;email&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-string&quot;&gt;&quot;tswift@cloud.com&quot;&lt;/span&gt;&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-942__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;In the snippet above, we’ve sent a POST request with the information of the new account we’d like to create. After sending the request, we’ll get back an &lt;a href=&quot;https://github.com/kbastani/service-block-samples/blob/master/basic-block/account-core/src/main/java/demo/account/Account.java&quot; target=&quot;_blank&quot;&gt;Account&lt;/a&gt; resource that contains the newly minted account.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-954__&quot; class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 7. The new account resource with hypermedia links&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div id=&quot;__asciidoctor-preview-968__&quot; class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-json hljs&quot; data-lang=&quot;json&quot;&gt;{&lt;br /&gt;  &lt;span class=&quot;hljs-attr&quot;&gt;&quot;createdAt&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-number&quot;&gt;1491473123758&lt;/span&gt;,&lt;br /&gt;  &lt;span class=&quot;hljs-attr&quot;&gt;&quot;lastModified&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-number&quot;&gt;1491473123758&lt;/span&gt;,&lt;br /&gt;  &lt;span class=&quot;hljs-attr&quot;&gt;&quot;firstName&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-string&quot;&gt;&quot;Taylor&quot;&lt;/span&gt;,&lt;br /&gt;  &lt;span class=&quot;hljs-attr&quot;&gt;&quot;lastName&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-string&quot;&gt;&quot;Swift&quot;&lt;/span&gt;,&lt;br /&gt;  &lt;span class=&quot;hljs-attr&quot;&gt;&quot;email&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-string&quot;&gt;&quot;tswift@cloud.com&quot;&lt;/span&gt;,&lt;br /&gt;  &lt;span class=&quot;hljs-attr&quot;&gt;&quot;status&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-string&quot;&gt;&quot;ACCOUNT_CREATED&quot;&lt;/span&gt;,&lt;br /&gt;  &lt;span class=&quot;hljs-attr&quot;&gt;&quot;_links&quot;&lt;/span&gt;: {&lt;br /&gt;    &lt;span class=&quot;hljs-attr&quot;&gt;&quot;commands&quot;&lt;/span&gt;: {&lt;br /&gt;      &lt;span class=&quot;hljs-attr&quot;&gt;&quot;href&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-string&quot;&gt;&quot;http://localhost:8080/v1/accounts/1/commands&quot;&lt;/span&gt;&lt;br /&gt;    },&lt;br /&gt;    &lt;span class=&quot;hljs-attr&quot;&gt;&quot;events&quot;&lt;/span&gt;: {&lt;br /&gt;      &lt;span class=&quot;hljs-attr&quot;&gt;&quot;href&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-string&quot;&gt;&quot;http://localhost:8080/v1/accounts/1/events&quot;&lt;/span&gt;&lt;br /&gt;    }&lt;br /&gt;  },&lt;br /&gt;  &lt;span class=&quot;hljs-attr&quot;&gt;&quot;accountId&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-972__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;Here we see the &lt;code&gt;Account&lt;/code&gt; that we just created. Notice that there are two hypermedia links in the response body for the &lt;code&gt;_links&lt;/code&gt; property. We can think of these &lt;a href=&quot;https://spring.io/understanding/HATEOAS&quot; target=&quot;_blank&quot;&gt;hypermedia links&lt;/a&gt; as if they were methods in the &lt;code&gt;Account&lt;/code&gt; class. If we want to access the available commands for an &lt;code&gt;Account&lt;/code&gt;, we can simply traverse the link for &lt;code&gt;commands&lt;/code&gt;, which returns a response containing the commands that can be executed on the account.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-978__&quot; class=&quot;admonitionblock tip&quot;&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;icon&quot;&gt;&lt;i class=&quot;fa icon-tip&quot; title=&quot;Tip&quot;&gt;&lt;/i&gt;&lt;/td&gt;&lt;td class=&quot;content&quot;&gt;By keeping the event log attached as a link on the account resource, all consumers will be able to easily locate the events that have affected the account’s current state. &lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_the_commands&quot;&gt;The Commands&lt;/h3&gt;&lt;div id=&quot;__asciidoctor-preview-996__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;Next, let’s fetch the commands that are available for the &lt;code&gt;Account&lt;/code&gt; resource. To do this, we’ll send an HTTP GET request to the location &lt;code&gt;href&lt;/code&gt; listed on the hypermedia link named &lt;code&gt;commands&lt;/code&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1008__&quot; class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 8. HTTP GET request to &lt;code&gt;/v1/accounts/1/commands&lt;/code&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div id=&quot;__asciidoctor-preview-1022__&quot; class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-json hljs&quot; data-lang=&quot;json&quot;&gt;{&lt;br /&gt;  &lt;span class=&quot;hljs-attr&quot;&gt;&quot;_links&quot;&lt;/span&gt;: {&lt;br /&gt;    &lt;span class=&quot;hljs-attr&quot;&gt;&quot;activate&quot;&lt;/span&gt;: {&lt;br /&gt;      &lt;span class=&quot;hljs-attr&quot;&gt;&quot;href&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-string&quot;&gt;&quot;http://localhost:8080/v1/accounts/1/commands/activate&quot;&lt;/span&gt;&lt;br /&gt;    },&lt;br /&gt;    &lt;span class=&quot;hljs-attr&quot;&gt;&quot;suspend&quot;&lt;/span&gt;: {&lt;br /&gt;      &lt;span class=&quot;hljs-attr&quot;&gt;&quot;href&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-string&quot;&gt;&quot;http://localhost:8080/v1/accounts/1/commands/suspend&quot;&lt;/span&gt;&lt;br /&gt;    }&lt;br /&gt;  }&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1028__&quot; class=&quot;admonitionblock tip&quot;&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;icon&quot;&gt;&lt;i class=&quot;fa icon-tip&quot; title=&quot;Tip&quot;&gt;&lt;/i&gt;&lt;/td&gt;&lt;td class=&quot;content&quot;&gt;By attaching the commands to an account resource as a hypermedia link, all consumers will be able to easily lookup the commands that can be executed on the resource. &lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1032__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;After traversing to &lt;code&gt;commands&lt;/code&gt;, we are provided back another set of links that we can continue to follow. We see that we can either &lt;code&gt;activate&lt;/code&gt; or &lt;code&gt;suspend&lt;/code&gt; this account. First, let’s try executing the &lt;code&gt;activate&lt;/code&gt; command. To do this, we make an HTTP GET request to the &lt;code&gt;href&lt;/code&gt; associated with the command.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1044__&quot; class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 9. HTTP GET request to &lt;code&gt;/v1/accounts/1/commands/activate&lt;/code&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div id=&quot;__asciidoctor-preview-1058__&quot; class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-json hljs&quot; data-lang=&quot;json&quot;&gt;{&lt;br /&gt;  &lt;span class=&quot;hljs-attr&quot;&gt;&quot;createdAt&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-number&quot;&gt;1491459939554&lt;/span&gt;,&lt;br /&gt;  &lt;span class=&quot;hljs-attr&quot;&gt;&quot;lastModified&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-number&quot;&gt;1491473977565&lt;/span&gt;,&lt;br /&gt;  &lt;span class=&quot;hljs-attr&quot;&gt;&quot;firstName&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-string&quot;&gt;&quot;Taylor&quot;&lt;/span&gt;,&lt;br /&gt;  &lt;span class=&quot;hljs-attr&quot;&gt;&quot;lastName&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-string&quot;&gt;&quot;Swift&quot;&lt;/span&gt;,&lt;br /&gt;  &lt;span class=&quot;hljs-attr&quot;&gt;&quot;email&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-string&quot;&gt;&quot;tswift@cloud.com&quot;&lt;/span&gt;,&lt;br /&gt;  &lt;span class=&quot;hljs-attr&quot;&gt;&quot;status&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-string&quot;&gt;&quot;ACCOUNT_ACTIVATED&quot;&lt;/span&gt;,&lt;br /&gt;  &lt;span class=&quot;hljs-attr&quot;&gt;&quot;_links&quot;&lt;/span&gt;: {&lt;br /&gt;    &lt;span class=&quot;hljs-attr&quot;&gt;&quot;commands&quot;&lt;/span&gt;: {&lt;br /&gt;      &lt;span class=&quot;hljs-attr&quot;&gt;&quot;href&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-string&quot;&gt;&quot;http://localhost:8080/v1/accounts/1/commands&quot;&lt;/span&gt;&lt;br /&gt;    },&lt;br /&gt;    &lt;span class=&quot;hljs-attr&quot;&gt;&quot;events&quot;&lt;/span&gt;: {&lt;br /&gt;      &lt;span class=&quot;hljs-attr&quot;&gt;&quot;href&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-string&quot;&gt;&quot;http://localhost:8080/v1/accounts/1/events&quot;&lt;/span&gt;&lt;br /&gt;    }&lt;br /&gt;  },&lt;br /&gt;  &lt;span class=&quot;hljs-attr&quot;&gt;&quot;accountId&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1062__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;In the example above, we see the command returned back the account resource with a new value for the &lt;code&gt;status&lt;/code&gt; property. After executing the command, the account’s status transitioned from &lt;code&gt;ACCOUNT_CREATED&lt;/code&gt; to &lt;code&gt;ACCOUNT_ACTIVATED&lt;/code&gt;. Let’s try sending the same &lt;code&gt;activate&lt;/code&gt; command twice in a row and see what happens.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1074__&quot; class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 10. 2nd HTTP GET request to &lt;code&gt;/v1/accounts/1/commands/activate&lt;/code&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div id=&quot;__asciidoctor-preview-1088__&quot; class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-json hljs&quot; data-lang=&quot;json&quot;&gt;{&lt;br /&gt;  &lt;span class=&quot;hljs-attr&quot;&gt;&quot;timestamp&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-number&quot;&gt;1491474077084&lt;/span&gt;,&lt;br /&gt;  &lt;span class=&quot;hljs-attr&quot;&gt;&quot;status&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-number&quot;&gt;400&lt;/span&gt;,&lt;br /&gt;  &lt;span class=&quot;hljs-attr&quot;&gt;&quot;error&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-string&quot;&gt;&quot;Bad Request&quot;&lt;/span&gt;,&lt;br /&gt;  &lt;span class=&quot;hljs-attr&quot;&gt;&quot;exception&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-string&quot;&gt;&quot;java.lang.RuntimeException&quot;&lt;/span&gt;,&lt;br /&gt;  &lt;span class=&quot;hljs-attr&quot;&gt;&quot;message&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-string&quot;&gt;&quot;Account already activated&quot;&lt;/span&gt;,&lt;br /&gt;  &lt;span class=&quot;hljs-attr&quot;&gt;&quot;path&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-string&quot;&gt;&quot;/v1/accounts/1/commands/activate&quot;&lt;/span&gt;&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1092__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;As expected, we’ve received an error. This is because the account we created had already been activated. Which means that we cannot issue the same command twice in a row. Now, what’s interesting about this response is that the validation logic is not coming from within the core Spring Boot application. Instead, we have two stateless functions that are deployed to AWS Lambda. These two functions will act as an event handlers — &lt;em&gt;mutating state&lt;/em&gt; based on the current context and command of an account.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1096__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;Now, let’s try the only &lt;em&gt;other&lt;/em&gt; command that is listed on the account resource: &lt;code&gt;suspend&lt;/code&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1108__&quot; class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 11. HTTP GET to &lt;code&gt;/v1/accounts/1/suspend&lt;/code&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div id=&quot;__asciidoctor-preview-1122__&quot; class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-json hljs&quot; data-lang=&quot;json&quot;&gt;{&lt;br /&gt;  &lt;span class=&quot;hljs-attr&quot;&gt;&quot;createdAt&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-number&quot;&gt;1491459939554&lt;/span&gt;,&lt;br /&gt;  &lt;span class=&quot;hljs-attr&quot;&gt;&quot;lastModified&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-number&quot;&gt;1491474306296&lt;/span&gt;,&lt;br /&gt;  &lt;span class=&quot;hljs-attr&quot;&gt;&quot;firstName&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-string&quot;&gt;&quot;Taylor&quot;&lt;/span&gt;,&lt;br /&gt;  &lt;span class=&quot;hljs-attr&quot;&gt;&quot;lastName&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-string&quot;&gt;&quot;Swift&quot;&lt;/span&gt;,&lt;br /&gt;  &lt;span class=&quot;hljs-attr&quot;&gt;&quot;email&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-string&quot;&gt;&quot;tswift@cloud.com&quot;&lt;/span&gt;,&lt;br /&gt;  &lt;span class=&quot;hljs-attr&quot;&gt;&quot;status&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-string&quot;&gt;&quot;ACCOUNT_SUSPENDED&quot;&lt;/span&gt;,&lt;br /&gt;  &lt;span class=&quot;hljs-attr&quot;&gt;&quot;_links&quot;&lt;/span&gt;: {&lt;br /&gt;    &lt;span class=&quot;hljs-attr&quot;&gt;&quot;commands&quot;&lt;/span&gt;: {&lt;br /&gt;      &lt;span class=&quot;hljs-attr&quot;&gt;&quot;href&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-string&quot;&gt;&quot;http://localhost:8080/v1/accounts/1/commands&quot;&lt;/span&gt;&lt;br /&gt;    },&lt;br /&gt;    &lt;span class=&quot;hljs-attr&quot;&gt;&quot;events&quot;&lt;/span&gt;: {&lt;br /&gt;      &lt;span class=&quot;hljs-attr&quot;&gt;&quot;href&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-string&quot;&gt;&quot;http://localhost:8080/v1/accounts/1/events&quot;&lt;/span&gt;&lt;br /&gt;    }&lt;br /&gt;  },&lt;br /&gt;  &lt;span class=&quot;hljs-attr&quot;&gt;&quot;accountId&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1126__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;Now we see that the account response successfully transitioned from &lt;code&gt;ACCOUNT_ACTIVATED&lt;/code&gt; to &lt;code&gt;ACCOUNT_SUSPENDED&lt;/code&gt;, without error. This is a fairly trivial example, where we have two different states that can be transitioned to and from without being applied twice in a row.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1132__&quot; class=&quot;admonitionblock tip&quot;&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;icon&quot;&gt;&lt;i class=&quot;fa icon-tip&quot; title=&quot;Tip&quot;&gt;&lt;/i&gt;&lt;/td&gt;&lt;td class=&quot;content&quot;&gt;Imagine the complexity of a domain aggregate with many different states and rules between transitions. Things can get complicated quickly. To simplify the system design, we can start out by modeling these state transitions as a directed graph, called a &lt;a href=&quot;https://en.wikipedia.org/wiki/Finite-state_machine&quot; target=&quot;_blank&quot;&gt;state machine&lt;/a&gt;. &lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_functions&quot;&gt;Functions&lt;/h3&gt;&lt;div id=&quot;__asciidoctor-preview-1146__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;Now that we’ve seen the workflow in the &lt;em&gt;account service core&lt;/em&gt; for creating and managing accounts, let’s see how the core makes requests to Spring Cloud Function apps deployed to AWS Lambda.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1158__&quot; class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 12. This interface defines functions to invoke on AWS Lambda&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div id=&quot;__asciidoctor-preview-1172__&quot; class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-java hljs&quot; data-lang=&quot;java&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-class&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;interface&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;LambdaFunctionService&lt;/span&gt; &lt;/span&gt;{&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-meta&quot;&gt;@LambdaFunction&lt;/span&gt;(functionName=&lt;span class=&quot;hljs-string&quot;&gt;&quot;account-activated&quot;&lt;/span&gt;, logType = LogType.Tail)&lt;br /&gt;    &lt;span class=&quot;hljs-function&quot;&gt;Account &lt;span class=&quot;hljs-title&quot;&gt;accountActivated&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(AccountEvent event)&lt;/span&gt;&lt;/span&gt;;&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-meta&quot;&gt;@LambdaFunction&lt;/span&gt;(functionName=&lt;span class=&quot;hljs-string&quot;&gt;&quot;account-suspended&quot;&lt;/span&gt;, logType = LogType.Tail)&lt;br /&gt;    &lt;span class=&quot;hljs-function&quot;&gt;Account &lt;span class=&quot;hljs-title&quot;&gt;accountSuspended&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(AccountEvent event)&lt;/span&gt;&lt;/span&gt;;&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1176__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;In the &lt;a href=&quot;https://github.com/kbastani/service-block-samples/blob/master/basic-block/account-core/src/main/java/demo/function/LambdaFunctionService.java&quot; target=&quot;_blank&quot;&gt;interface above&lt;/a&gt; we see two AWS Lambda functions that will handle events for an account, which are triggered by the &lt;code&gt;suspend&lt;/code&gt; and &lt;code&gt;activate&lt;/code&gt; commands.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1190__&quot; class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 13. For transitions in an account’s state, we can invoke an AWS Lambda function&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div id=&quot;__asciidoctor-preview-1196__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;div class=&quot;imageblock&quot; style=&quot;display: block; padding: inherit; max-width:40em;&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;img alt=&quot;Account Service Block&quot; src=&quot;http://imgur.com/S7Xenu0.png&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_the_event_log&quot;&gt;The Event Log&lt;/h3&gt;&lt;div id=&quot;__asciidoctor-preview-1214__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;The goal for each function is to validate the state of the &lt;code&gt;Account&lt;/code&gt; aggregate. This is a simple use case to start out, and as this series continues, we’ll see what more complex service blocks look like. For now, we want our functions to be able to change the &lt;code&gt;status&lt;/code&gt; field on an account. This means that the function will need a history of events that have previously been applied to an &lt;code&gt;Account&lt;/code&gt; aggregate. To be able to see the account’s historical events, we just follow the &lt;code&gt;events&lt;/code&gt; link to fetch the account’s event log.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1226__&quot; class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 14. HTTP GET request to &lt;code&gt;/v1/accounts/1/events&lt;/code&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div id=&quot;__asciidoctor-preview-1240__&quot; class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-json hljs&quot; data-lang=&quot;json&quot;&gt;[&lt;br /&gt;  {&lt;br /&gt;    &lt;span class=&quot;hljs-attr&quot;&gt;&quot;eventId&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;,&lt;br /&gt;    &lt;span class=&quot;hljs-attr&quot;&gt;&quot;type&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-string&quot;&gt;&quot;ACCOUNT_ACTIVATED&quot;&lt;/span&gt;,&lt;br /&gt;    &lt;span class=&quot;hljs-attr&quot;&gt;&quot;accountId&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;,&lt;br /&gt;    &lt;span class=&quot;hljs-attr&quot;&gt;&quot;createdAt&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-number&quot;&gt;1491459944711&lt;/span&gt;,&lt;br /&gt;    &lt;span class=&quot;hljs-attr&quot;&gt;&quot;lastModified&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-number&quot;&gt;1491459944711&lt;/span&gt;&lt;br /&gt;  },&lt;br /&gt;  {&lt;br /&gt;    &lt;span class=&quot;hljs-attr&quot;&gt;&quot;eventId&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-number&quot;&gt;2&lt;/span&gt;,&lt;br /&gt;    &lt;span class=&quot;hljs-attr&quot;&gt;&quot;type&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-string&quot;&gt;&quot;ACCOUNT_SUSPENDED&quot;&lt;/span&gt;,&lt;br /&gt;    &lt;span class=&quot;hljs-attr&quot;&gt;&quot;accountId&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;,&lt;br /&gt;    &lt;span class=&quot;hljs-attr&quot;&gt;&quot;createdAt&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-number&quot;&gt;1491459950342&lt;/span&gt;,&lt;br /&gt;    &lt;span class=&quot;hljs-attr&quot;&gt;&quot;lastModified&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-number&quot;&gt;1491459950342&lt;/span&gt;&lt;br /&gt;  }&lt;br /&gt;]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1244__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;After retrieving the event log for the account, we see two events that were added after executing the &lt;code&gt;activate&lt;/code&gt; and &lt;code&gt;suspend&lt;/code&gt; commands. Each time a command is executed on an account — and if the state of the aggregate is valid — we will apply one new event and append it to the log.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1248__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;Since it’s not practical for a Lambda function to callback to retrieve the event log, we’ll go ahead and send it as an &quot;attachment&quot; to the event’s payload. By doing this, we provide the full context on what has previously happened to the account.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1252__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;The next thing we need to do is to figure out how events are dispatched to Lambda functions. Let’s see how routing is handled from commands that are executed on an account, to events dispatched to functions.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_routing_to_aws_lambda&quot;&gt;Routing to AWS Lambda&lt;/h3&gt;&lt;div id=&quot;__asciidoctor-preview-1272__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;As we saw earlier, the &lt;em&gt;account service core&lt;/em&gt; has a controller class named &lt;code&gt;AccountController&lt;/code&gt;. Yet, we only observed the behavior of this component from the perspective of a REST API consumer. In addition to more basic CRUD operations on an account, the &lt;code&gt;AccountController&lt;/code&gt; allows API consumers to execute commands. These commands will then generate events that are handled by a Spring Cloud Function app.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1284__&quot; class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 15. Activate account command&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div id=&quot;__asciidoctor-preview-1298__&quot; class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-java hljs&quot; data-lang=&quot;java&quot;&gt;&lt;span class=&quot;hljs-meta&quot;&gt;@RequestMapping&lt;/span&gt;(path = &lt;span class=&quot;hljs-string&quot;&gt;&quot;/accounts/{id}/commands/activate&quot;&lt;/span&gt;)&lt;br /&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; ResponseEntity &lt;span class=&quot;hljs-title&quot;&gt;activate&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(@PathVariable Long id)&lt;/span&gt; &lt;/span&gt;{&lt;br /&gt;    &lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; Optional.ofNullable(accountRepository.findOne(id))&lt;br /&gt;            .map(a -&amp;gt; eventService&lt;br /&gt;                    .apply(&lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; AccountEvent(AccountEventType.ACCOUNT_ACTIVATED, id)))&lt;br /&gt;            .map(&lt;span class=&quot;hljs-keyword&quot;&gt;this&lt;/span&gt;::getAccountResource)&lt;br /&gt;            .map(e -&amp;gt; &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; ResponseEntity&amp;lt;&amp;gt;(e, HttpStatus.OK))&lt;br /&gt;            .orElseThrow(() -&amp;gt; &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; RuntimeException(&lt;span class=&quot;hljs-string&quot;&gt;&quot;The command could not be applied&quot;&lt;/span&gt;));&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1302__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;Here we see the method body for a command that activates an account. First, we fetch the &lt;code&gt;Account&lt;/code&gt; from the &lt;code&gt;AccountRepository&lt;/code&gt; by its ID. Next we create a new &lt;code&gt;AccountEvent&lt;/code&gt;. We then send the event to the &lt;a href=&quot;https://github.com/kbastani/service-block-samples/blob/master/basic-block/account-core/src/main/java/demo/event/EventService.java&quot; target=&quot;_blank&quot;&gt;EventService&lt;/a&gt; where the &lt;code&gt;apply&lt;/code&gt; method will figure out where to route this event to.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1314__&quot; class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 16. The apply method routes events to functions&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div id=&quot;__asciidoctor-preview-1328__&quot; class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-java hljs&quot; data-lang=&quot;java&quot;&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; Account &lt;span class=&quot;hljs-title&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(AccountEvent accountEvent)&lt;/span&gt; &lt;/span&gt;{&lt;br /&gt;    Assert.notNull(accountEvent.getAccountId(),&lt;br /&gt;            &lt;span class=&quot;hljs-string&quot;&gt;&quot;Account event must contain a valid account id&quot;&lt;/span&gt;);&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-comment&quot;&gt;// Get the account referenced by the event&lt;/span&gt;&lt;br /&gt;    Account account = accountRepository.findOne(accountEvent.getAccountId());&lt;br /&gt;    Assert.notNull(account, &lt;span class=&quot;hljs-string&quot;&gt;&quot;An account for that ID does not exist&quot;&lt;/span&gt;);&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-comment&quot;&gt;// Get a history of events for this account&lt;/span&gt;&lt;br /&gt;    List&amp;lt;AccountEvent&amp;gt; events = accountEventRepository&lt;br /&gt;            .findEventsByAccountId(accountEvent.getAccountId());&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-comment&quot;&gt;// Sort the events reverse chronological&lt;/span&gt;&lt;br /&gt;    events.sort(Comparator.comparing(AccountEvent::getCreatedAt).reversed());&lt;br /&gt;&lt;br /&gt;    LambdaResponse&amp;lt;Account&amp;gt; result = &lt;span class=&quot;hljs-keyword&quot;&gt;null&lt;/span&gt;;&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-comment&quot;&gt;// Route requests to serverless functions&lt;/span&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-keyword&quot;&gt;switch&lt;/span&gt; (accountEvent.getType()) {&lt;br /&gt;        &lt;span class=&quot;hljs-keyword&quot;&gt;case&lt;/span&gt; ACCOUNT_ACTIVATED:&lt;br /&gt;            result = accountCommandService.getActivateAccount()&lt;br /&gt;                    .apply(withPayload(accountEvent, events, account));&lt;br /&gt;            &lt;span class=&quot;hljs-keyword&quot;&gt;break&lt;/span&gt;;&lt;br /&gt;        &lt;span class=&quot;hljs-keyword&quot;&gt;case&lt;/span&gt; ACCOUNT_SUSPENDED:&lt;br /&gt;            result = accountCommandService.getSuspendAccount()&lt;br /&gt;                    .apply(withPayload(accountEvent, events, account));&lt;br /&gt;            &lt;span class=&quot;hljs-keyword&quot;&gt;break&lt;/span&gt;;&lt;br /&gt;    }&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-comment&quot;&gt;// ...&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; account;&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1332__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;The example snippet above shows how account events are dispatched to AWS Lambda functions. Depending on the &lt;code&gt;AccountEventType&lt;/code&gt;, the &lt;a href=&quot;https://github.com/kbastani/service-block-samples/blob/master/basic-block/account-core/src/main/java/demo/function/AccountCommandService.java&quot; target=&quot;_blank&quot;&gt;AccountCommandService&lt;/a&gt; will route the event request to a specific function deployed to AWS Lambda.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_functions_2&quot;&gt;Functions&lt;/h3&gt;&lt;div id=&quot;__asciidoctor-preview-1346__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;Now that the &lt;em&gt;account service core&lt;/em&gt; is ready to start dispatching events to AWS Lambda, it’s time to set up our Spring Cloud Function handlers.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1350__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;This example contains two Spring Cloud Function projects:&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1356__&quot; class=&quot;ulist&quot;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/kbastani/service-block-samples/tree/master/basic-block/account-functions/account-activated&quot; target=&quot;_blank&quot;&gt;Account Activated&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/kbastani/service-block-samples/tree/master/basic-block/account-functions/account-suspended&quot; target=&quot;_blank&quot;&gt;Account Suspended&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1378__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;Each of these projects are near identical, for simplicity’s sake. In the next part of this series we will look at consolidating the business logic for state transitions into a single function.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1382__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;Let’s explore the &lt;code&gt;account-activated&lt;/code&gt; function, assuming that &lt;code&gt;account-suspended&lt;/code&gt; has near to the same source code.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;sect3&quot;&gt;&lt;h4 id=&quot;_handler&quot;&gt;Handler&lt;/h4&gt;&lt;div id=&quot;__asciidoctor-preview-1394__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;Each Spring Cloud Function project has a handler that describes the inputs and outputs of a function.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1406__&quot; class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 17. The essential Spring Boot request handler&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div id=&quot;__asciidoctor-preview-1420__&quot; class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-java hljs&quot; data-lang=&quot;java&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-class&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;Handler&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;SpringBootRequestHandler&lt;/span&gt;&amp;lt;&lt;span class=&quot;hljs-title&quot;&gt;AccountEvent&lt;/span&gt;, &lt;span class=&quot;hljs-title&quot;&gt;Account&lt;/span&gt;&amp;gt; &lt;/span&gt;{&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1424__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;In the example above, not much is going on—but this little class is essential to a Spring Cloud Function application. This class describes how this function should be requested, and what the input and output types are. The only other requirement is that we define a functional bean that implements the business logic of the function.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1436__&quot; class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 18. A function’s application class&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div id=&quot;__asciidoctor-preview-1450__&quot; class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-java hljs&quot; data-lang=&quot;java&quot;&gt;&lt;span class=&quot;hljs-meta&quot;&gt;@SpringBootApplication&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-class&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;AccountActivatedFunction&lt;/span&gt; &lt;/span&gt;{&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(String[] args)&lt;/span&gt; &lt;/span&gt;{&lt;br /&gt;        SpringApplication.run(AccountActivatedFunction.class, args);&lt;br /&gt;    }&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-meta&quot;&gt;@Bean&lt;/span&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; Function&amp;lt;AccountEvent, Account&amp;gt; &lt;span class=&quot;hljs-title&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;br /&gt;        &lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; accountEvent -&amp;gt; {&lt;br /&gt;            &lt;span class=&quot;hljs-comment&quot;&gt;// Get event log from payload&lt;/span&gt;&lt;br /&gt;            List&amp;lt;AccountEvent&amp;gt; events = accountEvent.getPayload().getEvents();&lt;br /&gt;&lt;br /&gt;            &lt;span class=&quot;hljs-comment&quot;&gt;// Get account&lt;/span&gt;&lt;br /&gt;            Account account = accountEvent.getPayload().getAccount();&lt;br /&gt;&lt;br /&gt;            &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt;(events != &lt;span class=&quot;hljs-keyword&quot;&gt;null&lt;/span&gt; &amp;amp;&amp;amp; account != &lt;span class=&quot;hljs-keyword&quot;&gt;null&lt;/span&gt;) {&lt;br /&gt;                &lt;span class=&quot;hljs-comment&quot;&gt;// Get the most recent event&lt;/span&gt;&lt;br /&gt;                AccountEvent lastEvent = events.stream().findFirst().orElse(&lt;span class=&quot;hljs-keyword&quot;&gt;null&lt;/span&gt;);&lt;br /&gt;&lt;br /&gt;                &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt;(lastEvent == &lt;span class=&quot;hljs-keyword&quot;&gt;null&lt;/span&gt; || lastEvent.getType() != ACCOUNT_ACTIVATED) {&lt;br /&gt;                    account.setStatus(AccountStatus.ACCOUNT_ACTIVATED);&lt;br /&gt;                } &lt;span class=&quot;hljs-keyword&quot;&gt;else&lt;/span&gt; {&lt;br /&gt;                    &lt;span class=&quot;hljs-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; RuntimeException(&lt;span class=&quot;hljs-string&quot;&gt;&quot;Account already activated&quot;&lt;/span&gt;);&lt;br /&gt;                }&lt;br /&gt;            } &lt;span class=&quot;hljs-keyword&quot;&gt;else&lt;/span&gt; {&lt;br /&gt;                &lt;span class=&quot;hljs-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; RuntimeException(&lt;span class=&quot;hljs-string&quot;&gt;&quot;Payload did not supply account events&quot;&lt;/span&gt;);&lt;br /&gt;            }&lt;br /&gt;&lt;br /&gt;            &lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; account;&lt;br /&gt;        };&lt;br /&gt;    }&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1454__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;In the example above, we have our Spring Boot application class. This will be our entry point into the function. Here we describe a function bean that each and every event dispatched by the &lt;em&gt;account service core&lt;/em&gt; will be handled from.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1458__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;Now we have a runnable function that we can ship to AWS Lambda. We can even run this function locally for testing purposes. But to invoke the function from the &lt;em&gt;account service core&lt;/em&gt;, we’ll need to deploy it to AWS Lambda.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1464__&quot; class=&quot;admonitionblock caution&quot;&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;icon&quot;&gt;&lt;i class=&quot;fa icon-caution&quot; title=&quot;Caution&quot;&gt;&lt;/i&gt;&lt;/td&gt;&lt;td class=&quot;content&quot;&gt;There are some other things that we do need to worry about in the &lt;code&gt;pom.xml&lt;/code&gt;, but for now we’ll leave that to some upcoming documentation efforts. &lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_deployment&quot;&gt;Deployment&lt;/h3&gt;&lt;div id=&quot;__asciidoctor-preview-1480__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;If you’re familiar with AWS Lambda, you can manually deploy each of the artifacts for the functions using the &lt;a href=&quot;https://console.aws.amazon.com/lambda/home&quot; target=&quot;_blank&quot;&gt;AWS console&lt;/a&gt;. The problem with what I just said is that no one in their right mind would manually deploy artifacts to the cloud, right? To make the DevOps part easy, I’ve created a CI/CD pipeline with a tool named &lt;a href=&quot;http://concourse.ci/&quot; target=&quot;_blank&quot;&gt;Concourse&lt;/a&gt; that will automate the Lambda deployment.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1484__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;To automate the deployment, we’re going to use &lt;a href=&quot;https://aws.amazon.com/cloudformation/&quot; target=&quot;_blank&quot;&gt;CloudFormation&lt;/a&gt;, which provides an easy way to deploy changes for a set of components (known as a stack) as one atomic transaction from the &lt;a href=&quot;https://aws.amazon.com/cli/&quot; target=&quot;_blank&quot;&gt;AWS CLI&lt;/a&gt;. The first thing that is required for CloudFormation is a &lt;a href=&quot;https://aws.amazon.com/cloudformation/aws-cloudformation-templates/&quot; target=&quot;_blank&quot;&gt;template&lt;/a&gt; that describes what it is we want to deploy.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1496__&quot; class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 19. The CloudFormation template for the activated function&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div id=&quot;__asciidoctor-preview-1510__&quot; class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-yaml hljs&quot; data-lang=&quot;yaml&quot;&gt;&lt;span class=&quot;hljs-attr&quot;&gt;AWSTemplateFormatVersion:&lt;/span&gt; &lt;span class=&quot;hljs-string&quot;&gt;&#39;2010-09-09&#39;&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;hljs-attr&quot;&gt;Transform:&lt;/span&gt; &lt;span class=&quot;hljs-string&quot;&gt;&#39;AWS::Serverless-2016-10-31&#39;&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;hljs-attr&quot;&gt;Description:&lt;/span&gt; Account activated&lt;br /&gt;&lt;span class=&quot;hljs-attr&quot;&gt;Resources:&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;hljs-attr&quot;&gt;  accountActivated:&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;hljs-attr&quot;&gt;    Type:&lt;/span&gt; &lt;span class=&quot;hljs-string&quot;&gt;&#39;AWS::Serverless::Function&#39;&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;hljs-attr&quot;&gt;    Properties:&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;hljs-attr&quot;&gt;      Handler:&lt;/span&gt; demo.functions.Handler&lt;br /&gt;&lt;span class=&quot;hljs-attr&quot;&gt;      Runtime:&lt;/span&gt; java8&lt;br /&gt;&lt;span class=&quot;hljs-attr&quot;&gt;      FunctionName:&lt;/span&gt; account-activated&lt;br /&gt;&lt;span class=&quot;hljs-attr&quot;&gt;      CodeUri:&lt;/span&gt; ./account-activated&lt;span class=&quot;hljs-bullet&quot;&gt;-1.0&lt;/span&gt;&lt;span class=&quot;hljs-number&quot;&gt;.0&lt;/span&gt;-SNAPSHOT-aws.jar&lt;br /&gt;&lt;span class=&quot;hljs-attr&quot;&gt;      Description:&lt;/span&gt; Implements business logic for activating an account&lt;br /&gt;&lt;span class=&quot;hljs-attr&quot;&gt;      MemorySize:&lt;/span&gt; &lt;span class=&quot;hljs-number&quot;&gt;1024&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;hljs-attr&quot;&gt;      Timeout:&lt;/span&gt; &lt;span class=&quot;hljs-number&quot;&gt;30&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;hljs-attr&quot;&gt;      Role:&lt;/span&gt; &lt;span class=&quot;hljs-string&quot;&gt;&#39;arn:aws:iam::194021864310:role/service-role/public&#39;&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;hljs-attr&quot;&gt;      Events:&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;hljs-attr&quot;&gt;        Api1:&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;hljs-attr&quot;&gt;          Type:&lt;/span&gt; Api&lt;br /&gt;&lt;span class=&quot;hljs-attr&quot;&gt;          Properties:&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;hljs-attr&quot;&gt;            Path:&lt;/span&gt; /accountActivated&lt;br /&gt;&lt;span class=&quot;hljs-attr&quot;&gt;            Method:&lt;/span&gt; ANY&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1514__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;In the snippet above we see a CloudFormation template for deploying the &lt;code&gt;account-activated&lt;/code&gt; function. &lt;a href=&quot;https://github.com/kbastani/service-block-samples/blob/master/basic-block/account-functions/account-activated/package.yaml&quot; target=&quot;_blank&quot;&gt;This template&lt;/a&gt; will create a package that is uploaded to an &lt;a href=&quot;https://aws.amazon.com/s3/&quot; target=&quot;_blank&quot;&gt;Amazon S3&lt;/a&gt; bucket and then deployed to Lambda.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1518__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;There’s nothing tremendously exciting about this process. To make this as simple and boring as possible, I’ve created a &lt;a href=&quot;https://github.com/kbastani/service-block-samples/blob/master/basic-block/deployment/scripts/deploy-function.sh&quot; target=&quot;_blank&quot;&gt;deploy-function.sh&lt;/a&gt; script that will be used by Concourse to automate function deployments.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1530__&quot; class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 20. Package and deploy Lambda functions using CloudFormation&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div id=&quot;__asciidoctor-preview-1544__&quot; class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-bash hljs&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;hljs-built_in&quot;&gt;export&lt;/span&gt; AWS_ACCESS_KEY_ID=&lt;span class=&quot;hljs-variable&quot;&gt;$aws_access_key_id&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;hljs-built_in&quot;&gt;export&lt;/span&gt; AWS_SECRET_ACCESS_KEY=&lt;span class=&quot;hljs-variable&quot;&gt;$aws_secret_access_key&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;hljs-built_in&quot;&gt;export&lt;/span&gt; AWS_DEFAULT_REGION=&lt;span class=&quot;hljs-variable&quot;&gt;$aws_default_region&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-title&quot;&gt;package&lt;/span&gt;&lt;/span&gt;() {&lt;br /&gt;  &lt;span class=&quot;hljs-comment&quot;&gt;# Create a CloudFormation package for this AWS Lambda function&lt;/span&gt;&lt;br /&gt;  &lt;span class=&quot;hljs-built_in&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;hljs-_&quot;&gt;-e&lt;/span&gt; &lt;span class=&quot;hljs-string&quot;&gt;&quot;Packaging deployment...&quot;&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;  aws cloudformation package \&lt;br /&gt;     --template-file package.yaml \&lt;br /&gt;     --output-template-file deployment.yaml \&lt;br /&gt;     -&lt;span class=&quot;hljs-_&quot;&gt;-s&lt;/span&gt;3-bucket &lt;span class=&quot;hljs-variable&quot;&gt;$bucket_name&lt;/span&gt; || error_exit &lt;span class=&quot;hljs-string&quot;&gt;&quot;Packaging failed: Invalid S3 bucket...&quot;&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;     deploy&lt;br /&gt;}&lt;br /&gt;&lt;br /&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-title&quot;&gt;deploy&lt;/span&gt;&lt;/span&gt;() {&lt;br /&gt;  &lt;span class=&quot;hljs-comment&quot;&gt;# Deploy the CloudFormation package&lt;/span&gt;&lt;br /&gt;  &lt;span class=&quot;hljs-built_in&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;hljs-_&quot;&gt;-e&lt;/span&gt; &lt;span class=&quot;hljs-string&quot;&gt;&quot;Deploying package from s3://&lt;span class=&quot;hljs-variable&quot;&gt;$bucket_name&lt;/span&gt;...&quot;&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;  aws -- cloudformation deploy \&lt;br /&gt;     --template-file deployment.yaml \&lt;br /&gt;     --stack-name &lt;span class=&quot;hljs-variable&quot;&gt;$function_name&lt;/span&gt; || error_exit &lt;span class=&quot;hljs-string&quot;&gt;&quot;Deployment failed...&quot;&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;  &lt;span class=&quot;hljs-comment&quot;&gt;# Remove the deployment package&lt;/span&gt;&lt;br /&gt;  rm ./deployment.yaml&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1548__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;In the snippet above we see the magic of the &lt;code&gt;deploy-function.sh&lt;/code&gt; script. To make sure that this script works, we need to provide the following crucial bits of information.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1554__&quot; class=&quot;ulist&quot;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;AWS access key ID&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;AWS secret access key&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;AWS default region&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;S3 bucket name&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Function name&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1606__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;The last and final concern we’ll take care of is the invocation of Lambda functions from a Spring Boot application.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_lambda_invocation&quot;&gt;Lambda Invocation&lt;/h3&gt;&lt;div id=&quot;__asciidoctor-preview-1622__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;Once our Spring Cloud Function apps have been deployed to AWS Lambda, we can begin invoking them from the &lt;em&gt;account service core&lt;/em&gt;. To make this easy, I’ve created a &lt;a href=&quot;https://github.com/kbastani/service-block-samples/tree/master/starters/spring-boot-starter-aws-lambda&quot; target=&quot;_blank&quot;&gt;helper starter project&lt;/a&gt; that will manage the invocation context to AWS.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1626__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;This project makes it easy to start invoking AWS Lambda functions from a Spring Boot application. All we have to do is to update the &lt;em&gt;account service core&lt;/em&gt; &lt;a href=&quot;https://github.com/kbastani/service-block-samples/blob/master/basic-block/account-core/src/main/resources/application.yml&quot; target=&quot;_blank&quot;&gt;configuration&lt;/a&gt; with the AWS IAM credentials that we used to deploy the CloudFormation package. I’ve created &lt;a href=&quot;https://github.com/kbastani/service-block-samples/blob/master/starters/spring-boot-starter-aws-lambda/src/main/java/amazon/aws/AmazonProperties.java&quot; target=&quot;_blank&quot;&gt;a configuration class&lt;/a&gt; that will allow you to populate this in the &lt;code&gt;application.yml&lt;/code&gt; of the service core.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1638__&quot; class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 21. The application properties of the &lt;code&gt;account-core&lt;/code&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div id=&quot;__asciidoctor-preview-1652__&quot; class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-yaml hljs&quot; data-lang=&quot;yaml&quot;&gt;&lt;span class=&quot;hljs-attr&quot;&gt;spring:&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;hljs-attr&quot;&gt;  profiles:&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;hljs-attr&quot;&gt;    active:&lt;/span&gt; development&lt;br /&gt;&lt;span class=&quot;hljs-attr&quot;&gt;server:&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;hljs-attr&quot;&gt;  port:&lt;/span&gt; &lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;hljs-meta&quot;&gt;---&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;hljs-attr&quot;&gt;spring:&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;hljs-attr&quot;&gt;  profiles:&lt;/span&gt; development&lt;br /&gt;&lt;span class=&quot;hljs-attr&quot;&gt;amazon:&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;hljs-attr&quot;&gt;  aws:&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;hljs-attr&quot;&gt;    access-key-id:&lt;/span&gt; replace&lt;br /&gt;&lt;span class=&quot;hljs-attr&quot;&gt;    access-key-secret:&lt;/span&gt; replace&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1656__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;Now, I’m not a fan of saving sensitive credentials to disk, and neither should you. That’s why Spring Boot supports overriding configuration properties using environment variables.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1668__&quot; class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 22. Set the AWS credentials using environment variables&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div id=&quot;__asciidoctor-preview-1682__&quot; class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-bash hljs&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;hljs-built_in&quot;&gt;export&lt;/span&gt; AMAZON_AWS_ACCESS_KEY_ID=&amp;lt;replace&amp;gt;&lt;br /&gt;&lt;span class=&quot;hljs-built_in&quot;&gt;export&lt;/span&gt; AMAZON_AWS_ACCESS_KEY_SECRET=&amp;lt;replace&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1686__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;Now you can run the &lt;em&gt;account service core&lt;/em&gt; locally using the following command.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1698__&quot; class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-java hljs&quot; data-lang=&quot;java&quot;&gt;mvn spring-boot:run&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1702__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;The service core will start up—and if the IAM keys were configured correctly—you can start calling your functions from the Spring Boot application. To verify that this is working, try creating a new account and executing the &lt;code&gt;suspend&lt;/code&gt; command.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1714__&quot; class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-bash hljs&quot; data-lang=&quot;bash&quot;&gt;2017-07-06 18:47:29.027  INFO 64845 --- [uspendAccount-2] demo.function.LambdaFunctionService      : accountSuspended &lt;span class=&quot;hljs-built_in&quot;&gt;log&lt;/span&gt;:&lt;br /&gt; START RequestId: 78824b17-62a5-11e7-bd48&lt;span class=&quot;hljs-_&quot;&gt;-e&lt;/span&gt;3bbbc0eed75 Version: &lt;span class=&quot;hljs-variable&quot;&gt;$LATEST&lt;/span&gt;&lt;br /&gt; END RequestId: 78824b17-62a5-11e7-bd48&lt;span class=&quot;hljs-_&quot;&gt;-e&lt;/span&gt;3bbbc0eed75&lt;br /&gt; REPORT RequestId: 78824b17-62a5-11e7-bd48&lt;span class=&quot;hljs-_&quot;&gt;-e&lt;/span&gt;3bbbc0eed75 Duration: 5.05 ms Billed Duration: 100 ms  Memory Size: 1024 MB Max Memory Used: 106 MB&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1718__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;In the snippet above we can see that the Lambda function for &lt;code&gt;suspend-account&lt;/code&gt; was successfully invoked.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1724__&quot; class=&quot;admonitionblock tip&quot;&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;icon&quot;&gt;&lt;i class=&quot;fa icon-tip&quot; title=&quot;Tip&quot;&gt;&lt;/i&gt;&lt;/td&gt;&lt;td class=&quot;content&quot;&gt;The cold start time of a Spring Cloud Function app isn’t exactly ideal. The first time a function is invoked it will take up to 20 seconds to start the app. After the first request, things will run much faster. We’ll cover this more in the next post. &lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_summary&quot;&gt;Summary&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div id=&quot;__asciidoctor-preview-1740__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;In this post we looked at the basics behind a service block architecture. While this post tries to be comprehensive, there are a lot of moving parts that it may have left out. Spring Cloud Function is in its early days, but shows powerful promise of being a great serverless framework.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1744__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;In the next post, we’ll cover more of the logistics for creating a serverless CI/CD pipeline using Concourse. We’ll also look at how we can use the open source platform &lt;a href=&quot;https://en.wikipedia.org/wiki/Cloud_Foundry&quot; target=&quot;_blank&quot;&gt;Cloud Foundry&lt;/a&gt; to inject in service credentials into a Lambda function. This is an important goal because Cloud Foundry provides a portable abstraction that doesn’t lock you into a single cloud provider. Which means that you can use Lambda functions with your own services!&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_special_thanks&quot;&gt;Special thanks&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div id=&quot;__asciidoctor-preview-1760__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;Spring Cloud Function is a very exciting new project in the Spring ecosystem. I would like to give a special thanks to &lt;a href=&quot;https://twitter.com/david_syer&quot; target=&quot;_blank&quot;&gt;Dr. Dave Syer&lt;/a&gt; for helping me out with the examples in this post. There are many others to thank on the Spring Engineering team for this awesome new project, namely &lt;a href=&quot;https://twitter.com/m_f_&quot; target=&quot;_blank&quot;&gt;Mark Fisher&lt;/a&gt; for incubating and driving the project forward. Also, the one and only &lt;a href=&quot;https://github.com/mp911de&quot; target=&quot;_blank&quot;&gt;Mark Paluch&lt;/a&gt; who was kind enough to review my usage of Spring Data reactive repositories.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1764__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;Also, a huge thanks to &lt;a href=&quot;https://twitter.com/wattersjames&quot; target=&quot;_blank&quot;&gt;James Watters&lt;/a&gt; for being such a huge supporter, advocate, and driver of Spring. Back in December James &lt;a href=&quot;https://twitter.com/wattersjames/status/806329482114043904&quot; target=&quot;_blank&quot;&gt;tweeted&lt;/a&gt; the lone words &lt;em&gt;Spring Cloud Function&lt;/em&gt; as kind of a teaser, which initially got me very excited about this project. This blog post took months of research and experimentation, so if you found it useful, please share it.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;__asciidoctor-preview-1768__&quot; class=&quot;paragraph&quot;&gt;&lt;p&gt;Until next time!&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;                 &lt;/div&gt;&lt;/div&gt;</description><enclosure type='image/png' url='http://i.imgur.com/bHe0D5p.png' length='0'/><link>https://www.kennybastani.com/2017/07/microservices-to-service-blocks-spring-cloud-function-aws-lambda.html</link><author>noreply@blogger.com (Kenny Bastani)</author><thr:total>0</thr:total></item><item><guid isPermaLink="false">tag:blogger.com,1999:blog-6300367579216018061.post-5042612268447921974</guid><pubDate>Wed, 01 Feb 2017 01:59:00 +0000</pubDate><atom:updated>2017-01-31T18:03:08.187-08:00</atom:updated><category domain="http://www.blogger.com/atom/ns#">cloud native java</category><category domain="http://www.blogger.com/atom/ns#">cqrs</category><category domain="http://www.blogger.com/atom/ns#">event sourcing</category><category domain="http://www.blogger.com/atom/ns#">event-driven microservices</category><category domain="http://www.blogger.com/atom/ns#">microservices</category><category domain="http://www.blogger.com/atom/ns#">serverless</category><category domain="http://www.blogger.com/atom/ns#">spring boot</category><category domain="http://www.blogger.com/atom/ns#">spring cloud</category><title>Building Event-driven Microservices Using CQRS and Serverless</title><description>&lt;link rel=&quot;stylesheet&quot; href=&quot;https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans:400,700&quot;&gt;&lt;style&gt;.hljs-title, .hljs-id, .scss .hljs-preprocessor {    font-weight: 400 !important; } .hljs-class .hljs-title, .hljs-type, .vhdl .hljs-literal, .tex .hljs-command {    font-weight: 400 !important; } .hljs-keyword, .css .rule .hljs-keyword, .hljs-winutils, .nginx .hljs-title, .hljs-subst, .hljs-request, .hljs-status {    font-weight: 400 !important; } .sect1{padding-bottom:0!important} .sect1+.sect1{border:0!important} .conum[data-value]{display:inline-block;color:#fff!important;background-color:rgba(0,0,0,.8);-webkit-border-radius:100px;border-radius:100px;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:&quot;Open Sans&quot;,&quot;DejaVu Sans&quot;,sans-serif;font-style:normal;font-weight:bold} .conum[data-value] *{color:#fff!important} .conum[data-value]+b{display:none} .conum[data-value]:after{content:attr(data-value)} .fa-caret-up {     color: green;     text-shadow: 1px 1px 1px #ccc;     font-size: 1.75em !important; }  .fa-caret-down {     color: red;     text-shadow: 1px 1px 1px #ccc;     font-size: 1.75em !important; }  .fa-minus {     color: #999;     text-shadow: 1px 1px 1px #ccc;     font-size: 1em !important; }  .fa-plus {     font-size: 1em !important;     color: green;     text-shadow: 1px 1px 1px #ccc; }   @media screen and (min-width: 768px) { .table-responsive { font-size: 0.8em; max-width: 50em; } }  @media screen and (max-width: 768px) {     .table-responsive {     font-size: 0.65em; } }  .table-responsive th, .table-responsive tr, .table-responsive td { padding: 4px 4px 4px 4px !important; } p {     margin-bottom: 1.25em !important; line-height: 1.4; } li p { line-height: 1.4 !important; margin: 0 !important; } .blog-post-asciidoc .content img {  max-height: none;  width: 100% !important; } .admonitionblock &gt; table {     background: rgba(0, 0, 0, 0) none repeat scroll 0 0;     border: 0 none;     border-collapse: separate;     width: 100%; } table {     background: #fff none repeat scroll 0 0;     border: 1px solid #dedede;     margin-bottom: 1.25em; } pre .conum[data-value]{position:relative;top:-.125em} b.conum *{color:inherit!important} .conum:not([data-value]):empty{display:none} .hdlist&gt;table,.colist&gt;table{border:0;background:none} .hdlist&gt;table&gt;tbody&gt;tr,.colist&gt;table&gt;tbody&gt;tr{background:none} td.hdlist1{padding-right:.75em;font-weight:bold} td.hdlist1,td.hdlist2{vertical-align:top} .literalblock+.colist,.listingblock+.colist{margin-top:-.5em} .colist&gt;table tr&gt;td:first-of-type{padding:0 .75em;line-height:1} .colist&gt;table tr&gt;td:last-of-type{padding:.25em 0} h1,h2,h3,#toctitle,.sidebarblock&gt;.content&gt;.title,h3,h4,h6{font-family:&quot;Open Sans&quot;,sans-serif;font-style:normal;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;} .blog-post-asciidoc p{margin-bottom:1.25rem} @media only screen and (min-width:768px){.sect1{padding-bottom:1.25em}}.sect1+.sect1{border-top:1px solid #efefed} pre, pre &gt; code {     -moz-osx-font-smoothing: auto;     color: rgba(0, 0, 0, 0.9);     font-family: monospace,monospace;     font-weight: 400;     line-height: 1.45;     text-rendering: optimizelegibility; } .blog-post-asciidoc code,kbd,pre,samp{font-size:.9em;font-weight:400;} .blog-post-asciidoc .admonitionblock&gt;table{border-collapse:separate;border:0;background:none;width:100%} .blog-post-asciidoc .admonitionblock&gt;table td.icon{text-align:center;width:80px} .blog-post-asciidoc .admonitionblock&gt;table td.icon img{max-width:none} .blog-post-asciidoc .admonitionblock&gt;table td.icon .title{font-weight:bold;font-family:&quot;Open Sans&quot;,&quot;DejaVu Sans&quot;,sans-serif;text-transform:uppercase} .blog-post-asciidoc .admonitionblock&gt;table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #ddddd8;color:rgba(0,0,0,.6)} .blog-post-asciidoc .admonitionblock&gt;table td.content&gt;:last-child&gt;:last-child{margin-bottom:0} .blog-post-asciidoc .admonitionblock td.icon [class^=&quot;fa icon-&quot;]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default} .blog-post-asciidoc .admonitionblock td.icon .icon-note:before{content:&quot;\f05a&quot;;color:#19407c} .blog-post-asciidoc .admonitionblock td.icon .icon-tip:before{content:&quot;\f0eb&quot;;text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111} .blog-post-asciidoc .admonitionblock td.icon .icon-warning:before{content:&quot;\f071&quot;;color:#bf6900} .blog-post-asciidoc .admonitionblock td.icon .icon-caution:before{content:&quot;\f06d&quot;;color:#bf3400} .blog-post-asciidoc .admonitionblock td.icon .icon-important:before{content:&quot;\f06a&quot;;color:#bf0000} #personDataTable td {     vertical-align: middle; } .rank-col {     text-align: center; } #personDataTable img {     max-width: 35px;     padding: 0; } .table-responsive {     font-weight: 400; } .table &gt; thead &gt; tr &gt; th {     border-bottom: 2px solid #ddd;     font-weight: 400;     padding: 8px !important;     vertical-align: bottom; } .table-responsive {     font-family: Helvetica,sans-serif; } .exampleblock pre {     margin-top: auto; } .exampleblock .content {     margin-top: auto; } blockquote {     border-left: 5px solid #eee;     color: #666;     font-size: 16px;     margin: 0;     padding: 10px 20px; } .attribution {     font-size: small;     text-align: right; } .table-responsive p { margin: 0 !important; } p.tableblock {   font-size: 14px;   margin: 0 !important; } table.tableblock { max-width: 100%; border-collapse: separate; } table.tableblock td &gt; .paragraph:last-child p &gt; p:last-child, table.tableblock th &gt; p:last-child, table.tableblock td &gt; p:last-child { margin-bottom: 0; }  table.tableblock, th.tableblock, td.tableblock { border: 0 solid #dddddd; }  table.grid-all th.tableblock, table.grid-all td.tableblock { border-width: 0 1px 1px 0; }  table.grid-all tfoot &gt; tr &gt; th.tableblock, table.grid-all tfoot &gt; tr &gt; td.tableblock { border-width: 1px 1px 0 0; }  table.grid-cols th.tableblock, table.grid-cols td.tableblock { border-width: 0 1px 0 0; }  table.grid-all * &gt; tr &gt; .tableblock:last-child, table.grid-cols * &gt; tr &gt; .tableblock:last-child { border-right-width: 0; }  table.grid-rows th.tableblock, table.grid-rows td.tableblock { border-width: 0 0 1px 0; }  table.grid-all tbody &gt; tr:last-child &gt; th.tableblock, table.grid-all tbody &gt; tr:last-child &gt; td.tableblock, table.grid-all thead:last-child &gt; tr &gt; th.tableblock, table.grid-rows tbody &gt; tr:last-child &gt; th.tableblock, table.grid-rows tbody &gt; tr:last-child &gt; td.tableblock, table.grid-rows thead:last-child &gt; tr &gt; th.tableblock { border-bottom-width: 0; }  table.grid-rows tfoot &gt; tr &gt; th.tableblock, table.grid-rows tfoot &gt; tr &gt; td.tableblock { border-width: 1px 0 0 0; }  table.frame-all { border-width: 1px; }  table.frame-sides { border-width: 0 1px; }  table.frame-topbot { border-width: 1px 0; }  th.halign-left, td.halign-left { text-align: left; }  th.halign-right, td.halign-right { text-align: right; }  th.halign-center, td.halign-center { text-align: center; }  th.valign-top, td.valign-top { vertical-align: top; }  th.valign-bottom, td.valign-bottom { vertical-align: bottom; }  th.valign-middle, td.valign-middle { vertical-align: middle; }  table thead th, table tfoot th { font-weight: bold; }  tbody tr th { display: table-cell; line-height: 1.4; background: whitesmoke; }  tbody tr th, tbody tr th p, tfoot tr th, tfoot tr th p { color: #222222; font-weight: bold; }  p.tableblock &gt; code:only-child { background: none; padding: 0; }  table tr.even, table tr.alt, table tr:nth-of-type(2n) {     background: #f9f9f9 none repeat scroll 0 0; } div.table-responsive {  border: 0; }  .sql p {  font-family: courier; } &lt;/style&gt;&lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.2.0/css/font-awesome.min.css&quot;&gt;&lt;div id=&quot;content&quot; class=&quot;blog-post-asciidoc&quot;&gt;         &lt;div class=&quot;article&quot;&gt;          &lt;div id=&quot;preamble&quot;&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;This blog series will introduce you to building event-driven microservices as cloud-native applications.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;In this first post, we’ll explore how to implement the &lt;a href=&quot;https://martinfowler.com/bliki/CQRS.html&quot; target=&quot;_blank&quot;&gt;CQRS&lt;/a&gt; pattern in microservices. We’ll also dive into why &lt;a href=&quot;https://martinfowler.com/articles/serverless.html&quot; target=&quot;_blank&quot;&gt;serverless&lt;/a&gt; is a natural fit for these kinds of systems. Later in the series we’ll explore a reference application that uses &lt;a href=&quot;https://cloud.spring.io/spring-cloud-stream/&quot; target=&quot;_blank&quot;&gt;Spring Cloud Stream&lt;/a&gt; to implement CQRS.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_what_is_an_event_driven_architecture&quot;&gt;What is an event-driven architecture?&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Event-driven_architecture&quot; target=&quot;_blank&quot;&gt;Event-driven architectures&lt;/a&gt; treat domain events as first-class citizens. This approach is as old as software itself.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;One example we use every day is in front-end applications. In every web browser in use today, events are handled as a way to capture inputs of a user form. Events connected to page elements are handled by an explicitly mapped function, sometimes referred to as an &lt;em&gt;action&lt;/em&gt; or &lt;em&gt;command&lt;/em&gt;, which will apply state changes to a user interface when triggered.&lt;/p&gt;&lt;/div&gt;&lt;div style=&quot;display: none;&quot; class=&quot;imageblock&quot;&gt;&lt;div style=&quot;text-align: left; margin: auto;&quot; class=&quot;content&quot;&gt;&lt;img style=&quot;margin: auto !important; max-width: 32em;&quot; src=&quot;http://imgur.com/kr0O5QZ.png&quot; alt=&quot;CQRS microservice architecture&quot; width=&quot;100%&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Now, more recently, with the widespread adoption of &lt;a href=&quot;https://martinfowler.com/articles/microservices.html&quot; target=&quot;_blank&quot;&gt;microservices&lt;/a&gt;, there is renewed interest in how to take advantage of event-driven techniques in distributed back-end systems.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_cqrs&quot;&gt;CQRS&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;One of the most popular practices in event-driven architectures today is called CQRS, which is short for &lt;em&gt;Command Query Responsibility Segregation&lt;/em&gt;. CQRS is a style of architecture that allows you to use different models to update and read domain data.&lt;/p&gt;&lt;/div&gt;&lt;div style=&quot;display: block;&quot; class=&quot;imageblock&quot;&gt;&lt;div style=&quot;text-align: left; margin: auto;&quot; class=&quot;content&quot;&gt;&lt;img style=&quot;margin: auto !important;  max-width: 28em;&quot; src=&quot;http://imgur.com/zdCYjAL.png&quot; alt=&quot;CQRS model&quot; width=&quot;70%&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The basic idea of CQRS is that it’s perfectly natural to need to separate the models you’re using to update and read data. The diagram above shows this basic idea.&lt;/p&gt;&lt;/div&gt;&lt;a name=&#39;more&#39;&gt;&lt;/a&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;CQRS is popular for event-driven architectures because &lt;a href=&quot;https://martinfowler.com/eaaDev/DomainEvent.html&quot; target=&quot;_blank&quot;&gt;domain events&lt;/a&gt; — as inputs — are structurally different than the &lt;a href=&quot;https://martinfowler.com/eaaCatalog/domainModel.html&quot; target=&quot;_blank&quot;&gt;domain model&lt;/a&gt; they are subject to. Take for example the following domain model object representing an account.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 1. Account aggregate&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-json hljs&quot; data-lang=&quot;json&quot;&gt;{&lt;br /&gt;  &lt;span class=&quot;hljs-attr&quot;&gt;&quot;createdAt&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-number&quot;&gt;1481351048967&lt;/span&gt;,&lt;br /&gt;  &lt;span class=&quot;hljs-attr&quot;&gt;&quot;lastModified&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-number&quot;&gt;1481351049385&lt;/span&gt;,&lt;br /&gt;  &lt;span class=&quot;hljs-attr&quot;&gt;&quot;userId&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;,&lt;br /&gt;  &lt;span class=&quot;hljs-attr&quot;&gt;&quot;accountNumber&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-string&quot;&gt;&quot;123456&quot;&lt;/span&gt;,&lt;br /&gt;  &lt;span class=&quot;hljs-attr&quot;&gt;&quot;defaultAccount&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-literal&quot;&gt;true&lt;/span&gt;,&lt;br /&gt;  &lt;span class=&quot;hljs-attr&quot;&gt;&quot;status&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-string&quot;&gt;&quot;ACCOUNT_ACTIVE&quot;&lt;/span&gt;&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;When a service wants to query for an account, this is the model it will expect. Now, what if we wanted to update the status to &lt;code&gt;ACCOUNT_SUSPENDED&lt;/code&gt;? Normally this would be a simple update to the domain object for the status field. Now, what if we wanted to use a domain event to update the status instead? Since a domain object is structurally different from an event, we will need an API that accepts a different model as a command.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The following snippet is a domain event that transitions the state of the account from &lt;code&gt;ACCOUNT_ACTIVE&lt;/code&gt; to &lt;code&gt;ACCOUNT_SUSPENDED&lt;/code&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 2. Account event&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-json hljs&quot; data-lang=&quot;json&quot;&gt;{&lt;br /&gt;  &lt;span class=&quot;hljs-attr&quot;&gt;&quot;createdAt&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-number&quot;&gt;1481353397395&lt;/span&gt;,&lt;br /&gt;  &lt;span class=&quot;hljs-attr&quot;&gt;&quot;lastModified&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-number&quot;&gt;1481353397395&lt;/span&gt;,&lt;br /&gt;  &lt;span class=&quot;hljs-attr&quot;&gt;&quot;type&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-string&quot;&gt;&quot;ACCOUNT_SUSPENDED&quot;&lt;/span&gt;,&lt;br /&gt;  &lt;span class=&quot;hljs-attr&quot;&gt;&quot;accountNumber&quot;&lt;/span&gt;: &lt;span class=&quot;hljs-string&quot;&gt;&quot;123456&quot;&lt;/span&gt;&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;To process this domain event and apply the update to the query model, we must have an API to accept the command. The command will contain the model of the domain event and use it to process the update to the account’s query model.&lt;/p&gt;&lt;/div&gt;&lt;div style=&quot;display: block;&quot; class=&quot;imageblock&quot;&gt;&lt;div style=&quot;text-align: left; margin: auto;&quot; class=&quot;content&quot;&gt;&lt;img style=&quot;margin: auto !important;  max-width: 28em;&quot; src=&quot;http://imgur.com/QxLXnqe.png&quot; alt=&quot;CQRS suspend account&quot; width=&quot;70%&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;This is the simplest explanation of CQRS — to separate the command model from the query model. The complexity we often see today is more to do with the flavor of implementation. This is especially true when applying the pattern to microservices.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_cqrs_and_microservices&quot;&gt;CQRS and Microservices&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;When CQRS combines with microservices, things get a bit complex — to say the least. Let’s take a look at what a &quot;simple&quot; microservice resembles that implements CQRS using &lt;a href=&quot;https://projects.spring.io/spring-boot/&quot; target=&quot;_blank&quot;&gt;Spring Boot&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div style=&quot;display: block;&quot; class=&quot;imageblock&quot;&gt;&lt;div style=&quot;text-align: left; margin: auto;&quot; class=&quot;content&quot;&gt;&lt;img style=&quot;margin: auto !important; max-width: 32em;&quot; src=&quot;http://imgur.com/kr0O5QZ.png&quot; alt=&quot;CQRS microservice architecture&quot; width=&quot;100%&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The diagram above is a rough sketch of an implementation of the CQRS pattern.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Here we’ve split up a single microservice into a &lt;em&gt;command-side&lt;/em&gt;, &lt;em&gt;query-side&lt;/em&gt;, and &lt;em&gt;event processor&lt;/em&gt;—all of which can be deployed independently of one another.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_command_side&quot;&gt;Command-side&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The command-side in this example exposes a REST API that accepts requests over HTTP. Requests take the form of &lt;em&gt;commands&lt;/em&gt; that drive state changes to domain data owned by the microservice. To put it simply, any &lt;em&gt;writes&lt;/em&gt; on domain data will flow from an API request as a command — which handles an action that results in changes to the database.&lt;/p&gt;&lt;/div&gt;&lt;div style=&quot;display: block;&quot; class=&quot;imageblock&quot;&gt;&lt;div style=&quot;text-align: left; margin: auto;&quot; class=&quot;content&quot;&gt;&lt;img style=&quot;margin: auto !important; max-width: 10em;&quot; src=&quot;http://imgur.com/eClf191.png&quot; alt=&quot;Command-side CQRS&quot; width=&quot;60%&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Commands trigger actions and actions trigger domain events. The domain events persist to an &lt;a href=&quot;https://en.wikipedia.org/wiki/Event_store&quot; target=&quot;_blank&quot;&gt;&lt;em&gt;event store&lt;/em&gt;&lt;/a&gt;—a fancy way to say &quot;&lt;em&gt;a system that combines a database together with a message broker&lt;/em&gt;.&quot;&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;admonitionblock tip&quot;&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;icon&quot;&gt;&lt;i class=&quot;fa icon-tip&quot; title=&quot;Tip&quot;&gt;&lt;/i&gt;&lt;/td&gt;&lt;td class=&quot;content&quot;&gt;An excellent event store to get started with is called &lt;a href=&quot;http://eventuate.io/&quot; target=&quot;_blank&quot;&gt;Eventuate&lt;/a&gt;, which was founded by &lt;a href=&quot;https://twitter.com/crichardson&quot; target=&quot;_blank&quot;&gt;Chris Richardson&lt;/a&gt; as a project to help apply CQRS and Event Sourcing to microservices. &lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Domain events store as a series of time-ordered events appended to a log. Since every command generates an event, we’re able to rebuild the total state of the current system from a history of collected events. I cover this topic in more detail in a previous blog post on &lt;a href=&quot;http://www.kennybastani.com/2016/04/event-sourcing-microservices-spring-cloud.html&quot; target=&quot;_blank&quot;&gt;event sourcing in microservices&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_event_processor&quot;&gt;Event Processor&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The next component we’ll examine is the &lt;em&gt;Event Processor&lt;/em&gt;. This CQRS component takes the form of a worker application that is responsible for ingesting domain events. The event processor is stateless and listens for messages from the &lt;em&gt;event store&lt;/em&gt;, applying an action for incoming event messages.&lt;/p&gt;&lt;/div&gt;&lt;div style=&quot;display: block;&quot; class=&quot;imageblock&quot;&gt;&lt;div style=&quot;text-align: left; margin: auto;&quot; class=&quot;content&quot;&gt;&lt;img style=&quot;margin: auto !important; max-width: 22em;&quot; src=&quot;http://imgur.com/9dqHdEJ.png&quot; alt=&quot;Event processor CQRS&quot; width=&quot;60%&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The event processor can respond to a new domain event in many useful ways. One domain event can spawn more events that can be sent to other microservices. This is why most developers of microservices are attracted to CQRS—as a way to publish and subscribe to domain events originating from applications outside of a bounded context.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;This approach provides us with a mechanism to ensure referential integrity of domain data. Messages from other microservices can be used to handle domain events that allow maintenance of pesky foreign key relationships relating domain data from other records in the distributed system.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_query_side&quot;&gt;Query-side&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The event processor is first and foremost responsible for applying a domain event that changes the state of a &lt;a href=&quot;https://martinfowler.com/bliki/DDD_Aggregate.html&quot; target=&quot;_blank&quot;&gt;domain aggregate&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Each domain event can be used to update a database record that results in an incremental materialized view for describing an aggregate. In turn, the query-side will expose a REST API that allows HTTP clients to &lt;em&gt;read&lt;/em&gt; the resulting &lt;a href=&quot;https://en.wikipedia.org/wiki/Materialized_view&quot; target=&quot;_blank&quot;&gt;materialized views&lt;/a&gt; that were generated from the processed events.&lt;/p&gt;&lt;/div&gt;&lt;div style=&quot;display: block;&quot; class=&quot;imageblock&quot;&gt;&lt;div style=&quot;text-align: left; margin: auto;&quot; class=&quot;content&quot;&gt;&lt;img style=&quot;margin: auto !important; max-width: 32em;&quot; src=&quot;http://i.imgur.com/PztebDr.png&quot; alt=&quot;Query-side CQRS&quot; width=&quot;60%&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The constraint in the query-side component is that domain data is &lt;em&gt;read-only&lt;/em&gt;. All state changes in this system will flow in from the command-side and result in materialized views that can be read on the query-side.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_distributed_monolith_or_microservice&quot;&gt;Distributed Monolith or Microservice?&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Now if you’re like me, you might be thinking &quot;Hold up! That’s no moon…​ it’s a space station.&quot;&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;When most people think of a single microservice today, they think of an independent service component. In most cases, a microservice is built as an application that focuses on doing one thing well. Most importantly, the service can be upgraded and deployed independently of other services.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Now when it comes to the conventional CQRS implementation, because of the separate components, there seems to be a slight concern for calling it a microservice. So it’s worth asking: is this CQRS application considered a microservice? Or rather, could it be what some developers have started to refer to as a &lt;a href=&quot;https://www.infoq.com/news/2016/02/services-distributed-monolith?utm_source=infoq&amp;amp;utm_medium=popular_widget&amp;amp;utm_campaign=popular_content_list&amp;amp;utm_content=homepage&quot; target=&quot;_blank&quot;&gt;&lt;em&gt;distributed monolith&lt;/em&gt;&lt;/a&gt;?&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The answer is tricky, and it depends on who you’re asking. I find that a microservice is all about empowering small independent teams to continuously deliver features as a part of a larger ecosystem of other microservices.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;CQRS deployments are complex when compared to most microservice deployments. For a microservices team, the goal is to be able to continuously deliver features into production. Since the separated components of CQRS can still be independently deployed, then we can say that each unit of deployment still satisfies the minimum requirements for independently delivering features into production. One feature of a microservice should always require—at most—one deployable unit.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;em&gt;A distributed monolith happens when a feature is delivered that requires a coordinated deployment of multiple separate components at the same time.&lt;/em&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_serverless&quot;&gt;Serverless&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Event-driven architectures need not apply only to microservices.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Serverless—which is also referred to as FaaS (Function-as-a-Service)—allows you to deploy code as functions without needing to setup or manage application servers or containers. Serverless is a popular architectural style that is rapidly gaining traction when building and operating cloud-native applications. One notable benefit of using serverless functions is that the concept of events is treated as a first-class citizen.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_microservices_and_serverless&quot;&gt;Microservices and Serverless&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;A popular misconception of cloud-native applications is that microservices and serverless are largely incompatible, incongruent, or orthogonal styles of architectures.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Let’s consider the CQRS system that we reviewed earlier. The rule of thumb still holds for applications built as serverless functions.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;quoteblock&quot;&gt;&lt;blockquote&gt;A distributed monolith happens when a feature is delivered that requires a coordinated deployment of multiple separate components. &lt;/blockquote&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The inverse of this rule would imply that a microservice can also be built from a composition of serverless functions. In this scenario, where would one microservice begin and another end?&lt;/p&gt;&lt;/div&gt;&lt;div style=&quot;display: block;&quot; class=&quot;imageblock&quot;&gt;&lt;div style=&quot;text-align: left; margin: auto;&quot; class=&quot;content&quot;&gt;&lt;img style=&quot;margin: auto !important; max-width: 36em;&quot; src=&quot;http://imgur.com/feWJqtX.png&quot; alt=&quot;Serverless microservice&quot; width=&quot;100%&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;One way to look at it is to consider the &lt;em&gt;boundary of the microservice to be the boundary of the team&lt;/em&gt;. As long as a team can both independently and continuously deploy features as a function, then the boundary of the microservice is just the subset of functions (or application components) responsible for powering the features owned by the team.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_trade_offs&quot;&gt;Trade-offs&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;To understand why you would want to take this approach requires a close examination of the trade-offs.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_velocity&quot;&gt;Velocity&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;For microservices, the goal is velocity. We can measure velocity by answering the following two questions.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;ulist&quot;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;How fast can a developer make a single line of code change and safely deploy it into production?&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;How fast can a new developer ramp up and safely make changes to a code base?&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;A microservice team measures their velocity by answering the two questions. The lower the average time, the higher the velocity a team will have when delivering features.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Serverless comes with a learning curve, but lends well to increasing velocity in microservices. It does so by moving much of the workflow management out of the core components and into small composable functions that can be independently upgraded and deployed. This minimizes the time it takes for a developer to understand how a single function works and how to safely change it.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Serverless functions are also simple to upgrade and deploy, but may add complexity in understanding the whole picture. Managing hundreds of serverless functions as one team does not sound like much fun.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_complexity&quot;&gt;Complexity&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Complexity is unavoidable in software. Complexity grows over time as a code base ages. Monolithic applications become unwieldy and hard to change when complexity grows, or when frameworks or languages become out of date or obsolete. Microservices split up this complexity into a distributed system, where each deployable unit is both easy to understand and easy to change by a small agile group of developers.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_cloud_native_cqrs&quot;&gt;Cloud-native CQRS&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;This blog post is the first in a series that will introduce you to a &lt;a href=&quot;https://github.com/kbastani/event-stream-processing-microservices&quot; target=&quot;_blank&quot;&gt;reference application&lt;/a&gt; for building a cloud-native CQRS application as a collection of event-driven microservices and serverless functions.&lt;/p&gt;&lt;/div&gt;&lt;div style=&quot;display: block;&quot; class=&quot;imageblock&quot;&gt;&lt;div style=&quot;text-align: center; margin: auto;&quot; class=&quot;content&quot;&gt;&lt;img style=&quot;margin: auto !important;  max-width: 100%;&quot; src=&quot;https://camo.githubusercontent.com/77e3bbcf38c92533e831c155190901541d56a7ac/687474703a2f2f692e696d6775722e636f6d2f575a5452346c512e706e67&quot; alt=&quot;Cloud-native CQRS with serverless&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;In the next blog post, we will dive into an open source sample application that has a similar structure to the diagram shown above. We’ll explore how to implement a variant of CQRS that is composed of multiple independently deployable cloud-native components.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The sample will demonstrate how to build an end-to-end microservice application that is flexible to change and more easily decomposed. We’ll explore using Spring Boot together with &lt;a href=&quot;https://aws.amazon.com/lambda/&quot; target=&quot;_blank&quot;&gt;AWS Lambda&lt;/a&gt; to apply the CQRS pattern to a cloud-native application.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;        &lt;/div&gt;               &lt;/div&gt;</description><enclosure type='image/png' url='http://imgur.com/kr0O5QZ.png' length='0'/><link>https://www.kennybastani.com/2017/01/building-event-driven-microservices.html</link><author>noreply@blogger.com (Kenny Bastani)</author><thr:total>0</thr:total></item><item><guid isPermaLink="false">tag:blogger.com,1999:blog-6300367579216018061.post-3120176371307585472</guid><pubDate>Tue, 30 Aug 2016 16:19:00 +0000</pubDate><atom:updated>2016-08-30T13:05:40.651-07:00</atom:updated><category domain="http://www.blogger.com/atom/ns#">cloud foundry</category><category domain="http://www.blogger.com/atom/ns#">cloud native java</category><category domain="http://www.blogger.com/atom/ns#">docker compose</category><category domain="http://www.blogger.com/atom/ns#">legacy modernization</category><category domain="http://www.blogger.com/atom/ns#">legacy systems</category><category domain="http://www.blogger.com/atom/ns#">microservices</category><category domain="http://www.blogger.com/atom/ns#">PCF dev</category><category domain="http://www.blogger.com/atom/ns#">soa</category><category domain="http://www.blogger.com/atom/ns#">spring boot</category><category domain="http://www.blogger.com/atom/ns#">spring cloud</category><title>Building Spring Cloud Microservices That Strangle Legacy Systems</title><description>&lt;link rel=&quot;stylesheet&quot; href=&quot;https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans:400,700&quot;&gt;&lt;style&gt;.hljs-title, .hljs-id, .scss .hljs-preprocessor {    font-weight: 400 !important; } .hljs-class .hljs-title, .hljs-type, .vhdl .hljs-literal, .tex .hljs-command {    font-weight: 400 !important; } .hljs-keyword, .css .rule .hljs-keyword, .hljs-winutils, .nginx .hljs-title, .hljs-subst, .hljs-request, .hljs-status {    font-weight: 400 !important; } .sect1{padding-bottom:0!important} .sect1+.sect1{border:0!important} .conum[data-value]{display:inline-block;color:#fff!important;background-color:rgba(0,0,0,.8);-webkit-border-radius:100px;border-radius:100px;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:&quot;Open Sans&quot;,&quot;DejaVu Sans&quot;,sans-serif;font-style:normal;font-weight:bold} .conum[data-value] *{color:#fff!important} .conum[data-value]+b{display:none} .conum[data-value]:after{content:attr(data-value)} .fa-caret-up {     color: green;     text-shadow: 1px 1px 1px #ccc;     font-size: 1.75em !important; }  .fa-caret-down {     color: red;     text-shadow: 1px 1px 1px #ccc;     font-size: 1.75em !important; }  .fa-minus {     color: #999;     text-shadow: 1px 1px 1px #ccc;     font-size: 1em !important; }  .fa-plus {     font-size: 1em !important;     color: green;     text-shadow: 1px 1px 1px #ccc; }   @media screen and (min-width: 768px) { .table-responsive { font-size: 0.8em; max-width: 50em; } }  @media screen and (max-width: 768px) {     .table-responsive {     font-size: 0.65em; } }  .table-responsive th, .table-responsive tr, .table-responsive td { padding: 4px 4px 4px 4px !important; } p {     margin-bottom: 1.25em !important; line-height: 1.4; } li p { line-height: 1.4 !important; margin: 0 !important; } .blog-post-asciidoc .content img {  max-height: none; } .admonitionblock &gt; table {     background: rgba(0, 0, 0, 0) none repeat scroll 0 0;     border: 0 none;     border-collapse: separate;     width: 100%; } table {     background: #fff none repeat scroll 0 0;     border: 1px solid #dedede;     margin-bottom: 1.25em; } pre .conum[data-value]{position:relative;top:-.125em} b.conum *{color:inherit!important} .conum:not([data-value]):empty{display:none} .hdlist&gt;table,.colist&gt;table{border:0;background:none} .hdlist&gt;table&gt;tbody&gt;tr,.colist&gt;table&gt;tbody&gt;tr{background:none} td.hdlist1{padding-right:.75em;font-weight:bold} td.hdlist1,td.hdlist2{vertical-align:top} .literalblock+.colist,.listingblock+.colist{margin-top:-.5em} .colist&gt;table tr&gt;td:first-of-type{padding:0 .75em;line-height:1} .colist&gt;table tr&gt;td:last-of-type{padding:.25em 0} h1,h2,h3,#toctitle,.sidebarblock&gt;.content&gt;.title,h3,h4,h6{font-family:&quot;Open Sans&quot;,sans-serif;font-style:normal;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;} .blog-post-asciidoc p{margin-bottom:1.25rem} @media only screen and (min-width:768px){.sect1{padding-bottom:1.25em}}.sect1+.sect1{border-top:1px solid #efefed} pre, pre &gt; code {     -moz-osx-font-smoothing: auto;     color: rgba(0, 0, 0, 0.9);     font-family: monospace,monospace;     font-weight: 400;     line-height: 1.45;     text-rendering: optimizelegibility; } .blog-post-asciidoc code,kbd,pre,samp{font-size:.9em;font-weight:400;} .blog-post-asciidoc .admonitionblock&gt;table{border-collapse:separate;border:0;background:none;width:100%} .blog-post-asciidoc .admonitionblock&gt;table td.icon{text-align:center;width:80px} .blog-post-asciidoc .admonitionblock&gt;table td.icon img{max-width:none} .blog-post-asciidoc .admonitionblock&gt;table td.icon .title{font-weight:bold;font-family:&quot;Open Sans&quot;,&quot;DejaVu Sans&quot;,sans-serif;text-transform:uppercase} .blog-post-asciidoc .admonitionblock&gt;table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #ddddd8;color:rgba(0,0,0,.6)} .blog-post-asciidoc .admonitionblock&gt;table td.content&gt;:last-child&gt;:last-child{margin-bottom:0} .blog-post-asciidoc .admonitionblock td.icon [class^=&quot;fa icon-&quot;]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default} .blog-post-asciidoc .admonitionblock td.icon .icon-note:before{content:&quot;\f05a&quot;;color:#19407c} .blog-post-asciidoc .admonitionblock td.icon .icon-tip:before{content:&quot;\f0eb&quot;;text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111} .blog-post-asciidoc .admonitionblock td.icon .icon-warning:before{content:&quot;\f071&quot;;color:#bf6900} .blog-post-asciidoc .admonitionblock td.icon .icon-caution:before{content:&quot;\f06d&quot;;color:#bf3400} .blog-post-asciidoc .admonitionblock td.icon .icon-important:before{content:&quot;\f06a&quot;;color:#bf0000} #personDataTable td {     vertical-align: middle; } .rank-col {     text-align: center; } #personDataTable img {     max-width: 35px;     padding: 0; } .table-responsive {     font-weight: 400; } .table &gt; thead &gt; tr &gt; th {     border-bottom: 2px solid #ddd;     font-weight: 400;     padding: 8px !important;     vertical-align: bottom; } .table-responsive {     font-family: Helvetica,sans-serif; } .exampleblock pre {     margin-top: auto; } .exampleblock .content {     margin-top: auto; } blockquote {     border-left: 5px solid #eee;     color: #666;     font-size: 16px;     margin: 0;     padding: 10px 20px; } .attribution {     font-size: small;     text-align: right; } .table-responsive p { margin: 0 !important; } p.tableblock {   font-size: 14px;   margin: 0 !important; } table.tableblock { max-width: 100%; border-collapse: separate; } table.tableblock td &gt; .paragraph:last-child p &gt; p:last-child, table.tableblock th &gt; p:last-child, table.tableblock td &gt; p:last-child { margin-bottom: 0; }  table.tableblock, th.tableblock, td.tableblock { border: 0 solid #dddddd; }  table.grid-all th.tableblock, table.grid-all td.tableblock { border-width: 0 1px 1px 0; }  table.grid-all tfoot &gt; tr &gt; th.tableblock, table.grid-all tfoot &gt; tr &gt; td.tableblock { border-width: 1px 1px 0 0; }  table.grid-cols th.tableblock, table.grid-cols td.tableblock { border-width: 0 1px 0 0; }  table.grid-all * &gt; tr &gt; .tableblock:last-child, table.grid-cols * &gt; tr &gt; .tableblock:last-child { border-right-width: 0; }  table.grid-rows th.tableblock, table.grid-rows td.tableblock { border-width: 0 0 1px 0; }  table.grid-all tbody &gt; tr:last-child &gt; th.tableblock, table.grid-all tbody &gt; tr:last-child &gt; td.tableblock, table.grid-all thead:last-child &gt; tr &gt; th.tableblock, table.grid-rows tbody &gt; tr:last-child &gt; th.tableblock, table.grid-rows tbody &gt; tr:last-child &gt; td.tableblock, table.grid-rows thead:last-child &gt; tr &gt; th.tableblock { border-bottom-width: 0; }  table.grid-rows tfoot &gt; tr &gt; th.tableblock, table.grid-rows tfoot &gt; tr &gt; td.tableblock { border-width: 1px 0 0 0; }  table.frame-all { border-width: 1px; }  table.frame-sides { border-width: 0 1px; }  table.frame-topbot { border-width: 1px 0; }  th.halign-left, td.halign-left { text-align: left; }  th.halign-right, td.halign-right { text-align: right; }  th.halign-center, td.halign-center { text-align: center; }  th.valign-top, td.valign-top { vertical-align: top; }  th.valign-bottom, td.valign-bottom { vertical-align: bottom; }  th.valign-middle, td.valign-middle { vertical-align: middle; }  table thead th, table tfoot th { font-weight: bold; }  tbody tr th { display: table-cell; line-height: 1.4; background: whitesmoke; }  tbody tr th, tbody tr th p, tfoot tr th, tfoot tr th p { color: #222222; font-weight: bold; }  p.tableblock &gt; code:only-child { background: none; padding: 0; }  table tr.even, table tr.alt, table tr:nth-of-type(2n) {     background: #f9f9f9 none repeat scroll 0 0; } div.table-responsive {  border: 0; }  .sql p {  font-family: courier; } &lt;/style&gt;&lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.2.0/css/font-awesome.min.css&quot;&gt;&lt;div id=&quot;content&quot; class=&quot;blog-post-asciidoc&quot;&gt;  &lt;div id=&quot;preamble&quot;&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;It’s safe to say that any company who was writing software ten years ago—and is building &lt;a href=&quot;http://martinfowler.com/articles/microservices.html&quot; target=&quot;_blank&quot;&gt;microservices&lt;/a&gt; today—will need to integrate with &lt;a href=&quot;https://en.wikipedia.org/wiki/Legacy_system&quot; target=&quot;_blank&quot;&gt;legacy systems&lt;/a&gt;. In this article, we will explore building cloud-native microservices that still need to integrate with legacy systems. We’ll use practices from Martin Fowler’s &lt;a href=&quot;http://www.martinfowler.com/bliki/StranglerApplication.html&quot; target=&quot;_blank&quot;&gt;Strangler Application&lt;/a&gt; to slowly strangle domain data away from a legacy system using microservices.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;When building microservices, the general approach is to take &lt;a href=&quot;http://martinfowler.com/bliki/MonolithFirst.html&quot; target=&quot;_blank&quot;&gt;existing monoliths&lt;/a&gt; and to decompose their components into new microservices. The most critical concerns in this method have much less to do with the application code and more to do with &lt;em&gt;handling data&lt;/em&gt;. This article will focus on various methods of strangling a monolith’s ownership of domain data by transitioning the &lt;a href=&quot;https://en.wikipedia.org/wiki/System_of_record&quot; target=&quot;_blank&quot;&gt;system of record&lt;/a&gt; over time.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Throughout this article, we’ll use a &lt;a href=&quot;https://github.com/kbastani/cloud-native-microservice-strangler-example&quot; target=&quot;_blank&quot;&gt;reference application&lt;/a&gt; built with &lt;a href=&quot;http://projects.spring.io/spring-boot/&quot; target=&quot;_blank&quot;&gt;Spring Boot&lt;/a&gt; and &lt;a href=&quot;http://projects.spring.io/spring-cloud/&quot; target=&quot;_blank&quot;&gt;Spring Cloud&lt;/a&gt;. The example demonstrates techniques for integrating a cloud-native microservice architecture with legacy applications in an existing &lt;a href=&quot;https://en.wikipedia.org/wiki/Service-oriented_architecture&quot; target=&quot;_blank&quot;&gt;SOA&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_going_cloud_native&quot;&gt;Going Cloud Native&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Many companies want to start taking advantage of the public cloud without having to migrate every line of business application at the same time. The reasons for this are numerous. The existing line of business applications can be thought of as the vital organs of a living organism. During the migration, think about the complex relationships between the existing components deployed to your infrastructure. Think about the dependencies of your applications and the connections between them. Think about every application that relies on a database or network file system. These are among the many considerations that will cause a migration to become an expensive and time-consuming project.&lt;/p&gt;&lt;/div&gt;&lt;div style=&quot;display: block; padding: inherit; max-width:30em;&quot; class=&quot;imageblock&quot;&gt;&lt;div style=&quot;text-align: left; margin: auto;&quot; class=&quot;content&quot;&gt;&lt;img style=&quot;margin: auto !important;&quot; src=&quot;http://i.imgur.com/cREaaaW.png&quot; alt=&quot;Hybrid cloud data center integration&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The unfathomable complexity of migrating applications to the cloud can delay a decision from being made until the business deems necessary, which is usually triggered by a major event that results in a loss of revenue. This ticking time bomb will result in a &lt;a href=&quot;http://searchcloudcomputing.techtarget.com/feature/When-to-adopt-the-lift-and-shift-cloud-migration-model&quot; target=&quot;_blank&quot;&gt;&lt;em&gt;lift-and-shift&lt;/em&gt; migration&lt;/a&gt; of applications. The problem with the lift and shift approach is that any technical debt that you had on-premises finds new life in the cloud environment. The problem being, the architectural and infrastructure issues that triggered the cloud migration still may not be fixed.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The approach I discuss in this article focuses on addressing the underlying symptoms of legacy systems that decrease system resiliency and lead to costly failures.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;a name=&#39;more&#39;&gt;&lt;/a&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_legacy_systems&quot;&gt;Legacy Systems&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The chief benefit of building microservices is that the time it takes to deliver valuable features into production is significantly reduced. By creating microservices that are cloud-native, you can make use of on-demand virtual compute resources of the cloud to operate and scale your applications. Microservices provide agility while cloud-native architectures provide our distributed applications with additional performance, scalability, and resiliency characteristics.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;To gain the benefit of agility with microservices, you may not be required to move some or even all of your existing applications to the cloud in a &lt;a href=&quot;https://en.wikipedia.org/wiki/Big_bang_adoption&quot; target=&quot;_blank&quot;&gt;big bang migration&lt;/a&gt;. There are &lt;a href=&quot;https://en.wikipedia.org/wiki/Cloud_computing#Hybrid_cloud&quot; target=&quot;_blank&quot;&gt;hybrid approaches&lt;/a&gt; that can enable you to begin transitioning your business logic to the cloud by creating cloud-native microservices that will strangle legacy systems that are still on-premises.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;We can start by building microservices that are deployed to the public cloud and integrate with legacy systems that sit on-premises.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_data_ownership&quot;&gt;Data Ownership&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The most common pain point that companies experience when building microservices is handling &lt;em&gt;domain data&lt;/em&gt;. Your domain data is likely going to be trapped inside a large shared database—probably being of the Oracle or IBM variety. Because of this, your new microservices will be dependent on retrieving data from a large shared database.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Refactoring your monoliths to microservices will take time. The data migration is going to be an immediate challenge, as parts of the monolith will involve access to data inside a large shared database. There are different approaches to managing this, depending on the severity of risk tolerable for the system.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Microservices can reach into the legacy system and fetch data in the same way that front-end applications do. While this isn’t a good long-term strategy, it can be an intermediate step in gaining control over the legacy backend.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_extending_domain_data&quot;&gt;Extending Domain Data&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;One method for handling legacy data source integration for microservices is to extend domain data. In this approach, we gain the benefit of &lt;em&gt;agility&lt;/em&gt; in microservices by extending base domain objects retrieved from a legacy system. Going back to the primary goal of building microservices, we’re doing it to gain &lt;em&gt;speed and agility&lt;/em&gt; by being able to make changes quickly and having control to deploy changes to production continuously. We are still able to gain this benefit by extending domain data that can be retrieved from a legacy system.&lt;/p&gt;&lt;/div&gt;&lt;div style=&quot;display: block; padding: inherit; max-width:26em;&quot; class=&quot;imageblock&quot;&gt;&lt;div style=&quot;text-align: left; margin: auto;&quot; class=&quot;content&quot;&gt;&lt;img style=&quot;margin: auto !important;&quot; src=&quot;http://i.imgur.com/qdXqYUl.png&quot; alt=&quot;Extending domain data&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Suppose you’re developing software for a bank. You’ve been tasked with building a microservice that will wrap around an existing customer domain object. If you want to extend that customer object to include new fields for a feature, you can just persist the new fields of the customer object to the microservice’s database. Now when a customer domain object is requested through your microservice, a call to the legacy system will retrieve the base customer object, and any new extended fields are retrieved from your microservice’s database. The new fields are combined with the base customer object before being returned as a single domain object to consumers.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;There are a few pros and cons to this approach.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Pros:&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;ulist&quot;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;The legacy system does not need to be altered to support the development of new microservices&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;New features can be deployed independently without being tightly coupled to the legacy system&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;It ensures that any existing calls to a legacy web service are unaltered for other apps&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Cons:&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;ulist&quot;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Scalability may be a concern in the case that the base legacy service is not cloud-native&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Availability will be impacted if the base legacy service’s shared database suffers an outage&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;The dependency on the legacy system’s shared database is increased, making it harder to decompose&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_legacy_soa_integration&quot;&gt;Legacy SOA Integration&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Eventually, the new features that extend the base customer object will need to be consumed by legacy applications. Any new applications that consume microservices will have the benefit of using newer libraries that provide REST clients to make integration relatively straightforward. The same will not be true for legacy applications. The existing legacy system needs to be able to consume the new microservices without having to upgrade an application framework, platform, or library.&lt;/p&gt;&lt;/div&gt;&lt;div style=&quot;display: block; padding: inherit; max-width:24em;&quot; class=&quot;imageblock&quot;&gt;&lt;div style=&quot;text-align: left; margin: auto;&quot; class=&quot;content&quot;&gt;&lt;img style=&quot;margin: auto !important;&quot; src=&quot;http://i.imgur.com/7iz8pc1.png&quot; alt=&quot;Legacy SOAP web services and shared database&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;After a new microservice has been released—which &lt;em&gt;extends domain data&lt;/em&gt; from the legacy system—we need to start migrating all applications to consume the new microservice. The benefit we gained with the extension approach was &lt;em&gt;agility&lt;/em&gt; (and that’s good!), but we should be &lt;em&gt;decreasing&lt;/em&gt; our reliance on a large shared database for the microservice approach. To do this, we need to create an application that will sit on the edge of our legacy system and provide integration services to legacy applications that need to consume data from our new microservices.&lt;/p&gt;&lt;/div&gt;&lt;div style=&quot;display: block; padding: inherit; max-width:40em;&quot; class=&quot;imageblock&quot;&gt;&lt;div style=&quot;text-align: left; margin: auto;&quot; class=&quot;content&quot;&gt;&lt;img style=&quot;margin: auto !important;&quot; src=&quot;http://i.imgur.com/aG6qckH.png&quot; alt=&quot;Legacy edge service&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;To consume the new microservices from existing applications, you should think about limiting the amount of time spent on &lt;a href=&quot;https://en.wikipedia.org/wiki/Software_modernization&quot; target=&quot;_blank&quot;&gt;legacy modernization&lt;/a&gt;. Instead, there should be a focus on directing any available work cycles towards permanently reducing the risk per deployment—achieved by adopting a system that enables &lt;em&gt;deploying changes more often&lt;/em&gt;. To support this goal, we can impose the following principles of integration for both legacy and microservices.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;ulist&quot;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Legacy applications should be able to consume new microservices without being upgraded&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Microservices should be &lt;em&gt;the only&lt;/em&gt; direct consumer of existing legacy web services&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The Legacy Edge Service application will act as an adapter to support the expected contract and messaging protocols of existing legacy applications. The functions of the Legacy Edge Service will, in some ways, resemble functions and features that you would get from an &lt;a href=&quot;https://en.wikipedia.org/wiki/Enterprise_service_bus&quot; target=&quot;_blank&quot;&gt;ESB (Enterprise Service Bus)&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_the_dreaded_esb&quot;&gt;The Dreaded ESB&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The diagram below shows a view of the Customer Service connected to an ESB. This example is a familiar pattern of architecture for an SOA, where the ESB handles centralizing the integration concerns of applications.&lt;/p&gt;&lt;/div&gt;&lt;div style=&quot;display: block; padding: inherit; max-width:30em;&quot; class=&quot;imageblock&quot;&gt;&lt;div style=&quot;text-align: left; margin: auto;&quot; class=&quot;content&quot;&gt;&lt;img style=&quot;margin: auto !important;&quot; src=&quot;http://i.imgur.com/0Y1ywRk.png&quot; alt=&quot;Legacy web services SOA and ESB&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;In this scenario, we would have already re-routed any point-to-point calls between web services through the ESB. The ESB acts as a gateway, router, and transport layer for orchestrating and composing larger business services from components existing as backend services. These larger composite business services are monoliths in the SOA that can be decomposed into microservices. There will also be front-end applications that consume the business services through the ESB. These applications will also need to be decomposed into microservices, where self-contained business logic or any ownership of domain data exists.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;In this scenario, when new microservices are ready to start taking over ownership of domain data, we can use the ESB to switch incoming requests from the underlying service components to microservices.&lt;/p&gt;&lt;/div&gt;&lt;div style=&quot;display: block; padding: inherit; max-width:30em;&quot; class=&quot;imageblock&quot;&gt;&lt;div style=&quot;text-align: left; margin: auto;&quot; class=&quot;content&quot;&gt;&lt;img style=&quot;margin: auto !important;&quot; src=&quot;http://i.imgur.com/cREaaaW.png&quot; alt=&quot;Legacy edge service ESB adapter&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;In the diagram above we see the Legacy Edge Service is providing adapter support to the ESB, which can be used to support any existing service orchestration or business process. As microservices begin replacing larger service units of the SOA, the ESB will switch traffic to the Legacy Edge Service and consume microservice routes that wrap around legacy web services that are being strangled.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;It’s important that we can simply update the route configuration of existing legacy applications, making it possible to consume microservices without making source code changes. By doing this, we can defer modernizing legacy applications until they are ready to be refactored into microservices. The Legacy Edge Service provides this significant benefit.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;admonitionblock tip&quot;&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;icon&quot;&gt;&lt;i class=&quot;fa icon-tip&quot; title=&quot;Tip&quot;&gt;&lt;/i&gt;&lt;/td&gt;&lt;td class=&quot;content&quot;&gt;Spending time on legacy modernization is usually not a differentiator for the business. Instead, focus that engineering effort on tasks that help the business gain more agility—by &lt;em&gt;strangling&lt;/em&gt; legacy applications with new microservices. &lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_transferring_data_ownership&quot;&gt;Transferring Data Ownership&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;After legacy consumers are re-routed to the Legacy Edge Service, the only consumer of a legacy web service component will be a microservice. Because of this, we are now able to &lt;em&gt;shift the system of record&lt;/em&gt; safely for domain data retrieved from the legacy web services. With each unique request to a microservice that touches data in the legacy system, we can move ownership of that data to the new system of record—&lt;em&gt;our microservices&lt;/em&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;A microservice will transfer ownership of domain data by persisting the response from the legacy system to its exclusive database. Afterward, any subsequent request to the microservice for the same domain data will &lt;em&gt;not&lt;/em&gt; require a call back to the legacy system. Utilizing this technique, we can slowly strangle the monolithic service components of the legacy system by transitioning the system of record for newly requested domain data.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_cloud_native_applications&quot;&gt;Cloud Native Applications&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;As the volume of calls from microservices to the legacy system decreases over time, microservices can begin to take advantage of the other benefits of cloud-native architectures.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The approach here is similar to how web applications cache responses. We can consider for each call to the legacy system that we’re inevitably interacting with some &lt;a href=&quot;https://en.wikipedia.org/wiki/Scalability#Horizontal_and_vertical_scaling&quot; target=&quot;_blank&quot;&gt;vertically scaled&lt;/a&gt; infrastructure that has finite capacity. For each unique incoming request, we incur one hit on the legacy system, which can unfurl into many hits incurred on the vertically scaled infrastructure running on-premises. For every incoming non-unique request, we’ll incur one or more hit to cloud-native applications that are running on horizontally scaled infrastructure in the cloud. With this method, we’ll see the on-premises compute sharply drop off—&lt;em&gt;as more capacity is demanded&lt;/em&gt;—in favor of &lt;a href=&quot;https://en.wikipedia.org/wiki/Elasticity_(cloud_computing)&quot; target=&quot;_blank&quot;&gt;elastic compute&lt;/a&gt; served from the public cloud.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_monolith_to_microservice&quot;&gt;Monolith to Microservice&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The method that I explained above came to me about a year after completing a greenfield microservices project on a similar architecture. The project would be a pilot for building microservices that would extend legacy components of a retail banking platform—a system that was already serving millions of users in production.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The result of the project was a success, as we realized the direct benefits of &lt;a href=&quot;http://thenewstack.io/microservices-changed-matter/&quot; target=&quot;_blank&quot;&gt;being agile with the microservices approach&lt;/a&gt;. While we were able to deliver business differentiating features quickly, our speed to market came at the cost of tightly coupling microservices to the existing components of the legacy system.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;There were a few factors that required us to create this tight coupling.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;ulist&quot;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;We shackled ourselves into vertically scaled infrastructure provisioned in a private data center&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;We didn’t have a platform that supported cloud-native application development&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;We didn’t have a self-service tool in place to automate provisioning of databases for new microservices&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Because of these factors, we had to use the legacy system’s large shared database for persistence by our new microservices. We would use database access control features to isolate our microservice’s tables from being directly accessed by other applications. Even though these access features are for &lt;a href=&quot;https://en.wikipedia.org/wiki/Multitenancy&quot; target=&quot;_blank&quot;&gt;multitenancy&lt;/a&gt;, it would allow us to migrate the schema easily to a separate database at a later time.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The fundamental issue with this approach was that it took us seven months to get the first microservice release into production. The early dependency on the shared database posed too much of a risk of impacting millions of production users. We realized that risk when we discovered a framework defect that caused our new microservices to be unable to release database cursors when undergoing stress testing in the performance environment. The lesson learned in this experience was an important one.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;A new microservice should encapsulate both the &lt;em&gt;unit of service&lt;/em&gt; and the &lt;em&gt;unit of failure&lt;/em&gt;—in production—on the very first day of development.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;When I say &lt;em&gt;unit of service&lt;/em&gt; and &lt;em&gt;unit of failure&lt;/em&gt; I am referring to a quote by storied computer scientist, Jim Gray. Gray &lt;a href=&quot;http://www.hpl.hp.com/techreports/tandem/TR-85.7.pdf&quot; target=&quot;_blank&quot;&gt;wrote a technical report&lt;/a&gt; in 1985 titled &lt;em&gt;Why Do Computers Stop and What Can Be Done About It?&lt;/em&gt;&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;In the report, Gray talks about how to achieve fault-tolerance in software.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;quoteblock&quot;&gt;&lt;blockquote&gt;As with hardware, the key to software fault-tolerance is to hierarchically decompose large systems into modules, each module being a unit of service and a unit of failure. A failure of a module does not propagate beyond the module. &lt;/blockquote&gt;&lt;div class=&quot;attribution&quot;&gt;— Jim Gray &lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;When I hear thought leaders talk about microservices and say that the ideas are not new, I always think back to this quote by Jim.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_reference_architecture&quot;&gt;Reference Architecture&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The architecture for the reference application consists of multiple application layers deployed to infrastructure that is both on-premises and in the public cloud. This example works equally well when all your applications have been migrated to the cloud, but the reality is that this is almost never the case. We’ll assume throughout this example that the only viable path for you to adopt cloud-native microservices at your company is to go with a hybrid approach.&lt;/p&gt;&lt;/div&gt;&lt;div style=&quot;display: block; padding: inherit; max-width:40em;&quot; class=&quot;imageblock&quot;&gt;&lt;div style=&quot;text-align: left; margin: auto;&quot; class=&quot;content&quot;&gt;&lt;img style=&quot;margin: auto !important;&quot; src=&quot;http://i.imgur.com/ZhuwpbZ.png&quot; alt=&quot;Example Cloud Native Strangler Microservice Architecture&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The reference architecture in this diagram was modeled after a real world example of a hybrid cloud approach that uses &lt;a href=&quot;https://en.wikipedia.org/wiki/Cloud_Foundry&quot; target=&quot;_blank&quot;&gt;Cloud Foundry&lt;/a&gt; for operating cloud-native applications. The Cloud Foundry deployment uses a network bridge to connect to legacy systems deployed in a data center. Applications are categorized into different zones, which are deployed to infrastructure that is either in the public cloud or a data center.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_public_cloud&quot;&gt;Public Cloud&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Three zones represent applications deployed to the public cloud. These three areas separate applications into distinct categories. The difference between the zones has to do with how applications are located.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;ulist&quot;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Public Internet – Front-end applications and public REST APIs&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Platform Services – Managed cloud platform services&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Service Discovery – Microservices that subscribe to a discovery service&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The &lt;em&gt;Public Internet Zone&lt;/em&gt; uses routing from the cloud platform, requiring a server-side load balancer to route requests from the public internet to your applications.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The &lt;em&gt;Platform Services Zone&lt;/em&gt; consists of services that are explicitly bound to applications deployed using the platform. The platform services are found through this relationship between platform and application.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The &lt;em&gt;Service Discovery Zone&lt;/em&gt; consists of microservices that can only be discovered through the use of a discovery service. To locate other microservices, the platform provides a discovery service, which can be used to find the address of applications in the service discovery zone.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_data_center&quot;&gt;Data Center&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;There is one zone in the data center, and that is the Legacy Application Zone. Microservices deployed in the public cloud will need to connect to web services deployed to infrastructure in this zone. While over time the business logic that exists in the legacy zone will be refactored into microservices, the migration of your domain data may require extracting and moving data that is stored in a large shared database. To solve this problem and keep the system online is similar to swapping out the engine of an airplane while still in flight.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_reference_applications&quot;&gt;Reference Applications&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The &lt;a href=&quot;https://github.com/kbastani/cloud-native-microservice-strangler-example&quot; target=&quot;_blank&quot;&gt;source code&lt;/a&gt; in this reference consists of eight separate applications. Each application in this example is built with Spring Boot and Spring Cloud.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;ulist&quot;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Legacy Applications&lt;/p&gt;&lt;div class=&quot;ulist&quot;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Customer Service&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Legacy Edge Service&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Microservices&lt;/p&gt;&lt;div class=&quot;ulist&quot;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Discovery Service&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Edge Service&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Config Service&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;User Service&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Profile Service&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Profile Web&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_legacy_applications&quot;&gt;Legacy Applications&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The complexity of real world legacy systems will no doubt be more complicated than this scale model. This example application contains the minimum number of applications to demonstrate the strangler integration pattern.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;sect3&quot;&gt;&lt;h4 id=&quot;_customer_service&quot;&gt;Customer Service&lt;/h4&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The &lt;em&gt;Customer Service&lt;/em&gt; is a Spring Boot application that simulates a typical SOA web service by exposing a single SOAP endpoint for retrieving a customer domain object.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-java hljs&quot; data-lang=&quot;java&quot;&gt;&lt;span class=&quot;hljs-annotation&quot;&gt;@Endpoint&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-class&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;CustomerEndpoint&lt;/span&gt; &lt;/span&gt;{&lt;br /&gt;    &lt;span class=&quot;hljs-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;final&lt;/span&gt; String NAMESPACE_URI = &lt;span class=&quot;hljs-string&quot;&gt;&quot;http://kennybastani.com/guides/customer-service&quot;&lt;/span&gt;;&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-keyword&quot;&gt;private&lt;/span&gt; CustomerRepository customerRepository;&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-annotation&quot;&gt;@Autowired&lt;/span&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;CustomerEndpoint&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(CustomerRepository customerRepository)&lt;/span&gt; &lt;/span&gt;{&lt;br /&gt;        &lt;span class=&quot;hljs-keyword&quot;&gt;this&lt;/span&gt;.customerRepository = customerRepository;&lt;br /&gt;    }&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-annotation&quot;&gt;@PayloadRoot&lt;/span&gt;(namespace = NAMESPACE_URI, localPart = &lt;span class=&quot;hljs-string&quot;&gt;&quot;getCustomerRequest&quot;&lt;/span&gt;)&lt;br /&gt;    &lt;span class=&quot;hljs-annotation&quot;&gt;@ResponsePayload&lt;/span&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; GetCustomerResponse &lt;span class=&quot;hljs-title&quot;&gt;getCustomer&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(@RequestPayload GetCustomerRequest request)&lt;/span&gt; &lt;/span&gt;{&lt;br /&gt;        GetCustomerResponse response = &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; GetCustomerResponse();&lt;br /&gt;        response.setCustomer(customerRepository.findCustomer(request.getUsername()));&lt;br /&gt;        &lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; response;&lt;br /&gt;    }&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-annotation&quot;&gt;@PayloadRoot&lt;/span&gt;(namespace = NAMESPACE_URI, localPart = &lt;span class=&quot;hljs-string&quot;&gt;&quot;updateCustomerRequest&quot;&lt;/span&gt;)&lt;br /&gt;    &lt;span class=&quot;hljs-annotation&quot;&gt;@ResponsePayload&lt;/span&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; UpdateCustomerResponse &lt;span class=&quot;hljs-title&quot;&gt;updateCustomer&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(@RequestPayload UpdateCustomerRequest request)&lt;/span&gt;&lt;br /&gt;            &lt;span class=&quot;hljs-keyword&quot;&gt;throws&lt;/span&gt; SOAPException &lt;/span&gt;{&lt;br /&gt;        UpdateCustomerResponse response = &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; UpdateCustomerResponse();&lt;br /&gt;        response.setSuccess(customerRepository.updateCustomer(request.getCustomer()) &amp;gt; &lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;);&lt;br /&gt;        &lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; response;&lt;br /&gt;    }&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The &lt;code&gt;CustomerEndpoint&lt;/code&gt; has a &lt;code&gt;GetCustomer&lt;/code&gt; method that is mapped to a SOAP request payload at &lt;code&gt;/v1/customers&lt;/code&gt;. The input parameter for this request is simply the username of the customer. The username will be used to lookup the record from a &quot;large shared database&quot;, which will be retrieved using &lt;code&gt;JdbcTemplate&lt;/code&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-java hljs&quot; data-lang=&quot;java&quot;&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; Customer &lt;span class=&quot;hljs-title&quot;&gt;findCustomer&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(String username)&lt;/span&gt; &lt;/span&gt;{&lt;br /&gt;    Assert.notNull(username);&lt;br /&gt;&lt;br /&gt;    Customer result;&lt;br /&gt;&lt;br /&gt;    result = jdbcTemplate&lt;br /&gt;            .query(&lt;span class=&quot;hljs-string&quot;&gt;&quot;SELECT id, first_name, last_name, email, username FROM customer WHERE username = ?&quot;&lt;/span&gt;,&lt;br /&gt;                    &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; Object[]{username},&lt;br /&gt;                    (rs, rowNum) -&amp;gt; {&lt;br /&gt;                        Customer customer = &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; Customer();&lt;br /&gt;                        customer.setFirstName(rs.getString(&lt;span class=&quot;hljs-string&quot;&gt;&quot;first_name&quot;&lt;/span&gt;));&lt;br /&gt;                        customer.setLastName(rs.getString(&lt;span class=&quot;hljs-string&quot;&gt;&quot;last_name&quot;&lt;/span&gt;));&lt;br /&gt;                        customer.setEmail(rs.getString(&lt;span class=&quot;hljs-string&quot;&gt;&quot;email&quot;&lt;/span&gt;));&lt;br /&gt;                        customer.setUsername(rs.getString(&lt;span class=&quot;hljs-string&quot;&gt;&quot;username&quot;&lt;/span&gt;));&lt;br /&gt;                        &lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; customer;&lt;br /&gt;                    }).stream().findFirst().orElse(&lt;span class=&quot;hljs-keyword&quot;&gt;null&lt;/span&gt;);&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; result;&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;To retrieve a response from this service we will make a POST request of the content type &lt;code&gt;xml/text&lt;/code&gt; to the endpoint &lt;code&gt;/v1/customers&lt;/code&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-xml hljs&quot; data-lang=&quot;xml&quot;&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-title&quot;&gt;soapenv:Envelope&lt;/span&gt; &lt;span class=&quot;hljs-attribute&quot;&gt;xmlns:soapenv&lt;/span&gt;=&lt;span class=&quot;hljs-value&quot;&gt;&quot;http://schemas.xmlsoap.org/soap/envelope/&quot;&lt;/span&gt;&lt;br /&gt;                  &lt;span class=&quot;hljs-attribute&quot;&gt;xmlns:gs&lt;/span&gt;=&lt;span class=&quot;hljs-value&quot;&gt;&quot;http://kennybastani.com/guides/customer-service&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br /&gt;   &lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-title&quot;&gt;soapenv:Header&lt;/span&gt;/&amp;gt;&lt;/span&gt;&lt;br /&gt;   &lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-title&quot;&gt;soapenv:Body&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br /&gt;      &lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-title&quot;&gt;gs:getCustomerRequest&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br /&gt;         &lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-title&quot;&gt;gs:username&lt;/span&gt;&amp;gt;&lt;/span&gt;user&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-title&quot;&gt;gs:username&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br /&gt;      &lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-title&quot;&gt;gs:getCustomerRequest&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br /&gt;   &lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-title&quot;&gt;soapenv:Body&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-title&quot;&gt;soapenv:Envelope&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;An XML response is then returned from the SOAP request and looks like the following result.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-xml hljs&quot; data-lang=&quot;xml&quot;&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-title&quot;&gt;SOAP-ENV:Envelope&lt;/span&gt; &lt;span class=&quot;hljs-attribute&quot;&gt;xmlns:SOAP-ENV&lt;/span&gt;=&lt;span class=&quot;hljs-value&quot;&gt;&quot;http://schemas.xmlsoap.org/soap/envelope/&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-title&quot;&gt;SOAP-ENV:Header&lt;/span&gt;/&amp;gt;&lt;/span&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-title&quot;&gt;SOAP-ENV:Body&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br /&gt;        &lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-title&quot;&gt;ns2:getCustomerResponse&lt;/span&gt; &lt;span class=&quot;hljs-attribute&quot;&gt;xmlns:ns2&lt;/span&gt;=&lt;span class=&quot;hljs-value&quot;&gt;&quot;http://kennybastani.com/guides/customer-service&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br /&gt;            &lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-title&quot;&gt;ns2:customer&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br /&gt;                &lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-title&quot;&gt;ns2:username&lt;/span&gt;&amp;gt;&lt;/span&gt;user&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-title&quot;&gt;ns2:username&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br /&gt;                &lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-title&quot;&gt;ns2:firstName&lt;/span&gt;&amp;gt;&lt;/span&gt;John&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-title&quot;&gt;ns2:firstName&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br /&gt;                &lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-title&quot;&gt;ns2:lastName&lt;/span&gt;&amp;gt;&lt;/span&gt;Doe&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-title&quot;&gt;ns2:lastName&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br /&gt;                &lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-title&quot;&gt;ns2:email&lt;/span&gt;&amp;gt;&lt;/span&gt;john.doe@example.com&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-title&quot;&gt;ns2:email&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br /&gt;            &lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-title&quot;&gt;ns2:customer&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br /&gt;        &lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-title&quot;&gt;ns2:getCustomerResponse&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-title&quot;&gt;SOAP-ENV:Body&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-title&quot;&gt;SOAP-ENV:Envelope&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The &lt;em&gt;Customer Service&lt;/em&gt; here is simulating one of the most depended upon applications deployed on-premises. Simply modernizing this application will not solve the most important problem. The problem is that this service has to maintain expectations with mostly all critical applications that are running in production. Simply replacing this application with a microservice would mean updating every one of the applications that are depending on it.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;To reduce the risk of disrupting applications relying on this service, we can start building a microservice that extends its customer object with new features. As legacy applications begin to be updated to use the new features of the microservice, we can create a &lt;em&gt;Legacy Edge&lt;/em&gt; application that gives older applications a way to consume microservices without needing to modernize.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect3&quot;&gt;&lt;h4 id=&quot;_legacy_edge_service&quot;&gt;Legacy Edge Service&lt;/h4&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The &lt;em&gt;Legacy Edge Service&lt;/em&gt; is an API gateway that maps requests from legacy applications to responses from microservices—while adhering to the messaging protocol expectations of the legacy consumers. This service will contain no business logic. The purpose of this service is vital to being able to rewire direct connections away from the &lt;em&gt;Customer Service&lt;/em&gt;, so that we can safely transition the system of record for a customer’s domain data to a new microservice.&lt;/p&gt;&lt;/div&gt;&lt;div style=&quot;display: block; padding: inherit; max-width:30em;&quot; class=&quot;imageblock&quot;&gt;&lt;div style=&quot;text-align: left; margin: auto;&quot; class=&quot;content&quot;&gt;&lt;img style=&quot;margin: auto !important;&quot; src=&quot;http://i.imgur.com/cREaaaW.png&quot; alt=&quot;Legacy edge microservice&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Remember, we want to be able to make the switch as seamless as possible without performing any risky data migrations. This is the service that allows us to be able to do that.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-java hljs&quot; data-lang=&quot;java&quot;&gt;&lt;span class=&quot;hljs-annotation&quot;&gt;@Endpoint&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-class&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;CustomerEndpoint&lt;/span&gt; &lt;/span&gt;{&lt;br /&gt;    &lt;span class=&quot;hljs-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;final&lt;/span&gt; String NAMESPACE_URI = &lt;span class=&quot;hljs-string&quot;&gt;&quot;http://kennybastani.com/guides/customer-service&quot;&lt;/span&gt;;&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-keyword&quot;&gt;private&lt;/span&gt; OAuth2RestOperations restTemplate;&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-annotation&quot;&gt;@Autowired&lt;/span&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;CustomerEndpoint&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(OAuth2RestOperations oAuth2RestTemplate)&lt;/span&gt; &lt;/span&gt;{&lt;br /&gt;        &lt;span class=&quot;hljs-keyword&quot;&gt;this&lt;/span&gt;.restTemplate = oAuth2RestTemplate;&lt;br /&gt;    }&lt;br /&gt;&lt;br /&gt;    ...&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;In the code snippet above, the &lt;em&gt;Legacy Edge Service&lt;/em&gt; replicates the same SOAP endpoint as the &lt;em&gt;Customer Service&lt;/em&gt;, with a few differences. There is a new microservice called the &lt;em&gt;Profile Service&lt;/em&gt; that is protected with OAuth2 authorization. We should not expect that each of our legacy applications will be able to support the OAuth2 client specification without extensive changes. The legacy edge service will take care of these concerns for us.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-java hljs&quot; data-lang=&quot;java&quot;&gt;&lt;span class=&quot;hljs-annotation&quot;&gt;@PayloadRoot&lt;/span&gt;(namespace = NAMESPACE_URI, localPart = &lt;span class=&quot;hljs-string&quot;&gt;&quot;getCustomerRequest&quot;&lt;/span&gt;)&lt;br /&gt;&lt;span class=&quot;hljs-annotation&quot;&gt;@ResponsePayload&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; GetCustomerResponse &lt;span class=&quot;hljs-title&quot;&gt;getCustomer&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(@RequestPayload GetCustomerRequest request)&lt;/span&gt; &lt;/span&gt;{&lt;br /&gt;    GetCustomerResponse response = &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; GetCustomerResponse();&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-comment&quot;&gt;// Get customer object from profile microservice&lt;/span&gt;&lt;br /&gt;    response.setCustomer(Optional.ofNullable(&lt;br /&gt;            restTemplate.getForObject(&lt;span class=&quot;hljs-string&quot;&gt;&quot;http://profile-service/v1/profiles/{username}&quot;&lt;/span&gt;,&lt;br /&gt;                    Customer.class, request.getUsername()))&lt;br /&gt;            .map(c -&amp;gt; c).orElse(&lt;span class=&quot;hljs-keyword&quot;&gt;null&lt;/span&gt;));&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; response;&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Here we see that the &lt;em&gt;Legacy Edge Service&lt;/em&gt; uses the &lt;em&gt;Discovery Service&lt;/em&gt; to make a request to an OAuth2 protected resource on the &lt;em&gt;Profile Service&lt;/em&gt;. This microservice returns a &lt;code&gt;Profile&lt;/code&gt; object, which is the extended domain object for &lt;code&gt;Customer&lt;/code&gt;. The legacy edge service just translates the new &lt;code&gt;Profile&lt;/code&gt; object to the expected &lt;code&gt;Customer&lt;/code&gt; object and returns it as a SOAP response to consumers.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;By providing this endpoint, no legacy applications will need to be upgraded. To start consuming microservices all we need to do is point a legacy application to the &lt;code&gt;Legacy Edge Service&lt;/code&gt; instead of the &lt;code&gt;Customer Service&lt;/code&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;This example has a &lt;a href=&quot;https://cloud.spring.io/spring-cloud-security/&quot; target=&quot;_blank&quot;&gt;Spring Cloud Security&lt;/a&gt; OAuth2 resource and authorization server, which is a microservice named the &lt;em&gt;User Service&lt;/em&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The &lt;em&gt;Legacy Edge Service&lt;/em&gt; will use an authorization grant type of &lt;code&gt;client_credentials&lt;/code&gt; to access the protected resources of a microservice. The beautiful thing about Spring Cloud Security is that each microservice will call back to the User Service to validate an access token before being granted with access to a protected resource. This process federated authorization for microservices is called &lt;em&gt;token relay&lt;/em&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Any requests that come in from the public internet zone will need to authenticate using an authorization grant type of &lt;code&gt;authorization_code&lt;/code&gt;. This grant type differs from &lt;code&gt;client_credentials&lt;/code&gt; as it forces public internet users to authenticate through a provided login form before being granted an access token.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Since we cannot expect legacy applications to implement the OAuth2 workflow, the &lt;code&gt;Legacy Edge Service&lt;/code&gt; uses the &lt;code&gt;client_credentials&lt;/code&gt; grant type to request access tokens on behalf of the legacy system.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_microservices&quot;&gt;Microservices&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The microservices in this example are built using Spring Boot and Spring Cloud.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;sect3&quot;&gt;&lt;h4 id=&quot;_discovery_service&quot;&gt;Discovery Service&lt;/h4&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The &lt;em&gt;Discovery Service&lt;/em&gt; is a platform service that maintains a service registry that is redistributed to applications in the &lt;em&gt;Service Discovery Zone&lt;/em&gt;. For this example, we’ll stand up a &lt;a href=&quot;https://spring.io/guides/gs/service-registration-and-discovery/&quot; target=&quot;_blank&quot;&gt;Eureka Server&lt;/a&gt; from the Spring Cloud Netflix.&lt;/p&gt;&lt;/div&gt;&lt;div style=&quot;display: block; padding: inherit; max-width:45em;&quot; class=&quot;imageblock&quot;&gt;&lt;div style=&quot;text-align: left; margin: auto;&quot; class=&quot;content&quot;&gt;&lt;img style=&quot;margin: auto !important;&quot; src=&quot;http://i.imgur.com/MRECAGD.png&quot; alt=&quot;Discovery service&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect3&quot;&gt;&lt;h4 id=&quot;_edge_service&quot;&gt;Edge Service&lt;/h4&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The &lt;em&gt;Edge Service&lt;/em&gt; is a platform service that uses the service registry from the &lt;code&gt;Discovery Service&lt;/code&gt; to provide a public API gateway to the REST APIs exposed by the microservices. We’re using this &lt;em&gt;Edge Service&lt;/em&gt; in a similar way as the &lt;code&gt;Legacy Edge Service&lt;/code&gt;, but exposing it to the public internet zone. The &lt;em&gt;Edge Service&lt;/em&gt; will compose each microservice into a single unified REST API that enforces the OAuth2 client specification. Any consumer of this service will be forced to use the &lt;code&gt;authorization_code&lt;/code&gt; grant type, which requires user-level authentication.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;For the &lt;em&gt;Edge Service&lt;/em&gt;, we are again drawing from the Spring Cloud Netflix project to embed a &lt;a href=&quot;https://spring.io/guides/gs/routing-and-filtering/&quot; target=&quot;_blank&quot;&gt;Zuul reverse proxy&lt;/a&gt; that acts as a single gateway to each microservice. For front-end applications, we can bind to this &lt;em&gt;Edge Service&lt;/em&gt; and use it as a single REST API that provides endpoints for every independent microservice.&lt;/p&gt;&lt;/div&gt;&lt;div style=&quot;display: block; padding: inherit; max-width:45em;&quot; class=&quot;imageblock&quot;&gt;&lt;div style=&quot;text-align: left; margin: auto;&quot; class=&quot;content&quot;&gt;&lt;img style=&quot;margin: auto !important;&quot; src=&quot;http://i.imgur.com/FQvktwv.png&quot; alt=&quot;Edge service&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect3&quot;&gt;&lt;h4 id=&quot;_user_service&quot;&gt;User Service&lt;/h4&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The &lt;em&gt;User Service&lt;/em&gt; is a platform service that contains an OAuth2 authorization and resource server for accessing any protected resources of our microservices. The &lt;em&gt;User Service&lt;/em&gt; will manage and secure how all consumers can access resources from our microservices. Here we are using Spring Cloud Security OAuth2 to issue and validate access tokens for each microservice. The added benefit of using Spring Cloud Security is that access tokens will be relayed in requests microservice-to-microservice, securing an entire chain of requests for resources as a feature of the application framework.&lt;/p&gt;&lt;/div&gt;&lt;div style=&quot;display: block; padding: inherit; max-width:45em;&quot; class=&quot;imageblock&quot;&gt;&lt;div style=&quot;text-align: left; margin: auto;&quot; class=&quot;content&quot;&gt;&lt;img style=&quot;margin: auto !important;&quot; src=&quot;http://i.imgur.com/dbZDivd.png&quot; alt=&quot;User service&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect3&quot;&gt;&lt;h4 id=&quot;_profile_service&quot;&gt;Profile Service&lt;/h4&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The &lt;em&gt;Profile Service&lt;/em&gt; is a microservice that extends the domain data of the legacy &lt;em&gt;Customer Service&lt;/em&gt;. This is the microservice that is strangling the domain data of the &lt;em&gt;Customer Service&lt;/em&gt;—and in the process—slowly transitioning the system of record away from the &lt;em&gt;large shared database&lt;/em&gt; in the legacy system. The &lt;em&gt;Profile Service&lt;/em&gt; exposes protected domain resources as a REST API, using the Spring Cloud Security project to implement the OAuth2 client workflow.&lt;/p&gt;&lt;/div&gt;&lt;div style=&quot;display: block; padding: inherit; max-width:45em;&quot; class=&quot;imageblock&quot;&gt;&lt;div style=&quot;text-align: left; margin: auto;&quot; class=&quot;content&quot;&gt;&lt;img style=&quot;margin: auto !important;&quot; src=&quot;http://i.imgur.com/6A9vwLr.png&quot; alt=&quot;Profile service&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-java hljs&quot; data-lang=&quot;java&quot;&gt;&lt;span class=&quot;hljs-annotation&quot;&gt;@RestController&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;hljs-annotation&quot;&gt;@RequestMapping&lt;/span&gt;(path = &lt;span class=&quot;hljs-string&quot;&gt;&quot;/v1&quot;&lt;/span&gt;)&lt;br /&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-class&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;ProfileControllerV1&lt;/span&gt; &lt;/span&gt;{&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-keyword&quot;&gt;private&lt;/span&gt; ProfileServiceV1 profileService;&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-annotation&quot;&gt;@Autowired&lt;/span&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;ProfileControllerV1&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(ProfileServiceV1 profileService)&lt;/span&gt; &lt;/span&gt;{&lt;br /&gt;        &lt;span class=&quot;hljs-keyword&quot;&gt;this&lt;/span&gt;.profileService = profileService;&lt;br /&gt;    }&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-annotation&quot;&gt;@RequestMapping&lt;/span&gt;(path = &lt;span class=&quot;hljs-string&quot;&gt;&quot;/profiles/{username}&quot;&lt;/span&gt;, method = RequestMethod.GET)&lt;br /&gt;    &lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; ResponseEntity &lt;span class=&quot;hljs-title&quot;&gt;getProfile&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(@PathVariable String username)&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;throws&lt;/span&gt; Exception &lt;/span&gt;{&lt;br /&gt;        &lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; Optional.ofNullable(profileService.getProfile(username))&lt;br /&gt;                .map(a -&amp;gt; &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; ResponseEntity&amp;lt;&amp;gt;(a, HttpStatus.OK))&lt;br /&gt;                .orElseThrow(() -&amp;gt; &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; Exception(&lt;span class=&quot;hljs-string&quot;&gt;&quot;Profile for user does not exist&quot;&lt;/span&gt;));&lt;br /&gt;    }&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-annotation&quot;&gt;@RequestMapping&lt;/span&gt;(path = &lt;span class=&quot;hljs-string&quot;&gt;&quot;/profiles/{username}&quot;&lt;/span&gt;, method = RequestMethod.POST)&lt;br /&gt;    &lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; ResponseEntity &lt;span class=&quot;hljs-title&quot;&gt;updateProfile&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(@RequestBody Profile profile)&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;throws&lt;/span&gt; Exception &lt;/span&gt;{&lt;br /&gt;        &lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; Optional.ofNullable(profileService.updateProfile(profile))&lt;br /&gt;                .map(a -&amp;gt; &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; ResponseEntity&amp;lt;&amp;gt;(a, HttpStatus.OK))&lt;br /&gt;                .orElseThrow(() -&amp;gt; &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; Exception(&lt;span class=&quot;hljs-string&quot;&gt;&quot;Profile for user does not exist&quot;&lt;/span&gt;));&lt;br /&gt;    }&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;In the code snippet above we see the &lt;code&gt;ProfileControllerV1&lt;/code&gt; class, which is a REST controller that provides an endpoint for retrieving the &lt;code&gt;Profile&lt;/code&gt; of a user. The &lt;code&gt;Profile&lt;/code&gt; object we are retrieving here will extend fields from the &lt;code&gt;Customer&lt;/code&gt; object, after retrieving domain data from the legacy &lt;em&gt;Customer Service&lt;/em&gt;. To do this, we will call directly to the &lt;em&gt;Customer Service&lt;/em&gt; in the legacy application zone using a SOAP client.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-java hljs&quot; data-lang=&quot;java&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-class&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;CustomerClient&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;WebServiceGatewaySupport&lt;/span&gt; &lt;/span&gt;{&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;final&lt;/span&gt; Logger log = LoggerFactory.getLogger(CustomerClient.class);&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;final&lt;/span&gt; String ROOT_NAMESPACE = &lt;span class=&quot;hljs-string&quot;&gt;&quot;http://kennybastani.com/guides/customer-service/&quot;&lt;/span&gt;;&lt;br /&gt;    &lt;span class=&quot;hljs-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;final&lt;/span&gt; String GET_CUSTOMER_NAMESPACE = &lt;span class=&quot;hljs-string&quot;&gt;&quot;getCustomerRequest&quot;&lt;/span&gt;;&lt;br /&gt;    &lt;span class=&quot;hljs-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;final&lt;/span&gt; String UPDATE_CUSTOMER_NAMESPACE = &lt;span class=&quot;hljs-string&quot;&gt;&quot;updateCustomerRequest&quot;&lt;/span&gt;;&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; GetCustomerResponse &lt;span class=&quot;hljs-title&quot;&gt;getCustomerResponse&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(String username)&lt;/span&gt; &lt;/span&gt;{&lt;br /&gt;      ...&lt;br /&gt;    }&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; UpdateCustomerResponse &lt;span class=&quot;hljs-title&quot;&gt;updateCustomerResponse&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(Profile profile)&lt;/span&gt; &lt;/span&gt;{&lt;br /&gt;      ...&lt;br /&gt;    }&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;In the snippet above we find the definition of the &lt;code&gt;CustomerClient&lt;/code&gt;. This class will provide the &lt;em&gt;Profile Service&lt;/em&gt; with a capable SOAP client that can retrieve a &lt;code&gt;Customer&lt;/code&gt; record from the legacy &lt;code&gt;Customer Service&lt;/code&gt;. We’ll use this client from the &lt;code&gt;ProfileServiceV1&lt;/code&gt; class below to retrieve the &lt;code&gt;Customer&lt;/code&gt; domain data that we will be extending in the &lt;code&gt;Profile&lt;/code&gt; object.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-java hljs&quot; data-lang=&quot;java&quot;&gt;&lt;span class=&quot;hljs-annotation&quot;&gt;@Service&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-class&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;ProfileServiceV1&lt;/span&gt; &lt;/span&gt;{&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-keyword&quot;&gt;private&lt;/span&gt; ProfileRepository profileRepository;&lt;br /&gt;    &lt;span class=&quot;hljs-keyword&quot;&gt;private&lt;/span&gt; CustomerClient customerClient;&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-annotation&quot;&gt;@Autowired&lt;/span&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;ProfileServiceV1&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(ProfileRepository profileRepository, CustomerClient customerClient)&lt;/span&gt; &lt;/span&gt;{&lt;br /&gt;        &lt;span class=&quot;hljs-keyword&quot;&gt;this&lt;/span&gt;.profileRepository = profileRepository;&lt;br /&gt;        &lt;span class=&quot;hljs-keyword&quot;&gt;this&lt;/span&gt;.customerClient = customerClient;&lt;br /&gt;    }&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; Profile &lt;span class=&quot;hljs-title&quot;&gt;getProfile&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(String username)&lt;/span&gt; &lt;/span&gt;{&lt;br /&gt;        ...&lt;br /&gt;    }&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; Profile &lt;span class=&quot;hljs-title&quot;&gt;updateProfile&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(Profile profile)&lt;/span&gt; &lt;/span&gt;{&lt;br /&gt;        ...&lt;br /&gt;    }&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The code snippet above contains the definition of the &lt;code&gt;ProfileServiceV1&lt;/code&gt; class. This bean will conditionally call the legacy &lt;em&gt;Customer Service&lt;/em&gt; by making a SOAP request from the &lt;code&gt;CustomerClient&lt;/code&gt;. The &lt;code&gt;getProfile&lt;/code&gt; method is called by the &lt;code&gt;ProfileControllerV1&lt;/code&gt; class, returning a &lt;code&gt;Profile&lt;/code&gt; object that extends domain data from the legacy &lt;code&gt;Customer&lt;/code&gt; object.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-java hljs&quot; data-lang=&quot;java&quot;&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; Profile &lt;span class=&quot;hljs-title&quot;&gt;getProfile&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(String username)&lt;/span&gt; &lt;/span&gt;{&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-comment&quot;&gt;// Check for the profile record&lt;/span&gt;&lt;br /&gt;    Profile profile = profileRepository.getProfileByUsername(username);&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-comment&quot;&gt;// If the profile does not exist in the repository, import it from the SOAP service&lt;/span&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (profile == &lt;span class=&quot;hljs-keyword&quot;&gt;null&lt;/span&gt;) {&lt;br /&gt;        &lt;span class=&quot;hljs-comment&quot;&gt;// Request the customer record from the legacy customer SOAP service&lt;/span&gt;&lt;br /&gt;        profile = Optional.ofNullable(customerClient.getCustomerResponse(username)&lt;br /&gt;                .getCustomer())&lt;br /&gt;                .map(p -&amp;gt; &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; Profile(p.getFirstName(), p.getLastName(),&lt;br /&gt;                        p.getEmail(), p.getUsername()))&lt;br /&gt;                .orElseGet(&lt;span class=&quot;hljs-keyword&quot;&gt;null&lt;/span&gt;);&lt;br /&gt;&lt;br /&gt;        &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (profile != &lt;span class=&quot;hljs-keyword&quot;&gt;null&lt;/span&gt;) {&lt;br /&gt;            &lt;span class=&quot;hljs-comment&quot;&gt;// Migrate the system of record for the profile to this microservice&lt;/span&gt;&lt;br /&gt;            profile = profileRepository.save(profile);&lt;br /&gt;        }&lt;br /&gt;    }&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; profile;&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;As a part of this workflow, the &lt;em&gt;Profile Service&lt;/em&gt; looks to its attached MySQL database using the &lt;code&gt;ProfileRepository&lt;/code&gt; to find a &lt;code&gt;Profile&lt;/code&gt; record with &lt;code&gt;username&lt;/code&gt; as the lookup key. If the &lt;code&gt;Profile&lt;/code&gt; for the requested user does not exist in the database, a request to retrieve the &lt;code&gt;Customer&lt;/code&gt; object is made to the &lt;em&gt;Customer Service&lt;/em&gt;. If the &lt;em&gt;Customer Service&lt;/em&gt; returns a &lt;code&gt;Customer&lt;/code&gt; record in the response, the base domain data returned from the legacy &lt;em&gt;Customer Service&lt;/em&gt; will be used to construct a new &lt;code&gt;Profile&lt;/code&gt; record, which is consequently saved by the &lt;em&gt;Profile Service&lt;/em&gt; to the attached MySQL database.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Using this workflow, the &lt;em&gt;Profile Service&lt;/em&gt; only needs to call the legacy system &lt;em&gt;once&lt;/em&gt; for each &lt;code&gt;Profile&lt;/code&gt; that is requested. Since we’ve re-routed all requests from other legacy applications to use the &lt;em&gt;Legacy Edge Service&lt;/em&gt;, we can safely transition the system of record for domain data away from the legacy &lt;em&gt;Customer Service&lt;/em&gt; without performing any risky database migrations. Further, to support backward compatibility in the &quot;large shared database&quot;, we can replicate any updates to the base &lt;code&gt;Customer&lt;/code&gt; domain data by scheduling tasks asynchronously to call the &lt;em&gt;Customer Service&lt;/em&gt; when a change is made to a &lt;code&gt;Profile&lt;/code&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-java hljs&quot; data-lang=&quot;java&quot;&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; Profile &lt;span class=&quot;hljs-title&quot;&gt;updateProfile&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(Profile profile)&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;throws&lt;/span&gt; IOException &lt;/span&gt;{&lt;br /&gt;&lt;br /&gt;    Assert.notNull(profile);&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-comment&quot;&gt;// Get current authenticated user&lt;/span&gt;&lt;br /&gt;    User user = oAuth2RestTemplate.getForObject(&lt;span class=&quot;hljs-string&quot;&gt;&quot;http://user-service/uaa/v1/me&quot;&lt;/span&gt;, User.class);&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-comment&quot;&gt;// Get current profile&lt;/span&gt;&lt;br /&gt;    Profile currentProfile = getProfile(user.getUsername());&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (currentProfile != &lt;span class=&quot;hljs-keyword&quot;&gt;null&lt;/span&gt;) {&lt;br /&gt;        &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (currentProfile.getUsername().equals(profile.getUsername())) {&lt;br /&gt;            &lt;span class=&quot;hljs-comment&quot;&gt;// Save the profile&lt;/span&gt;&lt;br /&gt;            profile.setId(currentProfile.getId());&lt;br /&gt;            profile.setCreatedAt(currentProfile.getCreatedAt());&lt;br /&gt;            profile = profileRepository.save(profile);&lt;br /&gt;&lt;br /&gt;            &lt;span class=&quot;hljs-comment&quot;&gt;// Replicate the write to the legacy customer service&lt;/span&gt;&lt;br /&gt;            amqpTemplate.convertAndSend(&lt;span class=&quot;hljs-string&quot;&gt;&quot;customer.update&quot;&lt;/span&gt;,&lt;br /&gt;                    &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; ObjectMapper().writeValueAsString(profile));&lt;br /&gt;        }&lt;br /&gt;    }&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; profile;&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The snippet above is the implementation of &lt;code&gt;updateProfile&lt;/code&gt;. In this method we are receiving a request to update the profile of a user. The first step is to ensure that the profile being modified is the user who is currently authenticated. To make sure that only a user that owns the profile can update the domain resource, we check to see if the requested change is different from the profile of the authenticated user.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;admonitionblock warning&quot;&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;icon&quot;&gt;&lt;i class=&quot;fa icon-warning&quot; title=&quot;Warning&quot;&gt;&lt;/i&gt;&lt;/td&gt;&lt;td class=&quot;content&quot;&gt;To support backward compatibility with the legacy system, we’ll need to support a different workflow for validating the authenticated user, since the Legacy Edge Service uses &lt;code&gt;client_credentials&lt;/code&gt; for authorization. &lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;After updating the profile, we need to replicate the write back to the customer service. To make sure that the cloud-native application is able to scale writes without dependency on the legacy system, we want to be able to durably replicate the write in an async workflow. By sending a durable message to a RabbitMQ queue, we can use the Profile Service to send back updates to the Customer Service asynchronously without tying up thread and memory resources of the web server.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-java hljs&quot; data-lang=&quot;java&quot;&gt;&lt;span class=&quot;hljs-annotation&quot;&gt;@RabbitListener&lt;/span&gt;(queues = {&lt;span class=&quot;hljs-string&quot;&gt;&quot;customer.update&quot;&lt;/span&gt;})&lt;br /&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;updateCustomer&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(String message)&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;throws&lt;/span&gt; InterruptedException, IOException &lt;/span&gt;{&lt;br /&gt;    Profile profile = objectMapper.readValue(message, Profile.class);&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-keyword&quot;&gt;try&lt;/span&gt; {&lt;br /&gt;        &lt;span class=&quot;hljs-comment&quot;&gt;// Update the customer service for the profile&lt;/span&gt;&lt;br /&gt;        UpdateCustomerResponse response =&lt;br /&gt;                customerClient.updateCustomerResponse(profile);&lt;br /&gt;&lt;br /&gt;        &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (!response.isSuccess()) {&lt;br /&gt;            String errorMsg =&lt;br /&gt;                    String.format(&lt;span class=&quot;hljs-string&quot;&gt;&quot;Could not update customer from profile for %s&quot;&lt;/span&gt;,&lt;br /&gt;                            profile.getUsername());&lt;br /&gt;            log.error(errorMsg);&lt;br /&gt;            &lt;span class=&quot;hljs-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; UnexpectedException(errorMsg);&lt;br /&gt;        }&lt;br /&gt;    } &lt;span class=&quot;hljs-keyword&quot;&gt;catch&lt;/span&gt; (Exception ex) {&lt;br /&gt;        &lt;span class=&quot;hljs-comment&quot;&gt;// Throw AMQP exception and redeliver the message&lt;/span&gt;&lt;br /&gt;        &lt;span class=&quot;hljs-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; AmqpIllegalStateException(&lt;span class=&quot;hljs-string&quot;&gt;&quot;Customer service update failed&quot;&lt;/span&gt;, ex);&lt;br /&gt;    }&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The snippet above is our message listener on the Profile Service that will asynchronously issue writes back to the Customer Service in the legacy system. Since the network is prone to failure, this workflow ensures that there will be no loss of data since the RabbitMQ message can only be acknowledged after an attempt to update the Customer Service was a success.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_profile_web&quot;&gt;Profile Web&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The &lt;em&gt;Profile Web&lt;/em&gt; microservice is a front-end Spring Boot application that houses the static content of an AngularJS website. The &lt;em&gt;Profile Web&lt;/em&gt; application will bind to the &lt;em&gt;Edge Service&lt;/em&gt; and embed its API gateway using Spring Cloud Netflix’s Zuul as a reverse proxy. By embedding the &lt;em&gt;Edge Service&lt;/em&gt; into the &lt;em&gt;Profile Application&lt;/em&gt;, the client-side JavaScript of the AngularJS website will not need to request resources from a separate domain. The &lt;em&gt;Edge Service&lt;/em&gt; will be made available as an endpoint at &lt;code&gt;/api/**&lt;/code&gt;.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_running_the_example&quot;&gt;Running the Example&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;There are two ways to run the reference application, with either Docker Compose or Cloud Foundry, the latter of which can be installed on a development machine using &lt;a href=&quot;https://docs.pivotal.io/pcf-dev/&quot; target=&quot;_blank&quot;&gt;PCF Dev&lt;/a&gt;. Since the distributed application is designed to be cloud-native, there is a lot to be gained from understanding how to deploy the example using Cloud Foundry.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The source code for the reference application is available on GitHub at &lt;a href=&quot;https://github.com/kbastani/cloud-native-microservice-strangler-example&quot; target=&quot;_blank&quot;&gt;https://github.com/kbastani/cloud-native-microservice-strangler-example&lt;/a&gt;. Clone the repository and run the example using the directions below.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_docker_compose&quot;&gt;Docker Compose&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;To run the example using Docker Compose, a &lt;code&gt;run.sh&lt;/code&gt; script is provided which will orchestrate the startup of each application. Since the example will run 8 applications and multiple backing services, it’s necessary to have at least 9GB of memory allocated to Docker.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;admonitionblock warning&quot;&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;icon&quot;&gt;&lt;i class=&quot;fa icon-warning&quot; title=&quot;Warning&quot;&gt;&lt;/i&gt;&lt;/td&gt;&lt;td class=&quot;content&quot;&gt;The &lt;code&gt;run.sh&lt;/code&gt; script is designed to use Docker Machine, so if you’re using Docker for Mac, you’ll need to modify the &lt;code&gt;run.sh&lt;/code&gt; script by setting &lt;code&gt;DOCKER_IP&lt;/code&gt; to &lt;code&gt;localhost&lt;/code&gt;. &lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_cloud_foundry&quot;&gt;Cloud Foundry&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;To run the example using Cloud Foundry, a &lt;code&gt;deploy.sh&lt;/code&gt; script is provided which will orchestrate the deployment of each application to a simulated cloud-native environment. If you have enough resources available, you can deploy the example on &lt;a href=&quot;http://run.pivotal.io&quot; target=&quot;_blank&quot;&gt;Pivotal Web Services&lt;/a&gt;. If you’re new to Cloud Foundry, it’s highly recommended that you go with the PCF Dev approach, which you can install by following the directions at &lt;a href=&quot;https://docs.pivotal.io/pcf-dev/&quot; target=&quot;_blank&quot;&gt;https://docs.pivotal.io/pcf-dev/&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;When you have a CF environment to deploy the example, go ahead and run the &lt;code&gt;deploy.sh&lt;/code&gt; script in the parent directory of the project. The bash script is commented enough for most to understand the steps of the deployment. Each Cloud Foundry deployment manifest is located in the directory of the application and is named &lt;code&gt;manifest.yml&lt;/code&gt;. The script will deploy the Spring Cloud backing services first, and afterward, each microservice will be deployed one by one until each application is running.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_managing_profiles&quot;&gt;Managing Profiles&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;While the example project contains 8 separate applications, the only front-end application is the &lt;em&gt;Profile Web&lt;/em&gt; microservice. If you’re running the example on PCF Dev, you can access the Eureka dashboard at &lt;a href=&quot;http://discovery-service.local.pcfdev.io/&quot; target=&quot;_blank&quot;&gt;http://discovery-service.local.pcfdev.io/&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div style=&quot;display: block; padding: inherit; max-width:45em;&quot; class=&quot;imageblock&quot;&gt;&lt;div style=&quot;text-align: left; margin: auto;&quot; class=&quot;content&quot;&gt;&lt;img style=&quot;margin: auto !important;&quot; src=&quot;http://i.imgur.com/qAaPHGt.png&quot; alt=&quot;Eureka Dashboard&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;If the applications listed in the Eureka dashboard looks like the example above, then the deployment was successful. To access the &lt;em&gt;Profile Web&lt;/em&gt; application, go to &lt;a href=&quot;http://profile-web.local.pcfdev.io/&quot; target=&quot;_blank&quot;&gt;http://profile-web.local.pcfdev.io/&lt;/a&gt;. You’ll be immediately redirected to the OAuth2 gateway’s login form on the &lt;em&gt;User Service&lt;/em&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div style=&quot;display: block; padding: inherit; max-width:45em;&quot; class=&quot;imageblock&quot;&gt;&lt;div style=&quot;text-align: left; margin: auto;&quot; class=&quot;content&quot;&gt;&lt;img style=&quot;margin: auto !important;&quot; src=&quot;http://i.imgur.com/Lj4J8Me.png&quot; alt=&quot;OAuth2 user login&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The &lt;em&gt;User Service&lt;/em&gt; is only configured to allow one user to sign-in. To login, use the very secure credentials of &lt;strong&gt;user&lt;/strong&gt; and &lt;strong&gt;password&lt;/strong&gt;, and you’ll be redirected back to the &lt;em&gt;Profile Web&lt;/em&gt; application.&lt;/p&gt;&lt;/div&gt;&lt;div style=&quot;display: block; padding: inherit; max-width:45em;&quot; class=&quot;imageblock&quot;&gt;&lt;div style=&quot;text-align: left; margin: auto;&quot; class=&quot;content&quot;&gt;&lt;img style=&quot;margin: auto !important;&quot; src=&quot;http://i.imgur.com/EMFqm0e.png&quot; alt=&quot;Manage profile&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The &lt;em&gt;Profile Web&lt;/em&gt; application will then allow you to update the current user’s profile information. Going back to earlier when we talked about the workflow for getting the profile information from the &lt;em&gt;Customer Service&lt;/em&gt;, by the time the data is loaded, the workflow is complete. The &lt;em&gt;Profile Web&lt;/em&gt; application will call the &lt;em&gt;Profile Service&lt;/em&gt; through the embedded &lt;em&gt;Edge Service&lt;/em&gt; application’s API gateway. The &lt;em&gt;Profile Service&lt;/em&gt; will then check to see if the user’s profile information is stored in its database. If the data is unavailable, it will call the &lt;em&gt;Customer Service&lt;/em&gt; using the SOAP client and then import the profile information by saving it to its database.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Now that the domain data has been migrated from the &lt;em&gt;Customer Service&lt;/em&gt;, we need to verify that any updates from the &lt;em&gt;Profile Web&lt;/em&gt; application find their way back into the legacy application’s shared database. To verify this, go ahead and update the fields on the &lt;em&gt;Profile Web&lt;/em&gt; application’s UI.&lt;/p&gt;&lt;/div&gt;&lt;div style=&quot;display: block; padding: inherit; max-width:45em;&quot; class=&quot;imageblock&quot;&gt;&lt;div style=&quot;text-align: left; margin: auto;&quot; class=&quot;content&quot;&gt;&lt;img style=&quot;margin: auto !important;&quot; src=&quot;http://i.imgur.com/S31zA7g.png&quot; alt=&quot;Update profile&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Here I’ve updated the default user to my own profile information, and the result was successful. To verify that the legacy system is in sync with the microservices, we can send an HTTP SOAP request to the &lt;em&gt;Customer Service&lt;/em&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-xml hljs&quot; data-lang=&quot;xml&quot;&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-title&quot;&gt;soapenv:Envelope&lt;/span&gt; &lt;span class=&quot;hljs-attribute&quot;&gt;xmlns:soapenv&lt;/span&gt;=&lt;span class=&quot;hljs-value&quot;&gt;&quot;http://schemas.xmlsoap.org/soap/envelope/&quot;&lt;/span&gt;&lt;br /&gt;      &lt;span class=&quot;hljs-attribute&quot;&gt;xmlns:gs&lt;/span&gt;=&lt;span class=&quot;hljs-value&quot;&gt;&quot;http://kennybastani.com/guides/customer-service&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br /&gt;   &lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-title&quot;&gt;soapenv:Header&lt;/span&gt;/&amp;gt;&lt;/span&gt;&lt;br /&gt;   &lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-title&quot;&gt;soapenv:Body&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br /&gt;      &lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-title&quot;&gt;gs:getCustomerRequest&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br /&gt;         &lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-title&quot;&gt;gs:username&lt;/span&gt;&amp;gt;&lt;/span&gt;user&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-title&quot;&gt;gs:username&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br /&gt;      &lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-title&quot;&gt;gs:getCustomerRequest&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br /&gt;   &lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-title&quot;&gt;soapenv:Body&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-title&quot;&gt;soapenv:Envelope&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Using a REST client, send a POST request with the XML snippet above to the Customer Service at &lt;a href=&quot;http://customer-service.local.pcfdev.io/v1/customers/user&quot;&gt;http://customer-service.local.pcfdev.io/v1/customers/user&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;admonitionblock tip&quot;&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;icon&quot;&gt;&lt;i class=&quot;fa icon-tip&quot; title=&quot;Tip&quot;&gt;&lt;/i&gt;&lt;/td&gt;&lt;td class=&quot;content&quot;&gt;The REST client that you will use needs to send the POST request with a content type of &lt;code&gt;xml/text&lt;/code&gt;, since the legacy service uses SOAP as the messaging protocol. &lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-xml hljs&quot; data-lang=&quot;xml&quot;&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-title&quot;&gt;SOAP-ENV:Envelope&lt;/span&gt; &lt;span class=&quot;hljs-attribute&quot;&gt;xmlns:SOAP-ENV&lt;/span&gt;=&lt;span class=&quot;hljs-value&quot;&gt;&quot;http://schemas.xmlsoap.org/soap/envelope/&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-title&quot;&gt;SOAP-ENV:Header&lt;/span&gt;/&amp;gt;&lt;/span&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-title&quot;&gt;SOAP-ENV:Body&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br /&gt;        &lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-title&quot;&gt;ns2:getCustomerResponse&lt;/span&gt; &lt;span class=&quot;hljs-attribute&quot;&gt;xmlns:ns2&lt;/span&gt;=&lt;span class=&quot;hljs-value&quot;&gt;&quot;http://kennybastani.com/guides/customer-service&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br /&gt;            &lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-title&quot;&gt;ns2:customer&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br /&gt;                &lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-title&quot;&gt;ns2:username&lt;/span&gt;&amp;gt;&lt;/span&gt;user&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-title&quot;&gt;ns2:username&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br /&gt;                &lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-title&quot;&gt;ns2:firstName&lt;/span&gt;&amp;gt;&lt;/span&gt;Kenny&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-title&quot;&gt;ns2:firstName&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br /&gt;                &lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-title&quot;&gt;ns2:lastName&lt;/span&gt;&amp;gt;&lt;/span&gt;Bastani&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-title&quot;&gt;ns2:lastName&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br /&gt;                &lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-title&quot;&gt;ns2:email&lt;/span&gt;&amp;gt;&lt;/span&gt;kenny.bastani@example.com&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-title&quot;&gt;ns2:email&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br /&gt;            &lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-title&quot;&gt;ns2:customer&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br /&gt;        &lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-title&quot;&gt;ns2:getCustomerResponse&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-title&quot;&gt;SOAP-ENV:Body&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-title&quot;&gt;SOAP-ENV:Envelope&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;You should see something similar to the response above. The &lt;em&gt;Customer Service&lt;/em&gt; has no awareness of the new &lt;em&gt;Profile Service&lt;/em&gt; and will only return back a response from the large database that it shares with other legacy applications.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_conclusion&quot;&gt;Conclusion&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Now that we’ve explored the reference application, there are a few extra things to be mindful of as you tackle the challenges that come with implementing this hybrid microservice approach. One concern is that the legacy system will still need to be able to mirror any updates to domain data from new microservices. To do this, we used a RabbitMQ message broker that can durably store ordered messages and asynchronously apply updates back to the legacy system. This method will be eventually consistent, which requires additional scrutiny when it comes to handling state.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;sect3&quot;&gt;&lt;h4 id=&quot;_be_mindful_of_state&quot;&gt;Be mindful of state&lt;/h4&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Some domain objects will come from the legacy system that will contain stateful properties. It’s much safer to migrate domain data that is stateless—but in reality, that’s an uncommon occurrence. Any field of an object that represents state will have a dependency on business logic. That’s an important consideration with this approach, so be mindful of the following.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;ulist&quot;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Never deploy a new feature without ensuring backward compatibility with the legacy system&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Identify fields sourced from the legacy system that represents state&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Never store state as fields in microservices—store state as events&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect3&quot;&gt;&lt;h4 id=&quot;_be_mindful_of_consistency&quot;&gt;Be mindful of consistency&lt;/h4&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;To be successful with this method and make the minimum amount of changes to the legacy system, you’ll need to replicate updates to domain data durably back to the legacy system. With microservices we need to embrace eventual consistency, so be mindful of the following.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;ulist&quot;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Respect foreign key relationships in a monolith’s database&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Work to decouple table constraints that block updates through a legacy web service&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Move all legacy field validators (including database constraints) into your microservices&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Make sure updates sent to a legacy service from a microservice are always able to succeed eventually&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect3&quot;&gt;&lt;h4 id=&quot;_be_mindful_of_observability&quot;&gt;Be mindful of observability&lt;/h4&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;You can’t fix what you can’t measure. From the first day you’re in production, you should have maximal visibility into how your microservices are handling data capture from the legacy system. To increase observability, keep the following considerations in mind.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;ulist&quot;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Monitor for failures during an attempt to update the legacy system from a microservice&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Be quick to analyze and remediate failures that are blocking a microservice from replicating updates to the legacy system&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect3&quot;&gt;&lt;h4 id=&quot;_be_mindful_of_resiliency&quot;&gt;Be mindful of resiliency&lt;/h4&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Always account for the inevitable failures that will come with the first few iterations of integrating your new microservice with the legacy system. Use circuit breakers in &lt;a href=&quot;https://cloud.spring.io/spring-cloud-netflix/&quot; target=&quot;_blank&quot;&gt;Spring Cloud Netflix&lt;/a&gt; to create fallback plans that temporarily escalate the privilege of your microservice to be able to interact safely with a legacy data source in the event of repeated failure.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;ulist&quot;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Make sure to provide mechanisms to override unknown constraints that block updates to the legacy system&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Build in escalated fallback measures in the case that a microservice repeatedly fails to update a legacy data source&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Make sure to performance test connecting to a shared database from your microservice in any fallback scenario&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Spare no effort to prevent data loss by persisting any changes scheduled for the legacy system into durable storage&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;   &lt;/div&gt;</description><link>https://www.kennybastani.com/2016/08/strangling-legacy-microservices-spring-cloud.html</link><author>noreply@blogger.com (Kenny Bastani)</author><thr:total>0</thr:total></item><item><guid isPermaLink="false">tag:blogger.com,1999:blog-6300367579216018061.post-2426424856649856926</guid><pubDate>Tue, 19 Apr 2016 13:57:00 +0000</pubDate><atom:updated>2016-08-30T18:18:41.945-07:00</atom:updated><category domain="http://www.blogger.com/atom/ns#">cloud native java</category><category domain="http://www.blogger.com/atom/ns#">data</category><category domain="http://www.blogger.com/atom/ns#">docker</category><category domain="http://www.blogger.com/atom/ns#">event sourcing</category><category domain="http://www.blogger.com/atom/ns#">eventual consistency</category><category domain="http://www.blogger.com/atom/ns#">microservices</category><category domain="http://www.blogger.com/atom/ns#">reactive streaming</category><category domain="http://www.blogger.com/atom/ns#">reactor</category><category domain="http://www.blogger.com/atom/ns#">spring boot</category><category domain="http://www.blogger.com/atom/ns#">spring cloud</category><title> Event Sourcing in Microservices Using Spring Cloud and Reactor</title><description>&lt;link rel=&quot;stylesheet&quot; href=&quot;https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans:400,700&quot;&gt;&lt;style&gt;.hljs-title, .hljs-id, .scss .hljs-preprocessor {    font-weight: 400 !important; } .hljs-class .hljs-title, .hljs-type, .vhdl .hljs-literal, .tex .hljs-command {    font-weight: 400 !important; } .hljs-keyword, .css .rule .hljs-keyword, .hljs-winutils, .nginx .hljs-title, .hljs-subst, .hljs-request, .hljs-status {    font-weight: 400 !important; } .sect1{padding-bottom:0!important} .sect1+.sect1{border:0!important} .conum[data-value]{display:inline-block;color:#fff!important;background-color:rgba(0,0,0,.8);-webkit-border-radius:100px;border-radius:100px;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:&quot;Open Sans&quot;,&quot;DejaVu Sans&quot;,sans-serif;font-style:normal;font-weight:bold} .conum[data-value] *{color:#fff!important} .conum[data-value]+b{display:none} .conum[data-value]:after{content:attr(data-value)} .fa-caret-up {     color: green;     text-shadow: 1px 1px 1px #ccc;     font-size: 1.75em !important; }  .fa-caret-down {     color: red;     text-shadow: 1px 1px 1px #ccc;     font-size: 1.75em !important; }  .fa-minus {     color: #999;     text-shadow: 1px 1px 1px #ccc;     font-size: 1em !important; }  .fa-plus {     font-size: 1em !important;     color: green;     text-shadow: 1px 1px 1px #ccc; }   @media screen and (min-width: 768px) { .table-responsive { font-size: 0.8em; max-width: 50em; } }  @media screen and (max-width: 768px) {     .table-responsive {     font-size: 0.65em; } }  .table-responsive th, .table-responsive tr, .table-responsive td { padding: 4px 4px 4px 4px !important; } p {     margin-bottom: 1.25em !important; line-height: 1.4; } li p { line-height: 1.4 !important; margin: 0 !important; } .blog-post-asciidoc .content img {  max-height: none; } .admonitionblock &gt; table {     background: rgba(0, 0, 0, 0) none repeat scroll 0 0;     border: 0 none;     border-collapse: separate;     width: 100%; } table {     background: #fff none repeat scroll 0 0;     border: 1px solid #dedede;     margin-bottom: 1.25em; } pre .conum[data-value]{position:relative;top:-.125em} b.conum *{color:inherit!important} .conum:not([data-value]):empty{display:none} .hdlist&gt;table,.colist&gt;table{border:0;background:none} .hdlist&gt;table&gt;tbody&gt;tr,.colist&gt;table&gt;tbody&gt;tr{background:none} td.hdlist1{padding-right:.75em;font-weight:bold} td.hdlist1,td.hdlist2{vertical-align:top} .literalblock+.colist,.listingblock+.colist{margin-top:-.5em} .colist&gt;table tr&gt;td:first-of-type{padding:0 .75em;line-height:1} .colist&gt;table tr&gt;td:last-of-type{padding:.25em 0} h1,h2,h3,#toctitle,.sidebarblock&gt;.content&gt;.title,h3,h4,h6{font-family:&quot;Open Sans&quot;,sans-serif;font-style:normal;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;} .blog-post-asciidoc p{margin-bottom:1.25rem} @media only screen and (min-width:768px){.sect1{padding-bottom:1.25em}}.sect1+.sect1{border-top:1px solid #efefed} pre, pre &gt; code {     -moz-osx-font-smoothing: auto;     color: rgba(0, 0, 0, 0.9);     font-family: monospace,monospace;     font-weight: 400;     line-height: 1.45;     text-rendering: optimizelegibility; } .blog-post-asciidoc code,kbd,pre,samp{font-size:.9em;font-weight:400;} .blog-post-asciidoc .admonitionblock&gt;table{border-collapse:separate;border:0;background:none;width:100%} .blog-post-asciidoc .admonitionblock&gt;table td.icon{text-align:center;width:80px} .blog-post-asciidoc .admonitionblock&gt;table td.icon img{max-width:none} .blog-post-asciidoc .admonitionblock&gt;table td.icon .title{font-weight:bold;font-family:&quot;Open Sans&quot;,&quot;DejaVu Sans&quot;,sans-serif;text-transform:uppercase} .blog-post-asciidoc .admonitionblock&gt;table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #ddddd8;color:rgba(0,0,0,.6)} .blog-post-asciidoc .admonitionblock&gt;table td.content&gt;:last-child&gt;:last-child{margin-bottom:0} .blog-post-asciidoc .admonitionblock td.icon [class^=&quot;fa icon-&quot;]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default} .blog-post-asciidoc .admonitionblock td.icon .icon-note:before{content:&quot;\f05a&quot;;color:#19407c} .blog-post-asciidoc .admonitionblock td.icon .icon-tip:before{content:&quot;\f0eb&quot;;text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111} .blog-post-asciidoc .admonitionblock td.icon .icon-warning:before{content:&quot;\f071&quot;;color:#bf6900} .blog-post-asciidoc .admonitionblock td.icon .icon-caution:before{content:&quot;\f06d&quot;;color:#bf3400} .blog-post-asciidoc .admonitionblock td.icon .icon-important:before{content:&quot;\f06a&quot;;color:#bf0000} #personDataTable td {     vertical-align: middle; } .rank-col {     text-align: center; } #personDataTable img {     max-width: 35px;     padding: 0; } .table-responsive {     font-weight: 400; } .table &gt; thead &gt; tr &gt; th {     border-bottom: 2px solid #ddd;     font-weight: 400;     padding: 8px !important;     vertical-align: bottom; } .table-responsive {     font-family: Helvetica,sans-serif; } .exampleblock pre {     margin-top: auto; } .exampleblock .content {     margin-top: auto; } blockquote {     border-left: 5px solid #eee;     color: #666;     font-size: 16px;     margin: 0;     padding: 10px 20px; } .attribution {     font-size: small;     text-align: right; } .table-responsive p { margin: 0 !important; } p.tableblock {   font-size: 14px;   margin: 0 !important; } table.tableblock { max-width: 100%; border-collapse: separate; } table.tableblock td &gt; .paragraph:last-child p &gt; p:last-child, table.tableblock th &gt; p:last-child, table.tableblock td &gt; p:last-child { margin-bottom: 0; }  table.tableblock, th.tableblock, td.tableblock { border: 0 solid #dddddd; }  table.grid-all th.tableblock, table.grid-all td.tableblock { border-width: 0 1px 1px 0; }  table.grid-all tfoot &gt; tr &gt; th.tableblock, table.grid-all tfoot &gt; tr &gt; td.tableblock { border-width: 1px 1px 0 0; }  table.grid-cols th.tableblock, table.grid-cols td.tableblock { border-width: 0 1px 0 0; }  table.grid-all * &gt; tr &gt; .tableblock:last-child, table.grid-cols * &gt; tr &gt; .tableblock:last-child { border-right-width: 0; }  table.grid-rows th.tableblock, table.grid-rows td.tableblock { border-width: 0 0 1px 0; }  table.grid-all tbody &gt; tr:last-child &gt; th.tableblock, table.grid-all tbody &gt; tr:last-child &gt; td.tableblock, table.grid-all thead:last-child &gt; tr &gt; th.tableblock, table.grid-rows tbody &gt; tr:last-child &gt; th.tableblock, table.grid-rows tbody &gt; tr:last-child &gt; td.tableblock, table.grid-rows thead:last-child &gt; tr &gt; th.tableblock { border-bottom-width: 0; }  table.grid-rows tfoot &gt; tr &gt; th.tableblock, table.grid-rows tfoot &gt; tr &gt; td.tableblock { border-width: 1px 0 0 0; }  table.frame-all { border-width: 1px; }  table.frame-sides { border-width: 0 1px; }  table.frame-topbot { border-width: 1px 0; }  th.halign-left, td.halign-left { text-align: left; }  th.halign-right, td.halign-right { text-align: right; }  th.halign-center, td.halign-center { text-align: center; }  th.valign-top, td.valign-top { vertical-align: top; }  th.valign-bottom, td.valign-bottom { vertical-align: bottom; }  th.valign-middle, td.valign-middle { vertical-align: middle; }  table thead th, table tfoot th { font-weight: bold; }  tbody tr th { display: table-cell; line-height: 1.4; background: whitesmoke; }  tbody tr th, tbody tr th p, tfoot tr th, tfoot tr th p { color: #222222; font-weight: bold; }  p.tableblock &gt; code:only-child { background: none; padding: 0; }  table tr.even, table tr.alt, table tr:nth-of-type(2n) {     background: #f9f9f9 none repeat scroll 0 0; } div.table-responsive {  border: 0; }  .sql p {  font-family: courier; } &lt;/style&gt;&lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.2.0/css/font-awesome.min.css&quot;&gt;&lt;div id=&quot;content&quot; class=&quot;blog-post-asciidoc&quot;&gt; &lt;div id=&quot;preamble&quot;&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;When building applications in a microservice architecture, managing state becomes a distributed systems problem. Instead of being able to manage state as transactions inside the boundaries of a single monolithic application, a microservice must be able to manage consistency using transactions that are distributed across a network of many different applications and databases.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;In this article we will explore the problems of data consistency and high availability in microservices. We will start by taking a look at some of the important concepts and themes behind handling data consistency in distributed systems.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Throughout this article we will use a &lt;a href=&quot;https://github.com/kbastani/spring-cloud-event-sourcing-example&quot; target=&quot;_blank&quot;&gt;reference application of an online store&lt;/a&gt; that is built with microservices using &lt;a href=&quot;http://projects.spring.io/spring-boot/&quot; target=&quot;_blank&quot;&gt;Spring Boot&lt;/a&gt; and &lt;a href=&quot;http://projects.spring.io/spring-cloud/&quot; target=&quot;_blank&quot;&gt;Spring Cloud&lt;/a&gt;. We’ll then look at how to use &lt;a href=&quot;http://www.reactive-streams.org/&quot; target=&quot;_blank&quot;&gt;reactive streams&lt;/a&gt; with &lt;a href=&quot;https://projectreactor.io/&quot; target=&quot;_blank&quot;&gt;Project Reactor&lt;/a&gt; to implement event sourcing in a microservice architecture. Finally, we’ll use &lt;a href=&quot;https://www.docker.com/&quot; target=&quot;_blank&quot;&gt;Docker&lt;/a&gt; and Maven to build, run, and orchestrate the multi-container reference application.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_eventual_consistency&quot;&gt;Eventual Consistency&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;When building microservices, we are forced to start reasoning about state in an architecture where data is eventually consistent. This is because each microservice exclusively exposes resources from a database that it owns. Further, each of these databases would be configured for high availability, with different consistency guarantees for each type of database.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Eventual_consistency&quot; target=&quot;_blank&quot;&gt;Eventual consistency&lt;/a&gt; is a model that is used to describe some operations on data in a distributed system—where state is replicated and stored across multiple nodes of a network. Typically, eventual consistency is talked about when running a database in &lt;a href=&quot;https://en.wikipedia.org/wiki/High_availability&quot; target=&quot;_blank&quot;&gt;high availability mode&lt;/a&gt;, where replicas are maintained by coordinating writes between multiple nodes of a database cluster. The challenge of the database cluster is that writes must be coordinated to all replicas in the exact order that they were received. When this happens, each replica is considered to be eventually consistent—that the state of all replicas are guaranteed to converge towards a consistent state at some point in the future.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;When first building microservices, eventual consistency is a frequent point of contention between developers, DBAs, and architects. The head scratching starts to occur more frequently when the architecture design discussions begin to turn to the topic of data and handling state in a distributed system. The head scratching usually boils down to one question.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;quoteblock&quot;&gt;&lt;blockquote&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;How can we guarantee high availability while also guaranteeing data consistency?&lt;/p&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;To answer this question we need to understand how to best handle transactions in a distributed system. It just so happens that most distributed databases have this problem nailed down with a healthy helping of science.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_transaction_logs&quot;&gt;Transaction Logs&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Mostly all databases today support some form of high availability clustering. Most database products will provide a list of easy to understand guarantees about a system’s consistency model. A first step to achieving safety guarantees for stronger consistency models is to maintain an ordered log of database transactions. This approach is pretty simple in theory. A transaction log is an ordered record of all updates that were transacted by the database. When transactions are replayed in the exact order they were recorded, an exact replica of a database can be generated.&lt;/p&gt;&lt;/div&gt;&lt;div style=&quot;display: block;&quot; class=&quot;imageblock&quot;&gt;&lt;div style=&quot;text-align: center; margin: auto;&quot; class=&quot;content&quot;&gt;&lt;img style=&quot;margin: auto !important;&quot; src=&quot;http://imgur.com/1KWW64x.png&quot; alt=&quot;Eventual consistency diagram&quot; width=&quot;100%&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The diagram above represents three databases in a cluster that are replicating data using a shared transaction log. The zipper labeled &lt;em&gt;Primary&lt;/em&gt; is the authority in this case and has the most current view of the database. The difference between the zippers represent the consistency of each replica, and as the transactions are replayed, each replica converges to a consistent state with the &lt;em&gt;Primary&lt;/em&gt;. The basic idea here is that with eventual consistency, all zippers will eventually be zipped all the way up.&lt;/p&gt;&lt;/div&gt;&lt;a name=&#39;more&#39;&gt;&lt;/a&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The transaction logs that databases use actually have deep roots in history that pre-dates computing. The fundamental approach for managing an ordered log of transactions was first used by Venetian merchants as far back as the &lt;em&gt;15th century&lt;/em&gt;. The method that these Venetian merchants started using was called the &lt;a href=&quot;https://en.wikipedia.org/wiki/Double-entry_bookkeeping_system&quot; target=&quot;_blank&quot;&gt;double-entry bookkeeping system&lt;/a&gt;—which is a system of bookkeeping that requires two side-by-side entries for each transaction. For each of these transactions, both a credit and a debit are specified from an origin account to a destination account. To calculate the balance of an account, any merchant could simply replicate the current state of all accounts by replaying the events recorded in the ledger. This same fundamental practice of bookkeeping is still used today, and to some extent its a basic concept for transaction management in modern database systems.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;For databases that claim to have eventual consistency, it’s guaranteed that each node in the database cluster will converge towards a globally consistent state by simply replaying the transaction log that resulted from a merge of write transactions across replicas. This claim, however, is only a guarantee of a database’s &lt;em&gt;liveness&lt;/em&gt; properties, ignoring any guarantees about its &lt;em&gt;safety&lt;/em&gt; properties. The difference between &lt;em&gt;safety&lt;/em&gt; and &lt;em&gt;liveness&lt;/em&gt; here is that with eventual consistency we can only be guaranteed that all updates will be observed eventually, with no guarantee about correctness.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Most content available today that attempts to educate us on the benefits of microservices will contain a very sparse explanation behind the saying that &quot;&lt;em&gt;microservices use eventual consistency&lt;/em&gt;&quot;—sometimes referencing &lt;a href=&quot;https://en.wikipedia.org/wiki/CAP_theorem&quot; target=&quot;_blank&quot;&gt;CAP theorem&lt;/a&gt; to bolster any sense of existing confusion. This tends to be a shallow explanation that leads to more questions than answers. A more appropriate explanation of eventual consistency in microservices would be the following statement.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;quoteblock&quot;&gt;&lt;blockquote&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Microservice architectures provide no guarantees about the correctness of your data.&lt;/p&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The only consistency guarantee you’ll get with microservices is that all microservices will eventually agree on something—&lt;em&gt;correct or not&lt;/em&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Cutting through the vast hype that exists on the road to building microservices is not only important, it is an assured eventuality that all developers must face. This is because when it comes to building software, a distributed system is a &lt;em&gt;distributed system&lt;/em&gt;. A collection of communicating microservices are no exception. The good news is, there are tried and true patterns for how to successfully build and maintain complex distributed systems, and that’s the main theme of the rest of this article.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_event_sourcing&quot;&gt;Event Sourcing&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;a href=&quot;http://martinfowler.com/eaaDev/EventSourcing.html&quot; target=&quot;_blank&quot;&gt;Event sourcing&lt;/a&gt; is a method of data persistence that borrows similar ideas behind a database’s transaction log. For event sourcing, the unit of a transaction becomes much more granular, using a sequence of ordered events to represent the state of a domain object stored in a database. Once an event has been added to to the event log, it cannot be removed or re-ordered. Events are considered to be &lt;em&gt;immutable&lt;/em&gt; and the sequence of events that are stored are append-only.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;There are multiple benefits for handling state in a microservice architecture using event sourcing.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;ulist&quot;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;em&gt;Aggregates&lt;/em&gt; can be used to generate the consistent state of any object&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;It provides an &lt;em&gt;audit trail&lt;/em&gt; that can be replayed to generate the state of an object from any point in time&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;It provides the many inputs necessary for analyzing data using &lt;a href=&quot;https://en.wikipedia.org/wiki/Event_stream_processing&quot; target=&quot;_blank&quot;&gt;&lt;em&gt;event stream processing&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;It enables the use of &lt;a href=&quot;https://en.wikipedia.org/wiki/Compensating_transaction&quot; target=&quot;_blank&quot;&gt;&lt;em&gt;compensating transactions&lt;/em&gt;&lt;/a&gt; to rollback events leading to an inconsistent application state&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;It also avoids complex synchronization between microservices, paving the way for asynchronous &lt;em&gt;non-blocking operations&lt;/em&gt; between microservices&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;In this article we’re going to look at a JVM-based implementation of event sourcing that uses Spring Cloud and Spring Boot. As with &lt;a href=&quot;http://www.kennybastani.com/search/label/spring%20cloud&quot; target=&quot;_blank&quot;&gt;most of the articles you’ll find on this blog&lt;/a&gt;, we’re going to take a tour of a realistic sample application that you can run and deploy. This time I’ve put together an example of an end-to-end cloud native application using microservices. I’ve even included an &lt;a href=&quot;https://angularjs.org/&quot; target=&quot;_blank&quot;&gt;AngularJS&lt;/a&gt; frontend, &lt;a href=&quot;https://spring.io/guides/tutorials/spring-security-and-angular-js/&quot; target=&quot;_blank&quot;&gt;thanks to some very clever ground work&lt;/a&gt; by &lt;a href=&quot;https://spring.io/team/dsyer/&quot; target=&quot;_blank&quot;&gt;Dr. Dave Syer&lt;/a&gt; on the Spring Engineering team. &lt;em&gt;(Thanks Dr. Syer!)&lt;/em&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_reference_application&quot;&gt;Reference Application&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;As I mentioned earlier, this reference application was designed as a cloud native application. Cloud native applications and architectures are designed and built using a set of standard methodologies that maximize the utility of a cloud platform. Cloud native applications use something called &lt;a href=&quot;http://12factor.net/&quot; target=&quot;_blank&quot;&gt;&lt;em&gt;twelve-factor application methodology&lt;/em&gt;&lt;/a&gt;. The twelve-factor methodology is a set of practices and useful guidelines that were compiled by the engineers behind Heroku, which have become a standard reference for creating applications suitable to be deployed to a cloud platform.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Cloud native application architectures will typically embrace scale-out infrastructure principles, such as horizontal scaling of applications and databases. Applications also focus on building in resiliency and auto-healing to prevent downtime. Through the use of a platform, availability can be automatically adjusted as necessary using a set of policies. Also, load balancing for services are shifted to the client-side, and handled between applications, preventing the need to configure load balancers for new application instances.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_online_store_web&quot;&gt;Online Store Web&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;I’ve taken big leaps from the other microservice reference applications you’ll find here on this blog. This application was created to demonstrate a fully formed microservice architecture that implements the core functionality of an online store.&lt;/p&gt;&lt;/div&gt;&lt;div style=&quot;display: block;&quot; class=&quot;imageblock&quot;&gt;&lt;div style=&quot;text-align: center; margin: auto;&quot; class=&quot;content&quot;&gt;&lt;img style=&quot;margin: auto !important;&quot; src=&quot;http://imgur.com/zqzmAzi.png&quot; alt=&quot;Online store microservice architecture&quot; width=&quot;100%&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Users of this online store application will be interacting with a front-end website that is hosted on &lt;a href=&quot;https://github.com/kbastani/spring-cloud-event-sourcing-example/tree/master/online-store-web&quot; target=&quot;_blank&quot;&gt;Online Store Web&lt;/a&gt;, which is a Spring Boot application, and is the service colored purple in the diagram above. This application houses the static content of an AngularJS site.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The main challenge with writing a front-end application on a back-end of microservices, when using a client-side JavaScript framework like AngularJS, is how to safely expose REST APIs on the same host that houses the static JS content. We need to solve this challenge in order to prevent security vulnerabilities that could result from making our back-end REST APIs publicly accessible from multiple domains. If we were to host these microservices on separate domains, we would be required to enable &lt;a href=&quot;https://en.wikipedia.org/wiki/Cross-origin_resource_sharing&quot; target=&quot;_blank&quot;&gt;&lt;em&gt;Cross-origin resource sharing&lt;/em&gt;&lt;/a&gt; (CORS), which would make our application’s backend vulnerable to various forms of attack.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;In order to solve the problem of CORS, we have a suite of excellent tools at our disposal, all of which are a part of the &lt;em&gt;Spring Cloud&lt;/em&gt; project ecosystem.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_spring_cloud_backing_services&quot;&gt;Spring Cloud Backing Services&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Looking back at the reference architecture’s diagram, we see that &lt;code&gt;Online Store Web&lt;/code&gt; has direct HTTP connections to 4 other applications in the middle layer. These services are:&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;ulist&quot;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/kbastani/spring-cloud-event-sourcing-example/tree/master/user-service&quot; target=&quot;_blank&quot;&gt;User Service&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/kbastani/spring-cloud-event-sourcing-example/tree/master/edge-service&quot; target=&quot;_blank&quot;&gt;Edge Service&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/kbastani/spring-cloud-event-sourcing-example/tree/master/discovery-service&quot; target=&quot;_blank&quot;&gt;Discovery Service&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/kbastani/spring-cloud-event-sourcing-example/tree/master/config-service&quot; target=&quot;_blank&quot;&gt;Configuration Server&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div style=&quot;display: block;&quot; class=&quot;imageblock&quot;&gt;&lt;div style=&quot;text-align: center; margin: auto;&quot; class=&quot;content&quot;&gt;&lt;img style=&quot;margin: auto !important;&quot; src=&quot;http://imgur.com/yFKE0re.png&quot; alt=&quot;Spring Cloud services&quot; width=&quot;100%&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Each of these Spring Boot applications are considered to be &lt;em&gt;backing services&lt;/em&gt; to the &lt;code&gt;Online Store Web&lt;/code&gt; application. The &lt;a href=&quot;http://12factor.net/backing-services&quot; target=&quot;_blank&quot;&gt;&lt;em&gt;Backing service&lt;/em&gt;&lt;/a&gt; is a term that was popularized in the twelve-factor methodology. The premise is that there are third-party service dependencies that should be treated as attached resources to your cloud native applications. The key trait of backing services are that they are provided as bindings to an application in its deployment environment by a cloud platform.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The 4 backing services in the diagram will be bound to the &lt;code&gt;Online Store Web&lt;/code&gt; when it is run in the deployment’s target environment. A cloud platform, such as the popular open source &lt;a href=&quot;https://www.cloudfoundry.org/&quot; target=&quot;_blank&quot;&gt;PaaS Cloud Foundry&lt;/a&gt;, will &lt;a href=&quot;http://docs.cloudfoundry.org/services/binding-credentials.html&quot; target=&quot;_blank&quot;&gt;provide the application with secure credentials&lt;/a&gt; and URIs as externalized configuration properties that take the form of injected &lt;em&gt;environment variables&lt;/em&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The reason these backing services differ from the bottom layer in the diagram is that each of the backing services must be located using a statically defined route that can be injected as an environment variable to the &lt;code&gt;Online Store Web&lt;/code&gt; application’s container. Backing services always have this defining trait. This approach is considered a standard practice for providing a production application with secure credentials to connect to a database or service. The rule here is: if it cannot be discovered using a discovery service and has a statically defined route that one of your application deployments will depend on, then it’s considered to be a backing service for that environment.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Going back to the diagram, the services in the bottom layer do not need to have any statically defined route to be located. As long as the four backing services are locatable with an address, the bottom layer services can all be discovered through the backing services using the &lt;code&gt;Discovery Service&lt;/code&gt; and the &lt;code&gt;Edge Service&lt;/code&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;sect3&quot;&gt;&lt;h4 id=&quot;_user_service&quot;&gt;User Service&lt;/h4&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The &lt;code&gt;User Service&lt;/code&gt; is the authentication gateway that protects back-end resources in the application’s microservice architecture. There are two methods in which resources are exposed to a front-end application: protected and unprotected. A protected resource is one that requires user-level authentication. An unprotected resource is usually a read-only set of resources that can be viewed by users who are not authenticated, such as a product catalog.&lt;/p&gt;&lt;/div&gt;&lt;div style=&quot;display: block;&quot; class=&quot;imageblock&quot;&gt;&lt;div style=&quot;text-align: center; margin: auto;&quot; class=&quot;content&quot;&gt;&lt;img style=&quot;margin: auto !important;&quot; src=&quot;http://i.imgur.com/7ha54Ka.png&quot; alt=&quot;User service&quot; width=&quot;100%&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The &lt;code&gt;User Service&lt;/code&gt; also houses a &lt;a href=&quot;http://cloud.spring.io/spring-cloud-security/&quot; target=&quot;_blank&quot;&gt;&lt;em&gt;Spring Cloud OAuth2&lt;/em&gt;&lt;/a&gt; authorization server as well as a resource server. It is this service that all other applications in the target environment will be able to use to retrieve and validate token information. The token information that is validated will automatically be provided in the headers of requests to protected resources and used to authenticate a user’s session.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;If the user does not provide authentication details in the header of a request to protected resources, they will be redirected to the &lt;code&gt;User Service&lt;/code&gt; login page where they will be able to sign in securely and authorize a grant to obtain an access token.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect3&quot;&gt;&lt;h4 id=&quot;_edge_service&quot;&gt;Edge Service&lt;/h4&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The &lt;code&gt;Edge Service&lt;/code&gt; is a Spring Cloud application that is responsible for securely exposing HTTP routes from backend microservices. The &lt;code&gt;Edge Service&lt;/code&gt; is a very important component in a Spring Cloud microservices architecture, as it provides frontend applications a way to expose every API from the backend services as a single unified REST API.&lt;/p&gt;&lt;/div&gt;&lt;div style=&quot;display: block;&quot; class=&quot;imageblock&quot;&gt;&lt;div style=&quot;text-align: center; margin: auto;&quot; class=&quot;content&quot;&gt;&lt;img style=&quot;margin: auto !important;&quot; src=&quot;http://i.imgur.com/n443oQx.png&quot; alt=&quot;Edge service&quot; width=&quot;100%&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;To take advantage of the &lt;code&gt;Edge Service&lt;/code&gt;, a Spring Boot application would simply attach it as a backing service in the target environment. In doing this, the &lt;code&gt;Edge Service&lt;/code&gt; will provide secure authenticated access to all REST APIs that are exposed by the backend services. To be able to do this, the &lt;code&gt;Edge Service&lt;/code&gt; matches a request route’s URL fragment from a front-end application to a back-end microservice through a reverse proxy to retrieve the remote REST API response.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The end result is that the &lt;code&gt;Edge Service&lt;/code&gt; provides a seamless REST API that will become embedded in any Spring Boot application that attaches it as a backing service using &lt;a href=&quot;http://cloud.spring.io/spring-cloud-netflix/spring-cloud-netflix.html#_router_and_filter_zuul&quot; target=&quot;_blank&quot;&gt;Spring Cloud Netflix’s Zuul&lt;/a&gt; starter project.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect3&quot;&gt;&lt;h4 id=&quot;_discovery_service&quot;&gt;Discovery Service&lt;/h4&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The &lt;code&gt;Discovery Service&lt;/code&gt; is a Spring Cloud application that is responsible for maintaining a registry of service information in a target environment. Each service application will subscribe to a &lt;code&gt;Discovery Service&lt;/code&gt; application in the target environment at start-up. The subscribing application will then provide its local networking information, which includes its network address. By doing this, all other applications in the environment will be able to locate other subscribers by downloading a service registry and caching it locally. The local service registry will be used on an as-needed basis to retrieve the network address of other services that an application depends on in the target environment.&lt;/p&gt;&lt;/div&gt;&lt;div style=&quot;display: block;&quot; class=&quot;imageblock&quot;&gt;&lt;div style=&quot;text-align: center; margin: auto;&quot; class=&quot;content&quot;&gt;&lt;img style=&quot;margin: auto !important;&quot; src=&quot;http://i.imgur.com/VM3Bduc.png&quot; alt=&quot;Discovery and config services&quot; width=&quot;100%&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect3&quot;&gt;&lt;h4 id=&quot;_configuration_server&quot;&gt;Configuration Server&lt;/h4&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The &lt;code&gt;Configuration Server&lt;/code&gt; is a Spring Cloud application that centralizes external configurations using various methodologies of building twelve-factor applications. The &lt;a href=&quot;http://12factor.net/config&quot; target=&quot;_blank&quot;&gt;twelve-factor app stores configurations&lt;/a&gt; in the environment and not in the project’s source code. This service will allow other applications to retrieve their tailored configurations for the target environment.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_backend_microservices&quot;&gt;Backend Microservices&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;While the backing services in the middle layer are still considered to be microservices, they solve a set of concerns that are purely operational and security-related. The business logic of this application sits almost entirely in our bottom layer. These applications are designed around business capabilities of the fictitious online store, which I’ve gone ahead and branded as &lt;em&gt;Cloud Native Outfitters&lt;/em&gt;–a hypothetical Silicon Valley startup that sells 4 really clever t-shirts and hoodies.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;As a part of the business capabilities of the online store, we have the following 5 microservices that will serve as our backend REST API. The main consumer of these APIs is the &lt;code&gt;Online Store Web&lt;/code&gt;, as well as other planned customer facing applications that may never see the light of day in the case that &lt;em&gt;Cloud Native Outfitters&lt;/em&gt; is unable to secure a seed round of investment from one of the top-tier venture capital firms on Sand Hill Road.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Each of these microservices will be exposed as a seamless REST API via the &lt;code&gt;Edge Service&lt;/code&gt; application in the middle layer. The &lt;code&gt;Edge Service&lt;/code&gt; uses Spring Cloud Netflix’s Zuul proxy to map request routes from the &lt;code&gt;Online Store Web&lt;/code&gt; application to the appropriate backend microservice’s REST API.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;These applications can be found at:&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;ulist&quot;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/kbastani/spring-cloud-event-sourcing-example/tree/master/catalog-service&quot; target=&quot;_blank&quot;&gt;Catalog Service&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/kbastani/spring-cloud-event-sourcing-example/tree/master/account-service&quot; target=&quot;_blank&quot;&gt;Account Service&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/kbastani/spring-cloud-event-sourcing-example/tree/master/inventory-service&quot; target=&quot;_blank&quot;&gt;Inventory Service&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/kbastani/spring-cloud-event-sourcing-example/tree/master/shopping-cart-service&quot; target=&quot;_blank&quot;&gt;Cart Service&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/kbastani/spring-cloud-event-sourcing-example/tree/master/order-service&quot; target=&quot;_blank&quot;&gt;Order Service&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div style=&quot;display: block;&quot; class=&quot;imageblock&quot;&gt;&lt;div style=&quot;text-align: center; margin: auto;&quot; class=&quot;content&quot;&gt;&lt;img style=&quot;margin: auto !important;&quot; src=&quot;http://imgur.com/RRKoSI0.png&quot; alt=&quot;Online store microservice backend&quot; width=&quot;100%&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;A description of the role of each of these microservices is explained in the &lt;a href=&quot;https://github.com/kbastani/spring-cloud-event-sourcing-example&quot; target=&quot;_blank&quot;&gt;GitHub repository for this sample project&lt;/a&gt;. I’ll be regularly contributing to the applications in this project’s repository for future articles that will focus on more of the &lt;a href=&quot;http://microservices.io&quot; target=&quot;_blank&quot;&gt;patterns and best practices of microservice architectures&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The next part of this article is going to focus on the original topic of event sourcing in microservices using &lt;em&gt;Spring Boot&lt;/em&gt;, &lt;em&gt;Spring Cloud&lt;/em&gt;, and &lt;em&gt;Project Reactor&lt;/em&gt;.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_project_reactor&quot;&gt;Project Reactor&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;a href=&quot;http://projectreactor.io/&quot; target=&quot;_blank&quot;&gt;Project Reactor&lt;/a&gt; is an open source library for building JVM applications based on the &lt;a href=&quot;http://www.reactive-streams.org/&quot; target=&quot;_blank&quot;&gt;Reactive Streams Specification&lt;/a&gt; and is a member of the Spring ecosystem of maintained open source libraries. The purpose of Reactor is to provide developers that are building JVM-based applications with a &lt;em&gt;Reactive&lt;/em&gt; library that is dedicated to building non-blocking applications—and as a result help us tackle the problem of unnecessary latency.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;It is very common for applications interfacing with microservices to call multiple other microservices during the same execution context. As we talked about earlier, one of the key traits of a microservice architecture is eventual consistency. While eventual consistency does not provide any guarantees about the safety of our data, it does provide us with the option to use asynchronous non-blocking operations when communicating with other microservices in the same execution context. This is where the Reactor libraries become very useful.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;There are some rare situations, &lt;em&gt;if any&lt;/em&gt;, where the state of a domain object must be shared across microservices. When using &lt;em&gt;Event Sourcing&lt;/em&gt; in microservices we will only store a log of strictly ordered events. By taking this approach there should be very limited situations where there is a requirement to store the state of a domain object in a database. Instead, we are resolved to only store a stream of ordered events representing the aggregate state of an object. By doing this, it means we will have eliminated a majority of scenarios where we need to synchronize state with other microservices using RESTful APIs that use HTTP. These types of blocking operations are at the root of a variety of latency issues when communicating between microservices.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_event_sourcing_with_reactor_core&quot;&gt;Event Sourcing with Reactor Core&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;One of the microservices in the online store is the &lt;code&gt;Shopping Cart Service&lt;/code&gt;. Authenticated users browse the product catalog from the user interface of the &lt;code&gt;Online Store Web&lt;/code&gt; application. The users are able to add and remove product line items from their shopping cart as well as clear their cart or checkout.&lt;/p&gt;&lt;/div&gt;&lt;div style=&quot;display: block;&quot; class=&quot;imageblock&quot;&gt;&lt;div style=&quot;text-align: center; margin: auto;&quot; class=&quot;content&quot;&gt;&lt;img style=&quot;margin: auto !important;&quot; src=&quot;http://i.imgur.com/GNwbQzZ.png.png&quot; alt=&quot;Online store microservice backend&quot; width=&quot;100%&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;A user’s shopping cart paints a simple picture of how event sourcing works. The &lt;code&gt;Shopping Cart Service&lt;/code&gt; is the owner of a MySQL database that has a table called &lt;code&gt;cart_event&lt;/code&gt;. This table contains an ordered log of events that a user has generated in the response to an action, with the purpose of managing the items in their shopping cart.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 1. &lt;a href=&quot;https://github.com/kbastani/spring-cloud-event-sourcing-example/blob/master/shopping-cart-service/src/main/java/demo/cart/CartEventType.java&quot; target=&quot;_blank&quot;&gt;CartEventType.java&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-java hljs&quot; data-lang=&quot;java&quot;&gt;&lt;span class=&quot;hljs-comment&quot;&gt;// These will be the events that are stored in the event log for a cart&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;enum&lt;/span&gt; CartEventType {&lt;br /&gt;    ADD_ITEM,&lt;br /&gt;    REMOVE_ITEM,&lt;br /&gt;    CLEAR_CART,&lt;br /&gt;    CHECKOUT&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Let’s consider that the &lt;code&gt;CartEventType&lt;/code&gt; is an enum that has a list of 4 different event types. Each of these event types represent an action performed by a user on their shopping cart. With event sourcing, these cart events can each impact the outcome of the final state of a user’s shopping cart. When a user adds or removes an item to their cart, the action produces an event that increments or decrements the aggregate quantity of a line item. When these events are replayed in the same order as they were received, a list of product line items are created, each with a corresponding quantity value.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The following table is an export of an event log that represents a user’s actions on their shopping cart.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;table-responsive&quot;&gt;  &lt;table class=&quot;table table-striped&quot;&gt;  &lt;tbody&gt;&lt;tr&gt;&lt;th&gt;id&lt;/th&gt;&lt;th&gt;created_at&lt;/th&gt;&lt;th&gt;last_modified&lt;/th&gt;&lt;th&gt;cart_event_type&lt;/th&gt;&lt;th&gt;product_id&lt;/th&gt;&lt;th&gt;quantity&lt;/th&gt;&lt;th&gt;user_id&lt;/th&gt;&lt;/tr&gt;  &lt;tr&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;1460990971645&lt;/td&gt;&lt;td&gt;1460990971645&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;SKU-12464&lt;/td&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;  &lt;tr&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;1460992816398&lt;/td&gt;&lt;td&gt;1460992816398&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;SKU-12464&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;  &lt;tr&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;1460992826474&lt;/td&gt;&lt;td&gt;1460992826474&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;SKU-12464&lt;/td&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;  &lt;tr&gt;&lt;td&gt;4&lt;/td&gt;&lt;td&gt;1460992832872&lt;/td&gt;&lt;td&gt;1460992832872&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;SKU-12464&lt;/td&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;  &lt;tr&gt;&lt;td&gt;5&lt;/td&gt;&lt;td&gt;1460992836027&lt;/td&gt;&lt;td&gt;1460992836027&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;SKU-12464&lt;/td&gt;&lt;td&gt;5&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;  &lt;/tbody&gt;&lt;/table&gt;  &lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;We see from this table that each row has a unique timestamp to ensure strict ordering. We also see an integer representing the 4 &lt;code&gt;CartEventType&lt;/code&gt; enum types. There is also some meta-data that is stored in this table. The columns &lt;code&gt;product_id&lt;/code&gt; and &lt;code&gt;quantity&lt;/code&gt; are both used to generate the aggregate shopping cart and product line items.&lt;/p&gt;&lt;/div&gt;&lt;div style=&quot;display: block;&quot; class=&quot;imageblock&quot;&gt;&lt;div style=&quot;text-align: center; margin: auto;&quot; class=&quot;content&quot;&gt;&lt;img style=&quot;margin: auto !important;&quot; src=&quot;http://i.imgur.com/QmAehTS.png.png&quot; alt=&quot;Online store microservice backend&quot; width=&quot;100%&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The result of this is shown in the above screenshot. Here we see a user’s shopping cart that was generated as an aggregate object.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;sect3&quot;&gt;&lt;h4 id=&quot;_choosing_an_event_store&quot;&gt;Choosing an Event Store&lt;/h4&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;There are many options available when choosing an appropriate storage option for event sourcing. Mostly all databases today that provide streaming query capabilities will work. There are however some popular open source projects that stand out for this use case. One example of a project that is increasingly becoming the standard for event sourcing architectures is &lt;a href=&quot;http://kafka.apache.org/&quot; target=&quot;_blank&quot;&gt;Apache Kafka&lt;/a&gt;, which is a subject of a future blog post. For this example we’re going to use MySQL, which is a fine choice for implementing event sourcing for an online shopping cart.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;admonitionblock tip&quot;&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;icon&quot;&gt;&lt;i class=&quot;fa icon-tip&quot; title=&quot;Tip&quot;&gt;&lt;/i&gt;&lt;/td&gt;&lt;td class=&quot;content&quot;&gt;The choice of technology for your event store will always depend on the volume of writes and the throughput of your database. A project like Apache Kafka was designed for this exact use case but it requires us to take on some additional operational responsibility to scale it in production, including running an &lt;a href=&quot;https://zookeeper.apache.org/&quot; target=&quot;_blank&quot;&gt;Apache ZooKeeper&lt;/a&gt; cluster. &lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect3&quot;&gt;&lt;h4 id=&quot;_generating_aggregates&quot;&gt;Generating Aggregates&lt;/h4&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;In the &lt;code&gt;Shopping Cart Service&lt;/code&gt; we will provide a versioned REST API that implements a method for accepting new events from the &lt;code&gt;Online Store Web&lt;/code&gt; application.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 2. &lt;a href=&quot;https://github.com/kbastani/spring-cloud-event-sourcing-example/blob/master/shopping-cart-service/src/main/java/demo/api/v1/ShoppingCartControllerV1.java#L25&quot; target=&quot;_blank&quot;&gt;ShoppingCartControllerV1.java&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-java hljs&quot; data-lang=&quot;java&quot;&gt;&lt;span class=&quot;hljs-annotation&quot;&gt;@RequestMapping&lt;/span&gt;(path = &lt;span class=&quot;hljs-string&quot;&gt;&quot;/events&quot;&lt;/span&gt;, method = RequestMethod.POST)&lt;br /&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; ResponseEntity &lt;span class=&quot;hljs-title&quot;&gt;addCartEvent&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(@RequestBody CartEvent cartEvent)&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;throws&lt;/span&gt; Exception &lt;/span&gt;{&lt;br /&gt;    &lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; Optional.ofNullable(shoppingCartService.addCartEvent(cartEvent))&lt;br /&gt;            .map(event -&amp;gt; &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; ResponseEntity(HttpStatus.NO_CONTENT))&lt;br /&gt;            .orElseThrow(() -&amp;gt; &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; Exception(&lt;span class=&quot;hljs-string&quot;&gt;&quot;Could not find shopping cart&quot;&lt;/span&gt;));&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;In the code example above we define a controller method for collecting new &lt;code&gt;CartEvent&lt;/code&gt; objects from clients. The purpose of this method will be to append additional cart events to the event log in our &lt;code&gt;cart_event&lt;/code&gt; table. The result is that when clients then call the REST API method for retrieving a user’s shopping cart, it will be generated as an aggregate that incorporates all cart events using reactive streaming.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The next step is generating the aggregate of cart events using Reactor.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 3. &lt;a href=&quot;https://github.com/kbastani/spring-cloud-event-sourcing-example/blob/master/shopping-cart-service/src/main/java/demo/api/v1/ShoppingCartServiceV1.java#L116&quot; target=&quot;_blank&quot;&gt;ShoppingCartServiceV1.java&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-java hljs&quot; data-lang=&quot;java&quot;&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; ShoppingCart &lt;span class=&quot;hljs-title&quot;&gt;aggregateCartEvents&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(User user, Catalog catalog)&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;throws&lt;/span&gt; Exception &lt;/span&gt;{&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-comment&quot;&gt;// Create a reactive streams publisher by streaming ordered events from the database&lt;/span&gt;&lt;br /&gt;    Flux&amp;lt;CartEvent&amp;gt; cartEvents =&lt;br /&gt;            Flux.fromStream(cartEventRepository.getCartEventStreamByUser(user.getId()));&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-comment&quot;&gt;// Aggregate the current state of the shopping cart until arriving at a terminal state in the stream&lt;/span&gt;&lt;br /&gt;    ShoppingCart shoppingCart = cartEvents&lt;br /&gt;            .takeWhile(cartEvent -&amp;gt; !ShoppingCart.isTerminal(cartEvent.getCartEventType()))&lt;br /&gt;            .reduceWith(() -&amp;gt; &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; ShoppingCart(catalog), ShoppingCart::incorporate)&lt;br /&gt;            .get();&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-comment&quot;&gt;// Generate the list of line items in the cart from the aggregate&lt;/span&gt;&lt;br /&gt;    shoppingCart.getLineItems();&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; shoppingCart;&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;In the code example above we see three steps to generate the shopping cart object and return it back to a client. The first step is to create a reactive stream from the data source of the event store for cart events. Once the stream has been established, we can begin to incorporate each event in the stream to generate our aggregate. The reactive stream that is created will take each event from the data store and mutate the state of the &lt;code&gt;ShoppingCart&lt;/code&gt; until it eventually arrives at the terminating state, which gives us our final aggregate view of the user’s shopping cart.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;In the reduce phase of the reactive stream’s aggregation we use a method called &lt;code&gt;incorporate&lt;/code&gt; that belongs to the &lt;code&gt;ShoppingCart&lt;/code&gt; class. This method accepts a &lt;code&gt;CartEvent&lt;/code&gt; object which is used to mutate the state of the &lt;code&gt;ShoppingCart&lt;/code&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 4. &lt;a href=&quot;https://github.com/kbastani/spring-cloud-event-sourcing-example/blob/master/shopping-cart-service/src/main/java/demo/cart/ShoppingCart.java#L77&quot; target=&quot;_blank&quot;&gt;ShoppingCart.java&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-java hljs&quot; data-lang=&quot;java&quot;&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; ShoppingCart &lt;span class=&quot;hljs-title&quot;&gt;incorporate&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(CartEvent cartEvent)&lt;/span&gt; &lt;/span&gt;{&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-comment&quot;&gt;// Remember that thing about safety properties in microservices?&lt;/span&gt;&lt;br /&gt;    Flux&amp;lt;CartEventType&amp;gt; validCartEventTypes =&lt;br /&gt;            Flux.fromStream(Stream.of(CartEventType.ADD_ITEM,&lt;br /&gt;                    CartEventType.REMOVE_ITEM));&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-comment&quot;&gt;// The CartEvent&#39;s type must be either ADD_ITEM or REMOVE_ITEM&lt;/span&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (validCartEventTypes.exists(cartEventType -&amp;gt;&lt;br /&gt;            cartEvent.getCartEventType().equals(cartEventType)).get()) {&lt;br /&gt;&lt;br /&gt;        &lt;span class=&quot;hljs-comment&quot;&gt;// Update the aggregate view of each line item&#39;s quantity from the event type&lt;/span&gt;&lt;br /&gt;        productMap.put(cartEvent.getProductId(),&lt;br /&gt;                productMap.getOrDefault(cartEvent.getProductId(), &lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;) +&lt;br /&gt;                        (cartEvent.getQuantity() * (cartEvent.getCartEventType()&lt;br /&gt;                                .equals(CartEventType.ADD_ITEM) ? &lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt; : -&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;)));&lt;br /&gt;    }&lt;br /&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-comment&quot;&gt;// Return the updated state of the aggregate to the reactive stream&#39;s reduce method&lt;/span&gt;&lt;br /&gt;    &lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;this&lt;/span&gt;;&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;In the code example above we see the implementation of the &lt;code&gt;incorporate&lt;/code&gt; method for a &lt;code&gt;ShoppingCart&lt;/code&gt;. Here we accept a &lt;code&gt;CartEvent&lt;/code&gt; object and then take a very important step to ensure data safety by validating that the event’s type. This is where microservices need to be liberal with their unit testing to ensure that state mutation will ensure data correctness in an eventually consistent architecture. In this case, we ensure that the event types are either &lt;code&gt;ADD_ITEM&lt;/code&gt; or &lt;code&gt;REMOVE_ITEM&lt;/code&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The next step is to update the aggregate view of each line item in the shopping cart by mapping the corresponding event types to an increment or decrement value that can be applied to the line item’s quantity. Finally, we return the current view back to the client with the mutated state that resulted in incorporating the new event.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_docker_compose_demo&quot;&gt;Docker Compose Demo&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The example project uses &lt;a href=&quot;https://docs.docker.com/compose/&quot; target=&quot;_blank&quot;&gt;Docker Compose&lt;/a&gt; to build and run a container image of each of our microservices as a part of the Maven build process.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_getting_started&quot;&gt;Getting Started&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;To get started, visit the &lt;a href=&quot;https://github.com/kbastani/spring-cloud-event-sourcing-example&quot; target=&quot;_blank&quot;&gt;GitHub repository&lt;/a&gt; for this example project.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/kbastani/spring-cloud-event-sourcing-example&quot; target=&quot;_blank&quot;&gt;https://github.com/kbastani/spring-cloud-event-sourcing-example&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Clone or fork the project and download the repository to your machine. After downloading, you will need to use both Maven and Docker to compile and build the images locally.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_download_docker&quot;&gt;Download Docker&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;First, download Docker if you haven’t already. Follow the &lt;a href=&quot;https://www.docker.com/docker-toolbox&quot; target=&quot;_blank&quot;&gt;instructions found here&lt;/a&gt;, to get Docker toolbox up and running on your development machine.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;After you’ve installed Docker toolbox, run the following command to initialize a new virtualbox VM for this sample application.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-bash hljs&quot; data-lang=&quot;bash&quot;&gt;$ docker-machine create event-source-demo --driver virtualbox --virtualbox-memory &lt;span class=&quot;hljs-string&quot;&gt;&quot;11000&quot;&lt;/span&gt; --virtualbox-disk-size &lt;span class=&quot;hljs-string&quot;&gt;&quot;100000&quot;&lt;/span&gt;&lt;br /&gt;$ &lt;span class=&quot;hljs-built_in&quot;&gt;eval&lt;/span&gt; &lt;span class=&quot;hljs-string&quot;&gt;&quot;&lt;span class=&quot;hljs-variable&quot;&gt;$(docker-machine env event-source-demo)&lt;/span&gt;&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_requirements&quot;&gt;Requirements&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The requirements for running this demo on your machine are found below.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;ulist&quot;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Maven 3&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Java 8&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Docker&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Docker Compose&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_building_the_project&quot;&gt;Building the project&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;To build the project, from the terminal, run the following command at the root of the project.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-bash hljs&quot; data-lang=&quot;bash&quot;&gt;$ sh run.sh&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The project will then download all of the needed dependencies and compile each of the project artifacts. Each service will be built, and then a Maven Docker plugin will automatically build each of the images into your local Docker registry. Docker must be running and available from the command line where you run the &lt;code&gt;sh run.sh&lt;/code&gt; command for the build to succeed.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_start_the_cluster_with_docker_compose&quot;&gt;Start the Cluster with Docker Compose&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Now that each of the images has been built successfully, we can using Docker Compose to spin up our cluster. The &lt;code&gt;run.sh&lt;/code&gt; script will build each of the projects and Docker containers which will be used by Docker Compose to start each of the services. The services that need to be started first are the &lt;code&gt;Configuration Service&lt;/code&gt; and the &lt;code&gt;Discovery Service&lt;/code&gt;. The rest of the services will then begin to start up and eventually begin to communicate with each other.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;admonitionblock caution&quot;&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;icon&quot;&gt;&lt;i class=&quot;fa icon-caution&quot; title=&quot;Caution&quot;&gt;&lt;/i&gt;&lt;/td&gt;&lt;td class=&quot;content&quot;&gt;I highly recommend that you run this sample on a machine with at least 16GB of system memory. &lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Once the startup sequence is completed, you can navigate to the Eureka host and see which services have registered with the discovery service.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Copy and paste the following command into the terminal where Docker can be accessed using the &lt;code&gt;$DOCKER_HOST&lt;/code&gt; environment variable.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-bash hljs&quot; data-lang=&quot;bash&quot;&gt;$ open $(&lt;span class=&quot;hljs-built_in&quot;&gt;echo&lt;/span&gt; \&lt;span class=&quot;hljs-string&quot;&gt;&quot;&lt;span class=&quot;hljs-variable&quot;&gt;$(echo $DOCKER_HOST)&lt;/span&gt;\&quot;|&lt;br /&gt;            \sed &#39;s/tcp:\/\//http:\/\//g&#39;|&lt;br /&gt;            \sed &#39;s/[0-9]\{4,\}/8761/g&#39;|&lt;br /&gt;            \sed &#39;s/\&quot;//g&#39;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;When the user interface successfully loads for Eureka, you’ll see the list of services that have registered as a Eureka discovery client.&lt;/p&gt;&lt;/div&gt;&lt;div style=&quot;display: block;&quot; class=&quot;imageblock&quot;&gt;&lt;div style=&quot;text-align: center; margin: auto;&quot; class=&quot;content&quot;&gt;&lt;img style=&quot;margin: auto !important;&quot; src=&quot;http://i.imgur.com/3OUOmK3.png&quot; alt=&quot;Eureka discovery service&quot; width=&quot;100%&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;When all applications have finished starting and are registered with Eureka, you can access the &lt;code&gt;Online Store Web&lt;/code&gt; application using the following command.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-bash hljs&quot; data-lang=&quot;bash&quot;&gt;$ open $(&lt;span class=&quot;hljs-built_in&quot;&gt;echo&lt;/span&gt; \&lt;span class=&quot;hljs-string&quot;&gt;&quot;&lt;span class=&quot;hljs-variable&quot;&gt;$(echo $DOCKER_HOST)&lt;/span&gt;\&quot;|&lt;br /&gt;            \sed &#39;s/tcp:\/\//http:\/\//g&#39;|&lt;br /&gt;            \sed &#39;s/[0-9]\{4,\}/8787/g&#39;|&lt;br /&gt;            \sed &#39;s/\&quot;//g&#39;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;admonitionblock tip&quot;&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;icon&quot;&gt;&lt;i class=&quot;fa icon-tip&quot; title=&quot;Tip&quot;&gt;&lt;/i&gt;&lt;/td&gt;&lt;td class=&quot;content&quot;&gt;It may take some time for the application to start up, so make sure you refresh the UI every few minutes until the product catalog becomes visible. &lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;&lt;div style=&quot;display: block;&quot; class=&quot;imageblock&quot;&gt;&lt;div style=&quot;text-align: center; margin: auto;&quot; class=&quot;content&quot;&gt;&lt;img style=&quot;margin: auto !important;&quot; src=&quot;http://i.imgur.com/lyDmoZ7.png&quot; alt=&quot;Load the home page&quot; width=&quot;100%&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;To start adding products to the shopping cart, you’ll need to login with the default user. Click &lt;code&gt;Login&lt;/code&gt; and you’ll be redirected to the authentication gateway. Use the default credentials of &lt;code&gt;user&lt;/code&gt; and &lt;code&gt;password&lt;/code&gt; to login.&lt;/p&gt;&lt;/div&gt;&lt;div style=&quot;display: block;&quot; class=&quot;imageblock&quot;&gt;&lt;div style=&quot;text-align: center; margin: auto;&quot; class=&quot;content&quot;&gt;&lt;img style=&quot;margin: auto !important;&quot; src=&quot;http://imgur.com/sbZBaE1.png&quot; alt=&quot;Login to the application&quot; width=&quot;100%&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;You’ll be redirected to the home page where you will now be authenticated and can begin to manage items in your shopping cart.&lt;/p&gt;&lt;/div&gt;&lt;div style=&quot;display: block;&quot; class=&quot;imageblock&quot;&gt;&lt;div style=&quot;text-align: center; margin: auto;&quot; class=&quot;content&quot;&gt;&lt;img style=&quot;margin: auto !important;&quot; src=&quot;http://i.imgur.com/e4VBBkN.png&quot; alt=&quot;Now you&#39;re authenticated&quot; width=&quot;100%&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_conclusion&quot;&gt;Conclusion&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;In this article we took a hard look at the challenges of high availability and data consistency in microservice architectures. We looked at a full cloud native application of an online store as a collection of microservices that use event sourcing to maintain a consistent view of the world while still guaranteeing high availability.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;In upcoming blog posts I will be exploring how to use &lt;a href=&quot;http://cloud.spring.io/spring-cloud-stream/&quot; target=&quot;_blank&quot;&gt;Spring Cloud Stream&lt;/a&gt; for both event sourcing and event stream processing using Apache Kafka.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_special_thanks&quot;&gt;Special Thanks&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;This article was a real challenge to put together, and because of that, I do want to thank a few people who helped it all come together.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;First, I want to thank &lt;a href=&quot;https://twitter.com/crichardson&quot; target=&quot;_blank&quot;&gt;Chris Richardson&lt;/a&gt; for already contributing a majority of the existing content out there about event sourcing in microservices. I first started planning to put this project together a few months back after speaking at the Oakland Java User Group about Spring Cloud and microservices. Chris is the organizer of that group and he was in the audience during my talk. The audience was kind to me in the Q/A (which I appreciated!) and there were several questions about eventual consistency and how to share state between microservices. Chris was kind enough to bail me out for a few questions and provided details on many of the key points that I started researching as a part of this article and project. Chris has open source event sourcing examples available which I recommend taking a look at  &lt;a href=&quot;https://github.com/cer/event-sourcing-examples&quot; target=&quot;_blank&quot;&gt;and you can find them here&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;I also want to thank &lt;a href=&quot;https://spring.io/team/bhale&quot; target=&quot;_blank&quot;&gt;Ben Hale&lt;/a&gt; of the &lt;a href=&quot;https://spring.io/team&quot; target=&quot;_blank&quot;&gt;Spring Engineering team&lt;/a&gt; at Pivotal for being my guide when it came to putting together the reactive streaming examples for event sourcing using Project Reactor. I am fortunate to be able to have the privilege to work with so many brilliant minds behind the Spring open source ecosystem when I am putting together these articles and reference projects. If you want to get more involved with this amazing open source community please come visit us at our annual &lt;a href=&quot;http://springoneplatform.io/&quot; target=&quot;_blank&quot;&gt;SpringOne Platform conference&lt;/a&gt; this August in Las Vegas.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt; &lt;/div&gt;</description><link>https://www.kennybastani.com/2016/04/event-sourcing-microservices-spring-cloud.html</link><author>noreply@blogger.com (Kenny Bastani)</author><thr:total>0</thr:total></item><item><guid isPermaLink="false">tag:blogger.com,1999:blog-6300367579216018061.post-5256427464584699488</guid><pubDate>Sun, 03 Jan 2016 18:49:00 +0000</pubDate><atom:updated>2016-01-03T15:02:50.556-08:00</atom:updated><category domain="http://www.blogger.com/atom/ns#">apache spark</category><category domain="http://www.blogger.com/atom/ns#">docker</category><category domain="http://www.blogger.com/atom/ns#">docker compose</category><category domain="http://www.blogger.com/atom/ns#">graph analytics</category><category domain="http://www.blogger.com/atom/ns#">graph processing</category><category domain="http://www.blogger.com/atom/ns#">graphx</category><category domain="http://www.blogger.com/atom/ns#">microservices</category><category domain="http://www.blogger.com/atom/ns#">neo4j</category><category domain="http://www.blogger.com/atom/ns#">rabbitmq</category><category domain="http://www.blogger.com/atom/ns#">spring boot</category><category domain="http://www.blogger.com/atom/ns#">spring cloud</category><category domain="http://www.blogger.com/atom/ns#">twitter</category><title>Creating a PageRank Analytics Platform Using Spring Boot Microservices</title><description>&lt;link rel=&quot;stylesheet&quot; href=&quot;https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans:400,700&quot;&gt;&lt;style&gt;.hljs-title, .hljs-id, .scss .hljs-preprocessor {    font-weight: 400 !important; } .hljs-class .hljs-title, .hljs-type, .vhdl .hljs-literal, .tex .hljs-command {    font-weight: 400 !important; } .hljs-keyword, .css .rule .hljs-keyword, .hljs-winutils, .nginx .hljs-title, .hljs-subst, .hljs-request, .hljs-status {    font-weight: 400 !important; } .sect1{padding-bottom:0!important} .sect1+.sect1{border:0!important} .conum[data-value]{display:inline-block;color:#fff!important;background-color:rgba(0,0,0,.8);-webkit-border-radius:100px;border-radius:100px;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:&quot;Open Sans&quot;,&quot;DejaVu Sans&quot;,sans-serif;font-style:normal;font-weight:bold} .conum[data-value] *{color:#fff!important} .conum[data-value]+b{display:none} .conum[data-value]:after{content:attr(data-value)} .fa-caret-up {     color: green;     text-shadow: 1px 1px 1px #ccc;     font-size: 1.75em !important; }  .fa-caret-down {     color: red;     text-shadow: 1px 1px 1px #ccc;     font-size: 1.75em !important; }  .fa-minus {     color: #999;     text-shadow: 1px 1px 1px #ccc;     font-size: 1em !important; }  .fa-plus {     font-size: 1em !important;     color: green;     text-shadow: 1px 1px 1px #ccc; }   @media screen and (min-width: 768px) { .table-responsive { font-size: 0.8em; max-width: 50em; } }  @media screen and (max-width: 768px) {     .table-responsive {     font-size: 0.65em; } }  .table-responsive th, .table-responsive tr, .table-responsive td { padding: 4px 4px 4px 4px !important; } p {     margin-bottom: 1.25em !important; line-height: 1.4; } li p { line-height: 1.4 !important; margin: 0 !important; } .blog-post-asciidoc .content img {  max-height: none; } .admonitionblock &gt; table {     background: rgba(0, 0, 0, 0) none repeat scroll 0 0;     border: 0 none;     border-collapse: separate;     width: 100%; } table {     background: #fff none repeat scroll 0 0;     border: 1px solid #dedede;     margin-bottom: 1.25em; } pre .conum[data-value]{position:relative;top:-.125em} b.conum *{color:inherit!important} .conum:not([data-value]):empty{display:none} .hdlist&gt;table,.colist&gt;table{border:0;background:none} .hdlist&gt;table&gt;tbody&gt;tr,.colist&gt;table&gt;tbody&gt;tr{background:none} td.hdlist1{padding-right:.75em;font-weight:bold} td.hdlist1,td.hdlist2{vertical-align:top} .literalblock+.colist,.listingblock+.colist{margin-top:-.5em} .colist&gt;table tr&gt;td:first-of-type{padding:0 .75em;line-height:1} .colist&gt;table tr&gt;td:last-of-type{padding:.25em 0} h1,h2,h3,#toctitle,.sidebarblock&gt;.content&gt;.title,h3,h4,h6{font-family:&quot;Open Sans&quot;,sans-serif;font-style:normal;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;} .blog-post-asciidoc p{margin-bottom:1.25rem} @media only screen and (min-width:768px){.sect1{padding-bottom:1.25em}}.sect1+.sect1{border-top:1px solid #efefed} pre, pre &gt; code {     -moz-osx-font-smoothing: auto;     color: rgba(0, 0, 0, 0.9);     font-family: monospace,monospace;     font-weight: 400;     line-height: 1.45;     text-rendering: optimizelegibility; } .blog-post-asciidoc code,kbd,pre,samp{font-size:.9em;font-weight:400;} .blog-post-asciidoc .admonitionblock&gt;table{border-collapse:separate;border:0;background:none;width:100%} .blog-post-asciidoc .admonitionblock&gt;table td.icon{text-align:center;width:80px} .blog-post-asciidoc .admonitionblock&gt;table td.icon img{max-width:none} .blog-post-asciidoc .admonitionblock&gt;table td.icon .title{font-weight:bold;font-family:&quot;Open Sans&quot;,&quot;DejaVu Sans&quot;,sans-serif;text-transform:uppercase} .blog-post-asciidoc .admonitionblock&gt;table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #ddddd8;color:rgba(0,0,0,.6)} .blog-post-asciidoc .admonitionblock&gt;table td.content&gt;:last-child&gt;:last-child{margin-bottom:0} .blog-post-asciidoc .admonitionblock td.icon [class^=&quot;fa icon-&quot;]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default} .blog-post-asciidoc .admonitionblock td.icon .icon-note:before{content:&quot;\f05a&quot;;color:#19407c} .blog-post-asciidoc .admonitionblock td.icon .icon-tip:before{content:&quot;\f0eb&quot;;text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111} .blog-post-asciidoc .admonitionblock td.icon .icon-warning:before{content:&quot;\f071&quot;;color:#bf6900} .blog-post-asciidoc .admonitionblock td.icon .icon-caution:before{content:&quot;\f06d&quot;;color:#bf3400} .blog-post-asciidoc .admonitionblock td.icon .icon-important:before{content:&quot;\f06a&quot;;color:#bf0000} #personDataTable td {     vertical-align: middle; } .rank-col {     text-align: center; } #personDataTable img {     max-width: 35px;     padding: 0; } .table-responsive {     font-weight: 400; } .table &gt; thead &gt; tr &gt; th {     border-bottom: 2px solid #ddd;     font-weight: 400;     padding: 8px !important;     vertical-align: bottom; } .table-responsive {     font-family: Helvetica,sans-serif; } .exampleblock pre {     margin-top: auto; } .exampleblock .content {     margin-top: auto; } blockquote {     border-left: 5px solid #eee;     color: #666;     font-size: 16px;     margin: 0;     padding: 10px 20px; } .attribution {     font-size: small;     text-align: right; } &lt;/style&gt;&lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.2.0/css/font-awesome.min.css&quot;&gt;&lt;div id=&quot;content&quot; class=&quot;blog-post-asciidoc&quot;&gt;&lt;a style=&quot;display: none;&quot; href=&quot;http://2.bp.blogspot.com/-KlU_6MvFD5Y/VolMB55ZkVI/AAAAAAAABU8/3eu4YMbpcj8/s1600/twitter-analytics-microservice-diagram.png&quot; imageanchor=&quot;1&quot; &gt;&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-KlU_6MvFD5Y/VolMB55ZkVI/AAAAAAAABU8/3eu4YMbpcj8/s1600/twitter-analytics-microservice-diagram.png&quot; /&gt;&lt;/a&gt;&lt;div id=&quot;preamble&quot;&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;This article introduces you &lt;a href=&quot;https://github.com/kbastani/spring-boot-graph-processing-example&quot; target=&quot;_blank&quot;&gt;to a sample application&lt;/a&gt; that combines multiple microservices with a graph processing platform to rank communities of users on Twitter. We&amp;#8217;re going to use a collection of popular tools as a part of this article&amp;#8217;s sample application. The tools we&amp;#8217;ll use, in the order of importance, will be:&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;ulist&quot;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://projects.spring.io/spring-boot/&quot; target=&quot;_blank&quot;&gt;Spring Boot&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://neo4j.com/&quot; target=&quot;_blank&quot;&gt;Neo4j&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://spark.apache.org/&quot; target=&quot;_blank&quot;&gt;Apache Spark&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://www.docker.com/&quot;&gt;Docker&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://www.rabbitmq.com/&quot; target=&quot;_blank&quot;&gt;RabbitMQ&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_ranking_twitter_profiles&quot;&gt;Ranking Twitter Profiles&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Let&amp;#8217;s do an overview of the problem we will solve as a part of our sample application. The problem we&amp;#8217;re going to solve is how to &lt;a href=&quot;https://en.wikipedia.org/wiki/Influencer_marketing#What_is_.E2.80.9CInfluence.E2.80.9D.3F&quot; target=&quot;_blank&quot;&gt;discover communities of influencers&lt;/a&gt; on Twitter using a set of seed profiles as inputs. To solve this problem without a background in machine learning or social network analytics might be a bit of a stretch, but we&amp;#8217;re going to take a stab at it using a little bit of computer science history.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The &lt;a href=&quot;https://en.wikipedia.org/wiki/PageRank&quot; target=&quot;_blank&quot;&gt;PageRank algorithm&lt;/a&gt;, created by Google co-founder &lt;a href=&quot;https://en.wikipedia.org/wiki/Larry_Page&quot; target=&quot;_blank&quot;&gt;Larry Page&lt;/a&gt;, was first used by Google to rank website documents from analyzing the graph of backlinks between sites.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;I dug up the &lt;a href=&quot;http://ilpubs.stanford.edu:8090/422/1/1999-66.pdf&quot; target=&quot;_blank&quot;&gt;original research paper&lt;/a&gt; on PageRank from Stanford for some inspiration. In the paper, the authors talk about the notion of approximating the &quot;importance&quot; of an academic publication by weighting the value of its citations.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;quoteblock&quot;&gt;&lt;blockquote&gt;The reason that PageRank is interesting is that there are many cases where simple citation counting does not correspond to our common sense notion of importance. For example, if a webpage has a link to the Yahoo home page, it may be just one link but it is a very important one. This page should be ranked higher than many pages with more links but from obscure places. PageRank is an attempt to see how good an approximation to &quot;importance&quot; can be obtained just from the link structure. &lt;/blockquote&gt;&lt;div class=&quot;attribution&quot;&gt;&amp;mdash; Page, Lawrence and Brin, Sergey and Motwani, Rajeev and Winograd, Terry (1999)&lt;br&gt;&lt;cite&gt;&lt;a href=&quot;http://ilpubs.stanford.edu:8090/422&quot; target=&quot;_blank&quot;&gt;The PageRank Citation Ranking: Bringing Order to the Web&lt;/a&gt;&lt;/cite&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Now let&amp;#8217;s take the same definition that is described in the paper and apply it to our problem of discovering important profiles on Twitter. Twitter users typically follow other users to track their updates as a part of their stream. We can use the same reasoning behind using PageRank on citations to approximate the &quot;importance&quot; of profiles on Twitter. This reasoning would tell us that it&amp;#8217;s not the number of followers that make a profile important, it is measured by how important those followers are.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;That&amp;#8217;s exactly what we&amp;#8217;re going to build in this article, and we&amp;#8217;ll end up with something that looks like the following table.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;table-responsive&quot;&gt;  &lt;table class=&quot;table table-striped&quot;&gt;    &lt;thead&gt;      &lt;tr&gt;        &lt;th style=&quot;text-align: center;&quot;&gt;Rank&lt;/th&gt;        &lt;th&gt;Photo&lt;/th&gt;        &lt;th class=&quot;hidden-xs&quot;&gt;Name&lt;/th&gt;        &lt;th&gt;Profile&lt;/th&gt;        &lt;th class=&quot;hidden-xs&quot;&gt;Following&lt;/th&gt;        &lt;th&gt;Followers&lt;/th&gt;        &lt;th&gt;PageRank&lt;/th&gt;        &lt;th class=&quot;hidden-xs&quot;&gt;Change&lt;/th&gt;      &lt;/tr&gt;    &lt;/thead&gt;    &lt;tbody id=&quot;personDataTable&quot;&gt;      &lt;tr&gt;        &lt;td class=&quot;rank-col&quot;&gt;1.&lt;/td&gt;        &lt;td&gt;&lt;img src=&quot;http://pbs.twimg.com/profile_images/3363818792/c90e33ccf22e3146d5cd871ce561795a_normal.png&quot;&gt;&lt;/td&gt;        &lt;td class=&quot;hidden-xs&quot;&gt;Paul Ford&lt;/td&gt;        &lt;td&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.twitter.com/ftrain&quot;&gt;@ftrain&lt;/a&gt;&lt;/td&gt;        &lt;td class=&quot;hidden-xs&quot;&gt;175&lt;/td&gt;        &lt;td&gt;31948&lt;/td&gt;        &lt;td&gt;7368.2417&lt;/td&gt;        &lt;td class=&quot;hidden-xs&quot;&gt;&lt;i aria-hidden=&quot;true&quot; class=&quot;fa fa-minus&quot;&gt;&lt;/i&gt;&lt;/td&gt;      &lt;/tr&gt;      &lt;tr&gt;        &lt;td class=&quot;rank-col&quot;&gt;2.&lt;/td&gt;        &lt;td&gt;&lt;img src=&quot;http://pbs.twimg.com/profile_images/550153119208726529/ZZqJSFpi_normal.jpeg&quot;&gt;&lt;/td&gt;        &lt;td class=&quot;hidden-xs&quot;&gt;harper&lt;/td&gt;        &lt;td&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.twitter.com/harper&quot;&gt;@harper&lt;/a&gt;&lt;/td&gt;        &lt;td class=&quot;hidden-xs&quot;&gt;1024&lt;/td&gt;        &lt;td&gt;32452&lt;/td&gt;        &lt;td&gt;6754.455&lt;/td&gt;        &lt;td class=&quot;hidden-xs&quot;&gt;&lt;i aria-hidden=&quot;true&quot; class=&quot;fa fa-minus&quot;&gt;&lt;/i&gt;&lt;/td&gt;      &lt;/tr&gt;      &lt;tr&gt;        &lt;td class=&quot;rank-col&quot;&gt;3.&lt;/td&gt;        &lt;td&gt;&lt;img src=&quot;http://pbs.twimg.com/profile_images/478069251790499841/GNcGrhNt_normal.png&quot;&gt;&lt;/td&gt;        &lt;td class=&quot;hidden-xs&quot;&gt;Bret Victor&lt;/td&gt;        &lt;td&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.twitter.com/worrydream&quot;&gt;@worrydream&lt;/a&gt;&lt;/td&gt;        &lt;td class=&quot;hidden-xs&quot;&gt;35&lt;/td&gt;        &lt;td&gt;37658&lt;/td&gt;        &lt;td&gt;6747.585&lt;/td&gt;        &lt;td class=&quot;hidden-xs&quot;&gt;&lt;i aria-hidden=&quot;true&quot; class=&quot;fa fa-minus&quot;&gt;&lt;/i&gt;&lt;/td&gt;      &lt;/tr&gt;      &lt;tr&gt;        &lt;td class=&quot;rank-col&quot;&gt;4.&lt;/td&gt;        &lt;td&gt;&lt;img src=&quot;http://pbs.twimg.com/profile_images/673478075892404225/FB25Vch7_normal.jpg&quot;&gt;&lt;/td&gt;        &lt;td class=&quot;hidden-xs&quot;&gt;Lincoln Stoll&lt;/td&gt;        &lt;td&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.twitter.com/lstoll&quot;&gt;@lstoll&lt;/a&gt;&lt;/td&gt;        &lt;td class=&quot;hidden-xs&quot;&gt;872&lt;/td&gt;        &lt;td&gt;41067&lt;/td&gt;        &lt;td&gt;5976.3555&lt;/td&gt;        &lt;td class=&quot;hidden-xs&quot;&gt;&lt;i aria-hidden=&quot;true&quot; class=&quot;fa fa-minus&quot;&gt;&lt;/i&gt;&lt;/td&gt;      &lt;/tr&gt;      &lt;tr&gt;        &lt;td class=&quot;rank-col&quot;&gt;5.&lt;/td&gt;        &lt;td&gt;&lt;img src=&quot;http://pbs.twimg.com/profile_images/1768986828/image1327082013_normal.png&quot;&gt;&lt;/td&gt;        &lt;td class=&quot;hidden-xs&quot;&gt;kate matsudaira&lt;/td&gt;        &lt;td&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.twitter.com/katemats&quot;&gt;@katemats&lt;/a&gt;&lt;/td&gt;        &lt;td class=&quot;hidden-xs&quot;&gt;20465&lt;/td&gt;        &lt;td&gt;25799&lt;/td&gt;        &lt;td&gt;5916.3843&lt;/td&gt;        &lt;td class=&quot;hidden-xs&quot;&gt;&lt;i aria-hidden=&quot;true&quot; class=&quot;fa fa-caret-up&quot;&gt;&lt;/i&gt;&lt;/td&gt;      &lt;/tr&gt;      &lt;tr&gt;        &lt;td class=&quot;rank-col&quot;&gt;6.&lt;/td&gt;        &lt;td&gt;&lt;img src=&quot;http://pbs.twimg.com/profile_images/651438942181453824/Ov8RmRF9_normal.png&quot;&gt;&lt;/td&gt;        &lt;td class=&quot;hidden-xs&quot;&gt;rands&lt;/td&gt;        &lt;td&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.twitter.com/rands&quot;&gt;@rands&lt;/a&gt;&lt;/td&gt;        &lt;td class=&quot;hidden-xs&quot;&gt;741&lt;/td&gt;        &lt;td&gt;35079&lt;/td&gt;        &lt;td&gt;5888.145&lt;/td&gt;        &lt;td class=&quot;hidden-xs&quot;&gt;&lt;i aria-hidden=&quot;true&quot; class=&quot;fa fa-caret-down&quot;&gt;&lt;/i&gt;&lt;/td&gt;      &lt;/tr&gt;      &lt;tr&gt;        &lt;td class=&quot;rank-col&quot;&gt;7.&lt;/td&gt;        &lt;td&gt;&lt;img src=&quot;http://pbs.twimg.com/profile_images/513088789585993728/s1DnFxP6_normal.jpeg&quot;&gt;&lt;/td&gt;        &lt;td class=&quot;hidden-xs&quot;&gt;Alex Payne&lt;/td&gt;        &lt;td&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.twitter.com/al3x&quot;&gt;@al3x&lt;/a&gt;&lt;/td&gt;        &lt;td class=&quot;hidden-xs&quot;&gt;405&lt;/td&gt;        &lt;td&gt;41099&lt;/td&gt;        &lt;td&gt;5547.4307&lt;/td&gt;        &lt;td class=&quot;hidden-xs&quot;&gt;&lt;i aria-hidden=&quot;true&quot; class=&quot;fa fa-minus&quot;&gt;&lt;/i&gt;&lt;/td&gt;      &lt;/tr&gt;      &lt;tr&gt;        &lt;td class=&quot;rank-col&quot;&gt;8.&lt;/td&gt;        &lt;td&gt;&lt;img src=&quot;http://pbs.twimg.com/profile_images/1245949369/b8dbb1987e8e5318584865f880036796_normal.jpeg&quot;&gt;&lt;/td&gt;        &lt;td class=&quot;hidden-xs&quot;&gt;Chris Wanstrath&lt;/td&gt;        &lt;td&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.twitter.com/defunkt&quot;&gt;@defunkt&lt;/a&gt;&lt;/td&gt;        &lt;td class=&quot;hidden-xs&quot;&gt;5645&lt;/td&gt;        &lt;td&gt;45310&lt;/td&gt;        &lt;td&gt;4787.9644&lt;/td&gt;        &lt;td class=&quot;hidden-xs&quot;&gt;&lt;i aria-hidden=&quot;true&quot; class=&quot;fa fa-minus&quot;&gt;&lt;/i&gt;&lt;/td&gt;      &lt;/tr&gt;      &lt;tr&gt;        &lt;td class=&quot;rank-col&quot;&gt;9.&lt;/td&gt;        &lt;td&gt;&lt;img src=&quot;http://pbs.twimg.com/profile_images/629693983610961921/k-pW0Isa_normal.png&quot;&gt;&lt;/td&gt;        &lt;td class=&quot;hidden-xs&quot;&gt;SaraReyChipps&lt;/td&gt;        &lt;td&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.twitter.com/SaraJChipps&quot;&gt;@SaraJChipps&lt;/a&gt;&lt;/td&gt;        &lt;td class=&quot;hidden-xs&quot;&gt;1007&lt;/td&gt;        &lt;td&gt;29617&lt;/td&gt;        &lt;td&gt;4271.676&lt;/td&gt;        &lt;td class=&quot;hidden-xs&quot;&gt;&lt;i aria-hidden=&quot;true&quot; class=&quot;fa fa-caret-down&quot;&gt;&lt;/i&gt;&lt;/td&gt;      &lt;/tr&gt;      &lt;tr&gt;        &lt;td class=&quot;rank-col&quot;&gt;10.&lt;/td&gt;        &lt;td&gt;&lt;img src=&quot;http://pbs.twimg.com/profile_images/679769047022436353/nhMCEyEj_normal.jpg&quot;&gt;&lt;/td&gt;        &lt;td class=&quot;hidden-xs&quot;&gt;Leah Culver&lt;/td&gt;        &lt;td&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.twitter.com/leahculver&quot;&gt;@leahculver&lt;/a&gt;&lt;/td&gt;        &lt;td class=&quot;hidden-xs&quot;&gt;491&lt;/td&gt;        &lt;td&gt;30723&lt;/td&gt;        &lt;td&gt;3852.3728&lt;/td&gt;        &lt;td class=&quot;hidden-xs&quot;&gt;&lt;i aria-hidden=&quot;true&quot; class=&quot;fa fa-minus&quot;&gt;&lt;/i&gt;&lt;/td&gt;      &lt;/tr&gt;    &lt;/tbody&gt;  &lt;/table&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The first thing we&amp;#8217;re going to need to worry about when building this solution is how we&amp;#8217;re going to calculate PageRank on potentially millions of users and links. To do this, we&amp;#8217;re going to use something called a &lt;em&gt;graph processing platform&lt;/em&gt;.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_what_is_a_graph_processing_platform&quot;&gt;What is a graph processing platform?&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;A graph processing platform is an application architecture that provides a general-purpose job scheduling interface for analyzing graphs. The application we&amp;#8217;ll build will make use of a graph processing platform to analyze and rank communities of users on Twitter. For this we&amp;#8217;ll use &lt;a href=&quot;https://github.com/neo4j-contrib/neo4j-mazerunner&quot; target=&quot;_blank&quot;&gt;Neo4j Mazerunner&lt;/a&gt;, an open source project that I started that connects Neo4j’s database server to Apache Spark.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The diagram below illustrates a graph processing platform similar to Neo4j Mazerunner.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;div class=&quot;imageblock&quot; style=&quot;display: block;&quot;&gt;&lt;div class=&quot;content&quot; style=&quot;text-align: center;&quot;&gt;&lt;img width=&quot;100%&quot; alt=&quot;Graph processing platform diagram&quot; src=&quot;http://i.imgur.com/93dJ2MM.png&quot; style=&quot;max-height: 25em; margin: auto !important;&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_submitting_pagerank_jobs_to_graphx&quot;&gt;Submitting PageRank Jobs to GraphX&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The graph processing platform I&amp;#8217;ve described will provide us with a general purpose API for submitting PageRank jobs to &lt;a href=&quot;http://spark.apache.org/graphx/&quot; target=&quot;_blank&quot;&gt;Apache Spark&amp;#8217;s GraphX module&lt;/a&gt; from Neo4j. The PageRank results from GraphX will be automatically applied back to Neo4j without any additional work to manually handle data loading. The workflow for this is extremely simple for our purposes. From a backend service we will only need to make a simple HTTP request to Neo4j to begin a PageRank job.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;I&amp;#8217;ve also taken care of making sure that the graph processing platform is easily deployable to a cloud provider using Docker containers. In a &lt;a href=&quot;http://www.kennybastani.com/2015/03/spark-neo4j-tutorial-docker.html&quot; target=&quot;_blank&quot;&gt;previous article&lt;/a&gt;, I describe how to use &lt;a href=&quot;https://docs.docker.com/compose/&quot; target=&quot;_blank&quot;&gt;Docker Compose&lt;/a&gt; to run Mazerunner as a multi-container application. We&amp;#8217;ll do the same for this sample application but extend the Docker Compose file to include additional Spring Boot applications that will become our backend microservices.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;admonitionblock caution&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;icon&quot;&gt;&lt;i class=&quot;fa icon-caution&quot; title=&quot;Caution&quot;&gt;&lt;/i&gt;&lt;/td&gt;&lt;td class=&quot;content&quot;&gt;By default, Docker Compose will orchestrate containers on a single virtual machine. If we were to build a truly fault tolerant and resilient cloud-based application, we&amp;#8217;d need to be sure to scale our system to multiple virtual machines using a cloud platform. This is the subject of a later article. &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Now that we understand how we will use a graph processing platform, let&amp;#8217;s talk about how to build a microservice architecture using Spring Boot and Spring Cloud to rank profiles on Twitter.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;h1 id=&quot;_building_microservices&quot; class=&quot;sect0&quot;&gt;Building Microservices&lt;/h1&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;I&amp;#8217;ve talked a lot about microservices in past articles. When we talk about microservices we are talking about developing software in the context of &lt;a href=&quot;https://en.wikipedia.org/wiki/Continuous_delivery&quot; target=&quot;_blank&quot;&gt;continuous delivery&lt;/a&gt;. Microservices are not just smaller services that scale horizontally. When we talk about microservices, we are talking about being able to create applications that are the product of many teams delivering continuously in independent release cycles. Josh Long and I describe at length how to untangle the patterns of building and operating JVM-based microservices in &lt;a href=&quot;http://shop.oreilly.com/product/0636920038252.do&quot; target=&quot;_blank&quot;&gt;O&amp;#8217;Reilly&amp;#8217;s &lt;em&gt;Cloud Native Java&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;In this sample, we&amp;#8217;ll build 4 microservices, each as a Spring Boot application. If we were to build this architecture as microservices in an authentic scenario, each microservice would be owned and managed by a different team. This is an important differentiation in this new practice, as there is much confusion around what a microservice is and what it is not. A microservice is not just a distributed system of small services. The practice of building microservices should never be without the discipline of continuous delivery.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;For the purposes of this article, we&amp;#8217;ll focus on scenarios that help us gain experience and familiarity with building distributed systems that resemble a microservice architecture.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_overview&quot;&gt;Overview&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Now let&amp;#8217;s do a quick overview of the concepts we&amp;#8217;re going to cover as a part of this sample application. We will apply the same recipe from previous articles on similar topics for &lt;a href=&quot;http://www.kennybastani.com/2015/07/spring-cloud-docker-microservices.html&quot; target=&quot;_blank&quot;&gt;building microservices with Spring Boot and Spring Cloud&lt;/a&gt;. The key difference from my previous articles is that we are going to create a data service that does both batch processing tasks as well as exposing data as HTTP resources to API consumers.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_system_architecture_diagram&quot;&gt;System Architecture Diagram&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The diagram below shows each component and microservice that we will create as a part of this sample application. Notice how we’re connecting the Spring Boot applications to the graph processing platform we looked at earlier. Also, notice the connections between the services, these connections define communication points between each service and what protocol is used.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;div class=&quot;imageblock&quot; style=&quot;display: block;&quot;&gt;&lt;div class=&quot;content&quot; style=&quot;text-align: center;&quot;&gt;&lt;img width=&quot;100%&quot; alt=&quot;Microservice architecture with Spring Boot&quot; src=&quot;http://i.imgur.com/LDHQJAx.png&quot; style=&quot;max-height: 25em; margin: auto !important;&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The three applications that are colored in blue are stateless services. Stateless services will not attach a persistent &lt;a href=&quot;http://12factor.net/backing-services&quot; target=&quot;_blank&quot;&gt;backing service&lt;/a&gt; or need to worry about managing state locally. The application that is colored in green is the &lt;em&gt;Twitter Crawler&lt;/em&gt; service. Components that are colored in green will typically have an attached backing service. These backing services are responsible for managing state locally, and will either persist state to disk or in-memory.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;a name=&#39;more&#39;&gt;&lt;/a&gt;&lt;h1 id=&quot;_twitter_crawler&quot; class=&quot;sect0&quot;&gt;Twitter Crawler&lt;/h1&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;We’ll start by creating a service that is responsible for importing data from Twitter’s API and storing it in Neo4j. This service will be called the &lt;em&gt;Twitter Crawler&lt;/em&gt; service. This service will also schedule PageRank jobs on data it imports into Neo4j. The &lt;em&gt;Twitter Crawler&lt;/em&gt; service will be built using Spring Boot and attach backing services for Neo4j and RabbitMQ.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;We&amp;#8217;re going to walkthrough each of the following concerns as a part of building this service.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;ulist&quot;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;#_creating_spring_data_neo4j_repositories&quot;&gt;Creating Spring Data Neo4j repositories&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;#_exposing_repository_apis_using_spring_data_rest&quot;&gt;Exposing repository APIs using Spring Data REST&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;#_connecting_to_the_twitter_api&quot;&gt;Connecting to the Twitter API&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;#_using_amqp_to_import_profiles_from_the_twitter_api&quot;&gt;Using AMQP to import profiles from the Twitter API&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;#_scheduling_new_pagerank_jobs&quot;&gt;Scheduling new PageRank jobs&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;#_discovering_new_users&quot;&gt;Discovering new users&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;#_registering_as_a_discovery_client_with_eureka&quot;&gt;Registering as a discovery client with Eureka&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_creating_spring_data_neo4j_repositories&quot;&gt;Creating Spring Data Neo4j repositories&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;We&amp;#8217;ll start building the &lt;em&gt;Twitter Crawler&lt;/em&gt; service by creating a set of domain classes and repositories to manage data with the &lt;a href=&quot;http://projects.spring.io/spring-data-neo4j/&quot; target=&quot;_blank&quot;&gt;Spring Data Neo4j project&lt;/a&gt;. Spring Data Neo4j is a project in the Spring Data ecosystem that implements the Spring Data repository abstraction using an &lt;a href=&quot;http://neo4j.com/docs/ogm/java/stable/&quot; target=&quot;_blank&quot;&gt;OGM (Object Graph Mapping)&lt;/a&gt; library for Neo4j. Spring Data Neo4j allows you to manage data on a Neo4j server using annotated POJOs as entity references in a Spring Data application.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Before we can start managing data in Neo4j, we&amp;#8217;ll need to design and construct a graph data model for our application&amp;#8217;s domain data. The domain model for this application is rather simple, and we&amp;#8217;ll construct it using domain objects described in &lt;a href=&quot;https://dev.twitter.com/overview/documentation&quot; target=&quot;_blank&quot;&gt;Twitter&amp;#8217;s API documentation&lt;/a&gt;. We&amp;#8217;ll only have one domain concept, which is a &lt;code&gt;User&lt;/code&gt; profile, and we&amp;#8217;ll source this resource from profiles that are imported from the Twitter API. We&amp;#8217;ll then have a relationship entity with the type named &lt;code&gt;FOLLOWS&lt;/code&gt;. The &lt;code&gt;FOLLOWS&lt;/code&gt; relationship will connect &lt;code&gt;User&lt;/code&gt; profiles together in Neo4j after importing follower data from the Twitter API.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The graph data model that we will end up with looks like the following diagram.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;div class=&quot;imageblock&quot; style=&quot;display: block;&quot;&gt;&lt;div class=&quot;content&quot; style=&quot;text-align: center;&quot;&gt;&lt;img width=&quot;100%&quot; alt=&quot;Graph data model for Neo4j&quot; src=&quot;http://i.imgur.com/Fg2oOal.png&quot; style=&quot;max-height: 25em; margin: auto !important;&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;We&amp;#8217;ll now use the graph data model illustrated in the diagram to create a POJO that represents a domain class for the &lt;code&gt;User&lt;/code&gt; node in Neo4j. We&amp;#8217;ll also be sure to add fields for the incoming and outgoing follower connections as members of the &lt;code&gt;User&lt;/code&gt; domain class. These fields will be created with the type &lt;code&gt;Set&amp;lt;User&amp;gt;&lt;/code&gt;, and give us a way to load profiles that are connected to a &lt;code&gt;User&lt;/code&gt; node with a &lt;code&gt;FOLLOWS&lt;/code&gt; relationship. These steps are shown in the example code snippet below.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 1. &lt;a href=&quot;https://github.com/kbastani/spring-boot-graph-processing-example/blob/master/twitter-rank-crawler/src/main/java/org/kbastani/twitter/User.java#L22&quot; target=&quot;_blank&quot;&gt;User.java&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;prettyprint highlight&quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;@NodeEntity&lt;br /&gt;public class User implements Serializable {&lt;br /&gt;&lt;br /&gt;    @GraphId&lt;br /&gt;    private Long id;&lt;br /&gt;&lt;br /&gt;    @Index(unique = true) &lt;i class=&quot;conum&quot; data-value=&quot;1&quot;&gt;&lt;/i&gt;&lt;b&gt;(1)&lt;/b&gt;&lt;br /&gt;    private Long profileId;&lt;br /&gt;&lt;br /&gt;    @Relationship(type = &quot;FOLLOWS&quot;, direction = &quot;OUTGOING&quot;) &lt;i class=&quot;conum&quot; data-value=&quot;2&quot;&gt;&lt;/i&gt;&lt;b&gt;(2)&lt;/b&gt;&lt;br /&gt;    private Set&amp;lt;User&amp;gt; follows = new HashSet&amp;lt;&amp;gt;();&lt;br /&gt;&lt;br /&gt;    @Relationship(type = &quot;FOLLOWS&quot;, direction = &quot;INCOMING&quot;) &lt;i class=&quot;conum&quot; data-value=&quot;3&quot;&gt;&lt;/i&gt;&lt;b&gt;(3)&lt;/b&gt;&lt;br /&gt;    private Set&amp;lt;User&amp;gt; followers = new HashSet&amp;lt;&amp;gt;();&lt;br /&gt;&lt;br /&gt;    private String screenName;&lt;br /&gt;    private Float pagerank;&lt;br /&gt;&lt;br /&gt;    ...&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;colist arabic&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td&gt;&lt;i class=&quot;conum&quot; data-value=&quot;1&quot;&gt;&lt;/i&gt;&lt;b&gt;1&lt;/b&gt;&lt;/td&gt;&lt;td&gt;Creates a unique constraint on a user&amp;#8217;s &lt;code&gt;profileId&lt;/code&gt; property&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;i class=&quot;conum&quot; data-value=&quot;2&quot;&gt;&lt;/i&gt;&lt;b&gt;2&lt;/b&gt;&lt;/td&gt;&lt;td&gt;Manages relationships of user nodes that this profile is following&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;i class=&quot;conum&quot; data-value=&quot;3&quot;&gt;&lt;/i&gt;&lt;b&gt;3&lt;/b&gt;&lt;/td&gt;&lt;td&gt;Manages relationships of user nodes that this profile is being followed by&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Next, we&amp;#8217;ll need to create a repository to manage our data that will be mapped to the &lt;code&gt;User&lt;/code&gt; domain class. The Spring Data project makes repository-based management of database entities a snap. We&amp;#8217;re going to use the &lt;code&gt;GraphRepository&amp;lt;T&amp;gt;&lt;/code&gt; interface to create a repository bean that will be created at runtime in our Spring Boot application.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 2. &lt;a href=&quot;https://github.com/kbastani/spring-boot-graph-processing-example/blob/master/twitter-rank-crawler/src/main/java/org/kbastani/twitter/UserRepository.java#L14&quot; target=&quot;_blank&quot;&gt;UserRepository.java&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;prettyprint highlight&quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;public interface UserRepository extends GraphRepository&amp;lt;User&amp;gt; {&lt;br /&gt;&lt;br /&gt;  // Get a User&#39;s Neo4j node ID using a Twitter profile ID&lt;br /&gt;  @Query(&quot;MATCH (user:User { profileId: {profileId} }) RETURN id(user) as id&quot;)&lt;br /&gt;  Long getUserIdByProfileId(@Param(&quot;profileId&quot;) Long profileId);&lt;br /&gt;&lt;br /&gt;  ...&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Here we create a basic interface that extends &lt;code&gt;GraphRepository&amp;lt;User&amp;gt;&lt;/code&gt;. This repository interface will be initialized as a bean at runtime, and provides us with a client to manage transactions on entities for &lt;code&gt;User&lt;/code&gt; nodes in Neo4j.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Now that we can manage &lt;code&gt;User&lt;/code&gt; nodes and &lt;code&gt;FOLLOWS&lt;/code&gt; relationships, we need to think about how performant it will be to save potentially thousands of relationships per second when importing user profiles from the Twitter API. We&amp;#8217;ll need to be able to batch transactions so that Neo4j can handle the throughput of ingesting writes at a rapid pace. To do this, we need to create another &lt;code&gt;GraphRepository&lt;/code&gt; bean for managing the creation of many &lt;code&gt;FOLLOWS&lt;/code&gt; relationships between a set of &lt;code&gt;User&lt;/code&gt; profiles.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 3. &lt;a href=&quot;https://github.com/kbastani/spring-boot-graph-processing-example/blob/master/twitter-rank-crawler/src/main/java/org/kbastani/twitter/FollowsRepository.java#L13&quot; target=&quot;_blank&quot;&gt;FollowsRepository.java&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;prettyprint highlight&quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;public interface FollowsRepository extends GraphRepository&amp;lt;Follows&amp;gt; {&lt;br /&gt;&lt;br /&gt;  // Batches the creation of many FOLLOWS relationships&lt;br /&gt;  @Query(&quot;FOREACH(x in {follows} | MERGE (a:User { profileId: x.userA.profileId })\n&quot; +&lt;br /&gt;          &quot;MERGE (b:User { profileId: x.userB.profileId })\n&quot; +&lt;br /&gt;          &quot;MERGE (a)-[:FOLLOWS]-&amp;gt;(b))&quot;)&lt;br /&gt;  void saveFollows(@Param(&quot;follows&quot;) Set&amp;lt;Follows&amp;gt; follows);&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The repository interface definition above is similar to the &lt;code&gt;UserRepository&lt;/code&gt; interface. We&amp;#8217;ve defined a &lt;a href=&quot;http://neo4j.com/docs/stable/cypher-query-lang.html&quot; target=&quot;_blank&quot;&gt;Cypher query&lt;/a&gt; template for a custom repository method that will allow us to save batches of thousands of relationships that will connect &lt;code&gt;User&lt;/code&gt; nodes together with a &lt;code&gt;FOLLOWS&lt;/code&gt; relationship type in our Neo4j database. The custom &lt;code&gt;saveFollows&lt;/code&gt; method takes in a domain class representing a relationship entity for the &lt;code&gt;FOLLOWS&lt;/code&gt; relationship type. We&amp;#8217;ll also need to create this domain class as a POJO like we did with the &lt;code&gt;User&lt;/code&gt; node.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 4. &lt;a href=&quot;https://github.com/kbastani/spring-boot-graph-processing-example/blob/master/twitter-rank-crawler/src/main/java/org/kbastani/twitter/Follows.java#L11&quot; target=&quot;_blank&quot;&gt;Follows.java&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;prettyprint highlight&quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;@RelationshipEntity(type = &quot;FOLLOWS&quot;) &lt;i class=&quot;conum&quot; data-value=&quot;1&quot;&gt;&lt;/i&gt;&lt;b&gt;(1)&lt;/b&gt;&lt;br /&gt;public class Follows {&lt;br /&gt;&lt;br /&gt;  @GraphId&lt;br /&gt;  private Long relationshipId;&lt;br /&gt;  @StartNode&lt;br /&gt;  private User userA; &lt;i class=&quot;conum&quot; data-value=&quot;2&quot;&gt;&lt;/i&gt;&lt;b&gt;(2)&lt;/b&gt;&lt;br /&gt;  @EndNode&lt;br /&gt;  private User userB; &lt;i class=&quot;conum&quot; data-value=&quot;3&quot;&gt;&lt;/i&gt;&lt;b&gt;(3)&lt;/b&gt;&lt;br /&gt;&lt;br /&gt;  ...&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;colist arabic&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td&gt;&lt;i class=&quot;conum&quot; data-value=&quot;1&quot;&gt;&lt;/i&gt;&lt;b&gt;1&lt;/b&gt;&lt;/td&gt;&lt;td&gt;Demarcates this class as a relationship entity for the &lt;code&gt;FOLLOWS&lt;/code&gt; type&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;i class=&quot;conum&quot; data-value=&quot;2&quot;&gt;&lt;/i&gt;&lt;b&gt;2&lt;/b&gt;&lt;/td&gt;&lt;td&gt;This is the user with the outgoing &lt;code&gt;FOLLOWS&lt;/code&gt; relationship&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;i class=&quot;conum&quot; data-value=&quot;3&quot;&gt;&lt;/i&gt;&lt;b&gt;3&lt;/b&gt;&lt;/td&gt;&lt;td&gt;This is the other user with the incoming &lt;code&gt;FOLLOWS&lt;/code&gt; relationship&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;We now have the necessary data management capabilities to import Twitter profiles and their connections in the native shape of a graph. This is the advantage of using a graph database. Having our data stored as a graph makes it easy to perform PageRank analysis on without tedious aggregation and transformation that would be necessary if we used a relational database.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_exposing_repository_apis_using_spring_data_rest&quot;&gt;Exposing repository APIs using Spring Data REST&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Now that we have created our Spring Data Neo4j repositories for managing our Twitter follower graph, we&amp;#8217;ll need to expose a REST API interface that allows remote services to manage our domain data over HTTP. Thankfully this is a simple task when using the &lt;a href=&quot;http://projects.spring.io/spring-data-rest/&quot; target=&quot;_blank&quot;&gt;Spring Data REST&lt;/a&gt; project. All that we need to do to enable this as a feature on our Spring Data Neo4j repositories is add the &lt;code&gt;spring-boot-starter-data-rest&lt;/code&gt; artifact as a dependency to the project&amp;#8217;s &lt;code&gt;pom.xml&lt;/code&gt; file.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 5. &lt;a href=&quot;https://github.com/kbastani/spring-boot-graph-processing-example/blob/master/twitter-rank-crawler/pom.xml#L44&quot; target=&quot;_blank&quot;&gt;pom.xml&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;prettyprint highlight&quot;&gt;&lt;code class=&quot;language-xml&quot; data-lang=&quot;xml&quot;&gt;&amp;lt;dependency&amp;gt;&lt;br /&gt;    &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;&lt;br /&gt;    &amp;lt;artifactId&amp;gt;spring-boot-starter-data-rest&amp;lt;/artifactId&amp;gt;&lt;br /&gt;&amp;lt;/dependency&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;By adding this artifact as a dependency, the Spring Boot application will automatically find Spring Data repositories and expose a REST API to manage repository data remotely over HTTP. Now if we start our Spring Boot application and navigate to the base HTTP endpoint we&amp;#8217;ll see a JSON response in the format of &lt;code&gt;application/hal+json&lt;/code&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;prettyprint highlight&quot;&gt;&lt;code class=&quot;language-json&quot; data-lang=&quot;json&quot;&gt;{&lt;br /&gt;  &quot;_links&quot; : {&lt;br /&gt;    &quot;following&quot; : {&lt;br /&gt;      &quot;href&quot; : &quot;http://localhost:8080/following{?page,size,sort}&quot;,&lt;br /&gt;      &quot;templated&quot; : true&lt;br /&gt;    },&lt;br /&gt;    &quot;users&quot; : {&lt;br /&gt;      &quot;href&quot; : &quot;http://localhost:8080/users{?page,size,sort}&quot;,&lt;br /&gt;      &quot;templated&quot; : true&lt;br /&gt;    },&lt;br /&gt;    &quot;profile&quot; : {&lt;br /&gt;      &quot;href&quot; : &quot;http://localhost:8080/profile&quot;&lt;br /&gt;    }&lt;br /&gt;  }&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The &lt;code&gt;application/hal+json&lt;/code&gt; content type is a JSON representation that lists &lt;a href=&quot;https://spring.io/understanding/HATEOAS&quot; target=&quot;_blank&quot;&gt;hypermedia resources&lt;/a&gt; as embedded links. We can use these embedded links for &lt;code&gt;/users{?page,size,sort}&lt;/code&gt; and &lt;code&gt;/following{?page,size,sort}&lt;/code&gt; to manage resources of our graph repositories over HTTP.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_connecting_to_the_twitter_api&quot;&gt;Connecting to the Twitter API&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Now that we have everything we need to manage our Twitter profile data in Neo4j, we can import profiles from the Twitter API. To do this, we can use the &lt;a href=&quot;http://projects.spring.io/spring-social-twitter/&quot; target=&quot;_blank&quot;&gt;&lt;em&gt;Spring Social Twitter&lt;/em&gt;&lt;/a&gt; project, an open source project from the Spring ecosystem that provides a managed Twitter API client. Before we can start using this client, we&amp;#8217;ll need to add the &lt;code&gt;spring-social-twitter&lt;/code&gt; artifact as one of our project dependencies in the &lt;code&gt;pom.xml&lt;/code&gt;, which is shown in the code snippet below.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 6. &lt;a href=&quot;https://github.com/kbastani/spring-boot-graph-processing-example/blob/master/twitter-rank-crawler/pom.xml#L39&quot; target=&quot;_blank&quot;&gt;pom.xml&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;prettyprint highlight&quot;&gt;&lt;code class=&quot;language-xml&quot; data-lang=&quot;xml&quot;&gt;&amp;lt;dependency&amp;gt;&lt;br /&gt;    &amp;lt;groupId&amp;gt;org.springframework.social&amp;lt;/groupId&amp;gt;&lt;br /&gt;    &amp;lt;artifactId&amp;gt;spring-social-twitter&amp;lt;/artifactId&amp;gt;&lt;br /&gt;    &amp;lt;version&amp;gt;1.1.2.RELEASE&amp;lt;/version&amp;gt;&lt;br /&gt;&amp;lt;/dependency&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The next step will be to configure the &lt;a href=&quot;http://docs.spring.io/spring-social-twitter/docs/1.1.0.RELEASE/reference/htmlsingle/#twitter-api-binding&quot; target=&quot;_blank&quot;&gt;Twitter client&lt;/a&gt; that is provided by &lt;code&gt;spring-social-twitter&lt;/code&gt;. In order to access operations for importing profiles from Twitter’s API, we will need to provide API tokens and keys that are generated for an application by Twitter. You’ll need to register with Twitter and create a developer app in order to get these keys. Getting API access is a simple process. &lt;a href=&quot;https://spring.io/guides/gs/register-twitter-app/&quot;&gt;A step-by-step guide&lt;/a&gt; is available from Spring&amp;#8217;s website that will show you how to generate Twitter API keys for an application.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;In our Spring Boot application we will map configuration properties as key values on the classpath. To do this, we will map keys in our application&amp;#8217;s &lt;code&gt;.properties&lt;/code&gt; file to values in the environment. These values will be our keys and access tokens that we need to authenticate with the Twitter API, and we&amp;#8217;ll use them as parameters to configure a new &lt;code&gt;TwitterTemplate&lt;/code&gt; bean at runtime.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;admonitionblock note&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;icon&quot;&gt;&lt;i class=&quot;fa icon-note&quot; title=&quot;Note&quot;&gt;&lt;/i&gt;&lt;/td&gt;&lt;td class=&quot;content&quot;&gt;The &lt;code&gt;TwitterTemplate&lt;/code&gt; is provided as a bean from the &lt;a href=&quot;http://projects.spring.io/spring-social/&quot; target=&quot;_blank&quot;&gt;Spring Social&lt;/a&gt; project and provides a client for authenticating and interacting with Twitter&amp;#8217;s API. &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The example snippet below shows how we can use the &lt;code&gt;@Value&lt;/code&gt; &lt;a href=&quot;https://docs.spring.io/spring-boot/docs/current/reference/html/boot-features-external-config.html&quot; target=&quot;_blank&quot;&gt;annotation to load in configurations&lt;/a&gt; defined from the application&amp;#8217;s &lt;code&gt;.properties&lt;/code&gt; file.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 7. &lt;a href=&quot;https://github.com/kbastani/spring-boot-graph-processing-example/blob/master/twitter-rank-crawler/src/main/java/org/kbastani/config/TwitterCrawlerConfig.java#L43&quot; target=&quot;_blank&quot;&gt;TwitterCrawlerConfig.java&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;prettyprint highlight&quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;@Value(&quot;${spring.social.twitter.appId}&quot;)&lt;br /&gt;private String appId;&lt;br /&gt;&lt;br /&gt;@Value(&quot;${spring.social.twitter.appSecret}&quot;)&lt;br /&gt;private String appSecret;&lt;br /&gt;&lt;br /&gt;@Value(&quot;${spring.social.twitter.accessToken}&quot;)&lt;br /&gt;private String accessToken;&lt;br /&gt;&lt;br /&gt;@Value(&quot;${spring.social.twitter.accessTokenSecret}&quot;)&lt;br /&gt;private String accessTokenSecret;&lt;br /&gt;&lt;br /&gt;@Bean&lt;br /&gt;Twitter twitter() {&lt;br /&gt;    return new TwitterTemplate(appId, appSecret, accessToken, accessTokenSecret);&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;As we can see from the code example, we will use a hierarchy of keys as a map to where we will find configuration properties in our &lt;code&gt;application.yml&lt;/code&gt; file. We&amp;#8217;ll need to add our Twitter API keys and tokens to the &lt;code&gt;application.yml&lt;/code&gt; file exactly where it will be expected in our &lt;code&gt;TwitterTemplate&lt;/code&gt; configuration class. The &lt;code&gt;application.yml&lt;/code&gt; file for the &lt;em&gt;Twitter Crawler&lt;/em&gt; service will look like the following.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 8. &lt;a href=&quot;https://github.com/kbastani/spring-boot-graph-processing-example/blob/master/twitter-rank-crawler/src/main/resources/application.yml#L22&quot; target=&quot;_blank&quot;&gt;application.yml&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;prettyprint highlight&quot;&gt;&lt;code class=&quot;language-yaml&quot; data-lang=&quot;yaml&quot;&gt;spring.profiles.active: &#39;production&#39;&lt;br /&gt;---&lt;br /&gt;server:&lt;br /&gt;  port: 8080&lt;br /&gt;spring:&lt;br /&gt;  social: &lt;i class=&quot;conum&quot; data-value=&quot;1&quot;&gt;&lt;/i&gt;&lt;b&gt;(1)&lt;/b&gt;&lt;br /&gt;    twitter:&lt;br /&gt;      accessTokenSecret: &#39;replace&#39;&lt;br /&gt;      accessToken: &#39;replace&#39;&lt;br /&gt;      appSecret: &#39;replace&#39;&lt;br /&gt;      appId: &#39;replace&#39;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;colist arabic&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td&gt;&lt;i class=&quot;conum&quot; data-value=&quot;1&quot;&gt;&lt;/i&gt;&lt;b&gt;1&lt;/b&gt;&lt;/td&gt;&lt;td&gt;The &lt;code&gt;spring.social.twitter&lt;/code&gt; configuration properties map will contain our Twitter API keys and tokens&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;admonitionblock caution&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;icon&quot;&gt;&lt;i class=&quot;fa icon-caution&quot; title=&quot;Caution&quot;&gt;&lt;/i&gt;&lt;/td&gt;&lt;td class=&quot;content&quot;&gt;The Twitter API keys and access tokens for these properties can be overridden using externalized values in the application&amp;#8217;s runtime environment, since it&amp;#8217;s not a good practice to store sensitive information like this as hardcoded values in the project&amp;#8217;s source code repository. &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/div&gt;&lt;div class=&quot;admonitionblock note&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;icon&quot;&gt;&lt;i class=&quot;fa icon-note&quot; title=&quot;Note&quot;&gt;&lt;/i&gt;&lt;/td&gt;&lt;td class=&quot;content&quot;&gt;Spring Boot provides an &lt;a href=&quot;https://docs.spring.io/spring-boot/docs/current/reference/html/boot-features-external-config.html#boot-features-external-config-yaml&quot; target=&quot;_blank&quot;&gt;option to use YAML&lt;/a&gt; as a format for an application&amp;#8217;s configuration &lt;code&gt;.properties&lt;/code&gt; file, which I happen to be partial to using. To use YAML as a format instead of the classic &lt;code&gt;.properties&lt;/code&gt; format, change the &lt;code&gt;application.properties&lt;/code&gt; file name to &lt;code&gt;application.yml&lt;/code&gt;, located in the application&amp;#8217;s &lt;code&gt;src/main/resources&lt;/code&gt; folder &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Now our Spring Boot application for the &lt;em&gt;Twitter Crawler&lt;/em&gt; service will be able to use a &lt;code&gt;TwitterTemplate&lt;/code&gt; object as a client to interact with the Twitter API. The code snippet below is a simplified example of how we will access a &lt;code&gt;TwitterTemplate&lt;/code&gt; bean using a Spring framework technique called &lt;a href=&quot;http://docs.spring.io/spring/docs/current/spring-framework-reference/htmlsingle/#beans-constructor-injection&quot;&gt;constructor-based dependency injection&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 9. &lt;a href=&quot;https://github.com/kbastani/spring-boot-graph-processing-example/blob/master/twitter-rank-crawler/src/main/java/org/kbastani/message/Receiver.java#L46&quot; target=&quot;_blank&quot;&gt;Receiver.java&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;prettyprint highlight&quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;@Component&lt;br /&gt;public class Receiver {&lt;br /&gt;&lt;br /&gt;  private Twitter twitter;&lt;br /&gt;&lt;br /&gt;  @Autowired &lt;i class=&quot;conum&quot; data-value=&quot;1&quot;&gt;&lt;/i&gt;&lt;b&gt;(1)&lt;/b&gt;&lt;br /&gt;  public Listener(Twitter twitter) {&lt;br /&gt;    this.twitter = twitter;&lt;br /&gt;  }&lt;br /&gt;&lt;br /&gt;  private void findFollowers(Long profileId) {&lt;br /&gt;    // Retrieve a profile&#39;s followers using the TwitterTemplate&lt;br /&gt;    twitter.friendOperations().getFollowerIds(profileId);&lt;br /&gt;  }&lt;br /&gt;&lt;br /&gt;...&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;colist arabic&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td&gt;&lt;i class=&quot;conum&quot; data-value=&quot;1&quot;&gt;&lt;/i&gt;&lt;b&gt;1&lt;/b&gt;&lt;/td&gt;&lt;td&gt;Causes an instance of the &lt;code&gt;TwitterTemplate&lt;/code&gt; object to be provided as a constructor&amp;#8217;s parameter&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The snippet of code above is meant to illustrate how we&amp;#8217;ll be using the &lt;code&gt;TwitterTemplate&lt;/code&gt; client throughout the application. We can see that in this class that we&amp;#8217;re getting a reference to the &lt;code&gt;TwitterTemplate&lt;/code&gt; through the constructor, which will be called by Spring when initializing the bean at runtime.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_using_amqp_to_import_profiles_from_the_twitter_api&quot;&gt;Using AMQP to import profiles from the Twitter API&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The Twitter API has &lt;a href=&quot;https://dev.twitter.com/rest/public/rate-limiting&quot; target=&quot;_blank&quot;&gt;strict rate limiting policies&lt;/a&gt; for a single access token. The &lt;em&gt;follower&lt;/em&gt; and &lt;em&gt;friend&lt;/em&gt; API resources come with a 15 minute fixed window to make 15 HTTP requests. If we were to try to import a single user per request, it would take us roughly a year to import 1 million unique users. The good news is that Twitter has added the ability to grab cursored lists of followers and friends of a user. This allows us to import up to 5000 profiles per request. If you&amp;#8217;re crawling the right users, you can import about 1 million unique users per day. That&amp;#8217;s not too shabby.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;If we were to get rate limited before we were done importing all of a user&amp;#8217;s friends and followers, we need to make sure that we finish importing the rest of the user&amp;#8217;s friends and followers when our rate limit expires. We will need a complete picture of the follower graph in order for PageRank to be an accurate predictor of a user&amp;#8217;s importance in a community. We can&amp;#8217;t lose any data during the import process or the crawler algorithm will be unreliable. We need our data to be consistent at all times or else we&amp;#8217;ll suffer skewed results.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;To ensure that data is imported reliably while maximizing utility of the rate limiting policies for resources, we&amp;#8217;ll use the &lt;a href=&quot;http://projects.spring.io/spring-amqp/&quot; target=&quot;_blank&quot;&gt;Spring AMQP&lt;/a&gt; project and bind to RabbitMQ.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;We&amp;#8217;re going to create two queues that we will use to serially import friends and followers of each discovered Twitter profile. We&amp;#8217;ll start by configuring two RabbitMQ queues as beans in our Spring Boot application. The queues we need to create will be named &lt;strong&gt;twitter.follows&lt;/strong&gt; and &lt;strong&gt;twitter.followers&lt;/strong&gt;. We can do this by initializing the bean using the &lt;code&gt;@Bean&lt;/code&gt; annotation and returning a new instance of the &lt;code&gt;Queue&lt;/code&gt; class, shown below.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 10. &lt;a href=&quot;https://github.com/kbastani/spring-boot-graph-processing-example/blob/master/twitter-rank-crawler/src/main/java/org/kbastani/config/TwitterCrawlerConfig.java#L34&quot; target=&quot;_blank&quot;&gt;TwitterCrawlerConfig.java&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;prettyprint highlight&quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;@Configuration&lt;br /&gt;public class TwitterCrawlerConfig {&lt;br /&gt;&lt;br /&gt;  @Bean&lt;br /&gt;  Queue follows() {&lt;br /&gt;      return new Queue(&quot;twitter.follows&quot;, true, false, false);&lt;br /&gt;  }&lt;br /&gt;&lt;br /&gt;  @Bean&lt;br /&gt;  Queue followers() {&lt;br /&gt;      return new Queue(&quot;twitter.followers&quot;, true, false, false);&lt;br /&gt;  }&lt;br /&gt;...&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;We&amp;#8217;ll now create our RabbitMQ listeners for the two queues. The code snippet below uses the &lt;code&gt;@RabbitListener&lt;/code&gt; annotation to indicate that the &lt;code&gt;followers(String message)&lt;/code&gt; method should process messages that arrive to the &lt;code&gt;twitter.followers&lt;/code&gt; queue on the active RabbitMQ connection.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 11. &lt;a href=&quot;https://github.com/kbastani/spring-boot-graph-processing-example/blob/master/twitter-rank-crawler/src/main/java/org/kbastani/message/Receiver.java#L59&quot; target=&quot;_blank&quot;&gt;Receiver.java&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;prettyprint highlight&quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;@RabbitListener(queues = {&quot;twitter.followers&quot;})&lt;br /&gt;public void followers(String message) throws InterruptedException, IOException {&lt;br /&gt;  User user = objectMapper.readValue(message, User.class);&lt;br /&gt;&lt;br /&gt;  if (user != null) {&lt;br /&gt;    try {&lt;br /&gt;      // Get the first cursor of followers for the user&lt;br /&gt;      CursoredList&amp;lt;Long&amp;gt; followers = twitter.friendOperations()&lt;br /&gt;          .getFollowerIds(user.getProfileId());&lt;br /&gt;&lt;br /&gt;      // Import the users to Neo4j&lt;br /&gt;      saveFollowers(user, followers);&lt;br /&gt;&lt;br /&gt;      // Now import the users that the profile is following&lt;br /&gt;      amqpTemplate.convertAndSend(&quot;twitter.follows&quot;, objectMapper.writeValueAsString(user));&lt;br /&gt;&lt;br /&gt;    } catch (RateLimitExceededException rateLimitException) {&lt;br /&gt;&lt;br /&gt;      // We exceeded the rate limit, redeliver the message to retry after 40 seconds&lt;br /&gt;      Thread.sleep(40000L);&lt;br /&gt;      throw new AmqpIllegalStateException(rateLimitException.getMessage());&lt;br /&gt;      ...&lt;br /&gt;    }&lt;br /&gt;  }&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;We&amp;#8217;ll create a similar listener to the one that is shown in the snippet above for the &lt;code&gt;twitter.follows&lt;/code&gt; queue. To see both of these methods in full, head over to the source code repository for the sample application.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;admonitionblock note&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;icon&quot;&gt;&lt;i class=&quot;fa icon-note&quot; title=&quot;Note&quot;&gt;&lt;/i&gt;&lt;/td&gt;&lt;td class=&quot;content&quot;&gt;The reason why we need separate queues for each resource is to prevent wasting API requests if a failure occurs. Since the API resources for &quot;followers&quot; and &quot;friends&quot; have separate rate limiting policies, we could end up wasting duplicate API requests on the first resource if we encountered a fault during operations on the second resource. &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_scheduling_new_pagerank_jobs&quot;&gt;Scheduling new PageRank jobs&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The last concern we need to address on our &lt;em&gt;Twitter Crawler&lt;/em&gt; service is to integrate with the graph processing platform. The graph processing platform is an attached backing service on Neo4j, which makes it easy for us to issue requests for new graph processing jobs. Neo4j exposes an endpoint to an unmanaged extension for Mazerunner on the classpath of the Neo4j database server. This unmanaged extension exposes a REST API for interacting with the graph processing platform&amp;#8217;s analysis service that embeds an instance of Apache Spark.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;It&amp;#8217;s easy enough to make an HTTP GET request to the job scheduling interface on Neo4j, but we will still need to create a trigger that will be called on a scheduled time interval from the &lt;em&gt;Twitter Crawler&lt;/em&gt; service. To do this, we can use the &lt;code&gt;@Scheduled&lt;/code&gt; &lt;a href=&quot;http://docs.spring.io/spring/docs/current/spring-framework-reference/html/scheduling.html#scheduling-annotation-support-scheduled&quot; target=&quot;_blank&quot;&gt;annotation on a method&lt;/a&gt; of an object in our Spring Boot application. We&amp;#8217;ll then provide a fixed value for the rate parameter of the annotation that is measured in milliseconds. I&amp;#8217;ve decided that the PageRank job should be started about every 5 minutes, so we&amp;#8217;ll initialize the &lt;code&gt;fixedRate&lt;/code&gt; value to &lt;code&gt;300000&lt;/code&gt; milliseconds.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The snippet of code below is an example of how we will register a method using Spring&amp;#8217;s &lt;code&gt;@Scheduled&lt;/code&gt; annotation. The method issues an HTTP GET request to the job scheduling interface&amp;#8217;s REST API, which resides on Neo4j.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 12. &lt;a href=&quot;https://github.com/kbastani/spring-boot-graph-processing-example/blob/master/twitter-rank-crawler/src/main/java/org/kbastani/scheduling/AnalyticsScheduler.java#L47&quot; target=&quot;_blank&quot;&gt;AnalyticsScheduler.java&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;prettyprint highlight&quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;@Scheduled(fixedRate = 300000) &lt;i class=&quot;conum&quot; data-value=&quot;1&quot;&gt;&lt;/i&gt;&lt;b&gt;(1)&lt;/b&gt;&lt;br /&gt;public void schedulePageRank() {&lt;br /&gt;&lt;br /&gt;  // Schedule a PageRank job for the Twitter follower graph in Neo4j&lt;br /&gt;  String relativePath = &quot;%s/service/mazerunner/analysis/pagerank/FOLLOWS&quot;&lt;br /&gt;  String analysisEndpoint = String.format(relativePath, neo4jServer.url());&lt;br /&gt;&lt;br /&gt;  // Make a HTTP GET request to the analysis endpoint&lt;br /&gt;  new RestTemplate().getForEntity(analysisEndpoint, null);&lt;br /&gt;&lt;br /&gt;  logger.info(&quot;PageRank scheduled on follows graph &quot; + dateFormat.format(new Date()));&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;colist arabic&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td&gt;&lt;i class=&quot;conum&quot; data-value=&quot;1&quot;&gt;&lt;/i&gt;&lt;b&gt;1&lt;/b&gt;&lt;/td&gt;&lt;td&gt;The &lt;code&gt;@Scheduled&lt;/code&gt; annotation registers this method to be called every 5 minutes&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Now that we know how to schedule operations using the &lt;code&gt;@Scheduled&lt;/code&gt; annotation, we can use the same pattern above to create a reoccurring job to discover new users to import.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 13. &lt;a href=&quot;https://github.com/kbastani/spring-boot-graph-processing-example/blob/master/twitter-rank-crawler/src/main/java/org/kbastani/scheduling/AnalyticsScheduler.java&quot; target=&quot;_blank&quot;&gt;AnalyticsScheduler.java&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;prettyprint highlight&quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;...&lt;br /&gt;/**&lt;br /&gt; * Every minute, an attempt to discover a new user to be imported is made. This only succeeds if&lt;br /&gt; * the API is not restricted by a temporary rate limit. This makes sure that only relevant users are&lt;br /&gt; * discovered over time, to keep the API crawling relevant.&lt;br /&gt; */&lt;br /&gt;@Scheduled(fixedRate = 60000)&lt;br /&gt;public void scheduleDiscoverUser() {&lt;br /&gt;  // Only discover users if the rate limit has not been exceeded&lt;br /&gt;  if (!rateLimited) {&lt;br /&gt;    // Uses PageRank to find the next most important user to import&lt;br /&gt;    User user = userRepository.findRankedUserToCrawl();&lt;br /&gt;&lt;br /&gt;    // If the user is null, the first PageRank hasn&#39;t been applied&lt;br /&gt;    if (user == null) {&lt;br /&gt;      // Uses a mutual follower metric&lt;br /&gt;      user = userRepository.findNextUserToCrawl();&lt;br /&gt;    }&lt;br /&gt;&lt;br /&gt;    // If a user has been found, request the user to be imported&lt;br /&gt;    if (user != null) {&lt;br /&gt;      twitterService.discoverUserByProfileId(user.getProfileId());&lt;br /&gt;    }&lt;br /&gt;  } else {&lt;br /&gt;    rateLimited = false;&lt;br /&gt;  }&lt;br /&gt;&lt;br /&gt;  // Update user rankings for the web dashboard&lt;br /&gt;  logger.info(&quot;Updating last ranks...&quot;);&lt;br /&gt;  userRepository.setLastPageRank();&lt;br /&gt;  logger.info(&quot;Updating current rank...&quot;);&lt;br /&gt;  userRepository.updateUserCurrentRank();&lt;br /&gt;  logger.info(&quot;Current ranks updated!&quot;);&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_discovering_new_users&quot;&gt;Discovering new users&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Now we&amp;#8217;ll need to implement a service contract that provides methods for crawling and discovering new Twitter profiles to import to Neo4j. To do this we&amp;#8217;ll provide a REST API endpoint that takes in a Twitter user&amp;#8217;s screen name as input and imports their profile and follower data to Neo4j. We&amp;#8217;ll also need to implement a method for discovering a user using the Twitter &lt;code&gt;profileId&lt;/code&gt; as input. When we import a user&amp;#8217;s followers, we are only importing each follower&amp;#8217;s &lt;code&gt;profileId&lt;/code&gt;. This is enough for running PageRank on the resulting graph, but to display the user&amp;#8217;s information on the web dashboard, we&amp;#8217;ll need the rest of the profile information.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The &lt;code&gt;TwitterServiceImpl&lt;/code&gt; class is shown below in full, and implements methods for &lt;code&gt;discoverUserByScreenName&lt;/code&gt; and &lt;code&gt;discoverUserByProfileId&lt;/code&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 14. &lt;a href=&quot;https://github.com/kbastani/spring-boot-graph-processing-example/blob/master/twitter-rank-crawler/src/main/java/org/kbastani/twitter/TwitterServiceImpl.java&quot; target=&quot;_blank&quot;&gt;TwitterServiceImpl.java&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;prettyprint highlight&quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;...&lt;br /&gt;/**&lt;br /&gt; * This class implements the service contract for {@link TwitterService} and&lt;br /&gt; * is responsible for discovering users by screen name or profile ID.&lt;br /&gt; *&lt;br /&gt; * @author kbastani&lt;br /&gt; */&lt;br /&gt;@Service&lt;br /&gt;public class TwitterServiceImpl implements TwitterService {&lt;br /&gt;&lt;br /&gt;  private static final SimpleDateFormat dateFormat = new SimpleDateFormat(&quot;HH:mm:ss&quot;);&lt;br /&gt;  private final Log log = LogFactory.getLog(TwitterService.class);&lt;br /&gt;  private static final String QUEUE_NAME = &quot;twitter.followers&quot;;&lt;br /&gt;  private final Twitter twitter;&lt;br /&gt;  private final UserRepository userRepository;&lt;br /&gt;  private final RabbitTemplate rabbitTemplate;&lt;br /&gt;  private final ObjectMapper objectMapper;&lt;br /&gt;&lt;br /&gt;  // These two fields are constants that target users below follows/following thresholds&lt;br /&gt;  private static final Integer MAX_FOLLOWS = 50000;&lt;br /&gt;  private static final Integer MAX_FOLLOWERS = 50000;&lt;br /&gt;&lt;br /&gt;  @Autowired&lt;br /&gt;  public TwitterServiceImpl(Twitter twitter, UserRepository userRepository,&lt;br /&gt;    RabbitTemplate rabbitTemplate, ObjectMapper objectMapper) {&lt;br /&gt;    this.twitter = twitter;&lt;br /&gt;    this.userRepository = userRepository;&lt;br /&gt;    this.rabbitTemplate = rabbitTemplate;&lt;br /&gt;    this.objectMapper = objectMapper;&lt;br /&gt;  }&lt;br /&gt;&lt;br /&gt;  /**&lt;br /&gt;   * Discover a user on Twitter using only their screen name&lt;br /&gt;   *&lt;br /&gt;   * @param screenName is the screen name of the user on Twitter&lt;br /&gt;   * @return a user that has been retrieved from the Twitter API and saved to Neo4j&lt;br /&gt;   */&lt;br /&gt;  public User discoverUserByScreenName(String screenName) {&lt;br /&gt;    User user;&lt;br /&gt;&lt;br /&gt;    user = Optional.of(twitter.userOperations().getUserProfile(screenName))&lt;br /&gt;        .map(User::new)&lt;br /&gt;        .get();&lt;br /&gt;&lt;br /&gt;    // Set the user&#39;s default values&lt;br /&gt;    user.setPagerank(0f);&lt;br /&gt;    user.setImported(true);&lt;br /&gt;&lt;br /&gt;    user = getUser(user);&lt;br /&gt;&lt;br /&gt;    return user;&lt;br /&gt;  }&lt;br /&gt;&lt;br /&gt;  /**&lt;br /&gt;   * Discover a user on Twitter using their profile ID&lt;br /&gt;   *&lt;br /&gt;   * @param profileId is the profile ID of the user on the Twitter API&lt;br /&gt;   * @return a user that has been retrieved from the Twitter API and saved to Neo4j&lt;br /&gt;   */&lt;br /&gt;  public User discoverUserByProfileId(Long profileId) {&lt;br /&gt;    User user;&lt;br /&gt;&lt;br /&gt;    user = Optional.of(twitter.userOperations().getUserProfile(profileId))&lt;br /&gt;        .map(User::new)&lt;br /&gt;        .get();&lt;br /&gt;&lt;br /&gt;    user = getUser(user);&lt;br /&gt;&lt;br /&gt;    log.info(String.format(&quot;Discover user: %s&quot;, user.getScreenName()));&lt;br /&gt;&lt;br /&gt;    return user;&lt;br /&gt;  }&lt;br /&gt;&lt;br /&gt;  /**&lt;br /&gt;   * Submit a job to crawl this user only if their follows/follower counts are within limits&lt;br /&gt;   *&lt;br /&gt;   * @param user is the {@link User} that is to potentially be requested for crawling&lt;br /&gt;   * @return the saved {@link User} with full profile information now updated on the Neo4j node&lt;br /&gt;   */&lt;br /&gt;  private User getUser(User user) {&lt;br /&gt;    Long userId = userRepository.getUserIdByProfileId(user.getProfileId());&lt;br /&gt;&lt;br /&gt;    if (userId != null) {&lt;br /&gt;      user.setId(userId);&lt;br /&gt;    }&lt;br /&gt;&lt;br /&gt;    user = userRepository.save(user, 0);&lt;br /&gt;&lt;br /&gt;    try {&lt;br /&gt;      // Only crawl users that have manageable follows/follower counts&lt;br /&gt;      if (user.getFollowerCount() &amp;lt; MAX_FOLLOWERS &amp;amp;&amp;amp; user.getFollowsCount() &amp;lt; MAX_FOLLOWS) {&lt;br /&gt;        log.info(&quot;Discover user scheduled on follows graph &quot; + dateFormat.format(new Date()));&lt;br /&gt;        user.setDiscoveredTime(new Date().getTime());&lt;br /&gt;&lt;br /&gt;        // Update discovery time&lt;br /&gt;        userRepository.save(user, 0);&lt;br /&gt;&lt;br /&gt;        // Update the discovery chain&lt;br /&gt;        userRepository.updateDiscoveryChain();&lt;br /&gt;&lt;br /&gt;        // Send a new import message to the &#39;twitter.followers&#39; queue for the user&lt;br /&gt;        rabbitTemplate.convertAndSend(QUEUE_NAME, objectMapper.writeValueAsString(user));&lt;br /&gt;      } else {&lt;br /&gt;        // Retry on a user with a valid number of follows/followers&lt;br /&gt;        User nextUserToCrawl = userRepository.findNextUserToCrawl();&lt;br /&gt;&lt;br /&gt;        if (nextUserToCrawl != null) {&lt;br /&gt;          this.discoverUserByProfileId(nextUserToCrawl.getProfileId());&lt;br /&gt;        }&lt;br /&gt;      }&lt;br /&gt;    } catch (JsonProcessingException e) {&lt;br /&gt;      log.error(e);&lt;br /&gt;    }&lt;br /&gt;    return user;&lt;br /&gt;  }&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The last thing we&amp;#8217;ll need to do is to expose the &lt;code&gt;discoverUserByScreenName&lt;/code&gt; from the &lt;code&gt;TwitterService&lt;/code&gt; as a REST API method to allow the web dashboard to add seed profiles. Below, I&amp;#8217;ve created a &lt;code&gt;@RestController&lt;/code&gt; annotated class with the name &lt;code&gt;ApiController&lt;/code&gt;. This controller will be registered at runtime and allow consumers to issue &lt;code&gt;GET&lt;/code&gt; requests to the URL template &lt;code&gt;/v1/user/{screenName}&lt;/code&gt;, where &lt;code&gt;screenName&lt;/code&gt; is the Twitter profile&amp;#8217;s unique handle.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 15. &lt;a href=&quot;https://github.com/kbastani/spring-boot-graph-processing-example/blob/master/twitter-rank-crawler/src/main/java/org/kbastani/web/ApiController.java&quot; target=&quot;_blank&quot;&gt;ApiController.java&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;prettyprint highlight&quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;...&lt;br /&gt;/**&lt;br /&gt; * Provides a single REST endpoint for seeding users to crawl on Twitter. Automated&lt;br /&gt; * crawling of Twitter users requires three seed users as input.&lt;br /&gt; *&lt;br /&gt; * @author kbastani&lt;br /&gt; */&lt;br /&gt;@RestController&lt;br /&gt;@RequestMapping(&quot;v1&quot;)&lt;br /&gt;public class ApiController {&lt;br /&gt;&lt;br /&gt;  private final TwitterService twitterService;&lt;br /&gt;&lt;br /&gt;  @Autowired&lt;br /&gt;  public ApiController(TwitterService twitterService) {&lt;br /&gt;    this.twitterService = twitterService;&lt;br /&gt;  }&lt;br /&gt;&lt;br /&gt;  @RequestMapping(path = &quot;user/{screenName}&quot;, method = RequestMethod.GET)&lt;br /&gt;  public ResponseEntity&amp;lt;User&amp;gt; discoverProfileByScreenName(@PathVariable(&quot;screenName&quot;) String screenName) {&lt;br /&gt;    return Optional.of(ResponseEntity.ok(twitterService.discoverUserByScreenName(screenName)))&lt;br /&gt;        .or(new ResponseEntity&amp;lt;&amp;gt;(HttpStatus.INTERNAL_SERVER_ERROR));&lt;br /&gt;  }&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_registering_as_a_discovery_client_with_eureka&quot;&gt;Registering as a discovery client with Eureka&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Now that we&amp;#8217;re done with the core business logic of the &lt;em&gt;Twitter Crawler&lt;/em&gt; service, we need to think about making it operational. I&amp;#8217;ve introduced &lt;a href=&quot;http://www.kennybastani.com/search/label/spring%20cloud&quot; target=&quot;_blank&quot;&gt;Spring Cloud in previous articles&lt;/a&gt;, and we&amp;#8217;ll use it here in the form of a &lt;a href=&quot;http://cloud.spring.io/spring-cloud-netflix/spring-cloud-netflix.html#_registering_with_eureka&quot; target=&quot;_blank&quot;&gt;Eureka discovery service&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The discovery service is a critical part of a microservice architecture. Eureka acts as a registry of service information that can be downloaded by members in a cluster and used for client-side load balancing, or &lt;a href=&quot;http://projects.spring.io/spring-cloud/spring-cloud.html#_environment_changes&quot; target=&quot;_blank&quot;&gt;pushing live configuration changes&lt;/a&gt; to all instances of a service that are running in a cluster.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 16. &lt;a href=&quot;https://github.com/kbastani/spring-boot-graph-processing-example/blob/master/twitter-rank-crawler/src/main/java/org/kbastani/TwitterAnalyticsApplication.java&quot; target=&quot;_blank&quot;&gt;TwitterCrawlerApplication.java&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;prettyprint highlight&quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;@SpringCloudApplication &lt;i class=&quot;conum&quot; data-value=&quot;1&quot;&gt;&lt;/i&gt;&lt;b&gt;(1)&lt;/b&gt;&lt;br /&gt;@EnableZuulProxy &lt;i class=&quot;conum&quot; data-value=&quot;2&quot;&gt;&lt;/i&gt;&lt;b&gt;(2)&lt;/b&gt;&lt;br /&gt;@EnableScheduling &lt;i class=&quot;conum&quot; data-value=&quot;3&quot;&gt;&lt;/i&gt;&lt;b&gt;(3)&lt;/b&gt;&lt;br /&gt;public class TwitterCrawlerApplication extends SpringBootServletInitializer {&lt;br /&gt;    public static void main(String[] args) {&lt;br /&gt;        new SpringApplicationBuilder(TwitterCrawlerApplication.class).web(true).run(args);&lt;br /&gt;    }&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;colist arabic&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td&gt;&lt;i class=&quot;conum&quot; data-value=&quot;1&quot;&gt;&lt;/i&gt;&lt;b&gt;1&lt;/b&gt;&lt;/td&gt;&lt;td&gt;Adds &lt;code&gt;@SpringBootApplication&lt;/code&gt;, &lt;code&gt;@DiscoveryClient&lt;/code&gt;, and &lt;code&gt;@CircuitBreaker&lt;/code&gt; annotations&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;i class=&quot;conum&quot; data-value=&quot;2&quot;&gt;&lt;/i&gt;&lt;b&gt;2&lt;/b&gt;&lt;/td&gt;&lt;td&gt;Enables reverse proxying capabilities to route HTTP requests from other services&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;i class=&quot;conum&quot; data-value=&quot;3&quot;&gt;&lt;/i&gt;&lt;b&gt;3&lt;/b&gt;&lt;/td&gt;&lt;td&gt;Enables scheduling, making sure &lt;code&gt;@Scheduler&lt;/code&gt; annotations are registered&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;h1 id=&quot;_ranking_dashboard&quot; class=&quot;sect0&quot;&gt;Ranking Dashboard&lt;/h1&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;We&amp;#8217;ve finished creating the backend components of the microservice architecture and can now write a simple client-side web application to interface with the &lt;em&gt;Twitter Crawler&lt;/em&gt; service&amp;#8217;s REST API. Since we are using &lt;em&gt;Spring Cloud&lt;/em&gt;, we are able to take advantage of the &lt;em&gt;Eureka&lt;/em&gt; discovery service and the &lt;code&gt;@EnableZuulProxy&lt;/code&gt; annotation to automatically inject routes from the &lt;em&gt;Twitter Crawler&lt;/em&gt; service into our new &lt;em&gt;Ranking Dashboard&lt;/em&gt; service. What this means is that the new &lt;em&gt;Ranking Dashboard&lt;/em&gt; service will be able to expose the full REST API of the &lt;em&gt;Twitter Crawler&lt;/em&gt; service on its own host, without writing a single line of code.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_configuring_the_ranking_dashboard_for_reverse_proxy&quot;&gt;Configuring the Ranking Dashboard for reverse proxy&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The Spring Boot application we&amp;#8217;ll create is as simple as it gets. The only application code we&amp;#8217;ll create is the Spring Boot application class, shown below.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 17. &lt;a href=&quot;https://github.com/kbastani/spring-boot-graph-processing-example/blob/master/twitter-rank-web/src/main/java/org/kbastani/RankingDashboardApplication.java&quot; target=&quot;_blank&quot;&gt;RankingDashboardApplication.java&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;prettyprint highlight&quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;@SpringCloudApplication&lt;br /&gt;@EnableZuulProxy&lt;br /&gt;public class RankingDashboardApplication {&lt;br /&gt;  public static void main(String[] args) {&lt;br /&gt;    SpringApplication.run(RankingDashboardApplication.class, args);&lt;br /&gt;  }&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Here we&amp;#8217;ve provided the annotations &lt;code&gt;@SpringCloudApplication&lt;/code&gt;, which enables the basic Spring Cloud features for connecting to a discovery service. We&amp;#8217;ve also added the annotation &lt;code&gt;@EnableZuulProxy&lt;/code&gt;, which will enable an embedded Zuul proxy in this service. To get this to work, we do need to worry about some configuration properties in our &lt;code&gt;application.yml&lt;/code&gt; file.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The properties below are configured for the &lt;em&gt;production&lt;/em&gt; Spring profile and provides the necessary settings to connect and register with the discovery service. Since the &lt;em&gt;Twitter Crawler&lt;/em&gt; service we created earlier uses the same discovery service connection settings, the &lt;em&gt;Ranking Dashboard&lt;/em&gt; will automatically create a proxy to the &lt;em&gt;Twitter Crawler&amp;#8217;s&lt;/em&gt; REST API.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 18. &lt;a href=&quot;https://github.com/kbastani/spring-boot-graph-processing-example/blob/master/twitter-rank-web/src/main/resources/application.yml&quot; target=&quot;_blank&quot;&gt;application.yml&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;prettyprint highlight&quot;&gt;&lt;code class=&quot;language-yaml&quot; data-lang=&quot;yaml&quot;&gt;spring.profiles.active: &#39;production&#39;&lt;br /&gt;---&lt;br /&gt;server:&lt;br /&gt;  port: 8081&lt;br /&gt;  servletPath: /&lt;br /&gt;spring:&lt;br /&gt;  profiles: &#39;production&#39;&lt;br /&gt;eureka:&lt;br /&gt;  client:&lt;br /&gt;    serviceUrl:&lt;br /&gt;      defaultZone: http://discovery:8761/eureka/&lt;br /&gt;  instance:&lt;br /&gt;    preferIpAddress: true&lt;br /&gt;    leaseRenewalIntervalInSeconds: 10&lt;br /&gt;    hostname: ${spring.cloud.client.ipAddress:HOSTNAME}&lt;br /&gt;    statusPageUrlPath: /info&lt;br /&gt;    healthCheckUrlPath: /health&lt;br /&gt;hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds: 60000&lt;br /&gt;ribbon:&lt;br /&gt;  ConnectTimeout: 3000&lt;br /&gt;  ReadTimeout: 60000&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Now when the &lt;em&gt;Ranking Dashboard&lt;/em&gt; service is started, it will contact the &lt;em&gt;Eureka&lt;/em&gt; discovery service at &lt;code&gt;&lt;a href=&quot;http://discovery:8761/eureka/&quot; class=&quot;bare&quot;&gt;http://discovery:8761/eureka/&lt;/a&gt;&lt;/code&gt; and embed the request mappings that are exposed by the &lt;em&gt;Twitter Crawler&lt;/em&gt; service. The ID that the &lt;em&gt;Twitter Crawler&lt;/em&gt; service will use when registering with &lt;em&gt;Eureka&lt;/em&gt; will be &lt;code&gt;twitter-rank&lt;/code&gt;. This ID will be used as the request path to access the routes of the &lt;em&gt;Twitter Crawler&lt;/em&gt; service from the &lt;em&gt;Ranking Dashboard&lt;/em&gt; service. All requests to &lt;code&gt;/twitter-rank/**&lt;/code&gt; on the &lt;em&gt;Ranking Dashboard&lt;/em&gt; service will be forwarded to the &lt;em&gt;Twitter Crawler&lt;/em&gt; service.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The next step will be to add static web content to the &lt;em&gt;Ranking Dashboard&lt;/em&gt; service that connects to the REST API of the &lt;em&gt;Twitter Crawler&lt;/em&gt; service through our newly embedded Zuul proxy.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_adding_static_web_content&quot;&gt;Adding static web content&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;I&amp;#8217;ve created a simple client-side web application that uses jQuery to make AJAX requests to the &lt;em&gt;Twitter Crawler&lt;/em&gt; REST API. Spring Boot makes it easy to map static content by placing it in the resource directory under &lt;code&gt;resources/static&lt;/code&gt;. The example below shows a directory tree of the &lt;em&gt;Ranking Dashboard&lt;/em&gt; service and the static content I&amp;#8217;ve placed in the resource directory.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;prettyprint highlight&quot;&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;├── docker&lt;br /&gt;│   └── Dockerfile&lt;br /&gt;├── java&lt;br /&gt;│   └── org&lt;br /&gt;│       └── kbastani&lt;br /&gt;└── resources&lt;br /&gt;    ├── application.yml&lt;br /&gt;    ├── bootstrap.yml&lt;br /&gt;    └── static&lt;br /&gt;        ├── assets&lt;br /&gt;        ├── css&lt;br /&gt;        ├── dist&lt;br /&gt;        ├── fonts&lt;br /&gt;        ├── index.html&lt;br /&gt;        └── js&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Now when I run the Spring Boot application, the &lt;code&gt;src/main/resources/static/index.html&lt;/code&gt; file will be mapped to the service&amp;#8217;s root at &lt;code&gt;/&lt;/code&gt;, or accessed directly at &lt;code&gt;/index.html&lt;/code&gt;.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_consuming_the_twitter_crawler_s_rest_api&quot;&gt;Consuming the Twitter Crawler&amp;#8217;s REST API&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The dashboard is a single page web application which consumes two REST API methods on the &lt;em&gt;Twitter Crawler&lt;/em&gt; service. Let&amp;#8217;s first review how the dashboard will be used.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The first time the dashboard is loaded, there won&amp;#8217;t be any data to display from the &lt;em&gt;Twitter Crawler&lt;/em&gt; service.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;div class=&quot;imageblock&quot; style=&quot;display: block;&quot;&gt;&lt;div class=&quot;content&quot; style=&quot;text-align: center;&quot;&gt;&lt;img width=&quot;100%&quot; alt=&quot;Twitter discovery dashboard&quot; src=&quot;http://i.imgur.com/Zli5V4u.png&quot; style=&quot;max-height: 25em; margin: auto !important;&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Before the &lt;em&gt;Twitter Crawler&lt;/em&gt; service will begin to automatically discover new profiles, the user must provide a minimum of three screen names of Twitter users as seeds. The goal is to add three seed profiles of users who are members of a community on Twitter. It&amp;#8217;s important to make sure that these users follow each other, which will make it likely that there are other mutual profile connections between these users.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;div class=&quot;imageblock&quot; style=&quot;display: block;&quot;&gt;&lt;div class=&quot;content&quot; style=&quot;text-align: center;&quot;&gt;&lt;img width=&quot;100%&quot; alt=&quot;Add new Twitter profile to crawl&quot; src=&quot;http://i.imgur.com/XhWkJNd.png&quot; style=&quot;max-height: 25em; margin: auto !important;&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The seed profiles I&amp;#8217;ve chosen for this demonstration are:&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;ulist&quot;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://www.twitter.com/kennybastani&quot;&gt;@kennybastani&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://www.twitter.com/starbuxman&quot;&gt;@starbuxman&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://www.twitter.com/bridgetkromhout&quot;&gt;@bridgetkromhout&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;When adding new seed profiles through the UI, an AJAX call will be made as an HTTP GET request to the relative path:&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;code&gt;/twitter-rank/v1/user/{screenName}&lt;/code&gt;&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;After adding each of these profiles manually through the UI, we&amp;#8217;ll end up with the following view.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;div class=&quot;imageblock&quot; style=&quot;display: block;&quot;&gt;&lt;div class=&quot;content&quot; style=&quot;text-align: center;&quot;&gt;&lt;img width=&quot;100%&quot; alt=&quot;PageRank on Twitter profile followers&quot; src=&quot;http://i.imgur.com/dePUme2.png&quot; style=&quot;max-height: 35em; margin: auto !important;&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;To get the results that are displayed in the ranking table, the UI will make an AJAX call as an HTTP GET request to the relative path:&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;code&gt;/twitter-rank/users/search/findRankedUsers?skip=0&amp;amp;limit=100&lt;/code&gt;&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Now that I&amp;#8217;ve added the three seed profiles, each of these user&amp;#8217;s connections will be imported to Neo4j on the &lt;em&gt;Twitter Crawler&lt;/em&gt; service. After about 5 minutes, the PageRank job will have been scheduled and completed its analysis of the initial users. After a PageRank value has been assigned to the initial users, you will begin to see other users that the crawling algorithm on the &lt;em&gt;Twitter Crawler&lt;/em&gt; service has automatically discovered.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The following screenshot shows users that were discovered automatically by the &lt;em&gt;Twitter Crawler&lt;/em&gt; service.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;div class=&quot;imageblock&quot; style=&quot;display: block;&quot;&gt;&lt;div class=&quot;content&quot; style=&quot;text-align: center;&quot;&gt;&lt;img width=&quot;100%&quot; alt=&quot;Automated discovery of new Twitter profiles&quot; src=&quot;http://i.imgur.com/5TjfNj2.png&quot; style=&quot;max-height: 35em; margin: auto !important;&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;h1 id=&quot;_docker_demo&quot; class=&quot;sect0&quot;&gt;Docker Demo&lt;/h1&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The example project uses Docker to build a container image of each of our microservices as a part of the Maven build process.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_getting_started&quot;&gt;Getting Started&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;To get started, visit the GitHub repository for this example project.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/kbastani/spring-boot-graph-processing-example&quot; target=&quot;_blank&quot;&gt;https://github.com/kbastani/spring-boot-graph-processing-example&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Clone or fork the project and download the repository to your machine. After downloading, you will need to use both Maven and Docker to compile and build the images locally.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_download_docker&quot;&gt;Download Docker&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;First, download Docker if you haven’t already. Follow the &lt;a href=&quot;https://www.docker.com/docker-toolbox&quot; target=&quot;_blank&quot;&gt;instructions found here&lt;/a&gt;, to get Docker toolbox up and running on your development machine.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;After you&amp;#8217;ve installed Docker toolbox, run the following command to initialize a new virtualbox VM for this sample application.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;prettyprint highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;$ docker-machine create twitter-demo --driver virtualbox --virtualbox-memory &quot;11000&quot; --virtualbox-disk-size &quot;100000&quot;&lt;br /&gt;$ eval &quot;$(docker-machine env twitter-demo)&quot;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_requirements&quot;&gt;Requirements&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The requirements for running this demo on your machine are found below.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;ulist&quot;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Maven 3&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Java 8&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Docker&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Docker Compose&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_building_the_project&quot;&gt;Building the project&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;To build the project, from the terminal, run the following command at the root of the project.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;prettyprint highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;$ mvn clean install&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The project will then download all of the needed dependencies and compile each of the project artifacts. Each service will be built, and then a Maven Docker plugin will automatically build each of the images into your local Docker registry. Docker must be running and available from the command line where you run the &lt;code&gt;mvn clean install&lt;/code&gt; command for the build to succeed.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_start_the_cluster_with_docker_compose&quot;&gt;Start the Cluster with Docker Compose&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Now that each of the images has been built successfully, we can use Docker Compose to spin up our cluster. I&amp;#8217;ve put together a Docker Compose file that will allow you to run the full sample application without needing to run the build. Before being able to run the application, you must provide your Twitter API credentials.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;title&quot;&gt;Example 19. &lt;a href=&quot;https://github.com/kbastani/spring-boot-graph-processing-example/blob/master/docker-compose.yml&quot; target=&quot;_blank&quot;&gt;docker-compose.yml&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;prettyprint highlight&quot;&gt;&lt;code class=&quot;language-yaml&quot; data-lang=&quot;yaml&quot;&gt;---&lt;br /&gt;twitter-rank-crawler:&lt;br /&gt;  image: kbastani/twitter-rank-crawler:latest&lt;br /&gt;  ports:&lt;br /&gt;   - &#39;8080:8080&#39;&lt;br /&gt;  links:&lt;br /&gt;   - config&lt;br /&gt;   - discovery&lt;br /&gt;   - rabbit&lt;br /&gt;   - graphdb&lt;br /&gt;  environment:&lt;br /&gt;    SPRING_SOCIAL_TWITTER_ACCESSTOKENSECRET: &#39;REPLACE&#39;&lt;br /&gt;    SPRING_SOCIAL_TWITTER_ACCESSTOKEN: &#39;REPLACE&#39;&lt;br /&gt;    SPRING_SOCIAL_TWITTER_APPSECRET: &#39;REPLACE&#39;&lt;br /&gt;    SPRING_SOCIAL_TWITTER_APPID: &#39;REPLACE&#39;&lt;br /&gt;    SPRING_PROFILES_ACTIVE: &#39;production&#39;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;admonitionblock caution&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;icon&quot;&gt;&lt;i class=&quot;fa icon-caution&quot; title=&quot;Caution&quot;&gt;&lt;/i&gt;&lt;/td&gt;&lt;td class=&quot;content&quot;&gt;Make sure that you replace the environment values in the Docker Compose file with your own Twitter API keys and access tokens. Also, I highly recommend that you run this sample on a machine with at least 16GB of system memory. &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Once you have modified the &lt;code&gt;docker-compose.yml&lt;/code&gt; file in the project root, navigate to the &lt;code&gt;spring-boot-graph-processing-example/&lt;/code&gt; directory in your console.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;To startup the cluster in detached mode, run the following command:&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;prettyprint highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;$ docker-compose up -d&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;If everything is configured correctly, each of the container images we built earlier will be launched within their own VM container on Docker and networked for automatic service discovery. You will see a flurry of log output from each of the services as they begin their startup sequence. This might take a few minutes to complete, depending on the performance of the machine you’re running this demo on.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;To see the log output from the cluster, you can run the following command.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;prettyprint highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;$ docker-compose logs&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Once the startup sequence is completed, you can navigate to the Eureka host and see which services have registered with the discovery service.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Copy and paste the following command into the terminal where Docker can be accessed using the &lt;code&gt;$DOCKER_HOST&lt;/code&gt; environment variable.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;prettyprint highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;$ open $(echo \&quot;$(echo $DOCKER_HOST)\&quot;|&lt;br /&gt;            \sed &#39;s/tcp:\/\//http:\/\//g&#39;|&lt;br /&gt;            \sed &#39;s/[0-9]\{4,\}/8761/g&#39;|&lt;br /&gt;            \sed &#39;s/\&quot;//g&#39;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;When the user interface successfully loads for Eureka, you&amp;#8217;ll see the list of services that have registered as a Eureka client instance.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;exampleblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;div class=&quot;imageblock&quot; style=&quot;display: block;&quot;&gt;&lt;div class=&quot;content&quot; style=&quot;text-align: center;&quot;&gt;&lt;img width=&quot;100%&quot; alt=&quot;Eureka discovery service UI&quot; src=&quot;http://i.imgur.com/AaEz9hI.png&quot; style=&quot;max-height: 35em; margin: auto !important;&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;h1 id=&quot;_conclusion&quot; class=&quot;sect0&quot;&gt;Conclusion&lt;/h1&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;In this article we built a ranking engine and crawler for discovering influential Twitter profiles. As a part of this article we covered the following Spring concepts:&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;ulist&quot;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Spring Data Neo4j&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Spring Social Twitter&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Spring Boot: Schedulers&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Spring Boot: AMQP&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Spring Cloud: Eureka client registration&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Spring Cloud: Zuul Reverse Proxy&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;We covered a lot of ground in this one! This sample project is near and dear to my heart. I hope that this article showed you how incredibly simple Spring Boot makes developing these kinds of architectures. While there are some missing pieces, such as securing REST API access, and mapping device volumes to the containers, these kinds of important topics will be covered in future articles.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Please feel free to leave your questions and comments below.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;If you found this article useful, please share it on Twitter&amp;#8201;&amp;#8212;&amp;#8201;preferably with the influencers that you discover using the sample application!&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><link>https://www.kennybastani.com/2016/01/spring-boot-graph-processing-microservices.html</link><author>noreply@blogger.com (Kenny Bastani)</author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://2.bp.blogspot.com/-KlU_6MvFD5Y/VolMB55ZkVI/AAAAAAAABU8/3eu4YMbpcj8/s72-c/twitter-analytics-microservice-diagram.png" height="72" width="72"/><thr:total>0</thr:total></item><item><guid isPermaLink="false">tag:blogger.com,1999:blog-6300367579216018061.post-6744534622534479234</guid><pubDate>Tue, 25 Aug 2015 14:33:00 +0000</pubDate><atom:updated>2015-08-29T02:11:47.091-07:00</atom:updated><category domain="http://www.blogger.com/atom/ns#">cloud native java</category><category domain="http://www.blogger.com/atom/ns#">docker</category><category domain="http://www.blogger.com/atom/ns#">docker compose</category><category domain="http://www.blogger.com/atom/ns#">microservices</category><category domain="http://www.blogger.com/atom/ns#">mysql</category><category domain="http://www.blogger.com/atom/ns#">neo4j</category><category domain="http://www.blogger.com/atom/ns#">polyglot persistence</category><category domain="http://www.blogger.com/atom/ns#">spring boot</category><category domain="http://www.blogger.com/atom/ns#">spring cloud</category><category domain="http://www.blogger.com/atom/ns#">spring data</category><title>Building Microservices with Polyglot Persistence Using Spring Cloud and Docker</title><description>&lt;link rel=&quot;stylesheet&quot; href=&quot;https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400&quot;&gt;&lt;style&gt;.sect1{padding-bottom:0!important} .sect1+.sect1{border:0!important} .admonitionblock td.content&gt;.title,.audioblock&gt;.title,.exampleblock&gt;.title,.imageblock&gt;.title,.listingblock&gt;.title,.literalblock&gt;.title,.stemblock&gt;.title,.openblock&gt;.title,.paragraph&gt;.title,.quoteblock&gt;.title,table.tableblock&gt;.title,.verseblock&gt;.title,.videoblock&gt;.title,.dlist&gt;.title,.olist&gt;.title,.ulist&gt;.title,.qlist&gt;.title,.hdlist&gt;.title{text-rendering:optimizeLegibility;text-align:left;font-size:1.25rem;font-style:italic} .conum[data-value]{display:inline-block;color:#fff!important;background-color:rgba(0,0,0,.8);-webkit-border-radius:100px;border-radius:100px;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:&quot;Open Sans&quot;,&quot;DejaVu Sans&quot;,sans-serif;font-style:normal;font-weight:bold} .conum[data-value] *{color:#fff!important} .conum[data-value]+b{display:none} .conum[data-value]:after{content:attr(data-value)} pre .conum[data-value]{position:relative;top:-.125em} b.conum *{color:inherit!important} .conum:not([data-value]):empty{display:none} .hdlist&gt;table,.colist&gt;table{border:0;background:none} .hdlist&gt;table&gt;tbody&gt;tr,.colist&gt;table&gt;tbody&gt;tr{background:none} td.hdlist1{padding-right:.75em;font-weight:bold} td.hdlist1,td.hdlist2{vertical-align:top} .literalblock+.colist,.listingblock+.colist{margin-top:-.5em} .colist&gt;table tr&gt;td:first-of-type{padding:0 .75em;line-height:1} .colist&gt;table tr&gt;td:last-of-type{padding:.25em 0} h1,h2,h3,#toctitle,.sidebarblock&gt;.content&gt;.title,h4,h5,h6{font-family:&quot;Open Sans&quot;,sans-serif;font-style:normal;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;} .blog-post-asciidoc p{margin-bottom:1.25rem} .blog-post-asciidoc .content img {         max-height: 22em;     width: auto;     display: block;     height: inherit; } .blog-post-asciidoc .imageblock {     max-width: 100%;     background: #ffffff;     border: 1px solid #eeeeee;     -moz-box-shadow: 1px 1px 5px rgba(0, 0, 0, .1);     -webkit-box-shadow: 1px 1px 5px rgba(0, 0, 0, .1);     box-shadow: 1px 1px 5px rgba(0, 0, 0, .1);     display: inline-block;     padding: 1em; } .blog-post-asciidoc img { border: none; -webkit-box-shadow: none; box-shadow: none; } @media only screen and (min-width:768px){.sect1{padding-bottom:1.25em}}.sect1+.sect1{border-top:1px solid #efefed} pre,pre&gt;code{line-height:1.45;color:rgba(0,0,0,.9);font-family:&quot;Droid Sans Mono&quot;,&quot;DejaVu Sans Mono&quot;,monospace;font-weight:400;text-rendering:optimizeSpeed} .blog-post-asciidoc code,kbd,pre,samp{font-size:.9em;font-weight:300;} .blog-post-asciidoc .admonitionblock&gt;table{border-collapse:separate;border:0;background:none;width:100%} .blog-post-asciidoc .admonitionblock&gt;table td.icon{text-align:center;width:80px} .blog-post-asciidoc .admonitionblock&gt;table td.icon img{max-width:none} .blog-post-asciidoc .admonitionblock&gt;table td.icon .title{font-weight:bold;font-family:&quot;Open Sans&quot;,&quot;DejaVu Sans&quot;,sans-serif;text-transform:uppercase} .blog-post-asciidoc .admonitionblock&gt;table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #ddddd8;color:rgba(0,0,0,.6)} .blog-post-asciidoc .admonitionblock&gt;table td.content&gt;:last-child&gt;:last-child{margin-bottom:0} .blog-post-asciidoc .admonitionblock td.icon [class^=&quot;fa icon-&quot;]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default} .blog-post-asciidoc .admonitionblock td.icon .icon-note:before{content:&quot;\f05a&quot;;color:#19407c} .blog-post-asciidoc .admonitionblock td.icon .icon-tip:before{content:&quot;\f0eb&quot;;text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111} .blog-post-asciidoc .admonitionblock td.icon .icon-warning:before{content:&quot;\f071&quot;;color:#bf6900} .blog-post-asciidoc .admonitionblock td.icon .icon-caution:before{content:&quot;\f06d&quot;;color:#bf3400} .blog-post-asciidoc .admonitionblock td.icon .icon-important:before{content:&quot;\f06a&quot;;color:#bf0000} &lt;/style&gt;&lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.2.0/css/font-awesome.min.css&quot;&gt;&lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css&quot;&gt;&lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js&quot;&gt;&lt;/script&gt;&lt;div id=&quot;content&quot; class=&quot;blog-post-asciidoc&quot;&gt;&lt;div id=&quot;preamble&quot;&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;This series continues from the &lt;a href=&quot;http://www.kennybastani.com/2015/07/spring-cloud-docker-microservices.html&quot;&gt;last blog post about building microservices&lt;/a&gt; using &lt;a href=&quot;http://projects.spring.io/spring-cloud/&quot;&gt;Spring Cloud&lt;/a&gt;. This post has two parts. The first part describes how to create cloud-native data services using Spring Boot. The second part is a companion example project that uses Docker Compose to run multiple microservices locally to simulate a polyglot persistence setup.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_what_is_polyglot_persistence&quot;&gt;What is polyglot persistence?&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;a href=&quot;http://martinfowler.com/bliki/PolyglotPersistence.html&quot;&gt;Polyglot persistence is a term&lt;/a&gt; that describes an architecture that uses a collection of different database solutions as a part of a platform&amp;#8217;s core design. More plainly, each &lt;a href=&quot;http://12factor.net/backing-services&quot;&gt;backing service&lt;/a&gt; is managed from an exclusive connection to a Spring Boot service that exposes domain data as HTTP resources.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The central idea behind polyglot persistence is that service architectures should be able to utilize the best languages for the job at hand. There is no clear definition of how to do this well, and it tends to evolve organically as central databases become cumbersome when required to add new features.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_spring_boot_roles&quot;&gt;Spring Boot Roles&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;When designing microservices that manage exclusive access to multiple data providers, it can be useful to think about the roles in which your microservices will play.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;We can think of a &lt;a href=&quot;http://projects.spring.io/spring-boot/&quot;&gt;Spring Boot&lt;/a&gt; application as the basic building block for our microservice architecture.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;img-microservice-roles&quot; class=&quot;imageblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;img src=&quot;http://i.imgur.com/StpflHf.png&quot; alt=&quot;Microservice Roles&quot; width=&quot;70%&quot; height=&quot;auto&quot;&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Figure 1. Each Spring Boot application plays a role when integrating with other services&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The diagram above describes six Spring Boot applications that are color coded to describe the role they play when integrated using &lt;a href=&quot;http://projects.spring.io/spring-cloud/&quot;&gt;Spring Cloud&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_data_services&quot;&gt;Data Services&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Each Spring Boot application in a microservices architecture will play a role to varying degrees of importance. The data service role is one of the most important roles in any setup. This role handles exposing the application&amp;#8217;s domain data to other microservices in the platform.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;sect3&quot;&gt;&lt;h4 id=&quot;_polyglot_data_services&quot;&gt;Polyglot Data Services&lt;/h4&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The diagram below describes an example microservice architecture with multiple Spring Boot applications that expose data from multiple database providers.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;img-polyglot&quot; class=&quot;imageblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;img src=&quot;http://i.imgur.com/aQYGZFy.png&quot; alt=&quot;Polyglot Persistence Microservices&quot; width=&quot;80%&quot;&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Figure 2. Example Polyglot Persistence Architecture&lt;/div&gt;&lt;/div&gt;&lt;a name=&#39;more&#39;&gt;&lt;/a&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;We can see that our &lt;code&gt;User Service&lt;/code&gt; connects to two databases: &lt;a href=&quot;https://en.wikipedia.org/wiki/MySQL&quot;&gt;MySQL&lt;/a&gt; and &lt;a href=&quot;https://en.wikipedia.org/wiki/Couchbase_Server&quot;&gt;Couchbase&lt;/a&gt;. We can also see that our &lt;code&gt;Rating Service&lt;/code&gt; swaps out MySQL (RDBMS) for a &lt;a href=&quot;http://www.neo4j.com/developer&quot;&gt;Neo4j graph database&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;One of the reasons why you might decide to use a polyglot persistence setup for a microservice architecture is that it gives you the benefit of using the best &lt;a href=&quot;https://en.wikipedia.org/wiki/Database_model&quot;&gt;database model&lt;/a&gt; for the use case. For instance, I decided to use Neo4j for the &lt;code&gt;Rating Service&lt;/code&gt; because the shape of the data for ratings can be used to generate recommendations using &lt;a href=&quot;http://www.kennybastani.com/2014/11/using-apache-spark-and-neo4j-for-big.html&quot;&gt;Apache Spark&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_configuring_a_data_service&quot;&gt;Configuring a Data Service&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Let&amp;#8217;s take a look at what some of the common characteristics of a data service are in Spring Boot when using Spring Cloud.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_spring_data&quot;&gt;Spring Data&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Each Spring Boot application that we can consider to be a data service is one that has the responsibility for managing data access for other applications in the architecture. To do this, we can use another project of the Spring Framework, &lt;a href=&quot;http://projects.spring.io/spring-data/&quot;&gt;Spring Data&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_what_is_spring_data&quot;&gt;What is Spring Data?&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Spring Data is a project in the &lt;a href=&quot;http://projects.spring.io/spring-framework/&quot;&gt;Spring Framework&lt;/a&gt; ecosystem of tools that provides a familiar abstraction for interacting with a data store while preserving the special traits of its database model.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Anyone who has worked with the Spring Framework over the years has a good idea how to use Spring Data. If you&amp;#8217;re not familiar, please take a look at the &lt;a href=&quot;https://github.com/spring-projects/spring-data-examples&quot;&gt;Spring Data guides&lt;/a&gt; to get working examples.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_creating_a_data_service&quot;&gt;Creating a Data Service&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;When deciding to create a new data service for a &lt;a href=&quot;http://shop.oreilly.com/product/0636920038252.do&quot;&gt;cloud-native application&lt;/a&gt;, it is helpful to first examine the domain model of the application.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;img-movie-domain-graph-model&quot; class=&quot;imageblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;img src=&quot;http://i.imgur.com/5vPmly4.png&quot; alt=&quot;Movie Domain&quot; width=&quot;70%&quot;&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Figure 3. Graph model of the movie domain of our example application&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;In the graph data model above we can see the common entities that we need to expose from our services. The nodes represent the domain entities within our movie application.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;ulist&quot;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;User&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Movie&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Genre&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The connections between these entities give us a good idea of our boundaries that we need to consider when designing our microservices. For instance, we may have a requirement to analyze the ratings data between movies and users to generate movie recommendations.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;For this example project we will use three data services:&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;ulist&quot;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;Rating Service&lt;/code&gt; (Neo4j)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;Movie Service&lt;/code&gt; (MySQL)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;User Service&lt;/code&gt; (Neo4j)&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Before we can get started creating our data services, let&amp;#8217;s talk about what the anatomy of a Spring Boot data service looks like in a cloud-native application with Spring Cloud.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_anatomy_of_a_spring_boot_data_service&quot;&gt;Anatomy of a Spring Boot Data Service&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;This section will do a deep dive on how Spring Boot application are automatically configured to use data sources using Spring Data. Since each Spring Boot application is integrated using Spring Cloud, it is helpful to understand how these applications bootstrap their dependencies.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The dependencies each of our data services will have in common are:&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;ulist&quot;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://cloud.spring.io/spring-cloud-config/spring-cloud-config.html&quot;&gt;Configuration Server&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://projects.spring.io/spring-cloud/spring-cloud.html#_service_discovery_eureka_clients&quot;&gt;Discovery Client&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://projects.spring.io/spring-cloud/spring-cloud.html#_router_and_filter_zuul&quot;&gt;API Gateway&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://docs.spring.io/spring-data/jpa/docs/current/reference/html/&quot;&gt;Spring Data&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://projects.spring.io/spring-data-rest/&quot;&gt;Spring Data REST&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;These dependencies are declared in a Spring Boot application&amp;#8217;s &lt;code&gt;pom.xml&lt;/code&gt;. The common dependencies we will need are listed below.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-xml&quot; data-lang=&quot;xml&quot;&gt;&amp;lt;dependency&amp;gt;&lt;br /&gt;    &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;&lt;br /&gt;    &amp;lt;artifactId&amp;gt;spring-boot-starter&amp;lt;/artifactId&amp;gt;&lt;br /&gt;&amp;lt;/dependency&amp;gt;&lt;br /&gt;&amp;lt;dependency&amp;gt;&lt;br /&gt;    &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;&lt;br /&gt;    &amp;lt;artifactId&amp;gt;spring-boot-starter-data-rest&amp;lt;/artifactId&amp;gt;&lt;br /&gt;&amp;lt;/dependency&amp;gt;&lt;br /&gt;&amp;lt;dependency&amp;gt;&lt;br /&gt;    &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;&lt;br /&gt;    &amp;lt;artifactId&amp;gt;spring-boot-starter-data-jpa&amp;lt;/artifactId&amp;gt;&lt;br /&gt;&amp;lt;/dependency&amp;gt;&lt;br /&gt;&amp;lt;dependency&amp;gt;&lt;br /&gt;    &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt;&lt;br /&gt;    &amp;lt;artifactId&amp;gt;spring-cloud-config-server&amp;lt;/artifactId&amp;gt;&lt;br /&gt;&amp;lt;/dependency&amp;gt;&lt;br /&gt;&amp;lt;dependency&amp;gt;&lt;br /&gt;    &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt;&lt;br /&gt;    &amp;lt;artifactId&amp;gt;spring-cloud-starter-eureka&amp;lt;/artifactId&amp;gt;&lt;br /&gt;&amp;lt;/dependency&amp;gt;&lt;br /&gt;&amp;lt;dependency&amp;gt;&lt;br /&gt;    &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt;&lt;br /&gt;    &amp;lt;artifactId&amp;gt;spring-cloud-starter-zuul&amp;lt;/artifactId&amp;gt;&lt;br /&gt;&amp;lt;/dependency&amp;gt;&lt;br /&gt;&amp;lt;dependency&amp;gt;&lt;br /&gt;    &amp;lt;groupId&amp;gt;mysql&amp;lt;/groupId&amp;gt;&lt;br /&gt;    &amp;lt;artifactId&amp;gt;mysql-connector-java&amp;lt;/artifactId&amp;gt;&lt;br /&gt;&amp;lt;/dependency&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_bootstrapping_datasource_dependencies&quot;&gt;Bootstrapping Datasource Dependencies&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;One of the core principles of Spring Boot is minimal configuration. Spring Boot will automatically scan the classpath of an application at startup and bootstrap dependencies. For example, if I added &lt;code&gt;spring-boot-starter-jpa&lt;/code&gt; as one of my dependencies, the data source is automatically configured by looking for a compatible database driver elsewhere in the dependencies.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;In the example code snippet from the &lt;code&gt;pom.xml&lt;/code&gt;, I&amp;#8217;ve specified &lt;code&gt;mysql-connector-java&lt;/code&gt; dependency. Now when I start the Spring Boot application, this MySQL driver will automatically be configured as our default &lt;a href=&quot;http://projects.spring.io/spring-data-jpa/&quot;&gt;data source for JPA&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The data source connection details are retrieved from the configuration service for a specific environment. Those configurations are contained in &lt;code&gt;application.yml&lt;/code&gt;. Below is an example application properties for a Spring Data JPA application that has a connection to a MySQL database. This is similar to how the &lt;code&gt;Movie Service&lt;/code&gt; in the example project is configured.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-yaml&quot; data-lang=&quot;yaml&quot;&gt;spring:&lt;br /&gt;  profiles:&lt;br /&gt;    active: development&lt;br /&gt;---&lt;br /&gt;spring:&lt;br /&gt;  profiles: development&lt;br /&gt;  jpa:&lt;br /&gt;    show_sql: false&lt;br /&gt;    database: MYSQL&lt;br /&gt;    hibernate:&lt;br /&gt;      ddl-auto: none&lt;br /&gt;  datasource: &lt;i class=&quot;conum&quot; data-value=&quot;1&quot;&gt;&lt;/i&gt;&lt;b&gt;(1)&lt;/b&gt;&lt;br /&gt;    url: jdbc:mysql://localhost/test&lt;br /&gt;    username: dbuser&lt;br /&gt;    password: dbpass&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;colist arabic&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td&gt;&lt;i class=&quot;conum&quot; data-value=&quot;1&quot;&gt;&lt;/i&gt;&lt;b&gt;1&lt;/b&gt;&lt;/td&gt;&lt;td&gt;The &lt;code&gt;spring.datasource&lt;/code&gt; property block is where you configure connection details.&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_spring_cloud_dependencies&quot;&gt;Spring Cloud Dependencies&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The Spring Cloud dependencies that I&amp;#8217;ve specified in the &lt;code&gt;pom.xml&lt;/code&gt; will be common and standard throughout our connected data services. The dependency we can expect to change per the requirements of the attached data store will be the Spring Data project we choose for that data service.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;sect3&quot;&gt;&lt;h4 id=&quot;_config_server&quot;&gt;Config Server&lt;/h4&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The &lt;code&gt;spring-cloud-starter-config-server&lt;/code&gt; dependency is used to tell our Spring Boot application to use a configuration server to retrieve environment configurations.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;img-config-server&quot; class=&quot;imageblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;img src=&quot;http://i.imgur.com/J7FazPH.png&quot; alt=&quot;Spring Configurations&quot; width=&quot;80%&quot; height=&quot;80%&quot;&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Figure 4. Config server enables automatic configuration per environment in a Git repository&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;By adding this dependency to our classpath, we can configure the service to retrieve a set of configurations for a specific &lt;a href=&quot;http://docs.spring.io/spring-boot/docs/current/reference/html/boot-features-profiles.html&quot;&gt;Spring profile&lt;/a&gt;. A Spring profile could define configurations for an environment, for instance, staging and production profiles. Retrieving configurations for a profile is an important feature of a data service since we will connect to different databases in different environments.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect3&quot;&gt;&lt;h4 id=&quot;_eureka_discovery&quot;&gt;Eureka Discovery&lt;/h4&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The &lt;code&gt;spring-cloud-starter-eureka&lt;/code&gt; dependency is used to tell our Spring Boot application that it should register itself with the Eureka discovery service on startup.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Eureka is a service registry that provides us with a way to automatically discover and connect to other data services using the ID of a Spring Boot application. Further, as we scale up the number of instances of a data service, a client-side load balancer will automatically route requests to registered instances of the same service ID.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;img-eureka-load-balance&quot; class=&quot;imageblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;img src=&quot;http://i.imgur.com/aqCtybq.png?1&quot; alt=&quot;Discovery&quot; width=&quot;60%&quot; height=&quot;100%&quot;&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Figure 5. Eureka client-side load balancing with ribbon&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect3&quot;&gt;&lt;h4 id=&quot;_zuul_gateway&quot;&gt;Zuul Gateway&lt;/h4&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The &lt;code&gt;spring-cloud-starter-zuul&lt;/code&gt; dependency is used to tell our Spring Boot application that it should advertise its HTTP routes to other services using a &lt;a href=&quot;https://en.wikipedia.org/wiki/Reverse_proxy&quot;&gt;reverse proxy lookup&lt;/a&gt;. This technique is called a &lt;a href=&quot;http://projects.spring.io/spring-cloud/spring-cloud.html#_polyglot_support_with_sidecar&quot;&gt;sidecar proxy&lt;/a&gt;, which is used to expose domain resources to applications that do not register with Eureka. The use of a sidecar on an API Gateway is helpful if you have applications using a language other than the JVM.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;By adding the annotation &lt;code&gt;@EnableZuulProxy&lt;/code&gt; on the Spring Boot application class, your service will automatically add HTTP routes advertised by other services through Eureka.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;curl -X GET &#39;http://service.cfapps.io/routes&#39;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;By making a request to the &lt;code&gt;/routes&lt;/code&gt; endpoint of a Zuul enabled service, you will get back a manifest of services who have registered with Eureka and are exposing a REST API or HTTP route.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-json&quot; data-lang=&quot;json&quot;&gt;{&lt;br /&gt;  &quot;_links&quot;: {&lt;br /&gt;    &quot;self&quot;: {&lt;br /&gt;      &quot;href&quot;: &quot;http://service.cfapps.io/routes&quot;,&lt;br /&gt;      &quot;templated&quot;: false&lt;br /&gt;    }&lt;br /&gt;  },&lt;br /&gt;  &quot;/rating/**&quot;: &quot;rating&quot;,&lt;br /&gt;  &quot;/user/**&quot;: &quot;user&quot;,&lt;br /&gt;  &quot;/movie/**&quot;: &quot;movie&quot;,&lt;br /&gt;  &quot;/gateway/**&quot;: &quot;gateway&quot;,&lt;br /&gt;  &quot;/moviesui/**&quot;: &quot;moviesui&quot;&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The result shows that we have multiple services registered with their service ID as routes we can make requests to. Let&amp;#8217;s see the result of calling the &lt;code&gt;movie&lt;/code&gt; service&amp;#8217;s route at &lt;code&gt;/movie/**&lt;/code&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;curl -X GET &#39;http://service.cfapps.io/movie&#39;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-json&quot; data-lang=&quot;json&quot;&gt;{&lt;br /&gt;  &quot;_links&quot;: {&lt;br /&gt;    &quot;movies&quot;: {&lt;br /&gt;      &quot;href&quot;: &quot;http://service.cfapps.io/movie/movies{?page,size,sort}&quot;,&lt;br /&gt;      &quot;templated&quot;: true&lt;br /&gt;    },&lt;br /&gt;    &quot;profile&quot;: {&lt;br /&gt;      &quot;href&quot;: &quot;http://service.cfapps.io/movie/alps&quot;,&lt;br /&gt;      &quot;templated&quot;: false&lt;br /&gt;    }&lt;br /&gt;  }&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;We can now see the list of links that are advertised by the &lt;code&gt;movie&lt;/code&gt; service&amp;#8217;s root. We can see that this service has a single repository exposed as a REST resource at &lt;code&gt;/movie/movies&lt;/code&gt; and that it is a paging and sorting repository.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;admonitionblock note&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;icon&quot;&gt;&lt;i class=&quot;fa icon-note&quot; title=&quot;Note&quot;&gt;&lt;/i&gt;&lt;/td&gt;&lt;td class=&quot;content&quot;&gt;The JSON format we are looking at is &lt;a href=&quot;https://en.wikipedia.org/wiki/Hypertext_Application_Language&quot;&gt;HAL&lt;/a&gt;, which is the JSON and XML specification based on the principles of &lt;a href=&quot;https://en.wikipedia.org/wiki/HATEOAS&quot;&gt;HATEOAS (Hypermedia as the Engine of Application State)&lt;/a&gt;. This JSON format provides a way for clients to traverse a REST API using embedded links. &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;We can now traverse into the &lt;code&gt;movie&lt;/code&gt; service&amp;#8217;s &lt;code&gt;movies&lt;/code&gt; repository and take a look at the results.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;curl -X GET &#39;http://service.cfapps.io/movie/movies&#39;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The results of this request show a traversable page of items that are returned by the paging and sorting repository for this domain entity.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-json&quot; data-lang=&quot;json&quot;&gt;{&lt;br /&gt;  &quot;_links&quot;: {&lt;br /&gt;    &quot;first&quot;: {&lt;br /&gt;      &quot;href&quot;: &quot;http://service.cfapps.io/movie/movies?page=0&amp;amp;size=20&quot;,&lt;br /&gt;      &quot;templated&quot;: false&lt;br /&gt;    },&lt;br /&gt;    &quot;self&quot;: {&lt;br /&gt;      &quot;href&quot;: &quot;http://service.cfapps.io/movie/movies&quot;,&lt;br /&gt;      &quot;templated&quot;: false&lt;br /&gt;    },&lt;br /&gt;    &quot;next&quot;: {&lt;br /&gt;      &quot;href&quot;: &quot;http://service.cfapps.io/movie/movies?page=1&amp;amp;size=20&quot;,&lt;br /&gt;      &quot;templated&quot;: false&lt;br /&gt;    },&lt;br /&gt;    &quot;last&quot;: {&lt;br /&gt;      &quot;href&quot;: &quot;http://service.cfapps.io/movie/movies?page=83&amp;amp;size=20&quot;,&lt;br /&gt;      &quot;templated&quot;: false&lt;br /&gt;    },&lt;br /&gt;    &quot;search&quot;: {&lt;br /&gt;      &quot;href&quot;: &quot;http://service.cfapps.io/movie/movies/search&quot;,&lt;br /&gt;      &quot;templated&quot;: false&lt;br /&gt;    }&lt;br /&gt;  },&lt;br /&gt;  &quot;_embedded&quot;: {&lt;br /&gt;    &quot;movies&quot;: [&lt;br /&gt;      {&lt;br /&gt;        &quot;id&quot;: 1,&lt;br /&gt;        &quot;title&quot;: &quot;Toy Story (1995)&quot;,&lt;br /&gt;        &quot;released&quot;: 788918400000,&lt;br /&gt;        &quot;url&quot;: &quot;http://us.imdb.com/M/title-exact?Toy%20Story%20(1995)&quot;,&lt;br /&gt;        &quot;genres&quot;: [&lt;br /&gt;          {&lt;br /&gt;            &quot;name&quot;: &quot;Animation&quot;&lt;br /&gt;          },&lt;br /&gt;          {&lt;br /&gt;            &quot;name&quot;: &quot;Children&#39;s&quot;&lt;br /&gt;          },&lt;br /&gt;          {&lt;br /&gt;            &quot;name&quot;: &quot;Comedy&quot;&lt;br /&gt;          }&lt;br /&gt;        ],&lt;br /&gt;        &quot;_links&quot;: {&lt;br /&gt;          &quot;self&quot;: {&lt;br /&gt;            &quot;href&quot;: &quot;http://service.cfapps.io/movie/movies/1&quot;,&lt;br /&gt;            &quot;templated&quot;: false&lt;br /&gt;          },&lt;br /&gt;          &quot;movie&quot;: {&lt;br /&gt;            &quot;href&quot;: &quot;http://service.cfapps.io/movie/movies/1&quot;,&lt;br /&gt;            &quot;templated&quot;: false&lt;br /&gt;          }&lt;br /&gt;        }&lt;br /&gt;      }&lt;br /&gt;      ...&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_adding_a_neo4j_data_service&quot;&gt;Adding a Neo4j Data Service&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Now let&amp;#8217;s take a look at what a Spring Boot data service would look like if it exposed data from a Neo4j database. Since Spring Data provides a project for Neo4j, we can use a set of features that take advantage of the specialized traits of a graph database.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Instead of needing to specify a database driver in my classpath like we did with MySQL, I can provide dependencies in my &lt;code&gt;pom.xml&lt;/code&gt; for the Spring Data Neo4j project.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-xml&quot; data-lang=&quot;xml&quot;&gt;&amp;lt;dependency&amp;gt;&lt;br /&gt;   &amp;lt;groupId&amp;gt;org.springframework.data&amp;lt;/groupId&amp;gt;&lt;br /&gt;   &amp;lt;artifactId&amp;gt;spring-data-neo4j&amp;lt;/artifactId&amp;gt;&lt;br /&gt;   &amp;lt;version&amp;gt;3.4.0.RC1&amp;lt;/version&amp;gt;&lt;br /&gt;&amp;lt;/dependency&amp;gt;&lt;br /&gt;&amp;lt;dependency&amp;gt;&lt;br /&gt;   &amp;lt;groupId&amp;gt;org.springframework.data&amp;lt;/groupId&amp;gt;&lt;br /&gt;   &amp;lt;artifactId&amp;gt;spring-data-neo4j-rest&amp;lt;/artifactId&amp;gt;&lt;br /&gt;   &amp;lt;version&amp;gt;3.3.0.M1&amp;lt;/version&amp;gt;&lt;br /&gt;&amp;lt;/dependency&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Now I can use the specific features of the Spring Data Neo4j project, which gives native graph features like routing and graph traversals.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_rating_service&quot;&gt;Rating Service&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Going back to our domain model from earlier, I can see that users in my application can rate movies. We can use our Neo4j graph store as a way to index the connections between users and movies and later use that data to generate recommendations, a leading use case for graph databases.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;img-domain-graph-model-2&quot; class=&quot;imageblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;img src=&quot;http://i.imgur.com/5vPmly4.png&quot; alt=&quot;Movie Domain&quot; width=&quot;70%&quot;&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Figure 6. The domain model shows how we can use a graph database to analyze the connections between movies and users&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Using the Zuul enabled reverse proxy, let&amp;#8217;s take a look at what the &lt;code&gt;Rating Service&lt;/code&gt; exposes from Neo4j.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;curl -X GET &#39;http://service.cfapps.io/rating&#39;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-json&quot; data-lang=&quot;json&quot;&gt;{&lt;br /&gt;  &quot;_links&quot;: {&lt;br /&gt;    &quot;products&quot;: {&lt;br /&gt;      &quot;href&quot;: &quot;http://service.cfapps.io/rating/products{?page,size,sort}&quot;,&lt;br /&gt;      &quot;templated&quot;: true&lt;br /&gt;    },&lt;br /&gt;    &quot;ratings&quot;: {&lt;br /&gt;      &quot;href&quot;: &quot;http://service.cfapps.io/rating/ratings{?page,size,sort}&quot;,&lt;br /&gt;      &quot;templated&quot;: true&lt;br /&gt;    },&lt;br /&gt;    &quot;users&quot;: {&lt;br /&gt;      &quot;href&quot;: &quot;http://service.cfapps.io/rating/users{?page,size,sort}&quot;,&lt;br /&gt;      &quot;templated&quot;: true&lt;br /&gt;    },&lt;br /&gt;    &quot;profile&quot;: {&lt;br /&gt;      &quot;href&quot;: &quot;http://service.cfapps.io/rating/alps&quot;,&lt;br /&gt;      &quot;templated&quot;: false&lt;br /&gt;    }&lt;br /&gt;  }&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;We see from the results that we have 3 repositories that are exposed through REST and HATEOAS. The &lt;code&gt;/rating/products&lt;/code&gt; endpoint is a generic form of the &lt;code&gt;movie&lt;/code&gt; domain entity from our other service. Later we may want to offer things other than movies, this generic term saves us from having to change the semantics later if we enter a new line of business and still need recommendations.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;One of the key differences between our Spring Data JPA MySQL repository for movies is that a graph model has different underlying entity types that describe our data: nodes and relationships.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Let&amp;#8217;s take a look at the &lt;code&gt;/rating/ratings&lt;/code&gt; endpoint, which exposes the ratings of a user and movie.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-json&quot; data-lang=&quot;json&quot;&gt;...&lt;br /&gt;&quot;ratings&quot;: [&lt;br /&gt;{&lt;br /&gt;  &quot;id&quot;: 87863,&lt;br /&gt;  &quot;timestamp&quot;: 881252305,&lt;br /&gt;  &quot;rating&quot;: 1,&lt;br /&gt;  &quot;_links&quot;: {&lt;br /&gt;    &quot;self&quot;: {&lt;br /&gt;      &quot;href&quot;: &quot;http://service.cfapps.io/ratings/87863&quot;,&lt;br /&gt;      &quot;templated&quot;: false&lt;br /&gt;    },&lt;br /&gt;    &quot;rating&quot;: {&lt;br /&gt;      &quot;href&quot;: &quot;http://service.cfapps.io/ratings/87863&quot;,&lt;br /&gt;      &quot;templated&quot;: false&lt;br /&gt;    },&lt;br /&gt;    &quot;user&quot;: {&lt;br /&gt;      &quot;href&quot;: &quot;http://service.cfapps.io/ratings/87863/user&quot;,&lt;br /&gt;      &quot;templated&quot;: false&lt;br /&gt;    },&lt;br /&gt;    &quot;product&quot;: {&lt;br /&gt;      &quot;href&quot;: &quot;http://service.cfapps.io/ratings/87863/product&quot;,&lt;br /&gt;      &quot;templated&quot;: false&lt;br /&gt;    }&lt;br /&gt;  }&lt;br /&gt;},&lt;br /&gt;...&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The rating repository shows each relationship that connects a user to a product, and what they rated the product. The ID used for the user and the product relates back to the unique ID used by our other services that manage parts of our domain data, such as &lt;code&gt;Movie Service&lt;/code&gt; and &lt;code&gt;User Service&lt;/code&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;sect3&quot;&gt;&lt;h4 id=&quot;_custom_graph_queries&quot;&gt;Custom Graph Queries&lt;/h4&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Depending on how our connected data is used, we can create repository endpoints that allow us to bind certain REST API endpoints to tailored queries that use Neo4j&amp;#8217;s Cypher query language.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;One such example is the requirement to find all ratings for a user. The Cypher query to do this could be:&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-cypher&quot; data-lang=&quot;cypher&quot;&gt;MATCH (n:User)-[r:Rating]-&amp;gt;() WHERE n.knownId = {id} RETURN r&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Here we are matching the pattern where a user has rated something, starting at the user&amp;#8217;s ID and returning a list of the relationship entities containing the attributes of the rating entity.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;To bind this query to our Spring Data REST repository we would describe it as follows:&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;@RepositoryRestResource&lt;br /&gt;public interface RatingRepository extends PagingAndSortingRepository&amp;lt;Rating, Long&amp;gt; {&lt;br /&gt;    @Query(value = &quot;MATCH (n:User)-[r:Rating]-&amp;gt;() WHERE n.knownId = {id} RETURN r&quot;)&lt;br /&gt;    Iterable&amp;lt;Rating&amp;gt; findByUserId(@Param(value = &quot;id&quot;) String id);&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;By registering this custom repository method, Spring Data REST will automatically register it as an embedded link in the rating&amp;#8217;s REST repository. Let&amp;#8217;s take a look.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;curl -X GET &quot;http://service.cfapps.io/rating/ratings/search/findByUserId?id=1&quot;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The custom repository method will be added to the &lt;code&gt;rating&lt;/code&gt; service&amp;#8217;s &lt;code&gt;search&lt;/code&gt; links. We can now call this new method by its name, as shown above.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-json&quot; data-lang=&quot;json&quot;&gt;{&lt;br /&gt;  &quot;_links&quot;: {&lt;br /&gt;    &quot;self&quot;: {&lt;br /&gt;      &quot;href&quot;: &quot;http://service.cfapps.io/rating/ratings/search/findByUserId?id=1&quot;,&lt;br /&gt;      &quot;templated&quot;: false&lt;br /&gt;    }&lt;br /&gt;  },&lt;br /&gt;  &quot;_embedded&quot;: {&lt;br /&gt;    &quot;ratings&quot;: [&lt;br /&gt;      {&lt;br /&gt;        &quot;id&quot;: 87863,&lt;br /&gt;        &quot;timestamp&quot;: 881252305,&lt;br /&gt;        &quot;rating&quot;: 1&lt;br /&gt;      },&lt;br /&gt;      ...&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_binding_rest_clients&quot;&gt;Binding REST Clients&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The next thing we will want to do is to consume the data from our different polyglot persistence data services. To do this using Java is entirely too simple using Netflix Feign client, as described in my last blog post. Let&amp;#8217;s take a look at what these client contracts might look like in a UI application.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;sect3&quot;&gt;&lt;h4 id=&quot;_movie_client&quot;&gt;Movie Client&lt;/h4&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;@FeignClient(&quot;movie&quot;)&lt;br /&gt;public interface MovieClient {&lt;br /&gt;&lt;br /&gt;  @RequestMapping(method = RequestMethod.GET, value = &quot;/movies&quot;)&lt;br /&gt;  PagedResources&amp;lt;Movie&amp;gt; findAll();&lt;br /&gt;&lt;br /&gt;  @RequestMapping(method = RequestMethod.GET,&lt;br /&gt;      value = &quot;/movies/search/findByTitleContainingIgnoreCase?title={title}&quot;)&lt;br /&gt;  PagedResources&amp;lt;Movie&amp;gt; findByTitleContainingIgnoreCase(@PathVariable(&quot;title&quot;) String title);&lt;br /&gt;&lt;br /&gt;  @RequestMapping(method = RequestMethod.GET, value = &quot;/movies/{id}&quot;)&lt;br /&gt;  List&amp;lt;Movie&amp;gt; findById(@PathVariable(&quot;id&quot;) String id);&lt;br /&gt;&lt;br /&gt;  @RequestMapping(method = RequestMethod.GET,&lt;br /&gt;      value = &quot;/movies/search/findByIdIn?ids={ids}&quot;)&lt;br /&gt;  PagedResources&amp;lt;Movie&amp;gt; findByIds(@PathVariable(&quot;ids&quot;) String ids);&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The above interface declares that I would like to bind a method signature to the REST API route of the &lt;code&gt;movie&lt;/code&gt; service, as configured by the &lt;code&gt;@FeignClient(&quot;movie&quot;)&lt;/code&gt; annotation. This interface will be registered as a bean when the application starts up and can be autowired in other beans in the application.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;If you&amp;#8217;re like me, when you think about how powerful this can be in a large operation with many microservices, it gets you excited about the future of developing cloud-native Java applications using Spring.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect3&quot;&gt;&lt;h4 id=&quot;_autowire_a_feign_client&quot;&gt;Autowire a Feign Client&lt;/h4&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The snippet below shows how we would auto wire our Feign Client interface for our &lt;code&gt;movie&lt;/code&gt; service.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;@SpringUI(path = &quot;/movies&quot;)&lt;br /&gt;@Title(&quot;Movies&quot;)&lt;br /&gt;@Theme(&quot;valo&quot;)&lt;br /&gt;public class MovieUI extends UI {&lt;br /&gt;&lt;br /&gt;    private static final long serialVersionUID = -3540851800967573466L;&lt;br /&gt;&lt;br /&gt;    TextField filter = new TextField();&lt;br /&gt;    Grid movieList = new Grid();&lt;br /&gt;&lt;br /&gt;    @Autowired&lt;br /&gt;    MovieClient movieClient;&lt;br /&gt;&lt;br /&gt;    ...&lt;br /&gt;&lt;br /&gt;    private void refreshMovies(String stringFilter) {&lt;br /&gt;        if(!Objects.equals(stringFilter.trim(), &quot;&quot;)) {&lt;br /&gt;            movieList.setContainerDataSource(new BeanItemContainer&amp;lt;&amp;gt;(&lt;br /&gt;                    Movie.class, movieClient&lt;br /&gt;                        .findByTitleContainingIgnoreCase(stringFilter) &lt;i class=&quot;conum&quot; data-value=&quot;1&quot;&gt;&lt;/i&gt;&lt;b&gt;(1)&lt;/b&gt;&lt;br /&gt;                        .getContent()));&lt;br /&gt;        }&lt;br /&gt;    }&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;colist arabic&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td&gt;&lt;i class=&quot;conum&quot; data-value=&quot;1&quot;&gt;&lt;/i&gt;&lt;b&gt;1&lt;/b&gt;&lt;/td&gt;&lt;td&gt;We can call client APIs just as if they were Autowired repositories hosted within our application.&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_docker_demo&quot;&gt;Docker Demo&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The example project uses Docker to build a container image of each of our microservices as a part of the Maven build process. We can easily orchestrate the full microservice cluster on our machine using Docker compose.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_getting_started&quot;&gt;Getting Started&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;To get started, visit the GitHub repository for this example project.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/kbastani/spring-cloud-polyglot-persistence-example&quot; class=&quot;bare&quot;&gt;https://github.com/kbastani/spring-cloud-polyglot-persistence-example&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Clone or fork the project and download the repository to your machine. After downloading, you will need to use both Maven and Docker to compile and build the images locally.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_download_docker&quot;&gt;Download Docker&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;First, download Docker if you haven&amp;#8217;t already. Follow the instructions &lt;a href=&quot;https://docs.docker.com/installation/&quot;&gt;found here&lt;/a&gt;, to get Docker up and running on your development machine.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;You will also need to install &lt;a href=&quot;https://docs.docker.com/compose/&quot;&gt;Docker Compose&lt;/a&gt;, the installation guide can be &lt;a href=&quot;https://docs.docker.com/compose/install/&quot;&gt;found here&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_requirements&quot;&gt;Requirements&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The requirements for running this demo on your machine are found below.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;ulist&quot;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Maven 3&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Java 8&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Docker&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Docker Compose&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_building_the_project&quot;&gt;Building the project&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;To build the project, from the terminal, run the following command at the root of the project.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre&gt;$ mvn clean install&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The project will then download all of the needed dependencies and compile each of the project artifacts. Each service will be built, and then a Maven Docker plugin will automatically build each of the images into your local Docker registry. Docker must be running and available from the command line where you run the &lt;code&gt;mvn clean install&lt;/code&gt; command for the build to succeed.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;After the project successfully builds, you’ll see the following output:&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;[INFO] ------------------------------------------------------------------------&lt;br /&gt;[INFO] Reactor Summary:&lt;br /&gt;[INFO]&lt;br /&gt;[INFO] spring-cloud-microservice-example-parent ........... SUCCESS [  0.478 s]&lt;br /&gt;[INFO] user-microservice .................................. SUCCESS [ 36.055 s]&lt;br /&gt;[INFO] discovery-microservice ............................. SUCCESS [ 15.911 s]&lt;br /&gt;[INFO] api-gateway-microservice ........................... SUCCESS [ 17.904 s]&lt;br /&gt;[INFO] config-microservice ................................ SUCCESS [ 11.513 s]&lt;br /&gt;[INFO] movie-microservice ................................. SUCCESS [ 13.818 s]&lt;br /&gt;[INFO] ui-search .......................................... SUCCESS [ 31.328 s]&lt;br /&gt;[INFO] rating-microservice ................................ SUCCESS [ 22.910 s]&lt;br /&gt;[INFO] ------------------------------------------------------------------------&lt;br /&gt;[INFO] BUILD SUCCESS&lt;br /&gt;[INFO] ------------------------------------------------------------------------&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_start_the_cluster_with_docker_compose&quot;&gt;Start the Cluster with Docker Compose&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Now that each of the images has been built successfully, we can using Docker Compose to spin up our cluster. I’ve included a pre-configured Docker Compose yaml file with the project.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;From the project root, navigate to the &lt;code&gt;spring-cloud-polyglot-persistence-example/docker&lt;/code&gt; directory.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Now, to startup the microservice cluster, run the following command:&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;$ docker-compose up&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;If everything is configured correctly, each of the container images we built earlier will be launched within their VM container on Docker and networked for automatic service discovery. You will see a flurry of log output from each of the services as they begin their startup sequence. This might take a few minutes to complete, depending on the performance of the machine you’re running this demo on.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Once the startup sequence is completed, you can navigate to the Eureka host and see which services have registered with the discovery service.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Copy and paste the following command into the terminal where Docker can be accessed using the &lt;code&gt;$DOCKER_HOST&lt;/code&gt; environment variable.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;$ open $(echo \&quot;$(echo $DOCKER_HOST)\&quot;|&lt;br /&gt;            \sed &#39;s/tcp:\/\//http:\/\//g&#39;|&lt;br /&gt;            \sed &#39;s/[0-9]\{4,\}/8761/g&#39;|&lt;br /&gt;            \sed &#39;s/\&quot;//g&#39;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;If Eureka correctly started up, a browser window will open to the location of the Eureka service’s dashboard.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;admonitionblock note&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;icon&quot;&gt;&lt;i class=&quot;fa icon-note&quot; title=&quot;Note&quot;&gt;&lt;/i&gt;&lt;/td&gt;&lt;td class=&quot;content&quot;&gt;You&amp;#8217;ll need to wait for Eureka to start and see that all the other services are registered before proceeding. If Eureka is not yet available, give Docker Compose a few more minutes to get all the services fully started. &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_sidecar_routes&quot;&gt;Sidecar Routes&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;After all the services have started up and registered with Eureka, we can see each of the service instances that are running and their status. We can then access one of the data-driven services, for example the movie service. The following command will open a browser window and display the routes that have been bootstrapped on the API Gateway using the &lt;code&gt;@EnableZuulProxy&lt;/code&gt; ane &lt;code&gt;@EnableSidecar&lt;/code&gt; annotations.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;$ open $(echo \&quot;$(echo $DOCKER_HOST)/routes\&quot;|&lt;br /&gt;            \sed &#39;s/tcp:\/\//http:\/\//g&#39;|&lt;br /&gt;            \sed &#39;s/[0-9]\{4,\}/10000/g&#39;|&lt;br /&gt;            \sed &#39;s/\&quot;//g&#39;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;This command will navigate to the API gateway’s endpoint display each route that has been discovered through the Zuul Sidecar.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;{&lt;br /&gt;  &quot;_links&quot; : {&lt;br /&gt;    &quot;self&quot; : {&lt;br /&gt;      &quot;href&quot; : &quot;http://192.168.59.103:10000/routes&quot;,&lt;br /&gt;      &quot;templated&quot; : false&lt;br /&gt;    }&lt;br /&gt;  },&lt;br /&gt;  &quot;/gateway/**&quot; : &quot;gateway&quot;,&lt;br /&gt;  &quot;/movie/**&quot; : &quot;movie&quot;,&lt;br /&gt;  &quot;/rating/**&quot; : &quot;rating&quot;,&lt;br /&gt;  &quot;/moviesui/**&quot; : &quot;moviesui&quot;,&lt;br /&gt;  &quot;/user/**&quot; : &quot;user&quot;,&lt;br /&gt;  &quot;/discovery/**&quot; : &quot;discovery&quot;&lt;br /&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_movies_ui&quot;&gt;Movies UI&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;I&amp;#8217;ve created a simple &lt;a href=&quot;https://vaadin.com/wiki/-/wiki/Spring+Vaadin/I+-+Getting+Started+with+Vaadin+Spring+and+Spring+Boot&quot;&gt;Spring Boot Vaadin&lt;/a&gt; application to allow us to consume our data services and perform simple searches.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;$ open $(echo \&quot;$(echo $DOCKER_HOST)/movies\&quot;|&lt;br /&gt;            \sed &#39;s/tcp:\/\//http:\/\//g&#39;|&lt;br /&gt;            \sed &#39;s/[0-9]\{4,\}/1111/g&#39;|&lt;br /&gt;            \sed &#39;s/\&quot;//g&#39;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;This command will open up the &lt;code&gt;search-ui&lt;/code&gt; application and allow us to search for movies. Try typing in one of your favorite movies from the early 90s like I&amp;#8217;ve done in the screen shot below.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;img-vaadin-ui-movies&quot; class=&quot;imageblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;img src=&quot;http://i.imgur.com/KCS1riY.png&quot; alt=&quot;Vaadin Movies&quot; style=&quot;max-height: 38em;&quot;&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Figure 7. Search Movies UI&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;_users_ui&quot;&gt;Users UI&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Paste the following command into your terminal to open the user application.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;highlightjs highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;$ open $(echo \&quot;$(echo $DOCKER_HOST)/users\&quot;|&lt;br /&gt;            \sed &#39;s/tcp:\/\//http:\/\//g&#39;|&lt;br /&gt;            \sed &#39;s/[0-9]\{4,\}/1111/g&#39;|&lt;br /&gt;            \sed &#39;s/\&quot;//g&#39;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;I created this view to display the results from querying the &lt;code&gt;User Service&lt;/code&gt;, the &lt;code&gt;Rating Service&lt;/code&gt;, and the &lt;code&gt;Movie Service&lt;/code&gt;. This example demonstrates how fast Spring Boot can handle queries that span multiple data services. There are two view in this page. The table view to the left displays users that are returned from our &lt;code&gt;User Service&lt;/code&gt;. The table to the right will display the movies that a user has previously rated. To activate the view on the right, click on one of the table rows containing a user record, as shown below.&lt;/p&gt;&lt;/div&gt;&lt;div id=&quot;img-vaadin-ui-users&quot; class=&quot;imageblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;img src=&quot;http://i.imgur.com/fPMtn3f.png&quot; alt=&quot;Vaadin Users&quot; style=&quot;max-height: 38em;&quot;&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Figure 8. Search Users UI&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><enclosure type='image/png' url='http://i.imgur.com/aqCtybq.png?1' length='0'/><link>https://www.kennybastani.com/2015/08/polyglot-persistence-spring-cloud-docker.html</link><author>noreply@blogger.com (Kenny Bastani)</author><thr:total>0</thr:total></item><item><guid isPermaLink="false">tag:blogger.com,1999:blog-6300367579216018061.post-8368851254535781851</guid><pubDate>Mon, 13 Jul 2015 01:50:00 +0000</pubDate><atom:updated>2015-09-08T19:44:03.211-07:00</atom:updated><category domain="http://www.blogger.com/atom/ns#">api gateway</category><category domain="http://www.blogger.com/atom/ns#">discovery service</category><category domain="http://www.blogger.com/atom/ns#">docker</category><category domain="http://www.blogger.com/atom/ns#">docker compose</category><category domain="http://www.blogger.com/atom/ns#">microservices</category><category domain="http://www.blogger.com/atom/ns#">spring boot</category><category domain="http://www.blogger.com/atom/ns#">spring cloud</category><title>Building Microservices with Spring Cloud and Docker</title><description>&lt;style&gt;/* BASICS */  .CodeMirror {   /* Set height, width, borders, and global font properties here */   font-family: monospace;   color: black; }  /* PADDING */  .CodeMirror-lines {   padding: 4px 0; /* Vertical padding around content */ } .CodeMirror pre {   padding: 0 4px; /* Horizontal padding of content */ }  .CodeMirror-scrollbar-filler, .CodeMirror-gutter-filler {   background-color: white; /* The little square between H and V scrollbars */ }  /* GUTTER */  .CodeMirror-gutters {   border-right: 1px solid #ddd;   background-color: #f7f7f7;   white-space: nowrap; } .CodeMirror-linenumbers {} .CodeMirror-linenumber {   padding: 0 3px 0 5px;   min-width: 20px;   text-align: right;   color: #999;   white-space: nowrap; }  .CodeMirror-guttermarker { color: black; } .CodeMirror-guttermarker-subtle { color: #999; }  /* CURSOR */  .CodeMirror div.CodeMirror-cursor {   border-left: 1px solid black; } /* Shown when moving in bi-directional text */ .CodeMirror div.CodeMirror-secondarycursor {   border-left: 1px solid silver; } .CodeMirror.cm-fat-cursor div.CodeMirror-cursor {   width: auto;   border: 0;   background: #7e7; } .CodeMirror.cm-fat-cursor div.CodeMirror-cursors {   z-index: 1; }  .cm-animate-fat-cursor {   width: auto;   border: 0;   -webkit-animation: blink 1.06s steps(1) infinite;   -moz-animation: blink 1.06s steps(1) infinite;   animation: blink 1.06s steps(1) infinite; } @-moz-keyframes blink {   0% { background: #7e7; }   50% { background: none; }   100% { background: #7e7; } } @-webkit-keyframes blink {   0% { background: #7e7; }   50% { background: none; }   100% { background: #7e7; } } @keyframes blink {   0% { background: #7e7; }   50% { background: none; }   100% { background: #7e7; } }  /* Can style cursor different in overwrite (non-insert) mode */ div.CodeMirror-overwrite div.CodeMirror-cursor {}  .cm-tab { display: inline-block; text-decoration: inherit; }  .CodeMirror-ruler {   border-left: 1px solid #ccc;   position: absolute; }  /* DEFAULT THEME */  .cm-s-default .cm-header {color: blue;} .cm-s-default .cm-quote {color: #090;} .cm-negative {color: #d44;} .cm-positive {color: #292;} .cm-header, .cm-strong {font-weight: bold;} .cm-em {font-style: italic;} .cm-link {text-decoration: underline;} .cm-strikethrough {text-decoration: line-through;}  .cm-s-default .cm-keyword {color: #708;} .cm-s-default .cm-atom {color: #219;} .cm-s-default .cm-number {color: #164;} .cm-s-default .cm-def {color: #00f;} .cm-s-default .cm-variable, .cm-s-default .cm-punctuation, .cm-s-default .cm-property, .cm-s-default .cm-operator {} .cm-s-default .cm-variable-2 {color: #05a;} .cm-s-default .cm-variable-3 {color: #085;} .cm-s-default .cm-comment {color: #a50;} .cm-s-default .cm-string {color: #a11;} .cm-s-default .cm-string-2 {color: #f50;} .cm-s-default .cm-meta {color: #555;} .cm-s-default .cm-qualifier {color: #555;} .cm-s-default .cm-builtin {color: #30a;} .cm-s-default .cm-bracket {color: #997;} .cm-s-default .cm-tag {color: #170;} .cm-s-default .cm-attribute {color: #00c;} .cm-s-default .cm-hr {color: #999;} .cm-s-default .cm-link {color: #00c;}  .cm-s-default .cm-error {color: #f00;} .cm-invalidchar {color: #f00;}  .CodeMirror-composing { border-bottom: 2px solid; }  /* Default styles for common addons */  div.CodeMirror span.CodeMirror-matchingbracket {color: #0f0;} div.CodeMirror span.CodeMirror-nonmatchingbracket {color: #f22;} .CodeMirror-matchingtag { background: rgba(255, 150, 0, .3); } .CodeMirror-activeline-background {background: #e8f2ff;}  /* STOP */  /* The rest of this file contains styles related to the mechanics of    the editor. You probably shouldn&#39;t touch them. */  .CodeMirror {   position: relative;   overflow: hidden;   background: white; }  .CodeMirror-scroll {   overflow: scroll !important; /* Things will break if this is overridden */   /* 30px is the magic margin used to hide the element&#39;s real scrollbars */   /* See overflow: hidden in .CodeMirror */   margin-bottom: -30px; margin-right: -30px;   padding-bottom: 30px;   height: 100%;   outline: none; /* Prevent dragging from highlighting the element */   position: relative; } .CodeMirror-sizer {   position: relative;   border-right: 30px solid transparent; }  /* The fake, visible scrollbars. Used to force redraw during scrolling    before actuall scrolling happens, thus preventing shaking and    flickering artifacts. */ .CodeMirror-vscrollbar, .CodeMirror-hscrollbar, .CodeMirror-scrollbar-filler, .CodeMirror-gutter-filler {   position: absolute;   z-index: 6;   display: none; } .CodeMirror-vscrollbar {   right: 0; top: 0;   overflow-x: hidden;   overflow-y: scroll; } .CodeMirror-hscrollbar {   bottom: 0; left: 0;   overflow-y: hidden;   overflow-x: scroll; } .CodeMirror-scrollbar-filler {   right: 0; bottom: 0; } .CodeMirror-gutter-filler {   left: 0; bottom: 0; }  .CodeMirror-gutters {   position: absolute; left: 0; top: 0;   z-index: 3; } .CodeMirror-gutter {   white-space: normal;   height: 100%;   display: inline-block;   margin-bottom: -30px;   /* Hack to make IE7 behave */   *zoom:1;   *display:inline; } .CodeMirror-gutter-wrapper {   position: absolute;   z-index: 4;   height: 100%; } .CodeMirror-gutter-elt {   position: absolute;   cursor: default;   z-index: 4; } .CodeMirror-gutter-wrapper {   -webkit-user-select: none;   -moz-user-select: none;   user-select: none; }  .CodeMirror-lines {   cursor: text;   min-height: 1px; /* prevents collapsing before first draw */ } .CodeMirror pre {   /* Reset some styles that the rest of the page might have set */   -moz-border-radius: 0; -webkit-border-radius: 0; border-radius: 0;   border-width: 0;   background: transparent;   font-family: inherit;   font-size: inherit;   margin: 0;   white-space: pre;   word-wrap: normal;   line-height: inherit;   color: inherit;   z-index: 2;   position: relative;   overflow: visible;   -webkit-tap-highlight-color: transparent; } .CodeMirror-wrap pre {   word-wrap: break-word;   white-space: pre-wrap;   word-break: normal; }  .CodeMirror-linebackground {   position: absolute;   left: 0; right: 0; top: 0; bottom: 0;   z-index: 0; }  .CodeMirror-linewidget {   position: relative;   z-index: 2;   overflow: auto; }  .CodeMirror-widget {}  .CodeMirror-code {   outline: none; }  /* Force content-box sizing for the elements where we expect it */ .CodeMirror-scroll, .CodeMirror-sizer, .CodeMirror-gutter, .CodeMirror-gutters, .CodeMirror-linenumber {   -moz-box-sizing: content-box;   box-sizing: content-box; }  .CodeMirror-measure {   position: absolute;   width: 100%;   height: 0;   overflow: hidden;   visibility: hidden; } .CodeMirror-measure pre { position: static; }  .CodeMirror div.CodeMirror-cursor {   position: absolute;   border-right: none;   width: 0; }  div.CodeMirror-cursors {   visibility: hidden;   position: relative;   z-index: 3; } .CodeMirror-focused div.CodeMirror-cursors {   visibility: visible; }  .CodeMirror-selected { background: #d9d9d9; } .CodeMirror-focused .CodeMirror-selected { background: #d7d4f0; } .CodeMirror-crosshair { cursor: crosshair; } .CodeMirror-line::selection, .CodeMirror-line &gt; span::selection, .CodeMirror-line &gt; span &gt; span::selection { background: #d7d4f0; } .CodeMirror-line::-moz-selection, .CodeMirror-line &gt; span::-moz-selection, .CodeMirror-line &gt; span &gt; span::-moz-selection { background: #d7d4f0; }  .cm-searching {   background: #ffa;   background: rgba(255, 255, 0, .4); }  /* IE7 hack to prevent it from returning funny offsetTops on the spans */ .CodeMirror span { *vertical-align: text-bottom; }  /* Used to force a border model for a node */ .cm-force-border { padding-right: .1px; }  @media print {   /* Hide the cursor when printing */   .CodeMirror div.CodeMirror-cursors {     visibility: hidden;   } }  /* See issue #2901 */ .cm-tab-wrap-hack:after { content: &#39;&#39;; }  /* Help users use markselection to safely style text background */ span.CodeMirror-selectedtext { background: none; } &lt;/style&gt;&lt;div&gt;&lt;div id=&quot;preamble&quot;&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;This blog series will introduce you to some of the foundational concepts of building a microservice-based platform using Spring Cloud and Docker.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;what-is-spring-cloud&quot;&gt;&lt;a class=&quot;anchor&quot; href=&quot;#what-is-spring-cloud&quot;&gt;&lt;/a&gt;What is Spring Cloud?&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;a href=&quot;http://projects.spring.io/spring-cloud/&quot; target=&quot;_blank&quot;&gt;Spring Cloud&lt;/a&gt; is a collection of tools from &lt;a href=&quot;https://pivotal.io/&quot; target=&quot;_blank&quot;&gt;Pivotal&lt;/a&gt; that provides solutions to some of the commonly encountered patterns when building distributed systems. If you&amp;#8217;re familiar with building applications with &lt;a href=&quot;https://en.wikipedia.org/wiki/Spring_Framework&quot; target=&quot;_blank&quot;&gt;Spring Framework&lt;/a&gt;, Spring Cloud builds upon some of its common building blocks.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Among the solutions provided by Spring Cloud, you will find tools for the following problems:&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;ulist&quot;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://12factor.net/config&quot; target=&quot;_blank&quot;&gt;Configuration management&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Service_discovery&quot; target=&quot;_blank&quot;&gt;Service discovery&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://martinfowler.com/bliki/CircuitBreaker.html&quot; target=&quot;_blank&quot;&gt;Circuit breakers&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Distributed_cache&quot; target=&quot;_blank&quot;&gt;Distributed sessions&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;spring-boot&quot;&gt;&lt;a class=&quot;anchor&quot; href=&quot;#spring-boot&quot;&gt;&lt;/a&gt;Spring Boot&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The great part about working with Spring Cloud is that it builds on the concepts of &lt;a href=&quot;http://projects.spring.io/spring-boot/&quot; target=&quot;_blank&quot;&gt;Spring Boot&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;For those of you who are new to Spring Boot, the name of the project means exactly what it says. You get all of the best things of the Spring Framework and ecosystem of projects, tuned to perfection, with minimal configuration, all ready for production.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;service-discovery-and-intelligent-routing&quot;&gt;&lt;a class=&quot;anchor&quot; href=&quot;#service-discovery-and-intelligent-routing&quot;&gt;&lt;/a&gt;Service Discovery and Intelligent Routing&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Each service has a dedicated purpose in a microservices architecture. When building a microservices architecture on Spring Cloud, there are a few primary concerns to deal with first. The first two microservices you will want to create are the &lt;strong&gt;Configuration Service&lt;/strong&gt;, and the &lt;strong&gt;Discovery Service&lt;/strong&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;imageblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;  &lt;p&gt;&lt;span class=&quot;image&quot;&gt;&lt;img src=&quot;http://i.imgur.com/Dc6xjwd.png&quot; alt=&quot;Microservice Configuration&quot; style=&quot;width:100%;max-width:600px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The graphic above illustrates a 4-microservice setup, with the connections between them indicating a dependency.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The configuration service sits at the top, in yellow, and is depended on by the other microservices. The discovery service sits at the bottom, in blue, and also is depended upon by the other microservices.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;In green, we have two microservices that deal with a part of the domain of the example application I will use throughout this blog series: movies and recommendations.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;configuration-service&quot;&gt;&lt;a class=&quot;anchor&quot; href=&quot;#configuration-service&quot;&gt;&lt;/a&gt;Configuration Service&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The configuration service is a vital component of any microservices architecture. Based on the &lt;a href=&quot;http://12factor.net/config&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;twelve-factor app&lt;/strong&gt;&lt;/a&gt; methodology, configurations for your microservice applications should be stored in the environment and not in the project.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The configuration service is essential because it handles the configurations for all of the services through a simple point-to-point service call to retrieve those configurations. The advantages of this are multi-purpose.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Let&#39;s assume that we have multiple deployment environments. If we have a staging environment and a production environment, configurations for those environments will be different. A configuration service might have a dedicated Git repository for the configurations of that environment. None of the other environments will be able to access this configuration, it is available only to the configuration service running in that environment.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;imageblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;  &lt;p&gt;&lt;span class=&quot;image&quot;&gt;&lt;img src=&quot;http://i.imgur.com/J7FazPH.png&quot; alt=&quot;Microservice Configuration 2&quot; style=&quot;width:100%;max-width:900px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;a name=&#39;more&#39;&gt;&lt;/a&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;When the configuration service starts up, it will reference the path to those configuration files and begin to serve them up to the microservices that request those configurations. Each microservice can have their configuration file configured to the specifics of the environment that it is running in. In doing this, the configuration is both externalized and centralized in one place that can be version-controlled and revised without having to restart a service to change a configuration.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;With management endpoints available from Spring Cloud, you can make a configuration change in the environment and signal a refresh to the discovery service that will force all consumers to fetch the new configurations.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;discovery-service&quot;&gt;&lt;a class=&quot;anchor&quot; href=&quot;#discovery-service&quot;&gt;&lt;/a&gt;Discovery Service&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The discovery service is another vital component of our microservice architecture. The discovery service handles maintaining a list of service instances that are available for work within a cluster. Within applications, service-to-service calls are made using clients. For this example project, I used &lt;a href=&quot;https://github.com/spring-cloud-samples/feign-eureka&quot; target=&quot;_blank&quot;&gt;Spring Cloud Feign&lt;/a&gt;, a client-based API for RESTful microservices that originated from the &lt;a href=&quot;https://github.com/spring-cloud-samples/feign-eureka&quot; target=&quot;_blank&quot;&gt;Netflix OSS project&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;listingblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;CodeMirror&quot; data-lang=&quot;text/x-java&quot;&gt;@FeignClient(&quot;movie&quot;)&lt;br /&gt;public interface MovieClient {&lt;br /&gt;    @RequestMapping(method = RequestMethod.GET, value = &quot;/movies&quot;)&lt;br /&gt;    PagedResources&lt;User&gt; findAll();&lt;br /&gt;&lt;br /&gt;    @RequestMapping(method = RequestMethod.GET, value = &quot;/movies/{id}&quot;)&lt;br /&gt;    Movie findById(@RequestParam(&quot;id&quot;) String id);&lt;br /&gt;&lt;br /&gt;    @RequestMapping(method = RequestMethod.POST, value = &quot;/movies&quot;,&lt;br /&gt;      produces = MediaType.APPLICATION_JSON_VALUE)&lt;br /&gt;    void createMovie(@RequestBody Movie movie);&lt;br /&gt;}&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;In the code example above, I am creating a Feign client that maps to the REST API methods that are exposed by the movie service. Using the &lt;code&gt;@FeignClient&lt;/code&gt; annotation, I first specify that I want to create a client API for the &lt;code&gt;movie&lt;/code&gt; microservice. Next I specify the mappings of the service that I want to consume. I do this by declaring a URL pattern over the methods that describes a route for a REST API.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The wonderfully easy part of creating Feign clients is that all I need to know is the ID of the service that I would like to create a client on. The URL of the service is automatically configured at runtime because each microservice in the cluster will register with the discovery service with its &lt;code&gt;serviceId&lt;/code&gt; at startup.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The same is true for all other services of my microservice architecture. All I need to know is the &lt;code&gt;serviceId&lt;/code&gt; of the service I want to communicate with, and everything else will be autowired by Spring.&lt;/p&gt;&lt;/div&gt; &lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;api-gateway&quot;&gt;&lt;a class=&quot;anchor&quot; href=&quot;#api-gateway&quot;&gt;&lt;/a&gt;API Gateway&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The API gateway service is another vital component if we are going to create a cluster of services managing their own domain entities. The green hexagons below are our data-driven services that manage their own domain entities and even their own databases. By adding an API gateway service, we can create a proxy of each API route that are exposed by the green services.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;imageblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;  &lt;p&gt;&lt;span class=&quot;image&quot;&gt;&lt;img src=&quot;http://i.imgur.com/JVSGMfY.png&quot; alt=&quot;Microservice API Gateway&quot; style=&quot;width:100%;max-width:500px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Let&amp;#8217;s assume that both the recommendation service and the movie service expose their own REST API over the domain entities that they manage. The API gateway will discover these services through the discovery service and inject a proxy-based route of the API methods from the other services. In this way, both the recommendation and movie microservice will have a full definition of routes available locally from all the microservices that expose a REST API. The API Gateway will re-route the request to the service instances that own the route being requested through HTTP.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;example-project&quot;&gt;&lt;a class=&quot;anchor&quot; href=&quot;#example-project&quot;&gt;&lt;/a&gt;Example Project&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/kbastani/spring-cloud-microservice-example&quot; target=&quot;_blank&quot;&gt;I&amp;#8217;ve put together an example project&lt;/a&gt; that demonstrates an end-to-end cloud-native platform using Spring Cloud for building a practical microservices architecture.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Demonstrated concepts:&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;ulist&quot;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Integration testing using Docker&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Polyglot persistence&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Microservice architecture&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Service discovery&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;API gateway&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;docker&quot;&gt;&lt;a class=&quot;anchor&quot; href=&quot;#docker&quot;&gt;&lt;/a&gt;Docker&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Each service is built and deployed using Docker. End-to-end integration testing can be done on a developer&amp;#8217;s machine using Docker compose.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;polyglot-persistence&quot;&gt;&lt;a class=&quot;anchor&quot; href=&quot;#polyglot-persistence&quot;&gt;&lt;/a&gt;Polyglot Persistence&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;One of the core concepts of this example project is how polyglot persistence can be approached in practice. Microservices in the project use their own database while integrating with the data from other services through REST or a message bus. For example, you could have a microservice for each of the following databases.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;ulist&quot;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Neo4j (graph)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;MongoDB (document)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;MySQL (relational)&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;microservice-architecture&quot;&gt;&lt;a class=&quot;anchor&quot; href=&quot;#microservice-architecture&quot;&gt;&lt;/a&gt;Microservice architecture&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;This example project demonstrates how to build a new application using microservices, as opposed to a monolith-first strategy. Since each microservice in the project is a module of a single parent project, developers have the advantage of being able to run and develop with each microservice running on their local machine. Adding a new microservice is easy, as the discovery microservice will automatically discover new services running on the cluster.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;service-discovery&quot;&gt;&lt;a class=&quot;anchor&quot; href=&quot;#service-discovery&quot;&gt;&lt;/a&gt;Service discovery&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;This project contains two discovery services, one on &lt;a href=&quot;https://github.com/Netflix/eureka&quot; target=&quot;_blank&quot;&gt;Netflix Eureka&lt;/a&gt;, and the other uses &lt;a href=&quot;https://consul.io/&quot; target=&quot;_blank&quot;&gt;Consul from Hashicorp&lt;/a&gt;. Having multiple discovery services provides the opportunity to use one (Consul) as a DNS provider for the cluster, and the other (Eureka) as a proxy-based API gateway.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;api-gateway-2&quot;&gt;&lt;a class=&quot;anchor&quot; href=&quot;#api-gateway-2&quot;&gt;&lt;/a&gt;API gateway&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Each microservice will coordinate with Eureka to retrieve API routes for the entire cluster. Using this strategy each microservice in a cluster can be load balanced and exposed through one API gateway. Each service will automatically discover and route API requests to the service that owns the route. This proxying technique is equally helpful when developing user interfaces, as the full API of the platform is available through its own host as a proxy.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;docker-demo&quot;&gt;&lt;a class=&quot;anchor&quot; href=&quot;#docker-demo&quot;&gt;&lt;/a&gt;Docker Demo&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The example project uses Docker to build a container image of each of our microservices as a part of the Maven build process. We can easily orchestrate the full microservice cluster on our own machine using Docker compose.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;getting-started&quot;&gt;&lt;a class=&quot;anchor&quot; href=&quot;#getting-started&quot;&gt;&lt;/a&gt;Getting Started&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;To get started, visit the GitHub repository for this example project.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;literalblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre&gt;&lt;a href=&quot;https://github.com/kbastani/spring-cloud-microservice-example&quot; target=&quot;_blank&quot;&gt;https://github.com/kbastani/spring-cloud-microservice-example&lt;/a&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Clone or fork the project and download the repository to your machine. After downloading, you will need to use both Maven and Docker to compile and build the images locally.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;sect3&quot;&gt;&lt;h4 id=&quot;download-docker&quot;&gt;&lt;a class=&quot;anchor&quot; href=&quot;#download-docker&quot;&gt;&lt;/a&gt;Download Docker&lt;/h4&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;First, download Docker if you haven&amp;#8217;t already. Follow the instructions &lt;a href=&quot;https://docs.docker.com/installation/&quot; target=&quot;_blank&quot;&gt;found here&lt;/a&gt;, to get Docker up and running on your development machine.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;You will also need to install &lt;a href=&quot;https://docs.docker.com/compose/&quot; target=&quot;_blank&quot;&gt;Docker Compose&lt;/a&gt;, the installation guide can be &lt;a href=&quot;https://docs.docker.com/compose/install/&quot; target=&quot;_blank&quot;&gt;found here&lt;/a&gt;. If you are using Mac OSX and boot2docker, make sure that you provision the boot2docker-vm on VirtualBox with at least 5GB of memory. The following command will allow you to do this.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;literalblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;CodeMirror&quot; data-lang=&quot;text/x-sh&quot;&gt;$ boot2docker init --memory=5000&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect3&quot;&gt;&lt;h4 id=&quot;requirements&quot;&gt;&lt;a class=&quot;anchor&quot; href=&quot;#requirements&quot;&gt;&lt;/a&gt;Requirements&lt;/h4&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The requirements for running this demo on your machine are found below.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;ulist&quot;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Maven 3&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Java 8&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Docker&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Docker Compose&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;building-the-project&quot;&gt;&lt;a class=&quot;anchor&quot; href=&quot;#building-the-project&quot;&gt;&lt;/a&gt;Building the project&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;To build the project, from the terminal, run the following command at the root of the project.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;literalblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;CodeMirror&quot; data-lang=&quot;text/x-sh&quot;&gt;$ mvn clean install&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;The project will then download all of the needed dependencies and compile each of the project artifacts. Each service will be built, and then a Maven Docker plugin will automatically build each of the images into your local Docker registry. Docker must be running and available from the command line where you run the &lt;code&gt;mvn clean install&lt;/code&gt; command for the build to succeed.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;After the project successfully builds, you&amp;#8217;ll see the following output:&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;literalblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;CodeMirror&quot; style=&quot;     max-width: 50em;     text-overflow:auto;     min-width: 50em;     overflow: scroll;&quot; data-lang=&quot;text/x-sh&quot;&gt;[INFO] ------------------------------------------------------------------------&lt;br /&gt;[INFO] Reactor Summary:&lt;br /&gt;[INFO]&lt;br /&gt;[INFO] spring-cloud-microservice-example-parent .......... SUCCESS [  0.268 s]&lt;br /&gt;[INFO] users-microservice ................................ SUCCESS [ 11.929 s]&lt;br /&gt;[INFO] discovery-microservice ............................ SUCCESS [  5.640 s]&lt;br /&gt;[INFO] api-gateway-microservice .......................... SUCCESS [  5.156 s]&lt;br /&gt;[INFO] recommendation-microservice ....................... SUCCESS [  7.732 s]&lt;br /&gt;[INFO] config-microservice ............................... SUCCESS [  4.711 s]&lt;br /&gt;[INFO] hystrix-dashboard ................................. SUCCESS [  4.251 s]&lt;br /&gt;[INFO] consul-microservice ............................... SUCCESS [  6.763 s]&lt;br /&gt;[INFO] movie-microservice ................................ SUCCESS [  8.359 s]&lt;br /&gt;[INFO] movies-ui ......................................... SUCCESS [ 15.833 s]&lt;br /&gt;[INFO] ------------------------------------------------------------------------&lt;br /&gt;[INFO] BUILD SUCCESS&lt;br /&gt;[INFO] ------------------------------------------------------------------------&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect2&quot;&gt;&lt;h3 id=&quot;start-the-cluster-with-docker-compose&quot;&gt;&lt;a class=&quot;anchor&quot; href=&quot;#start-the-cluster-with-docker-compose&quot;&gt;&lt;/a&gt;Start the Cluster with Docker Compose&lt;/h3&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Now that each of the images has been built successfully, we can using Docker Compose to spin up our cluster. I&amp;#8217;ve included a pre-configured Docker Compose yaml file with the project.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;From the project root, navigate to the &lt;code&gt;spring-cloud-microservice-example/docker&lt;/code&gt; directory.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Now, to startup the microservice cluster, run the following command:&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;literalblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;CodeMirror&quot; data-lang=&quot;text/x-sh&quot;&gt;$ docker-compose up&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;If everything is configured correctly, each of the container images we built earlier will be launched within their own VM container on Docker and networked for automatic service discovery. You will see a flurry of log output from each of the services as they begin their startup sequence. This might take a few minutes to complete, depending on the performance of the machine you&amp;#8217;re running this demo on.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Once the startup sequence is completed, you can navigate to the Eureka host and see which services have registered with the discovery service.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Copy and paste the following command into the terminal where Docker can be accessed using the &lt;code&gt;$DOCKER_HOST&lt;/code&gt; environment variable.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;literalblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;CodeMirror&quot; data-lang=&quot;text/x-sh&quot;&gt;$ open $(echo \&quot;$(echo $DOCKER_HOST)\&quot;|&lt;br /&gt;            \sed &#39;s/tcp:\/\//http:\/\//g&#39;|&lt;br /&gt;            \sed &#39;s/[0-9]\{4,\}/8761/g&#39;|&lt;br /&gt;            \sed &#39;s/\&quot;//g&#39;)&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;If Eureka correctly started up, a browser window will open to the location of the Eureka service&amp;#8217;s dashboard, as shown below.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span class=&quot;image&quot;&gt;&lt;img src=&quot;http://i.imgur.com/buABI3h.png&quot; alt=&quot;Eureka&quot; style=&quot;width:100%;max-width:600px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;We can see each of the service instances that are running and their status. We can then access one of the data-driven services, for example the &lt;code&gt;movie&lt;/code&gt; service.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;literalblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;CodeMirror&quot; data-lang=&quot;text/x-sh&quot;&gt;$ open $(echo \&quot;$(echo $DOCKER_HOST)/movie\&quot;|&lt;br /&gt;            \sed &#39;s/tcp:\/\//http:\/\//g&#39;|&lt;br /&gt;            \sed &#39;s/[0-9]\{4,\}/10000/g&#39;|&lt;br /&gt;            \sed &#39;s/\&quot;//g&#39;)&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;This command will navigate to the API gateway&amp;#8217;s endpoint and proxy to the movie service&amp;#8217;s REST API endpoints. These REST APIs have been configured to use &lt;a href=&quot;https://en.wikipedia.org/wiki/HATEOAS&quot; target=&quot;_blank&quot;&gt;HATEOAS&lt;/a&gt;, which supports the auto-discovery of all of the service&amp;#8217;s functionality as embedded links.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;literalblock&quot;&gt;&lt;div class=&quot;content&quot;&gt;&lt;pre class=&quot;CodeMirror&quot;  style=&quot;     max-width: 50em;     text-overflow:auto;     min-width: 50em;     overflow: scroll;&quot; data-lang=&quot;application/json&quot;&gt;{&lt;br /&gt;  &quot;_links&quot; : {&lt;br /&gt;    &quot;self&quot; : {&lt;br /&gt;      &quot;href&quot; : &quot;http://192.168.59.103:10000/movie&quot;&lt;br /&gt;    },&lt;br /&gt;    &quot;resume&quot; : {&lt;br /&gt;      &quot;href&quot; : &quot;http://192.168.59.103:10000/movie/resume&quot;&lt;br /&gt;    },&lt;br /&gt;    &quot;pause&quot; : {&lt;br /&gt;      &quot;href&quot; : &quot;http://192.168.59.103:10000/movie/pause&quot;&lt;br /&gt;    },&lt;br /&gt;    &quot;restart&quot; : {&lt;br /&gt;      &quot;href&quot; : &quot;http://192.168.59.103:10000/movie/restart&quot;&lt;br /&gt;    },&lt;br /&gt;    &quot;metrics&quot; : {&lt;br /&gt;      &quot;href&quot; : &quot;http://192.168.59.103:10000/movie/metrics&quot;&lt;br /&gt;    },&lt;br /&gt;    &quot;env&quot; : [ {&lt;br /&gt;      &quot;href&quot; : &quot;http://192.168.59.103:10000/movie/env&quot;&lt;br /&gt;    }, {&lt;br /&gt;      &quot;href&quot; : &quot;http://192.168.59.103:10000/movie/env&quot;&lt;br /&gt;    } ],&lt;br /&gt;    &quot;archaius&quot; : {&lt;br /&gt;      &quot;href&quot; : &quot;http://192.168.59.103:10000/movie/archaius&quot;&lt;br /&gt;    },&lt;br /&gt;    &quot;beans&quot; : {&lt;br /&gt;      &quot;href&quot; : &quot;http://192.168.59.103:10000/movie/beans&quot;&lt;br /&gt;    },&lt;br /&gt;    &quot;configprops&quot; : {&lt;br /&gt;      &quot;href&quot; : &quot;http://192.168.59.103:10000/movie/configprops&quot;&lt;br /&gt;    },&lt;br /&gt;    &quot;trace&quot; : {&lt;br /&gt;      &quot;href&quot; : &quot;http://192.168.59.103:10000/movie/trace&quot;&lt;br /&gt;    },&lt;br /&gt;    &quot;info&quot; : {&lt;br /&gt;      &quot;href&quot; : &quot;http://192.168.59.103:10000/movie/info&quot;&lt;br /&gt;    },&lt;br /&gt;    &quot;health&quot; : {&lt;br /&gt;      &quot;href&quot; : &quot;http://192.168.59.103:10000/movie/health&quot;&lt;br /&gt;    },&lt;br /&gt;    &quot;hystrix.stream&quot; : {&lt;br /&gt;      &quot;href&quot; : &quot;http://192.168.59.103:10000/movie/hystrix.stream&quot;&lt;br /&gt;    },&lt;br /&gt;    &quot;routes&quot; : {&lt;br /&gt;      &quot;href&quot; : &quot;http://192.168.59.103:10000/movie/routes&quot;&lt;br /&gt;    },&lt;br /&gt;    &quot;dump&quot; : {&lt;br /&gt;      &quot;href&quot; : &quot;http://192.168.59.103:10000/movie/dump&quot;&lt;br /&gt;    },&lt;br /&gt;    &quot;refresh&quot; : {&lt;br /&gt;      &quot;href&quot; : &quot;http://192.168.59.103:10000/movie/refresh&quot;&lt;br /&gt;    },&lt;br /&gt;    &quot;mappings&quot; : {&lt;br /&gt;      &quot;href&quot; : &quot;http://192.168.59.103:10000/movie/mappings&quot;&lt;br /&gt;    },&lt;br /&gt;    &quot;autoconfig&quot; : {&lt;br /&gt;      &quot;href&quot; : &quot;http://192.168.59.103:10000/movie/autoconfig&quot;&lt;br /&gt;    }&lt;br /&gt;  }&lt;br /&gt;}&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;conclusion&quot;&gt;&lt;a class=&quot;anchor&quot; href=&quot;#conclusion&quot;&gt;&lt;/a&gt;Conclusion&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;This has been the first part in a multi-part series about building microservice architectures with Spring Cloud and Docker. In this blog post, we went over the following concepts:&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;ulist&quot;&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Service Discovery&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Externalized Configuration&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;API Gateway&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Service Orchestration with Docker Compose&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;In the next blog post, we will go over how to build application front-ends that integrate with our backend services. We will also take a look at a use case for &lt;a href=&quot;http://martinfowler.com/bliki/PolyglotPersistence.html&quot; target=&quot;_blank&quot;&gt;polyglot persistence&lt;/a&gt;, using both MySQL (relational) and Neo4j (graph).&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;Special thanks&lt;/h2&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;I want to give special thanks to &lt;a href=&quot;http://www.twitter.com/starbuxman&quot; target=&quot;_blank&quot;&gt;Josh Long&lt;/a&gt; and the rest of the Spring team for giving me the chance to learn first-hand about the many wonderful things that the Spring Framework has to offer. Without Josh&#39;s mentorship I would not be able to put into words all of the amazing things that the Spring ecosystem has to offer.&lt;/p&gt;&lt;p&gt;Many of the great open source tools, like Spring Cloud, wouldn&#39;t be possible without the thought leadership from people like &lt;a href=&quot;https://twitter.com/adrianco&quot; target=&quot;_blank&quot;&gt;Adrian Cockcroft&lt;/a&gt; (Netflix OSS), &lt;a href=&quot;https://twitter.com/martinfowler&quot; target=&quot;_blank&quot;&gt;Martin Fowler&lt;/a&gt; (everything), &lt;a href=&quot;https://twitter.com/samnewman&quot; target=&quot;_blank&quot;&gt;Sam Newman&lt;/a&gt; (&lt;a href=&quot;http://shop.oreilly.com/product/0636920033158.do&quot; target=&quot;_blank&quot;&gt;O&#39;Reilly&#39;s Building Microservices&lt;/a&gt;), &lt;a href=&quot;https://twitter.com/iansrobinson&quot; target=&quot;_blank&quot;&gt;Ian Robinson&lt;/a&gt; (consumer driven contracts), &lt;a href=&quot;https://twitter.com/crichardson&quot; target=&quot;_blank&quot;&gt;Chris Richardson&lt;/a&gt; (Cloud Foundry) and the many others who have helped to make the world of open source software what it is today.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><enclosure type='image/png' url='http://i.imgur.com/Dc6xjwd.png' length='0'/><enclosure type='image/png' url='http://i.imgur.com/J7FazPH.png' length='0'/><enclosure type='image/png' url='http://i.imgur.com/JVSGMfY.png' length='0'/><link>https://www.kennybastani.com/2015/07/spring-cloud-docker-microservices.html</link><author>noreply@blogger.com (Kenny Bastani)</author><thr:total>0</thr:total></item><item><guid isPermaLink="false">tag:blogger.com,1999:blog-6300367579216018061.post-2980636106907343614</guid><pubDate>Thu, 14 May 2015 08:24:00 +0000</pubDate><atom:updated>2019-12-10T07:13:51.227-08:00</atom:updated><category domain="http://www.blogger.com/atom/ns#">architecture</category><category domain="http://www.blogger.com/atom/ns#">data science</category><category domain="http://www.blogger.com/atom/ns#">graph analysis</category><category domain="http://www.blogger.com/atom/ns#">microservices</category><category domain="http://www.blogger.com/atom/ns#">monoliths</category><category domain="http://www.blogger.com/atom/ns#">neo4j</category><category domain="http://www.blogger.com/atom/ns#">open source software</category><category domain="http://www.blogger.com/atom/ns#">spring boot</category><title>Using Graph Analysis to Decompose Monoliths into Microservices with Neo4j</title><description>&lt;p&gt;This blog post will take some of my learnings in developing &lt;a href=&quot;http://martinfowler.com/articles/microservices.html&quot; target=&quot;_blank&quot;&gt;microservices&lt;/a&gt; and apply a graph processing technique to simulate the &lt;a href=&quot;http://www.infoq.com/articles/microservices-intro&quot; target=&quot;_blank&quot;&gt;decomposition of service architectures into microservices&lt;/a&gt;.&lt;/p&gt;&lt;h2 id=&quot;what-is-a-microservice-&quot;&gt;What is a microservice?&lt;/h2&gt;&lt;p&gt;Microservices are an extension of SOA principles that are better suited for agile software development. A microservice architecture usually starts from decomposing monolithic applications into services that are cheaper to evolve and easier to throw away. The guiding theme behind this movement is to decentralize change management and reduce conflicts that tend to cause roadblocks in an SOA-based platform.&lt;/p&gt;&lt;h2 id=&quot;using-data-to-design-better-technology-platforms&quot;&gt;Using Data to Design Better Technology Platforms&lt;/h2&gt;&lt;p&gt;Microservices aren&#39;t new. The pattern has been adopted at many software companies.&lt;/p&gt;&lt;p&gt;When companies on an SOA add new features to their platform, there tends to be a fair amount of conflicts between service teams. Certain services in the SOA become more relied upon by other services or applications in the platform.&lt;/p&gt;&lt;p&gt;What I&#39;ve seen is that services tend towards growth rather than decomposing into smaller units. It&#39;s far easier to add features to existing services than to create new services that require operational support. Every new service requires a focus on deployment and configurations. The complexity can be tough to support with rigid processes and a lack of focus on automation.&lt;/p&gt;&lt;p&gt;Jumping head first into microservices is a major commitment. A monolith will have highly centralized components that will gain more mass as new microservices are born, adding additional complexity with each service call to replace modules or add functionality. It&#39;s important to analyze these connections to understand which services in an SOA are becoming more depended on.&lt;/p&gt;&lt;h1 id=&quot;measuring-service-centrality&quot;&gt;Measuring Service Centrality&lt;/h1&gt;&lt;p&gt;My time spent using graphs to analyze data has given me a great tool for understanding how to use data to drive decisions on decomposing an SOA. The first metric that I will use is network centrality. This metric measures how centralized a service is within a network of dependencies.&lt;/p&gt;&lt;p&gt;The whole idea here is to determine what components in a service are good candidates for a microservice. This can be determined by finding a component that will be the highest contributor to decreasing the overall centrality of a service, once removed.&lt;/p&gt;&lt;p&gt;The &lt;a href=&quot;http://en.wikipedia.org/wiki/Centrality&quot; target=&quot;_blank&quot;&gt;graph metric for centrality&lt;/a&gt; is a great starting point to analyze how services are gaining mass and how best to decompose services.&lt;/p&gt;&lt;h3 id=&quot;decomposition-strategy&quot;&gt;Decomposition Strategy&lt;/h3&gt;&lt;p&gt;The decomposition strategy that I would like to demonstrate is based on &lt;a href=&quot;http://en.wikipedia.org/wiki/Resource-oriented_architecture&quot; target=&quot;_blank&quot;&gt;RESTful web services that manage a set of resources&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Each service will expose a set of REST API methods to interact with the resources of the domain. The graph data model that will be used to calculate centrality will be represented by relationships of service to service interactions.&lt;/p&gt;&lt;p&gt;Graphs are a great way to model the resources of a domain and their interactions. Below I&#39;ve sketched out a domain model for an eCommerce website based on &lt;a href=&quot;http://microservices.io/patterns/monolithic.html&quot;&gt;an example&lt;/a&gt; by &lt;a href=&quot;https://twitter.com/crichardson&quot; target=&quot;_blank&quot;&gt;Chris Richardson&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/4w4xEgN.png&quot; alt=&quot;Store front domain resources&quot;&gt;&lt;/p&gt;&lt;p&gt;This domain model has a set of resources which are represented by their label. Those resources are:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Customer&lt;/li&gt;&lt;li&gt;Order&lt;/li&gt;&lt;li&gt;Account&lt;/li&gt;&lt;li&gt;Address&lt;/li&gt;&lt;li&gt;Product&lt;/li&gt;&lt;li&gt;Warehouse&lt;/li&gt;&lt;li&gt;Credit Card&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;In a monolithic architecture all of our services will be contained in a single project, for example a WAR, with modules representing each service.&lt;/p&gt;&lt;p&gt;From Chris&#39;s example, we have the following deployment model:&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/XdW2dZF.png&quot; alt=&quot;Deployment model&quot;&gt;&lt;/p&gt;&lt;p&gt;From this example deployment model I&#39;ve mapped the calls from each module to resources in the domain. That ends up looking like this:&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/fF2X6HY.png?1&quot; alt=&quot;Service to resource mappings&quot;&gt;&lt;/p&gt;&lt;p&gt;As systems scale and dependencies grow, they become harder for us to understand. However, these mappings can be tremendously valuable to understand which service is best suited to first become a microservice.&lt;/p&gt;&lt;h3 id=&quot;mapping-stories-to-release-artifacts&quot;&gt;Mapping Stories to Release Artifacts&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Conway%27s_law&quot;&gt;Conway&#39;s law&lt;/a&gt; states that organizations are constrained to produce systems that mirror their communication structures. In order to make the jump to microservices we need to scale teams horizontally and not vertically.  To do this well, we need to figure out how to split applications into independently releasable containers. One principle metric to be aware of is the number of business stories that are affected per release. Each of these stories have a certain level of functionality that drives revenue for the business. This can help determine which features are more valuable in terms of revenue than others.&lt;/p&gt;&lt;p&gt;Let&#39;s take for example the following story.&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;As a user, I want to be able to browse the product catalog so that I can find products I want to buy.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;If the product catalog becomes unavailable to users of the website, there will be an impact to revenue. This shows that not all user stories have the same business value.&lt;/p&gt;&lt;p&gt;Ideally we want to find ways to empower single teams to be accountable for single stories. This way, if there is an outage that affects a story, teams will have more autonomy to bring that functionality back online.&lt;/p&gt;&lt;h3 id=&quot;dependency-graph&quot;&gt;Dependency Graph&lt;/h3&gt;&lt;p&gt;Below you will find an example graph data model of the service dependencies shared between containers, services, resources, and user stories that describe product features.&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/Kfa8Jfn.png&quot; alt=&quot;Service Dependency Model&quot;&gt;&lt;/p&gt;&lt;p&gt;In order to generate a rich dataset to analyze, I chose to use the concept of a user story as an added dimension to the dependency graph. User stories do well to group together a set of features. These features act as a good boundary criteria for determining how to make components more modular from a business value perspective.&lt;/p&gt;&lt;p&gt;The relationships between concepts in this dependency graph are driven by the following rules:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;User stories depend on domain resources&lt;/li&gt;&lt;li&gt;Domain resources are owned by services&lt;/li&gt;&lt;li&gt;Services are managed by teams&lt;/li&gt;&lt;li&gt;A service belongs to a deployment container&lt;/li&gt;&lt;/ul&gt;&lt;h3 id=&quot;interactive-neo4j-graphgist-example&quot;&gt;Interactive Neo4j GraphGist Example&lt;/h3&gt;&lt;p&gt;I&#39;ve put together a &lt;a href=&quot;https://portal.graphgist.org/graph_gist_candidates/using-graph-analysis-to-design-microservice-architectures-in-the-cloud-candidate-2&quot; target=&quot;_blank&quot;&gt;step by step walkthrough&lt;/a&gt; of how you can use Neo4j to do graph analysis to functionally decompose a monolithic application into microservices.&lt;/p&gt;&lt;p&gt;In the coming months I will be focusing a lot on this topic with demos that revolve around how to build great microservice architectures using &lt;a href=&quot;http://projects.spring.io/spring-boot/&quot; target=&quot;_blank&quot;&gt;Spring boot&lt;/a&gt;.&lt;/p&gt;</description><enclosure type='image/png' url='http://i.imgur.com/fF2X6HY.png' length='0'/><link>https://www.kennybastani.com/2015/05/graph-analysis-microservice-neo4j.html</link><author>noreply@blogger.com (Kenny Bastani)</author><thr:total>0</thr:total></item><item><guid isPermaLink="false">tag:blogger.com,1999:blog-6300367579216018061.post-4907209467989693658</guid><pubDate>Tue, 10 Mar 2015 08:01:00 +0000</pubDate><atom:updated>2015-12-08T00:38:05.643-08:00</atom:updated><category domain="http://www.blogger.com/atom/ns#">apache spark</category><category domain="http://www.blogger.com/atom/ns#">docker</category><category domain="http://www.blogger.com/atom/ns#">docker compose</category><category domain="http://www.blogger.com/atom/ns#">docker swarm</category><category domain="http://www.blogger.com/atom/ns#">graphx</category><category domain="http://www.blogger.com/atom/ns#">Mazerunner</category><category domain="http://www.blogger.com/atom/ns#">neo4j</category><category domain="http://www.blogger.com/atom/ns#">spark neo4j</category><category domain="http://www.blogger.com/atom/ns#">tutorial</category><title>Getting Started with Apache Spark and Neo4j Using Docker Compose </title><description> &lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center; margin-right: 1em;&quot;&gt;&lt;a href=&quot;http://i.imgur.com/SPwFYVD.png&quot; imageanchor=&quot;1&quot; style=&quot;clear: left; float: right; margin-bottom: 1em; margin-right: 1em; padding-left: 2em;&quot;&gt;&lt;img border=&quot;0&quot; style=&quot;max-width: 300px;&quot; src=&quot;http://i.imgur.com/SPwFYVD.png&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;p&gt;I&#39;ve received a lot of interest in &lt;a href=&quot;http://www.kennybastani.com/2014/11/using-apache-spark-and-neo4j-for-big.html&quot;&gt;Neo4j Mazerunner&lt;/a&gt; since first announcing it a few months ago. People from around the world have reached out to me and are excited about the possibilities of using &lt;a href=&quot;https://github.com/kbastani/neo4j-mazerunner&quot;&gt;Apache Spark and Neo4j together&lt;/a&gt;. From authors who are writing new books about big data to PhD researchers who need it to solve the world&#39;s most challenging problems.  &lt;p&gt;I&#39;m glad to see such a wide range of needs for a simple integration like this. Spark and Neo4j are two great open source projects that are focusing on doing one thing very well. Integrating both products together makes for an awesome result.&lt;/p&gt; &lt;h2&gt;Less is always more, simpler is always better.&lt;/h2&gt;&lt;p&gt;Both &lt;a href=&quot;https://spark.apache.org/&quot;&gt;Apache Spark&lt;/a&gt; and &lt;a href=&quot;http://www.neo4j.com&quot;&gt;Neo4j&lt;/a&gt; are two tremendously useful tools. I&#39;ve seen how both of these two tools give their users a way to transform problems that start out both large and complex into problems that become &lt;i&gt;simpler and easier to solve&lt;/i&gt;. That&#39;s what the companies behind these platforms are getting at. They are two sides of the same coin.   &lt;p&gt;One tool solves for scaling the size, complexity, and retrieval of data, while the other is solving for the complexity of processing the enormity of data by distributed computation at scale. Both of these products are achieving this without sacrificing ease of use.&lt;/p&gt; &lt;p&gt;Inspired by this, I&#39;ve been working to make the integration in &lt;a href=&quot;https://registry.hub.docker.com/u/kbastani/neo4j-graph-analytics/&quot;&gt;Neo4j Mazerunner&lt;/a&gt; easier to install and deploy. I believe I&#39;ve taken a step forward in this and I&#39;m excited to announce it in this blog post.&lt;/p&gt; &lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;http://i.imgur.com/6DanVHg.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; display: block; margin-bottom: 2em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; style=&quot;height: auto; max-width: 42em; vertical-align: middle; width: 100%;&quot; src=&quot;http://i.imgur.com/6DanVHg.png&quot; /&gt;&lt;/a&gt;&lt;/div&gt; &lt;a name=&#39;more&#39;&gt;&lt;/a&gt; &lt;h2&gt;Announcing Spark Neo4j for Docker&lt;/h2&gt; &lt;p&gt;I&#39;ll start by saying that I&#39;m not announcing yet another new open source project. &lt;a href=&quot;https://registry.hub.docker.com/u/kbastani/spark-neo4j/&quot;&gt;Spark Neo4j&lt;/a&gt; is a Docker image that uses the new &lt;a href=&quot;https://docs.docker.com/compose/&quot;&gt;Compose&lt;/a&gt; tool to make it easier to deploy and eventually scale both Neo4j and Spark into their own clusters using &lt;a href=&quot;https://docs.docker.com/swarm/&quot;&gt;Docker Swarm&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Docker Compose is something I&#39;ve been waiting awhile for. It&#39;s one pillar of Docker&#39;s answer to cluster computing using containers. This previously not so easy thing to do on Docker is now completely doable. In a simple way. That&#39;s really exciting.&lt;/p&gt; &lt;p&gt;Now let&#39;s get on to this business of processing graphs.&lt;/p&gt; &lt;h2&gt;Installing Spark Neo4j&lt;/h2&gt; &lt;p&gt;The tutorial below is meant for Mac users. If you&#39;re on Linux, I&#39;ve got you covered: &lt;a href=&quot;https://github.com/kbastani/spark-neo4j/wiki/Linux-Install-Guide&quot;&gt;Spark Neo4j Linux install guide&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;This tutorial will walk you through:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Setting up Spark Neo4j cluster using Docker&lt;/li&gt;&lt;li&gt;Streaming log output from Spark and Neo4j&lt;/li&gt;&lt;li&gt;Using Spark GraphX to calculate PageRank and Closeness Centrality on a celebrity graph&lt;/li&gt;&lt;li&gt;Querying the results in Neo4j to find the most influential actor in Hollywood&lt;/li&gt;&lt;/ul&gt;&lt;h3 id=&quot;requirements&quot;&gt;Requirements&lt;/h3&gt;&lt;p&gt;Get Docker:  &lt;a href=&quot;https://docs.docker.com/installation/&quot;&gt;https://docs.docker.com/installation/&lt;/a&gt;&lt;/p&gt;&lt;p&gt;After you&amp;#39;ve installed Docker on Mac OSX with boot2docker, you&amp;#39;ll need to make sure that the &lt;code&gt;DOCKER_HOST&lt;/code&gt; environment variable points to the URL of the Docker daemon.&lt;/p&gt;&lt;pre class=&quot;cm-s-pastel-on-dark CodeMirror&quot; data-lang=&quot;text/x-sh&quot;&gt;&lt;br /&gt;$ export DOCKER_HOST=tcp://$(boot2docker ip 2&amp;gt;/dev/null):2375&lt;br /&gt;&lt;/pre&gt;&lt;blockquote&gt;&lt;p&gt;Neo4j Spark uses the &lt;code&gt;DOCKER_HOST&lt;/code&gt; environment variable to manage multiple containers with &lt;a href=&quot;https://docs.docker.com/compose/&quot;&gt;Docker Compose&lt;/a&gt;.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;Run the following command in your current shell to generate the other necessary Docker configurations:&lt;/p&gt;&lt;pre class=&quot;cm-s-pastel-on-dark CodeMirror&quot; data-lang=&quot;text/x-sh&quot;&gt;&lt;br /&gt;$ $(boot2docker shellinit)&lt;/pre&gt;&lt;blockquote&gt;&lt;p&gt;You&amp;#39;ll need to repeat this process if you open a new shell. Spark Neo4j requires the following environment variables: &lt;code&gt;DOCKER_HOST&lt;/code&gt;, &lt;code&gt;DOCKER_CERT_PATH&lt;/code&gt;, and &lt;code&gt;DOCKER_TLS_VERIFY&lt;/code&gt;.&lt;/p&gt;&lt;/blockquote&gt;&lt;h4 id=&quot;start-the-spark-neo4j-cluster&quot;&gt;Start the Spark Neo4j cluster&lt;/h4&gt;&lt;p&gt;In your current shell, run the following command to download and launch the Spark Neo4j cluster.&lt;/p&gt;&lt;pre class=&quot;cm-s-pastel-on-dark CodeMirror&quot; data-lang=&quot;text/x-sh&quot;&gt;&lt;br /&gt;$ docker run  --env DOCKER_HOST=$DOCKER_HOST \&lt;br /&gt;              --env DOCKER_TLS_VERIFY=$DOCKER_TLS_VERIFY \&lt;br /&gt;              --env DOCKER_CERT_PATH=/docker/cert \&lt;br /&gt;              -v $DOCKER_CERT_PATH:/docker/cert \&lt;br /&gt;              -ti kbastani/spark-neo4j up -d&lt;br /&gt;&lt;/pre&gt;&lt;blockquote&gt;&lt;p&gt;This command will pull down multiple docker images the first time you run it. Grab a beer or coffee. You&amp;#39;ll soon be taking over the world with your new found graph processing skills.&lt;/p&gt;&lt;/blockquote&gt;&lt;h4 id=&quot;stream-log-output-from-the-cluster&quot;&gt;Stream log output from the cluster&lt;/h4&gt;&lt;p&gt;After the Docker images are installed and configured, you will be able to access the Neo4j browser. To know whether or not Neo4j has been started, you can stream the log output from your Spark Neo4j cluster by running this command in your current shell:&lt;/p&gt;&lt;pre class=&quot;cm-s-pastel-on-dark CodeMirror&quot; data-lang=&quot;text/x-sh&quot;&gt;$ docker run  --env DOCKER_HOST=$DOCKER_HOST \&lt;br /&gt;              --env DOCKER_TLS_VERIFY=$DOCKER_TLS_VERIFY \&lt;br /&gt;              --env DOCKER_CERT_PATH=/docker/cert \&lt;br /&gt;              -v $DOCKER_CERT_PATH:/docker/cert \&lt;br /&gt;              -ti kbastani/spark-neo4j logs graphdb&lt;br /&gt;&lt;/pre&gt;&lt;p&gt;This command will stream the log output from Neo4j to your current shell.&lt;/p&gt; &lt;pre class=&quot;cm-s-pastel-on-dark CodeMirror&quot; style=&quot;word-wrap: initial; overflow: auto;&quot; data-lang=&quot;text/x-sh&quot;&gt;&lt;br /&gt;...&lt;br /&gt;graphdb_1    | 20:18:36.736 [main] INFO  o.e.jetty.server.ServerConnector - Started ServerConnector@788ddc1f{HTTP/1.1}{0.0.0.0:7474}&lt;br /&gt;graphdb_1    | 20:18:36.908 [main] INFO  o.e.jetty.server.ServerConnector - Started ServerConnector@24d61e4{SSL-HTTP/1.1}{0.0.0.0:7473}&lt;br /&gt;graphdb_1    | 2015-03-08 20:18:36.908+0000 INFO  [API] Server started on: http://0.0.0.0:7474/&lt;br /&gt;graphdb_1    | 2015-03-08 20:18:36.909+0000 INFO  [API] Remote interface ready and available at [http://0.0.0.0:7474/]&lt;br /&gt;&lt;/pre&gt; &lt;p&gt;Confirm that Neo4j has started before continuing.&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;code&gt;CTRL-C&lt;/code&gt; will exit the log view and bring you back to your current shell.&lt;/p&gt;&lt;p&gt;You can alter the above command to stream log output from all service containers simultaneously by removing &lt;code&gt;graphdb&lt;/code&gt; from the last line.&lt;/p&gt;&lt;/blockquote&gt;&lt;h4 id=&quot;open-the-neo4j-browser&quot;&gt;Open the Neo4j browser&lt;/h4&gt;&lt;p&gt;Now that you&amp;#39;ve confirmed Neo4j is running as a container in your Docker host, let&amp;#39;s open up Neo4j&amp;#39;s browser and test running PageRank on actors in a movie dataset.&lt;/p&gt;&lt;p&gt;Run the following command to open a browser window that navigates to Neo4j&amp;#39;s URL.&lt;/p&gt;&lt;pre class=&quot;cm-s-pastel-on-dark CodeMirror&quot; data-lang=&quot;text/x-sh&quot;&gt;$ open $(echo \&amp;quot;$(echo $DOCKER_HOST)\&amp;quot;|&lt;br /&gt;              \sed &amp;#39;s/tcp:\/\//http:\/\//g&amp;#39;|&lt;br /&gt;              \sed &amp;#39;s/[0-9]\{4,\}/7474/g&amp;#39;|&lt;br /&gt;              \sed &amp;#39;s/\&amp;quot;//g&amp;#39;)&lt;br /&gt;&lt;/pre&gt;&lt;blockquote&gt;&lt;p&gt;This command finds the &lt;code&gt;$DOCKER_HOST&lt;/code&gt; environment variable to generate the URL of Neo4j&amp;#39;s browser. On Linux, this would be &lt;a href=&quot;http://localhost:7474&quot;&gt;http://localhost:7474&lt;/a&gt;.&lt;/p&gt;&lt;/blockquote&gt;&lt;h4 id=&quot;import-the-movie-graph&quot;&gt;Import the movie graph&lt;/h4&gt;&lt;p&gt;In the Neo4j console type &lt;code&gt;:play movies&lt;/code&gt; and press enter. Follow the directions to import the movie sample dataset.&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;We&amp;#39;ll use this dataset to test the Spark integration by running PageRank on the &amp;quot;Celebrity Graph&amp;quot; of actors.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;Now that the movie dataset has been imported, let&amp;#39;s create new relationships between actors who appeared together in the same movie. Copy and paste the following command into the Neo4j console and press &lt;code&gt;CTRL+Enter&lt;/code&gt; to execute.&lt;/p&gt;&lt;pre class=&quot;cm-neo CodeMirror&quot; data-lang=&quot;cypher&quot;&gt;&lt;code&gt;MATCH (p1:Person)-[:ACTED_IN]-&amp;gt;(m:Movie),&lt;br /&gt;      (p2:Person)-[:ACTED_IN]-&amp;gt;(m)&lt;br /&gt;CREATE (p1)-[:KNOWS]-&amp;gt;(p2)&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;blockquote&gt;&lt;p&gt;PageRank measures the probability of finding a node on the graph by randomly following links from one node to another node. It&amp;#39;s a measure of a node&amp;#39;s importance.&lt;/p&gt;&lt;/blockquote&gt;&lt;h4 id=&quot;calculate-pagerank-on-the-celebrity-graph&quot;&gt;Calculate PageRank on the celebrity graph&lt;/h4&gt;&lt;p&gt;Now that we&amp;#39;ve generated our &amp;quot;Celebrity Graph&amp;quot; by inferring the &lt;code&gt;:KNOWS&lt;/code&gt; relationship between co-actors, we can run PageRank on all nodes connected by this new relationship.&lt;/p&gt;&lt;p&gt;In the Neo4j console, copy and paste the following command:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;:GET /service/mazerunner/analysis/pagerank/KNOWS&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;and press enter.&lt;/p&gt;&lt;p&gt;If everything ran correctly, we should have a result of:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;{&lt;br /&gt;  &amp;quot;result&amp;quot;: &amp;quot;success&amp;quot;&lt;br /&gt;}&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;blockquote&gt;&lt;p&gt;This means that the graph was exported to Spark for processing. &lt;/p&gt;&lt;/blockquote&gt;&lt;h4 id=&quot;monitor-spark-s-log-output&quot;&gt;Monitor Spark&amp;#39;s log output&lt;/h4&gt;&lt;p&gt;We can monitor the log output from Spark by returning to the terminal we used during setup from earlier. From that shell, run the following command:&lt;/p&gt;&lt;pre class=&quot;cm-s-pastel-on-dark CodeMirror&quot; data-lang=&quot;text/x-sh&quot;&gt;$ docker run  --env DOCKER_HOST=$DOCKER_HOST \&lt;br /&gt;              --env DOCKER_TLS_VERIFY=$DOCKER_TLS_VERIFY \&lt;br /&gt;              --env DOCKER_CERT_PATH=/docker/cert \&lt;br /&gt;              -v $DOCKER_CERT_PATH:/docker/cert \&lt;br /&gt;              -ti kbastani/spark-neo4j logs&lt;br /&gt;&lt;/pre&gt;&lt;h4 id=&quot;calculate-closeness-centrality&quot;&gt;Calculate Closeness Centrality&lt;/h4&gt;&lt;p&gt;You&amp;#39;ll now be able to monitor the real-time log output from the &lt;strong&gt;Spark Neo4j&lt;/strong&gt; cluster as you submit new graph processing jobs.&lt;/p&gt;&lt;p&gt;Return back to the Neo4j browser and run the following command to calculate the Closeness Centrality of our &amp;quot;Celebrity Graph&amp;quot;.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;:GET /service/mazerunner/analysis/closeness_centrality/KNOWS&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;blockquote&gt;&lt;p&gt;If your log output from the terminal is visible, you&amp;#39;ll see a flurry of activity from Spark as it calculates this new metric. Don&amp;#39;t blink, you might miss it.&lt;/p&gt;&lt;/blockquote&gt;&lt;h4 id=&quot;querying-the-metrics-from-neo4j&quot;&gt;Querying the metrics from Neo4j&lt;/h4&gt;&lt;p&gt;You can now query on the newly calculated metrics from Neo4j. In the Neo4j browser, run the following command:&lt;/p&gt;&lt;pre class=&quot;cm-neo&quot; data-lang=&quot;cypher&quot;&gt;MATCH (p:Person) WHERE has(p.pagerank) AND has(p.closeness_centrality)&lt;br /&gt;RETURN p.name, p.pagerank as pagerank, p.closeness_centrality&lt;br /&gt;ORDER BY pagerank DESC&lt;br /&gt;&lt;/pre&gt;&lt;p&gt;The results show which of the celebrities have the most influence in Hollywood.&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;Go forth and process graphs.&lt;/p&gt;&lt;/blockquote&gt;</description><enclosure type='image/png' url='http://i.imgur.com/6DanVHg.png' length='0'/><link>https://www.kennybastani.com/2015/03/spark-neo4j-tutorial-docker.html</link><author>noreply@blogger.com (Kenny Bastani)</author><thr:total>0</thr:total></item><item><guid isPermaLink="false">tag:blogger.com,1999:blog-6300367579216018061.post-816081338302001237</guid><pubDate>Tue, 20 Jan 2015 06:25:00 +0000</pubDate><atom:updated>2015-03-01T17:33:00.689-08:00</atom:updated><category domain="http://www.blogger.com/atom/ns#">apache spark</category><category domain="http://www.blogger.com/atom/ns#">graph analytics</category><category domain="http://www.blogger.com/atom/ns#">graph database</category><category domain="http://www.blogger.com/atom/ns#">Mazerunner</category><category domain="http://www.blogger.com/atom/ns#">neo4j</category><category domain="http://www.blogger.com/atom/ns#">open source</category><category domain="http://www.blogger.com/atom/ns#">PageRank</category><title>Categorical PageRank Using Neo4j and Apache Spark</title><description>&lt;p&gt;PageRank is an important concept in computer science and modern technology. It is important because it is the underlying algorithm that mostly dictates what more than 3 billion users who use the internet experience as they browse the world wide web.&lt;/p&gt;&lt;h3 id=&quot;how-does-pagerank-work-&quot;&gt;How does PageRank work?&lt;/h3&gt;&lt;p&gt;The first PageRank algorithm was developed by Larry Page and Sergey Brinn at Stanford in 1996. Sergey Brinn had the idea that pages on the world wide web could be ordered and ranked by analyzing the number of links that point to each page. This idea was the foundation of the imminent rise of Google as the world&amp;#39;s most popular search engine, with now over 3.5 billion searches made by its users every day.&lt;/p&gt;&lt;p&gt;PageRank gives us a measure of popularity in an ever connected world of information. With an enormous degree of complexity increasing every day in the virtual space of information sharing, PageRank gives us a way to understand what is important to us as users.&lt;/p&gt;&lt;p&gt;&lt;div style=&quot;clear: both; text-align: center;&quot; class=&quot;separator&quot;&gt;&lt;a style=&quot;margin-left: 1em; margin-right: 1em;&quot; imageanchor=&quot;1&quot; href=&quot;http://1.bp.blogspot.com/-lN2PW8Q3Xk4/VL3k8WdARqI/AAAAAAAABBI/KqUqDnHT0x4/s1600/PageRanks-Example.png&quot;&gt;&lt;img width=&quot;400&quot; border=&quot;0&quot; height=&quot;321&quot; src=&quot;http://1.bp.blogspot.com/-lN2PW8Q3Xk4/VL3k8WdARqI/AAAAAAAABBI/KqUqDnHT0x4/s1600/PageRanks-Example.png&quot;&gt;&lt;/a&gt;&lt;/div&gt;&lt;/p&gt;&lt;p&gt;The unfortunate bit of this is that PageRank itself is mostly unapproachable to anything but seasoned engineers and esteemed academics. That&amp;#39;s why I want to make it easier for every developer around the world to make this algorithm the foundation of their innovative desires.&lt;/p&gt;&lt;h3 id=&quot;distributing-pagerank-jobs&quot;&gt;Distributing PageRank Jobs&lt;/h3&gt;&lt;p&gt;It should be no surprise to regular readers of this blog that I am &lt;a href=&quot;http://www.neo4j.com&quot;&gt;all about the graph&lt;/a&gt;. Graphs are the best abstraction of data that we have today. The concept is brilliantly easy and intuitive. Nodes represent data points and are described by meta data. Relationships connect nodes together, also described by meta data, and they enrich the information of each node relative to one another.&lt;/p&gt;&lt;h3 id=&quot;neo4j-mazerunner-project&quot;&gt;Neo4j Mazerunner Project&lt;/h3&gt;&lt;p&gt;As I have been building the open source project &lt;a href=&quot;https://github.com/kbastani/neo4j-mazerunner&quot;&gt;Neo4j Mazerunner&lt;/a&gt; to use Apache Spark GraphX and Neo4j for big scale graph analysis, I&amp;#39;ve come to understand the need for breaking down PageRank into categories. Something I call &amp;#39;Categorical PageRank&amp;#39;.&lt;/p&gt;&lt;a name=&#39;more&#39;&gt;&lt;/a&gt;&lt;h3 id=&quot;categorical-pagerank&quot;&gt;Categorical PageRank&lt;/h3&gt;&lt;p&gt;This concept came to me while writing a blog post about analyzing Wikipedia. I was trying to understand why calendar year articles on Wikipedia have a distinct pattern of PageRank growth when plotted on a line graph. I introduced this data &lt;a href=&quot;http://www.kennybastani.com/2014/12/graph-analysis-wikipedia-recent-relevancy.html&quot;&gt;in an earlier article&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;div style=&quot;clear: both; text-align: center;&quot; class=&quot;separator&quot;&gt;&lt;a style=&quot;margin-left: 1em; margin-right: 1em;&quot; imageanchor=&quot;1&quot; href=&quot;http://3.bp.blogspot.com/-AGQlQSB2UR0/VIUyqWMaamI/AAAAAAAABA0/JozoiAPk9t0/s1600/wikipedia-pagerank-graph-analysis.png&quot;&gt;&lt;img width=&quot;400&quot; border=&quot;0&quot; height=&quot;346&quot; src=&quot;http://3.bp.blogspot.com/-AGQlQSB2UR0/VIUyqWMaamI/AAAAAAAABA0/JozoiAPk9t0/s1600/wikipedia-pagerank-graph-analysis.png&quot;&gt;&lt;/a&gt;&lt;/div&gt;&lt;/p&gt;&lt;p&gt;To better understand the causality it would be necessary to break each PageRank down into a set of partitions that could describe what the contributing factors were to the rise or decline of each year&amp;#39;s PageRank. This led me to an idea. That I could build a job scheduler that would scalably distribute PageRank jobs using both &lt;a href=&quot;http://www.neo4j.com/&quot;&gt;Neo4j&lt;/a&gt; and &lt;a href=&quot;https://spark.apache.org/&quot;&gt;Apache Spark&lt;/a&gt;. This builds on top of earlier work I&amp;#39;ve done described &lt;a href=&quot;http://www.kennybastani.com/2014/11/using-apache-spark-and-neo4j-for-big.html&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;h3 id=&quot;the-design&quot;&gt;The Design&lt;/h3&gt;&lt;p&gt;Over the course of a weekend I was able to sketch out a design on a whiteboard and implement the functionality as a proof of concept to see whether or not it would both work and be scalable (because all things I build must be &lt;a href=&quot;http://www.mongodb-is-web-scale.com/&quot;&gt;web scale&lt;/a&gt;).&lt;/p&gt;&lt;h3 id=&quot;partitioned-pagerank-diagram&quot;&gt;Partitioned PageRank Diagram&lt;/h3&gt;&lt;p&gt;&lt;div style=&quot;clear: both; text-align: center;&quot; class=&quot;separator&quot;&gt;&lt;a style=&quot;margin-left: 1em; margin-right: 1em;&quot; imageanchor=&quot;1&quot; href=&quot;http://1.bp.blogspot.com/-9i64hxun2jk/VL3tOu1aBwI/AAAAAAAABBo/IOv-AIFfl7A/s1600/Categorical_PageRank.png&quot;&gt;&lt;img width=&quot;640&quot; border=&quot;0&quot; height=&quot;460&quot; src=&quot;http://1.bp.blogspot.com/-9i64hxun2jk/VL3tOu1aBwI/AAAAAAAABBo/IOv-AIFfl7A/s1600/Categorical_PageRank.png&quot;&gt;&lt;/a&gt;&lt;/div&gt;&lt;/p&gt;&lt;p&gt;The diagram above describes the &lt;a href=&quot;http://neo4j.com/developer/graph-database/&quot;&gt;property graph data model &lt;/a&gt;of the popular open knowledge graph, &lt;a href=&quot;http://dbpedia.org/&quot;&gt;DBPedia.org&lt;/a&gt;. This knowledge graph is a crowdsourced community effort that extracts information from Wikipedia and organizes it as a graph data model. &lt;/p&gt;&lt;h3 id=&quot;the-graph-model&quot;&gt;The Graph Model&lt;/h3&gt;&lt;p&gt;The graph data model consists of resources which represent &lt;strong&gt;Wikipedia pages&lt;/strong&gt; and &lt;strong&gt;categories&lt;/strong&gt;. The categories organize that information into a set of common groups, which forms partitions of the graph that we want to analyze. Finally, each Wikipedia page has a set of &lt;strong&gt;links&lt;/strong&gt; that connect articles together.&lt;/p&gt;&lt;h3 id=&quot;edge-list&quot;&gt;Edge List&lt;/h3&gt;&lt;p&gt;PageRank only requires an edge list that describes those inbound and outbound links of each page. An edge list is a simplified representation of the shape of our graph. For example, the following edge list forms a triangle where each ID represents a single node and the relationships are directed from &lt;code&gt;srcId&lt;/code&gt; to &lt;code&gt;dstId&lt;/code&gt;.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;srcId dstId&lt;br /&gt;1     2&lt;br /&gt;2     3 &lt;br /&gt;3     1&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;distributing-pagerank-jobs-by-category&quot;&gt;Distributing PageRank Jobs by Category&lt;/h3&gt;&lt;p&gt;In the &lt;a href=&quot;http://1.bp.blogspot.com/-9i64hxun2jk/VL3tOu1aBwI/AAAAAAAABBo/IOv-AIFfl7A/s1600/Categorical_PageRank.png&quot;&gt;diagram design&lt;/a&gt; I showed earlier, there are two partitions of interest that can run in graph parallel operations. Of the 4 &lt;em&gt;page&lt;/em&gt; nodes, there are 2 nodes that belong to the blue category and 3 nodes that belong to the red category. &lt;em&gt;I&amp;#39;ve colored the 1 node that belongs to both blue and red categories as purple.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;While we see that the 4 page nodes have link relationships between them, the goal for me was to run the PageRank jobs on local subgraphs that described the metric for each category a node belongs to.&lt;/p&gt;&lt;h3 id=&quot;versioning-pagerank-metrics-on-relationships&quot;&gt;Versioning PageRank Metrics on Relationships&lt;/h3&gt;&lt;p&gt;For PageRank &lt;strong&gt;Partition 0&lt;/strong&gt; in the diagram, the &lt;strong&gt;blue&lt;/strong&gt; category maps to a corresponding box at the bottom and describes the results of the analysis operation. &lt;/p&gt;&lt;p&gt;In the previous release of Mazerunner, the PageRank metrics would be stored as a single property on each node in Neo4j. The big epiphany for me was that the Neo4j relationship entity that is displayed between &lt;strong&gt;category&lt;/strong&gt; and the &lt;strong&gt;page&lt;/strong&gt; nodes could have versioned metrics for each partition from the results of each PageRank analysis. &lt;/p&gt;&lt;p&gt;This means that multiple &lt;strong&gt;page&lt;/strong&gt; nodes can have different PageRank values based on the pages&amp;#39;s locality within the graph. This then allows you to see how a single node ranks relative to each category it belongs to. &lt;/p&gt;&lt;h3 id=&quot;context-aware-knowledge-graph-search&quot;&gt;Context-aware Knowledge Graph Search&lt;/h3&gt;&lt;p&gt;This method turns out to provide you with a way to do context-aware relevancy ranking of pages to help refine results related to a subset of a node&amp;#39;s categories. &lt;/p&gt;&lt;p&gt;The metaphor being that if Google allowed you to refine search results by categories you could better break down search queries like the following:&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em&gt;&amp;quot;Actors who won an Oscar in 2015&amp;quot;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;We have 3 &lt;strong&gt;category&lt;/strong&gt; nodes in this search result:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Actor&lt;/li&gt;&lt;li&gt;Oscar Winner&lt;/li&gt;&lt;li&gt;Year:2015&lt;/li&gt;&lt;/ul&gt;&lt;h3 id=&quot;neo4j-cypher-query&quot;&gt;Neo4j Cypher Query&lt;/h3&gt;&lt;p&gt;After distirbuting out PageRank jobs per category, you can use a simple Neo4j Cypher query to return the search results:&lt;/p&gt;&lt;pre data-lang=&quot;cypher&quot;&gt;MATCH (category:Category)&amp;lt;-[metric:HAS_CATEGORY]-(page:Page)&lt;br /&gt;WHERE category.title in [&amp;quot;Actor&amp;quot;, &amp;quot;Oscar Winner&amp;quot;, &amp;quot;Year:2015&amp;quot;]&lt;br /&gt;RETURN page.title, page.url, page.description, metric.pagerank as pagerank&lt;br /&gt;ORDER BY pagerank DESC&lt;br /&gt;LIMIT 10&lt;br /&gt;&lt;/pre&gt;&lt;p&gt;The user ends up being able to get much more accurate search results ranked for the locality of the graph that is relevant for a query. You get both the benefit of relevance by locality and relevance by PageRank.&lt;/p&gt;&lt;h3 id=&quot;the-prototype&quot;&gt;The prototype&lt;/h3&gt;&lt;p&gt;The result of the proof of concept and prototype worked out great. I imported all of DBPedia into Neo4j and started up my distributed job manager for partitioning PageRank jobs.&lt;/p&gt;&lt;p&gt;I can scale each of the Apache Spark workers to orchestrate jobs in parallel on independent and isolated processes. HDFS is used to store the Neo4j subgraphs that are exported for each job, analyzed by Spark. When finished, each Spark worker will update the Neo4j graph with the calculated metrics.&lt;/p&gt;&lt;p&gt;Here is a screenshot that shows the prototype running on my laptop:&lt;/p&gt;&lt;p&gt;&lt;div style=&quot;clear: both; text-align: center;&quot; class=&quot;separator&quot;&gt;&lt;a style=&quot;margin-left: 1em; margin-right: 1em;&quot; imageanchor=&quot;1&quot; href=&quot;http://1.bp.blogspot.com/-LadDpRm3WMM/VL3xGWH5ZBI/AAAAAAAABB0/U2vPmfcEAo8/s1600/dbpedia-categorical-pagerank.png&quot;&gt;&lt;img width=&quot;640&quot; border=&quot;0&quot; height=&quot;450&quot; src=&quot;http://1.bp.blogspot.com/-LadDpRm3WMM/VL3xGWH5ZBI/AAAAAAAABB0/U2vPmfcEAo8/s1600/dbpedia-categorical-pagerank.png&quot;&gt;&lt;/a&gt;&lt;/div&gt;&lt;/p&gt;&lt;h3 id=&quot;available-as-open-source&quot;&gt;Available as open source&lt;/h3&gt;&lt;p&gt;This feature is available as a part of the &lt;a href=&quot;http://www.github.com/kbastani/neo4j-mazerunner&quot;&gt;Neo4j Mazerunner open source project&lt;/a&gt;. You can take a look at the original story detail as an issue here: &lt;a href=&quot;https://github.com/kbastani/neo4j-mazerunner/issues/29&quot;&gt;Issue 29&lt;/a&gt;&lt;/p&gt;&lt;p&gt;If you&amp;#39;re more interested in getting it running quickly, head on over to the &lt;a href=&quot;https://registry.hub.docker.com/u/kbastani/neo4j-graph-analytics/&quot;&gt;Neo4j Graph Analytics Docker repository&lt;/a&gt; and follow the setup directions to deploy it as a container to a Docker host.&lt;/p&gt;&lt;p&gt;This DBpedia dataset containing over 100 million nodes and relationships is also open source and available from this &lt;a href=&quot;https://github.com/kbastani/neo4j-dbpedia-importer&quot;&gt;GitHub repository&lt;/a&gt;.&lt;/p&gt;</description><enclosure type='image/png' url='http://1.bp.blogspot.com/-9i64hxun2jk/VL3tOu1aBwI/AAAAAAAABBo/IOv-AIFfl7A/s1600/Categorical_PageRank.png' length='0'/><link>https://www.kennybastani.com/2015/01/categorical-pagerank-neo4j-spark.html</link><author>noreply@blogger.com (Kenny Bastani)</author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://1.bp.blogspot.com/-lN2PW8Q3Xk4/VL3k8WdARqI/AAAAAAAABBI/KqUqDnHT0x4/s72-c/PageRanks-Example.png" height="72" width="72"/><thr:total>0</thr:total></item><item><guid isPermaLink="false">tag:blogger.com,1999:blog-6300367579216018061.post-4174091254220194468</guid><pubDate>Mon, 08 Dec 2014 05:32:00 +0000</pubDate><atom:updated>2014-12-07T22:43:31.433-08:00</atom:updated><category domain="http://www.blogger.com/atom/ns#">apache spark</category><category domain="http://www.blogger.com/atom/ns#">big data</category><category domain="http://www.blogger.com/atom/ns#">data science</category><category domain="http://www.blogger.com/atom/ns#">graph analytics</category><category domain="http://www.blogger.com/atom/ns#">graphx</category><category domain="http://www.blogger.com/atom/ns#">neo4j</category><category domain="http://www.blogger.com/atom/ns#">PageRank</category><category domain="http://www.blogger.com/atom/ns#">triangle count</category><category domain="http://www.blogger.com/atom/ns#">wikipedia</category><title>What Graph Analysis of Wikipedia Tells Us About the Relevancy of Recent Knowledge</title><description>   &lt;script src=&quot;http://code.highcharts.com/highcharts.js&quot;&gt;&lt;/script&gt;&lt;script src=&quot;http://code.highcharts.com/modules/exporting.js&quot;&gt;&lt;/script&gt;&lt;script&gt;$(function () {     /**      * Description: Graph Analysis of Wikipedia Category:Years      * Author: @kennybastani      * Info: Analyzed with Neo4j + Apache Spark GraphX      * Link: http://bit.ly/1u6F3Qn      **/      Highcharts.theme = {         colors: [&quot;#F25A29&quot;, &quot;#058DC7&quot;, &quot;#30B6AF&quot;, &quot;#FCC940&quot;, &quot;#FF6C7C&quot;, &quot;#4356C0&quot;, &quot;#DFE1E3&quot;],         chart: {             backgroundColor: {                 linearGradient: {                     x1: 0,                     y1: 0,                     x2: 0,                     y2: 1                 },                 stops: [                     [0, &#39;rgb(255, 255, 255)&#39;],                     [1, &#39;rgb(255, 255, 255)&#39;]                 ]             },             backgroundColor: &#39;rgb(255, 255, 255)&#39;,             borderWidth: .5,             plotBackgroundColor: &#39;rgba(255, 255, 255, .9)&#39;,             plotShadow: false,             plotBorderWidth: .5         },         title: {             style: {                 color: &#39;#000&#39;,                 fontWeight: &#39;300&#39;,                 fontSize: &#39;14px&#39;,                 fontFamily: &#39;\&#39;Open Sans\&#39; sans-serif&#39;             }         },         subtitle: {             style: {                 color: &#39;#777&#39;,                 fontWeight: &#39;300&#39;,                 fontSize: &#39;10px&#39;,                 fontFamily: &#39;\&#39;Open Sans\&#39; sans-serif&#39;             }         },         xAxis: {             gridLineWidth: .5,             lineColor: &#39;#333&#39;,             tickColor: &#39;#333&#39;,             labels: {                 style: {                     color: &#39;#333&#39;,                     fontWeight: &#39;normal&#39;                 }             },             title: {                 style: {                     color: &#39;#333&#39;,                     font: &#39;normal 12px &quot;Open Sans&quot;, sans-serif&#39;                 }             }         },         yAxis: {             minorTickInterval: &#39;auto&#39;,             lineColor: &#39;#000&#39;,             lineWidth: .5,             tickWidth: .5,             tickColor: &#39;#000&#39;,             labels: {                 style: {                     color: &#39;#555&#39;,                     fontWeight: &#39;300&#39;,                     fontSize: &#39;11px&#39;,                     fontFamily: &#39;\&#39;Open Sans\&#39; sans-serif&#39;                 }             },             title: {                 style: {                     color: &#39;#333&#39;,                     fontWeight: &#39;400&#39;,                     fontSize: &#39;12px&#39;,                     fontFamily: &#39;\&#39;Open Sans\&#39; sans-serif&#39;                 }             }         },         legend: {             itemStyle: {                 color: &#39;#333&#39;,                 font: &#39;normal 12px &quot;Open Sans&quot;, sans-serif&#39;             },             itemHoverStyle: {                 color: &#39;#428BCA&#39;,                 font: &#39;normal 12px &quot;Open Sans&quot;, sans-serif&#39;             },             itemHiddenStyle: {                 color: &#39;#CCC&#39;,                 font: &#39;normal 12px &quot;Open Sans&quot;, sans-serif&#39;             }         },         labels: {             style: {                 color: &#39;#333&#39;             }         },         tooltip: {             backgroundColor: {                 linearGradient: {                     x1: 0,                     y1: 0,                     x2: 0,                     y2: 1                 },                 stops: [                     [0, &#39;rgba(96, 96, 96, .8)&#39;],                     [1, &#39;rgba(16, 16, 16, .8)&#39;]                 ]             },             borderWidth: 0,             style: {                 color: &#39;#FFF&#39;             }         },           plotOptions: {             series: {                 nullColor: &#39;#444444&#39;             },             line: {                 dataLabels: {                     color: &#39;#333&#39;                 },                 marker: {                     lineColor: &#39;#333&#39;                 }             },             spline: {                 marker: {                     lineColor: &#39;#333&#39;                 }             },             scatter: {                 marker: {                     lineColor: &#39;#333&#39;                 }             },             candlestick: {                 lineColor: &#39;black&#39;             }         },          toolbar: {             itemStyle: {                 color: &#39;#333&#39;             }         },          navigation: {             buttonOptions: {                 symbolStroke: &#39;#DDDDDD&#39;,                 hoverSymbolStroke: &#39;#FFFFFF&#39;,                 theme: {                     fill: {                         linearGradient: {                             x1: 0,                             y1: 0,                             x2: 0,                             y2: 1                         },                         stops: [                             [0.4, &#39;#FFF&#39;],                             [0.6, &#39;#FFF&#39;]                         ]                     },                     stroke: &#39;#CCC&#39;                 }             }         },          // scroll charts         rangeSelector: {             buttonTheme: {                 fill: {                     linearGradient: {                         x1: 0,                         y1: 0,                         x2: 0,                         y2: 1                     },                     stops: [                         [0.4, &#39;#888&#39;],                         [0.6, &#39;#555&#39;]                     ]                 },                 stroke: &#39;#000000&#39;,                 style: {                     color: &#39;#CCC&#39;,                     fontWeight: &#39;normal&#39;                 },                 states: {                     hover: {                         fill: {                             linearGradient: {                                 x1: 0,                                 y1: 0,                                 x2: 0,                                 y2: 1                             },                             stops: [                                 [0.4, &#39;#BBB&#39;],                                 [0.6, &#39;#888&#39;]                             ]                         },                         stroke: &#39;#000000&#39;,                         style: {                             color: &#39;black&#39;                         }                     },                     select: {                         fill: {                             linearGradient: {                                 x1: 1,                                 y1: 0,                                 x2: 0,                                 y2: 1                             },                             stops: [                                 [0.1, &#39;#333&#39;],                                 [0.3, &#39;#333&#39;]                             ]                         },                         stroke: &#39;#000000&#39;,                         style: {                             color: &#39;yellow&#39;                         }                     }                 }             },             inputStyle: {                 backgroundColor: &#39;#333&#39;,                 color: &#39;silver&#39;             },             labelStyle: {                 color: &#39;silver&#39;             }         },          navigator: {             handles: {                 backgroundColor: &#39;#666&#39;,                 borderColor: &#39;#AAA&#39;             },             outlineColor: &#39;#CCC&#39;,             maskFill: &#39;rgba(16, 16, 16, 0.5)&#39;,             series: {                 color: &#39;#7798BF&#39;,                 lineColor: &#39;#A6C7ED&#39;             }         },          scrollbar: {             barBackgroundColor: {                 linearGradient: {                     x1: 0,                     y1: 0,                     x2: 0,                     y2: 1                 },                 stops: [                     [0.4, &#39;#888&#39;],                     [0.6, &#39;#555&#39;]                 ]             },             barBorderColor: &#39;#CCC&#39;,             buttonArrowColor: &#39;#CCC&#39;,             buttonBackgroundColor: {                 linearGradient: {                     x1: 0,                     y1: 0,                     x2: 0,                     y2: 1                 },                 stops: [                     [0.4, &#39;#888&#39;],                     [0.6, &#39;#555&#39;]                 ]             },             buttonBorderColor: &#39;#CCC&#39;,             rifleColor: &#39;#FFF&#39;,             trackBackgroundColor: {                 linearGradient: {                     x1: 0,                     y1: 0,                     x2: 0,                     y2: 1                 },                 stops: [                     [0, &#39;#333&#39;],                     [1, &#39;#333&#39;]                 ]             },             trackBorderColor: &#39;#666&#39;         },          // special colors for some of the demo examples         legendBackgroundColor: &#39;rgba(48, 48, 48, 0.8)&#39;,         legendBackgroundColorSolid: &#39;rgb(70, 70, 70)&#39;,         dataLabelsColor: &#39;#444&#39;,         textColor: &#39;#E0E0E0&#39;,         maskColor: &#39;rgba(0,0,0,0.3)&#39;     };       // Apply the theme     var highchartsOptions = Highcharts.setOptions(Highcharts.theme);      $(&#39;#container&#39;).highcharts({         chart: {             type: &#39;area&#39;,             zoomType: &#39;x&#39;         },         title: {             text: &#39;Graph Analysis of Wikpedia Pages in Category:Years&#39;         },         subtitle: {             text: &#39;http://en.wikipedia.org/wiki/Category:Years&#39;         },         xAxis: {             min: 1850,             max: 2012,             title: {                 text: &#39;Wiki Year Page&#39;             }         },         yAxis: {             title: {                 text: &#39;Relevance Ranking&#39;             },             min: 0,             ceiling: 4.9         },         legend: {             enabled: true         },         plotOptions: {             series: {                 lineWidth: .85,                 lineColor: &quot;#555&quot;             },             areaspline: {                  fillOpacity: 0.45             },             marker: {                 radius: 0             },             states: {                 hover: {                     lineWidth: 1                 }             },             threshold: null         },         tooltip: {             formatter: function () {                 return &#39;&lt;b&gt;&#39; + this.series.name + &#39;&lt;/b&gt;&#39; + &#39;: &#39; + (this.series.name == &quot;Triangle Count (Weighted)&quot; ? (parseFloat(this.y) * 83796).toFixed(0) : this.y) + &#39;&lt;br/&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/&#39; + this.x + &#39;&quot; target=&quot;_blank&quot;&gt;&#39; + &#39;http://en.wikipedia.org/wiki/&#39; + this.x + &#39;&lt;/a&gt;&#39;              },             shared: false         },         series: [{             pointInterval: 1,             pointStart: 1850,             name: &quot;Triangle Count (Weighted)&quot;,             data: [16979, 8863, 10149, 8434, 9901, 6654, 11119, 13513, 11939, 9965, 21339, 15860, 16707, 15796, 18377, 18559, 13214, 17689, 21000, 13388, 16583, 14790, 17191, 19626, 18048, 18027, 19501, 17399, 21619, 22902, 23589, 21275, 26977, 26857, 26789, 32069, 28932, 29123, 30830, 31664, 34708, 29875, 39347, 39280, 34404, 36939, 37385, 36656, 40585, 38846, 51782, 36927, 41778, 47127, 47611, 44496, 45045, 43531, 56153, 48090, 49730, 52784, 56883, 48814, 64911, 56951, 56202, 56477, 72723, 60231, 86155, 56452, 69421, 70487, 80945, 61685, 71819, 56746, 77176, 61643, 75398, 69154, 73652, 61851, 74600, 68141, 78725, 69936, 74746, 68750, 81098, 72462, 75736, 71199, 72695, 92983, 87283, 84601, 100861, 86802, 85411, 84711, 86123, 78020, 89104, 78103, 86335, 88093, 106552, 92051, 128205, 103063, 101043, 109819, 130449, 106968, 126650, 121516, 119908, 129115, 159067, 127909, 162849, 126588, 125981, 156997, 161096, 131136, 154512, 158400, 159331, 135833, 138078, 161108, 162903, 156650, 177831, 140422, 181214, 194831, 243776, 225805, 217411, 189383, 158843, 199303, 232197, 211651, 262296, 222836, 286824, 213459, 250890, 238563, 321472, 323294, 340543, 343074, 424294, 371908, 382312, 343894, 338948].map(function (num) {                 return parseFloat((num / 83796.0).toFixed(3));             })         }, {             pointInterval: 1,             pointStart: 1850,             name: &quot;PageRank&quot;,             data: [0.02417966854560197, 0.024184331925143843, 0.06452562661062759, 0.020446383701600332, 0.023332879839573734, 0.028852817937719485, 0.030924435929512144, 0.06149152784999033, 0.029449759626764545, 0.04744978905238744, 0.04614966045566021, 0.03821753943409271, 0.027473394180998048, 0.03260519920260544, 0.029037128754305617, 0.06845331799436556, 0.03207680689078672, 0.033475850341578475, 0.0944827341453766, 0.03327554481141983, 0.037906587683909546, 0.05179960845637006, 0.04747649343500299, 0.04111816959843884, 0.09390397815141809, 0.04312847161246515, 0.06581744655578611, 0.03447228472515291, 0.051550092065052594, 0.04388429327953825, 0.11319298174676592, 0.04889649213341791, 0.055088253336500935, 0.04656148890720485, 0.07053190991216189, 0.20176113639406684, 0.09656953022669153, 0.09169192736321177, 0.06622306186222524, 0.05711288970192277, 0.07559751327489331, 0.07110023290914828, 0.1329525027320194, 0.0831009234063066, 0.0749919306004876, 0.142110262058551, 0.1295562502247769, 0.08070099016664646, 0.09540346665862977, 0.09547401985100355, 0.2189892705376167, 0.10473528670844673, 0.10517389614590268, 0.10722076971440482, 0.15554018957794066, 0.10868860642018777, 0.2350326617201346, 0.12373099101451372, 0.27014334161809567, 0.12868468096234054, 0.16912937208344067, 0.21433055128039416, 0.25630361726997136, 0.16256795939188606, 0.20573727611275563, 0.17427466044678208, 0.2000929787913933, 0.17367105696423668, 0.30469578536863007, 0.18841061418951613, 0.3184093308050868, 0.20909099908979842, 0.31490891410846267, 0.27267354027761226, 0.4324305415004563, 0.23535804973245247, 0.2447090624064168, 0.22069532339320572, 0.33309628346122866, 0.3046229931039648, 0.2932373249797671, 0.33436785253319545, 0.32050492627907073, 0.2477435395419587, 0.29989929214886063, 0.35994392517394175, 0.3693780857521691, 0.2639011273469816, 0.3312525383596781, 0.25987403544686677, 0.2843401149311412, 0.2249088728924231, 0.21733927774307063, 0.18503734532049168, 0.22629633224048826, 0.36090286546913225, 0.287897867208696, 0.278378404987835, 0.48702541067971566, 0.34949928611470193, 0.4977233367673465, 0.4077845327782603, 0.4877409523815279, 0.344579352583002, 0.38110988706186455, 0.3719651789179822, 0.4659737222901417, 0.40973634081949745, 0.4157285894145852, 0.4060120557378039, 0.6144269616083984, 0.37200760003665906, 0.5144780603644714, 0.43975373674020446, 0.6547439849352155, 0.46013090843442994, 0.5146544725835115, 0.5042500635100301, 0.6771018576162711, 0.48377668868096757, 0.6063256509048176, 0.5568818499179863, 0.7546974554302175, 0.5597363758752948, 0.6659660116243352, 0.5769308314301003, 0.740615843488298, 0.6023906202614444, 0.6233835982449064, 0.7266405296765432, 0.8210354118815637, 0.6069947149091565, 0.7035209184285423, 0.804516220268465, 0.9640535972245852, 0.6652865772615223, 0.7722513443287764, 0.8283189486381991, 1.030728031673538, 0.8178309939886721, 0.8995374619735679, 0.898992390696153, 1.2818885810439675, 0.9826465815400885, 1.1264110119809527, 1.0816735881808222, 1.7325919563875158, 1.3112709716742728, 1.3722712926924217, 1.417297800635086, 3.8042761594778582, 1.8385361973400738, 1.653630673042514, 1.6888835874018877, 2.143311502614124, 1.9431549449169847, 2.518043360947946, 2.34421772983646, 2.6550651194813204, 2.2953798236901326, 5.063404499451981, 2.6238729941386434, 2.3661520426898828].map(function (num) {                 return parseFloat(num.toFixed(3));             })         }]     }); });&lt;/script&gt; &lt;p&gt;The chart below was generated using data analyzed with a &lt;a href=&quot;http://www.neo4j.com&quot; target=&quot;_blank&quot;&gt;Neo4j Graph Database&lt;/a&gt; and &lt;a href=&quot;http://spark.apache.org/docs/1.1.1/graphx-programming-guide.html&quot; target=&quot;_blank&quot;&gt;Apache Spark GraphX&lt;/a&gt;. 10.9 million Wikipedia articles and 110 million hyperlinks were analyzed to produce a &lt;a href=&quot;http://en.wikipedia.org/wiki/PageRank&quot; target=&quot;_blank&quot;&gt;PageRank&lt;/a&gt; and &lt;a href=&quot;http://arxiv.org/abs/1301.5887&quot; target=&quot;_blank&quot;&gt;Triangle Count&lt;/a&gt; for each node in the graph. The &lt;i&gt;Triangle Count&lt;/i&gt; metric is a measure of clustering, while the &lt;i&gt;PageRank&lt;/i&gt; metric is a measure of relevancy.&lt;/p&gt; &lt;div id=&quot;container&quot; style=&quot;min-width: 250px; max-width: 700px; min-height: 320px; margin: 0 auto; margin-bottom: 1em;&quot;&gt;&lt;/div&gt; &lt;h2&gt;Knowledge moves forward in time&lt;/h2&gt;&lt;p&gt;Every year through 1850&amp;mdash;2012 on the X-axis represents a Wikipedia page that describes historical events and facts about that calendar year. Link analysis was performed on the inbound and outbound hyperlinks for each page and all other pages in the graph that contribute to that page&#39;s relevancy.&lt;/p&gt;&lt;p&gt;    The chart describes a probability distribution over time. This distribution indicates that if a person were to randomly click hyperlinks starting from any page on Wikipedia, the person would move towards articles with a higher closeness centrality to &lt;a href=&quot;http://en.wikipedia.org/wiki/Category:Years&quot; target=&quot;_blank:&quot;&gt;Category:Year&lt;/a&gt; pages occurring later in the timeline. &lt;/p&gt;&lt;p&gt;When it comes to our collective human knowledge, as time moves forward, distant history becomes inversely relevant to more recent events in our timeline.&lt;/p&gt;&lt;p&gt;To see this pattern you can click and drag areas of the chart to zoom in. You&#39;ll notice the pattern is local as well as global.&lt;/p&gt;&lt;h3 style=&quot;display: block;&quot;&gt;Why is the year 2000 so relevant?&lt;/h3&gt; &lt;a style=&quot;max-width:400px; margin-top: 1.5em; display: block;&quot; href=&quot;http://1.bp.blogspot.com/-AGQlQSB2UR0/VIUyqWMaamI/AAAAAAAABAw/OsS2dSaBaJk/s1600/wikipedia-pagerank-graph-analysis.png&quot; imageanchor=&quot;1&quot; &gt;&lt;img border=&quot;0&quot; style=&quot;max-width:500px; margin-top: 2em; width:320px;&quot; class=&quot;thumbnail&quot;  src=&quot;http://1.bp.blogspot.com/-AGQlQSB2UR0/VIUyqWMaamI/AAAAAAAABAw/OsS2dSaBaJk/s1600/wikipedia-pagerank-graph-analysis.png&quot; /&gt;&lt;/a&gt;&lt;blockquote&gt;Wikipedia, the world&#39;s largest encyclopedia of human knowledge, was first launched on January 15th, 2001.&lt;/blockquote&gt;&lt;h3&gt;Links&lt;/h3&gt;&lt;p&gt;&lt;ul&gt;&lt;li&gt;Chart source code: &lt;a href=&quot;http://jsfiddle.net/rbxp0hsw/28/&quot; target=&quot;_blank&quot;&gt;jsfiddle/highcharts&lt;/a&gt;&lt;/li&gt;&lt;li&gt;In an upcoming blog post I&#39;ll walk you through launching an EC2 Spark Cluster with a Wikipedia dataset in Neo4j. Stay tuned!&lt;/li&gt;&lt;li&gt;If you&#39;re interested in learning more about how I computed the graph metrics for this chart, take a look at &lt;a href=&quot;http://www.kennybastani.com/2014/11/graph-analytics-docker-spark-neo4j.html&quot;&gt;this blog post about how to extend Neo4j to do big data analysis with Apache Spark GraphX&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;        </description><enclosure type='image/png' url='http://1.bp.blogspot.com/-AGQlQSB2UR0/VIUyqWMaamI/AAAAAAAABAw/OsS2dSaBaJk/s1600/wikipedia-pagerank-graph-analysis.png' length='0'/><link>https://www.kennybastani.com/2014/12/graph-analysis-wikipedia-recent-relevancy.html</link><author>noreply@blogger.com (Kenny Bastani)</author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://1.bp.blogspot.com/-AGQlQSB2UR0/VIUyqWMaamI/AAAAAAAABAw/OsS2dSaBaJk/s72-c/wikipedia-pagerank-graph-analysis.png" height="72" width="72"/><thr:total>0</thr:total></item><item><guid isPermaLink="false">tag:blogger.com,1999:blog-6300367579216018061.post-337994707669735079</guid><pubDate>Thu, 27 Nov 2014 17:26:00 +0000</pubDate><atom:updated>2014-11-29T07:50:52.971-08:00</atom:updated><category domain="http://www.blogger.com/atom/ns#">apache spark</category><category domain="http://www.blogger.com/atom/ns#">docker</category><category domain="http://www.blogger.com/atom/ns#">graph analytics</category><category domain="http://www.blogger.com/atom/ns#">graphx</category><category domain="http://www.blogger.com/atom/ns#">Mazerunner</category><category domain="http://www.blogger.com/atom/ns#">neo4j</category><category domain="http://www.blogger.com/atom/ns#">open source</category><category domain="http://www.blogger.com/atom/ns#">PageRank</category><title>A Docker Image for Graph Analytics on Neo4j with Apache Spark GraphX</title><description>&lt;p&gt;I&#39;ve just released a useful new &lt;a href=&quot;https://registry.hub.docker.com/u/kbastani/neo4j-graph-analytics/&quot;&gt;Docker image for graph analytics&lt;/a&gt; on a &lt;a href=&quot;http://www.neo4j.com&quot;&gt;Neo4j graph database&lt;/a&gt; with Apache Spark GraphX. This image deploys a container with &lt;a href=&quot;https://spark.apache.org/&quot;&gt;Apache Spark&lt;/a&gt; and uses &lt;a href=&quot;https://spark.apache.org/graphx/&quot;&gt;GraphX&lt;/a&gt; to perform ETL graph analysis on subgraphs exported from Neo4j. This docker image is a great addition to Neo4j if you&#39;re looking to do easy PageRank or community detection on your graph data. Additionally, the results of the graph analysis are applied back to Neo4j.&lt;/p&gt;&lt;p&gt;This gives you the ability to optimize your recommendation-based Cypher queries by filtering and sorting on the results of the analysis.&lt;/p&gt; &lt;table cellspacing=&quot;0&quot; cellpadding=&quot;0&quot; align=&quot;center&quot; style=&quot;margin-left: auto; margin-right: auto; text-align: center; margin-bottom: 2em; margin-top: 2em;&quot; class=&quot;tr-caption-container&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://ampcamp.berkeley.edu/big-data-mini-course/img/tables_and_graphs.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img width=&quot;500&quot; border=&quot;0&quot; src=&quot;http://ampcamp.berkeley.edu/big-data-mini-course/img/tables_and_graphs.png&quot; /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style=&quot;text-align: center;&quot; class=&quot;tr-caption&quot;&gt;&lt;a href=&quot;http://ampcamp.berkeley.edu/big-data-mini-course/graph-analytics-with-graphx.html&quot; target=&quot;_blank&quot;&gt;Photo credit AMPLab Berkley&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt; &lt;a name=&#39;more&#39;&gt;&lt;/a&gt; &lt;p&gt;As an example, if I wanted to calculate the popularity of my Twitter network, I could run a PageRank and Triangle Count analysis on my community subgraph and calculate the popularity of users using Cypher.&lt;/p&gt; &lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center; margin-top: 2em; margin-bottom: 2em;&quot;&gt;&lt;a href=&quot;http://i.imgur.com/NqhjGbK.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; width=&quot;640&quot; src=&quot;http://i.imgur.com/NqhjGbK.png&quot; /&gt;&lt;/a&gt;&lt;/div&gt; &lt;h2&gt;&lt;a id=&quot;user-content-supported-algorithms&quot; class=&quot;anchor&quot; href=&quot;#supported-algorithms&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;octicon octicon-link&quot;&gt;&lt;/span&gt;&lt;/a&gt;Supported Algorithms&lt;/h2&gt;&lt;p&gt;There are four supported graph analysis algorithms available in this version of the image.&lt;/p&gt;&lt;ul&gt; &lt;li&gt;&lt;p&gt;&lt;em&gt;PageRank&lt;/em&gt;&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;em&gt;Triangle Counting&lt;/em&gt;&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;em&gt;Connected Components&lt;/em&gt;&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;em&gt;Strongly Connected Components&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Each of these algorithms come default with Spark GraphX.&lt;/p&gt; &lt;h3&gt;&lt;a id=&quot;user-content-neo4j-mazerunner-service&quot; class=&quot;anchor&quot; href=&quot;#neo4j-mazerunner-service&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;octicon octicon-link&quot;&gt;&lt;/span&gt;&lt;/a&gt;Extending the Neo4j Server&lt;/h3&gt; &lt;p&gt;The Neo4j server is extended using an &lt;a href=&quot;http://neo4j.com/docs/stable/server-unmanaged-extensions.html&quot;&gt;unmanaged extension&lt;/a&gt; that adds a REST API endpoint to Neo4j for submitting graph analysis jobs to Apache Spark GraphX. The results of the analysis are applied back to the nodes in Neo4j as property values, making the results queryable using Cypher.&lt;/p&gt; &lt;h2&gt;&lt;a id=&quot;user-content-installationdeployment&quot; class=&quot;anchor&quot; href=&quot;#installationdeployment&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;octicon octicon-link&quot;&gt;&lt;/span&gt;&lt;/a&gt;Installation/Deployment&lt;/h2&gt; &lt;p&gt;Installation requires 3 docker image deployments, each containing a separate linked component.&lt;/p&gt; &lt;ul class=&quot;task-list&quot;&gt;&lt;li&gt;&lt;em&gt;Hadoop HDFS&lt;/em&gt; (sequenceiq/hadoop-docker:2.4.1)&lt;/li&gt;&lt;li&gt;&lt;em&gt;Neo4j Graph Database&lt;/em&gt; (kbastani/docker-neo4j:latest)&lt;/li&gt;&lt;li&gt;&lt;em&gt;Apache Spark Service&lt;/em&gt; (kbastani/neo4j-graph-analytics:latest)&lt;/li&gt;&lt;/ul&gt; &lt;p&gt;Pull the following docker images:&lt;/p&gt; &lt;pre class=&quot;zsh highlight&quot;&gt;&lt;code&gt;docker pull sequenceiq/hadoop-docker:2.4.1&lt;br /&gt;docker pull kbastani/docker-neo4j:latest&lt;br /&gt;docker pull kbastani/neo4j-graph-analytics:latest&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;After each image has been downloaded to your Docker server, run the following commands in order to create the linked containers.&lt;/p&gt; &lt;pre class=&quot;zsh highlight&quot;&gt;&lt;code&gt;# Create HDFS&lt;br /&gt;docker run -i -t --name hdfs sequenceiq/hadoop-docker:2.4.1 /etc/bootstrap.sh -bash&lt;br /&gt;&lt;br /&gt;# Create Mazerunner Apache Spark Service&lt;br /&gt;docker run -i -t --name mazerunner --link hdfs:hdfs kbastani/neo4j-graph-analytics&lt;br /&gt;&lt;br /&gt;# Create Neo4j database with links to HDFS and Mazerunner&lt;br /&gt;# Replace &amp;lt;user&amp;gt; and &amp;lt;neo4j-path&amp;gt;&lt;br /&gt;# with the location to your existing Neo4j database store directory&lt;br /&gt;docker run -d -P -v /Users/&amp;lt;user&amp;gt;/&amp;lt;neo4j-path&amp;gt;/data:/opt/data --name graphdb --link mazerunner:mazerunner --link hdfs:hdfs kbastani/docker-neo4j&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;&lt;a id=&quot;user-content-use-existing-neo4j-database&quot; class=&quot;anchor&quot; href=&quot;#use-existing-neo4j-database&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;octicon octicon-link&quot;&gt;&lt;/span&gt;&lt;/a&gt;Use Your Existing Neo4j Database&lt;/h3&gt; &lt;p&gt;To use an existing Neo4j database, make sure that the database store directory, typically &lt;code&gt;data/graph.db&lt;/code&gt;, is available on your host OS. Read the &lt;a href=&quot;https://github.com/kbastani/docker-neo4j#start-neo4j-container&quot;&gt;setup guide&lt;/a&gt; for &lt;em&gt;kbastani/docker-neo4j&lt;/em&gt; for additional details.&lt;/p&gt; &lt;h3&gt;&lt;a id=&quot;user-content-accessing-the-neo4j-browser&quot; class=&quot;anchor&quot; href=&quot;#accessing-the-neo4j-browser&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;octicon octicon-link&quot;&gt;&lt;/span&gt;&lt;/a&gt;Accessing the Neo4j Browser&lt;/h3&gt; &lt;p&gt;The Neo4j browser is exposed as a container on port 7474. If you&#39;re wanting to test this deployment on your development machine and are using &lt;a href=&quot;http://boot2docker.io/&quot; target=&quot;_blank&quot;&gt;boot2docker&lt;/a&gt; on MacOSX, follow the directions &lt;a href=&quot;https://github.com/kbastani/docker-neo4j#boot2docker&quot; target=&quot;_blank&quot;&gt;here&lt;/a&gt; to access the Neo4j browser on your environment.&lt;/p&gt; &lt;h2&gt;&lt;a id=&quot;user-content-usage-directions&quot; class=&quot;anchor&quot; href=&quot;#usage-directions&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;octicon octicon-link&quot;&gt;&lt;/span&gt;&lt;/a&gt;Usage Directions&lt;/h2&gt; &lt;p&gt;Graph analysis jobs are started by accessing the following endpoint:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;http://localhost:7474/service/mazerunner/analysis/{analysis}/{relationship_type}&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;To choose an analysis to start running, replace &lt;code&gt;{analysis}&lt;/code&gt; in the URL above with one of the following keys:&lt;/p&gt; &lt;ul class=&quot;task-list&quot;&gt;&lt;li&gt;pagerank&lt;/li&gt;&lt;li&gt;triangle_count&lt;/li&gt;&lt;li&gt;connected_components&lt;/li&gt;&lt;li&gt;strongly_connected_components&lt;/li&gt;&lt;/ul&gt; &lt;p&gt;To select a subgraph from Neo4j that you would like to analyze, replace the &lt;code&gt;{relationship_type}&lt;/code&gt; in the URL above with a relationship type in your Neo4j database. The nodes that are connected by that relationship will form the graph that will be analyzed. For example, the equivalent Cypher query would be the following:&lt;/p&gt; &lt;pre data-lang=&quot;cypher&quot;&gt;MATCH (a)-[:FOLLOWS]-&amp;gt;(b)&lt;br /&gt;RETURN id(a) as src, id(b) as dst&lt;br /&gt;&lt;/pre&gt; Just to illustrate, if you ran a &lt;code&gt;pagerank&lt;/code&gt; analysis on the &lt;code&gt;FOLLOWS&lt;/code&gt; relationship type, the following Cypher query will display the results:&lt;/p&gt; &lt;pre data-lang=&quot;cypher&quot;&gt;MATCH (a)-[:FOLLOWS]-()&lt;br /&gt;RETURN DISTINCT id(a) as id, a.pagerank as pagerank&lt;br /&gt;ORDER BY pagerank DESC&lt;/pre&gt; &lt;h2&gt;&lt;a id=&quot;user-content-usage-examples&quot; class=&quot;anchor&quot; href=&quot;#usage-examples&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;octicon octicon-link&quot;&gt;&lt;/span&gt;&lt;/a&gt;Usage Examples&lt;/h2&gt; &lt;p&gt;To run graph analysis algorithms, HTTP GET request on the following Neo4j server endpoints:&lt;/p&gt; &lt;h3&gt;&lt;a id=&quot;user-content-pagerank&quot; class=&quot;anchor&quot; href=&quot;#pagerank&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;octicon octicon-link&quot;&gt;&lt;/span&gt;&lt;/a&gt;PageRank&lt;/h3&gt; &lt;pre&gt;&lt;code&gt;http://172.17.0.21:7474/service/mazerunner/analysis/pagerank/FOLLOWS&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt; &lt;ul class=&quot;task-list&quot;&gt;&lt;li&gt;&lt;p&gt;Gets all nodes connected by the &lt;code&gt;FOLLOWS&lt;/code&gt; relationship and updates each node with the property key &lt;code&gt;pagerank&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;The value of the &lt;code&gt;pagerank&lt;/code&gt; property is a float data type, ex. &lt;code&gt;pagerank: 3.14159265359&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;PageRank is used to find the relative importance of a node within a set of connected nodes.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt; &lt;h3&gt;&lt;a id=&quot;user-content-triangle-counting&quot; class=&quot;anchor&quot; href=&quot;#triangle-counting&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;octicon octicon-link&quot;&gt;&lt;/span&gt;&lt;/a&gt;Triangle Counting&lt;/h3&gt; &lt;pre&gt;&lt;code&gt;http://172.17.0.21:7474/service/mazerunner/analysis/triangle_count/FOLLOWS&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt; &lt;ul class=&quot;task-list&quot;&gt;&lt;li&gt;&lt;p&gt;Gets all nodes connected by the &lt;code&gt;FOLLOWS&lt;/code&gt; relationship and updates each node with the property key &lt;code&gt;triangle_count&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;The value of the &lt;code&gt;triangle_count&lt;/code&gt; property is an integer data type, ex. &lt;code&gt;triangle_count: 2&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;The value of &lt;code&gt;triangle_count&lt;/code&gt; represents the count of the triangles that a node is connected to.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;A node is part of a triangle when it has two adjacent nodes with a relationship between them. The &lt;code&gt;triangle_count&lt;/code&gt; property provides a measure of clustering for each node.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt; &lt;h3&gt;&lt;a id=&quot;user-content-connected-components&quot; class=&quot;anchor&quot; href=&quot;#connected-components&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;octicon octicon-link&quot;&gt;&lt;/span&gt;&lt;/a&gt;Connected Components&lt;/h3&gt; &lt;pre&gt;&lt;code&gt;http://172.17.0.21:7474/service/mazerunner/analysis/connected_components/FOLLOWS&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt; &lt;ul class=&quot;task-list&quot;&gt;&lt;li&gt;&lt;p&gt;Gets all nodes connected by the &lt;code&gt;FOLLOWS&lt;/code&gt; relationship and updates each node with the property key &lt;code&gt;connected_components&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;The value of &lt;code&gt;connected_components&lt;/code&gt; property is an integer data type, ex. &lt;code&gt;connected_components: 181&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;The value of &lt;code&gt;connected_components&lt;/code&gt; represents the &lt;em&gt;Neo4j internal node ID&lt;/em&gt; that has the lowest integer value for a set of connected nodes.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Connected components are used to find isolated clusters, that is, a group of nodes that can reach every other node in the group through a &lt;em&gt;bidirectional&lt;/em&gt; traversal.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt; &lt;h3&gt;&lt;a id=&quot;user-content-strongly-connected-components&quot; class=&quot;anchor&quot; href=&quot;#strongly-connected-components&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;octicon octicon-link&quot;&gt;&lt;/span&gt;&lt;/a&gt;Strongly Connected Components&lt;/h3&gt; &lt;pre&gt;&lt;code&gt;http://172.17.0.21:7474/service/mazerunner/analysis/strongly_connected_components/FOLLOWS&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt; &lt;ul class=&quot;task-list&quot;&gt;&lt;li&gt;&lt;p&gt;Gets all nodes connected by the &lt;code&gt;FOLLOWS&lt;/code&gt; relationship and updates each node with the property key &lt;code&gt;strongly_connected_components&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;The value of &lt;code&gt;strongly_connected_components&lt;/code&gt; property is an integer data type, ex. &lt;code&gt;strongly_connected_components: 26&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;The value of &lt;code&gt;strongly_connected_components&lt;/code&gt; represents the &lt;em&gt;Neo4j internal node ID&lt;/em&gt; that has the lowest integer value for a set of strongly connected nodes.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Strongly connected components are used to find clusters, that is, a group of nodes that can reach every other node in the group through a &lt;em&gt;directed&lt;/em&gt; traversal.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt; &lt;h2&gt;Getting started&lt;/h2&gt; &lt;p&gt;To get started, head over to the &lt;a href=&quot;https://registry.hub.docker.com/u/kbastani/neo4j-graph-analytics/&quot;&gt;neo4j-graph-analytics Docker Repository&lt;/a&gt; and follow the directions to get started. If you&#39;re new to Docker and looking to get your feet wet, take a look at this great online tutorial: &lt;a href=&quot;https://www.docker.com/tryit/&quot;&gt;https://www.docker.com/tryit/&lt;/a&gt;&lt;/p&gt; &lt;p&gt;If you have any questions or need help getting setup, please feel free to comment below. Also, comment your ideas for additional graph analytics algorithms that could be added to this library.&lt;/p&gt; &lt;p&gt;Have fun!&lt;/p&gt;</description><link>https://www.kennybastani.com/2014/11/graph-analytics-docker-spark-neo4j.html</link><author>noreply@blogger.com (Kenny Bastani)</author><thr:total>0</thr:total></item><item><guid isPermaLink="false">tag:blogger.com,1999:blog-6300367579216018061.post-4014480702246945050</guid><pubDate>Mon, 03 Nov 2014 22:33:00 +0000</pubDate><atom:updated>2014-11-27T19:57:44.593-08:00</atom:updated><category domain="http://www.blogger.com/atom/ns#">analytics</category><category domain="http://www.blogger.com/atom/ns#">apache hadoop</category><category domain="http://www.blogger.com/atom/ns#">apache spark</category><category domain="http://www.blogger.com/atom/ns#">big data</category><category domain="http://www.blogger.com/atom/ns#">data science</category><category domain="http://www.blogger.com/atom/ns#">graph database</category><category domain="http://www.blogger.com/atom/ns#">graph processing</category><category domain="http://www.blogger.com/atom/ns#">Mazerunner</category><category domain="http://www.blogger.com/atom/ns#">neo4j</category><category domain="http://www.blogger.com/atom/ns#">PageRank</category><title>Using Apache Spark and Neo4j for Big Data Graph Analytics</title><description>&lt;p&gt;As engineers, when we think about how to solve big data problems, evaluating technologies becomes a choice between scalable and not scalable. Ideally we choose the technologies that can scale to a variety of business problems without hitting a ceiling down the road.&lt;/p&gt; &lt;p&gt;Database technologies have evolved to be able to store big data, but are largely inflexible. The data models require tedious transformations and shuffling around of data. This is a complex process that is compounded in its complexity by combining a variety of inflexible solutions and platforms.&lt;/p&gt; &lt;p&gt;Fast and scalable analysis of big data has become a critical competitive advantage for companies. There are open source tools like &lt;a href=&quot;http://en.wikipedia.org/wiki/Apache_Hadoop&quot; target=&quot;_blank&quot;&gt;Apache Hadoop&lt;/a&gt; and &lt;a href=&quot;http://en.wikipedia.org/wiki/Apache_Spark&quot; target=&quot;_blank&quot;&gt;Apache Spark&lt;/a&gt; that are providing opportunities for companies to solve these big data problems in a scalable way. Platforms like these have become the foundation of the big data analysis movement.&lt;/p&gt;&lt;p&gt;Still, where does all that data come from? Where does it go when the analysis is done?&lt;/p&gt;&lt;a name=&#39;more&#39;&gt;&lt;/a&gt;&lt;h3&gt;Graph databases&lt;/h3&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;I&#39;ve been working with the &lt;a href=&quot;http://www.neo4j.com&quot;&gt;Neo4j graph database&lt;/a&gt; for the last few years and I have yet to become jaded by its powerful ability to combine both data transformation and data analysis. Graph databases like Neo4j are solving analytical problems that relational databases struggle to solve in a flexible way.&lt;br /&gt;&lt;br /&gt;Graph processing at scale from a graph database like Neo4j is a tremendously valuable power.&lt;br /&gt;&lt;br /&gt;But if you wanted to run PageRank on a dump of Wikipedia articles in less than 2 hours on a laptop, you&#39;d be hard pressed to be successful. More so, what if you wanted the power of a high-performance transactional database that seamlessly handled graph analysis at this scale?&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;Mazerunner for Neo4j&lt;/h3&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/kbastani/neo4j-mazerunner&quot; target=&quot;_blank&quot;&gt;Mazerunner&lt;/a&gt; is a &lt;a href=&quot;http://neo4j.com/docs/stable/server-unmanaged-extensions.html&quot;&gt;Neo4j unmanaged extension&lt;/a&gt; and distributed graph processing platform that extends Neo4j to do big data graph processing jobs while persisting the results  back to Neo4j.&lt;br /&gt;&lt;br /&gt;Mazerunner uses a message broker to distribute graph processing jobs to &lt;a href=&quot;https://spark.apache.org/graphx/&quot;&gt;Apache Spark&#39;s GraphX&lt;/a&gt; module. When an agent job is dispatched, a subgraph is exported from Neo4j and written to &lt;a href=&quot;https://hadoop.apache.org/docs/r2.4.1/hadoop-project-dist/hadoop-hdfs/HdfsUserGuide.html&quot;&gt;Apache Hadoop HDFS&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;After Neo4j exports a subgraph to HDFS, a separate Mazerunner service  for Spark is notified to begin processing that data. The Mazerunner  service will then start a distributed graph processing algorithm using  Scala and Spark&#39;s GraphX module. The GraphX algorithm is serialized and  dispatched to Apache Spark for processing.&lt;br /&gt;&lt;br /&gt;Once the Apache Spark job completes, the results are written back to  HDFS as a Key-Value list of property updates to be applied back to  Neo4j.&lt;br /&gt;&lt;br /&gt;Neo4j is then notified that a property update list is available from  Apache Spark on HDFS. Neo4j batch imports the results and applies the  updates back to the original graph.&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;Example&lt;/h3&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Neo4j ships with a sample movie dataset and I&#39;ll use that for this example. The graph data model looks like this:&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;http://1.bp.blogspot.com/-gta3ODAcdBg/VFf-ROiOR8I/AAAAAAAAA8w/Jxu99gIW3cE/s1600/movie-model.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-gta3ODAcdBg/VFf-ROiOR8I/AAAAAAAAA8w/Jxu99gIW3cE/s1600/movie-model.png&quot; height=&quot;255&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;br /&gt;If we run a transformation on this model and create relationships between people who acted in the same movie, we can use the resulting graph to determine which actors are most valuable to work with.&lt;br /&gt;&lt;br /&gt;The Cypher query to do this looks like this:&lt;br /&gt;&lt;pre&gt;&lt;code&gt;MATCH (a1:Person)-[:ACTED_IN]-&amp;gt;(m)&amp;lt;-[:ACTED_IN]-(coActors)&lt;br /&gt;CREATE (a1)-[:KNOWS]-&amp;gt;(coActors);&lt;/code&gt;&lt;/pre&gt;Now our model looks like this:&lt;br /&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;http://3.bp.blogspot.com/-gwGKjYDA-DE/VFgAC9CTEVI/AAAAAAAAA88/oAc0Kgp32pY/s1600/actor-link-graph.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-gwGKjYDA-DE/VFgAC9CTEVI/AAAAAAAAA88/oAc0Kgp32pY/s1600/actor-link-graph.png&quot; height=&quot;468&quot; width=&quot;640&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;By doing this, we create a direct link between actors that can be used for a PageRank analysis of the most valuable actors to work with.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;To start the PageRank job on Apache Spark, Mazerunner extends an endpoint to start the processing job.&lt;br /&gt;&lt;pre&gt;&lt;code&gt;http://localhost:7474/service/mazerunner/pagerank&lt;/code&gt;&lt;/pre&gt;Hitting this endpoint will run the PageRank algorithm on actors who know each other and then write the results back into Neo4j as a &lt;b&gt;weight&lt;/b&gt; property on the &lt;b&gt;Person&lt;/b&gt; nodes.&lt;br /&gt;&lt;br /&gt;When the job finishes then we can find the top ten most valuable actors to work with. Running a Cypher query against this dataset produces the following results:&lt;br /&gt;&lt;pre&gt;&lt;code&gt;&lt;br /&gt;neo4j-sh (?)$ MATCH n WHERE HAS(n.weight) RETURN n ORDER BY n.weight DESC LIMIT 10;&lt;br /&gt;+-----------------------------------------------------------------------+&lt;br /&gt;| n                                                                     |&lt;br /&gt;+-----------------------------------------------------------------------+&lt;br /&gt;| Node[71]{name:&quot;Tom Hanks&quot;,born:1956,weight:4.642800717539658}         |&lt;br /&gt;| Node[1]{name:&quot;Keanu Reeves&quot;,born:1964,weight:2.605304495549113}       |&lt;br /&gt;| Node[22]{name:&quot;Cuba Gooding Jr.&quot;,born:1968,weight:2.5655048212974223} |&lt;br /&gt;| Node[34]{name:&quot;Meg Ryan&quot;,born:1961,weight:2.52628473708215}           |&lt;br /&gt;| Node[16]{name:&quot;Tom Cruise&quot;,born:1962,weight:2.430592498009265}        |&lt;br /&gt;| Node[19]{name:&quot;Kevin Bacon&quot;,born:1958,weight:2.0886893112867035}      |&lt;br /&gt;| Node[17]{name:&quot;Jack Nicholson&quot;,born:1937,weight:1.9641313625284538}   |&lt;br /&gt;| Node[120]{name:&quot;Ben Miles&quot;,born:1967,weight:1.8680986516285438}       |&lt;br /&gt;| Node[4]{name:&quot;Hugo Weaving&quot;,born:1960,weight:1.8515582875810466}      |&lt;br /&gt;| Node[20]{name:&quot;Kiefer Sutherland&quot;,born:1966,weight:1.784065038526406} |&lt;br /&gt;+-----------------------------------------------------------------------+&lt;br /&gt;10 rows&lt;/code&gt;&lt;/pre&gt;&lt;br /&gt;&lt;h3&gt;PageRank on Wikipedia Dump&lt;/h3&gt;&lt;br /&gt;&lt;div&gt;A small movie dataset is cute, but if we&#39;re talking about scale, we need a dataset that is at a massive scale. I took a dump of Wikipedia and imported it into Neo4j using &lt;a href=&quot;https://github.com/mirkonasato/graphipedia&quot; target=&quot;_blank&quot;&gt;Graphipedia&lt;/a&gt;.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;The resulting graph of hyperlink references connecting articles to each other resulted in a massive graph in Neo4j.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;b&gt;Nodes&lt;/b&gt;: 10,985,338 &lt;br /&gt;&lt;b&gt;Relationships&lt;/b&gt;: 104,673,778&lt;br /&gt;&lt;b&gt;Database&lt;/b&gt; size:&amp;nbsp;11,002  MB&lt;br /&gt;&lt;br /&gt;It took a little less than 3 hours for Mazerunner to run PageRank on 11 million Wikipedia articles on my laptop.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Here are the top 100 results of that analysis:&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;pre&gt;&lt;code&gt;+-------------------------------------------------------------+&lt;br /&gt;| title                                  | weight             |&lt;br /&gt;+-------------------------------------------------------------+&lt;br /&gt;| &quot;United States&quot;                        | 13481.465434735326 |&lt;br /&gt;| &quot;France&quot;                               | 5866.673240306334  |&lt;br /&gt;| &quot;Animal&quot;                               | 5665.755894233272  |&lt;br /&gt;| &quot;Country&quot;                              | 5422.733465218685  |&lt;br /&gt;| &quot;County&quot;                               | 5097.065153505375  |&lt;br /&gt;| &quot;World War II&quot;                         | 4903.803574507514  |&lt;br /&gt;| &quot;Germany&quot;                              | 4758.829204613294  |&lt;br /&gt;| &quot;United Kingdom&quot;                       | 4538.534060897834  |&lt;br /&gt;| &quot;Russia&quot;                               | 4328.2166400665055 |&lt;br /&gt;| &quot;English&quot;                              | 4220.257198573251  |&lt;br /&gt;| &quot;India&quot;                                | 3956.6896584623237 |&lt;br /&gt;| &quot;England&quot;                              | 3895.7939536781337 |&lt;br /&gt;| &quot;Japan&quot;                                | 3665.9152429486285 |&lt;br /&gt;| &quot;Canada&quot;                               | 3657.4749257843423 |&lt;br /&gt;| &quot;Australia&quot;                            | 3595.941069092141  |&lt;br /&gt;| &quot;Iran&quot;                                 | 3482.6418104876884 |&lt;br /&gt;| &quot;Province&quot;                             | 3400.887300974972  |&lt;br /&gt;| &quot;China&quot;                                | 3239.811469195496  |&lt;br /&gt;| &quot;American&quot;                             | 3192.7699175209023 |&lt;br /&gt;| &quot;French&quot;                               | 3182.4457685761104 |&lt;br /&gt;| &quot;The New York Times&quot;                   | 3181.5839069249864 |&lt;br /&gt;| &quot;Arthropod&quot;                            | 3097.8173315850213 |&lt;br /&gt;| &quot;Italy&quot;                                | 3032.3644182841776 |&lt;br /&gt;| &quot;German&quot;                               | 3012.815858491087  |&lt;br /&gt;| &quot;London&quot;                               | 2965.4743930058657 |&lt;br /&gt;| &quot;Insect&quot;                               | 2869.920827785085  |&lt;br /&gt;| &quot;District&quot;                             | 2784.755324500963  |&lt;br /&gt;| &quot;Spain&quot;                                | 2668.2978896378804 |&lt;br /&gt;| &quot;New York City&quot;                        | 2650.752385794727  |&lt;br /&gt;| &quot;Latin&quot;                                | 2584.6877541535127 |&lt;br /&gt;| &quot;Poland&quot;                               | 2575.2112457023773 |&lt;br /&gt;| &quot;World War I&quot;                          | 2573.8477947401866 |&lt;br /&gt;| &quot;Soviet Union&quot;                         | 2477.694486425502  |&lt;br /&gt;| &quot;Catholic Church&quot;                      | 2474.683318006141  |&lt;br /&gt;| &quot;New York&quot;                             | 2468.8443657519097 |&lt;br /&gt;| &quot;Brazil&quot;                               | 2435.2531424225617 |&lt;br /&gt;| &quot;Romania&quot;                              | 2393.1873377303928 |&lt;br /&gt;| &quot;Europe&quot;                               | 2353.968692909295  |&lt;br /&gt;| &quot;California&quot;                           | 2266.6608579578156 |&lt;br /&gt;| &quot;Lepidoptera&quot;                          | 2158.715841127394  |&lt;br /&gt;| &quot;State&quot;                                | 2132.243578231637  |&lt;br /&gt;| &quot;Italian&quot;                              | 2106.6553548486086 |&lt;br /&gt;| &quot;Greek&quot;                                | 2028.1563330073805 |&lt;br /&gt;| &quot;Switzerland&quot;                          | 2027.8234786567634 |&lt;br /&gt;| &quot;Paris&quot;                                | 1970.357297581375  |&lt;br /&gt;| &quot;Chordata&quot;                             | 1950.4239922246595 |&lt;br /&gt;| &quot;Spanish&quot;                              | 1926.201753857372  |&lt;br /&gt;| &quot;New Zealand&quot;                          | 1828.6683122383472 |&lt;br /&gt;| &quot;Mexico&quot;                               | 1828.0197503654385 |&lt;br /&gt;| &quot;British&quot;                              | 1811.7648105938251 |&lt;br /&gt;| &quot;Washington, D.C.&quot;                     | 1810.533732133272  |&lt;br /&gt;| &quot;Netherlands&quot;                          | 1803.7312379217158 |&lt;br /&gt;| &quot;Scotland&quot;                             | 1776.2112626996402 |&lt;br /&gt;| &quot;National Register of Historic Places&quot; | 1765.6396180107192 |&lt;br /&gt;| &quot;Sweden&quot;                               | 1750.4933182628488 |&lt;br /&gt;| &quot;USA&quot;                                  | 1708.9086633673999 |&lt;br /&gt;| &quot;Chordate&quot;                             | 1659.5183460486119 |&lt;br /&gt;| &quot;Ireland&quot;                              | 1630.2162859072075 |&lt;br /&gt;| &quot;United States Census Bureau&quot;          | 1590.6841804100668 |&lt;br /&gt;| &quot;Turkey&quot;                               | 1571.7895450758779 |&lt;br /&gt;| &quot;South Africa&quot;                         | 1552.1113319282647 |&lt;br /&gt;| &quot;Belgium&quot;                              | 1548.2393303043832 |&lt;br /&gt;| &quot;Austria&quot;                              | 1517.0098756018515 |&lt;br /&gt;| &quot;Los Angeles&quot;                          | 1487.3395876804987 |&lt;br /&gt;| &quot;Region&quot;                               | 1455.4554257569105 |&lt;br /&gt;| &quot;Municipality&quot;                         | 1422.385733793246  |&lt;br /&gt;| &quot;Greece&quot;                               | 1415.3614936831354 |&lt;br /&gt;| &quot;CET&quot;                                  | 1393.056892061773  |&lt;br /&gt;| &quot;Norway&quot;                               | 1387.064297388938  |&lt;br /&gt;| &quot;Chicago&quot;                              | 1386.6868499051984 |&lt;br /&gt;| &quot;European Union&quot;                       | 1382.571030912079  |&lt;br /&gt;| &quot;President&quot;                            | 1376.0926002579163 |&lt;br /&gt;| &quot;Philippines&quot;                          | 1371.3808757708794 |&lt;br /&gt;| &quot;BBC&quot;                                  | 1362.697735274599  |&lt;br /&gt;| &quot;White&quot;                                | 1329.6229862450132 |&lt;br /&gt;| &quot;Voivodeship&quot;                          | 1325.3419002294163 |&lt;br /&gt;| &quot;African American&quot;                     | 1316.08289317503   |&lt;br /&gt;| &quot;New York Times&quot;                       | 1305.9732797320457 |&lt;br /&gt;| &quot;Israel&quot;                               | 1289.4941308687928 |&lt;br /&gt;| &quot;United Nations&quot;                       | 1275.3410092372967 |&lt;br /&gt;| &quot;Rome&quot;                                 | 1268.7924011211794 |&lt;br /&gt;| &quot;Gmina&quot;                                | 1264.8386282950032 |&lt;br /&gt;| &quot;CEST&quot;                                 | 1263.3655294822495 |&lt;br /&gt;| &quot;Canadian&quot;                             | 1257.0066905218277 |&lt;br /&gt;| &quot;Argentina&quot;                            | 1256.590368894054  |&lt;br /&gt;| &quot;Dutch&quot;                                | 1253.7080447443823 |&lt;br /&gt;| &quot;Angiosperms&quot;                          | 1247.3964328063778 |&lt;br /&gt;| &quot;Taiwan&quot;                               | 1244.5572462360428 |&lt;br /&gt;| &quot;Native Americans&quot;                     | 1231.9646926767173 |&lt;br /&gt;| &quot;Egypt&quot;                                | 1230.2800089879247 |&lt;br /&gt;| &quot;Chinese&quot;                              | 1226.417515716627  |&lt;br /&gt;| &quot;North America&quot;                        | 1226.211997093438  |&lt;br /&gt;| &quot;Indonesia&quot;                            | 1221.68337046196   |&lt;br /&gt;| &quot;Oxford University Press&quot;              | 1205.4955933795306 |&lt;br /&gt;| &quot;Roman Catholic&quot;                       | 1205.3842960845823 |&lt;br /&gt;| &quot;Islam&quot;                                | 1200.4126147456059 |&lt;br /&gt;| &quot;Pakistan&quot;                             | 1199.2589818906795 |&lt;br /&gt;| &quot;Jews&quot;                                 | 1187.7942956454976 |&lt;br /&gt;| &quot;Texas&quot;                                | 1187.3229003531255 |&lt;br /&gt;| &quot;The Guardian&quot;                         | 1185.9922865148167 |&lt;br /&gt;+-------------------------------------------------------------+&lt;/code&gt;&lt;/pre&gt;&lt;h3&gt;Try it out&lt;/h3&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Mazerunner is currently in its alpha stages of development. For this  initial release PageRank is the only available graph processing  algorithm.&lt;br /&gt;&lt;div&gt;&lt;br /&gt;Head over to the &lt;a href=&quot;https://github.com/kbastani/neo4j-mazerunner&quot; target=&quot;_blank&quot;&gt;GitHub repository&lt;/a&gt; to keep track of the progress of the project as it moves forward to its 1.0.0 release.&lt;/div&gt;&lt;/div&gt;&lt;br/&gt;&lt;a href=&quot;https://news.ycombinator.com/submit&quot; class=&quot;hn-button&quot; data-title=&quot;Using Apache Spark and Neo4j for Big Data Graph Analytics&quot; data-url=&quot;http://www.kennybastani.com/2014/11/using-apache-spark-and-neo4j-for-big.html&quot; data-count=&quot;horizontal&quot;&gt;Vote on Hacker News&lt;/a&gt;&lt;script type=&quot;text/javascript&quot;&gt;var HN=[];HN.factory=function(e){return function(){HN.push([e].concat(Array.prototype.slice.call(arguments,0)))};},HN.on=HN.factory(&quot;on&quot;),HN.once=HN.factory(&quot;once&quot;),HN.off=HN.factory(&quot;off&quot;),HN.emit=HN.factory(&quot;emit&quot;),HN.load=function(){var e=&quot;hn-button.js&quot;;if(document.getElementById(e))return;var t=document.createElement(&quot;script&quot;);t.id=e,t.src=&quot;//hn-button.herokuapp.com/hn-button.js&quot;;var n=document.getElementsByTagName(&quot;script&quot;)[0];n.parentNode.insertBefore(t,n)},HN.load();&lt;/script&gt;</description><link>https://www.kennybastani.com/2014/11/using-apache-spark-and-neo4j-for-big.html</link><author>noreply@blogger.com (Kenny Bastani)</author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://1.bp.blogspot.com/-gta3ODAcdBg/VFf-ROiOR8I/AAAAAAAAA8w/Jxu99gIW3cE/s72-c/movie-model.png" height="72" width="72"/><thr:total>0</thr:total></item><item><guid isPermaLink="false">tag:blogger.com,1999:blog-6300367579216018061.post-4401667510940730909</guid><pubDate>Mon, 15 Sep 2014 19:14:00 +0000</pubDate><atom:updated>2015-02-05T21:36:03.374-08:00</atom:updated><category domain="http://www.blogger.com/atom/ns#">deep learning</category><category domain="http://www.blogger.com/atom/ns#">graph data modeling</category><category domain="http://www.blogger.com/atom/ns#">graph database</category><category domain="http://www.blogger.com/atom/ns#">graphify</category><category domain="http://www.blogger.com/atom/ns#">machine learning</category><category domain="http://www.blogger.com/atom/ns#">natural language processing</category><category domain="http://www.blogger.com/atom/ns#">neo4j</category><category domain="http://www.blogger.com/atom/ns#">sentiment analysis</category><category domain="http://www.blogger.com/atom/ns#">text classification</category><title>Deep Learning Sentiment Analysis for Movie Reviews using Neo4j</title><description>&lt;p&gt;&lt;i&gt;While the title of this article references Deep Learning, it&#39;s important to note that the process described below is more of a deep learning metaphor into a graph-based machine learning algorithm. No neural networks are used.&lt;/i&gt;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Sentiment_analysis&quot;&gt;Sentiment analysis&lt;/a&gt; uses natural language processing to &lt;a href=&quot;http://en.wikipedia.org/wiki/Feature_selection&quot;&gt;extract features&lt;/a&gt; of a text that relate to subjective information found in source materials.&lt;/p&gt; &lt;h3&gt;Movie Review Sentiment Analysis&lt;/h3&gt; &lt;p&gt;A movie review website allows users to submit reviews describing what they either liked or disliked about a particular movie. Being able to mine these reviews and generate valuable meta data that describes its content provides an opportunity to understand the general sentiment around that movie in a democratized way. That’s a pretty cool thing if you think about it. Using machine learning we can democratize subjectivity about anything in the world. We can make an objective analysis of subjective content, giving us the ability to better understand trends around products and services that we can use to make better decisions as consumers.&lt;/p&gt; &lt;a name=&#39;more&#39;&gt;&lt;/a&gt; &lt;h3&gt;Sentiment Analysis Data Model&lt;/h3&gt; &lt;p&gt;One of the major barriers to unlocking this ability is in the way we structure and transform our data. The current state-of-the-art methods include approaches such as &lt;a href=&quot;http://en.wikipedia.org/wiki/Naive_Bayes_classifier&quot;&gt;Naive Bayes&lt;/a&gt;, &lt;a href=&quot;http://en.wikipedia.org/wiki/Support_vector_machine&quot;&gt;Support Vector Machines&lt;/a&gt;, and &lt;a href=&quot;http://en.wikipedia.org/wiki/Multinomial_logistic_regression&quot;&gt;Maximum Entropy&lt;/a&gt;. The challenges imposed by these approaches still remains in how features are extracted from a text and structured as data in a way that is least costly in terms of performance. I decided to focus on solving the problem of performance, in the way features are selected and extracted, and the availability of that data as the number of features grow over time.&lt;/p&gt;  &lt;p&gt;Using a &lt;a href=&quot;http://en.wikipedia.org/wiki/Feature_selection&quot;&gt;feature selection&lt;/a&gt; algorithm I describe &lt;a href=&quot;http://www.kennybastani.com/2014/06/hierchical-pattern-recognition.html&quot;&gt;here&lt;/a&gt;, I used the &lt;a href=&quot;http://www.neo4j.com&quot;&gt;Graph Database Neo4j&lt;/a&gt; to solve the challenge of data transformation and availability. While the &lt;a href=&quot;http://nlp.stanford.edu/sentiment/&quot;&gt;state of the art natural language parsing algorithms&lt;/a&gt; are focused on sentence structure, I’ve decided to pursue a statistical approach to &lt;a href=&quot;http://en.wikipedia.org/wiki/Grammar_induction&quot;&gt;natural language grammar induction&lt;/a&gt;. My approach focuses on generalizations across a vast corpus of text, generating new features using a method inspired by &lt;a href=&quot;http://en.wikipedia.org/wiki/Deep_learning&quot;&gt;deep learning&lt;/a&gt;, which predicts features with the highest probability of being present to the left or right of a new feature.&lt;/p&gt;  &lt;h3&gt;Graph-based NLP Example&lt;/h3&gt;  &lt;p&gt;Let&#39;s assume that the phrase “&lt;b&gt;one of the worst&lt;/b&gt;” has been extracted as a feature of a set of texts. The reason that this phrase was extracted was that a phrase that it was descended from had determined that this particular phrase was the most statistically relevant, meaning that the phrase had the best chance of being matched after the parent phrase. Using Neo4j we can determine the line of inheritance that produced this phrase as a feature.&lt;/p&gt;  &lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;http://3.bp.blogspot.com/-chxX9JlvqE8/VBc12JXqrPI/AAAAAAAAA78/gvzXro5PedA/s1600/movie-sentiment-1.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-chxX9JlvqE8/VBc12JXqrPI/AAAAAAAAA78/gvzXro5PedA/s640/movie-sentiment-1.png&quot; /&gt;&lt;/a&gt;&lt;/div&gt;  &lt;p&gt;Starting at the root node, which is captioned as “&lt;b&gt;{0} {1}&lt;/b&gt;”, the path in which the phrase “&lt;b&gt;one of the worst&lt;/b&gt;” will be parsed is &lt;b&gt;(the)-&gt;(of the)-&gt;(one of the)-&gt;(one of the worst)&lt;/b&gt;.&lt;/p&gt; &lt;p&gt;The hierarchy reveals more possibilities as you move deeper from “&lt;b&gt;one of the worst&lt;/b&gt;”. Expanding the path seen in the image above to include all possible features that descend from the phrase “&lt;b&gt;one of the worst&lt;/b&gt;” reveals the following:&lt;/p&gt; &lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;http://4.bp.blogspot.com/-8XMgLdZIF-w/VBc2Usjz4rI/AAAAAAAAA8E/LF9kzt1eDlM/s1600/movie-sentiment-2.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-8XMgLdZIF-w/VBc2Usjz4rI/AAAAAAAAA8E/LF9kzt1eDlM/s640/movie-sentiment-2.png&quot; /&gt;&lt;/a&gt;&lt;/div&gt; &lt;p&gt;This feature selection algorithm can select on the most statistically relevant features and phrases extracted from a corpus of text in less than a second. The reason an approach like this is extremely relevant to sentiment analysis is that these pattern nodes can be connected to the label of the text they were trained from, as seen below.&lt;/p&gt; &lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;http://4.bp.blogspot.com/-6QFCfAxSfcc/VBc2rRhA6rI/AAAAAAAAA8M/eW37Ie6lOe4/s1600/movie-sentiment-3.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-6QFCfAxSfcc/VBc2rRhA6rI/AAAAAAAAA8M/eW37Ie6lOe4/s640/movie-sentiment-3.png&quot; /&gt;&lt;/a&gt;&lt;/div&gt; &lt;p&gt;The result of this algorithm, and largely thanks to Neo4j’s graph traversals, is that any natural language text can be parsed with sub second performance and generate a subgraph to be used for whichever classification algorithm makes the most sense for your dataset.&lt;/p&gt; &lt;h3&gt;Open Source Demo&lt;/h3&gt; &lt;p&gt;For the movie review example I took 500 movie reviews for both negative and positive labels and trained a natural language parsing model in Neo4j using &lt;a href=&quot;https://github.com/kbastani/graphify&quot;&gt;Graphify&lt;/a&gt;. In the next blog post in this series I will introduce you to a demo that can perform better at classifying movie reviews than a human. The &lt;a href=&quot;http://en.wikipedia.org/wiki/Sentiment_analysis#Evaluation&quot;&gt;human classification error being 0.3, or 70% success&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;If you’re looking to get your feet wet before then, take a look at the finished demo here: &lt;a href=&quot;https://github.com/kbastani/graphify/tree/master/src/examples/graphify-examples-sentiment-analysis&quot;&gt;Graphify Sentiment Analysis for Movie Reviews&lt;/a&gt;&lt;/p&gt; &lt;h3&gt;Notes&lt;/h3&gt; &lt;p&gt;&lt;a href=&quot;http://www.neo4j.com&quot;&gt;Neo4j&lt;/a&gt; is an open source graph database.&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/kbastani/graphify&quot;&gt;Graphify&lt;/a&gt; is an open source extension to Neo4j that extends Neo4j to include classification-based algorithms for natural language processing.&lt;/p&gt;&lt;a href=&quot;https://news.ycombinator.com/submit&quot; class=&quot;hn-button&quot; data-title=&quot;Deep Learning Sentiment Analysis for Movie Reviews using Neo4j &quot; data-url=&quot;http://www.kennybastani.com/2014/09/deep-learning-sentiment-analysis-for.html&quot; data-count=&quot;horizontal&quot;&gt;Vote on Hacker News&lt;/a&gt;&lt;script type=&quot;text/javascript&quot;&gt;var HN=[];HN.factory=function(e){return function(){HN.push([e].concat(Array.prototype.slice.call(arguments,0)))};},HN.on=HN.factory(&quot;on&quot;),HN.once=HN.factory(&quot;once&quot;),HN.off=HN.factory(&quot;off&quot;),HN.emit=HN.factory(&quot;emit&quot;),HN.load=function(){var e=&quot;hn-button.js&quot;;if(document.getElementById(e))return;var t=document.createElement(&quot;script&quot;);t.id=e,t.src=&quot;//hn-button.herokuapp.com/hn-button.js&quot;;var n=document.getElementsByTagName(&quot;script&quot;)[0];n.parentNode.insertBefore(t,n)},HN.load();&lt;/script&gt;</description><link>https://www.kennybastani.com/2014/09/deep-learning-sentiment-analysis-for.html</link><author>noreply@blogger.com (Kenny Bastani)</author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://3.bp.blogspot.com/-chxX9JlvqE8/VBc12JXqrPI/AAAAAAAAA78/gvzXro5PedA/s72-c/movie-sentiment-1.png" height="72" width="72"/><thr:total>0</thr:total></item><item><guid isPermaLink="false">tag:blogger.com,1999:blog-6300367579216018061.post-642063457744207821</guid><pubDate>Wed, 27 Aug 2014 00:45:00 +0000</pubDate><atom:updated>2014-11-27T19:59:47.620-08:00</atom:updated><category domain="http://www.blogger.com/atom/ns#">document classification</category><category domain="http://www.blogger.com/atom/ns#">feature learning</category><category domain="http://www.blogger.com/atom/ns#">graph database</category><category domain="http://www.blogger.com/atom/ns#">natural language processing</category><category domain="http://www.blogger.com/atom/ns#">neo4j</category><category domain="http://www.blogger.com/atom/ns#">pattern recognition</category><category domain="http://www.blogger.com/atom/ns#">text classification</category><title>Using a Graph Database for Deep Learning Text Classification</title><description>&lt;a href=&quot;https://github.com/kbastani/graphify&quot;&gt;Graphify&lt;/a&gt; is a &lt;a href=&quot;http://www.neo4j.com&quot;&gt;Neo4j&lt;/a&gt; unmanaged extension that provides plug and play &lt;a href=&quot;http://en.wikipedia.org/wiki/Text_classification&quot;&gt;natural language text classification&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;Graphify gives you a mechanism to train &lt;a href=&quot;http://en.wikipedia.org/wiki/Language_model&quot;&gt;natural language parsing models&lt;/a&gt; that &lt;a href=&quot;http://en.wikipedia.org/wiki/Feature_extraction&quot;&gt;extract features&lt;/a&gt; of a text using &lt;a href=&quot;http://en.wikipedia.org/wiki/Deep_learning&quot;&gt;deep learning&lt;/a&gt;. When training a model to recognize the meaning of a text, you can send an article of text with a provided set of labels that describe the nature of the text. Over time the natural language parsing model in Neo4j will grow to identify those features that optimally disambiguate a text to a set of classes.&lt;br /&gt;&lt;br /&gt;&lt;img alt=&quot;Feature Hierarchy&quot; data-canonical-src=&quot;http://i.imgur.com/NTFytZ8.png&quot; src=&quot;https://camo.githubusercontent.com/4cfa3ba468abd2424c7e763c40df8fc4a5b3903b/687474703a2f2f692e696d6775722e636f6d2f4e544679745a382e706e67&quot; /&gt;&lt;br /&gt;&lt;br /&gt;&lt;a name=&#39;more&#39;&gt;&lt;/a&gt;The &lt;a href=&quot;http://en.wikipedia.org/wiki/Statistical_parsing&quot;&gt;feature hierarchy is generated probabilistically&lt;/a&gt; as a result of a statistical analysis of neighboring words to a feature. By doing this it becomes possible to recognize a large set of features in test data by eliminating possibilities at each layer.&lt;br /&gt;&lt;br /&gt;The lowest level &lt;a href=&quot;http://en.wikipedia.org/wiki/Learning_representation&quot;&gt;representation of a feature&lt;/a&gt; is closest to the root pattern. In the case of Graphify, the root pattern is a space character. As training increases the number of examples that match the space character, deeper levels of representations will be generated by choosing features with the highest probability of being matched to the left or right of a feature. This kind of deep learning doesn&#39;t require a neural network because of the nature of &lt;a href=&quot;http://docs.neo4j.org/chunked/stable/what-is-a-graphdb.html&quot;&gt;Neo4j&#39;s property graph data model&lt;/a&gt;, providing a way to generate a &lt;a href=&quot;http://en.wikipedia.org/wiki/Vector_space_model&quot;&gt;vector space model&lt;/a&gt; of extracted features and relate them to feature vectors by means of &lt;a href=&quot;http://en.wikipedia.org/wiki/Cosine_similarity&quot;&gt;cosine similarity&lt;/a&gt; of the classes which are mapped to a subset of feature nodes within the hierarchy.&lt;br /&gt;&lt;br /&gt;An advantage of using Neo4j to do this is that you can attach classes to the features that matched text with those classes being applied as labels during training.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;img alt=&quot;Features Have Classes&quot; data-canonical-src=&quot;http://i.imgur.com/BTWbu7N.png&quot; src=&quot;https://camo.githubusercontent.com/8f7ada6b71735847336815587d7c6e66c0696320/687474703a2f2f692e696d6775722e636f6d2f4254576275374e2e706e67&quot; /&gt;&lt;br /&gt;&lt;br /&gt;Using a 3D visualization tool called &lt;a href=&quot;http://ubietylab.net/ubigraph/&quot;&gt;UbiGraph&lt;/a&gt;, a visualization of the feature hierarchy shows how deep feature representations grow over time.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;img alt=&quot;Training the feature hierarchy&quot; data-canonical-src=&quot;http://fat.gfycat.com/FarawayPlasticJellyfish.gif&quot; src=&quot;https://camo.githubusercontent.com/f4b612c2434b278d659b67349417f9e81305f88b/687474703a2f2f6661742e6766796361742e636f6d2f46617261776179506c61737469634a656c6c79666973682e676966&quot; /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;Vector Space Model&lt;/h3&gt;&lt;br /&gt;Graphify generates a &lt;code&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Vector_space_model&quot;&gt;Vector Space Model&lt;/a&gt;&lt;/code&gt; when classifying text on training data. There are two endpoints that provide classification and similarity features.&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;Classify unlabeled text&lt;/h3&gt;&lt;br /&gt;The first endpoint is &lt;code&gt;http://localhost:7474/service/graphify/classify&lt;/code&gt; which supports the HTTP method &lt;code&gt;POST&lt;/code&gt;. By posting the following JSON model, the text property will automatically be classified to the feature vector of all previously trained classes and sorted by the cosine similarity between these vectors.&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;code&gt;{&lt;br /&gt;    &quot;text&quot;: &quot;Interoperability is the ability of making systems work together.&quot;&lt;br /&gt;}&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;The result that will be returned from Neo4j will be a sorted list of matches that are ordered on the cosine similarity of feature vectors for each class in the database.&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;code&gt;{&lt;br /&gt;    &quot;classes&quot;: [&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Interoperability&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.01478629324290398&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Natural language&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.014352533094325508&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Artificial intelligence&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.008389954131481638&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Graph database&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.006780234851792194&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Inference engine&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.005775135975571818&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Neo4j&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.005011493979094744&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Expert system&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.0045493507614881076&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Knowledge representation and reasoning&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.0035488311479422202&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Speech recognition&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.0035459146405026746&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Knowledge acquisition&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.0033585907499658666&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Memory&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.003286652624915932&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Cognitive robotics&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.0026605991849062826&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Hierarchical control system&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.0024852750266223995&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;NoSQL&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.002359964627061625&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Hierarchical database model&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.0016629332691377717&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Never-Ending Language Learning&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.0014433749914281816&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Multilayer perceptron&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.0014070718231579983&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Sentence (linguistics)&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.0012682029230640021&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Argument&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.0012446298877431268&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Deep learning&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.0011171501184315629&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Inductive reasoning&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.0010671296082781958&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Machine translation&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.0010150803638098256&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Automatic Language Translator&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.001008811074376599&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Relational database&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.0009875922800915275&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Storage (memory)&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.000980910572273953&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Clause&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.0009355842513276578&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Dependency grammar&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.0006764745128168179&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Autoencoder&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.0005224831369792641&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Phrase&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.00029583989661492754&lt;br /&gt;        }&lt;br /&gt;    ]&lt;br /&gt;}&lt;/code&gt;&lt;br /&gt;&lt;/pre&gt;&lt;h3&gt;Get similar classes&lt;/h3&gt;&lt;br /&gt;To get most related classes, which were provided during training as labels, the following endpoint: &lt;code&gt;http://localhost:7474/service/graphify/similar/{class}&lt;/code&gt; provides a way to get the most similar classes to a provided class name. Again, this uses a vector space model generated from the hierarchy of features mined in the pattern recognition tree.&lt;br /&gt;&lt;br /&gt;The result is a sorted list of classes ordered by the cosine similarity of each of the feature vectors associated with a class.&lt;br /&gt;&lt;br /&gt;For example, issuing a HTTP &lt;code&gt;GET&lt;/code&gt; request to the following endpoint, &lt;code&gt;http://localhost:7474/service/graphify/similar/NoSQL&lt;/code&gt; returns the following results:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;code&gt;{&lt;br /&gt;    &quot;classes&quot;: [&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Graph database&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.09574535643836013&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Relational database&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.07991318266439677&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Machine translation&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.07693041732140395&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Deep learning&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.07027180553561777&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Speech recognition&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.06491846260229797&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Knowledge representation and reasoning&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.061825794099321346&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Artificial intelligence&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.059426927894936345&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Multilayer perceptron&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.056943365042175544&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Hierarchical database model&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.05617955585333319&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Interoperability&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.05541367925131132&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Memory&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.05514558364443694&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Expert system&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.04869202636766413&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Inductive reasoning&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.04542968846354395&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Argument&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.04473621436021445&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Clause&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.03686385050753761&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Dependency grammar&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.035584209032388084&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Sentence (linguistics)&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.03329025076397098&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Inference engine&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.031225512897898145&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Neo4j&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.03101280823703653&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Storage (memory)&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.02979918393661567&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Hierarchical control system&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.028800749676585427&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Autoencoder&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.02527201414259688&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Cognitive robotics&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.023697018076748396&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Never-Ending Language Learning&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.021246276238820964&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Phrase&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.019941608021991825&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Natural language&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.019809613865907624&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Automatic Language Translator&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.017520049172816868&lt;br /&gt;        },&lt;br /&gt;        {&lt;br /&gt;            &quot;class&quot;: &quot;Knowledge acquisition&quot;,&lt;br /&gt;            &quot;similarity&quot;: 0.01264614704679436&lt;br /&gt;        }&lt;br /&gt;    ]&lt;br /&gt;}&lt;/code&gt;&lt;br /&gt;&lt;/pre&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;h3&gt;Training&lt;/h3&gt;&lt;br /&gt;The training endpoint is located at &lt;code&gt;http://localhost:7474/service/graphify/training&lt;/code&gt;. By issuing an HTTP &lt;code&gt;POST&lt;/code&gt; request to this endpoint with the following model:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;code&gt;{&lt;br /&gt;    &quot;text&quot;: [&lt;br /&gt;        &quot;Interoperability is the ability of making systems and organizations work together.&quot;&lt;br /&gt;    ],&lt;br /&gt;    &quot;label&quot;: [&lt;br /&gt;        &quot;Interoperability&quot;&lt;br /&gt;    ]&lt;br /&gt;}&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;Features are learned through repetition. The more text containing similar phrases (&lt;a href=&quot;http://en.wikipedia.org/wiki/N-gram&quot;&gt;n-grams&lt;/a&gt;), the more likely those features will be extracted and associated with any classes contained in prior training data. &lt;br/&gt;&lt;br/&gt;&lt;h3&gt;Links&lt;/h3&gt;&lt;p&gt;If you&#39;re interested in being a pioneer and testing out this &lt;a href=&quot;http://docs.neo4j.org/chunked/stable/server-unmanaged-extensions.html&quot;&gt;unmanaged extension&lt;/a&gt;, head on over to the GitHub project page and follow the installation instructions.&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/kbastani/graphify&quot;&gt;https://github.com/kbastani/graphify&lt;/a&gt;&lt;/p&gt;&lt;p&gt;To better provide examples of how to implement this extension for your use cases, I will soon be authoring a sample project that creates a vector space model from a collection of Wikipedia documents.&lt;/p&gt;&lt;p&gt;If you&#39;re interested in helping contribute, please tweet me at &lt;a href=&quot;http://www.twitter.com/kennybastani&quot;&gt;@kennybastani&lt;/a&gt;&lt;/p&gt;&lt;a href=&quot;https://news.ycombinator.com/submit&quot; class=&quot;hn-button&quot; data-title=&quot;Using a Graph Database for Deep Learning Text Classification&quot; data-url=&quot;http://www.kennybastani.com/2014/08/using-graph-database-for-deep-learning-text-classification.html&quot; data-count=&quot;horizontal&quot;&gt;Vote on Hacker News&lt;/a&gt;&lt;script type=&quot;text/javascript&quot;&gt;var HN=[];HN.factory=function(e){return function(){HN.push([e].concat(Array.prototype.slice.call(arguments,0)))};},HN.on=HN.factory(&quot;on&quot;),HN.once=HN.factory(&quot;once&quot;),HN.off=HN.factory(&quot;off&quot;),HN.emit=HN.factory(&quot;emit&quot;),HN.load=function(){var e=&quot;hn-button.js&quot;;if(document.getElementById(e))return;var t=document.createElement(&quot;script&quot;);t.id=e,t.src=&quot;//hn-button.herokuapp.com/hn-button.js&quot;;var n=document.getElementsByTagName(&quot;script&quot;)[0];n.parentNode.insertBefore(t,n)},HN.load();&lt;/script&gt;</description><link>https://www.kennybastani.com/2014/08/using-graph-database-for-deep-learning-text-classification.html</link><author>noreply@blogger.com (Kenny Bastani)</author><thr:total>0</thr:total></item><item><guid isPermaLink="false">tag:blogger.com,1999:blog-6300367579216018061.post-7246453222913999813</guid><pubDate>Thu, 10 Jul 2014 04:35:00 +0000</pubDate><atom:updated>2015-12-08T00:15:27.827-08:00</atom:updated><category domain="http://www.blogger.com/atom/ns#">cypher</category><category domain="http://www.blogger.com/atom/ns#">declarative query language</category><category domain="http://www.blogger.com/atom/ns#">execution planning</category><category domain="http://www.blogger.com/atom/ns#">graph database</category><category domain="http://www.blogger.com/atom/ns#">graphs</category><category domain="http://www.blogger.com/atom/ns#">neo4j</category><category domain="http://www.blogger.com/atom/ns#">open source software</category><title>Understanding How Neo4j Cypher Queries are Evaluated</title><description>&lt;script src=&quot;https://google-code-prettify.googlecode.com/svn/loader/run_prettify.js&quot;&gt;&lt;/script&gt;There are many ways to store and manage data within a &lt;a href=&quot;http://www.neo4j.com/&quot; target=&quot;_blank&quot;&gt;Neo4j graph database&lt;/a&gt;. When Neo4j 2.0 launched late last year we had an entirely new browser experience for interacting with graphs. The graph visualization from the return results of Cypher queries were at the core of the user experience enhancements to the platform.&lt;br /&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;http://4.bp.blogspot.com/-QgyjbOTkSo8/U72irZchIJI/AAAAAAAAA7E/QouCN-D8DX4/s1600/neo4j-browser.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-QgyjbOTkSo8/U72irZchIJI/AAAAAAAAA7E/QouCN-D8DX4/s1600/neo4j-browser.png&quot; height=&quot;496&quot; width=&quot;640&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;a name=&#39;more&#39;&gt;&lt;/a&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;For most users that use the Neo4j browser, this is an ideal experience for learning and designing great graph data models for querying. For applications that require a deeper control over how graphs are stored and queried, the native&amp;nbsp;&lt;a href=&quot;http://docs.neo4j.org/chunked/stable/tutorials-java-embedded.html&quot; target=&quot;_blank&quot;&gt;Java API&lt;/a&gt; provides a great deal of benefits. When using the Java API you gain a degree of freedom to tell Neo4j how to query your data.&lt;br /&gt;&lt;br /&gt;The &lt;a href=&quot;http://docs.neo4j.org/chunked/stable/cypher-introduction.html&quot; target=&quot;_blank&quot;&gt;Cypher query language&lt;/a&gt;, with an innovative SQL-like syntax for graphs, is a declarative query language. That means you tell Neo4j what you want and not how to get it. When you run a Cypher query you are expressing to the graph database what you want from it. In turn, Neo4j maintains a compiler that translates that query into&amp;nbsp;an execution plan that describes a set of data operations, arranged such that data is obtained from the graph and processed sequentially through each operation until a result is generated for the user.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;h4&gt;What does an execution plan look like?&lt;/h4&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;The typical approach for interacting with Neo4j involves sending a Cypher query and parameters in a POST request to the Neo4j database server. We call the frameworks or libraries that manage wrappers around the REST API methods of Neo4j from an arbitrary programming language a &quot;&lt;a href=&quot;http://neo4j.com/contrib/&quot; target=&quot;_blank&quot;&gt;driver&lt;/a&gt;&quot;. These drivers transport queries and results over the network and Neo4j further translates the declarative syntax of Cypher into an execution plan.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Using the &lt;a href=&quot;http://console.neo4j.org/&quot; target=&quot;_blank&quot;&gt;Neo4j web-based console&lt;/a&gt;, we can get the results of each query in the detailed query results.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;I&#39;ve setup a sample graph with 3 people: Kenny, Adam, and Greta. These 3 people are friends on a social network.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;iframe height=&quot;600&quot; src=&quot;http://console.neo4j.org/r/f71ux0&quot; width=&quot;900&quot;&gt;&lt;/iframe&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;If you run an &quot;All Nodes&quot; query in the console above:&lt;br /&gt;&lt;br /&gt;&lt;pre data-lang=&quot;cypher&quot;&gt;&lt;br /&gt;// All nodes query&lt;br /&gt;MATCH (n)&lt;br /&gt;RETURN n&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;You will be able to see the detailed results by clicking on the &quot;Result Details&quot; button, shown in the screenshot below.&lt;br /&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;http://4.bp.blogspot.com/-rbz7DQ81v-A/U72nGjdB29I/AAAAAAAAA7Q/zgxcnjv_2_4/s1600/Neo4j_Console.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-rbz7DQ81v-A/U72nGjdB29I/AAAAAAAAA7Q/zgxcnjv_2_4/s1600/Neo4j_Console.png&quot; height=&quot;165&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;h3 style=&quot;color: #111111; font-family: &#39;Bitstream Vera Sans Mono&#39;, &#39;DejaVu Sans Mono&#39;, Consolas, Monaco, Courier, monospace; margin: 1px;&quot;&gt;Detailed Query Results&lt;/h3&gt;&lt;pre id=&quot;stats-output&quot;&gt;&lt;h4 style=&quot;color: #111111; font-family: &#39;Bitstream Vera Sans Mono&#39;, &#39;DejaVu Sans Mono&#39;, Consolas, Monaco, Courier, monospace !important; font-size: 12px;&quot;&gt;&lt;br /&gt;Query Results&lt;/h4&gt;&lt;br /&gt;&lt;span style=&quot;color: #111111; font-family: Bitstream Vera Sans Mono, DejaVu Sans Mono, Consolas, Monaco, Courier, monospace;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;+-----------------------+&lt;br /&gt;| n                     |&lt;br /&gt;+-----------------------+&lt;br /&gt;| Node[6]{name:&quot;Kenny&quot;} |&lt;br /&gt;| Node[7]{name:&quot;Adam&quot;}  |&lt;br /&gt;| Node[8]{name:&quot;Greta&quot;} |&lt;br /&gt;+-----------------------+&lt;br /&gt;3 rows&lt;br /&gt;6 ms&lt;br /&gt;&lt;/span&gt;&lt;/span&gt;&lt;h4 style=&quot;color: #111111; font-family: &#39;Bitstream Vera Sans Mono&#39;, &#39;DejaVu Sans Mono&#39;, Consolas, Monaco, Courier, monospace !important; font-size: 12px;&quot;&gt;&lt;br /&gt;Execution Plan&lt;/h4&gt;&lt;br /&gt;&lt;span style=&quot;color: #111111; font-family: Bitstream Vera Sans Mono, DejaVu Sans Mono, Consolas, Monaco, Courier, monospace;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;AllNodes&lt;br /&gt;&lt;br /&gt;+----------+------+--------+-------------+-------+&lt;br /&gt;| Operator | Rows | DbHits | Identifiers | Other |&lt;br /&gt;+----------+------+--------+-------------+-------+&lt;br /&gt;| AllNodes |    3 |      4 |        n, n |       |&lt;br /&gt;+----------+------+--------+-------------+-------+&lt;br /&gt;&lt;/span&gt;&lt;/span&gt;&lt;br /&gt;&lt;/pre&gt;As the execution plan states, the Cypher query has been translated to the &lt;i&gt;AllNodes&lt;/i&gt; operation.&lt;br /&gt;&lt;br /&gt;Now if we run a slightly more complex Cypher query, the execution plan shows the piping of operations.&lt;br /&gt;&lt;br /&gt;&lt;pre data-lang=&quot;cypher&quot;&gt;&lt;br /&gt;// Find Kenny&#39;s friends&lt;br /&gt;MATCH (kenny:Person {name:&quot;Kenny&quot;})-[:FRIEND_OF]-(friends)&lt;br /&gt;RETURN friends&lt;br /&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 style=&quot;box-sizing: border-box; color: #111111; font-family: &#39;Bitstream Vera Sans Mono&#39;, &#39;DejaVu Sans Mono&#39;, Consolas, Monaco, Courier, monospace; font-size: 16px; font-weight: bold; line-height: normal; margin: 1px; white-space: normal;&quot;&gt;Detailed Query Results&lt;/h3&gt;&lt;pre id=&quot;stats-output&quot; style=&quot;box-sizing: border-box; color: #111111; font-family: &#39;Bitstream Vera Sans Mono&#39;, &#39;DejaVu Sans Mono&#39;, Consolas, Monaco, Courier, monospace !important; font-size: 12px; font-weight: normal; line-height: normal;&quot;&gt;&lt;h4&gt;&lt;br /&gt;Query Results&lt;/h4&gt;&lt;br /&gt;+-----------------------+&lt;br /&gt;| friends               |&lt;br /&gt;+-----------------------+&lt;br /&gt;| Node[1]{name:&quot;Adam&quot;}  |&lt;br /&gt;| Node[2]{name:&quot;Greta&quot;} |&lt;br /&gt;+-----------------------+&lt;br /&gt;2 rows&lt;br /&gt;14 ms&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;&lt;br /&gt;Execution Plan&lt;/h4&gt;&lt;br /&gt;ColumnFilter&lt;br /&gt;  |&lt;br /&gt;  +Filter&lt;br /&gt;    |&lt;br /&gt;    +TraversalMatcher&lt;br /&gt;&lt;br /&gt;+------------------+------+--------+-------------+--------------------------------------------+&lt;br /&gt;|         Operator | Rows | DbHits | Identifiers |                                      Other |&lt;br /&gt;+------------------+------+--------+-------------+--------------------------------------------+&lt;br /&gt;|     ColumnFilter |    2 |      0 |             |                       keep columns friends |&lt;br /&gt;|           Filter |    2 |     12 |             | Property(kenny,name(0)) == {  AUTOSTRING0} |&lt;br /&gt;| TraversalMatcher |    6 |     13 |             |              friends,   UNNAMED37, friends |&lt;br /&gt;+------------------+------+--------+-------------+--------------------------------------------+&lt;/pre&gt;&lt;div&gt;The execution plan for the query shows 3 operators: &lt;i&gt;ColumnFilter&lt;/i&gt;, &lt;i&gt;Filter&lt;/i&gt;, and &lt;i&gt;TraversalMatcher&lt;/i&gt;. The &lt;i&gt;ColumnFilter&lt;/i&gt; operation receives a row of data from the &lt;i&gt;Filter&lt;/i&gt; operation and processes it by keeping only the identifier &quot;&lt;b&gt;&lt;i&gt;friends&lt;/i&gt;&lt;/b&gt;&quot;, which is in the RETURN statement. The &lt;i&gt;Filter&lt;/i&gt; operation also receives rows of data from its preceding operation, the &lt;i&gt;TraversalMatcher&lt;/i&gt;, and applies a predicate to decide whether to pass that data row along to the next operation (the &lt;i&gt;ColumnFilter&lt;/i&gt;) or to discard it. In the case of our query, the predicate is to filter nodes by applying the criteria for the identifier &quot;&lt;b&gt;&lt;i&gt;kenny&lt;/i&gt;&lt;/b&gt;&quot; with the property &quot;&lt;b&gt;&lt;i&gt;name&lt;/i&gt;&lt;/b&gt;&quot; that equals &lt;i&gt;&lt;b&gt;AUTOSTRING0&lt;/b&gt;&lt;/i&gt;, which will resolve to the token &quot;&lt;b&gt;&lt;i&gt;Kenny&lt;/i&gt;&lt;/b&gt;&quot; when the plan is executed. Finally the &lt;i&gt;TraversalMatcher&lt;/i&gt; doesn&#39;t receive any rows of data, due to being the first operation, but generates new rows of data by searching the graph for the pattern specified in the MATCH clause.&lt;br /&gt;&lt;br /&gt;So you can see that the execution plan, as constructed from the Cypher query, operates &lt;u&gt;bottom up&lt;/u&gt;. Patterns are found in the &lt;i&gt;TraversalMatcher&lt;/i&gt; (a total of 6 rows), and then passed through the &lt;i&gt;Filter&lt;/i&gt;, which only allows 2 through, and finally to the &lt;i&gt;ColumnFilter&lt;/i&gt;, which only keeps the &quot;&lt;i&gt;&lt;b&gt;friends&lt;/b&gt;&lt;/i&gt;&quot; column specified in the RETURN clause.&lt;br /&gt;&lt;br /&gt;Knowing how the data is generated, filtered, and processed is tremendously helpful for understanding how to optimize queries for the best performance. The compiler does what it can to generate the most optimal plan. It is constantly being made smarter with each release, yet its still extremely relevant for us developers to understand what the result is&amp;nbsp;&lt;em style=&quot;background-color: white; border: none; box-sizing: border-box; color: #5f5f5f; font-family: Arial, Helvetica, sans-serif; font-size: 16px; line-height: 25.600000381469727px; margin: 0px; padding: 0px;&quot;&gt;&lt;span style=&quot;border: none; box-sizing: border-box; font-size: x-small; margin: 0px; padding: 0px;&quot;&gt;—&lt;/span&gt;&lt;/em&gt;&amp;nbsp;and to consider how we can adjust the query we&#39;re asking to obtain a more optimal result.&lt;/div&gt;&lt;/br&gt;&lt;a href=&quot;https://news.ycombinator.com/submit&quot; class=&quot;hn-button&quot; data-title=&quot;Understanding How Neo4j Cypher Queries are Evaluated &quot; data-url=&quot;http://www.kennybastani.com/2014/07/understanding-how-neo4j-cypher-queries.html&quot; data-count=&quot;horizontal&quot;&gt;Vote on Hacker News&lt;/a&gt;&lt;script type=&quot;text/javascript&quot;&gt;var HN=[];HN.factory=function(e){return function(){HN.push([e].concat(Array.prototype.slice.call(arguments,0)))};},HN.on=HN.factory(&quot;on&quot;),HN.once=HN.factory(&quot;once&quot;),HN.off=HN.factory(&quot;off&quot;),HN.emit=HN.factory(&quot;emit&quot;),HN.load=function(){var e=&quot;hn-button.js&quot;;if(document.getElementById(e))return;var t=document.createElement(&quot;script&quot;);t.id=e,t.src=&quot;//hn-button.herokuapp.com/hn-button.js&quot;;var n=document.getElementsByTagName(&quot;script&quot;)[0];n.parentNode.insertBefore(t,n)},HN.load();&lt;/script&gt;</description><link>https://www.kennybastani.com/2014/07/understanding-how-neo4j-cypher-queries.html</link><author>noreply@blogger.com (Kenny Bastani)</author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://4.bp.blogspot.com/-QgyjbOTkSo8/U72irZchIJI/AAAAAAAAA7E/QouCN-D8DX4/s72-c/neo4j-browser.png" height="72" width="72"/><thr:total>0</thr:total></item><item><guid isPermaLink="false">tag:blogger.com,1999:blog-6300367579216018061.post-8483148551697005371</guid><pubDate>Mon, 07 Jul 2014 21:13:00 +0000</pubDate><atom:updated>2014-11-27T20:00:53.489-08:00</atom:updated><category domain="http://www.blogger.com/atom/ns#">algorithms</category><category domain="http://www.blogger.com/atom/ns#">graph database</category><category domain="http://www.blogger.com/atom/ns#">neo4j</category><category domain="http://www.blogger.com/atom/ns#">pattern recognition</category><category domain="http://www.blogger.com/atom/ns#">ubigraph</category><category domain="http://www.blogger.com/atom/ns#">visualization</category><title>Using 3D Visualization to Debug a Graph-based Algorithm</title><description>Recently I have been working on an idea for an algorithm that discovers patterns in raw streams of data. This pattern recognition algorithm uses &lt;a href=&quot;http://en.wikipedia.org/wiki/Deep_learning&quot; target=&quot;_blank&quot;&gt;deep learning&lt;/a&gt;&amp;nbsp;to classify certain combinatorial features that uniquely identify an input stream.&lt;br /&gt;&lt;br /&gt;I&#39;m going to first talk a bit about the algorithm so it makes sense as to why visualization is such an important step in iterating and tweaking code that most efficiently implements the algorithm.&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;The Algorithm&lt;/h3&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;In a &lt;a href=&quot;http://www.kennybastani.com/2014/06/hierchical-pattern-recognition.html&quot; target=&quot;_blank&quot;&gt;previous post&lt;/a&gt; I introduce the idea for the algorithm and how a graph-based approach might work.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;http://1.bp.blogspot.com/-e_PVtiJrBRg/U5_Vn3r_aUI/AAAAAAAAA5g/qYkZouyPG6c/s1600/neo4j-pattern-recognition-engine.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-e_PVtiJrBRg/U5_Vn3r_aUI/AAAAAAAAA5g/qYkZouyPG6c/s1600/neo4j-pattern-recognition-engine.png&quot; height=&quot;312&quot; width=&quot;640&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;a name=&#39;more&#39;&gt;&lt;/a&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;The image above illustrates the idea as a graph. A tree is built by training on data and recognizing prevalent features in that data.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;This works in two phases, training and recognition. In this blog post I&#39;ll go over training.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;h3&gt;Training&lt;/h3&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;In the training phase the algorithm should produce a hierarchy of nodes that grows using genetic inheritance.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;http://3.bp.blogspot.com/-f38-EUPUxNQ/U7rn9N366hI/AAAAAAAAA6A/vY4Qe51MrTs/s1600/graph-recognition-algorithm-1.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-f38-EUPUxNQ/U7rn9N366hI/AAAAAAAAA6A/vY4Qe51MrTs/s1600/graph-recognition-algorithm-1.png&quot; height=&quot;254&quot; width=&quot;640&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;In the image above I&#39;ve illustrated the root of the graph with two descendants. The regular expressions act as a predicate and also as the template for each child node. The RegEx of the parent is inherited by descendants as a base genetic code but with a mutation that expands the RegEx either left or right of the base code. This abstraction enables for a probabilistic expansion of the pattern matching algorithm.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;But how does training generate child nodes?&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;http://3.bp.blogspot.com/-b2ZAUz2vo_4/U7rpBFL3JnI/AAAAAAAAA6I/vk2LIdTmKQU/s1600/graph-recognition-algorithm-2.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-b2ZAUz2vo_4/U7rpBFL3JnI/AAAAAAAAA6I/vk2LIdTmKQU/s1600/graph-recognition-algorithm-2.png&quot; height=&quot;327&quot; width=&quot;640&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div&gt;The genetic inheritance is done by setting a threshold and counting on the number of matches. Using &lt;a href=&quot;http://www.neo4j.com/&quot; target=&quot;_blank&quot;&gt;Neo4j&lt;/a&gt; I am able to attach matches to source data at each match.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;For example, if each input is a binary string of an arbitrary length, each node represents some mutating binary operation with a method signature matchInput(Node input, Node current).&lt;br /&gt;&lt;br /&gt;As the input node represented as the &quot;input&quot; parameter is positively matched on the RegEx of the &quot;current&quot; parameter, the property named &quot;matches&quot; on the &quot;current&quot; node is incremented by 1. When the match count on the &quot;current&quot; node equals the &quot;threshold&quot; parameter, two leaf nodes are created using a statistical measure on previous matches.&lt;br /&gt;&lt;br /&gt;The image below illustrates the genetic algorithm that sums on the statistical distribution of matches against bits and producing a new RegEx inherited from the parent.&lt;br /&gt;&lt;br /&gt;&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto; text-align: center;&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://3.bp.blogspot.com/-wTJNG683gK8/U7sGgVOEjzI/AAAAAAAAA6Y/r_hLR9IItHM/s1600/graph-recognition-algorithm-3.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-wTJNG683gK8/U7sGgVOEjzI/AAAAAAAAA6Y/r_hLR9IItHM/s1600/graph-recognition-algorithm-3.png&quot; height=&quot;566&quot; width=&quot;640&quot; /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;&gt;Click to enlarge&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;br /&gt;In the diagram we see that the current node is ∆101∆ which has the RegEx match string of &lt;i&gt;([01])101([01])&lt;/i&gt;. The result of the matches should produce two leaf nodes, one that expands left and one that expands right.&lt;br /&gt;&lt;br /&gt;Because I have stored the pointers in Neo4j for the previous 3 matches, an aggregation can be made on references to that input data, as illustrated in the graph diagram. The aggregation produces a left node that expands on the RegEx &lt;i&gt;&lt;b&gt;([01])&lt;/b&gt;101([01])&lt;/i&gt; in the first group. The result of the sum of the bit&#39;s counts for the left group results in 5 for 0-bit and 1 for 1-bit. Since 5 &amp;gt; 1, the new RegEx will replace the first group of the parent node with a 0-bit, producing the new template ([01])&lt;b&gt;&lt;i&gt;0&lt;/i&gt;&lt;/b&gt;101([01]) or more easily read as ∆0101∆ where ∆ means 0 or 1.&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;3D Graph Visualization&lt;/h3&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;I started out by visualizing the results of the graph-based algorithm through the &lt;a href=&quot;http://vimeo.com/97204829&quot; target=&quot;_blank&quot;&gt;Neo4j browser&lt;/a&gt;. Translating the algorithm into code was easy enough, except the results were not as expected. I wanted something that could give me some visual feedback so I could iterate on the code to make it faster.&lt;br /&gt;&lt;br /&gt;&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto; text-align: center;&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://4.bp.blogspot.com/-8iI_AwVvmWk/U7sQXS4IXGI/AAAAAAAAA6o/k815PehYukM/s1600/graph-recognition-algorithm-browser.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-8iI_AwVvmWk/U7sQXS4IXGI/AAAAAAAAA6o/k815PehYukM/s1600/graph-recognition-algorithm-browser.png&quot; height=&quot;546&quot; width=&quot;640&quot; /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;&gt;2D Graph Visualization in Neo4j Browser&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;Since the branching factor for this graph is 2, the total depth can get rather large. While Neo4j&#39;s browser-based visualization is great for small to medium-sized graphs, I wanted to see things in three dimensions.&lt;br /&gt;&lt;br /&gt;Using a blog post by my colleague Michael Hunger, located &lt;a href=&quot;http://jexp.de/blog/2014/06/rendering-a-neo4j-database-in-ubigraph/&quot; target=&quot;_blank&quot;&gt;here&lt;/a&gt;, I had a way to see how my algorithm was growing over time and apply tweaks and heuristics to make it perform better in training phase.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;blockquote class=&quot;twitter-tweet&quot; lang=&quot;en&quot;&gt;3D graph visualization of a pattern recognition algorithm training into a massive binary decision tree. &lt;a href=&quot;https://twitter.com/hashtag/Neo4j?src=hash&quot;&gt;#Neo4j&lt;/a&gt; &lt;a href=&quot;http://t.co/Llh0olPH1p&quot;&gt;http://t.co/Llh0olPH1p&lt;/a&gt;&lt;br /&gt;— Kenny Bastani (@kennybastani) &lt;a href=&quot;https://twitter.com/kennybastani/statuses/484450100920320000&quot;&gt;July 2, 2014&lt;/a&gt;&lt;/blockquote&gt;&lt;script async=&quot;&quot; charset=&quot;utf-8&quot; src=&quot;//platform.twitter.com/widgets.js&quot;&gt;&lt;/script&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;I recorded my most recent iteration of the algorithm, which I wrote in Java, and created a GIF out of it. If you play the GIF in the tweet you can see how my algorithm expands over time.&lt;br /&gt;&lt;br /&gt;I also uploaded a video that was a screen recording of the training phase of the algorithm at a slower speed.&lt;br /&gt;&lt;br /&gt;&lt;iframe allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;315&quot; src=&quot;//www.youtube.com/embed/bIBYSAepmUk&quot; width=&quot;420&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;Creating these kinds of visualizations were both fun and helpful to understand how the algorithm was evolving over time. I could understand better the computational performance and feasibilities of my various approaches and choose the best approach based on feedback from the visualizations.&lt;br /&gt;&lt;br /&gt;In an upcoming blog post I will take this algorithm further to create a Neo4j plugin that performs image recognition and classification. The killer use case for this being an open-source deep learning plugin for&amp;nbsp;&lt;a href=&quot;http://docs.neo4j.org/chunked/milestone/server-plugins.html&quot; target=&quot;_blank&quot;&gt;Neo4j&lt;/a&gt;&amp;nbsp;that can be used for face and object recognition in image data.&lt;br /&gt;&lt;br /&gt;References:&lt;br /&gt;&lt;br /&gt;Ubigraph:&amp;nbsp;&lt;a href=&quot;http://ubietylab.net/ubigraph/&quot;&gt;http://ubietylab.net/ubigraph/&lt;/a&gt;&lt;br /&gt;Neo4j: &lt;a href=&quot;http://www.neo4j.com/&quot;&gt;http://www.neo4j.com/&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;/div&gt;&lt;/br&gt;&lt;a href=&quot;https://news.ycombinator.com/submit&quot; class=&quot;hn-button&quot; data-title=&quot;Using 3D Visualization to Debug a Graph-based Algorithm&quot; data-url=&quot;http://www.kennybastani.com/2014/07/using-3d-visualization-to-debug-graph.html&quot; data-count=&quot;horizontal&quot;&gt;Vote on Hacker News&lt;/a&gt;&lt;script type=&quot;text/javascript&quot;&gt;var HN=[];HN.factory=function(e){return function(){HN.push([e].concat(Array.prototype.slice.call(arguments,0)))};},HN.on=HN.factory(&quot;on&quot;),HN.once=HN.factory(&quot;once&quot;),HN.off=HN.factory(&quot;off&quot;),HN.emit=HN.factory(&quot;emit&quot;),HN.load=function(){var e=&quot;hn-button.js&quot;;if(document.getElementById(e))return;var t=document.createElement(&quot;script&quot;);t.id=e,t.src=&quot;//hn-button.herokuapp.com/hn-button.js&quot;;var n=document.getElementsByTagName(&quot;script&quot;)[0];n.parentNode.insertBefore(t,n)},HN.load();&lt;/script&gt;</description><link>https://www.kennybastani.com/2014/07/using-3d-visualization-to-debug-graph.html</link><author>noreply@blogger.com (Kenny Bastani)</author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://1.bp.blogspot.com/-e_PVtiJrBRg/U5_Vn3r_aUI/AAAAAAAAA5g/qYkZouyPG6c/s72-c/neo4j-pattern-recognition-engine.png" height="72" width="72"/><thr:total>0</thr:total></item><item><guid isPermaLink="false">tag:blogger.com,1999:blog-6300367579216018061.post-2171353829393854564</guid><pubDate>Tue, 17 Jun 2014 16:00:00 +0000</pubDate><atom:updated>2014-11-27T20:01:15.414-08:00</atom:updated><category domain="http://www.blogger.com/atom/ns#">artificial intelligence</category><category domain="http://www.blogger.com/atom/ns#">gephi</category><category domain="http://www.blogger.com/atom/ns#">graph database</category><category domain="http://www.blogger.com/atom/ns#">graphs</category><category domain="http://www.blogger.com/atom/ns#">information theory</category><category domain="http://www.blogger.com/atom/ns#">james gleick</category><category domain="http://www.blogger.com/atom/ns#">jeff hawkins</category><category domain="http://www.blogger.com/atom/ns#">neo4j</category><category domain="http://www.blogger.com/atom/ns#">pattern recognition</category><category domain="http://www.blogger.com/atom/ns#">ray kurzweil</category><title>Hierarchical Pattern Recognition</title><description>&lt;div&gt;About a year ago I read about Ray Kurzweil&#39;s &quot;&lt;a href=&quot;http://en.wikipedia.org/wiki/How_to_Create_a_Mind#Pattern_Recognition_Theory_of_Mind&quot; target=&quot;_blank&quot;&gt;Pattern Recognition Theory of Mind&lt;/a&gt;&quot;, which he articulates in his book, &quot;&lt;a href=&quot;http://en.wikipedia.org/wiki/How_to_Create_a_Mind&quot; target=&quot;_blank&quot;&gt;How to Create a Mind&lt;/a&gt;&quot;. I picked up the book after struggling with the idea of implementing a deep learning algorithm for parsing natural language text on Wikipedia. My goal was to discover links in volumes of text that were not already linked. I ended up developing all kinds of cool heuristics to do this, mostly by a lot of trial and error. King of these heuristics was a pretty simple algorithm at the core of the library that would find redundancies in batches of text content.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;How this worked is if a phrase was mentioned repeatedly in a collection of about 50 sentences, then I could extract that phrase as a node and link it back to the pieces of content it belonged to. Every now and then you&#39;ll get a reference to another article&#39;s name, which can then be verified against Wikipedia&#39;s site index, which would provide more sentences to find repeated phrases within.&lt;br /&gt;&lt;br /&gt;I struggled with persistency because I knew how ugly my problem was for a relational database. I created some &lt;a href=&quot;http://en.wikipedia.org/wiki/Entity%E2%80%93relationship_model&quot; target=&quot;_blank&quot;&gt;entity-relationship models&lt;/a&gt;, and implemented them using &lt;a href=&quot;http://msdn.microsoft.com/en-us/data/ef.aspx&quot; target=&quot;_blank&quot;&gt;Entity Framework&lt;/a&gt;&amp;nbsp;over &lt;a href=&quot;http://en.wikipedia.org/wiki/Microsoft_sql_server&quot; target=&quot;_blank&quot;&gt;Microsoft SQL Server&lt;/a&gt;. It worked, kind of.&amp;nbsp;I waited patiently to happen upon a better solution. Thankfully I did, and using a&amp;nbsp;&lt;a href=&quot;http://www.neo4j.com/download&quot; target=&quot;_blank&quot;&gt;graph database&lt;/a&gt; I was able to take my cool little algorithms and solve my persistency problem at scale.&lt;/div&gt;&lt;a name=&#39;more&#39;&gt;&lt;/a&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Since &lt;a href=&quot;http://www.neo4j.com/&quot; target=&quot;_blank&quot;&gt;Neo4j&lt;/a&gt; allowed easy integration with graph visualization tools, I started producing some compelling images of my data. The result would yield a nice looking visualization of the contents of my Neo4j database in &lt;a href=&quot;https://gephi.org/&quot; target=&quot;_blank&quot;&gt;Gephi&lt;/a&gt;.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;http://1.bp.blogspot.com/-wDbe665YKZ4/U5_Z8fb7nnI/AAAAAAAAA5o/SYM5JnyUFNE/s1600/wikipedia-text.png&quot; imageanchor=&quot;1&quot; style=&quot;clear: left; float: left; margin-bottom: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-wDbe665YKZ4/U5_Z8fb7nnI/AAAAAAAAA5o/SYM5JnyUFNE/s1600/wikipedia-text.png&quot; height=&quot;400&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div&gt;The image to the left shows article names surrounded by regular phrases that are shared by the content of many different articles on Wikipedia. The algorithm starts with a seed article, which in this case I chose the article &quot;Dark Matter&quot; as the seed.&lt;br /&gt;&lt;br /&gt;As phrases are discovered within the content of the article titled &quot;Dark Matter&quot;, they are compared to the Wikipedia site index. If a positive match is found from a phrase in one article to another&#39;s name, that article&#39;s content is then parsed using the same process.&lt;br /&gt;&lt;br /&gt;After around 25 articles were parsed, linked, and stored as a graph, a fairly interesting image of the data emerges. Using PageRank in combination with a force directed layout, a wonderful thing appeared, a map of knowledge.&lt;br /&gt;&lt;br /&gt;Naturally, I got pretty excited. I was reading a lot of &lt;a href=&quot;http://en.wikipedia.org/wiki/James_Gleick&quot; target=&quot;_blank&quot;&gt;James Gleick&#39;s&lt;/a&gt; books on the history of &lt;a href=&quot;http://en.wikipedia.org/wiki/Chaos_theory&quot; target=&quot;_blank&quot;&gt;Chaos Theory&lt;/a&gt; and &lt;a href=&quot;http://en.wikipedia.org/wiki/Information_theory&quot; target=&quot;_blank&quot;&gt;Information Theory&lt;/a&gt;. I started anew with a different article name, this time &quot;&lt;a href=&quot;http://en.wikipedia.org/wiki/Artificial_intelligence&quot; target=&quot;_blank&quot;&gt;Artificial Intelligence&lt;/a&gt;&quot;. I was feeling lucky. I started up the process, and let it be for about a day. I came back the next morning, imported the data to Gephi, did the PageRank and layout. The image below resulted.&lt;br /&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;http://4.bp.blogspot.com/-Ky0p3pnupIg/UQf3fFSlx-I/AAAAAAAAAkc/4Nx4J15vCJA/s1600/Semantic_Universe.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-Ky0p3pnupIg/UQf3fFSlx-I/AAAAAAAAAkc/4Nx4J15vCJA/s1600/Semantic_Universe.png&quot; height=&quot;640&quot; width=&quot;640&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;The pattern started to emerge. Countries were situated around countries, mathematical topics next to mathematical topics, science fiction bordered topics about artificial intelligence. It was a genuine kind of discovery, the kind of thing that makes you tweet James Gleick with a presumptuous explanation that the universe is a network of information.&lt;br /&gt;&lt;br /&gt;&lt;blockquote class=&quot;twitter-tweet&quot; lang=&quot;en&quot;&gt;&lt;a href=&quot;https://twitter.com/JamesGleick&quot;&gt;@JamesGleick&lt;/a&gt; You set the challenge, we answered it. The universe may be an information network that runs off entropy. &lt;a href=&quot;http://t.co/1Hacy9F4&quot;&gt;http://t.co/1Hacy9F4&lt;/a&gt;&lt;br /&gt;— Kenny Bastani (@kennybastani) &lt;a href=&quot;https://twitter.com/kennybastani/statuses/296344799844384768&quot;&gt;January 29, 2013&lt;/a&gt;&lt;/blockquote&gt;&lt;script async=&quot;&quot; charset=&quot;utf-8&quot; src=&quot;//platform.twitter.com/widgets.js&quot;&gt;&lt;/script&gt; I was far off point, because what I had stumbled upon didn&#39;t require any inflation or grand explanation. The image is compelling because it looks a lot like a geographical map of human knowledge. Much like Google maps, you could zoom into this graph and observe how things are connected, you could find causality at the finest granularity.&lt;br /&gt;&lt;br /&gt;Since then I have been on a pursuit to learn more about the constraints of theoretical computer science. Mainly, how the heuristics I developed could be improved upon and made scalable for other kinds of unsupervised machine learning. Late last year I joined up with the &lt;a href=&quot;http://www.neotechnology.com/&quot; target=&quot;_blank&quot;&gt;company&lt;/a&gt; who created the database technology that allowed me to move past my graph persistency issues. This move allowed me to make graphs my life and ride the wave of an entirely new technology &lt;a href=&quot;http://db-engines.com/en/blog_post/26&quot; target=&quot;_blank&quot;&gt;as it disrupts and bites off a piece of its own market&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;A part of this journey has been honing my skills as a Java developer and getting into the Neo4j internals that provide the extreme performance needed to do high-volume pattern recognition at scale.&lt;br /&gt;&lt;br /&gt;Let&#39;s assume that each node is not just data but a code block. Each block has a very specific purpose, to take an input and produce an output. Each node could therefore be thought of as a &lt;a href=&quot;http://en.wikipedia.org/wiki/Finite-state_machine&quot; target=&quot;_blank&quot;&gt;finite-state machine&lt;/a&gt;, which performs a bit of computation, which causes its state to change according to the result of the computation. Consider the graph diagram below.&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto; text-align: center;&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://3.bp.blogspot.com/-e_PVtiJrBRg/U5_Vn3r_aUI/AAAAAAAAA5c/niGfyGEK9bQ/s1600/neo4j-pattern-recognition-engine.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-e_PVtiJrBRg/U5_Vn3r_aUI/AAAAAAAAA5c/niGfyGEK9bQ/s1600/neo4j-pattern-recognition-engine.png&quot; height=&quot;312&quot; width=&quot;640&quot; /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;&gt;Hierarchical Pattern Recognition Graph&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;div&gt;The ∆ symbol represents something similar to a &lt;a href=&quot;http://en.wikipedia.org/wiki/Qubit&quot; target=&quot;_blank&quot;&gt;qubit&lt;/a&gt;, which could be 1 or 0 or a superposition of both. I realize the metaphor of a qubit may be confusing, so to simplify this, a ∆ is a wildcard match on an input represented as a bit, being 1 or 0. As a stream of bits are processed, new nodes are created that have some statistical probability of being selected based on a history of matches on training data. As the number of matches of some threshold&amp;nbsp;θ is surpassed, the leaf node changes states and produces two or more leaf nodes, depending on the number of ∆ in the pattern template of the node.&lt;br /&gt;&lt;br /&gt;The new leaf nodes inherit the template of the parent node, but replace each ∆ with the bit selected based on the statistical probability measured over all previous matches for the parent. New ∆ wildcards encapsulate the new templates that are produced. This natural selection of patterns produces an algorithmic data structure from input data. Labels can be connected to nodes from labeled training data, like faces in photos or images of text.&lt;br /&gt;&lt;br /&gt;This is largely inspired by Ray Kurzweil&#39;s &lt;a href=&quot;http://en.wikipedia.org/wiki/How_to_Create_a_Mind#Pattern_Recognition_Theory_of_Mind&quot; target=&quot;_blank&quot;&gt;PRTM&lt;/a&gt; and Jeff Hawkin&#39;s &lt;a href=&quot;http://en.wikipedia.org/wiki/Hierarchical_Temporal_Memory&quot; target=&quot;_blank&quot;&gt;Hierarchical Temporal Memory&lt;/a&gt;. Both approaches teeter on the cusp of some kind of deep learning.&lt;br /&gt;&lt;br /&gt;Quote from the Wikipedia article about &lt;a href=&quot;http://deep_learning_in_the_human_brain/&quot; target=&quot;_blank&quot;&gt;Deep Learning&lt;/a&gt;:&lt;br /&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;&lt;span style=&quot;background-color: white; color: #252525; font-family: sans-serif; font-size: 14px; line-height: 22.399999618530273px;&quot;&gt;...These models share the interesting property that various proposed learning dynamics in the brain (e.g., a wave of neurotrophic growth factor) conspire to support the self-organization of just the sort of inter-related neural networks utilized in the later, purely computational deep learning models, and which appear to be analogous to one way of understanding the neocortex of the brain as a hierarchy of filters where each layer captures some of the information in the operating environment, and then passes the remainder, as well as modified base signal, to other layers further up the hierarchy.&lt;/span&gt;&lt;/blockquote&gt;That&#39;s all for now. Stay tuned for updates.&amp;nbsp;&lt;/div&gt;&lt;/br&gt;&lt;a href=&quot;https://news.ycombinator.com/submit&quot; class=&quot;hn-button&quot; data-title=&quot;Hierarchical Pattern Recognition&quot; data-url=&quot;http://www.kennybastani.com/2014/06/hierchical-pattern-recognition.html&quot; data-count=&quot;horizontal&quot;&gt;Vote on Hacker News&lt;/a&gt;&lt;script type=&quot;text/javascript&quot;&gt;var HN=[];HN.factory=function(e){return function(){HN.push([e].concat(Array.prototype.slice.call(arguments,0)))};},HN.on=HN.factory(&quot;on&quot;),HN.once=HN.factory(&quot;once&quot;),HN.off=HN.factory(&quot;off&quot;),HN.emit=HN.factory(&quot;emit&quot;),HN.load=function(){var e=&quot;hn-button.js&quot;;if(document.getElementById(e))return;var t=document.createElement(&quot;script&quot;);t.id=e,t.src=&quot;//hn-button.herokuapp.com/hn-button.js&quot;;var n=document.getElementsByTagName(&quot;script&quot;)[0];n.parentNode.insertBefore(t,n)},HN.load();&lt;/script&gt;</description><link>https://www.kennybastani.com/2014/06/hierchical-pattern-recognition.html</link><author>noreply@blogger.com (Kenny Bastani)</author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://1.bp.blogspot.com/-wDbe665YKZ4/U5_Z8fb7nnI/AAAAAAAAA5o/SYM5JnyUFNE/s72-c/wikipedia-text.png" height="72" width="72"/><thr:total>0</thr:total></item><item><guid isPermaLink="false">tag:blogger.com,1999:blog-6300367579216018061.post-9019768780095380158</guid><pubDate>Wed, 30 Apr 2014 23:14:00 +0000</pubDate><atom:updated>2015-03-01T11:48:14.947-08:00</atom:updated><category domain="http://www.blogger.com/atom/ns#">analytics</category><category domain="http://www.blogger.com/atom/ns#">big data</category><category domain="http://www.blogger.com/atom/ns#">data import</category><category domain="http://www.blogger.com/atom/ns#">data science</category><category domain="http://www.blogger.com/atom/ns#">github</category><category domain="http://www.blogger.com/atom/ns#">heroku scheduler</category><category domain="http://www.blogger.com/atom/ns#">meetup</category><category domain="http://www.blogger.com/atom/ns#">neo4j</category><category domain="http://www.blogger.com/atom/ns#">node.js</category><category domain="http://www.blogger.com/atom/ns#">open source software</category><category domain="http://www.blogger.com/atom/ns#">reporting</category><title>Building a Neo4j Reporting Service Part II</title><description>&lt;style&gt;blockquote {   border-left: 5px solid #EEEEEE;   margin: 0 0 20px;   padding: 0 0 0 15px; } &lt;/style&gt; &lt;br /&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;It is a capital mistake to theorize before one has data. Insensibly one begins to twist facts to suit theories, instead of theories to suit facts.&lt;br /&gt;&lt;br /&gt;&lt;cite&gt;Sir Arthur Conan Doyle, Author of Sherlock Holmes stories&lt;/cite&gt;&lt;/blockquote&gt;&lt;table cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;float: right; margin-left: 1em; text-align: right;&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/kbastani/meetup-analytics/master/docs/images/Neo4j_data_graph_db.png&quot; imageanchor=&quot;1&quot; style=&quot;clear: right; margin-bottom: 1em; margin-left: auto; margin-right: auto;&quot;&gt;&lt;img border=&quot;0&quot; height=&quot;180&quot; src=&quot;https://raw.githubusercontent.com/kbastani/meetup-analytics/master/docs/images/Neo4j_data_graph_db.png&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;&gt;A Subgraph From Neo4j&#39;s Browser&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;Just as Sir Arthur Conan Doyle&#39;s character, Sherlock Holmes, manically collects facts and evidence to prove theories, we find ourselves doing much of the same today except on a much larger scale&lt;b&gt;—&lt;/b&gt;&amp;nbsp;web scale. The web is an ever growing expanse of facts and evidence. It is at our disposal to observe without much of a challenge, but to store it and retrieve it in a way that answers the big questions, that&#39;s challenging.&lt;br /&gt;&lt;br /&gt;Continuing on from &lt;a href=&quot;http://www.kennybastani.com/2014/04/building-graph-based-analytics-platform-part-1.html&quot; target=&quot;_blank&quot;&gt;Building a Graph-based Reporting Platform: Part I&lt;/a&gt;, I posed some questions related to understanding how to build great community experiences around Neo4j using Meetup.com for local events. I presented an idea to use Neo4j to build a platform that could help us understand the demand for presenting compelling content at events.&lt;br /&gt;&lt;br /&gt;Compelling content is at the core of great community experiences. That content fuels the conversations between people, ideas begin to flow, and innovation is born.&lt;br /&gt;&lt;br /&gt;My idea was to build an open-source platform that would poll public APIs, translate collected data into a graph, and store it in a graph database to be analyzed, queried, and visualized over time. The first component of this architecture is the &lt;a href=&quot;https://github.com/neo4j-meetups-reporting/wiki#data-import-scheduler&quot; target=&quot;_blank&quot;&gt;Data Import Scheduler&lt;/a&gt;, which this post describes in detail.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;&lt;span style=&quot;font-size: large;&quot;&gt;Polling Data From Public APIs&lt;/span&gt;&lt;/h2&gt;&lt;div&gt;Let&#39;s start out by answering a basic question.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;What does the data import scheduler do?&lt;/blockquote&gt;The analytics data import scheduler is a Node.js process that can be hosted for free on Heroku and is responsible for collecting time-based statistics from a public API. In this case, the Meetup.com REST API exposes a set of methods that provide a momentary snapshot into the number of members that a group has at the time of the request. The data import scheduler polls this endpoint once a day to retrieve Meetup group statistics to later be used for time-based analysis from our graph database, &lt;a href=&quot;http://www.neo4j.com/&quot; target=&quot;_blank&quot;&gt;Neo4j&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;As illustrated in the diagram below, the Node.js application wakes up once a day and checks in with the Meetup.com REST API.&lt;br /&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/kbastani/meetup-analytics/master/docs/images/Graph-based%20Analytics%20Platform%20-%20Import%20Scheduler%20Diagram.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; height=&quot;430&quot; src=&quot;https://raw.githubusercontent.com/kbastani/meetup-analytics/master/docs/images/Graph-based%20Analytics%20Platform%20-%20Import%20Scheduler%20Diagram.png&quot; width=&quot;640&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;The scheduler process polls Meetup.com&#39;s REST API daily. An HTTP GET request is dispatched for each city we&#39;re tracking, returning a JSON formatted response for groups in those cities. The JSON data for each group is then translated into a subgraph, formatted as &lt;a href=&quot;http://docs.neo4j.org/chunked/stable/cypher-query-lang.html&quot; target=&quot;_blank&quot;&gt;Neo4j&#39;s Cypher query language&lt;/a&gt;. The Cypher query is then sent as a transaction to Neo4j and updates a snapshot of the group&#39;s stats for that day.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;&lt;span style=&quot;font-size: large;&quot;&gt;Importing a Meetup Group&#39;s Subgraph&lt;/span&gt;&lt;/h2&gt;The image below is a visualization of a Meetup group&#39;s subgraph, translated from JSON data polled on an arbitrary date.&lt;br /&gt;&lt;br /&gt;&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto; text-align: center;&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/kbastani/meetup-analytics/master/docs/images/data-import-scheduler-model-slice.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;img border=&quot;0&quot; height=&quot;470&quot; src=&quot;https://raw.githubusercontent.com/kbastani/meetup-analytics/master/docs/images/data-import-scheduler-model-slice.png&quot; width=&quot;640&quot; /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;tr-caption&quot;&gt;&lt;i&gt;Graph Database - San Francisco&lt;/i&gt;&amp;nbsp;on 4/28/2014&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;br /&gt;We see that the group has a set of topic nodes, which may already exist within the database. The subgraph must be merged into the larger graph without duplicating any nodes. Using Cypher&#39;s &lt;a href=&quot;http://docs.neo4j.org/chunked/stable/query-merge.html&quot; target=&quot;_blank&quot;&gt;MERGE&lt;/a&gt; clause we can get or create nodes, which is useful for expanding our graph&#39;s connected data. Each topic will collect more groups as new subgraphs are merged for daily imports. The same is also true for both day and location nodes.&lt;br /&gt;&lt;br /&gt;After a few days of scheduled imports, a group&#39;s subgraph begins to take shape. As day nodes are connected to the previous day&#39;s node, membership statistics are connected.&lt;br /&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;/div&gt;&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto; text-align: center;&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/kbastani/meetup-analytics/master/docs/images/data-import-scheduler-model.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;img alt=&quot;Neo4j Data Import Model&quot; border=&quot;0&quot; height=&quot;281&quot; src=&quot;https://raw.githubusercontent.com/kbastani/meetup-analytics/master/docs/images/data-import-scheduler-model.png&quot; title=&quot;Data import model&quot; width=&quot;640&quot; /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;&gt;A Meetup Group Statistics Subgraph, 4/23 to 4/28&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;br /&gt;The data import scheduler application is open-source and &lt;a href=&quot;http://www.github.com/neo4j-contrib/neo4j-meetups-reporting&quot; target=&quot;_blank&quot;&gt;available on GitHub&lt;/a&gt;. Also, &lt;a href=&quot;http://www.github.com/neo4j-contrib/neo4j-meetups-reporting/wiki&quot; target=&quot;_blank&quot;&gt;full documentation&lt;/a&gt; is available to help you get started with customizing your own graph-based reporting platform.&lt;br /&gt;&lt;br /&gt;All analysis on the temporal stats collected from the data import scheduler is performed within the &lt;a href=&quot;https://github.com/neo4j-contrib/neo4j-meetups-reporting/wiki#rest-api&quot; target=&quot;_blank&quot;&gt;REST API module of the reporting platform&lt;/a&gt;. It also safely exposes the graph database to a front-end web dashboard, consumed from client-side JavaScript. The REST API uses&amp;nbsp;&lt;a href=&quot;https://github.com/neo4j-contrib/neo4j-meetups-reporting/wiki#the-swagger-project&quot;&gt;Swagger&lt;/a&gt;, which is a&amp;nbsp;specification and complete framework for describing, producing, consuming, and visualizing RESTful web services.&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;http://www.kennybastani.com/2014/04/building-graph-based-analytics-platform-part-1.html&quot; target=&quot;_blank&quot;&gt;Building a Graph-based Reporting Platform: Part I&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://meetup-analytics-api.herokuapp.com/&quot; target=&quot;_blank&quot;&gt;Meetup Analytics API Demo&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://meetup-analytics-dashboard.herokuapp.com/&quot; target=&quot;_blank&quot;&gt;Meetup Analytics Web Dashboard Demo&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://www.github.com/neo4j-contrib/neo4j-meetups-reporting&quot; target=&quot;_blank&quot;&gt;Meetup Reporting GitHub Repository&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;</description><enclosure type='image/png' url='http://i.imgur.com/loY1ym6.png' length='0'/><link>https://www.kennybastani.com/2014/04/building-graph-based-analytics-platform-part-2.html</link><author>noreply@blogger.com (Kenny Bastani)</author><thr:total>0</thr:total></item><item><guid isPermaLink="false">tag:blogger.com,1999:blog-6300367579216018061.post-3127660464826424827</guid><pubDate>Thu, 24 Apr 2014 23:04:00 +0000</pubDate><atom:updated>2015-03-01T11:46:08.554-08:00</atom:updated><category domain="http://www.blogger.com/atom/ns#">analytics</category><category domain="http://www.blogger.com/atom/ns#">big data</category><category domain="http://www.blogger.com/atom/ns#">data science</category><category domain="http://www.blogger.com/atom/ns#">github</category><category domain="http://www.blogger.com/atom/ns#">meetup</category><category domain="http://www.blogger.com/atom/ns#">neo4j</category><category domain="http://www.blogger.com/atom/ns#">node.js</category><category domain="http://www.blogger.com/atom/ns#">open source software</category><category domain="http://www.blogger.com/atom/ns#">reporting</category><title>Building a Neo4j Reporting Service Part I</title><description>Data science is pretty hot right now. The obvious reason is that data is rapidly expanding in complexity and size. There is an opportunity to be had in building systems that can capture this data, classify it in multiple dimensions, and to scale it up to the demands of analysts looking to convert data into valuable reports.&lt;br /&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://pbs.twimg.com/media/Bj4RwfrCYAA_8pb.png:large&quot; imageanchor=&quot;1&quot; style=&quot;clear: left; float: right; margin-bottom: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; height=&quot;271&quot; src=&quot;https://pbs.twimg.com/media/Bj4RwfrCYAA_8pb.png:large&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;As a developer evangelist for Neo4j, I am frequently out in the community talking about things I build using our database. We use Meetup.com to schedule and promote our community events all over the world.&lt;br /&gt;&lt;br /&gt;If you&#39;re unfamiliar with Meetup.com, here is a description from their Wikipedia entry:&lt;br /&gt;&lt;br /&gt;&quot;&lt;i&gt;Meetup is an online social networking portal that facilitates offline  group meetings in various localities around the world. Meetup allows  members to find and join groups unified by a common interest, such as  politics, books, games, movies, health, pets, careers or hobbies. Users  enter their postal code or their city and the topic they want to meet  about, and the website helps them arrange a place and time to meet.  Topic listings are also available for users who only enter a location.&lt;/i&gt;&quot; &lt;br /&gt;&lt;br /&gt;At &lt;a href=&quot;http://www.neo4j.com/&quot; target=&quot;_blank&quot;&gt;Neo4j&lt;/a&gt;, we&#39;re obsessed with data, especially connected data. We believe in our product because we use it to solve our own problems every day. With something like Meetup.com, we found ourselves guessing about many of the aspects of our community and how we could do a better job creating a great community experience.&lt;br /&gt;&lt;br /&gt;Some of those questions were:&lt;br /&gt;&lt;ul&gt;&lt;li&gt;&lt;blockquote&gt;How many people will show up to an event from the attendee list?&lt;/blockquote&gt;&lt;/li&gt;&lt;li&gt;&lt;blockquote&gt;What kind of content are people interested in hearing about?&lt;/blockquote&gt;&lt;/li&gt;&lt;li&gt;&lt;blockquote&gt;What&#39;s the best location to host our meetups to boost attendance?&lt;/blockquote&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;I wanted to use Neo4j to do reporting. I decided to put together a platform to track some of this information and build some reports to visualize the data we collected. I started by breaking down the problem into a set of stories to be implemented as a report.&lt;/p&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_problem&quot; style=&quot;cursor: pointer;&quot;&gt;&lt;span style=&quot;font-size: large;&quot;&gt;Problem&lt;/span&gt;&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;ulist&quot;&gt;&lt;ul&gt;&lt;li&gt;Track meetup group growth over time&lt;br /&gt; &lt;/li&gt;&lt;li&gt;Apply tags to meetup groups and report combined growth of all groups over time&lt;br /&gt; &lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;sect1&quot;&gt;&lt;h2 id=&quot;_questions&quot; style=&quot;cursor: pointer;&quot;&gt;&lt;span style=&quot;font-size: large;&quot;&gt;Questions&lt;/span&gt;&lt;/h2&gt;&lt;div class=&quot;sectionbody&quot;&gt;&lt;div class=&quot;ulist&quot;&gt;&lt;ul&gt;&lt;li&gt;Given a start date and an end date, what is the time series that plots the membership growth of a given meetup group?&lt;br /&gt; &lt;/li&gt;&lt;li&gt;Given a start date, an end date, and a combination of tags, what is  the time series that plots the combined membership growth of all meetup  groups with those tags?&lt;br /&gt; &lt;/li&gt;&lt;li&gt;How do you generate the JSON data of a time series for a basic JS line chart plugin?&lt;br /&gt; &lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;br /&gt;I decided to start with a &lt;a href=&quot;http://gist.neo4j.org/&quot; target=&quot;_blank&quot;&gt;GraphGist&lt;/a&gt;, which is an open source project we built to enable our community to put together a quick proof of concept using our database.&lt;br /&gt;&lt;br /&gt;&lt;a href=&quot;http://gist.neo4j.org/?e2e0e4469917729765fe&quot; target=&quot;_blank&quot;&gt;Neo4j for Graph Analytics: Meetup.com Example&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;I designed an example graph data model, which I then translated into Neo4j&#39;s Cypher query language to create an example dataset.&lt;br /&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/kbastani/meetup-analytics/master/docs/images/meetup-analytics-graph-gist.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; height=&quot;584&quot; src=&quot;https://raw.githubusercontent.com/kbastani/meetup-analytics/master/docs/images/meetup-analytics-graph-gist.png&quot; width=&quot;640&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;br /&gt;Now it was time to scale it up to a full platform. I decided to use Node.js.&lt;br /&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/kbastani/meetup-analytics/master/docs/images/graph-based-analytics-components.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; height=&quot;315&quot; src=&quot;https://raw.githubusercontent.com/kbastani/meetup-analytics/master/docs/images/graph-based-analytics-components.png&quot; width=&quot;640&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;There would be three Node.js driven components. One console application for importing data on a schedule and two web applications; a dashboard for displaying reports and REST API to communicate with the Neo4j graph database. &lt;br /&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/kbastani/meetup-analytics/master/docs/images/graph-based-analytics-system-diagram.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; height=&quot;315&quot; src=&quot;https://raw.githubusercontent.com/kbastani/meetup-analytics/master/docs/images/graph-based-analytics-system-diagram.png&quot; width=&quot;640&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;With an architecture in place, I went forward with building out each of the modules.&lt;br /&gt;&lt;br /&gt;&lt;a href=&quot;http://www.kennybastani.com/2014/04/building-graph-based-analytics-platform-part-2.html&quot; target=&quot;_blank&quot;&gt;In my next blog post&lt;/a&gt; I will go through the details of building the import scheduler, which polls the Meetup.com API each day and imports the graph data model into Neo4j. &lt;br /&gt;&lt;br /&gt;Feel free to take a look at the finished documentation which details the creation of each of the Node.js modules:&lt;br /&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/neo4j-contrib/neo4j-meetups-reporting/wiki&quot; target=&quot;_blank&quot;&gt;Graph-based Reporting Documentation&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;Also, I put a slide deck together:&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;iframe allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;356&quot; marginheight=&quot;0&quot; marginwidth=&quot;0&quot; scrolling=&quot;no&quot; src=&quot;http://www.slideshare.net/slideshow/embed_code/33832810&quot; style=&quot;border-width: 1px 1px 0; border: 1px solid #CCC; margin-bottom: 5px; max-width: 100%;&quot; width=&quot;427&quot;&gt; &lt;/iframe&gt; &lt;br /&gt;&lt;div style=&quot;margin-bottom: 5px;&quot;&gt;&lt;b&gt; &lt;a href=&quot;https://www.slideshare.net/KennyBastani/building-a-graph-based-analytics-platform&quot; target=&quot;_blank&quot; title=&quot;Building a Graph-based Reporting Platform&quot;&gt;Building a Graph-based Reporting Platform&lt;/a&gt; &lt;/b&gt; from &lt;b&gt;&lt;a href=&quot;http://www.slideshare.net/KennyBastani&quot; target=&quot;_blank&quot;&gt;Kenny Bastani&lt;/a&gt;&lt;/b&gt; &lt;/div&gt;</description><enclosure type='image/png' url='http://pbs.twimg.com/media/Bj4RwfrCYAA_8pb.png' length='0'/><link>https://www.kennybastani.com/2014/04/building-graph-based-analytics-platform-part-1.html</link><author>noreply@blogger.com (Kenny Bastani)</author><thr:total>0</thr:total></item><item><guid isPermaLink="false">tag:blogger.com,1999:blog-6300367579216018061.post-9026102605042703913</guid><pubDate>Tue, 15 Oct 2013 16:36:00 +0000</pubDate><atom:updated>2013-10-15T09:36:34.788-07:00</atom:updated><category domain="http://www.blogger.com/atom/ns#">graph database</category><category domain="http://www.blogger.com/atom/ns#">graph theory</category><category domain="http://www.blogger.com/atom/ns#">neo4j</category><category domain="http://www.blogger.com/atom/ns#">recommendation engine</category><category domain="http://www.blogger.com/atom/ns#">time scales</category><title>Time Scale Event Meta Model</title><description>&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;float: left; margin-right: 1em; text-align: left;&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://4.bp.blogspot.com/-xSx8J_6BLIg/Ul1tMrWx5QI/AAAAAAAAA3o/73E6I-_Qtow/s1600/TSEMM-v1.04.png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;img border=&quot;0&quot; height=&quot;320&quot; src=&quot;http://4.bp.blogspot.com/-xSx8J_6BLIg/Ul1tMrWx5QI/AAAAAAAAA3o/73E6I-_Qtow/s320/TSEMM-v1.04.png&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;&gt;Time Scale Graph&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;Recently at the &lt;a href=&quot;http://www.graphconnect.com/san-francisco&quot;&gt;GraphConnect 2013 conference in San Francisco&lt;/a&gt;, questions were asked about how to handle temporal or time-based traversals in a Neo4j graph database.&lt;br /&gt;&lt;br /&gt;So I decided to write a GraphGist to help Neo4j developers do recommendations by logging events within a &quot;Time Scale Graph&quot;. &lt;br /&gt;&lt;br /&gt;The goal of this GraphGist is to provide you with a lens to help you see information as simple temporal facts that are captured across space and time.&lt;br /&gt;&lt;br /&gt;You can find the full GraphGist &lt;a href=&quot;http://gist.neo4j.org/?github-kbastani%2Fgists%2F%2Fmeta%2FTimeScaleEventMetaModel.adoc&quot;&gt;here&lt;/a&gt;&lt;br /&gt;</description><link>https://www.kennybastani.com/2013/10/time-scale-event-meta-model.html</link><author>noreply@blogger.com (Kenny Bastani)</author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://4.bp.blogspot.com/-xSx8J_6BLIg/Ul1tMrWx5QI/AAAAAAAAA3o/73E6I-_Qtow/s72-c/TSEMM-v1.04.png" height="72" width="72"/><thr:total>0</thr:total></item><item><guid isPermaLink="false">tag:blogger.com,1999:blog-6300367579216018061.post-5507396156360903260</guid><pubDate>Wed, 14 Aug 2013 18:00:00 +0000</pubDate><atom:updated>2015-12-08T00:10:14.443-08:00</atom:updated><category domain="http://www.blogger.com/atom/ns#">cypher</category><category domain="http://www.blogger.com/atom/ns#">delete duplicate records</category><category domain="http://www.blogger.com/atom/ns#">graph database</category><category domain="http://www.blogger.com/atom/ns#">neo4j</category><category domain="http://www.blogger.com/atom/ns#">nodes</category><title>Delete Duplicate Node By Index Using Neo4j Cypher Query</title><description>&lt;p&gt;Follow the steps below to find and delete duplicate nodes on property and index in Neo4j&#39;s web admin console.&lt;/p&gt;&lt;h3&gt;Step 1&lt;/h3&gt;&lt;p&gt;Select duplicate records by executing the following Cypher query in the Neo4j admin console.&lt;/p&gt;&lt;pre data-lang=&quot;cypher&quot;&gt;START n=node:invoices(&quot;PO_NUMBER:(\&quot;112233\&quot;)&quot;)&lt;br /&gt;// Cypher query for collecting the ids of indexed nodes containing duplicate properties&lt;br /&gt;WITH n&lt;br /&gt;ORDER BY id(n) DESC  // Order by descending to delete the most recent duplicated record&lt;br /&gt;WITH n.Key? as DuplicateKey, COUNT(n) as ColCount, COLLECT(id(n)) as ColNode&lt;br /&gt;WITH DuplicateKey, ColCount, ColNode, HEAD(ColNode) as DuplicateId&lt;br /&gt;WHERE ColCount &gt; 1 AND (DuplicateKey is not null) AND (DuplicateId is not null)&lt;br /&gt;WITH DuplicateKey, ColCount, ColNode, DuplicateId &lt;br /&gt;ORDER BY DuplicateId &lt;br /&gt;RETURN DuplicateKey, ColCount, DuplicateId &lt;br /&gt;//RETURN COLLECT(DuplicateId) as CommaSeparatedListOfIds&lt;br /&gt;//** Toggle comments for the return statements above to validate duplicate records &lt;br /&gt;//** Do not proceed to delete without validating&lt;br /&gt;&lt;/pre&gt;&lt;h3&gt;Step 2&lt;/h3&gt;&lt;p&gt;Validate and copy duplicate record IDs from web admin console:&lt;/p&gt;&lt;div style=&quot;float: left;&quot;&gt;&lt;table cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;float: left; margin-bottom: 2em; margin-right: 1em; text-align: left;&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://3.bp.blogspot.com/-qazIr48H3dI/Ugu7wlQ0upI/AAAAAAAAA2w/rIkSJXZxkpw/s1600/validate-duplicates.PNG&quot; imageanchor=&quot;1&quot; style=&quot;clear: left; margin-bottom: 1em; margin-left: auto; margin-right: auto;&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-qazIr48H3dI/Ugu7wlQ0upI/AAAAAAAAA2w/rIkSJXZxkpw/s1600/validate-duplicates.PNG&quot; /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;tr-caption&quot;&gt;Execute the Cypher query from Step 1 to validate duplicate records exist.&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;float: left; margin-bottom: 2em; text-align: left;&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://3.bp.blogspot.com/-BwIggYU3MUg/Ugu78nyPW3I/AAAAAAAAA24/jlHkRJip8Eo/s1600/comma-separated-list-id-duplicates.PNG&quot; imageanchor=&quot;1&quot; style=&quot;clear: left; margin-bottom: 1em; margin-left: auto; margin-right: auto;&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-BwIggYU3MUg/Ugu78nyPW3I/AAAAAAAAA24/jlHkRJip8Eo/s1600/comma-separated-list-id-duplicates.PNG&quot; /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;tr-caption&quot;&gt;After validating duplicate records, execute the Cypher query from Step 1 as a comma separated list of IDs.&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;&lt;h3&gt;Step 3&lt;/h3&gt;&lt;p&gt;Copy and paste CommaSeparatedListOfIds into the delete query below.&lt;/p&gt;&lt;pre data-lang=&quot;cypher&quot;&gt;&lt;br /&gt;START n=node(1120038,1120039,1120040,1120042,1120044,1120048,1120049,1120050,1120053,1120067,1120068)&lt;br /&gt;// Replace above with the IDs from CommaSeparatedListOfIds in the previous step&lt;br /&gt;MATCH n-[r]-()&lt;br /&gt;DELETE r, n&lt;br /&gt;&lt;/pre&gt;&lt;p&gt;** Execute the Cypher query above &lt;b&gt;ONLY&lt;/b&gt; after replacing the example IDs in the START statement.&lt;/p&gt;&lt;h3&gt;Step 4&lt;/h3&gt;&lt;p&gt;Validate that the delete transaction committed.&lt;/p&gt; &lt;p&gt;&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-bottom:2em; margin-right: 1em; text-align: left;&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://1.bp.blogspot.com/-5rXcl9VhY7Q/Ugu-PbcrFMI/AAAAAAAAA3I/OqN0nqhVFfI/s1600/comma-separated-list-id-duplicates-deleted.PNG&quot; imageanchor=&quot;1&quot; style=&quot;clear: both; margin-bottom: 1em; margin-left: auto; margin-right: auto;&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-5rXcl9VhY7Q/Ugu-PbcrFMI/AAAAAAAAA3I/OqN0nqhVFfI/s1600/comma-separated-list-id-duplicates-deleted.PNG&quot; /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;&gt;Execute the Cypher query from Step 1 to make sure that the transaction was committed.&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/p&gt;&lt;p&gt;That&#39;s it! Comment below with questions or feedback.&lt;/p&gt;</description><link>https://www.kennybastani.com/2013/08/delete-duplicate-node-by-index-using.html</link><author>noreply@blogger.com (Kenny Bastani)</author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://3.bp.blogspot.com/-qazIr48H3dI/Ugu7wlQ0upI/AAAAAAAAA2w/rIkSJXZxkpw/s72-c/validate-duplicates.PNG" height="72" width="72"/><thr:total>0</thr:total></item><item><guid isPermaLink="false">tag:blogger.com,1999:blog-6300367579216018061.post-9157088403367201566</guid><pubDate>Sat, 26 Jan 2013 00:22:00 +0000</pubDate><atom:updated>2013-02-01T22:10:22.526-08:00</atom:updated><category domain="http://www.blogger.com/atom/ns#">c#</category><category domain="http://www.blogger.com/atom/ns#">coding rocks</category><category domain="http://www.blogger.com/atom/ns#">computable numbers</category><category domain="http://www.blogger.com/atom/ns#">information theory</category><category domain="http://www.blogger.com/atom/ns#">universal turing machine</category><title>Universal Turing Machine in C#</title><description>&lt;div&gt;&lt;div style=&quot;text-align: right;&quot;&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;http://3.bp.blogspot.com/-8NOa0ghIuMc/UQyttWVMT-I/AAAAAAAAAlM/esDCP6HHf2s/s1600/Photo+to+Painting+Turing.png&quot; imageanchor=&quot;1&quot; style=&quot;clear: right; float: right; margin-bottom: 1em; margin-left: 1em;&quot;&gt;&lt;img border=&quot;0&quot; height=&quot;320&quot; src=&quot;http://3.bp.blogspot.com/-8NOa0ghIuMc/UQyttWVMT-I/AAAAAAAAAlM/esDCP6HHf2s/s320/Photo+to+Painting+Turing.png&quot; width=&quot;256&quot; /&gt;&lt;/a&gt;&lt;/div&gt;I realized that this blog is fairly absent of any actual programming posts, even though it takes up a majority of my time on any given day (or night). &lt;br /&gt;&lt;br /&gt;Here is a complete Universal Turing Machine I wrote in C#. The state table computes general relativity, based on my &quot;theory of everything&quot; down in another blog post. Each bit on the tape represents a photon and each full cycle represents a frame of reference.&lt;br /&gt;&lt;br /&gt;I&#39;ve excluded some code from my implementation so that it is easier to read, specifically if you run this, make sure you change the stopping criteria or run it in a console application in debug mode with a break point.&lt;br /&gt;&lt;br /&gt;This is easily ported to JavaScript, so look forward to a jQuery plugin soon.&lt;br /&gt;&lt;br /&gt;A paper where Turing first proposed the idea of computable numbers:&lt;br /&gt;&lt;b&gt;&lt;i&gt;&lt;br /&gt;&lt;/i&gt;&lt;/b&gt;&lt;b&gt;&lt;i&gt;&lt;a href=&quot;http://www.cs.virginia.edu/~robins/Turing_Paper_1936.pdf&quot; target=&quot;_blank&quot;&gt;http://www.cs.virginia.edu/~robins/Turing_Paper_1936.pdf&lt;/a&gt;&lt;/i&gt;&lt;/b&gt;&lt;br /&gt;&lt;span style=&quot;font-size: small;&quot;&gt;&lt;span style=&quot;font-size: small;&quot;&gt;&lt;span style=&quot;font-family: Arial,Helvetica,sans-serif;&quot;&gt;&lt;span style=&quot;font-size: small;&quot;&gt;&lt;span style=&quot;font-size: small;&quot;&gt;&lt;span style=&quot;font-size: small;&quot;&gt;&lt;span style=&quot;font-size: small;&quot;&gt;&lt;span style=&quot;font-size: small;&quot;&gt;&lt;span style=&quot;font-size: small;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: small;&quot;&gt;&lt;span style=&quot;font-size: small;&quot;&gt;&lt;span style=&quot;font-family: Arial,Helvetica,sans-serif;&quot;&gt;&lt;span style=&quot;font-size: small;&quot;&gt;&lt;span style=&quot;font-size: small;&quot;&gt;&lt;span style=&quot;font-size: small;&quot;&gt;&lt;span style=&quot;font-size: small;&quot;&gt;&lt;span style=&quot;font-size: small;&quot;&gt;&lt;span style=&quot;font-size: small;&quot;&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&amp;nbsp; &lt;span style=&quot;font-family: Arial,Helvetica,sans-serif;&quot;&gt;&lt;span style=&quot;font-size: small;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/div&gt;&lt;pre class=&quot;brush: csharp&quot;&gt;// DIGITAL UNIVERSAL TURING MACHINE – C# &lt;br /&gt;// -------------------------------------&lt;br /&gt;// Author: Kenny Bastani&lt;br /&gt;//&lt;br /&gt;// Based on the theory of computable numbers by Alan Turing&lt;br /&gt;// Inspired by James Gleick’s “The Information: A History, a Theory, a Flood&quot;&lt;br /&gt;// &lt;br /&gt;// positions[] table is an infinite length: &lt;br /&gt;// ----------------------------------------&lt;br /&gt;// positions[i] = (positions[i] &amp;gt;= tape.Length ? positions[i] % tape.Length : positions[i]) &lt;br /&gt;// OR &lt;br /&gt;// positions[i] = (positions[i] &amp;lt; 0 ? tape.Length – 1 : positions[i])&lt;br /&gt;//&lt;br /&gt;// STATE A:&lt;br /&gt;//          0: move forward 1 space; state A&lt;br /&gt;//          1: write 0; state B&lt;br /&gt;// STATE B:&lt;br /&gt;//          0: move forward 1 space; state C&lt;br /&gt;//          1: move forward 1 space; state A&lt;br /&gt;// STATE C:&lt;br /&gt;//          0: stay; state B&lt;br /&gt;//          1: move backward 1 space; state D&lt;br /&gt;// STATE D:&lt;br /&gt;//          0: write 1; state B&lt;br /&gt;//          1: stay; state C&lt;br /&gt;&lt;br /&gt;byte i = 0;&lt;br /&gt;while (true)&lt;br /&gt;{&lt;br /&gt;    // The positions table stores the position of the Turing machine on the tape,&lt;br /&gt;    // where byte i represents multiple Turing machines operating on the same tape&lt;br /&gt;    byte bit = tape[positions[i]];&lt;br /&gt;    switch (turingMachines[i])&lt;br /&gt;    {&lt;br /&gt;        // State A is the ready state, it holds no memory of erasing a bit. This is the &quot;ZERO STATE&quot;.&lt;br /&gt;        case &quot;A&quot;:&lt;br /&gt;            if (bit == 0)&lt;br /&gt;            {&lt;br /&gt;                // Advance until a bit 1 is found&lt;br /&gt;                positions[i]++;&lt;br /&gt;                turingMachines[i] = &quot;A&quot;;&lt;br /&gt;            }&lt;br /&gt;            else if (bit == 1)&lt;br /&gt;            {&lt;br /&gt;                // Erase the bit from the tape and store it in memory as state B  &lt;br /&gt;                tape[positions[i]] = 0;&lt;br /&gt;                turingMachines[i] = &quot;B&quot;;&lt;br /&gt;            }&lt;br /&gt;            break;&lt;br /&gt;        case &quot;B&quot;:&lt;br /&gt;            if (bit == 0)&lt;br /&gt;            {&lt;br /&gt;                // Advance until a bit 1 is found&lt;br /&gt;                positions[i]++;&lt;br /&gt;                turingMachines[i] = &quot;C&quot;;&lt;br /&gt;            }&lt;br /&gt;            else if (bit == 1)&lt;br /&gt;            {&lt;br /&gt;                // If a bit in state B is equal to 1, it is because the machine &lt;br /&gt;                // just wrote it to the tape&lt;br /&gt;                positions[i]++;&lt;br /&gt;                turingMachines[i] = &quot;A&quot;;&lt;br /&gt;            }&lt;br /&gt;            break;&lt;br /&gt;        case &quot;C&quot;:&lt;br /&gt;            if (bit == 0)&lt;br /&gt;            {&lt;br /&gt;                // A bit 1 is held in memory, switch to B state and continue oscillating&lt;br /&gt;                // until colliding with bit 1&lt;br /&gt;                turingMachines[i] = &quot;B&quot;;&lt;br /&gt;            }&lt;br /&gt;            else if (bit == 1)&lt;br /&gt;            {&lt;br /&gt;                // A bit 1 has been found and cannot be erased because a bit is already &lt;br /&gt;                // in memory, move back one space and switch to the D state&lt;br /&gt;                positions[i]--;&lt;br /&gt;                turingMachines[i] = &quot;D&quot;;&lt;br /&gt;            }&lt;br /&gt;            break;&lt;br /&gt;        case &quot;D&quot;:&lt;br /&gt;            if (bit == 0)&lt;br /&gt;            {&lt;br /&gt;                // Release the bit from memory and write it back to the tape, &lt;br /&gt;                // revert to state B&lt;br /&gt;                tape[positions[i]] = 1;&lt;br /&gt;                turingMachines[i] = &quot;B&quot;;&lt;br /&gt;            }&lt;br /&gt;            else if (bit == 1)&lt;br /&gt;            {&lt;br /&gt;                // This state is rare and happens when another Turing machine has released &lt;br /&gt;                // a bit in a parallel operation, revert to state C&lt;br /&gt;                turingMachines[i] = &quot;C&quot;;&lt;br /&gt;            }&lt;br /&gt;            break;&lt;br /&gt;        default:&lt;br /&gt;            break;&lt;br /&gt;    }&lt;br /&gt;}&lt;br /&gt;&lt;/pre&gt;</description><link>https://www.kennybastani.com/2013/01/universal-turing-machine-in-c.html</link><author>noreply@blogger.com (Kenny Bastani)</author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://3.bp.blogspot.com/-8NOa0ghIuMc/UQyttWVMT-I/AAAAAAAAAlM/esDCP6HHf2s/s72-c/Photo+to+Painting+Turing.png" height="72" width="72"/><thr:total>0</thr:total></item></channel></rss>