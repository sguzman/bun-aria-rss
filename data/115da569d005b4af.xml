<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	
	xmlns:georss="http://www.georss.org/georss"
	xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#"
	>

<channel>
	<title>neptune.ai</title>
	<atom:link href="https://neptune.ai/feed" rel="self" type="application/rss+xml" />
	<link>https://neptune.ai</link>
	<description>Metadata store for MLOps, built for teams that run a lot of experiments.</description>
	<lastBuildDate>Fri, 04 Nov 2022 09:04:36 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	

<image>
	<url>https://i0.wp.com/neptune.ai/wp-content/uploads/2019/03/cropped-Artboard-12.png?fit=32%2C32&#038;ssl=1</url>
	<title>neptune.ai</title>
	<link>https://neptune.ai</link>
	<width>32</width>
	<height>32</height>
</image> 
<site xmlns="com-wordpress:feed-additions:1">158350742</site>	<item>
		<title>Argo vs Airflow vs Prefect: How Are They Different</title>
		<link>https://neptune.ai/blog/argo-vs-airflow-vs-prefect-differences</link>
		
		<dc:creator><![CDATA[Nilesh Barla]]></dc:creator>
		<pubDate>Fri, 04 Nov 2022 09:04:34 +0000</pubDate>
				<category><![CDATA[Machine Learning Tools]]></category>
		<category><![CDATA[model management]]></category>
		<guid isPermaLink="false">https://neptune.ai/?p=72250</guid>

					<description><![CDATA[<p>We live at a stage where ML and DL software are everywhere. New startups and various other companies are adapting and integrating AI systems into their new and already existing workflows to be much more productive and efficient. These systems reduce manual tasks and deliver smart and intelligent solutions. Although they are quite proficient in [&#8230;]</p>
<p>The post <a rel="nofollow" href="https://neptune.ai/blog/argo-vs-airflow-vs-prefect-differences">Argo vs Airflow vs Prefect: How Are They Different</a> appeared first on <a rel="nofollow" href="https://neptune.ai">neptune.ai</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<p>We live at a stage where ML and DL software are everywhere. New startups and various other companies are adapting and integrating AI systems into their new and already existing workflows to be much more productive and efficient. These systems reduce manual tasks and deliver smart and intelligent solutions. Although they are quite proficient in what they do, all AI systems have different modules that must be brought together to build an operational and effective product.&nbsp;</p>



<p>These systems can be broadly divided into five phases, keeping in mind that these phases contain various additional and repetitive tasks:</p>


<div class="case-study-numbered-list">
    <h2></h2>
    <ul>
                    <li><span>1</span>Data collection </li>
                    <li><span>2</span>Feature engineering</li>
                    <li><span>3</span>Modeling (which includes training, validation, testing, and inference)</li>
                    <li><span>4</span>Deployment </li>
                    <li><span>5</span>Monitoring</li>
            </ul>
</div>



<p>Executing these phases individually can take a lot of time and continuous human effort. These phases must be synchronized and sequentially orchestrated in order to get the best out of them. This can be achieved by <strong>task orchestration tools</strong> that enable ML practitioners to effortlessly bring together and orchestrate different phases of an AI system.</p>


<div id="block_a590483c437b08259999f8b6675fb640" class="separator separator-15"></div>


<div class="wp-block-image">
<figure class="aligncenter size-large is-resized"><img data-attachment-id="72252" data-permalink="https://neptune.ai/argo-vs-airflow-vs-prefect-1" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/argo-vs-airflow-vs-prefect-1.png?fit=1443%2C1600&amp;ssl=1" data-orig-size="1443,1600" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="argo-vs-airflow-vs-prefect-1" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/argo-vs-airflow-vs-prefect-1.png?fit=271%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/argo-vs-airflow-vs-prefect-1.png?fit=924%2C1024&amp;ssl=1" decoding="async" src="https://i0.wp.com/neptune.ai/wp-content/uploads/argo-vs-airflow-vs-prefect-1.png?resize=693%2C768&#038;ssl=1" alt="Phases of AI systems" class="wp-image-72252" width="693" height="768" data-recalc-dims="1" /><figcaption class="wp-element-caption"><em>Phases of AI systems | <a href="https://www.datarevenue.com/en-blog/what-we-are-loving-about-prefect" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>

<div id="block_85ff0a448aeeb70a2a8cdd832cd74858" class="separator separator-10"></div>



<p>In this article, we will explore:</p>


<div class="case-study-numbered-list">
    <h2></h2>
    <ul>
                    <li><span>1</span>What task orchestration tools are?</li>
                    <li><span>2</span>Three different tools that can help ML practitioners to orchestrate their workflow.</li>
                    <li><span>3</span>Comparison of the three tools</li>
                    <li><span>4</span>Which tool to use and when?</li>
            </ul>
</div>



<h2>Task orchestration tools: What they are and how are they useful?</h2>



<p>Orchestration tools enable various tasks in MLOps to be organized and sequentially executed. These tools have the capability to orchestrate different tasks at a given period. One of the key properties of these tools is the distribution of tasks. Most of the tools leverage what is known as the DAG or Directed Acyclic Graph, which you will often come across in this article. A DAG is a graph representation of the tasks that need to be executed.&nbsp;</p>


<div id="block_85ff0a448aeeb70a2a8cdd832cd74858" class="separator separator-10"></div>


<div class="wp-block-image">
<figure class="aligncenter size-large is-resized"><img data-attachment-id="72253" data-permalink="https://neptune.ai/argo-vs-airflow-vs-prefect-2" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/argo-vs-airflow-vs-prefect-2.png?fit=1472%2C1334&amp;ssl=1" data-orig-size="1472,1334" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="argo-vs-airflow-vs-prefect-2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/argo-vs-airflow-vs-prefect-2.png?fit=300%2C272&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/argo-vs-airflow-vs-prefect-2.png?fit=1024%2C928&amp;ssl=1" decoding="async" src="https://i0.wp.com/neptune.ai/wp-content/uploads/argo-vs-airflow-vs-prefect-2.png?resize=768%2C696&#038;ssl=1" alt="Explanation of DAG" class="wp-image-72253" width="768" height="696" data-recalc-dims="1" /><figcaption class="wp-element-caption"><em>Graphic explanation of DAG | <a href="https://www.datarevenue.com/en-blog/airflow-vs-luigi-vs-argo-vs-mlflow-vs-kubeflow" target="_blank" rel="noreferrer noopener nofollow">Source</a>&nbsp;</em></figcaption></figure></div>

<div id="block_85ff0a448aeeb70a2a8cdd832cd74858" class="separator separator-10"></div>



<p>DAG enables tasks in a pipeline to be distributed parallelly to various other modules for processing, this offers efficiency. See the image above. DAG also enables tasks to be sequentially sound or arranged for proper execution and timely results.</p>



<p>Another important property that these tools have is adaptability to agile environments. This allows ML practitioners to incorporate various other tools that can be used to monitor, deploy, analyze and preprocess, test, infer, et cetera. If an orchestration tool can orchestrate various tasks from different tools, then it can be considered a good tool. But this is not the case every time, some of the tools are strictly contained within their derived environments, which does not bode well for users trying to integrate any third-party applications.&nbsp;</p>



<p>In this article, we will explore three tools – <a href="https://argoproj.github.io/" target="_blank" rel="noreferrer noopener nofollow">Argo</a>, <a href="https://airflow.apache.org/" target="_blank" rel="noreferrer noopener nofollow">Airflow</a>, and <a href="https://www.prefect.io/" target="_blank" rel="noreferrer noopener nofollow">Prefect</a>, that incorporate these two properties and various others as well.&nbsp;</p>



<h2>TL;DR comparison table&nbsp;</h2>



<p>Here is a table inspired by <a href="https://medium.com/arthur-engineering/picking-a-kubernetes-orchestrator-airflow-argo-and-prefect-83539ecc69b" target="_blank" rel="noreferrer noopener nofollow">Ian McGraw&#8217;s article</a>, which provides an overview of what these tools offer for orchestration and how they differ from each other in these aspects.</p>


<div id="block_1f2b87c2de136cd7e7f6f69de21adf08" class="separator separator-15"></div>


<div class="medium-table">
        <div class="mt-row heading">
            <div class="mt-col" style="width: 8%">
                    </div>
            <div class="mt-col" style="width: 23%">
            Features        </div>
            <div class="mt-col" style="width: 23%">
            Argo        </div>
            <div class="mt-col" style="width: 23%">
            Airflow        </div>
            <div class="mt-col" style="width: 23%">
            Prefect        </div>
        </div>
    
            <div class="mt-row">
                            <div class="mt-col" style="width: 8%">
                                                                <p><strong>1.</strong></p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Features:
                    </span>
                                                                <p>Fault-tolerant scheduling</p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Argo:
                    </span>
                                                                                            <img decoding="async" src="https://neptune.ai/wp-content/themes/neptune-experience/img/unchecked.svg"/>
                                                            </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Airflow:
                    </span>
                                                                                            <img decoding="async" src="https://neptune.ai/wp-content/themes/neptune-experience/img/checked.svg"/>
                                                            </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Prefect:
                    </span>
                                                                                            <img decoding="async" src="https://neptune.ai/wp-content/themes/neptune-experience/img/checked.svg"/>
                                                            </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 8%">
                                                                <p><strong>2.</strong></p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Features:
                    </span>
                                                                <p>UI Support</p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Argo:
                    </span>
                                                                                            <img decoding="async" src="https://neptune.ai/wp-content/themes/neptune-experience/img/checked.svg"/>
                                                            </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Airflow:
                    </span>
                                                                                            <img decoding="async" src="https://neptune.ai/wp-content/themes/neptune-experience/img/checked.svg"/>
                                                            </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Prefect:
                    </span>
                                                                                            <img decoding="async" src="https://neptune.ai/wp-content/themes/neptune-experience/img/checked.svg"/>
                                                            </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 8%">
                                                                <p><strong>3.</strong></p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Features:
                    </span>
                                                                <p>Workflow definitionlanguage</p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Argo:
                    </span>
                                                                <p>YAML</p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Airflow:
                    </span>
                                                                <p>Python</p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Prefect:
                    </span>
                                                                <p>Pytchon</p>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 8%">
                                                                <p><strong>4.</strong></p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Features:
                    </span>
                                                                <p>3rd partyintegration</p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Argo:
                    </span>
                                                                <p>Since Argo is container-based it doesn’t come with pre-installed 3rd party systems.</p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Airflow:
                    </span>
                                                                <p>Supports various 3rd party integration</p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Prefect:
                    </span>
                                                                <p>Supports various 3rd party integration</p>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 8%">
                                                                <p><strong>5.</strong></p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Features:
                    </span>
                                                                <p>Workflows</p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Argo:
                    </span>
                                                                <p>Dynamic workflow</p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Airflow:
                    </span>
                                                                <p>Static workflow</p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Prefect:
                    </span>
                                                                <p>Dynamic workflow</p>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 8%">
                                                                <p><strong>6.</strong></p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Features:
                    </span>
                                                                <p>Accessibility</p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Argo:
                    </span>
                                                                <p>Open-sourced</p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Airflow:
                    </span>
                                                                <p>Open-source</p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Prefect:
                    </span>
                                                                <p>Hybrid (Open-sourced and subscription-based)</p>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 8%">
                                                                <p><strong>7.</strong></p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Features:
                    </span>
                                                                <p>Parametrized workflows</p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Argo:
                    </span>
                                                                <p>Have an extensive parameter-passing syntax.</p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Airflow:
                    </span>
                                                                <p>Does not has a mechanism to pass parameter.</p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Prefect:
                    </span>
                                                                <p>Supports parameters as first-class object</p>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 8%">
                                                                <p><strong>8.</strong></p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Features:
                    </span>
                                                                <p>Kubernetes support</p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Argo:
                    </span>
                                                                                            <img decoding="async" src="https://neptune.ai/wp-content/themes/neptune-experience/img/checked.svg"/>
                                                            </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Airflow:
                    </span>
                                                                                            <img decoding="async" src="https://neptune.ai/wp-content/themes/neptune-experience/img/unchecked.svg"/>
                                                            </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Prefect:
                    </span>
                                                                                            <img decoding="async" src="https://neptune.ai/wp-content/themes/neptune-experience/img/checked.svg"/>
                                                            </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 8%">
                                                                <p><strong>9.</strong></p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Features:
                    </span>
                                                                <p>Scalability</p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Argo:
                    </span>
                                                                <p>Highly Parallel</p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Airflow:
                    </span>
                                                                <p>Horizontal scalable</p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Prefect:
                    </span>
                                                                <p>Parallel when using Kubernetes</p>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 8%">
                                                                <p><strong>10.</strong></p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Features:
                    </span>
                                                                <p>Community Support</p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Argo:
                    </span>
                                                                <p>Large</p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Airflow:
                    </span>
                                                                <p>Large</p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Prefect:
                    </span>
                                                                <p>Medium</p>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 8%">
                                                                <p><strong>11.</strong></p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Features:
                    </span>
                                                                <p>State storage</p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Argo:
                    </span>
                                                                <p>All states are stored within the Kubernetes workflow</p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Airflow:
                    </span>
                                                                <p>Postgres DB</p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Prefect:
                    </span>
                                                                <p>Postgres DB</p>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 8%">
                                                                <p><strong>12.</strong></p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Features:
                    </span>
                                                                <p>Ease of deployment</p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Argo:
                    </span>
                                                                <p>Medium</p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Airflow:
                    </span>
                                                                <p>Medium</p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Prefect:
                    </span>
                                                                <p>Difficult</p>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 8%">
                                                                <p><strong>13.</strong></p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Features:
                    </span>
                                                                <p>Event-driven workflows</p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Argo:
                    </span>
                                                                                            <img decoding="async" src="https://neptune.ai/wp-content/themes/neptune-experience/img/checked.svg"/>
                                                            </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Airflow:
                    </span>
                                                                                            <img decoding="async" src="https://neptune.ai/wp-content/themes/neptune-experience/img/unchecked.svg"/>
                                                            </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Prefect:
                    </span>
                                                                                            <img decoding="async" src="https://neptune.ai/wp-content/themes/neptune-experience/img/checked.svg"/>
                                                            </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 8%">
                                                                <p><strong>14.</strong></p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Features:
                    </span>
                                                                <p>Scripts in DAG definition</p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Argo:
                    </span>
                                                                <p>Argo uses text scripts to pass in containers.</p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Airflow:
                    </span>
                                                                <p>Airflow uses Python-based DAG definition language.</p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Prefect:
                    </span>
                                                                <p>Perfect uses functional flow a Python-based API.</p>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 8%">
                                                                <p><strong>15.</strong></p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Features:
                    </span>
                                                                <p>Use Cases</p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Argo:
                    </span>
                                                                <p>&#8211; CI/CD- Data Processing- Infrastructure  Automation- Machine Learning- Stream Processing</p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Airflow:
                    </span>
                                                                <p>&#8211; ELT &#8211; ML Workflow- ML Automation</p>
                                    </div>
                            <div class="mt-col" style="width: 23%">
                                        <span class="column-name">
                        Prefect:
                    </span>
                                                                <p>&#8211; Automating Data Workflow (ELT)- ML Workflow and Orchestration- CI/CD</p>
                                    </div>
                    </div>
    </div>


<div id="block_93515cae6659e5256211b6b628c5a42c" class="separator separator-25"></div>



<p>Now let’s explore each of these tools in more detail under three primary categories:&nbsp;</p>


<div class="case-study-numbered-list">
    <h2></h2>
    <ul>
                    <li><span>1</span>Core concepts</li>
                    <li><span>2</span>Features they offer</li>
                    <li><span>3</span>Why use it?</li>
            </ul>
</div>



<h2>Core concepts</h2>



<p>All three tools are built on a set of concepts or principles around which they function. Argo is, for instance, built around two concepts: <strong>Workflow </strong>and<strong> Templates</strong>. Both of these make the backbone of its system. Likewise, Airflow is built around <strong>Webserver, Scheduler, Executor, </strong>and<strong> Database,</strong> while Prefect is built around <strong>Flows </strong>and<strong> Task</strong>. Now it is important for us to know what these concepts mean, what they offer, and how it is beneficial to us.</p>



<p>Before going into the details, here is a brief summary of the concepts.&nbsp;</p>


<div id="block_ab3f951667ba5e0c119448e7302b333a" class="separator separator-20"></div>


<div class="medium-table">
        <div class="mt-row heading">
            <div class="mt-col" style="width: 15%">
                    </div>
            <div class="mt-col" style="width: 85%">
            Properties of the Concepts        </div>
        </div>
    
            <div class="mt-row">
                            <div class="mt-col" style="width: 15%">
                                                                <p><strong>Argo</strong></p>
                                    </div>
                            <div class="mt-col" style="width: 85%">
                                        <span class="column-name">
                        Properties of the Concepts:
                    </span>
                                                                <p>It has two concepts <strong>Workflow</strong>, and <strong>Templates</strong>. Essentially the Workflow is the config YAML file. It provides structure and robustness to the workflow as they use DAGs to manage the workflows. On the other hand, templates are the functions that need to be executed. <br data-rich-text-line-break="true" />They are both static and dynamic meaning that you can modify steps on the go.</p>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 15%">
                                                                <p><strong>Airflow</strong></p>
                                    </div>
                            <div class="mt-col" style="width: 85%">
                                        <span class="column-name">
                        Properties of the Concepts:
                    </span>
                                                                <p>It has four concepts Webserver, Scheduler, Executor, and Database. They basically divide the whole process into different segments and these concepts act as major components to automate the whole process. This allows the workflow to be efficient since each component relies on the other, in this way it is easy to find and report bugs and errors. Furthermore, monitoring is quite easy.<br />
Though Airflow uses DAGs it is not dynamic but only static.</p>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 15%">
                                                                <p><strong>Prefect</strong></p>
                                    </div>
                            <div class="mt-col" style="width: 85%">
                                        <span class="column-name">
                        Properties of the Concepts:
                    </span>
                                                                <p>It leverages two concepts Flows and Tasks. Prefect uses DAGs that are defined as flow object which uses Python. In Prefect, flow objects can be created using Python which provides flexibility and robustness to define complex pipelines.<br />
Tasks are like templates in Argo which are used to define a specific function that needs to be executed. Again, it uses Python for this.<br />
Because Prefect uses Python as its main programming language it is easy to work with.</p>
                                    </div>
                    </div>
    </div>


<div id="block_f234d26439284ef4f7d43b9cdaa2d453" class="separator separator-5"></div>



<p class="has-text-align-center has-small-font-size"><em>Summary of the concepts</em></p>


<div id="block_1f2b87c2de136cd7e7f6f69de21adf08" class="separator separator-15"></div>



<p>Now, let’s understand these concepts in detail.&nbsp;</p>



<h3>Argo&nbsp;</h3>



<p>Argo uses two core concepts:</p>


<div class="custom-point-list">
<ol>
<li>Workflow</li>



<li>Templates</li>
</ol>
</div>


<h4>Workflow</h4>



<p>In Argo, the workflow happens to be the most integral component of the whole system. It has two important functions:&nbsp;</p>


<div class="custom-point-list">
<ol>
<li>It defines the tasks that need to be executed.</li>



<li>It stores the state of the tasks, which means that it serves as both a static and a dynamic object.</li>
</ol>
</div>


<p>Workflow is defined in the workflow.spec configuration file. It is a YAML file that consists of a list of <strong>templates</strong> and <strong>entry points</strong>. The Workflow can be considered as a file that hosts different templates. These templates define the function that needs to be executed.&nbsp;</p>



<p>As mentioned earlier that Argo leverages the <strong>Kubernetes</strong> engine for workflow synchronization, and the configuration file uses the same syntax as Kubernetes. The workflow YAML file has the following dictionaries or objects:</p>


<div class="custom-point-list">
<ol>
<li>apiVersion: This is where you define the name of the doc or API.</li>



<li>kind: It defines the type of Kubernetes object that needs to be created. For instance, if you want to deploy an app you can use <strong>Deployment </strong>as one of a kind, at other times you can use service. But in this case, we will use <strong>Workflow</strong>.</li>



<li>metadata: It enables us to define unique properties for that object, that could be a name, UUID, et cetera.&nbsp;</li>



<li>spec: It enables us to define specifications concerning the Workflow. These specifications would be entry points and templates.&nbsp;</li>



<li>templates: This is where we can define the tasks. The template can contain the docker image and various other scripts.&nbsp;</li>
</ol>
</div>


<h4>Templates&nbsp;</h4>



<p>In Argo, there are two types of templates which again are sub-classified into 6 types. The two major types are <strong>definition </strong>and <strong>invocators.&nbsp;</strong></p>



<h5>Definition</h5>



<p>This template, as the name suggests, defines the type of task in a Docker container. The Definition itself is divided into four categories:</p>


<div class="custom-point-list">
<ol>
<li><strong>Container</strong>: It enables users to schedule the workflow in a container. Since the application is containerized in Kubernetes, the steps defined in the YAML file are identical. It is also one of the most used templates.</li>
</ol>
</div>


<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);"><span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;">#source: https://argoproj.github.io/argo-workflows/workflow-concepts/</span>
- name: whalesay
    container:
      image: docker/whalesay
      command: [cowsay]
      args: [<span class="hljs-string" style="color: rgb(221, 17, 68);">"hello world"</span>]</pre>


<div class="custom-point-list">
<ol start="2">
<li><strong>Script</strong>: If you want a wrapper around a container, then the script template is perfect. The script template is similar in structure to the container template but adds a source field. The field allows you to define a script in place. You can define any variable or command based on your requirements. Once defined, the script will be saved into a file, and it will be executed for you as an Argo variable.</li>
</ol>
</div>


<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);"><span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;">#source: https://argoproj.github.io/argo-workflows/workflow-concepts/</span>
 - name: gen-random-int
    script:
      image: python:alpine3<span class="hljs-number" style="color: teal;">.6</span>
      command: [python]
      source: <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">import</span> random
       
        	i = random.randint(<span class="hljs-number" style="color: teal;">1</span>, <span class="hljs-number" style="color: teal;">100</span>)
        	  	print(i)
</pre>


<div class="custom-point-list">
<ol start="3">
<li><strong>Resource</strong>: It allows you to perform operations like get, create, apply, delete et cetera on the K8 cluster directly.</li>
</ol>
</div>


<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);"><span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;">#source: https://argoproj.github.io/argo-workflows/workflow-concepts/</span>
- name: k8s-owner-reference
    resource:
      action: create
      manifest: |
        apiVersion: v1
        kind: ConfigMap
        metadata:
          generateName: owned-eg-
        data:
          some: value</pre>


<div class="custom-point-list">
<ol start="4">
<li><strong>Suspend</strong>: It basically introduces a time dimension to the workflow. It can suspend the execution of the workflow for a defined duration or till the workflow is resumed manually.&nbsp;</li>
</ol>
</div>


<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);"><span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;">#source: https://argoproj.github.io/argo-workflows/workflow-concepts/ </span>
 - name: delay
    suspend:
      duration: <span class="hljs-string" style="color: rgb(221, 17, 68);">"20s"</span></pre>



<h5>Invocators</h5>



<p>Once the templates are defined, they can be invoked or called on demand by other templates called invocators. These invocators are more of controllers templates that can control the execution of defined templates.&nbsp;</p>



<p>There are two types of invocator templates:</p>


<div class="custom-point-list">
<ol>
<li><strong>Steps: </strong>It basically allows you to define the tasks in steps. All YAML files are enabled with the ‘steps’ template.&nbsp;</li>



<li><strong>Directed acyclic graph</strong>: Argo enables its users to manage steps with multiple dependencies in their workflow. This allows parallel execution of different workflows in their respective containers. These types of workflows are managed using a directed acyclic graph or DAG. For instance, if you are working on image segmentation and generation for medical purposes then you can create a pipeline that:<div class="custom-point-list">
<ul>
<li>Processes the images.</li>



<li>Distributes the images (or dataset) to the respective DL models for image segmentation and generation pipeline.</li>



<li>Continuously predicts segmentation masks and updates the dataset storage with new images after proper inspection.&nbsp;</li>
</ul>
</div></li>
</ol>
</div>


<h3>Airflow</h3>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img data-attachment-id="72254" data-permalink="https://neptune.ai/argo-vs-airflow-vs-prefect-3" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/argo-vs-airflow-vs-prefect-3.png?fit=1036%2C331&amp;ssl=1" data-orig-size="1036,331" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="argo-vs-airflow-vs-prefect-3" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/argo-vs-airflow-vs-prefect-3.png?fit=300%2C96&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/argo-vs-airflow-vs-prefect-3.png?fit=1024%2C327&amp;ssl=1" decoding="async" width="1024" height="327" src="https://i0.wp.com/neptune.ai/wp-content/uploads/argo-vs-airflow-vs-prefect-3.png?resize=1024%2C327&#038;ssl=1" alt="Feature Pipeline- Airflow" class="wp-image-72254" data-recalc-dims="1"/><figcaption class="wp-element-caption"><em>Feature Pipeline | <a href="https://towardsdatascience.com/mlops-with-a-feature-store-816cfa5966e9" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>

<div id="block_4e3b4877214e5a7513f2a72872ccbe27" class="separator separator-10"></div>



<p>Apache Airflow consists of four main components:</p>


<div class="custom-point-list">
<ol>
<li>Webserver</li>



<li>Scheduler</li>



<li>Executor</li>



<li>Database</li>
</ol>
</div>

<div class="wp-block-image">
<figure class="aligncenter size-full is-resized"><img data-attachment-id="72255" data-permalink="https://neptune.ai/argo-vs-airflow-vs-prefect-4" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/argo-vs-airflow-vs-prefect-4.png?fit=744%2C484&amp;ssl=1" data-orig-size="744,484" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="argo-vs-airflow-vs-prefect-4" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/argo-vs-airflow-vs-prefect-4.png?fit=300%2C195&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/argo-vs-airflow-vs-prefect-4.png?fit=744%2C484&amp;ssl=1" decoding="async" src="https://i0.wp.com/neptune.ai/wp-content/uploads/argo-vs-airflow-vs-prefect-4.png?resize=744%2C484&#038;ssl=1" alt="Main components of Apache Airflow" class="wp-image-72255" width="744" height="484" data-recalc-dims="1" /><figcaption class="wp-element-caption"><em> Four main components of Apache Airflow | <a href="https://airflow.apache.org/docs/apache-airflow/stable/concepts/overview.html" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>


<h3>Webserver</h3>



<p>It provides the user with UI for inspecting, triggering, and debugging all DAGs and tasks. It essentially serves as the entry point for Airflow. The Webserver leverages Python-Flask to manage all the requests made by the user. It also renders the state metadata from the database and displays the same to the UI.</p>



<h3>Scheduler</h3>



<p>It monitors and manages all the tasks and DAGs. It examines the state of the tasks by querying the database to decide the order of the task that needs to be executed. The aim of the scheduler is then to resolve dependencies and submit the task instance to the executor once the dependencies are taken care of.</p>



<h3>Executor</h3>



<p>It runs the task instances which are ready to run. It executes all the tasks as scheduled by the scheduler. There are four types of executors:</p>


<div class="custom-point-list">
<ol>
<li>Sequential Executor</li>



<li>Local Executor</li>



<li>Celery Executor</li>



<li>Kubernetes Executor</li>
</ol>
</div>


<h3>Metadata Database</h3>



<p>It stores the state of the tasks and DAGs that can be used by the scheduler for proper scheduling of the tasks instance. It is worth noting that Airflow uses SQLAlchemy and Object Relational Mapping (ORM) to store the information.&nbsp;</p>



<h3>Prefect</h3>



<p>Prefect uses two core concepts:&nbsp;</p>


<div class="custom-point-list">
<ol>
<li>Flows</li>



<li>Tasks</li>
</ol>
</div>


<h4>Flows</h4>



<p>In Prefect, flows are the Python objects that can be interacted with. Here DAG is defined as flow objects. See the image below.&nbsp;</p>


<div id="block_a590483c437b08259999f8b6675fb640" class="separator separator-15"></div>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img data-attachment-id="72256" data-permalink="https://neptune.ai/argo-vs-airflow-vs-prefect-5" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/argo-vs-airflow-vs-prefect-5.png?fit=1600%2C269&amp;ssl=1" data-orig-size="1600,269" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="argo-vs-airflow-vs-prefect-5" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/argo-vs-airflow-vs-prefect-5.png?fit=300%2C50&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/argo-vs-airflow-vs-prefect-5.png?fit=1024%2C172&amp;ssl=1" decoding="async" width="1024" height="172" src="https://i0.wp.com/neptune.ai/wp-content/uploads/argo-vs-airflow-vs-prefect-5.png?resize=1024%2C172&#038;ssl=1" alt="DAG defined as flow objects " class="wp-image-72256" data-recalc-dims="1"/><figcaption class="wp-element-caption"><em> DAG defined as flow objects | <a href="https://spell.ml/blog/orchestrating-spell-model-pipelines-using-prefect-YU3rsBEAACEAmRxp" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>

<div id="block_f234d26439284ef4f7d43b9cdaa2d453" class="separator separator-5"></div>



<p>Flow can be imported and can be used as a decorator, @flow, for any given function. Flows take an existing function and transform it into a Prefect flow function, with the following advantages:</p>


<div class="custom-point-list">
<ul>
<li>The function can be monitored and governed as it is now reported to the API.</li>



<li>The activity of the function can be tracked and displayed in the UI.</li>



<li>Inputs given to the function can be validated.</li>



<li>Various workflow features like retries, distributed execution et cetera can be added to the function.<em>&nbsp;</em></li>



<li>Timeouts can be enforced to prevent unintentional long-running workflows&nbsp;</li>
</ul>
</div>


<p>Here is a code block depicting the implementation of a flow object.</p>



<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);"><span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;">#Source: https://github.com/PrefectHQ/prefect</span>
<span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">from</span> prefect <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">import</span> flow

<span class="hljs-meta" style="font-weight: 700; color: rgb(153, 153, 153);">@flow(name="GitHub Stars")</span>
<span class="hljs-function"><span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">def</span> <span class="hljs-title" style="color: rgb(153, 0, 0); font-weight: 700;">github_stars</span><span class="hljs-params">(repos: List[str])</span>:</span>
    <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">for</span> repo <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">in</span> repos:
        get_stars(repo)
</pre>



<p>In the code above, the function has been transformed into a flow which is named as “GitHub Stars”. This function is now within the constraints of Prefect orchestration laws.&nbsp;</p>



<p>Now it must be noted that all workflows must be defined within the flow function. Likewise, all tasks must be called within the flow (function). Keep in mind that when a flow is executed, it is known as a <em>flow run</em>.&nbsp;</p>



<h5>Tasks</h5>



<p>Tasks can be defined as specific work that needs to be executed, for instance, the addition of two numbers. In another word, tasks take an input, perform an operation and yield an output. Like flow, tasks can be imported and can be used as a decorator, @task, for a function. Once used for a function, it essentially wraps the function within the Prefect workflow and has similar advantages to the flow. For instance, it can automatically log information about task runs, such as runtime, tags, and final state.&nbsp;</p>



<p>The code below demonstrates how a task is defined:&nbsp;</p>



<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);"><span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;">#Source: https://github.com/PrefectHQ/prefect</span>

<span class="hljs-meta" style="font-weight: 700; color: rgb(153, 153, 153);">@task(retries=3)</span>
<span class="hljs-function"><span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">def</span> <span class="hljs-title" style="color: rgb(153, 0, 0); font-weight: 700;">get_stars</span><span class="hljs-params">(repo: str)</span>:</span>
    url = f<span class="hljs-string" style="color: rgb(221, 17, 68);">"https://api.github.com/repos/{repo}"</span>
    count = httpx.get(url).json()[<span class="hljs-string" style="color: rgb(221, 17, 68);">"stargazers_count"</span>]
    print(f<span class="hljs-string" style="color: rgb(221, 17, 68);">"{repo} has {count} stars!"</span>)

<span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># run the flow!</span>
github_stars([<span class="hljs-string" style="color: rgb(221, 17, 68);">"PrefectHQ/Prefect"</span>])</pre>



<p>To sum up, the flow looks for any task that is defined within its body, and once found it then creates a computational graph in the same order. It then creates dependencies between the tasks whenever the output of one task instance is used to yield output by another.&nbsp;</p>



<h2>Features</h2>



<p>All three provide more or less the same features, but some features are better than others, and it also boils down to users&#8217; adaptability. Just like in the previous section, let’s begin with a summary of the features.&nbsp;</p>


<div class="medium-table">
        <div class="mt-row heading">
            <div class="mt-col" style="width: 15%">
                    </div>
            <div class="mt-col" style="width: 28.33%">
            Argo        </div>
            <div class="mt-col" style="width: 28.33%">
            Airflow        </div>
            <div class="mt-col" style="width: 28.33%">
            Prefect        </div>
        </div>
    
            <div class="mt-row">
                            <div class="mt-col" style="width: 15%">
                                                                <p><strong>User Interface</strong></p>
                                    </div>
                            <div class="mt-col" style="width: 28.33%">
                                        <span class="column-name">
                        Argo:
                    </span>
                                                                <p>It has a complete view of the workflow. You can define workflow straight from the UI.</p>
                                    </div>
                            <div class="mt-col" style="width: 28.33%">
                                        <span class="column-name">
                        Airflow:
                    </span>
                                                                <p>Workflow is very well-maintained as it provides a number of different views.</p>
                                    </div>
                            <div class="mt-col" style="width: 28.33%">
                                        <span class="column-name">
                        Prefect:
                    </span>
                                                                <p>Prefect is similar to Airflow.</p>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 15%">
                                                                <p><strong>Deployment Style </strong></p>
                                    </div>
                            <div class="mt-col" style="width: 28.33%">
                                        <span class="column-name">
                        Argo:
                    </span>
                                                                <p>Supports only Kubernetes-supported environments such as AWS and other S3-compatible services.</p>
                                    </div>
                            <div class="mt-col" style="width: 28.33%">
                                        <span class="column-name">
                        Airflow:
                    </span>
                                                                <p>Supports Kubernetes-supported environment as well as other third-party environments.</p>
                                    </div>
                            <div class="mt-col" style="width: 28.33%">
                                        <span class="column-name">
                        Prefect:
                    </span>
                                                                <p>Same as Airflow</p>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 15%">
                                                                <p><strong>Scalability</strong></p>
                                    </div>
                            <div class="mt-col" style="width: 28.33%">
                                        <span class="column-name">
                        Argo:
                    </span>
                                                                <p>Parallel</p>
                                    </div>
                            <div class="mt-col" style="width: 28.33%">
                                        <span class="column-name">
                        Airflow:
                    </span>
                                                                <p>Horizontal</p>
                                    </div>
                            <div class="mt-col" style="width: 28.33%">
                                        <span class="column-name">
                        Prefect:
                    </span>
                                                                <p>Parallel</p>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 15%">
                                                                <p><strong>Accessibility</strong></p>
                                    </div>
                            <div class="mt-col" style="width: 28.33%">
                                        <span class="column-name">
                        Argo:
                    </span>
                                                                <p>Open-sourced</p>
                                    </div>
                            <div class="mt-col" style="width: 28.33%">
                                        <span class="column-name">
                        Airflow:
                    </span>
                                                                <p>Open-source</p>
                                    </div>
                            <div class="mt-col" style="width: 28.33%">
                                        <span class="column-name">
                        Prefect:
                    </span>
                                                                <p>Open-sourced and subscription-based</p>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 15%">
                                                                <p><strong>Flexibility</strong></p>
                                    </div>
                            <div class="mt-col" style="width: 28.33%">
                                        <span class="column-name">
                        Argo:
                    </span>
                                                                <p>Rigid</p>
                                    </div>
                            <div class="mt-col" style="width: 28.33%">
                                        <span class="column-name">
                        Airflow:
                    </span>
                                                                <p>Rigid and Complicated</p>
                                    </div>
                            <div class="mt-col" style="width: 28.33%">
                                        <span class="column-name">
                        Prefect:
                    </span>
                                                                <p>Flexible</p>
                                    </div>
                    </div>
    </div>



<p class="has-text-align-center has-small-font-size"><em>Comparison of the features</em></p>



<p>Let’s start this section by exploring the User Interface.&nbsp;</p>



<h3>User Interface</h3>



<h4>Argo</h4>



<p>For ease of use, Argo Workflow provides a web-based UI to define workflows and templates. The UI enables various purposes like:</p>


<div class="custom-point-list">
<ul>
<li>Artifact visualization&nbsp;</li>



<li>Using generated charts to compare Machine Learning pipelines</li>



<li>Visualizing results&nbsp;</li>



<li>Debugging</li>



<li>It can also be used to define workflows</li>
</ul>
</div>

<div id="block_4e3b4877214e5a7513f2a72872ccbe27" class="separator separator-10"></div>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img data-attachment-id="72257" data-permalink="https://neptune.ai/argo-vs-airflow-vs-prefect-6" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/argo-vs-airflow-vs-prefect-6.png?fit=1276%2C751&amp;ssl=1" data-orig-size="1276,751" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="argo-vs-airflow-vs-prefect-6" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/argo-vs-airflow-vs-prefect-6.png?fit=300%2C177&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/argo-vs-airflow-vs-prefect-6.png?fit=1024%2C603&amp;ssl=1" decoding="async" width="1024" height="603" src="https://i0.wp.com/neptune.ai/wp-content/uploads/argo-vs-airflow-vs-prefect-6.png?resize=1024%2C603&#038;ssl=1" alt="Argo user interface" class="wp-image-72257" data-recalc-dims="1"/><figcaption class="wp-element-caption"><em>Argo UI | <a href="https://github.com/argoproj/argo-workflows" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>


<h4>Airflow</h4>



<p>Airflow UI provides a clean and efficient design that enables the user to interact with the Airflow server allowing them to <strong>monitor</strong> and <strong>troubleshoot</strong> the entire pipeline. It also allows editing the state of the task in the database and manipulating the behaviour of DAGs and tasks.&nbsp;</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img data-attachment-id="72258" data-permalink="https://neptune.ai/argo-vs-airflow-vs-prefect-7" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/argo-vs-airflow-vs-prefect-7.png?fit=1999%2C1203&amp;ssl=1" data-orig-size="1999,1203" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="argo-vs-airflow-vs-prefect-7" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/argo-vs-airflow-vs-prefect-7.png?fit=300%2C181&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/argo-vs-airflow-vs-prefect-7.png?fit=1024%2C616&amp;ssl=1" decoding="async" width="1024" height="616" src="https://i0.wp.com/neptune.ai/wp-content/uploads/argo-vs-airflow-vs-prefect-7.png?resize=1024%2C616&#038;ssl=1" alt="Airflow user interface" class="wp-image-72258" data-recalc-dims="1"/><figcaption class="wp-element-caption"><em>Airflow UI | <a href="https://airflow.apache.org/docs/apache-airflow/stable/ui.html#" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>


<p>The Airflow UI also provides various views for its users, they include:</p>


<div class="custom-point-list">
<ul>
<li>DAGs View</li>



<li>Datasets View</li>



<li>Grid View</li>



<li>Graph View</li>



<li>Calendar View</li>



<li>Variable View</li>



<li>Gantt View</li>



<li>Task Duration</li>



<li>Code View</li>
</ul>
</div>


<h4>Prefect</h4>



<p>Prefect like Airflow provides an overview of all the tasks, which helps you visualize all your workflow, tasks, and DAGs. It provides two ways to access UI:</p>


<div class="custom-point-list">
<ol>
<li><strong>Prefect Cloud</strong>: It is hosted on the cloud, which enables you to configure your personal accounts and workspaces.&nbsp;</li>



<li><strong>Prefect Orion UI</strong>: It is hosted locally, and it is also open-sourced. You cannot configure it the way you can with Prefect cloud.&nbsp;</li>
</ol>
</div>

<div class="wp-block-image">
<figure class="aligncenter size-large"><img data-attachment-id="72259" data-permalink="https://neptune.ai/argo-vs-airflow-vs-prefect-8" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/argo-vs-airflow-vs-prefect-8.png?fit=1280%2C552&amp;ssl=1" data-orig-size="1280,552" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="argo-vs-airflow-vs-prefect-8" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/argo-vs-airflow-vs-prefect-8.png?fit=300%2C129&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/argo-vs-airflow-vs-prefect-8.png?fit=1024%2C442&amp;ssl=1" decoding="async" width="1024" height="442" src="https://i0.wp.com/neptune.ai/wp-content/uploads/argo-vs-airflow-vs-prefect-8.png?resize=1024%2C442&#038;ssl=1" alt="Prefect user interface" class="wp-image-72259" data-recalc-dims="1"/><figcaption class="wp-element-caption"><em>Prefect UI | <a href="https://docs.prefect.io/ui/overview/" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>


<p>Some additional features of Prefect UI:</p>


<div class="custom-point-list">
<ul>
<li>Displaying run summaries</li>



<li>Displaying flow details that are deployed</li>



<li>Scheduled flow&nbsp;</li>



<li>Warnings notification for late and failed runs</li>



<li>Details information of tasks and workflows</li>



<li>Task dependency visualization and Radar flow</li>



<li>Logs details</li>
</ul>
</div>


<h3>Deployment Style</h3>



<h4>Argo</h4>



<p>It is a native Kubernetes workflow engine which means it:</p>


<div class="case-study-numbered-list">
    <h2></h2>
    <ul>
                    <li><span>1</span>Runs on containers.</li>
                    <li><span>2</span>Runs on Kubernetes-supported pods.</li>
                    <li><span>3</span>Easy to deploy and scale.</li>
            </ul>
</div>



<p>On the downside:</p>


<div class="custom-point-list">
<ul>
<li>Implementation is hard since it uses configurational language (YAML).</li>
</ul>
</div>


<h4>Airflow</h4>


<div class="case-study-numbered-list">
    <h2></h2>
    <ul>
                    <li><span>1</span>Supports Kubernetes as well as other third–party integrations.</li>
                    <li><span>2</span>It runs on containers as well. </li>
                    <li><span>3</span>Implementation is easy.</li>
            </ul>
</div>



<p>The downside of Airflow is:</p>


<div class="custom-point-list">
<ul>
<li>It is not parallel scalable.</li>



<li>Deployment needs extra effort, which depends upon the cloud facility you choose.&nbsp;</li>
</ul>
</div>


<h4>Prefect</h4>



<p>Lastly, Prefect is a combination of both Argo and Airflow:</p>


<div class="case-study-numbered-list">
    <h2></h2>
    <ul>
                    <li><span>1</span>It can run on Containers and Kubernetes pods.</li>
                    <li><span>2</span>It is highly parallel and efficient.</li>
                    <li><span>3</span>It supports fault-tolerant scheduling.</li>
                    <li><span>4</span>Easy to deploy.</li>
                    <li><span>5</span>It also supports third-party integrations.</li>
            </ul>
</div>



<p>When it comes to the downside:</p>


<div class="custom-point-list">
<ul>
<li>It does not support open-source deployment with Kubernetes.&nbsp;</li>



<li>Deployment is difficult.&nbsp;</li>
</ul>
</div>


<h3>Scalability</h3>



<p>When it comes to scalability, Argo and Prefect are highly parallel, which makes them efficient and especially Prefect because it can leverage different third-party integrations support, making it the best of the three.&nbsp;</p>



<p>Airflow, on the other, is horizontally scalable i.e., the number of active workers is equal to maximum task parallelism.&nbsp;</p>



<h3>Accessibility</h3>



<p>All three are open-sourced, but Prefect also comes with a <a href="https://www.prefect.io/pricing/" target="_blank" rel="noreferrer noopener nofollow">subscription-based</a> service.&nbsp;</p>



<h3>Flexibility</h3>



<p>Argo and Airflow aren’t that flexible when compared with Prefect as the former is Kubernetes-native it is confined in that environment, making it rigid, while the latter is complicated as it requires a well-defined and structured template, making itself not very well suited to an agile environment.&nbsp;</p>



<p>Prefect, on the other hand, enables you to create dynamic dataflow in native Python, which does not require you to use DAG. All Python functions can be transformed to Prefect Flow and Task. This ensures flexibility.</p>



<h2>Why use these tools?</h2>



<p>So far, I’ve compared the basic concepts and features that these tools possess. Now let me give reasons as to why you can use any of these tools in your project.&nbsp;&nbsp;</p>



<h3>Argo</h3>



<p>Here are some of the reasons why you should use Argo:</p>


<div class="case-study-numbered-list">
    <h2></h2>
    <ul>
                    <li><span>1</span>The Kubernetes native workflow tool enables you to run each step in its own Kubernetes pod.</li>
                    <li><span>2</span>Easy to scale because it can be executed parallelly. </li>
                    <li><span>3</span>Workflow templates offer reusability.</li>
                    <li><span>4</span>Similarly, artifact integrations are also reusable. </li>
                    <li><span>5</span>DAG is dynamic for each run of the workflow. </li>
                    <li><span>6</span>Low Latency Scheduler.</li>
                    <li><span>7</span>Event-Driven Workflows.</li>
            </ul>
</div>



<h3>Airflow</h3>



<p>Reasons for you to use Airflow:</p>


<div class="case-study-numbered-list">
    <h2></h2>
    <ul>
                    <li><span>1</span>It enables users to connect with various technologies.</li>
                    <li><span>2</span>It offers rich scheduling and easy-to-define pipelines. </li>
                    <li><span>3</span>Pythonic integration is another reason to use Airflow. </li>
                    <li><span>4</span>You can create custom components as per your requirements.</li>
                    <li><span>5</span>Allows rollback to the previous version as workflows are stored.</li>
                    <li><span>6</span>Has a well-defined UI.</li>
                    <li><span>7</span>Multiple users can write a workflow for a given project, i.e. it is shareable. </li>
            </ul>
</div>



<h3>Prefect</h3>



<p>Prefect is one of the well-planned orchestration tools for MLops. It is Python-native and requires you to put effort into the engineering side of things. One of the areas where Prefect shines is in data processing and pipeline. It can be used to fetch the data, apply the necessary transformation, and monitor and orchestrate necessary tasks.</p>



<p>When it comes to tasks related to machine learning, it can be used to automate the entire data flow.&nbsp;</p>



<p>Some other reasons to use Prefect are:</p>


<div class="case-study-numbered-list">
    <h2></h2>
    <ul>
                    <li><span>1</span>Provides excellent security as it keeps your data and codes private.  </li>
                    <li><span>2</span>Enhanced UI and notification feature which directly comes to your email or Slack.</li>
                    <li><span>3</span>It can be used with Kubernetes and Docker. </li>
                    <li><span>4</span>Efficient parallel processing of tasks.</li>
                    <li><span>5</span>Dynamic workflow.</li>
                    <li><span>6</span>Allows many third-party integrations.</li>
                    <li><span>7</span>Prefect uses GraphQL API, enabling it to trigger workflow on demand. </li>
            </ul>
</div>



<h2>How to decide?</h2>



<p>Choosing the right tool for your project depends on what you want and what you already have. But I can surely put some criteria that can help you decide which tool will be appropriate for you. You can use –</p>



<h3>Argo</h3>


<div class="custom-point-list">
<ul>
<li>If you want to set up a workflow based on Kubernetes.</li>



<li>If you want to define your workflow as DAGs.</li>



<li>If your dataset is huge and model training requires highly parallel and distributed training.&nbsp;</li>



<li>If your task is complex.</li>



<li>If you are well-versed in YAML files. Even if you are not, learning YAML is not difficult.</li>



<li>If you want to use a cloud platform like GCD or AWS, which is Kubernetes enabled.&nbsp;</li>
</ul>
</div>


<h3>Airflow</h3>


<div class="custom-point-list">
<ul>
<li>If you want to incorporate a lot of other 3rd party technology like Jenkins, Airbyte, Amazon, Cassandra, Docker, et cetera. Check the <a href="https://airflow.apache.org/docs/apache-airflow-providers/core-extensions/index.html" target="_blank" rel="noreferrer noopener nofollow">list of supported third-party extensions</a>.</li>



<li>If you want to use Python to define the workflow.</li>



<li>If you want to define your workflow as DAGs.</li>



<li>If your workflow is static.</li>



<li>If you want a mature tool because Airflow is quite old.&nbsp;</li>



<li>If you want to run tasks on schedule.</li>
</ul>
</div>


<h3>Prefect</h3>


<div class="custom-point-list">
<ul>
<li>If you want to incorporate a lot of other 3rd party technology.</li>



<li>If you want to use Python to define the workflow.</li>



<li>If your workflow is dynamic.</li>



<li>If you want to run tasks on schedule.</li>



<li>If you want something light and modern.</li>
</ul>
</div>


<p>I found a thread on <a href="https://www.reddit.com/r/dataengineering/comments/oqbiiu/airflow_vs_prefect/" target="_blank" rel="noreferrer noopener nofollow">Reddit</a> concerning the use of Airflow and Prefect. Maybe this can give you some additional information as to which tool to use.</p>



<p>“…The pros of Airflow are that it&#8217;s an established and popular project. This means it&#8217;s much easier to find someone who has done a random blog that answers your question. Another pro is that it&#8217;s much easier to hire someone with Airflow experience than Prefect experience. The cons are that Airflow&#8217;s age is showing, in that it wasn&#8217;t really designed for the kind of<em> dynamic workflows that exist within modern data environments</em>. If your company is going to be pushing the limits in terms of <em>computation or complexity, I&#8217;d highly suggest looking at Prefect.</em> Additionally, unless you go through Astronomer, if you can&#8217;t find an answer to a question you have about Airflow, you have to go through their fairly inactive slack chat.</p>



<p>The pros of Prefect are that it&#8217;s much more modern in its assumptions about what you&#8217;re doing and what it needs to do. It has an extensive API that allows you to programmatically control executions or otherwise interact with the scheduler, which I believe Airflow has only recently implemented out of beta in their 2.0 release. Prior to this, it was recommended not to use the API in production, which often leads to hacky workarounds. In addition, Prefect allows for a much more dynamic execution model with some of its concepts by determining the DAG that gets executed at runtime and then handing off the computation/optimization to other systems (namely Dask) to actually execute the tasks. I believe this is a much smarter approach, as I&#8217;ve seen workflows get more and more dynamic over the years.</p>



<p>If my company had neither Airflow nor Prefect in place already, I&#8217;d opt for Prefect. I believe it allows for much better modularization of code (which can then be tested more aggressively / thoroughly), which I already think is worth its weight in gold for data-driven companies that rely on having well-curated data in place to make automated product decisions. You can achieve something similar with Airflow, but you really need to go out of your way to make something like that happen, whereas in Prefect it kind of naturally comes out.”&nbsp;</p>



<p>Here is a useful chart illustrating the popularity of different orchestration tools based on GitHub stars.</p>


<div id="block_1f2b87c2de136cd7e7f6f69de21adf08" class="separator separator-15"></div>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img data-attachment-id="72260" data-permalink="https://neptune.ai/argo-vs-airflow-vs-prefect-9" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/argo-vs-airflow-vs-prefect-9.png?fit=1472%2C1030&amp;ssl=1" data-orig-size="1472,1030" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="argo-vs-airflow-vs-prefect-9" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/argo-vs-airflow-vs-prefect-9.png?fit=300%2C210&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/argo-vs-airflow-vs-prefect-9.png?fit=1024%2C717&amp;ssl=1" decoding="async" width="1024" height="717" src="https://i0.wp.com/neptune.ai/wp-content/uploads/argo-vs-airflow-vs-prefect-9.png?resize=1024%2C717&#038;ssl=1" alt="Chart illustrating the popularity of different orchestration tools" class="wp-image-72260" data-recalc-dims="1"/><figcaption class="wp-element-caption"><em>The popularity of different orchestration tools based on GitHub stars | <a href="https://www.datarevenue.com/en-blog/airflow-vs-luigi-vs-argo-vs-mlflow-vs-kubeflow" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>


<h2>Conclusion</h2>



<p>In this article, we discussed and compared the three popular tools for task orchestration, namely Argo, Airflow, and Prefect. My main aim was to help you understand these tools on the basis of three important factors i.e. Core concepts, Features offered, and why you should use them. The article also compared the three tools on some of the important features they offer, which could help you make the decision of choosing the most appropriate tool for your project.</p>



<p>I hope this article was informative and gave you a better understanding of these tools.&nbsp;</p>



<p>Thanks!!!&nbsp;</p>



<h3>References</h3>


<div class="custom-point-list">
<ol>
<li><a href="https://github.com/argoproj/argo-workflows" target="_blank" rel="noreferrer noopener nofollow">https://github.com/argoproj/argo-workflows</a>&nbsp;</li>



<li><a href="https://argoproj.github.io/" target="_blank" rel="noreferrer noopener nofollow">https://argoproj.github.io/</a>&nbsp;</li>



<li><a href="https://codefresh.io/learn/argo-workflows/" target="_blank" rel="noreferrer noopener nofollow">https://codefresh.io/learn/argo-workflows/</a>&nbsp;</li>



<li><a href="https://hazelcast.com/glossary/directed-acyclic-graph/" target="_blank" rel="noreferrer noopener nofollow">https://hazelcast.com/glossary/directed-acyclic-graph/</a></li>



<li><a href="https://towardsdatascience.com/mlops-with-a-feature-store-816cfa5966e9" target="_blank" rel="noreferrer noopener nofollow">https://towardsdatascience.com/mlops-with-a-feature-store-816cfa5966e9</a>&nbsp;</li>



<li><a href="https://medium.com/arthur-engineering/picking-a-kubernetes-orchestrator-airflow-argo-and-prefect-83539ecc69b" target="_blank" rel="noreferrer noopener nofollow">https://medium.com/arthur-engineering/picking-a-kubernetes-orchestrator-airflow-argo-and-prefect-83539ecc69b</a></li>



<li><a href="https://argoproj.github.io/argo-workflows/artifact-visualization/#artifact-types" target="_blank" rel="noreferrer noopener nofollow">https://argoproj.github.io/argo-workflows/artifact-visualization/#artifact-types</a>&nbsp;</li>



<li><a href="https://airflow.apache.org/docs/apache-airflow/stable/concepts/overview.html" target="_blank" rel="noreferrer noopener nofollow">https://airflow.apache.org/docs/apache-airflow/stable/concepts/overview.html</a>&nbsp;</li>



<li><a href="https://spell.ml/blog/orchestrating-spell-model-pipelines-using-prefect-YU3rsBEAACEAmRxp" target="_blank" rel="noreferrer noopener nofollow">https://spell.ml/blog/orchestrating-spell-model-pipelines-using-prefect-YU3rsBEAACEAmRxp</a>&nbsp;</li>



<li><a href="https://github.com/PrefectHQ/prefect" target="_blank" rel="noreferrer noopener nofollow">https://github.com/PrefectHQ/prefect</a></li>



<li><a href="https://www.datarevenue.com/en-blog/airflow-vs-luigi-vs-argo-vs-mlflow-vs-kubeflow" target="_blank" rel="noreferrer noopener nofollow">https://www.datarevenue.com/en-blog/airflow-vs-luigi-vs-argo-vs-mlflow-vs-kubeflow</a>&nbsp;</li>



<li><a href="https://hevodata.com/learn/argo-vs-airflow/#w6" target="_blank" rel="noreferrer noopener nofollow">https://hevodata.com/learn/argo-vs-airflow/#w6</a>&nbsp;</li>



<li><a href="https://www.datarevenue.com/en-blog/what-we-are-loving-about-prefect" target="_blank" rel="noreferrer noopener nofollow">https://www.datarevenue.com/en-blog/what-we-are-loving-about-prefect</a>&nbsp;</li>



<li><a href="https://github.com/PrefectHQ/prefect" target="_blank" rel="noreferrer noopener nofollow">https://github.com/PrefectHQ/prefect</a>&nbsp;</li>



<li><a href="https://docs.prefect.io/" target="_blank" rel="noreferrer noopener nofollow">https://docs.prefect.io/</a>&nbsp;</li>



<li><a href="https://medium.com/the-prefect-blog/introducing-the-artifacts-api-b9e5972db043" target="_blank" rel="noreferrer noopener nofollow">https://medium.com/the-prefect-blog/introducing-the-artifacts-api-b9e5972db043</a>&nbsp;</li>



<li><a href="https://medium.com/the-prefect-blog/orchestrate-your-data-science-project-with-prefect-2-0-4118418fd7ce" target="_blank" rel="noreferrer noopener nofollow">https://medium.com/the-prefect-blog/orchestrate-your-data-science-project-with-prefect-2-0-4118418fd7ce</a>&nbsp;</li>



<li><a href="https://www.reddit.com/r/dataengineering/comments/oqbiiu/airflow_vs_prefect/" target="_blank" rel="noreferrer noopener nofollow">https://www.reddit.com/r/dataengineering/comments/oqbiiu/airflow_vs_prefect/</a></li>
</ol>
</div>



<div id="author-box-new-format-block_604218f9077b8" class="article__footer article__author">
  <div class="article__authorImage">
          <img width="193" height="193" src="https://i0.wp.com/neptune.ai/wp-content/uploads/Nilesh-Barla.png?fit=193%2C193&amp;ssl=1" class="article__authorImage-img" alt="Nilesh Barla" decoding="async" data-attachment-id="35510" data-permalink="https://neptune.ai/blog/representation-learning-with-autoencoder/attachment/nilesh-barla" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Nilesh-Barla.png?fit=193%2C193&amp;ssl=1" data-orig-size="193,193" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Nilesh Barla" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Nilesh-Barla.png?fit=193%2C193&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Nilesh-Barla.png?fit=193%2C193&amp;ssl=1" />      </div>

  <div class="article__authorContent">
          <h3 class="article__authorContent-name">Nilesh Barla</h3>
    
          <p class="article__authorContent-text">I am the founder of a recent startup perceptronai.net which aims to provide solutions in medical and material science through our deep learning algorithms. I also read and think a lot. And sometimes I put them in a form of a painting or a piece of music. And when I need to catch a breath I go for a run.</p>
    
          <ul class="article__authorSocial">
        <li class="article__authorSocial-single article__authorSocial-name">Follow me on</li>
                  <li class="article__authorSocial-single"><a href="https://twitter.com/nielspace07" class="article__authorSocial-tw" target="_blank"></a></li>
        
                  <li class="article__authorSocial-single"><a href="https://www.linkedin.com/in/nielspace/?originalSubdomain=in" class="article__authorSocial-lk" target="_blank"></a></li>
        
              </ul>
    
  </div>
</div>


<div class="is-layout-flow wp-block-group"><div class="wp-block-group__inner-container">
<hr class="wp-block-separator has-css-opacity"/>



<p class="has-text-color" style="color:#4455a6"><strong>READ NEXT</strong></p>



<h2>MLOps: What It Is, Why it Matters, and How To Implement It</h2>



<p class="has-small-font-size">13 mins read | Prince Canuma | Posted January 14, 2021</p>


<div id="block_5ffc75def9f8e" class="separator separator-10"></div>



<p>According to techjury, every person created at least 1.7 MB of data per second in 2020. For data scientists like you and me, that is like early Christmas because there are so many theories/ideas to explore, experiment with, and many discoveries to be made and models to be developed. </p>



<p>But if we want to be serious and actually have those models touch real-life business problems and real people, we have to deal with the essentials like:</p>


<div class="custom-point-list">
<ul><li>acquiring &amp; cleaning large amounts of data;</li><li>setting up tracking and versioning for experiments and model training runs;</li><li>setting up the deployment and monitoring pipelines for the models that do get to production.&nbsp;</li></ul>
</div>


<p>And we need to find a way to scale our ML operations to the needs of the business and/or users of our ML models.</p>



<p>There were similar issues in the past when we needed to scale conventional software systems so that more people can use them. DevOps’ solution was a set of practices for developing, testing, deploying, and operating large-scale software systems. With DevOps, development cycles became shorter, deployment velocity increased, and system releases became auditable and dependable.</p>



<p>That brings us to&nbsp;<strong>MLOps</strong>. It was born at the intersection of&nbsp;<strong>DevOps</strong>,&nbsp;<strong>Data Engineering,</strong>&nbsp;and&nbsp;<strong>Machine Learning</strong>, and it’s a similar concept to DevOps<strong>,&nbsp;</strong>but the execution is different. ML systems are experimental in nature and have more components that are significantly more complex to build and operate.</p>



<p>Let’s dig in!</p>


<a class="button continous-post blue-filled" href="/blog/mlops" target="_blank">
    Continue reading -&gt;</a>



<hr class="wp-block-separator has-css-opacity"/>
</div></div>
<p>The post <a rel="nofollow" href="https://neptune.ai/blog/argo-vs-airflow-vs-prefect-differences">Argo vs Airflow vs Prefect: How Are They Different</a> appeared first on <a rel="nofollow" href="https://neptune.ai">neptune.ai</a>.</p>
]]></content:encoded>
					
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">72250</post-id>	</item>
		<item>
		<title>Good Design in ML Applications With Konrad Piercey</title>
		<link>https://neptune.ai/blog/good-design-machine-learning</link>
		
		<dc:creator><![CDATA[Patrycja Jenkner]]></dc:creator>
		<pubDate>Thu, 27 Oct 2022 06:57:43 +0000</pubDate>
				<category><![CDATA[General]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[mlops]]></category>
		<guid isPermaLink="false">https://neptune.ai/?p=72133</guid>

					<description><![CDATA[<p>Some time ago, Konrad Piercey, a Lead Product Designer at Delivery Hero, was one of the speakers on the MLOps Community meetup in Berlin. He talked about good design in ML applications &#8211; why it’s a growing topic, what it actually means and how to start implementing it.&#160; And we thought that it’s a very [&#8230;]</p>
<p>The post <a rel="nofollow" href="https://neptune.ai/blog/good-design-machine-learning">Good Design in ML Applications With Konrad Piercey</a> appeared first on <a rel="nofollow" href="https://neptune.ai">neptune.ai</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<p>Some time ago, Konrad Piercey, a Lead Product Designer at Delivery Hero, was one of the speakers on the MLOps Community meetup in Berlin. He talked about good design in ML applications &#8211; why it’s a growing topic, what it actually means and how to start implementing it.&nbsp;</p>



<p>And we thought that it’s a very interesting topic that we definitely want to learn more about. So we sat down with Konrad and asked him a few(ish) questions. Here’s the effect of our conversation!&nbsp;</p>



<p>By the way, MLOps Meetups happen more and more often in different cities around the world. If you’re interested, you should <a href="https://www.meetup.com/pro/mlops-community/" target="_blank" rel="noreferrer noopener nofollow">check the MLOps Community schedule here</a>. Maybe there’s a meeting happening in your city soon! You can also organize one &#8211; <a href="https://go.mlops.community/slack" target="_blank" rel="noreferrer noopener nofollow">join the MLOps Community slack channel</a> if you’re interested!&nbsp;&nbsp;</p>



<p>Okay, now, we can really talk about design in ML.&nbsp;</p>



<h2>What is (good) design/UX for ML?</h2>



<p><strong>Patrycja</strong>: Let&#8217;s start from the basics. What is design/UX for ML? Is it anything specific for ML, or is it just the usual design? And why do you think it&#8217;s important to talk about it in the context of ML?&nbsp;</p>



<p><strong>Konrad: </strong>The idea here is that a design for machine learning isn&#8217;t really an existing field. There are no machine learning designers, there are machine learning and data science engineers out there. Then there are product designers and UX/UI designers and then may contribute in some way to some elements of machine learning. But if they do, it is a very small part of the larger initiative of how machine learning is integrated into a product.</p>



<blockquote class="wp-block-quote">
<p><strong><em>The main goal of the machine learning design is to help create a better experience and a better relationship between the machine and the user.</em></strong></p>
</blockquote>



<p>How do we do it? By revealing what&#8217;s behind the curtain and how the system is operating.&nbsp;</p>



<p>Because machine learning, from its early principles, is something that happens in the background. You don&#8217;t see what&#8217;s happening when it&#8217;s doing a number of calculations, building some models, and producing some output.&nbsp;</p>


<div class="custom-point-list">
<ul>
<li>You don&#8217;t see how that&#8217;s working.</li>



<li>You also don&#8217;t see how you&#8217;re affecting the model generally.&nbsp;</li>
</ul>
</div>


<p>And machine learning design is taking some fundamentals of UX/UI and applying that to the bigger product strategy behind how a company or product wants to integrate machine learning.&nbsp;</p>



<p>So you take UX/UI and machine learning and add those two together.&nbsp;</p>



<p>And I think if you were to ask a general person in tech what is machine learning design, they&#8217;re probably not going to mention many things that relate to the user interface, and that&#8217;s where I&#8217;m hoping to change the current industry outlook.</p>



<h3>Why good design in ML apps is important?</h3>



<p><strong>Patrycja</strong>: And why do you think it&#8217;s important? Why do you think users have to have this good experience with ML apps instead of just getting the results of the model?</p>



<p><strong>Konrad</strong>: Well, first, I think we should state the obvious, that machine learning is fascinating and it&#8217;s amazing. Some of the greatest machine learning integrations people don&#8217;t even realize. Forget the future where machine learning is going to be most of our digital products.&nbsp;</p>


<div class="custom-point-list">
<ul>
<li>Take driverless cars, for instance. Driverless cars won&#8217;t ever exist without machine learning.&nbsp;</li>



<li>But even more basic machine learning at the consumer level is your auto-correct on your phone. That uses ML to ensure that it’s suggesting the proper correction or proper next word.&nbsp;&nbsp;</li>



<li>My favorite example, though, is the email spam filter. Your email spam filter would never exist without machine learning. All those lovely emails saying you&#8217;ve won the lottery would go right to the top of your email inbox without machine learning.&nbsp;</li>
</ul>
</div>


<p>So there are different levels of integration of these. Why it&#8217;s exciting and why we need to look at it now is because machine learning is starting to integrate into more personalized experiences that really define cooperation with a product or service. You can take most large consumer applications, and they use machine learning in some way.&nbsp;</p>



<blockquote class="wp-block-quote">
<p><strong><em>Whether that&#8217;s Amazon, Facebook, YouTube, or Netflix, all of these use machine learning in order to either drive engagement or sales. And so, it&#8217;s important for users to understand how their interaction with the system is affecting their product experience.</em></strong></p>
</blockquote>



<h3>Is “good design for ML” a new thing?</h3>



<p><strong>Patrycja</strong>: Do you see this need being noticed by the business? Is it something completely new, or do people already think, “okay, we need to design it in a way that people have this good experience”?</p>



<p><strong>Konrad</strong>: I think it&#8217;s not totally new that data scientists and product designers try to be cautious with how they integrate and launch ML properties into their products or application. But it&#8217;s definitely not thought of at the depth at which it needs to be considered because the implications of machine learning now can affect things at an immense scale, like the critical infrastructure of electoral voting systems or moving the needle on nationwide obesity epidemics.</p>



<blockquote class="wp-block-quote">
<p><strong><em>This is stuff that machine learning now affects. We&#8217;re not just talking about your email inbox spam filter anymore. We&#8217;re talking about things that fundamentally change societies or human nature. And this is only growing with time</em></strong><em>.&nbsp;</em></p>
</blockquote>



<p>It’s also important to think about how quickly it moves forward. By the time it already has an impact, it can often be too late. So you can&#8217;t start to think of machine learning design after the fact because once you put a model in place, the impact it&#8217;s producing can already be widespread.&nbsp;</p>



<p>That can be both good and bad. The widespread success of a model then can have both positive and negative outcomes.</p>



<h2>The biggest challenges when designing ML products</h2>



<p><strong>Patrycja</strong>: What do you think are the biggest challenges in designing ML applications in a way that they provide a good experience to people?</p>



<p><strong>Konrad</strong>: The first step really starts with bringing in the team to understand how the model is working. What are the data points which you&#8217;re using to drive the model, and how are those being used to push the product forward?&nbsp;</p>



<p>And normally, speaking from my experience, data science and machine learning isn&#8217;t something that often has designers (people who are user-centered) coming in and speaking on behalf of the user, on behalf of their values. So I’d say that’s part of the growing problem, but also the growing opportunity.&nbsp;</p>



<p><strong>Patrycja</strong>: Talking about your experience, could mention some specific challenges for the projects that you&#8217;re working on in <a href="https://www.deliveryhero.com/" target="_blank" rel="noreferrer noopener nofollow">Delivery Hero</a>?</p>



<p><strong>Konrad</strong>: Sure. So in Delivery Hero, we operate more than 12 different food delivery apps. And those 12 food delivery apps are present in over 70 countries. That&#8217;s a ton of people that we’re affecting.&nbsp;</p>



<p>In just one day, for example, more than half a million people order on our platform. So talking about scale and the impact of a product, by the time our product does its job, we&#8217;ve already affected so many users:</p>


<div class="custom-point-list">
<ul>
<li>what they&#8217;ve ingested and eaten,&nbsp;</li>



<li>potential habit changes,&nbsp;</li>



<li>how they think about and perceive food and their diet,</li>



<li>And the rest of their day (if you ate a really heavy meal, you might not want to exercise later, right?)</li>
</ul>
</div>


<p>So eating is really intricate part of our human nature, metabolic functions, and mood.</p>



<p>So at Delivery Hero, we&#8217;re looking to integrate machine learning more and more intensively because of the growing size of the organization and how many people we are affecting.&nbsp;</p>



<p>And at Delivery Hero, we&#8217;re looking at machine learning in a way where we can guide users to find better products, better food, or other items which they want to order. It&#8217;s similar to any other eCommerce platform. Obviously, we are trying to make a sale, but hopefully, not doing it with any negative intentions or built-in biases programmed into the system. That&#8217;s the main goal.</p>



<p>At Delivery Hero, we&#8217;re not trying to make people more unhealthy. We want people to be healthy, but we also want people to find things that they&#8217;re hungry for and to find something delicious&#8230; to feed the beast haha.</p>



<blockquote class="wp-block-quote">
<p><strong><em>So, it&#8217;s now a challenge for Delivery Hero to find the best ways to move forward with machine learning that:</em></strong></p>
</blockquote>


<div class="custom-point-list">
<ol>
<li><strong><em>Helps the business grow,&nbsp;</em></strong></li>



<li><strong><em>Helps people find what they&#8217;re looking for regarding the products and foods,</em></strong></li>



<li><strong><em>And also create a system that doesn&#8217;t undermine the morals and values that those users have when using our platform.</em></strong></li>
</ol>
</div>


<h2>How to align good user experience with business goals?</h2>



<p><strong>Prince</strong>: This is really interesting. You&#8217;re seeing Delivery Hero aligning its goals with the user goals. But what is the business incentive there?</p>



<p>For example, the users won&#8217;t be buying as much if they&#8217;re having the right foods which don&#8217;t make them binge eat. That means perhaps fewer sales.&nbsp;</p>



<p>So how are you guys aligning those two things with your design?</p>



<p><strong>Konrad</strong>: A lot of good questions. I think we can break that down into a few areas. I think there&#8217;s a section that you touched on &#8211; a user perception of the brand, loyalty brand perception.&nbsp;</p>



<p>And within these different fields of balancing is what I call: the biggest balance. That&#8217;s balancing shareholder profitability and big tech with what is morally the right thing to do.&nbsp;</p>



<p>Because in any large-scale business, you&#8217;re there to grow the business, to make the business profitable. And that is still ongoing. Even in Delivery Hero, I am a shareholder, and most of the staff is, and that&#8217;s what is hard.&nbsp;</p>



<p>There&#8217;s no easy answer to balancing shareholder profitability with the best product experience for users. That&#8217;s why it&#8217;s a conversation, an ongoing conversation that we have all the time.&nbsp;</p>



<p>But I think most businesses and organizations don&#8217;t fully realize the scale at which their technology is constantly moving and morphing (for us in Delivery Hero, it&#8217;s around our growing industry of logistics and food). Users are becoming more aware of their interaction with these large-scale businesses, whether it&#8217;s Facebook, Uber, ride-sharing, or food delivery. With the growing technology, users understand the product that they&#8217;re using (maybe a bit slower than the people making the product itself). But users understand:</p>


<div class="custom-point-list">
<ul>
<li>“Okay, these things are getting smarter”,&nbsp;</li>



<li>“The experience, my feed, it has been uniquely crafted for me.”</li>
</ul>
</div>


<blockquote class="wp-block-quote">
<p><strong><em>The users, including you and me, we&#8217;re not dumb, but we don&#8217;t always know how the technology is working. Once users get an idea of how the service may be potentially misusing them, that can have a huge detractor and effect on brand loyalty and brand perception.</em></strong></p>
</blockquote>



<p>So if I realize:</p>


<div class="case-study-numbered-list">
    <h2></h2>
    <ul>
                    <li><span>1</span>One service is really pushing sales no matter what the outcome,<br />
</li>
                    <li><span>2</span>The other suggests items to buy, but it also says, “hey, you can set your budget to make sure you don&#8217;t overreach each month. We know not everybody&#8217;s just made of money, so let&#8217;s help you spend mindfully.” </li>
            </ul>
</div>



<p>I think this type of value to product design is something that&#8217;s growing quite fast because users are seeing what&#8217;s happening to their digital services and how they&#8217;re often being misused against them.&nbsp;</p>



<p>You can see right now the churn against Facebook, for instance. There are many competitors to it, so it&#8217;s not the main reason why Facebook is losing a large swath of younger audiences. But in large part, it&#8217;s because of brand perception and the product experience.</p>



<p>Facebook isn&#8217;t the newest kid on the block when it comes to apps that have a large footprint. But with that footprint, there comes a heavy lingering shadow behind the product:</p>


<div class="custom-point-list">
<ul>
<li>What it means,</li>



<li>What it does to people,</li>



<li>How it&#8217;s used.&nbsp;</li>
</ul>
</div>


<p>And businesses get ahead of that by being a bit more honest and open with users, saying, “look, we&#8217;re here to make a profit, but we also want to provide the best value, the best experience for you”.&nbsp;</p>



<p>How are they doing that? How are they voicing this approach to product design through the app experience, through the UI, through the UX? That is being crafted now. That is a new field. How to engage the audience in an honest and open way while not undermining the core business values of:</p>


<div class="case-study-numbered-list">
    <h2></h2>
    <ul>
                    <li><span>1</span>Growing the business, <br />
</li>
                    <li><span>2</span>Growing sales, <br />
</li>
                    <li><span>3</span>Growing engagement.</li>
            </ul>
</div>



<p><strong>Prince</strong>: I would like to understand some of the metrics you guys are aiming at. Are you using any metrics, or did you see any difference between when you started and now?</p>



<p><strong>Konrad</strong>: I can&#8217;t dig into those small details about the intricacies of how Delivery Hero is using machine learning today. A lot of it is still intellectual property, stuff that we&#8217;re building or testing, and we want to keep private for the time being.&nbsp;</p>



<p>What I can say is the general outlook. Some of the things we&#8217;re hoping to build and we&#8217;re testing today are suggested content based on how you’re using the system and your surrounding elements (the region, the city you&#8217;re in.)</p>



<p>All these factors are taken into account, some of them we can use more accurately, and some of them less. But these data points would be suggestions based on your previous purchases or your previous search history.&nbsp;</p>



<p>We take these in, we look at these, and then we suggest material based on those criteria. This is very similar and not unlike the other digital products you&#8217;re using today.</p>



<p>At its most basic principle, this is how Google search works. Based on how everybody else is searching for similar words, in your similar country, at a similar time of day. These are the data points that later produce your search results. And your search results are refined very heavily.</p>



<p>When you look at a product experience that’s consumer-driven (Netflix or YouTube). These features are heavily personalized just for you. We&#8217;re all gonna have different feeds and content. And that&#8217;s a good thing, that&#8217;s helpful. That&#8217;s exactly what machine learning is supposed to do.&nbsp;</p>



<p>Unfortunately, machine learning can also show you content that is overwhelming or content that is leading you down into an echo chamber. From the food side, we want to suggest the content you&#8217;re looking for. But if you constantly eat burgers on our platform, all we ever suggest to you is burgers. That&#8217;s not a healthy lifestyle, and we don&#8217;t want to do that.</p>



<blockquote class="wp-block-quote">
<p><strong><em>So that&#8217;s where this balance comes in. We take the data points that can be helpful to craft an experience that is personalized to you, but also we balance and know the other aspects which contribute to overall physical health and well-being.</em></strong></p>
</blockquote>


<div class="wp-block-image">
<figure class="aligncenter size-large is-resized"><img data-attachment-id="72136" data-permalink="https://neptune.ai/good-design-in-ml-applications-with-konrad-piercey-1" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/good-design-in-ml-applications-with-Konrad-Piercey-1.png?fit=1184%2C1999&amp;ssl=1" data-orig-size="1184,1999" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="good-design-in-ml-applications-with-Konrad-Piercey-1" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/good-design-in-ml-applications-with-Konrad-Piercey-1.png?fit=178%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/good-design-in-ml-applications-with-Konrad-Piercey-1.png?fit=607%2C1024&amp;ssl=1" decoding="async" src="https://i0.wp.com/neptune.ai/wp-content/uploads/good-design-in-ml-applications-with-Konrad-Piercey-1.png?resize=475%2C802&#038;ssl=1" alt="Examples of good design in ML - Delivery Hero " class="wp-image-72136" width="475" height="802" data-recalc-dims="1" /><figcaption class="wp-element-caption"><em>Examples of good design in ML &#8211; Delivery Hero | Copyright Konrad Piercey</em></figcaption></figure></div>


<p><strong>Patrycja</strong>: Maybe coming back to your specific project. In the context of understanding the ML or this demand to know what&#8217;s under the hood. Is there a difference in how people want this in different parts of the world?</p>



<p><strong>Konrad</strong>: Well, I wouldn&#8217;t say that our integrations with ML are going to change drastically from one region to the next. I can only speak a little bit on behalf of my ML team, as I&#8217;m not directly a data scientist or machine learning engineer. I&#8217;m on the design side. I can talk about our cooperation and our goal vision setting. With the details of exactly which models we&#8217;re testing in each region, I can&#8217;t specify that.</p>



<p>But, I would say it is not the larger goal to have some sort of radically different model for each country. You can think about it from a user experience side, the eating habits of somebody in the city center of Singapore are going to be different eating habits of somebody in Stockholm, Sweden.&nbsp;</p>


<div class="case-study-numbered-list">
    <h2></h2>
    <ul>
                    <li><span>1</span>The things to eat</li>
                    <li><span>2</span>The time of day</li>
                    <li><span>3</span>The amount to eat</li>
                    <li><span>4</span>Who do they eat with, </li>
                    <li><span>5</span>How often are they doing meals together.</li>
            </ul>
</div>



<p>These are the type of things that are more interesting from the design side. They probably do have some effect on the machine learning models (which we would use).&nbsp;</p>



<h2>Examples of good and bad UX practices in ML apps</h2>



<p><strong>Patrycja</strong>: So you talked a bit about those bad patterns in the UX for ML apps, like suggesting too much unhealthy food or trying to keep you watching something forever.</p>



<p>I&#8217;m wondering what you think could be done to make it a more positive experience for people. What are the good UX practices for ML applications?</p>



<p><strong>Konrad</strong>: Good examples are a little bit hard to come by because, honestly, we don&#8217;t have many great ones. But I can share some examples that your audience may have already seen and already engaged with, but they hadn&#8217;t realized this is machine learning design.<strong><em>&nbsp;</em></strong></p>



<p>Some poor examples would be where you have engagement on a level that is unhealthy. If you look at content-driven services (whether that&#8217;s social media or news), you don&#8217;t often get a sense of your path of consumption.&nbsp;</p>



<p>But right now, on your phone, you can see and set individual app limits (“I only want to use this app for this long”). This is a new feature for smartphones. This is not something that has existed for a very long time. You have to ask yourself &#8211; why does this exist now? This exists because of a growing need for it to exist. This is something users want because of our unhealthy technological habits.&nbsp;</p>



<p>You can also see this happening on YouTube. YT has a timer you can set that alerts you, “You&#8217;ve been watching for an hour. Do you still want to engage with the service?”.&nbsp;</p>



<p>TikTok actually has something that you&#8217;re not able to turn on or off. For some users, TikTok tested videos directly in the feed. As you were transitioning between content, a personality came on and said, “Hey, you&#8217;ve been watching a lot of content. Why don&#8217;t you take a break and step outside to get some fresh air”. This is great, but it also goes against the principle of the business to push users to engage more. Very interesting to see how industries are pushing these concepts forward of healthier habits.</p>



<blockquote class="wp-block-quote">
<p><strong><em>So at this point, you&#8217;re seeing what happens if the model has become so effective that it&#8217;s now detrimental to the user. The machine learning model is, in a way, almost too good.&nbsp;</em></strong></p>
</blockquote>



<p>This is not something that people often talk about, but that&#8217;s what&#8217;s happening. This is the concept of very progressive machine learning modeling. AI and ML are at the point when models almost become too efficient. Now people (not machines) have to put these sorts of break times, like “Hey, it&#8217;s time to take a break”, and “Hey, you might have been consuming too much”.</p>


<div class="wp-block-image">
<figure class="aligncenter size-large is-resized"><img data-attachment-id="72137" data-permalink="https://neptune.ai/good-design-in-ml-applications-with-konrad-piercey-2" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/good-design-in-ml-applications-with-Konrad-Piercey-2.png?fit=1132%2C1999&amp;ssl=1" data-orig-size="1132,1999" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="good-design-in-ml-applications-with-Konrad-Piercey-2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/good-design-in-ml-applications-with-Konrad-Piercey-2.png?fit=170%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/good-design-in-ml-applications-with-Konrad-Piercey-2.png?fit=580%2C1024&amp;ssl=1" decoding="async" src="https://i0.wp.com/neptune.ai/wp-content/uploads/good-design-in-ml-applications-with-Konrad-Piercey-2.png?resize=456%2C805&#038;ssl=1" alt="Examples of good design in ML - Facebook" class="wp-image-72137" width="456" height="805" data-recalc-dims="1" /><figcaption class="wp-element-caption"><em>Examples of good design in ML &#8211; Facebook | Copyright Konrad Piercey</em></figcaption></figure></div>


<p>But as Prince said, it goes against the business model to purchase more, to spend more time. Yes, it does. But that is the judgment of moral values that must occur on the design, on the product side, and on the experience side.</p>



<h2>The process of designing and building ML applications</h2>



<p><strong>Patrycja</strong>: I see. So now, I&#8217;m wondering what the process looks like on your side when the designer is this extra person on the team. What does the workflow look like? When do you start cooperating with the ML team and the others?</p>



<p><strong>Konrad</strong>: That&#8217;s an interesting topic because on my teams at Delivery Hero, we have the menu where you&#8217;re actually browsing products of a specific vendor, and you want to add stuff to your cart.&nbsp;</p>



<p>We&#8217;re also making suggestions on that screen. And the idea here is that as the menu grows, we will make more and more types of suggestions. The menus presented will be more personalized. There will be more input from the model in order to reorganize what&#8217;s presented to you.&nbsp;</p>



<p>This is the inevitable path of actually any food delivery app. Even outside of Delivery Hero, the apps will start suggesting and personalizing more and more content. They&#8217;re already doing this. But this will become a larger part of the product experience.</p>



<p>What&#8217;s important is that on my team, we started asking questions:</p>


<div class="case-study-numbered-list">
    <h2></h2>
    <ul>
                    <li><span>1</span>Where exactly is machine learning gonna come in and make an effect on users? <br />
</li>
                    <li><span>2</span>How would they be affected by this, in both positive and negative ways? </li>
            </ul>
</div>



<p>You don&#8217;t just look at machine learning and say, okay, what can I do for users in order to help them find a product at the price point they are looking for. You have to ask, are there any downsides to just adding more products to the basket?&nbsp;</p>



<p>We have to ask those questions simultaneously as we integrate this service.&nbsp;</p>



<blockquote class="wp-block-quote">
<p><strong><em>Integrating machine learning isn&#8217;t all positive impact. You do have to weigh the outcomes. On our side, I think what we&#8217;re trying to do, is to educate both inside the company and outside to other designers.&nbsp;</em></strong></p>
</blockquote>



<p>If you know machine learning is being used in your team, the first thing is to educate yourself on:</p>


<div class="custom-point-list">
<ul>
<li>How that model works,</li>



<li>What data points it&#8217;s using,&nbsp;</li>



<li>And then what it produces.&nbsp;</li>
</ul>
</div>


<p>So, what is the input, and what is the output. That&#8217;s what machine learning is, input and output. So educate yourself and your product team on those criteria.</p>



<p>From there, you can better understand how the model can be integrated and what it can or can’t do. I&#8217;m not saying make all the designers machine learning experts or take a course in machine learning, but understand the basic principles of how your model works and is being applied.&nbsp;</p>



<p>From there, there are actually three steps. Three super important steps to Good Design in Machine Learning (as I like to call it) GDML:</p>


<div class="case-study-numbered-list">
    <h2></h2>
    <ul>
                    <li><span>1</span>Educational<br />
</li>
                    <li><span>2</span>Simple <br />
</li>
                    <li><span>3</span>Fun</li>
            </ul>
</div>



<p>With these three principles or pillars, that&#8217;s how we define and approach integration with machine learning. So, if we want to integrate machine learning on the menu, we look at how we can bring something educational to the user by telling them what the machine is suggesting or maybe why we&#8217;ve suggested that. Speaking a little bit more in detail on how we change their feed or that what we suggest to them is having an effect on their habits. Because, again, that&#8217;s a two-way relationship between the machine and the user.</p>



<blockquote class="wp-block-quote">
<p><strong><em>My interaction with the system changes the system. Also, what the system is displaying to me, what it&#8217;s giving me, changes me. In return, depending on what I interact with and order, this will change the system. And so that&#8217;s a symbiotic relationship that machine learning starts to build between users and the product.&nbsp;</em></strong></p>
</blockquote>



<p>But again, educational, simple, and fun:</p>


<div class="custom-point-list">
<ol>
<li>Educate &#8211; try to show something to users they didn&#8217;t know before. Try to teach them something new and valuable which is not naturally understood. That&#8217;s educational.&nbsp;</li>
</ol>
</div>

<div class="custom-point-list">
<ol start="2">
<li>Keep it simple &#8211; if we want to educate the user on something relating to ML or the model in the background, we&#8217;re not gonna teach them the data attributes of how things are going in or how things are coming out. We&#8217;re not trying to write a book or have them read a book on these complex mathematics.&nbsp;</li>
</ol>
</div>


<p>Show them a simple graphic. That&#8217;s generally the approach we wanna take. We know that the phrase: pictures speak 1000 words. UX copy is super important here. We don&#8217;t want to lecture the user, we want to keep the language simple.</p>


<div class="custom-point-list">
<ol start="3">
<li>And the last one is fun &#8211; we needed to add this one because, at the end of the day, machine learning, AI, and deep learning can be really complicated topics. And I think for a lot of people, it may be naturally uninteresting if it&#8217;s not easy to digest.&nbsp;</li>
</ol>
</div>


<p>So trying to find a way to create some visual language or graphic that uses fun colors or fun animations to be a bit more humanistic. We want to try to put a smile on some users&#8217; faces (I think the world could generally use a few more smiles in it). So trying to create a fun and engaging experience is also part of that.</p>



<p><strong>Prince:</strong> How do you make people want to learn?&nbsp;</p>



<p><strong>Konrad</strong>: Again, back to our values. Those three values or principles can be generally summarized in two words.&nbsp;</p>


<div class="case-study-numbered-list">
    <h2></h2>
    <ul>
                    <li><span>1</span>Transparency</li>
                    <li><span>2</span>Disclosure</li>
            </ul>
</div>



<p>Transparency and disclosure are sorts of our leading lights whenever we approach ML integrations. I think the design community also is approaching ML/AI/DL in this manner. We want to be transparent and disclose when there is a machine making decisions on behalf of people.</p>



<p>Transparency and disclosure are actually often legally binding rules in countries&#8217; laws. This is a huge facet of UX principles that many large organizations are not aware of, and it could potentially put them at legal risk. If we look at UNESCO (where 200+ countries are member states), they actually adopted the first-ever AI ethics guideline, which states, “people should be fully informed when a decision is informed by or is made on the basis of AI algorithms”.&nbsp;</p>



<p>So we&#8217;re not talking about machine learning and design in some abstract way. As in, “we can maybe cut some corners here and do some things there,” that may not be the best for users, but it&#8217;s going to help the business. Or even not thinking about the user at all &#8211; that&#8217;s a scary thought. Let&#8217;s just only think about increasing engagement and let that be the first priority, this type of strategy isn&#8217;t going to get you very far, in fact, it might be endangering your business.</p>



<p>Well, I think you&#8217;re gonna find that very soon within a lot of countries, and even businesses (sometimes they have their own internal guidelines for AI and ML) release newly updated rules for ethics and guidelines.</p>



<blockquote class="wp-block-quote">
<p><strong><em>So, as I said, people should be fully informed when a decision is made on the basis of AI algorithms.</em></strong>&nbsp;</p>
</blockquote>



<p>Most of the products we&#8217;ve already talked about today are doing this. They are suggesting content or showing you content, not because you necessarily want to see that content, but because it&#8217;s making an assumption you want to see that. And this assumption is being done on behalf of the machine.&nbsp;</p>



<p>And when you don&#8217;t like the content, you do have some options. There is this little hamburger menu, or three-dot menu, where you can choose “hey, I&#8217;m not interested in this” or “don&#8217;t show me this anymore”.&nbsp;</p>



<p>But generally speaking, those algorithms are hidden behind a deeper menu, a deeper layer, and it&#8217;s usually on a per-content basis. That means that I can decide whether or not I want to see this video or post, but it&#8217;s not giving me any analytical data as a whole. I don&#8217;t know how I&#8217;m consuming content there or what path I&#8217;m moving forward down.&nbsp;</p>



<p>In the food delivery space, it’s actually much easier. We have a much easier guiding light for us compared to social media, news, music, or movies. Well, the human body has very easy guidelines on what is and what isn&#8217;t good for us. Of course, this changes from person to person throughout the world.&nbsp;</p>



<p>But as an example, the WHO has a standard for public health. One of these numbers is for the average adult, they should consume at least 400 grams of fruit and vegetables per day (this is not an exact number for every single person. It depends on your weight, your height, your region, and other factors. . So local standards have to be taken into effect).&nbsp;</p>



<p>So whether it&#8217;s these AI and ML ethics guidelines, or clear health standards from the WHO, users need to be aware of how their product is affecting them and how the machine is making decisions on their behalf. As we&#8217;ve said, even suggesting on behalf of them &#8211; this also counts because they&#8217;re consuming, they&#8217;re engaging.</p>



<p>And as Prince said, that can be hard sometimes because you have to balance that with the growth of the business. You don&#8217;t want to put people off by potentially limiting their choices. That&#8217;s not what Delivery Hero wants to do. We don&#8217;t want to limit people&#8217;s choices. Nor would Netflix or Instagram want to stop people from watching a movie or from reading a post.&nbsp;</p>



<blockquote class="wp-block-quote">
<p><strong><em>That&#8217;s not the idea to limit the content, to draw a hard line. It&#8217;s just to inform the user. And machine learning design, or GDML, is all about that. Not about saying what&#8217;s right or wrong but about guiding the user to more information so that they can be better informed. We only want to inform.</em></strong></p>
</blockquote>



<h2>What’s next for a good design in ML?</h2>



<p><strong>Prince:</strong> You talked about limits in services that are based on machine learning. I am wondering, in terms of good design ML, or probably the next few steps, do you see imposing or adding limits or summary statistics to applications in ML becoming a standard?&nbsp;</p>



<p><strong>Konrad</strong>: If the question is whether we want to give users the ability to turn off the algorithm &#8211; I don&#8217;t think that&#8217;s gonna happen any time soon. Nor do I think it’s the best thing to do. I think giving the user options to reset their algorithm, or to totally turn it off, may not be that beneficial.</p>



<p>For instance, if you take your YouTube account, I don&#8217;t know how helpful that would be for the users to just turn off their algorithms. That&#8217;s gonna be very strange. Of course, if they really want to do that, I could just make a new account and start from scratch. But there is no button on YouTube that says &#8220;reset my algorithm&#8221;. It&#8217;s always just constantly feeding into what you consume, whether that&#8217;s like your Google search history or what you&#8217;re actually watching on YouTube.&nbsp;</p>



<p>I&#8217;d say probably the growing trend is more looking at the broader awareness of what we&#8217;re going to give to users, e.g., the statistics you mentioned. Bringing a broader awareness of what the machine has learned about them and giving users some insight into it. Again, coming back to the first principle of GDML. Education, showing some of those statistics, is gonna be a large fundamental part of it.&nbsp;</p>



<p>One of my favorite examples is if you use Spotify, perhaps you&#8217;ve seen your end-of-year summary, they call it &#8220;Wrapped&#8221;. Have you guys seen that? That is GDML. However, it&#8217;s only a surface-level implementation of what we&#8217;ve been talking about so far for good design machine learning. Your end-of-year summary Wrapped on Spotify shows you how you have affected the system and how the system affected you. It shows you how many songs you consume and how many hours you listen to. They can even break that down into morning, afternoon, and evening. They&#8217;re showing you how your data is unique in the system. Also, based on its suggestions to you, it shows you, “hey, you&#8217;ve discovered x number of artists, and you&#8217;re in the x percentile of this genre for people who listen to similar music as you. ?”. That is the start of GDML.&nbsp;</p>



<p>However, I want to make an important note that even though this is a nice example of modern GDML, Spotify summary wrap doesn&#8217;t actually show any deeper level value to the user. It&#8217;s showing very surface-level numbers, stuff that wouldn&#8217;t necessarily help the user in any way. It&#8217;s just somewhat interesting. A key factor to good design in machine learning is to educate the user on something actually useful, not just frivolous data.</p>



<p>The mock visual examples I&#8217;ve shared with you (Food Delivery app, Facebook, Amazon) show how we can bring a deeper level of meaning using GDML by showing statistics and relevant data to the user. In these draft examples, users go away learning something that has some deeper level of meaning or value to their life, habits, consumption, or purchases.</p>


<div id="block_0f45e5b90102b77346c7a189258c5034" class="separator separator-20"></div>


<div class="wp-block-image">
<figure class="aligncenter size-large is-resized"><img data-attachment-id="72138" data-permalink="https://neptune.ai/good-design-in-ml-applications-with-konrad-piercey-3" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/good-design-in-ml-applications-with-Konrad-Piercey-3.png?fit=1999%2C1099&amp;ssl=1" data-orig-size="1999,1099" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="good-design-in-ml-applications-with-Konrad-Piercey-3" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/good-design-in-ml-applications-with-Konrad-Piercey-3.png?fit=300%2C165&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/good-design-in-ml-applications-with-Konrad-Piercey-3.png?fit=1024%2C563&amp;ssl=1" decoding="async" src="https://i0.wp.com/neptune.ai/wp-content/uploads/good-design-in-ml-applications-with-Konrad-Piercey-3.png?resize=832%2C458&#038;ssl=1" alt="Examples of good design in ML - Amazon page" class="wp-image-72138" width="832" height="458" data-recalc-dims="1" /></figure></div>

<div class="wp-block-image">
<figure class="aligncenter size-full is-resized"><img data-attachment-id="72139" data-permalink="https://neptune.ai/good-design-in-ml-applications-with-konrad-piercey-4" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/good-design-in-ml-applications-with-Konrad-Piercey-4.png?fit=818%2C566&amp;ssl=1" data-orig-size="818,566" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="good-design-in-ml-applications-with-Konrad-Piercey-4" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/good-design-in-ml-applications-with-Konrad-Piercey-4.png?fit=300%2C208&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/good-design-in-ml-applications-with-Konrad-Piercey-4.png?fit=818%2C566&amp;ssl=1" decoding="async" src="https://i0.wp.com/neptune.ai/wp-content/uploads/good-design-in-ml-applications-with-Konrad-Piercey-4.png?resize=749%2C518&#038;ssl=1" alt="Examples of good design in ML - Amazon metrics" class="wp-image-72139" width="749" height="518" data-recalc-dims="1" /><figcaption class="wp-element-caption"><em>Examples of good design in ML &#8211; Amazon | Copyright Konrad Piercey</em></figcaption></figure></div>


<p>Spotify is a nice example because it shows what it means to peek behind the curtain of the algorithm. These statistics of how much you consume that song in the year versus everybody else etc., you would never know that by default. They show you these because it&#8217;s interesting, it’s about you personally. And that&#8217;s why people like it. It&#8217;s about me. It shows why I’m special. But it doesn&#8217;t go beyond that really surface-level projection of information.</p>



<h2>How to measure if design improvements affect users?</h2>



<p><strong>Patrycja</strong>: After implementing some good design practices in ML, do you somehow test or check if users start to use the application differently or they limit the usage? Or the opposite, maybe they use it even more now that they are informed. Do you have this data?</p>



<p><strong>Konrad</strong>: Inside Delivery Hero and our family of food apps, we&#8217;re not gonna know the real results for some time, but we do know:</p>


<div class="custom-point-list">
<ul>
<li>what users are asking for,&nbsp;</li>



<li>the solutions that we&#8217;re building,&nbsp;</li>



<li>and the process that I&#8217;ve shown to you today (educate, keep it simple, try to make it fun).</li>
</ul>
</div>


<p>As well as those principles of trying to be transparent and disclose how the model is working. These are our best efforts to provide what&#8217;s right for the customer.</p>



<p>But on the part of impact and validation, how do we know what we&#8217;ve built is meaningful? Well, there are some ways to find out, and there are some processes and standards which are helpful.&nbsp;</p>



<blockquote class="wp-block-quote">
<p><strong><em>You need to contrast soft qualitative metrics against hard quantitative metrics.&nbsp;</em></strong></p>
</blockquote>



<p>What we&#8217;re talking about here is user interviews vs. live data analytics. So things like whether people use the product more after they&#8217;ve viewed some bar graph showing usage of the system or whether they&#8217;re eating more noodles and pizza at night versus in the afternoon.&nbsp;</p>



<p>So checking, after a user has engaged/seen content related to their machine learning algorithm, how they&#8217;re going to continue engaging with the product. You can tell some of that by data analytics. But you also have to contrast that against user interviews because some of that won&#8217;t be able to be told by just the base numbers. You need to do interviews and studies. So spending some time on research and user research is never a waste of time.&nbsp;</p>


<div class="case-study-numbered-list">
    <h2></h2>
    <ul>
                    <li><span>1</span>Eye tracking, <br />
</li>
                    <li><span>2</span>Dwell time, <br />
</li>
                    <li><span>3</span>Click-through rates, </li>
            </ul>
</div>



<p>All this stuff is super helpful. So all that can help you validate the impact of your GDML.</p>



<p>I will make a specific statement about using click-through rates. Let&#8217;s say you have some GDML component that helps educate the user on the algorithm and the product experience: how it&#8217;s changing, how they&#8217;re changing it, and how it&#8217;s changing them. If you do have some specific component that people can click on and learn more about their data, you should have that CTA very non-intrusive. So it really shouldn&#8217;t be visually screaming at the user, but it should be there if they want to click on it and learn more. But it shouldn&#8217;t be yelling at them like,” you need to take a look at this now! You should investigate your data, that would just sound scary.&nbsp;</p>



<blockquote class="wp-block-quote">
<p><strong><em>Again. We&#8217;re not trying to scare the user or make this a critical part of the user flow or user experience. But we&#8217;re giving them, what&#8217;s most important, the opportunity to learn more if they&#8217;d like to learn more. We&#8217;re not hiding this stuff. We don&#8217;t wanna make it to seem like we&#8217;re hiding anything that is potentially affecting their mental or physical health.</em></strong></p>
</blockquote>



<p>Also, it’s worth mentioning that, in many cases, companies don’t hide that information intentionally. They often don&#8217;t even necessarily know what the system is doing or what effect it has on the user.</p>



<p>Let’s take Facebook in the U. S. &#8211; the fake news propagation. They didn&#8217;t know fake news was a problem till it already was a problem and wrecked havoc for a critical US election. So that shows that once machine learning at scale is applied, the effects are much faster than what you might imagine because that&#8217;s the nature of machine learning and product consumption on a user&#8217;s part.&nbsp;</p>



<p>If it&#8217;s propagating information or propagating sales or making suggestions, we should know:&nbsp;</p>


<div class="custom-point-list">
<ul>
<li>What is that doing to the user?&nbsp;</li>



<li>How can we inform them before we know, as a product, what is good or bad for them?&nbsp;</li>
</ul>
</div>


<p>That&#8217;s why GDML is so powerful, it keeps the user informed so that they can make a decision on what they think is healthy for them.&nbsp;</p>



<p><strong>Patrycja</strong>: It is also touching what you said before that before educating users about the product, people also have to educate themselves. They need to understand the tool and what the algorithm is doing before they even can share this info with others.</p>



<p><strong>Konrad</strong>: Yeah, it&#8217;s something new that designers and product people will have to start implementing into their own internal processes. Just five years ago, I didn&#8217;t have to worry about ML or deep learning or any of this algorithmic learning. It wasn&#8217;t part of my process or methodology as a designer.&nbsp;</p>



<p>But now, when machine learning is integrated into almost any digital consumer experience, designers really have to take a step forward and start participating in those conversations. Both learn about ML, in general (how it works), but also specifically inside their teams (how they&#8217;re planning to use it, how they want to apply it). That will be part of the growing portfolio of needs from new people in the product and design space.</p>



<h2>How can Data Scientists and ML Engineers help UX designers?</h2>



<p><strong>Patrycja</strong>: Following up on what you said, let’s go to the other side of this process. Is there anything machine learning people, like data scientists and ML engineers, can do to make it easier for you to design this product in a better way?</p>



<p><strong>Konrad</strong>: I would say, if you&#8217;re a machine learning engineer or data scientist, strike up a random conversation with one of your fellow product or design people. Make new friends there.</p>



<p>The interaction between machine and user, between data science and UX, is becoming so intricate now that it&#8217;s hard for us to understand how best to move forward. These things are just being defined now. Designing machine learning is not an industry that currently exists. It is a burgeoning field.&nbsp;</p>



<p>So, anybody who&#8217;s super interested in it, if you are going to get ahead on that curve, you have to know how to speak about the information in a way that&#8217;s personal, that is humanistic, and you can only speak about it if you know what you&#8217;re talking about. This is not a call out for every designer to become a machine learning engineer or every machine learning engineer to take a boot camp on UX.&nbsp;</p>



<blockquote class="wp-block-quote">
<p><strong><em>It&#8217;s about sort of linking arms and moving forward together to create product experiences that we&#8217;re proud of. To create products for the people who come after us, for our kids, for your grandparents, and for the people who are long after once, we&#8217;re dead. </em></strong></p>



<p><strong><em>We have to set an industry standard for what is right here because we&#8217;re no longer creating static product experiences, these products are, in a way, sort of growing organisms themselves. </em></strong></p>



<p><strong><em>The product experiences we now craft are moving, flexing, and vicious in their nature. And the machines, our newest friends, are part of that. So we have to learn how to integrate with that properly.</em></strong></p>
</blockquote>



<h2>Most important design principles&nbsp;</h2>



<p><strong>Prince</strong>: Yes, that makes sense! Before we finish, I wanted to ask you, what are your top three things, principles, or must-haves, when designing UX/UI design before releasing any machine learning application or your first iteration of the product?&nbsp;</p>



<p><strong>Konrad</strong>: Wow, I would say:</p>



<blockquote class="wp-block-quote">
<p><strong><em>Get to know your audience and become your audience. As you&#8217;re only able to build a great experience if you know and can connect empathetically with your users and with your customers. So that&#8217;s the most important.&nbsp;</em></strong></p>
</blockquote>



<p>And that&#8217;s what being a product designer is.&nbsp;</p>


<div class="case-study-numbered-list">
    <h2></h2>
    <ul>
                    <li><span>1</span>Try to break the product,<br />
</li>
                    <li><span>2</span>Talk to the people you&#8217;re affecting, <br />
</li>
                    <li><span>3</span>And if possible, use what you&#8217;re building. That&#8217;s a super important part.</li>
            </ul>
</div>



<p>I think even big businesses today don&#8217;t do that enough. And it&#8217;s sometimes difficult to ensure that everybody working on the product really engages with that product, uses it, and tries to be a part of the experience instead of just designing or building something which you don&#8217;t really have the perspective on what is in the end experience.&nbsp;</p>



<h2>Good Desing Machine Learning (GDML) community</h2>



<p><strong>Patrycja</strong>: Okay, the final question is about the GDML community or the movement…</p>



<p><strong>Konrad</strong>: The movement… hah, sounds like I&#8217;m starting an army here, “If you want to join the ranks of GDML, I&#8217;m gonna post a signup sheet”.</p>



<p><strong>Patrycja</strong>: Not yet, but who knows?</p>



<p><strong>Konrad</strong>: So GDML, it&#8217;s the phrase we found that best summarizes our attitude toward creating a better user experience where ML, deep learning, and AI are involved, and that stands for Good Design Machine Learning. <a href="https://knpdesign.co/gdml.html" target="_blank" rel="noreferrer noopener nofollow">Learn more about GDML</a></p>



<p>We want to be good. We want to do good. We want to design good. And with GDML, we&#8217;re just trying to find other people who are interested in this topic. That&#8217;s the main thing. People who are interested to learn more, who are interested in progressing in this field.&nbsp;</p>



<p>Currently, I&#8217;m acting as a pseudomoderator in this group and in my own specific areas, but we&#8217;re eagerly looking for engineers, data scientists, designers, and anybody else who wants to help communicate GDML in their own company or maybe start a meet up in their own community.</p>



<p>As a side gig, I&#8217;m also working on completing my first book, on GDML, as you might have assumed. We will hopefully see that coming out sometime soon, but I won&#8217;t remark on it too much until it&#8217;s on the shelves.</p>



<p><strong>Patrycja</strong>: Okay, perfect. Thank you for sharing your experience!</p>




<div id="author-box-new-format-block_39f96350d5a664aea8dcf1158b814db5" class="article__footer article__author">
  <div class="article__authorImage">
          <img width="200" height="200" src="https://i0.wp.com/neptune.ai/wp-content/uploads/Konrad-Piercey.png?fit=200%2C200&amp;ssl=1" class="article__authorImage-img" alt="" decoding="async" data-attachment-id="72140" data-permalink="https://neptune.ai/konrad-piercey" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Konrad-Piercey.png?fit=200%2C200&amp;ssl=1" data-orig-size="200,200" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Konrad-Piercey" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Konrad-Piercey.png?fit=200%2C200&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Konrad-Piercey.png?fit=200%2C200&amp;ssl=1" />      </div>

  <div class="article__authorContent">
          <h3 class="article__authorContent-name">Konrad Piercey </h3>
    
          <p class="article__authorContent-text">Konrad leads founders and their teams to understand successful product &#038; experience design methodologies, merging business development with user experience and product design.

Konrad is a product steward and IOT guru, interested in the way consumers connect with changing digital landscapes. With 10+ years in UX/UI design and launches in the US, EU, and Asia, he loves building unusual products. Mentoring teams to best understand their potential and be industry leaders. Konrad guides organizations on how to achieve their goals and create impactful products.
</p>
    
          <ul class="article__authorSocial">
        <li class="article__authorSocial-single article__authorSocial-name">Follow me on</li>
        
                  <li class="article__authorSocial-single"><a href="https://www.linkedin.com/in/konradpiercey/" class="article__authorSocial-lk" target="_blank"></a></li>
        
              </ul>
    
  </div>
</div>


<div class="is-layout-flow wp-block-group"><div class="wp-block-group__inner-container">
<hr class="wp-block-separator has-css-opacity"/>



<p class="has-text-color" style="color:#4455a6"><strong>READ NEXT</strong></p>



<h2>MLOps: What It Is, Why it Matters, and How To Implement It</h2>



<p class="has-small-font-size">13 mins read | Prince Canuma | Posted January 14, 2021</p>


<div id="block_5ffc75def9f8e" class="separator separator-10"></div>



<p>According to techjury, every person created at least 1.7 MB of data per second in 2020. For data scientists like you and me, that is like early Christmas because there are so many theories/ideas to explore, experiment with, and many discoveries to be made and models to be developed. </p>



<p>But if we want to be serious and actually have those models touch real-life business problems and real people, we have to deal with the essentials like:</p>


<div class="custom-point-list">
<ul><li>acquiring &amp; cleaning large amounts of data;</li><li>setting up tracking and versioning for experiments and model training runs;</li><li>setting up the deployment and monitoring pipelines for the models that do get to production.&nbsp;</li></ul>
</div>


<p>And we need to find a way to scale our ML operations to the needs of the business and/or users of our ML models.</p>



<p>There were similar issues in the past when we needed to scale conventional software systems so that more people can use them. DevOps’ solution was a set of practices for developing, testing, deploying, and operating large-scale software systems. With DevOps, development cycles became shorter, deployment velocity increased, and system releases became auditable and dependable.</p>



<p>That brings us to&nbsp;<strong>MLOps</strong>. It was born at the intersection of&nbsp;<strong>DevOps</strong>,&nbsp;<strong>Data Engineering,</strong>&nbsp;and&nbsp;<strong>Machine Learning</strong>, and it’s a similar concept to DevOps<strong>,&nbsp;</strong>but the execution is different. ML systems are experimental in nature and have more components that are significantly more complex to build and operate.</p>



<p>Let’s dig in!</p>


<a class="button continous-post blue-filled" href="/blog/mlops" target="_blank">
    Continue reading -&gt;</a>



<hr class="wp-block-separator has-css-opacity"/>
</div></div>
<p>The post <a rel="nofollow" href="https://neptune.ai/blog/good-design-machine-learning">Good Design in ML Applications With Konrad Piercey</a> appeared first on <a rel="nofollow" href="https://neptune.ai">neptune.ai</a>.</p>
]]></content:encoded>
					
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">72133</post-id>	</item>
		<item>
		<title>Your First MLOps System: What Does Good Look Like? With Andy McMahon</title>
		<link>https://neptune.ai/blog/first-mlops-system-with-andy-mcmahon</link>
		
		<dc:creator><![CDATA[Stephen Oladele]]></dc:creator>
		<pubDate>Wed, 19 Oct 2022 10:48:09 +0000</pubDate>
				<category><![CDATA[MLOps]]></category>
		<category><![CDATA[mlops]]></category>
		<guid isPermaLink="false">https://neptune.ai/?p=72034</guid>

					<description><![CDATA[<p>This article was originally an episode of the MLOps Live, an interactive Q&#38;A session where ML practitioners answer questions from other ML practitioners.&#160; Every episode is focused on one specific ML topic, and during this one, we talked to Andy McMahon about your first MLOps system.&#160; You can watch it on YouTube: Or listen to [&#8230;]</p>
<p>The post <a rel="nofollow" href="https://neptune.ai/blog/first-mlops-system-with-andy-mcmahon">Your First MLOps System: What Does Good Look Like? With Andy McMahon</a> appeared first on <a rel="nofollow" href="https://neptune.ai">neptune.ai</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<p>This article was originally an episode of the <a href="/events">MLOps Live</a>, an interactive Q&amp;A session where ML practitioners answer questions from other ML practitioners.&nbsp;</p>



<p>Every episode is focused on one specific ML topic, and during this one, we talked to Andy McMahon about<strong> your first MLOps system.</strong>&nbsp;</p>



<p>You can watch it on YouTube:</p>



<figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">
<iframe class="youtube-player" width="640" height="360" src="https://www.youtube.com/embed/fge5I_SZu5Y?version=3&#038;rel=1&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;fs=1&#038;hl=en-US&#038;autohide=2&#038;wmode=transparent" allowfullscreen="true" style="border:0;" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe>
</div></figure>



<p>Or listen to it as a podcast on:</p>


<div class="custom-point-list">
<ul><li><a href="https://open.spotify.com/episode/7u4qCqEO1q1UlWTkB08RFq" target="_blank" rel="noreferrer noopener nofollow">Spotify</a></li><li><a href="https://podcasts.apple.com/us/podcast/your-first-mlops-system-what-does-good-look-like-with/id1622835619?i=1000576346323" target="_blank" rel="noreferrer noopener nofollow">Apple Podcasts&nbsp;</a></li></ul>
</div>


<p>But if you prefer a written version, here it is!&nbsp;</p>



<p>You’ll learn about:</p>


<div class="case-study-numbered-list">
    <h2></h2>
    <ul>
                    <li><span>1</span>What is an MLOps system?<br />
</li>
                    <li><span>2</span>What does a good MLOps system look like?<br />
</li>
                    <li><span>3</span>How to implement it?</li>
                    <li><span>4</span>How to scale an MLOps system?</li>
                    <li><span>5</span>And much more!</li>
            </ul>
</div>



<p><strong>Sabine: </strong>We are joined today by our esteemed guest, <a href="https://www.linkedin.com/in/andymcmahon629/" target="_blank" rel="noreferrer noopener nofollow">Andy McMahon</a>, and our topic will be &#8220;Your first MLOps system. What does good look like?&#8221; Andy, welcome to the show.</p>



<p><strong>Andy McMahon: </strong>Thank you so much for having me.</p>



<p><strong>Sabine: </strong>Andy, you have an educational background in some interesting stuff. Master of Science in Simulation of Materials and a Ph.D. in Physics, and then you got more into the machine learning side of things. You have a bunch of experience with data science and ML engineering. Currently, you&#8217;re the machine learning engineering lead at <a href="https://www.natwestgroup.com/" target="_blank" rel="noreferrer noopener nofollow">NatWest Group</a>, Banking, and Insurance Holding Company. You&#8217;ve also published a book titled “Machine Learning Engineering With Python”, and you&#8217;re doing a podcast called<a href="https://open.spotify.com/show/4bRuzmU97MWPDTf2FxkEEc" target="_blank" rel="noreferrer noopener nofollow"> “AI Right”</a> Podcast. Is there anything you&#8217;re not doing in the space of machine learning?</p>



<p><strong>Andy: </strong>Thank you. Sleeping is the main one.&nbsp;</p>



<h2>What is an MLOps system?</h2>



<p><strong>Sabine: </strong>Fair enough. We do hope you get to rest every now and then. Okay, to warm you up, Andy, how would you explain to us MLOps Systems in one minute? We will time you.</p>



<p><strong>Andy: </strong>To me, MLOps Systems are software solutions that basically allow you to do good operational practices for machine learning products. What that means, in a sense, is building ML solutions that are:</p>


<div class="case-study-numbered-list">
    <h2></h2>
    <ul>
                    <li><span>1</span>reusable, <br />
</li>
                    <li><span>2</span>scalable, <br />
</li>
                    <li><span>3</span>and reproducible. </li>
            </ul>
</div>



<p>Contained within that are several different sub-practices, some of which are very important, in particular, to machine learning software solutions, like:</p>


<div class="custom-point-list">
<ul><li>Model monitoring, </li><li>How do you know your machine learning model is performing at the appropriate performance criteria? </li><li>How are you retraining? </li><li>How do you trigger retraining? </li><li>How often are you retraining? </li><li>Are you scheduling it? </li><li>Et cetera.</li></ul>
</div>


<p>You then also have model management practices. You need to <a href="/blog/ml-metadata-store" target="_blank" rel="noreferrer noopener">track and manage the metadata associated with your model artifacts</a> and make sure that is clearly labeled and articulated. Then all of that has to come together in a sustainable set of practices and processes that have a very clear route to life within it so that you can take machine learning models from ideation through to production. That, to me, is <a href="/blog/mlops" target="_blank" rel="noreferrer noopener">MLOps </a>systems.</p>



<p><strong>Sabine: </strong>Excellent. That was just a few seconds over one minute, and it was very nicely encapsulated. Nicely done.&nbsp;</p>



<h2>What does a good MLOps system look like?</h2>



<p><strong>Stephen: </strong>I also like to preface with trying to understand what good looks like because I think it&#8217;s one of the key things we&#8217;re emphasizing in the title. What is a good MLOps system? Especially when you&#8217;re trying to build it for the first time. Let&#8217;s start from there.</p>



<p><strong>Andy:</strong> I think what&#8217;s really important for this is making sure that it makes your life easier.</p>



<blockquote class="wp-block-quote"><p><strong><em>The worst thing we can do as a community is build MLOps systems and solutions because we feel we have to. Just because it&#8217;s the latest fad or the latest trend, I should incorporate MLOps tools or build my own MLOps processes is in place. That&#8217;s not true. You need to understand that we are solving a particular set of problems fundamentally.</em></strong></p></blockquote>



<p>I think what good looks like is when you feel that your MLOps systems and solutions are making your life as a data scientist or an ML engineer easier. We&#8217;ll go through, I suppose, through the chat, the iterations that I can go through and how you can start small and scale up.</p>



<p>Fundamentally for me, you&#8217;re doing this well if it&#8217;s making your life easier. That can manifest in multiple ways, which you can dive into, but it could just be a developer experience is easier, but also you see an uptick in things like the <a href="https://www.cloudbees.com/blog/dora-devops-metrics-bandwagon'" target="_blank" rel="noreferrer noopener nofollow">DORA metrics</a> from the DevOps world.&nbsp;</p>


<div class="case-study-numbered-list">
    <h2></h2>
    <ul>
                    <li><span>1</span>Is your time to live reducing? <br />
</li>
                    <li><span>2</span>Is the number of field deployments reducing? <br />
</li>
                    <li><span>3</span>Is the general performance improving? </li>
            </ul>
</div>



<p>These things are not just making your lives easier but also for your customers&#8217; lives easier. Good to me looks like it&#8217;s something that helps you do ML more repeatably and scalably but also ultimately impacts your customers in a positive way.</p>



<h2>How to set up a good MLOps system?</h2>



<p><strong>Stephen: </strong>Great. What does it take to set up a good system? At the high level anyways.</p>



<p><strong>Andy:</strong> I think you need to break down the problem into its constituent parts. I mentioned some of that before, but your first system should always be, I think, relatively rudimentary<strong>.</strong> I&#8217;m a huge believer in bootstrapping your capability, as I call it. I&#8217;ve spoken about this in the past, so you shouldn&#8217;t go into this problem thinking, I want to solve all of those pieces I mentioned at the top of the call and one goal because you&#8217;ll do that for five years, and by that time, your business problems disappeared, your customer base is gone. It&#8217;s very important that you pick what&#8217;s the most pressing pain point for me, as a group, as a team, as a data scientist, and as an organization, and chase that first.</p>



<p>Your initial MLOps systems, in my view, should always be ones that do the very basics in terms of<strong> <a href="/blog/machine-learning-model-management" target="_blank" rel="noreferrer noopener">model management</a> </strong>and<strong> <a href="/blog/ml-experiment-tracking" target="_blank" rel="noreferrer noopener">experiment tracking</a></strong> first. You need to have some way of understanding the experiments you&#8217;ve run when you&#8217;re building the model. There are tons of tools that do this, we can go into specific tools later, but you need to really have a way of tracking the different experiments you&#8217;ve got.</p>



<p>You then need to have a way of tracking, as I mentioned before that the model artifacts you generate through those processes. You don&#8217;t just want to run a thousand experiments trying different hyperparameters. You also need to say, this is the best model, how do I store it somewhere in the target so I can use it later?</p>



<p>You then need to have a way of monitoring your ML solution. You need to start thinking, How do I know when the performance is drifting? What does performance drift look like for me? That can be very basic, again, it can be very much, you define one performance metric that you think is the most important, you then define some scheduled thing that goes and pulls relevant data, runs a simple query on it, and then outputs to a file somewhere. That&#8217;s you still doing MLOps, it&#8217;s not the most sophisticated approach in the world, but it&#8217;s good enough for that version zero.</p>



<div id="blog-cta-intext-block_75e4bbc58e460172e3812aa4d68a0c28" class="blog-cta-intext">
  <h3 class="blog-cta-intext__title">May interest you</h3>
  <div class="blog-cta-intext__content"><p><img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f449.png" alt="👉" class="wp-smiley" style="height: 1em; max-height: 1em;" /> <a href="/blog/best-ml-experiment-tracking-tools" target="_blank" rel="noopener">15 Best Tools for ML Experiment Tracking and Management</a></p>
<p><img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f449.png" alt="👉" class="wp-smiley" style="height: 1em; max-height: 1em;" /> <a href="/blog/ml-model-monitoring-best-tools" target="_blank" rel="noopener">Best Tools to Do ML Model Monitoring</a></p>
</div>
  </div>


<p>Then I think you need to fundamentally, just think as well, what are the practices you need to develop to keep building on top of that. Do you have the right software engineering capability in your team? Do you have the right understanding of integration points, et cetera, et cetera? I think you start small and then iterate up, I would say. Again, you should see the uptick in those different metrics that you&#8217;ve hopefully typified at the beginning of your journey.</p>



<h2>Difference between an ML system and an MLOps system</h2>



<p><strong>Stephen:</strong> Is there any clear difference between me talking about an ML system and an MLOps system? Because the way I think is I just want to deploy something out there. I&#8217;m not thinking of any experiment tracking and anything like that, I just want to put a model out there. Maybe you can give that a clear distinction.</p>



<p><strong>Andy: </strong>Absolutely,<strong> </strong>I think it&#8217;s a really good question, actually.</p>



<blockquote class="wp-block-quote"><p><strong><em>You can take machine learning models through to production or build a solution and think you&#8217;re not doing MLOps, but realistically, you&#8217;re just doing MLOps very badly.&nbsp;</em></strong></p></blockquote>



<p>What I mean by that is, you build your model, you ramp up in a pipeline, you&#8217;ve run that pipeline in some way, if you don&#8217;t have any tracking of your experiments, any tracking of the model artifacts, if you&#8217;re not monitoring the end result, you&#8217;re almost not doing MLOps, but the MLOps you&#8217;re doing is just the most basic possible, which is where I assume everything operationally is fine. It&#8217;s like MLOps version 0.00.</p>



<p>I think it is important that some element of this from the ground up, any ML solution to my main task has to have some element of MLOps in it. Now whether you disentangle that into a different system is an interesting question.&nbsp;</p>



<blockquote class="wp-block-quote"><p><strong><em>MLOps, to me, is a bit more general than just I know, as we&#8217;re focusing on systems tonight, but it&#8217;s also a set of holistic practices and a way of viewing the world right. It&#8217;s like DevOps was for software engineering, it&#8217;s just about understanding that the solution you&#8217;re building won&#8217;t just be built, and then you can forget about it. It&#8217;s a living, breathing thing.</em></strong></p></blockquote>



<p>That&#8217;s very particular in ML and machine learning, obviously, where we have retraining requirements, et cetera. You could separate it into different systems and have it kind of hook in multiple places in your ML solution, but to me, MLOps practices should be embedded within what you&#8217;re doing as an ML practitioner anyway. Then it&#8217;s just a question for that particular organization, team, et cetera, whether it&#8217;s separate systems or it&#8217;s just embedded within the tools you&#8217;re using.</p>



<h2>How to scale an MLOps system</h2>



<p><strong>Stephen: </strong>I think we have a clear distinction now. You spoke about the very basic version 0.00. How would you differentiate the very basic V0 to V1? How can we start thinking that we are at V0, how is it different from moving to V1, V2, and then start iterating going forward?</p>



<p><strong>Andy: </strong>Any problem you&#8217;re solving you will optimize in certain dimensions versus others. You only have finite time, energy, and effort to expend.&nbsp;</p>



<p>To my mind,<strong> version zero</strong> is about maybe dropping down on repeatability, scalability in a sense and just optimizing for understanding the basic principles and really going through the process end to end.</p>



<div id="blog-cta-intext-block_b6b94a504b5ac70423a9171fcd58f799" class="blog-cta-intext">
  <h3 class="blog-cta-intext__title">Read also </h3>
  <div class="blog-cta-intext__content"><p><a href="/blog/how-to-scale-ml-projects">How to Scale ML Projects – Lessons Learned from Experience</a></p>
</div>
  </div>


<p>I often think that in any team I&#8217;ve built up or worked in, the first problem we go through, all of you probably on the call can sympathize with this. It&#8217;s not great when I look back, but the point was to go through that process the first time. In MLOps, what that means is just doing some basic exporting of your models somewhere and just solving the problem in any way. Again, it could be very rudimentary, but is it simply the case of the name of your pickle or the joblibfile telling you the model version? That can be very much version zero because what you&#8217;re optimizing the first time is what the entire end-to-end process looks like.</p>



<p>Then for me,<strong> version 1, 2, 3</strong>, et cetera is about starting to move the other way and upping the quality, repeatability, and scalability. It&#8217;s up to you and your particular use case, which you optimize first. I think just anything you can do to make it as simple as possible will help in all these dimensions. If the code you&#8217;re building&#8217;s modular, if the systems you&#8217;re building reference good architecture patterns if everything&#8217;s quite distinct and embodies separation of concerns, that&#8217;s often a good sign. Once you get to the most sophisticated, so version N, where N is quite large, I&#8217;d say you&#8217;re very much at the case where scaling from one use case to 1000 use cases shouldn&#8217;t scare you too much.</p>



<p>There are some problems maybe to work out there. Maybe the bill you&#8217;ll have to fit for the infrastructures concerning you, but you know that the processes and toolset you&#8217;ve put in place is one that can scale that way. And that’s the stage I am in NatWest as we’ve built our MLOps capabilities that way.. I&#8217;d say it&#8217;s about that, version zero is about optimizing, just understanding the process, building out the initial principles, and learning a lot. Version 1, 2, and 3 are about iterating on that and building something much more repeatable.</p>



<h2>What should small teams prioritize while building an MLOps system?</h2>



<p><strong>Stephen: </strong>I think one thing this podcast focuses a lot on is the <strong>reasonable scale teams</strong>. In the<a href="https://www.youtube.com/watch?v=YeTjgzllGqw&amp;ab_channel=NeptuneAI" target="_blank" rel="noreferrer noopener nofollow"> second episode</a>, we have this call with <a href="https://www.linkedin.com/in/jacopotagliabue/" target="_blank" rel="noreferrer noopener nofollow">Jacopo</a>, and I think it was similar, a lot of things we discussed building, just starting small, putting out something there that solves a problem, and iterating going forward.</p>



<div id="blog-cta-intext-block_b384a17fc089e13404a15b3515a68908" class="blog-cta-intext">
  <h3 class="blog-cta-intext__title">Check the podcast&#8217;s written version</h3>
  <div class="blog-cta-intext__content"><p><a href="/blog/mlops-reasonable-scale-jacopo-tagliabue" target="_blank" rel="noopener">Setting up MLOps at a Reasonable Scale With Jacopo Tagliabue</a></p>
</div>
  </div>


<p>In your opinion, if we are looking at a team that has six people, maybe two data scientists, three data scientists, one Ops engineer, and then they have just, say, three, four, or a handful of models of production. They are building starters.&nbsp;</p>



<p>What advice would you have for such a team? Just thinking about that problem first, and then thinking about what components they need to start setting up first just to ensure that they&#8217;re showing that immediate ROI before they start thinking about, &#8220;Oh, I want to build a bigger platform and house lots of models and scale up,&#8221; and things like that.</p>



<p><strong>Andy: </strong>I was actually in a similar scenario a few years ago. When I started out, I was in a scale-up of 12 people. I was head of data science and machine learning, which meant I was in charge of just myself because I was the only data scientist. Very similar scenario, very resource-constrained, and had a few software engineers who would help. I think in that scenario, you have to really think about how to not reinvent the wheel. I mentioned doing things in a very rudimentary way. Thankfully, now, there are so many tools, and packages out there that you can do things in a rudimentary way in terms of you&#8217;ve maybe not solved all of the scaling issues you know you&#8217;ll come up against, but you can at least leverage what&#8217;s out there.</p>



<p>There are lots of great packages in Python, there are lots of great tools that have open-source or freemium models where you can at least get started. I&#8217;d recommend doing your research and understanding which of these can you leverage and which of these can you use in a way that means you build a minimal set of workaround that really leverages it as much as possible. Harking back to some of the stuff we&#8217;ve already mentioned, keep it simple as well. I believe this for&nbsp; ML model development as well, always start with the simplest case. If you can solve it with linear regression, don&#8217;t go to a neural network.</p>



<p>The same thing applies to MLOps systems. If you can solve it from a cron job and a Python script, do a cron job and a Python script first and then start probing it, understanding in the later iterations. &#8220;Why would that fall down, or cron&#8217;s not very stable?&#8221; &#8220;It&#8217;s got some issues, I should go this way.&#8221; Maybe move towards more sophisticated orchestration pieces or whatever the particular part of the problem you want to go after is.</p>



<p>One thing that is not covered there is that I think any ML team at that scale has to really focus on data quality upfront because that&#8217;s very intimately tied to the MLOps challenge. If you have very poor data quality, no matter how good your ML engineers and your AI engineers are, your performance is going to be all over the place. You&#8217;re going to be triggering incidents. You&#8217;re going to be retraining and debugging that model all the time.</p>



<p>That&#8217;s just not something that you can do when you&#8217;re that small. You can&#8217;t absorb all your time doing these instant management issues.</p>



<blockquote class="wp-block-quote"><p><strong><em>I think making sure the data quality is really good upfront is also an important one that I would say applies to any skill, but particularly when you&#8217;re small and when you&#8217;re very resource constrained.</em></strong></p></blockquote>



<h2>Baseline tool stack for an MLOps system</h2>



<p><strong>Stephen: </strong>I would love to zoom into your early experience a little bit, before NatWest. What&#8217;s your typical baseline tool stack? You are thinking about this problem firsthand, and then you just want to put a few things together. What are those components you really prioritize just on a general level? Are there hidden blind spots that teams would often miss when thinking about the components they need to put together for their first MLOps systems?</p>



<p><strong>Andy:</strong> Good question. I think we can often in this field get very attracted by the shiniest tools that seem to have the slickest videos or really cool demos and cool UI. That sometimes belies the importance of more fundamental things like you&#8217;re mentioning. For me, one huge thing that I always come up against and I always think is fundamentally important is <strong><a href="/blog/best-workflow-and-pipeline-orchestration-tools" target="_blank" rel="noreferrer noopener">orchestration</a></strong>. If you have a very clean orchestration layer, a very simplified orchestration layer, and <a href="https://airflow.apache.org/" target="_blank" rel="noreferrer noopener nofollow">Apache Airflow</a> in particular is amazing for this. In my book, I talk about managed workflows with Apache Airflow, the AWS-managed service for this.</p>



<p>If you have that orchestration layer in place and you can schedule your pipelines and create the processes that will then trigger other processes, you can then start building very sophisticated things very quickly. Even if you don&#8217;t have a tool that has an amazing bias or explainability tool set or an amazing model monitoring capability, you can do what I mentioned before and have the basic Python script running. Something like Airflow, a really good orchestration layer, means that you&#8217;re still doing that from a very solid foundation and solid base.</p>



<p>Then eventually, you can swap out a simple Python script for a very fancy ML tool. I think my baseline tool stack is to solve your orchestration problem and then solve for me almost the other two I mentioned, the model management and model monitoring problem is really important. Again, just start small, and do that from simple Python scripts first. A very important one that is a blind spot, I think, is how complex it is to do model management. Things like<a href="https://mlflow.org/" target="_blank" rel="noreferrer noopener nofollow"> MLflow,</a> <a href="https://www.comet.com/site/" target="_blank" rel="noreferrer noopener nofollow">Comet</a>, and lots of other tools, are solving a very acute problem. The quicker you can use something like that, I think you&#8217;ll find that it makes your life a lot easier.</p>



<div id="blog-cta-intext-block_f088eabe24df38fb7b65665e29abcefb" class="blog-cta-intext">
  <h3 class="blog-cta-intext__title">Check also </h3>
  <div class="blog-cta-intext__content"><p>Deep dive into the differences between <a href="/vs/comet">Neptune and Comet</a>, and <a href="/vs/mlflow">Neptune and MLflow</a>.</p>
</div>
  </div>


<p>I&#8217;d almost chase after model management before I would monitor. It&#8217;s far easier for me to imagine how to code up some monitoring logic and vanilla Python than it is to build a model management piece of software. That&#8217;s a very complex problem. In the previous teams I worked in, that was always a challenge for us, as we didn&#8217;t have a tool necessarily off the shelf ready for us. We spent a lot of time building these horrible JSONs that tracked where our model artifacts were and what data we used for things. Say, if we can get orchestration, then model management sorted, everything else you can do in the first instance with quite a vanilla Python, it&#8217;s my feeling. Then you can build on that as much as you need to.</p>



<h2>Solving the buying vs. building dilemma</h2>



<p><strong>Stephen: </strong>I think the reality of most teams is that maybe they hire one data scientist or an ML engineer to come and beat the full system. We have this argument in the community that platforms are not enough. You have platforms that claim to be able to solve the end-to-end problem, and so forth, and then you find that inflexibility. Do you have any argument against buying platforms as a system or something, especially for early-stage teams?</p>



<p><strong>Andy:</strong> I love this question because it&#8217;s a perennial debate. I think it relates to what I said about the shiny new tools and the fixation we sometimes have.&nbsp;</p>



<blockquote class="wp-block-quote"><p><strong><em>I think tools, platforms, SaaS, PaaS, all of these solutions will only help if you know what you&#8217;re doing in the first place. If you subscribe to a silver bullet methodology where you think, &#8220;You know what, I buy this thing, I spend a million dollars,&#8221; or I&#8217;m a much smaller company, few thousand dollars or whatever, &#8220;I&#8217;m going to buy this tool that&#8217;s going to solve things.&#8221; You&#8217;ll just find that you&#8217;re facing the same challenges, but now in front of a shiny UI, and you&#8217;re burning through lots of cash.</em></strong></p></blockquote>



<p>Back to the point, we mentioned before, I would much rather teams go through building up what they can themselves, the exception maybe being the orchestration piece and model management piece. There are lots of open-source tools that do this. There are lots of open-source tools that are able to help you with those things. So, I would say, see what you can get with open-source tooling. There&#8217;s also great open-source tooling for generally building ML and MLOps pipelines as well.</p>



<p>If you can get to a stage where you&#8217;re like, &#8220;Actually, there&#8217;s an acute need for something else,&#8221; then invest the money. If you put the cart before the horse, as it were, you&#8217;ll just burn a lot of money and be very disappointed because you&#8217;ve not solved the fundamental problem. The fundamental problems are often more process-specific and architecture-design-specific, but not really what&#8217;s the best tool. You can always spend more money on tools, but if you don&#8217;t stick them together properly, I think you&#8217;re going to run into trouble.</p>



<h2>How to implement an MLOps system well while being an early-stage team?</h2>



<p><strong>Stephen: </strong>Yes, and speaking about the processes, what are some practices that you think would enable these early-stage teams to think about these systems properly and properly implement them?</p>



<p>I watched one of <a href="https://www.youtube.com/watch?v=l1uhE9fEfo8&amp;ab_channel=MLOps.community" target="_blank" rel="noreferrer noopener nofollow">your podcasts with the MLOps community</a>, and there, you talked about the chasm between idea and production, and in the middle there, you have this bridge, this gap that needs to be filled. I think beyond just the tool which you&#8217;ve spoken about, there are also some practices that can make things work. Some, like culture, you can view as a team of try thinking the more systems properly. What are those practices that you think the teams should start thinking about at the early stage when thinking about systems?</p>



<p><strong>Andy: </strong>I&#8217;m glad someone watched that podcast. The thing that I often come back to is what I call the four P&#8217;s:</p>


<div class="case-study-numbered-list">
    <h2></h2>
    <ul>
                    <li><span>1</span>people, <br />
</li>
                    <li><span>2</span>process,</li>
                    <li><span>3</span>pattern, <br />
</li>
                    <li><span>4</span>products. </li>
            </ul>
</div>



<p>Just covering them very quickly. I think you can never be too early thinking about this.&nbsp;</p>



<p>On the <strong>people </strong>front, and we alluded to this earlier, we should always avoid thinking there&#8217;s a unicorn person out there who can do everything we need. We need hybrid teams, blended teams that have very complementary capabilities. You can do that with any skill. As long as you have two or even three people, you can still get that blend of to have the software, engineering knowledge, the ML knowledge, and then something maybe in the middle, or a translation layer towards the business, et cetera. People are such an important part of that. Who are the people you have, do they complement each other and work well together?</p>



<p><strong>Product </strong>is about just really what this whole podcast is about, ensuring you understand that you&#8217;re building intense systems that eventually impact customers, and how are you going to think about that differently from just a normal piece of prototype code? Well, you understand the products, people expect them to work. That implies that you should be testing a lot. Do you have testing processes in place? Are you already thinking about unit testing, integration testing, or regression testing? If you&#8217;re not, start thinking about them because that&#8217;s the only way to build scalable and usable products.</p>



<p>Then also, think about the user experience. The user, in this case, might not be an actual person but maybe another system. There they have a clear interface and clear contract to consume from. It could be something as simple as, does the other system have access to the same S3 bucket, or is done by results? That&#8217;s the sort of thing you sometimes have to think about in that product space, but then to your particular question around process and patterns, which I think is really linked.</p>



<p><strong>Pattern,</strong> for me, is about, whether you are using really well-known architecture patterns, or at least ones that make sense, using microservice architectures, or using architectures that are already there and used by some of the best companies out there?&nbsp;</p>



<p>Then on the <strong>process </strong>side, do you have clearer development guardrails? Do you know how to develop high-quality codes? Do you at least know how you&#8217;ll improve the quality of your code? Can you do anything you can to automate? The earlier you can embed CI/CD practices. I think anything, <a href="https://github.com/features/actions" target="_blank" rel="noreferrer noopener nofollow">GitHub actions</a> are a great example, <a href="https://www.jenkins.io/" target="_blank" rel="noreferrer noopener nofollow">Jen</a>kins, and all of these other tools for having CI/CD servers in place means that that process can go faster and faster.</p>



<p>I think the earlier you think about all of these things together, you&#8217;ll start doing the right things that then put you in place for the future. When you&#8217;re challenged more on issues like massive scale structure of things like account security, networking, et cetera, this can come a bit later.&nbsp;</p>



<blockquote class="wp-block-quote"><p><strong><em>Those four P&#8217;s for me is fundamental that you should always think about for any team really, but it’s especially pertinent into ML and MLOps teams, I think, that people, pattern and process and product viewpoints.</em></strong></p></blockquote>



<h2>Skill set required for building an MLOps system</h2>



<p><strong>Stephen: </strong>I think if you speak to teams about this, most teams would agree that it&#8217;s really hard, just linking these four P&#8217;s together and just trying to coordinate around the people, the process, the product, and the pattern itself. How do you think that teams can appropriately achieve this? A good follow-up question as well to that is, who should I hire for us to build up that system, my first MLOps system? Should I hire a data scientist or an MLOps engineer or an ML engineer or stuff like that?</p>



<p><strong>Andy: </strong>Good. In terms of who you should hire first, the challenges there are, it’s a trick question. If you&#8217;re hiring one person, you&#8217;re already in unicorn thinking, which I think we should avoid. If you&#8217;re hiring two people, which I would always recommend, a minimum viable team, at least, I think you need <strong>someone with a good data engineering mindset</strong>. As I mentioned, data is super important.</p>



<p>Then it could be a data scientist, ML engineer, MLOps engineer, it doesn&#8217;t matter what they call themselves, but I think <strong>someone that complements that data knowledge quite strongly with the knowledge of pipelining</strong>, for example. How do you build ML pipelines? How do you build MLOps pipelines? By which we mean all the things we mentioned before, something that runs into some monitoring, something that checks what model version to build, but that will require a few basic things.</p>



<p>They&#8217;ll need to understand models and maybe even build those models or use the off-the-shelf model. Even if it&#8217;s an ML engineer, but they&#8217;re reusing hugging face models, that&#8217;s absolutely fine as well, but there needs to be someone who understands models because how else can you build the monitoring logic behind that and understand what you&#8217;re doing with model artifact management.</p>



<p>They also need to have enough software engineering capability that they can start building these systems that are robust and reliable. That&#8217;s the whole point of Ops and MLOps, is, you&#8217;re not just doing a flash in the pan, you&#8217;re building something that has to work again and again and again. You really need that software engineering capability there as well. I think, how can they coordinate? That is, it&#8217;s always a challenge, but I think splitting it out into those four P&#8217;s helps me rationalize it often and always break down the problem.</p>



<p>From the people side, we&#8217;ve just discussed that we&#8217;ve got the complementary capabilities, the cover-off, the key things, and patterns. Again, leverage what&#8217;s out there, don&#8217;t reinvent the wheels. AWS has their architecture LENS framework, I think it&#8217;s called<a href="https://docs.aws.amazon.com/wellarchitected/latest/userguide/lenses.html" target="_blank" rel="noreferrer noopener nofollow"> AWS LENS</a>, where they publish a lot of really well-detailed architectures. Even if you&#8217;re not on AWS, you can at least see them and see the different components and how they interact together. That ticks off patterns.</p>



<p>Product is really the end goal, constantly iterating towards the business goal, but just always thinking about reliability and robustness, not just breach testing. Then, in terms of process, it&#8217;s back to that point of it starting small and iterating. Go through the first cycle, constantly iterate working, and you improve. A lot of those problems will not be new problems, there will be problems solved in software engineering. Leverage the software development and software engineering ecosystem as well.</p>



<h2>Is simple Ops the right first step?</h2>



<p><strong>Stephen: </strong>This is something that is quite popular in the MLOps community, and the thing is to keep the first model simple, or you should try to get the infrastructure right, especially when you&#8217;re trying to deploy your first model or just deploy your first iteration pushing it out there. Can you elaborate on something like this, this particular statement?</p>



<p><strong>Andy: </strong>Yes, definitely. I 100% agree with this, we should always start simple Ops. The key difference that I maybe alluded to earlier between just doing some research-based data science and machine learning versus building a product with MLOps at its core is that you are thinking about it as something that has to work again and again and again.</p>



<p>Your <strong>simple sklearn model</strong> that does some regression, you could take one of them, the Boston housing data set, that&#8217;s a very simple thing, lots of tutorials on that. Building that ML model is really easy. What is difficult is if you start saying something like this can be particular to the business use case, but how am I going to serve a request to score with that across 50,000 or 100,000 users? How am I going to run that, maybe as a batch or maybe as a live microservice that can be requested by API?&nbsp;</p>



<div id="blog-cta-intext-block_ca33202763b86fbf1ba2333bbb68e79c" class="blog-cta-intext">
  <h3 class="blog-cta-intext__title">May be useful</h3>
  <div class="blog-cta-intext__content"><p>Check how you can <a href="https://docs.neptune.ai/integrations/sklearn/" target="_blank" rel="noopener">track and analyze sklearn model training</a>.</p>
</div>
  </div>


<p>I think all of that may be flavored by the business you&#8217;re operating in.</p>


<div class="custom-point-list">
<ol><li>If you know you&#8217;re supporting a customer-facing web application, you&#8217;re maybe going to naturally go down the REST API microservices route.</li><li>If you&#8217;re servicing a very large organization, as a lot of overnight processes, like we often do, you&#8217;re maybe thinking more in a batch way and thinking about using far more scalable technologies like PySpark, et cetera.&nbsp;</li></ol>
</div>


<blockquote class="wp-block-quote"><p><strong><em>Just mapping out what your business challenges are going to be then automatically starts helping you make architecture and design decisions.</em></strong></p></blockquote>



<p>Then the model piece becomes, again, something that you can always iterate on, but fundamentally, it&#8217;s probably relatively simple compared to these other choices you&#8217;ve had to make. Then you start thinking, &#8220;Right, how do I set that up in a minimum viable product fashion? How do I stick it all together back to the orchestrator and make sure that it&#8217;s all running at the right time, et cetera?&#8221; Definitely, I agree with that, and I think always draw back to the business problem you&#8217;re trying to solve.</p>



<p>That also drives your operational considerations and what MLOps looks like for you.&nbsp;</p>


<div class="custom-point-list">
<ol><li>Again, if you&#8217;re running a big batch process every night, do you really need some sort of complicated live streaming of metrics for your model? No, that&#8217;s overkill. You maybe just need, again, a nightly report that runs just after your batch production.&nbsp;</li><li>If you&#8217;re doing a very scalable, customer-facing application, if you do need some more real-time metrics, and you maybe also need to resurrect and be aware of some of the metrics or just classic from DevOps, who&#8217;s the memory, the CPU utilization, all of these things, and not just what&#8217;s the recall of my model.</li></ol>
</div>


<p>Then another challenge that, this just came to mind, I think it&#8217;s important as well, that comes from the business problem is, you&#8217;ll also be able to put constraints on those processes in a different way. Something I&#8217;ve come up across quite a lot is the business once they understand what you&#8217;re trying to do with MLOps will often say, &#8220;Right. I want to know how the model&#8217;s doing every single day.&#8221; I&#8217;ll say, &#8220;Right. How often can I get the truth data for this model,&#8221; and they&#8217;ll say every month. Automatically, there&#8217;s a disconnect between the business, the technology, and how it&#8217;s all implemented together. Just always drawing back to the business problem really helps hone that in a bit and understand what choices you need to make.</p>



<h2>Busting myths about MLOps systems</h2>



<p><strong>Stephen:</strong> Curious, are there any misconceptions in the MLOps community about MLOps systems that you don&#8217;t agree with? Let&#8217;s trash it out here.&nbsp;</p>



<p><strong>Andy: </strong>Oh, that I don&#8217;t agree with? I think the tooling obsession annoys me a bit. I think we do forget as a community the importance of just good design, good processes, and good software development techniques. We often get obsessed about the latest demos and the latest big announcements, and I do it as well. I&#8217;ll sign up for about 10 webinars that I&#8217;ll never attend on all these different technologies because there&#8217;s a new release or a new version, but I think we often forget just how relatively simple the problem we&#8217;re trying to solve in MLOps is.</p>



<p>To my mind, there are only a few different pipelines you&#8217;re building,&nbsp;</p>


<div class="case-study-numbered-list">
    <h2></h2>
    <ul>
                    <li><span>1</span>You&#8217;re building your training pipeline to reach in the model. <br />
</li>
                    <li><span>2</span>You&#8217;re building the inference pipeline to bring out the results. <br />
</li>
                    <li><span>3</span>And then you&#8217;re building an MLOps type link to do the other bits. </li>
            </ul>
</div>



<p>That&#8217;s it fundamentally. I think I do sometimes dislike how we will oversell the importance of specific tool choices.</p>



<blockquote class="wp-block-quote"><p><strong><em>You should very much be comfortable swapping out tools as you progress through your journey, as they solve slightly different flavors of the problem.</em></strong></p></blockquote>



<p>Your model management software starts with the open-source version, then you say, &#8220;Actually, I want the benefit of being supported at an enterprise level, so I&#8217;ll switch to a paid model with this provider,&#8221; but it should not fundamentally change the design you have. If your design is tightly coupled to your tool choice, you&#8217;ve made a massive error I think, because it should really be a swap out. You&#8217;re just doing a different API call, or you&#8217;re just writing to a different location.</p>



<p>You shouldn&#8217;t be so tied to a product that you suffer from lock-in, which is one of the other dangers you can have as well. Either with cloud providers or specific tools, you can just become so wedded to it that when you have to change because the companies went bust or the tool&#8217;s no longer available because of major upgrades, you have to fix so much technical depth.&nbsp;</p>



<p>I think that the big bugbear for me is the obsession with tooling. I am maybe being too harsh, there are a lot of people I know who work in the community on really amazing tools, and there are amazing tools out there, especially in the open-source community.</p>



<blockquote class="wp-block-quote"><p><strong><em>I just think as practitioners trying to build these solutions for organizations, we shouldn&#8217;t just think there&#8217;s a silver bullet out there. We really need to bring it back to basics while the processes we need to develop how we&#8217;re making sure they&#8217;re robust and monitored, then we have good metrics for their performance, and then just work against that.</em></strong></p></blockquote>



<h2>Role of MLOps in scaling a system</h2>



<p><strong>Stephen: </strong>We have a question from the MLOps Community. This person says, &#8220;I&#8217;m working towards building a restaurant<strong> recommendation system</strong> that provides the restaurant&#8217;s business similarity between two people&#8217;s tastes. I&#8217;m planning to deploy it as a web app. How should I proceed towards this, knowing that I&#8217;ll be scaling this to 50 or more users? Then how does MLOps come into this particular scenario?&#8221;</p>



<p><strong>Andy: </strong>It sounds like this person&#8217;s thinking of a very particular use case which is great for bringing this to life. If you&#8217;re building a web application that&#8217;s going to have 50 or 50,000 users, and you have to run this ML process in the background, this recommendation engine. What&#8217;s important to my mind at the beginning is not putting all that together in your head because you&#8217;ll be a bit overwhelmed, and you&#8217;ll probably try and solve it all at the one time and create some spaghetti code or something that&#8217;s not very modular.</p>



<div id="blog-cta-intext-block_c3c2395fa6512dd9a6aca3bde60feb94" class="blog-cta-intext">
  <h3 class="blog-cta-intext__title">Read also </h3>
  <div class="blog-cta-intext__content"><p><img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f449.png" alt="👉" class="wp-smiley" style="height: 1em; max-height: 1em;" /> <a href="/blog/recommender-systems-lessons-from-building-and-deployment" target="_blank" rel="noopener">Recommender Systems: Lessons From Building and Deployment</a></p>
<p><img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f449.png" alt="👉" class="wp-smiley" style="height: 1em; max-height: 1em;" /> <a href="/blog/how-to-test-recommender-system" target="_blank" rel="noopener">How to Test a Recommender System</a></p>
</div>
  </div>


<p>If you separate out all those pieces, you can start breaking down the problem and understanding how to solve each one. The front end, right, how you&#8217;re going to scale the front end to 50,000 users? This is done all the time, so look online and see how that&#8217;s done for general web applications, that&#8217;s not something new. You have the frontend system, you have the application database that stores the right data needed to run the actual web interface. Think about that user experience, get good UX design in place if possible. That&#8217;s a solved problem, but that&#8217;s the first piece, that&#8217;s only the entry point to the rest of the solution.&nbsp;</p>



<p>You then have to run your recommendation engine updates, your retraining, your re-running and I&#8217;m not a recommendation engine expert at all. I&#8217;ll just assume that&#8217;s a black box in a sense. You fundamentally have this process that you need to run a very large scale that can often be very computationally intense. Put that on one side.&nbsp;</p>


<div class="custom-point-list">
<ul><li>How do you solve that problem, and how often are you going to run those updates?</li><li>Do you have the infrastructure you need in place?</li><li>Do you need to think about things like auto-scaling for particularly chunky or compute updates et cetera?&nbsp;</li><li>Do you need to think about moving to the cloud in order to service these questions?</li></ul>
</div>


<p>I think you think about that recommendation engine update as its own process and separate that as well.&nbsp;</p>



<p>You then have the interaction between the two. This is something I love talking about is interfaces and contracts.&nbsp;</p>


<div class="custom-point-list">
<ul><li>What&#8217;s the contract going to be between your frontend and your recommendation engine?&nbsp;</li><li>Is it a direct API call to some basic Flask app or something else that just surfaces the results of the recommendation engine?&nbsp;</li><li>Is it going to be something a bit more complex?</li><li>Is it actually going to be that a recommendation engine can work in a batch offline modes and the web application just needs to pick up the results from some S3 bucket or other location?</li></ul>
</div>


<p>Then where MLOps comes into really is making sure all that hangs together from the ML point of view. The recommendation engine,&nbsp;</p>


<div class="custom-point-list">
<ul><li>How do you know that&#8217;s performant?&nbsp;</li><li>How are you going to check in on the status of that?&nbsp;</li><li>Then what actions are you going to take based on it – that&#8217;s your model monitoring process?&nbsp;</li><li>How often are you going to run that as well if it&#8217;s a nightly batch process?&nbsp;</li><li>Do you run the MLOps pipeline every night as well to check the monitoring performance or do you run that less frequently?&nbsp;</li><li>How do you manage the actual versions of the recommendation engine as well because you might want to do rollbacks if something goes wrong? You start thinking about that as well.</li></ul>
</div>


<p>Then finally, I think in this scenario, orchestration comes in through again that decision about it is a dynamic request that triggers an ML process. In which case, you&#8217;re thinking about event-driven architectures things like <a href="https://kafka.apache.org/" target="_blank" rel="noreferrer noopener nofollow">Kafka </a>and <a href="https://cloud.google.com/pubsub/architecture#:~:text=Pub%2FSub%20is%20divided%20into,servers%20on%20the%20data%20plane." target="_blank" rel="noreferrer noopener nofollow">Pub/Sub </a>architectures. Is it actually again it&#8217;s really about retrieving results on the back of a user request? It&#8217;s on a batch schedule which case you could do a cron job or some other scheduler or go back to Apache Airflow, which I mentioned earlier.</p>



<blockquote class="wp-block-quote"><p><strong><em>I think the key thing is breaking it down into those constituent parts and then working out how you solve each of those problems individually. Then which are the most pressing problems you&#8217;re not sure how to solve go and get the results and help you need to understand that.</em></strong>&nbsp;</p></blockquote>



<p>For me, the bit that I would be less comfortable with is the frontend. I have no UX skills, and no understanding of how to build a good front end at all, so I would need help to do that. The other pieces, I&#8217;d probably know. MLOps is really about managing that back end and just making sure it&#8217;s monitored, looked after, and then retrained appropriately when necessary.</p>



<h2>Building a strong foundation for future scalability</h2>



<p><strong>Stephen: </strong>Yes, and following up to that particular question, I think one of the challenges when building your first ML system, for example, is that when you want to scale, it literally just breaks. Especially if you don&#8217;t take that scale into account, your system just breaks apart. Maybe you&#8217;re running a cron job and a Python script, and then you don&#8217;t know how to handle 50k requests, 100k requests because all of a sudden, the business has grown. How do you start thinking about scalability at the onset when building a good first MLOps system?</p>



<p><strong>Andy:</strong> There are some choices you can make earlier to help with these things. If your problem lends you to, say a batch process type architecture, or at least some element of batch processing, doing things like building everything around PySpark, for example, means that scalability is really a question of how much infrastructure you&#8217;re willing to pay for.</p>



<p>I&#8217;ll come back to AWS just because it&#8217;s the one I&#8217;m most familiar with, but it applies to the other cloud providers. If I use their own cloud smart clusters, the <a href="https://aws.amazon.com/emr/" target="_blank" rel="noreferrer noopener nofollow">Elastic Map Reduce</a> clusters, you can start putting in things like auto-scaling policies and scaling up that infrastructure as and when you need it, and the fundamentals of your code don&#8217;t need to change. I think that&#8217;s a decision you can make early on because I can run PySpark on my laptop, it&#8217;s probably not much use, it&#8217;s a very small cluster, but I can also run it on a 10,000-node cluster if I have the capability to pay for it, so even though choices like that.</p>



<p>If you think more about the microservice architecture we were talking a little bit about before, you start thinking about things like load balancers.&nbsp;</p>


<div class="custom-point-list">
<ul><li>Do you start bringing in load balancers?&nbsp;</li><li>Do you have the expertise for that?&nbsp;</li><li>Do you understand how to write this traffic appropriately, the networking, and the questions that come from that?&nbsp;</li><li>Then are you able to spawn up the processes you need to maybe run your ML model?&nbsp;</li></ul>
</div>


<p>Then I would start leveraging things like maybe cloud functions or Lambda as it is in AWS, so very lightweight pieces of code that you can run in an extremely scalable fashion where you don&#8217;t have to think about that underlying infrastructure.</p>



<blockquote class="wp-block-quote"><p><strong><em>I think in general the cloud just helps with scalability, you pay a little bit of a premium per unit but you just sleep better at night because you know scaling is very much easier there. I would always recommend that you at least explore and understand the options available in cloud. Then if you are building in a more on-prem or local way, you at least do know whether you know you can port up to clouds.</em></strong></p></blockquote>



<p>A great example there is PySpark. Even if I&#8217;m running on my laptop but building everything in PySpark porting it up to use a very scalable cloud service later is not a big deal. Whereas it would be a big deal if I had written everything in vanilla Python and serial Python, and then I had to refactor for scalability. There are some choices and thoughts you can make early in the process that should help, I think.</p>



<h2>Timeline for the entire project and managing expectations</h2>



<p><strong>Sabine: </strong>We have a question in chat from Penny Johnson. Penny is asking, &#8220;Can you give an insight into actual timescales in the field from model ideation to solution delivery, monitoring cycles, and improvements? Also, how do you manage the business expectations for these?&#8221;</p>



<p><strong>Andy: </strong>Oh, great question. This is what my job is. I was worried about this. I&#8217;ve actually just finished a webinar on the work we&#8217;ve done on decreasing our time to value in that way, so I can mention some of the figures and things now because it&#8217;s in the public domain.&nbsp;</p>



<p>Typically for us, we have a finding before we adopt some of the basic practices on tooling, one, on the cloud. We were roughly a year to get a model from ideation to production. Now, that is long, and the big factor there for us was being in financial services, there&#8217;s a lot of governance and all the things we have to go through.</p>



<p>In my previous job, we were delivering a model every quarter, roughly, and I would say that&#8217;s more feasible, for every few months taking something through ideation to production. If you&#8217;re talking about iterative improvements on models rather than a full, which I think, Penny, you&#8217;re asking about the whiteboard through to a solution, iterative improvements, I think, can be a sprint or sub-sprint level if you&#8217;ve got good CI/CD practices in place.</p>



<p>We&#8217;ve now been able in NatWest to get that down to around three months, that once-a-quarter level, for any particular team because we invested time, energy, and effort in building out an MLOps platform that used SageMaker and surrounding ecosystems. That was a case of harking back to what I mentioned before. We understood how to do the processes well first, then we understood the fundamentals and what good design looked like. We upgraded everything and were able to refactor all of the internal processes as well for that.</p>



<p>I&#8217;d say, for me, that a once-a-quarter piece is reasonable for most scaled organizations. The scale factor comes in for larger organizations because they can do a lot in parallel, so, for a smaller company, once a quarter means literally one ML model for the company, for a huge organization like NatWest, it might mean hundreds per quarter. MLOps building, et cetera, should just be part of that process, so as long as you&#8217;ve got the understanding, the design, the architecture in place, you should be able to also incorporate that into that once-a-quarter cycle. That&#8217;s just my view. I think there&#8217;ll be a million different views in this across the piece.</p>



<p>Managing expectations is the fun part, so I think you&#8217;ve got a few challenges you need to overcome.&nbsp;</p>


<div class="custom-point-list">
<ol><li>One is really making sure that your stakeholders, your customers, your colleagues understand the benefits of machine learning in the first place, but they also understand why MLOps is important. It&#8217;s one thing to solve a problem using a machine learning algorithm.&nbsp;</li><li>The next thing is to make sure you can solve it every day for the rest of the time, and that&#8217;s where the MLOps piece comes in.</li></ol>
</div>


<p>You need to win hearts and minds so that they understand why you&#8217;re investing time, energy, effort, and money into developing these extra bits of the solution, the monitoring capabilities, the model management pieces, et cetera. I think you really need to do that. Then they understand why you&#8217;re investing all of that in those extra pieces, but again, it comes down to just simplifying, making sure they understand the basics of what you&#8217;re doing and you&#8217;re constantly updating them and making sure they understand when you&#8217;re running into issues and where the bottlenecks are. That means you can then iterate on that for your next set of projects.</p>



<p>I&#8217;ve had to do that many a time where we thought we&#8217;d deliver in three months, and then it&#8217;s taken a lot longer. As long as you&#8217;re clearly communicating with your stakeholders, they&#8217;ll understand that those expectations are shifting, and they&#8217;ll buy into that, I think. That&#8217;s a really great question. I think it&#8217;s one of the most important challenges is stakeholder management.</p>



<h2>Fitting retraining scenario in an MLOps system</h2>



<p><strong>Sabine: </strong>Yes, for sure. It&#8217;s not just about the tech stack, but sometimes, it&#8217;s about the people and communications and all of that. We have another question from Nabil Belgasmi. &#8220;If we want our ML models to be retrained automatically on new data, what is the impact of this requirement on a simple MLOps workflow?&#8221;</p>



<p><strong>Andy:&nbsp;</strong></p>



<blockquote class="wp-block-quote"><p><strong><em>If you want it trained on new data every single time, first of all, you could challenge that assumption, &#8220;Do I really need it trained on new data every time, or do I just need it trained when there&#8217;s a shift in the distribution of the data or when there&#8217;s a drop in performance”.</em></strong></p></blockquote>



<p>Let&#8217;s assume the build for your question we&#8217;ve settled on when new data is in we want to train the model. The downstream impacts on your MLOps processes and system are going to be that, okay, retrain the model, but what do I do with it? What is your process for determining if it&#8217;s the actual model that goes through into production?</p>



<p>What you don&#8217;t want to do is just automatically push it to production. That&#8217;s the first got you, because it could be retrained, and it&#8217;s really bad, terrible. It&#8217;s basically absolute garbage. You push it through production, everything goes down, so you need some mechanism to view the performance of that newly trained model, not just the one already in production. That&#8217;s again where your model management and other tools come in. Can you try the appropriate metadata and the metrics for the training run?</p>



<p>I think what&#8217;s important as well, if you are thinking about pushing a specific model into production, is, &#8220;Have you actually simulated production-like conditions? Do you have a test environment setup that runs in the same way as your production model?&#8221;</p>



<p>Actually, I missed this earlier from your question, Stephen, but I&#8217;ve seen a lot of developer models with a particular set of assumptions. They have five years of data, for example. They&#8217;ve done their training, test, and validation split. Then they think it&#8217;s going to work in production, but actually, in production, you get a thousand new records every single day, and they don&#8217;t know what the fluctuation of behavior is going to be like. I think you need to make sure that if going to Nabil, retraining, and then pushing a model into production, you have some testing that&#8217;s available that shows how it will work on production-like data coming in at the cadence and the frequency that it will.</p>



<p>Then, underpinning all of that, back to the process point earlier, is you need a good MLOps process in place to say, &#8220;That&#8217;s actually okay. That fits within our operational risk profiles. That&#8217;s on the governance control.&#8221; Whatever the mechanism is. You need basically a way to say, &#8220;Push the button. Push it into production.&#8221; I would say all of that has to be factored into what your MLOps system looks like and is capable of doing.</p>



<p>It&#8217;s a really good question. A lot of people come up against this very quickly, and I think the most important pieces there are operating or testing in some sort of production-like environment and then having a good process for saying, &#8220;Everything&#8217;s okay. I can now push it into production.&#8221; Things like blue-green deployments, as you might sometimes hear about if you give that a google, it talks about how you can run basically the two solutions in parallel, but one&#8217;s in an air-gapped environment. Then, once you&#8217;re happy, just swap them around seamlessly. Building in processes like that is often a really good MLOps practice as well.</p>



<h2>Other questions</h2>



<p><strong>Stephen: </strong>We have another question from the MLOps community. This time it&#8217;s from Jeremy.</p>



<p>Jeremy says he&#8217;s walking on with a very early-stage startup with a single model and pretty low inference volume. What&#8217;s the best training work to put in place? In the old days, he&#8217;d wrap the model in a Flask API, make an image, push it to a K-cluster as part of a CI/CD process. Now, he&#8217;d have an Airflow script as well that will daily retrain the model with new data from production. He would do regression testing and then trigger the deployment process. He&#8217;d have a data warehouse where he keeps inference data to be able to run the performance queries and stuff like that. This seems like a lot for him.&nbsp;</p>



<p>He&#8217;s thinking, &#8220;What&#8217;s the easiest way to do this today?&#8221; Is there something that consolidates this entire- his very, very modular paths? What&#8217;s your opinion?</p>



<p><strong>Andy: </strong>The first thing I&#8217;m thinking is that Jeremy seems to know what he&#8217;s talking about, which is good. I think this perfectly embodies what I mentioned earlier about learning the basics and the fundamentals first. What Jeremy&#8217;s mapped out there is all of the correct processes and the correct handovers, so you&#8217;ve got the model. How is that hosting, and what infrastructures are running on? How is that all being updated? That&#8217;s all the <strong>Flask</strong>, <a href="https://kubernetes.io/docs/concepts/overview/components/" target="_blank" rel="noreferrer noopener nofollow"><strong>K</strong></a>AS, and the CI/CD. Then, starting to think about Airflow, he mentioned all the right words around regression testing, et cetera.</p>



<p>This question then is about how you then simplify and improve that moving forward. One thing I would say is look at the tooling out there to see what can take some of those pain points away for you. If you&#8217;re on particularly low inference volumes, are you maybe able to do that as a matching process that&#8217;s easily scheduled? Are you also overcomplicating given tools out there, how do the pipelines all stick together? I don&#8217;t think he mentioned that too much, but a great example is SageMaker.</p>



<p><a href="https://aws.amazon.com/sagemaker/" target="_blank" rel="noreferrer noopener nofollow">AWS SageMaker</a> is their MLOps tool, but it also provides really good, strong, opinionated guidance on writing good pipelines. An open-source thing that does a very similar thing is <a href="https://zenml.io/home" target="_blank" rel="noreferrer noopener nofollow">ZenML</a>. There&#8217;s a lot of tooling out there that may be able to simplify some of the development activities he&#8217;s doing.&nbsp;</p>



<p>Then, in terms of the <a href="https://kubernetes.io/docs/concepts/overview/components/" target="_blank" rel="noreferrer noopener nofollow">KAS cluster</a>, which is really about the hosting, you can start thinking again about if you were on SageMaker, for example, which takes care of the hosting and the underlying infrastructure for you. You can put in scaling policies.</p>



<p>There are solutions out there that take away some of that pain for you, but it sounds like he&#8217;s got all the right pieces in place, it&#8217;s just about maybe now moving onto that question of what particular bit I should invest the time and effort in optimizing.</p>



<p>I&#8217;m not sure Jeremy&#8217;s maybe not on, but I&#8217;m not sure where the particular pain point is. If it&#8217;s really scaling out that Flask API, maybe moving away from a Flask API, SageMaker endpoint, or some other tooling that provides a similar way to host the model is a good idea. Could you do it all in a cloud function or an AWS Lambda? Actually, it keeps all the rest of the pieces, but actually, you&#8217;ve got really vast scalability because it&#8217;s a very simple sklearnmodel. You could host that in AWS Lambda very easily.</p>



<p>I think he has to be strategic about what pieces he solves, but there are a lot of tools and capabilities out there that will help. Now that he&#8217;s got that fundamental design piece in place. Now I&#8217;m okay with tooling, I know before I poo-pooed it, but I think he&#8217;s got the fundamental design in place. You can now iterate and find open-source and paid-for tooling that will solve some of these problems.</p>



<p><strong>Stephen: </strong>Right, and we have another question from the MLOps community. This time from Fatima, and she asks, &#8220;What are the challenges they are going to face if they want to shift an SME, a small and medium scale enterprise, from Level 0 MLOps that&#8217;s their typical Google reference, Level 0 MLOps to Level say 1 or 2 MLOps of end-to-end automation for example and stuff like that? They have a very basic system which works manually, but then they want to move things to automate the end-to-end pipeline.”</p>



<p><strong>Andy: </strong>I like this because I reference the same maturity model in my job, so that&#8217;s good. A big piece of that is inherent, and the question is automation versus the manual piece, as you put it, Stephen. For me, that is a question of orchestration and CI/CD practices. How do you orchestrate the different processes you&#8217;re going to need? I&#8217;m assuming you&#8217;ve gone through level zero and you&#8217;ve done that work we mentioned earlier where you&#8217;ve got. You&#8217;ve gone through the processes end to end the first time, which maybe similar to Jeremy&#8217;s question. You know how to solve all of these in principle, what you&#8217;re now moving to is to do it in a really scalable fashion.</p>



<p>For it to be automated, it needs to all be orchestrated in a way that&#8217;s very safe if a component fails and also one that you can monitor quite successfully. All of that needs to come together. Then I think back to Nabil&#8217;s question quite nicely earlier, did you start thinking about what&#8217;s triggering the automated process, and how are you doing that triggering? Is it off of a Kafka topic, or is it off of drift in your monitoring metrics? Is it still a manual process? Because you could automate a lot of stuff but still have a manual person pulling the trigger and pushing the button at the beginning.</p>



<p>Sometimes that&#8217;s good if you have specific requirements for risk and control governance behaviors like we do in financial services. Sometimes it&#8217;s important to have a human in that process. It&#8217;s not completely automated, but it&#8217;s pretty much, I&#8217;m happy, goal, and then everything&#8217;s automated.</p>



<p>I think the key things that will move the needle for you, Fatima are those orchestration questions, the triggering questions, and then the CI/CD questions as well that will help you move towards a more continuous and automated way of iterating your solution.</p>



<p><strong>Stephen: </strong>Cool, and we have one final question from the community, and this person asks, &#8220;Should I worry about the reliability of my MLOps system when building it at an early stage? Since my use case is mission critical, I am currently building an ML product for the healthcare industry.&#8221;</p>



<p><strong>Andy: </strong>Yes, so should you care about the reliability of your MLOps system? Absolutely because if you don&#8217;t have a reliable MLOps system, how do you know you have a reliable ML system full stop?&nbsp;</p>



<p>I think in a mission-critical scenario like this, and I&#8217;ve not worked in healthcare, but I&#8217;ve worked for a distributed energy provider before where we were building models that would detect if a generator would catch fire, so I&#8217;d call that mission-critical as well. What we found was that, again, pulling it back to the very simplest, most basic, and robust things we wanted to track really helped because then what you can do is work very closely with the people with the domain knowledge and your business colleagues to really understand what are the one or two metrics that we absolutely must track.</p>



<p>I think that helps with reliability because you&#8217;re not going to build a super complex MLOps system, right? You&#8217;re not going to build something with 10 million lines of code that&#8217;s doing 100,000 different metrics. You&#8217;re going to just focus on the one or two that&#8217;s absolutely critical to know the system is performing and is doing things in the right way.&nbsp;</p>



<p>Then I think you need to make sure that you&#8217;re checking in on that MLOps system as well. The MLOps system is there to monitor your ML system, but how do you get a view of how everything is performing? To me, that comes naturally from just having an MLOps system because if you&#8217;re going to look at the results of your MLOps process either in a dashboard or some other database that you&#8217;re querying, just the act of doing that is you checking that your MLOps system is working.</p>



<p>I think you should worry about the reliability of it, but the main thing that will help you reduce the worry is simplifying it down to the key metrics, the KPIs just building the minimum viable product that does that robustly, and then testing the hell out of it. Make sure you test it until you&#8217;ve broken it in a million different ways, and you&#8217;re very happy that this small minimum viable product will not break. Then you&#8217;re good to go, I think.</p>



<p><strong>Sabine: </strong>It&#8217;s time to wrap things up. I&#8217;m sure there would have been a lot more, we would have loved to pick Andy&#8217;s brain about. Thank you so much, Andy, you really demystified MLOps, at least for me, so thanks very much.</p>



<p>Before we wrap it up, Andy, how can people follow what you&#8217;re doing online and maybe connect with you?</p>



<p><strong>Andy: </strong>Yes, so you can find me on LinkedIn. Just search <a href="https://www.linkedin.com/in/andymcmahon629/" target="_blank" rel="noreferrer noopener nofollow">Andy McMahon</a>, you&#8217;ll hopefully work out which one it is. On Twitter, I&#8217;m <a href="https://twitter.com/electricweegie" target="_blank" rel="noreferrer noopener nofollow">@ElectricWeegie</a>. I also have a website, a blog that I&#8217;ve not updated in a while, which is electricweegie.com. Then finally, you can follow and subscribe to the <a href="https://open.spotify.com/show/4bRuzmU97MWPDTf2FxkEEc" target="_blank" rel="noreferrer noopener nofollow">“AI Right?” Podcast</a>, it&#8217;s on Spotify, Acast or wherever you get your podcasts.</p>



<p>Then you&#8217;ll hear me, <a href="https://www.linkedin.com/in/megan-a-stamper/?originalSubdomain=uk" target="_blank" rel="noreferrer noopener nofollow">Megan Stamper</a>, who&#8217;s one of the heads of machine learning at the BBC, and <a href="https://www.linkedin.com/in/krismcfadyen/" target="_blank" rel="noreferrer noopener nofollow">Kris </a>McFadyen, who&#8217;s someone I know very well, who does a lot of recruitment. You&#8217;ll hear us talk about the Scottish tech team if that&#8217;s your particular interest, but we talk about lots of really cool stuff in ML and MLOps there as well. Those are the main places to find me.</p>



<p><strong>Sabine</strong>: Right, so plenty of channels to run into you. We&#8217;ll be back in two weeks on August 3rd, and next time our guest will be<a href="https://www.linkedin.com/in/aesroka/" target="_blank" rel="noreferrer noopener nofollow"> Adam Sroka</a>, we&#8217;ll be talking about <a href="https://www.youtube.com/watch?v=iykUtOagU_8&amp;list=PLKePQLVx9tOczB07_oyDkdQqdNiqLV-zX&amp;index=10&amp;ab_channel=NeptuneAI" target="_blank" rel="noreferrer noopener">building an MLOps culture on your team</a>.</p>




<div id="author-box-new-format-block_4d615ecfebd44bf7e7f2c691dbf2d3b4" class="article__footer article__author">
  <div class="article__authorImage">
          <img width="230" height="230" src="https://i0.wp.com/neptune.ai/wp-content/uploads/Andy-McMahon.jpeg?fit=230%2C230&amp;ssl=1" class="article__authorImage-img" alt="Andy McMahon" decoding="async" data-attachment-id="72084" data-permalink="https://neptune.ai/your-first-mlops-system-with-andy-mcmahon/attachment/andy-mcmahon" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Andy-McMahon.jpeg?fit=800%2C800&amp;ssl=1" data-orig-size="800,800" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Andy McMahon" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Andy-McMahon.jpeg?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Andy-McMahon.jpeg?fit=800%2C800&amp;ssl=1" />      </div>

  <div class="article__authorContent">
          <h3 class="article__authorContent-name">Andy McMahon</h3>
    
          <p class="article__authorContent-text">Head of MLOps at NatWest Group. A data scientist and ML engineer with extensive experience of taking analytics solutions from ideation to production, particularly interested in the challenge of deploying machine learning based software products at scale. 
 Author of the book “Machine Learning Engineering with Python”.</p>
    
          <ul class="article__authorSocial">
        <li class="article__authorSocial-single article__authorSocial-name">Follow me on</li>
                  <li class="article__authorSocial-single"><a href="https://twitter.com/electricweegie" class="article__authorSocial-tw" target="_blank"></a></li>
        
                  <li class="article__authorSocial-single"><a href="https://www.linkedin.com/in/andrew-p-mcmahon/" class="article__authorSocial-lk" target="_blank"></a></li>
        
                  <li class="article__authorSocial-single"><a href="electricweegie.com" class="article__authorSocial-www" target="_blank"></a></li>
              </ul>
    
  </div>
</div>


<div class="is-layout-flow wp-block-group"><div class="wp-block-group__inner-container">
<hr class="wp-block-separator has-css-opacity"/>



<p class="has-text-color" style="color:#4455a6"><strong>READ NEXT</strong></p>



<h2>MLOps at a Reasonable Scale [The Ultimate Guide]</h2>



<p class="has-small-font-size">9 mins read | Author Jakub Czakon | Updated July 27th, 2022</p>


<div id="block_5ffc75def9f8e" class="separator separator-10"></div>



<p>For a couple of years now,&nbsp;<a href="https://neptune.ai/blog/mlops">MLOps</a>&nbsp;is probably the most (over)used term in the ML industry. The more models people want to deploy to production, the more they think about how to organize the Ops part of this process.&nbsp;</p>



<p>Naturally, the way to do&nbsp;<strong>MLOps has been shaped by the big players</strong>&nbsp;on the market – companies like Google, Netflix, and Uber. What they did for the community was (and is) great, but they were solving their MLOps problems.&nbsp;</p>



<p>And most companies don’t have their problems. The&nbsp;<strong>majority of ML teams operate on a smaller scale</strong>&nbsp;and have different challenges. Yet they are the biggest part of the ML industry, and they want to know what’s the best way to do MLOps at their scale, with their resources and limitations.&nbsp;</p>



<p>The<strong>&nbsp;reasonable scale MLOps</strong>&nbsp;is addressing this need. “Reasonable scale” is a<a href="https://towardsdatascience.com/ml-and-mlops-at-a-reasonable-scale-31d2c0782d9c" target="_blank" rel="noreferrer noopener">&nbsp;term coined last year by Jacopo Tagliabue</a>, and it refers to the companies that:</p>


<div class="custom-point-list">
<ul><li>have ml models that generate hundreds of thousands to tens of millions of USD per year (rather than hundreds of millions or billions)</li><li>have dozens of engineers (rather than hundreds or thousands)</li><li>deal with terabytes (rather than petabytes or exabytes)</li><li>have a finite amount of computing budget</li></ul>
</div>


<p>In this guide, you’ll learn more about the MLOps at a reasonable scale, and you’ll get to know the best practices, templates, and examples that will help you understand how to implement them in your work.&nbsp;</p>



<p>Before that, let’s do a few steps back and see why we even talk about reasonable scale.</p>


<a class="button continous-post blue-filled" href="/blog/mlops" target="_blank">
    Continue reading -&gt;</a>



<hr class="wp-block-separator has-css-opacity"/>
</div></div>
<p>The post <a rel="nofollow" href="https://neptune.ai/blog/first-mlops-system-with-andy-mcmahon">Your First MLOps System: What Does Good Look Like? With Andy McMahon</a> appeared first on <a rel="nofollow" href="https://neptune.ai">neptune.ai</a>.</p>
]]></content:encoded>
					
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">72034</post-id>	</item>
		<item>
		<title>5 Tools That Will Help You Setup Production ML Model Testing</title>
		<link>https://neptune.ai/blog/tools-ml-model-testing</link>
		
		<dc:creator><![CDATA[Nilesh Barla]]></dc:creator>
		<pubDate>Fri, 30 Sep 2022 11:15:04 +0000</pubDate>
				<category><![CDATA[Machine Learning Tools]]></category>
		<category><![CDATA[MLOps]]></category>
		<category><![CDATA[mlops]]></category>
		<guid isPermaLink="false">https://neptune.ai/?p=71745</guid>

					<description><![CDATA[<p>Developing a machine learning or a deep learning model seems like a relatively straightforward task. It usually involves research, collecting and preprocessing the data, extracting features, building and training the model, evaluation, and inference. Most of the time is consumed in the data-preprocessing phase, followed by the modeling-building phase. If the accuracy is not up [&#8230;]</p>
<p>The post <a rel="nofollow" href="https://neptune.ai/blog/tools-ml-model-testing">5 Tools That Will Help You Setup Production ML Model Testing</a> appeared first on <a rel="nofollow" href="https://neptune.ai">neptune.ai</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<p><a href="/categories/ml-model-development" target="_blank" rel="noreferrer noopener">Developing a machine learning or a deep learning model</a> seems like a relatively straightforward task. It usually involves research, collecting and preprocessing the data, extracting features, building and training the model, evaluation, and inference. Most of the time is consumed in the <a href="/blog/data-preprocessing-guide" target="_blank" rel="noreferrer noopener">data-preprocessing phase</a>, followed by the modeling-building phase. If the accuracy is not up to the mark, we then reiterate the whole process until we find a satisfactory accuracy. </p>



<p>The difficulty arises when we want to put the model into production in the real world. The model often does not perform as well as it did during the training and evaluation phase. This happens primarily because of <a href="/blog/concept-drift-best-practices" target="_blank" rel="noreferrer noopener">concept drift</a> or data drift and issues concerning data integrity. Therefore, testing an ML model becomes very important so that we can understand its strengths and weaknesses and act accordingly. </p>



<p>In this article, we will discuss some of the tools that can be leveraged to test an ML model. Some of these tools and libraries are open-source, while others require a subscription. Either way, this article will fully explore the tools which will be handy for your MLOps pipeline. </p>



<h2>Why does model testing matter?</h2>



<p>Building upon what we just discussed, model testing allows you to pinpoint a bug or area of concern that might cause the prediction capability of the model to degrade. This can happen over time gradually or in an instant. Either way, it is always good to know in which area they might fail and which features can cause them to fail. It exposes flaws, and it can also bring new insights to light. Essentially, the idea is to make a robust model that can efficiently handle uncertain data entries and anomalies. </p>



<p>Some of the benefits of model testing are:</p>


<div class="case-study-numbered-list">
    <h2></h2>
    <ul>
                    <li><span>1</span>Detecting model and data drift<br />
</li>
                    <li><span>2</span>Finding anomalies in dataset<br />
</li>
                    <li><span>3</span>Checking data and model integrity<br />
</li>
                    <li><span>4</span>Detect possible root cause for model failure<br />
</li>
                    <li><span>5</span>Eliminating bugs and errors<br />
</li>
                    <li><span>6</span>Reducing false positives and false negatives <br />
</li>
                    <li><span>7</span>Encouraging retraining the model over a certain period of time<br />
</li>
                    <li><span>8</span>Creating a production-ready model<br />
</li>
                    <li><span>9</span>Ensuring robustness of ML model<br />
</li>
                    <li><span>10</span>Finding new insights within the model</li>
            </ul>
</div>



<h3>Is model testing the same as model evaluation?</h3>



<p>Model testing and evaluation are similar to what we call diagnosis and screening in medicine.&nbsp;</p>



<p><strong>Model evaluation</strong> is similar to diagnosis, where the performance of the model is checked based upon certain metrics like F1 score or MSE loss. These metrics do not provide a focused area of concern. </p>



<div id="blog-cta-intext-block_d1673f5fecd9b26cff36f4679f22c5c1" class="blog-cta-intext">
  <h3 class="blog-cta-intext__title">Learn more</h3>
  <div class="blog-cta-intext__content"><p><img src="https://s.w.org/images/core/emoji/14.0.0/72x72/27a1.png" alt="➡" class="wp-smiley" style="height: 1em; max-height: 1em;" /> <a href="/blog/the-ultimate-guide-to-evaluation-and-selection-of-models-in-machine-learning" target="_blank" rel="noopener">The Ultimate Guide to Evaluation and Selection of Models in Machine Learning</a></p>
<p><img src="https://s.w.org/images/core/emoji/14.0.0/72x72/27a1.png" alt="➡" class="wp-smiley" style="height: 1em; max-height: 1em;" /> <a href="/blog/f1-score-accuracy-roc-auc-pr-auc" target="_blank" rel="noopener">F1 Score vs ROC AUC vs Accuracy vs PR AUC: Which Evaluation Metric Should You Choose?</a></p>
</div>
  </div>


<p><strong>Model testing</strong> is similar to diagnosis, where a certain test like the invariance test and unit test aims to find a particular issue in the model.&nbsp;</p>



<h2>What will a typical ML software testing suite include?</h2>



<p>A machine learning testing suite often includes testing modules to <strong>detect different types of drifts</strong> like concept drift and data drift, which can include covariant drift, prediction drift, and so on. These issues usually occur within the dataset. Most of the time, the dataset&#8217;s distribution changes over time, affecting the model’s capability to accurately predict the output. You will find that the frameworks we will discuss will contain tools to detect data drifts. </p>



<p>Apart from testing data, the ML testing suite contains tools to test the <strong>model&#8217;s capability to predict, </strong>as well as<strong> overfitting, underfitting, variance and bias</strong> et cetera. The idea of the testing framework is to inspect the pipeline in the three major phases of development: </p>


<div class="custom-point-list">
<ul><li>data ingestion, </li><li>data preprocessing, </li><li>and model evaluation. </li></ul>
</div>


<p>Some of the frameworks like Robust Intelligence and Kolena rigorously test the given ML pipeline automatically in these given areas to ensure a production-ready model. </p>



<p>In essence, a machine learning suite will contain:</p>


<div class="custom-point-list">
<ol><li><strong>Unit tests</strong> that operate on the level of the codebase,</li><li><strong>Regression tests</strong> replicate bugs from the previous iteration of the model that is fixed,</li><li><strong>Integration tests</strong> simulate conditions and are typically longer-running tests that observe model behaviors. These conditions can mirror the ML pipeline, including preprocessing phase, data distribution, et cetera. </li></ol>
</div>

<div class="wp-block-image">
<figure class="aligncenter size-large"><img data-attachment-id="71569" data-permalink="https://neptune.ai/5-tools-that-will-help-you-setup-production-ml-model-testing-1" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-1.png?fit=1333%2C321&amp;ssl=1" data-orig-size="1333,321" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="5-tools-that-will-help-you-setup-production-ML-model-testing-1" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-1.png?fit=300%2C72&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-1.png?fit=1024%2C247&amp;ssl=1" decoding="async" width="1024" height="247" src="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-1.png?resize=1024%2C247&#038;ssl=1" alt="A workflow of software development " class="wp-image-71569" data-recalc-dims="1"/><figcaption><em>The image above depicts a typical workflow of software development | <a href="https://www.jeremyjordan.me/testing-ml/" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>


<div id="blog-cta-intext-block_da657b78c485ddf1c2607b0e532603e5" class="blog-cta-intext">
  <h3 class="blog-cta-intext__title">Read also </h3>
  <div class="blog-cta-intext__content"><p><img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f449.png" alt="👉" class="wp-smiley" style="height: 1em; max-height: 1em;" /> <a href="/blog/ml-model-testing-teams-share-how-they-test-models" target="_blank" rel="noopener">ML Model Testing: 4 Teams Share How They Test Their Models</a></p>
<p><img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f449.png" alt="👉" class="wp-smiley" style="height: 1em; max-height: 1em;" /> <a href="/blog/automated-testing-machine-learning" target="_blank" rel="noopener">Automated Testing in Machine Learning Projects [Best Practices for MLOps]</a></p>
</div>
  </div>


<h2>What are the best tools for machine learning model testing?</h2>



<p>Now, let’s discuss some of the tools for testing ML models. This section is divided into three parts: open-source tools, subscription-based tools, and hybrid tools.&nbsp;</p>



<h3>Open-source model testing tools</h3>



<h4>1. DeepChecks</h4>



<p><a href="https://deepchecks.com/" target="_blank" rel="noreferrer noopener nofollow">DeepChecks</a> is an open-source Python framework for testing ML Models &amp; Data. It basically enables users to test the ML pipeline in three different phases:</p>


<div class="custom-point-list">
<ol><li><strong>Data integrity test </strong>before the preprocessing phase.</li><li><strong>Data Validation, </strong>before the training, mostly while splitting the data into training and testing, and</li><li><strong>ML model testing</strong>.</li></ol>
</div>

<div class="wp-block-image">
<figure class="aligncenter size-large"><img data-attachment-id="71570" data-permalink="https://neptune.ai/5-tools-that-will-help-you-setup-production-ml-model-testing-2" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-2.png?fit=1999%2C477&amp;ssl=1" data-orig-size="1999,477" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="5-tools-that-will-help-you-setup-production-ML-model-testing-2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-2.png?fit=300%2C72&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-2.png?fit=1024%2C244&amp;ssl=1" decoding="async" width="1024" height="244" src="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-2.png?resize=1024%2C244&#038;ssl=1" alt="" class="wp-image-71570" data-recalc-dims="1"/><figcaption><em> The image above shows the schema of three different tests that could be performed in an ML pipeline | <a href="https://docs.deepchecks.com/stable/getting-started/when_should_you_use.html" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>


<p>These tests can be performed all at once and even independently. The image above shows the schema of three different tests that could be performed in an ML pipeline.&nbsp;</p>



<h5>Installation</h5>



<p>Deepchecks can be installed using following the pip command:</p>



<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);">pip install deepchecks &gt; <span class="hljs-number" style="color: teal;">0.5</span><span class="hljs-number" style="color: teal;">.0</span></pre>



<p>The latest version of Deepcheck is 0.8.0.&nbsp;</p>



<h5>Structure of the framework&nbsp;</h5>



<p>DeepChecks introduces three important terms: <strong>Check</strong>, <strong>Condition</strong> and <strong>Suite</strong>. It is worth noting that these three terms together form the core structure of the framework.&nbsp;</p>



<p><strong>Check</strong></p>



<p>It enables a user to inspect a specific aspect of the data and models. The framework contains various classes which allow you to check both of them. You can do a full check as well. Here are a couple of such checks:</p>


<div class="custom-point-list">
<ol><li><strong><em>Data inspecting</em></strong><em> </em>involves inspection around data drift, duplication, missing values, string mismatch, statistical analysis such as data distribution et cetera<em>.</em> You can find the various data inspecting tools within the check module. The check module allows you to precisely design the inspecting methods for your datasets. These are some of the tools that you will find for data inspection:</li></ol>
</div>

<div class="custom-point-list">
<ul><li>&nbsp;&#8216;DataDuplicates&#8217;,</li><li>&nbsp;&#8216;DatasetsSizeComparison&#8217;,</li><li>&nbsp;&#8216;DateTrainTestLeakageDuplicates&#8217;,</li><li>&nbsp;&#8216;DateTrainTestLeakageOverlap&#8217;,</li><li>&nbsp;&#8216;DominantFrequencyChange&#8217;,</li><li>&nbsp;&#8216;FeatureFeatureCorrelation&#8217;,</li><li>&nbsp;&#8216;FeatureLabelCorrelation&#8217;,</li><li>&nbsp;&#8216;FeatureLabelCorrelationChange&#8217;,</li><li>&nbsp;&#8216;IdentifierLabelCorrelation&#8217;,</li><li>&nbsp;&#8216;IndexTrainTestLeakage&#8217;,</li><li>&nbsp;&#8216;IsSingleValue&#8217;,</li><li>&nbsp;&#8216;MixedDataTypes&#8217;,</li><li>&nbsp;&#8216;MixedNulls&#8217;,</li><li>&nbsp;&#8216;WholeDatasetDrift&#8217;</li></ul>
</div>


<p>In the following example, we will inspect whether the dataset has duplicates or not. We will import the class DataDuplicates from the checks module and pass the dataset as a parameter. This will return a table containing relevant information on whether the dataset has duplicate values or not. </p>



<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);"><span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">from</span> deepchecks.checks <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">import</span> DataDuplicates, FeatureFeatureCorrelation
dup = DataDuplicates()
dup.run(data)
</pre>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img data-attachment-id="71571" data-permalink="https://neptune.ai/5-tools-that-will-help-you-setup-production-ml-model-testing-3" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-3.png?fit=1246%2C502&amp;ssl=1" data-orig-size="1246,502" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="5-tools-that-will-help-you-setup-production-ML-model-testing-3" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-3.png?fit=300%2C121&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-3.png?fit=1024%2C413&amp;ssl=1" decoding="async" width="1024" height="413" src="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-3.png?resize=1024%2C413&#038;ssl=1" alt="Inspection of dataset duplicates " class="wp-image-71571" data-recalc-dims="1"/><figcaption><em>An example of inspecting if the dataset has duplicates | Source: Author</em></figcaption></figure></div>


<p>As you can see, the table above yields relative information about the number of duplicates present in the dataset. Now let’s see how DeepChecks uses a visual aid to provide the concerning information.&nbsp;</p>



<p>In the following example, we will inspect feature-feature correlation within the dataset. For that, we will import the FeatureFeatureCorrelation class from the checks module.</p>



<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);">ffc = FeatureFeatureCorrelation()
ffc.run(data)
</pre>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img data-attachment-id="71572" data-permalink="https://neptune.ai/5-tools-that-will-help-you-setup-production-ml-model-testing-4" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-4.png?fit=1760%2C1036&amp;ssl=1" data-orig-size="1760,1036" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="5-tools-that-will-help-you-setup-production-ML-model-testing-4" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-4.png?fit=300%2C177&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-4.png?fit=1024%2C603&amp;ssl=1" decoding="async" width="1024" height="603" src="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-4.png?resize=1024%2C603&#038;ssl=1" alt=" Inspection of feature-feature correlation" class="wp-image-71572" data-recalc-dims="1"/><figcaption><em>An example of inspecting feature-feature correlation within the dataset | Source: Author</em></figcaption></figure></div>


<p>As you can see from both examples, the results can be displayed either in the form of a table or a graph, or even both to give relevant information to the user.&nbsp;&nbsp;</p>


<div class="custom-point-list">
<ol start="2"><li><strong><em>The model inspection</em></strong><em> </em>involves overfitting, underfitting, et cetera<em>. </em>Similar to data inspection, you can also find the various model inspecting tools within the check module. These are some of the tools that you will find for model inspection:</li></ol>
</div>

<div class="custom-point-list">
<ul><li>&#8216;ModelErrorAnalysis&#8217;,</li><li>&nbsp;&#8216;ModelInferenceTime&#8217;,</li><li>&nbsp;&#8216;ModelInfo&#8217;,</li><li>&nbsp;&#8216;MultiModelPerformanceReport&#8217;,</li><li>&nbsp;&#8216;NewLabelTrainTest&#8217;,</li><li>&nbsp;&#8216;OutlierSampleDetection&#8217;,</li><li>&nbsp;&#8216;PerformanceReport&#8217;,</li><li>&nbsp;&#8216;RegressionErrorDistribution&#8217;,</li><li>&nbsp;&#8216;RegressionSystematicError&#8217;,</li><li>&nbsp;&#8216;RocReport&#8217;,</li><li>&nbsp;&#8216;SegmentPerformance&#8217;,</li><li>&nbsp;&#8216;SimpleModelComparison&#8217;,</li><li>&nbsp;&#8216;SingleDatasetPerformance&#8217;,</li><li>&nbsp;&#8216;SpecialCharacters&#8217;,</li><li>&nbsp;&#8216;StringLengthOutOfBounds&#8217;,</li><li>&nbsp;&#8216;StringMismatch&#8217;,</li><li>&nbsp;&#8216;StringMismatchComparison&#8217;,</li><li>&nbsp;&#8216;TrainTestFeatureDrift&#8217;,</li><li>&nbsp;&#8216;TrainTestLabelDrift&#8217;,</li><li>&nbsp;&#8216;TrainTestPerformance&#8217;,</li><li>&nbsp;&#8216;TrainTestPredictionDrift&#8217;,</li></ul>
</div>


<p>Example of a model check or inspection on Random Forest Classifier:</p>



<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);"><span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">from</span> deepchecks.checks <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">import</span> ModelInfo
info = ModelInfo()
info.run(RF)
</pre>


<div class="wp-block-image">
<figure class="aligncenter size-large is-resized"><img data-attachment-id="71573" data-permalink="https://neptune.ai/5-tools-that-will-help-you-setup-production-ml-model-testing-5" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-5.png?fit=746%2C1170&amp;ssl=1" data-orig-size="746,1170" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="5-tools-that-will-help-you-setup-production-ML-model-testing-5" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-5.png?fit=191%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-5.png?fit=653%2C1024&amp;ssl=1" decoding="async" src="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-5.png?resize=490%2C768&#038;ssl=1" alt="A model check or inspection on Random Forest Classifier" class="wp-image-71573" width="490" height="768" data-recalc-dims="1" /><figcaption><em>An example of a model check or inspection on Random Forest Classifier | Source: Author&nbsp;</em></figcaption></figure></div>


<p><strong>Condition</strong>&nbsp;</p>



<p>It is a function or attribute that can be added to a Check. Essentially it contains a predefined parameter that can return a pass, fail, or warning results. These parameters can be modified as well accordingly. Follow the code snippet below to get an understanding.&nbsp;</p>



<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);"><span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">from</span> deepchecks.checks <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">import</span> ModelInfo
info = ModelInfo()
info.run(RF)
</pre>


<div class="wp-block-image">
<figure class="aligncenter size-large is-resized"><img data-attachment-id="71574" data-permalink="https://neptune.ai/5-tools-that-will-help-you-setup-production-ml-model-testing-6" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-6.png?fit=1852%2C1166&amp;ssl=1" data-orig-size="1852,1166" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="5-tools-that-will-help-you-setup-production-ML-model-testing-6" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-6.png?fit=300%2C189&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-6.png?fit=1024%2C645&amp;ssl=1" decoding="async" src="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-6.png?resize=908%2C572&#038;ssl=1" alt="A bar graph of feature label correlation" class="wp-image-71574" width="908" height="572" data-recalc-dims="1" /><figcaption><em>An example of a bar graph of feature label correlation | Source: Author</em></figcaption></figure></div>


<p>The image above shows a bar graph of feature label correlation. It essentially measures the predictive power of an independent feature that can predict the target value by itself. When you add a condition to a check as in the example above, the condition will return additional information mentioning the features which are above and below the condition.&nbsp;</p>



<p>In this particular example, you will find that the condition returned a statement stating that the algorithm “<em>Found 2 out of 4 features with PPS above threshold: {&#8216;petal width (cm)&#8217;: &#8216;0.9&#8217;, &#8216;petal length (cm)&#8217;: &#8216;0.87&#8217;}</em>” meaning that features with high PPS are suitable to predict the labels.&nbsp;</p>



<p><strong>Suite</strong>&nbsp;</p>



<p>It is a module containing a collection of checks for data and model. It is an ordered collection of checks. All the checks can be found in the suite module. Below is the schematic diagram of the framework and how it works. </p>


<div class="wp-block-image">
<figure class="aligncenter size-full"><img data-attachment-id="71575" data-permalink="https://neptune.ai/5-tools-that-will-help-you-setup-production-ml-model-testing-7" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-7.png?fit=547%2C601&amp;ssl=1" data-orig-size="547,601" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="5-tools-that-will-help-you-setup-production-ML-model-testing-7" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-7.png?fit=273%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-7.png?fit=547%2C601&amp;ssl=1" decoding="async" width="547" height="601" src="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-7.png?resize=547%2C601&#038;ssl=1" alt="Schematic diagram of suite of checks " class="wp-image-71575" data-recalc-dims="1"/><figcaption><em>The schematic diagram of the suite of checks and how it works | <a href="https://medium.com/@ptannor/new-open-source-for-validating-and-testing-machine-learning-86bb9c575e71" target="_blank" rel="noreferrer noopener nofollow">Source</a>&nbsp;</em></figcaption></figure></div>


<p>As you can see from the image above, the data and the model can be passed into the suites which contain the different checks. The checks can be provided with the conditions for much more precise testing.&nbsp;</p>



<p>You can run the following code to see the list of 35 checks and their conditions that DeepChecks provides:</p>



<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);"><span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">from</span> deepchecks.suites <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">import</span> full_suite
suites = full_suite()
print(suites)


Full Suite: [
	<span class="hljs-number" style="color: teal;">0</span>: ModelInfo
	<span class="hljs-number" style="color: teal;">1</span>: ColumnsInfo
	<span class="hljs-number" style="color: teal;">2</span>: ConfusionMatrixReport
	<span class="hljs-number" style="color: teal;">3</span>: PerformanceReport
		Conditions:
			<span class="hljs-number" style="color: teal;">0</span>: Train-Test scores relative degradation <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">is</span> <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">not</span> greater than <span class="hljs-number" style="color: teal;">0.1</span>
	<span class="hljs-number" style="color: teal;">4</span>: RocReport(excluded_classes=[])
		Conditions:
			<span class="hljs-number" style="color: teal;">0</span>: AUC score <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">for</span> all the classes <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">is</span> <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">not</span> less than <span class="hljs-number" style="color: teal;">0.7</span>
	<span class="hljs-number" style="color: teal;">5</span>: SimpleModelComparison
		Conditions:
			<span class="hljs-number" style="color: teal;">0</span>: Model performance gain over simple model <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">is</span> <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">not</span> less than
…]

</pre>



<p>In conclusion, Check, Condition, and Suites allow users to essentially check the data and model in their respective tasks. These can be extended and modified according to the requirements of the project and for various use cases.&nbsp;</p>



<p>DeepChecks allows flexibility and instant validation of the ML pipeline with less effort. Their strong boilerplate code can allow users to automate the whole testing process, which can save a lot of time.&nbsp;</p>


<div class="wp-block-image">
<figure class="aligncenter size-full"><img data-attachment-id="71576" data-permalink="https://neptune.ai/5-tools-that-will-help-you-setup-production-ml-model-testing-8" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-8.png?fit=1014%2C772&amp;ssl=1" data-orig-size="1014,772" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="5-tools-that-will-help-you-setup-production-ML-model-testing-8" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-8.png?fit=300%2C228&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-8.png?fit=1014%2C772&amp;ssl=1" decoding="async" width="1014" height="772" src="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-8.png?resize=1014%2C772&#038;ssl=1" alt="Graph with distribution checks" class="wp-image-71576" data-recalc-dims="1"/><figcaption><em>An example of distribution checks | <a href="https://deepchecks.com/" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>


<h5>Why should you use this?</h5>


<div class="custom-point-list">
<ul><li>It is open-source and free, and it has a growing community.</li><li>Very well-structured framework. </li><li>Because it has built-in checks and suites, it can be extremely useful for inspecting potential issues in your data and models.</li><li>It is efficient in the research phase as it can be easily integrated into the pipeline.</li><li>If you are mostly working with tabular datasets, then DeepChecks is extremely good. </li><li>You can also use it to check data, model drifts, model integrity, and model monitoring.</li></ul>
</div>

<div class="wp-block-image">
<figure class="aligncenter size-large is-resized"><img data-attachment-id="71577" data-permalink="https://neptune.ai/5-tools-that-will-help-you-setup-production-ml-model-testing-9" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-9.png?fit=1042%2C770&amp;ssl=1" data-orig-size="1042,770" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="5-tools-that-will-help-you-setup-production-ML-model-testing-9" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-9.png?fit=300%2C222&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-9.png?fit=1024%2C757&amp;ssl=1" decoding="async" src="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-9.png?resize=768%2C568&#038;ssl=1" alt="Methodology issues" class="wp-image-71577" width="768" height="568" data-recalc-dims="1" /><figcaption><em>An example of methodology issues | <a href="https://deepchecks.com/" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>


<h5>Key features </h5>


<div class="case-study-numbered-list">
    <h2></h2>
    <ul>
                    <li><span>1</span>It supports both classification and regression models in both computer vision and tabular datasets. <br />
</li>
                    <li><span>2</span>It can easily run a large group of checks with a single call. <br />
</li>
                    <li><span>3</span>It is flexible, editable, and expandable. <br />
</li>
                    <li><span>4</span>It yields results in both tabular and visual formats.<br />
</li>
                    <li><span>5</span>It does not require a login dashboard as all the results, including the visualization, are displayed instantly during execution itself.  And it has a pretty good UX on the go. </li>
            </ul>
</div>


<div class="wp-block-image">
<figure class="aligncenter size-large is-resized"><img data-attachment-id="71578" data-permalink="https://neptune.ai/5-tools-that-will-help-you-setup-production-ml-model-testing-10" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-10.png?fit=1146%2C866&amp;ssl=1" data-orig-size="1146,866" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="5-tools-that-will-help-you-setup-production-ML-model-testing-10" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-10.png?fit=300%2C227&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-10.png?fit=1024%2C774&amp;ssl=1" decoding="async" src="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-10.png?resize=768%2C581&#038;ssl=1" alt="Performance checks " class="wp-image-71578" width="768" height="581" data-recalc-dims="1" /><figcaption><em>An example of performance checks | <a href="https://deepchecks.com/" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>


<h5>Key drawbacks</h5>


<div class="case-study-numbered-list">
    <h2></h2>
    <ul>
                    <li><span>1</span>It does not support NLP tasks. <br />
</li>
                    <li><span>2</span>Deep Learning support is in beta version including computer vision. So results can yield errors. </li>
            </ul>
</div>



<h4>2. Drifter-ML</h4>



<p>Drifter ML is an ML model testing tool specifically written for the Scikit-learn library. It can also be used to test datasets similar to DeepChecks. It has five modules, each very specific to the task at hand.</p>


<div class="custom-point-list">
<ol><li><strong>Classification test: </strong>It enables you to test classification algorithms.</li><li><strong>Regression test: </strong>It enables you to test classification algorithms.</li><li><strong>Structural test: </strong>This module has a bunch of classes that allow testing of clustering algorithms.</li><li><strong>Time Series test: </strong>This module can be used to test model drifts.&nbsp;</li><li><strong>Columnar test: </strong>This module allows you to test your tabular dataset. Tests include sanity testing, mean and median similarity, Pearson’s correlation et cetera.&nbsp;</li></ol>
</div>


<h5>Installation</h5>



<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);">pip install drifter-ml</pre>



<h5>Structure of the framework</h5>



<p>Drifter ML conforms to the Scikit-Learn blueprint for models, i.e., the model must contain a .fit and .predict methods. This essentially means that you can test deep learning models as well since Scikit-Learn has an integrated Keras API. Check the <a href="https://drifter-ml.readthedocs.io/en/latest/introduction.html" target="_blank" rel="noreferrer noopener nofollow">example</a> below.</p>



<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);"><span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;">#Source: https://drifter-ml.readthedocs.io/en/latest/classification-tests.html#lower-bound-classification-measures</span>

<span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">from</span> keras.models <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">import</span> Sequential
<span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">from</span> keras.layers <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">import</span> Dense
<span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">from</span> keras.wrappers.scikit_learn <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">import</span> KerasClassifier
<span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">import</span> pandas <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">as</span> pd
<span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">import</span> numpy <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">as</span> np
<span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">import</span> joblib

<span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># Function to create model, required for KerasClassifier</span>
<span class="hljs-function"><span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">def</span> <span class="hljs-title" style="color: rgb(153, 0, 0); font-weight: 700;">create_model</span><span class="hljs-params">()</span>:</span>
   <span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># create model</span>
   model = Sequential()
   model.add(Dense(<span class="hljs-number" style="color: teal;">12</span>, input_dim=<span class="hljs-number" style="color: teal;">3</span>, activation=<span class="hljs-string" style="color: rgb(221, 17, 68);">'relu'</span>))
   model.add(Dense(<span class="hljs-number" style="color: teal;">8</span>, activation=<span class="hljs-string" style="color: rgb(221, 17, 68);">'relu'</span>))
   model.add(Dense(<span class="hljs-number" style="color: teal;">1</span>, activation=<span class="hljs-string" style="color: rgb(221, 17, 68);">'sigmoid'</span>))
   <span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># Compile model</span>
   model.compile(loss=<span class="hljs-string" style="color: rgb(221, 17, 68);">'binary_crossentropy'</span>, optimizer=<span class="hljs-string" style="color: rgb(221, 17, 68);">'adam'</span>, metrics=[<span class="hljs-string" style="color: rgb(221, 17, 68);">'accuracy'</span>])
   <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">return</span> model

<span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># fix random seed for reproducibility</span>
df = pd.DataFrame()
<span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">for</span> _ <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">in</span> range(<span class="hljs-number" style="color: teal;">1000</span>):
   a = np.random.normal(<span class="hljs-number" style="color: teal;">0</span>, <span class="hljs-number" style="color: teal;">1</span>)
   b = np.random.normal(<span class="hljs-number" style="color: teal;">0</span>, <span class="hljs-number" style="color: teal;">3</span>)
   c = np.random.normal(<span class="hljs-number" style="color: teal;">12</span>, <span class="hljs-number" style="color: teal;">4</span>)
   <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">if</span> a + b + c &gt; <span class="hljs-number" style="color: teal;">11</span>:
       target = <span class="hljs-number" style="color: teal;">1</span>
   <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">else</span>:
       target = <span class="hljs-number" style="color: teal;">0</span>
   df = df.append({
       <span class="hljs-string" style="color: rgb(221, 17, 68);">"A"</span>: a,
       <span class="hljs-string" style="color: rgb(221, 17, 68);">"B"</span>: b,
       <span class="hljs-string" style="color: rgb(221, 17, 68);">"C"</span>: c,
       <span class="hljs-string" style="color: rgb(221, 17, 68);">"target"</span>: target
   }, ignore_index=<span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">True</span>)

<span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># split into input (X) and output (Y) variables</span>
<span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># create model</span>
clf = KerasClassifier(build_fn=create_model, epochs=<span class="hljs-number" style="color: teal;">150</span>, batch_size=<span class="hljs-number" style="color: teal;">10</span>, verbose=<span class="hljs-number" style="color: teal;">0</span>)
X = df[[<span class="hljs-string" style="color: rgb(221, 17, 68);">"A"</span>, <span class="hljs-string" style="color: rgb(221, 17, 68);">"B"</span>, <span class="hljs-string" style="color: rgb(221, 17, 68);">"C"</span>]]
clf.fit(X, df[<span class="hljs-string" style="color: rgb(221, 17, 68);">"target"</span>])
joblib.dump(clf, <span class="hljs-string" style="color: rgb(221, 17, 68);">"model.joblib"</span>)
df.to_csv(<span class="hljs-string" style="color: rgb(221, 17, 68);">"data.csv"</span>)

</pre>



<p>The example above shows the ease with which you can design your ANN model using drifter-ml. Similarly, you can also design a test case as well. In the test defined below, we will try to find the lowest decision boundary by which the model can easily classify the two classes.&nbsp;</p>



<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);"><span class="hljs-function"><span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">def</span> <span class="hljs-title" style="color: rgb(153, 0, 0); font-weight: 700;">test_cv_precision_lower_boundary</span><span class="hljs-params">()</span>:</span>
   df = pd.read_csv(<span class="hljs-string" style="color: rgb(221, 17, 68);">"data.csv"</span>)
   column_names = [<span class="hljs-string" style="color: rgb(221, 17, 68);">"A"</span>, <span class="hljs-string" style="color: rgb(221, 17, 68);">"B"</span>, <span class="hljs-string" style="color: rgb(221, 17, 68);">"C"</span>]
   target_name = <span class="hljs-string" style="color: rgb(221, 17, 68);">"target"</span>
   clf = joblib.load(<span class="hljs-string" style="color: rgb(221, 17, 68);">"model.joblib"</span>)

   test_suite = ClassificationTests(clf,
   df, target_name, column_names)
   lower_boundary = <span class="hljs-number" style="color: teal;">0.9</span>
   <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">return</span> test_suite.cross_val_precision_lower_boundary(
       lower_boundary
   )</pre>



<h5>Why should you use this?</h5>


<div class="custom-point-list">
<ul><li>Drifter-ML is specifically written for Scikit-learn, and this library acts as an extension to it. All the classes and methods are written in sync with Scikit-learn, so data and model testing become relatively easy and straightforward.&nbsp;</li></ul>
</div>

<div class="custom-point-list">
<ul><li>On a side note, if you like to work on an open-source library, then you can extend the library to other machine learning and deep learning libraries such as Pytorch as well.&nbsp;</li></ul>
</div>


<h5>Key features </h5>


<div class="case-study-numbered-list">
    <h2></h2>
    <ul>
                    <li><span>1</span>Built on top of Scikit-learn. <br />
</li>
                    <li><span>2</span>Offers to test for Deep learning architecture but only for Keras since it is extended in Scikit-learn. <br />
</li>
                    <li><span>3</span>Open source library and open to contribution. </li>
            </ul>
</div>



<h5>Key drawbacks</h5>


<div class="case-study-numbered-list">
    <h2></h2>
    <ul>
                    <li><span>1</span>It is not up to date, and its community is not fairly active. <br />
</li>
                    <li><span>2</span>It does not work well with other libraries. </li>
            </ul>
</div>



<h3>Subscription-based tools</h3>



<h4>1. Kolena.io</h4>



<p><a href="https://www.kolena.io/" target="_blank" rel="noreferrer noopener nofollow">Kolena.io</a> is a Python-based framework for ML testing. It also includes an online platform where the results and insights can be logged. Kolena focuses mostly on the ML unit testing and validation process at scale.&nbsp;</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img data-attachment-id="71579" data-permalink="https://neptune.ai/5-tools-that-will-help-you-setup-production-ml-model-testing-11" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-11.png?fit=1440%2C924&amp;ssl=1" data-orig-size="1440,924" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="5-tools-that-will-help-you-setup-production-ML-model-testing-11" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-11.png?fit=300%2C193&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-11.png?fit=1024%2C657&amp;ssl=1" decoding="async" width="1024" height="657" src="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-11.png?resize=1024%2C657&#038;ssl=1" alt="Kolena.io dashboard" class="wp-image-71579" data-recalc-dims="1"/><figcaption><em>Kolena.io dashboard example | <a href="https://www.kolena.io/" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>


<h5>Why you should use this?</h5>



<p>Kolena argues that the split test dataset methodology isn’t as reliable as it seems to be. Splitting the datasets provides a global representation of the entire population distribution and fails to capture the local representations at a granular level, this is especially true with label or class. There are hidden nuances of features that still need to be discovered. This leads to the failure of the model in the real world even though the model yields good scores in the performance metrics during training and evaluation.&nbsp;</p>



<p>One way of addressing that issue is by creating a much more focused dataset that can be achieved by breaking a given class into smaller subclasses for focused results or even creating a subset of the features themselves. Such a dataset can enable the ML model to extract features and representation at a much granular level. This will increase the performance of the model as well by balancing both the bias and variance such that the model generalizes well in the real-world scenario.&nbsp;</p>



<p>For example, when building a classification model, a given class in the dataset can be broken down into various subsets and those subsets into finer subsets. This can enable users to test the model in various scenarios. In the table below, the CAR class is tested against several test cases to check the model’s performance on various attributes.&nbsp;</p>


<div class="wp-block-image">
<figure class="aligncenter size-large is-resized"><img data-attachment-id="71580" data-permalink="https://neptune.ai/5-tools-that-will-help-you-setup-production-ml-model-testing-12" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-12.png?fit=1262%2C906&amp;ssl=1" data-orig-size="1262,906" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="5-tools-that-will-help-you-setup-production-ML-model-testing-12" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-12.png?fit=300%2C215&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-12.png?fit=1024%2C735&amp;ssl=1" decoding="async" src="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-12.png?resize=768%2C551&#038;ssl=1" alt="CAR class tested against several test cases" class="wp-image-71580" width="768" height="551" data-recalc-dims="1" /><figcaption>CAR class tested against several test cases to check the model’s performance on various attributes | <a href="https://medium.com/kolena-ml/best-practices-for-ml-model-testing-224366d3f23c" target="_blank" rel="noreferrer noopener nofollow">Source</a></figcaption></figure></div>


<p>Another benefit is whenever we face a new scenario in the real-world, a new test case can be designed and tested immediately. Likewise, users can build more comprehensive test cases for a variety of tasks and train or build a model. The users can also generate a detailed report on a model’s performance in each category of test cases and compare it to the previous models with each iteration.</p>



<p>To sum up, Kolena offers:</p>


<div class="custom-point-list">
<ul><li>Ease of python framework</li><li>Automated workflow testing and deployment</li><li>Faster model debugging</li><li>Faster model deployment</li></ul>
</div>


<p>If you are working on a large-scale deep learning model which will be complex to monitor, then Kolena will be beneficial.&nbsp;</p>



<h5>Key features </h5>


<div class="case-study-numbered-list">
    <h2></h2>
    <ul>
                    <li><span>1</span>Supports Deep Learning architectures.<br />
</li>
                    <li><span>2</span>Kolena Test Case Studio offers to curate customizable test cases for the model. <br />
</li>
                    <li><span>3</span>It allows users to prepare quality tests by removing noise and improving annotations.<br />
</li>
                    <li><span>4</span>It can automatically diagnose failure modes and can find the exact issue concerning the same. <br />
</li>
                    <li><span>5</span>Integrates seamlessly into the ML pipeline. </li>
            </ul>
</div>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img data-attachment-id="71581" data-permalink="https://neptune.ai/5-tools-that-will-help-you-setup-production-ml-model-testing-13" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-13.png?fit=1440%2C926&amp;ssl=1" data-orig-size="1440,926" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="5-tools-that-will-help-you-setup-production-ML-model-testing-13" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-13.png?fit=300%2C193&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-13.png?fit=1024%2C658&amp;ssl=1" decoding="async" width="1024" height="658" src="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-13.png?resize=1024%2C658&#038;ssl=1" alt="App Kolena.io " class="wp-image-71581" data-recalc-dims="1"/><figcaption><em>View from the Kolena.io app | Source</em></figcaption></figure></div>


<h5>Key drawbacks</h5>


<div class="case-study-numbered-list">
    <h2></h2>
    <ul>
                    <li><span>1</span>Subscription-based model (pricing not mentioned).<br />
</li>
                    <li><span>2</span>Subscription-based model (pricing not mentioned).<br />
</li>
                    <li><span>3</span>In order to download the framework, you need a CloudRepo pass. </li>
            </ul>
</div>



<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);">pip3 install --extra-index-url <span class="hljs-string" style="color: rgb(221, 17, 68);">"$CR_URL"</span> kolena-client</pre>



<h3>2. Robust intelligence</h3>



<p>It is an E2E ML platform that offers various services in terms of ML integrity. The framework is written in Python and allows customizing your code according to your needs. The framework also integrates into an online dashboard that provides insights into various testing on data and model performance as well as model monitoring. All these services target the ML model and data right from training to the post-production phase.&nbsp;</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img data-attachment-id="71582" data-permalink="https://neptune.ai/5-tools-that-will-help-you-setup-production-ml-model-testing-14" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-14.png?fit=1999%2C1158&amp;ssl=1" data-orig-size="1999,1158" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="5-tools-that-will-help-you-setup-production-ML-model-testing-14" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-14.png?fit=300%2C174&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-14.png?fit=1024%2C593&amp;ssl=1" decoding="async" width="1024" height="593" src="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-14.png?resize=1024%2C593&#038;ssl=1" alt="Robust intelligence " class="wp-image-71582" data-recalc-dims="1"/><figcaption><em>Robust intelligence features | <a href="https://www.robustintelligence.com/platform/overview" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>


<h5>Why should you use this?</h5>



<p>The platform offers services like:</p>



<p><strong>1. AI stress testing,</strong> which includes hundreds of tests to automatically evaluate the performance of the model and identify potential drawbacks.&nbsp;</p>


<div class="wp-block-image">
<figure class="aligncenter size-full"><img data-attachment-id="71583" data-permalink="https://neptune.ai/5-tools-that-will-help-you-setup-production-ml-model-testing-15" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-15.png?fit=556%2C390&amp;ssl=1" data-orig-size="556,390" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="5-tools-that-will-help-you-setup-production-ML-model-testing-15" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-15.png?fit=300%2C210&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-15.png?fit=556%2C390&amp;ssl=1" decoding="async" width="556" height="390" src="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-15.png?resize=556%2C390&#038;ssl=1" alt="AI stress testing" class="wp-image-71583" data-recalc-dims="1"/><figcaption><em>Evaluating the performance of the model | <a href="https://www.robustintelligence.com/platform/overview" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>


<p><strong>2. AI Firewall, </strong>which automatically creates a wrapper around the trained model to protect it from bad data in real-time. The wrapper is configured based on the model. It also automatically checks both the data and model, reducing manual effort and time.</p>


<div class="wp-block-image">
<figure class="aligncenter size-full"><img data-attachment-id="71584" data-permalink="https://neptune.ai/5-tools-that-will-help-you-setup-production-ml-model-testing-16" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-16.png?fit=612%2C360&amp;ssl=1" data-orig-size="612,360" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="5-tools-that-will-help-you-setup-production-ML-model-testing-16" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-16.png?fit=300%2C176&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-16.png?fit=612%2C360&amp;ssl=1" decoding="async" width="612" height="360" src="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-16.png?resize=612%2C360&#038;ssl=1" alt="AI Firewall" class="wp-image-71584" data-recalc-dims="1"/><figcaption><em>Prevention of model failures in production | <a href="https://www.robustintelligence.com/platform/overview" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>


<p><strong>3. AI continuous testing</strong>, which<strong> </strong>monitors the model and automatically tests the deployed model to check for updates and retraining. The testing involves data drift, error, root cause analysis, anomalies detection et cetera. All the insights gained during continuous testing are displayed on the dashboard.&nbsp;</p>


<div class="wp-block-image">
<figure class="aligncenter size-full"><img data-attachment-id="71585" data-permalink="https://neptune.ai/5-tools-that-will-help-you-setup-production-ml-model-testing-17" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-17.png?fit=612%2C360&amp;ssl=1" data-orig-size="612,360" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="5-tools-that-will-help-you-setup-production-ML-model-testing-17" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-17.png?fit=300%2C176&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-17.png?fit=612%2C360&amp;ssl=1" decoding="async" width="612" height="360" src="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-17.png?resize=612%2C360&#038;ssl=1" alt="AI continuous testing" class="wp-image-71585" data-recalc-dims="1"/><figcaption><em>Monitoring model in production | <a href="https://www.robustintelligence.com/platform/overview" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>


<p>Robust intelligence enables model testing, model protection during deployment, and model monitoring after deployment. Since it is an e2e-based platform, all the phases can be easily automated with hundreds of stress tests run on the model to make it production ready. If the project is fairly large, then Robust intelligence will give you an edge.&nbsp;</p>



<h5>Key features </h5>


<div class="case-study-numbered-list">
    <h2></h2>
    <ul>
                    <li><span>1</span>Supports deep learning frameworks<br />
</li>
                    <li><span>2</span>Flexible and easy to use<br />
</li>
                    <li><span>3</span>Customisable<br />
</li>
                    <li><span>4</span>Scalable</li>
            </ul>
</div>



<h5>Key drawbacks</h5>


<div class="case-study-numbered-list">
    <h2></h2>
    <ul>
                    <li><span>1</span>Only for enterprise. <br />
</li>
                    <li><span>2</span>Few details are available online. <br />
</li>
                    <li><span>3</span>Expensive: One-year subscription costs around $60,000.</li>
            </ul>
</div>



<p class="has-text-align-left"><span style="color: initial;"><em>(</em></span><a href="https://aws.amazon.com/marketplace/pp/prodview-23bciknsbkgta" target="_blank" rel="noreferrer noopener nofollow"><em>Source</em></a><strong style="color: initial;"><em>)</em></strong></p>



<h3>Hybrid frameworks</h3>



<h4>1. Etiq.ai</h4>



<p>​​<a href="https://etiq.ai/" target="_blank" rel="noreferrer noopener nofollow">Etiq </a>is an AI-observability platform that supports AI/ML lifecycle. Like Kolena and Robust Intelligence, the framework offers ML Model testing, monitoring, optimization, and explainability. </p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img data-attachment-id="71586" data-permalink="https://neptune.ai/5-tools-that-will-help-you-setup-production-ml-model-testing-18" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-18.png?fit=1917%2C923&amp;ssl=1" data-orig-size="1917,923" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="5-tools-that-will-help-you-setup-production-ML-model-testing-18" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-18.png?fit=300%2C144&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-18.png?fit=1024%2C493&amp;ssl=1" decoding="async" width="1024" height="493" src="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-18.png?resize=1024%2C493&#038;ssl=1" alt="Etiq.ai" class="wp-image-71586" data-recalc-dims="1"/><figcaption><em>The dashboard of Etiq.ai | <a href="https://docs.google.com/document/d/1oJ20eZeuuuFigdi4P4rqgcLONZ2ulimFn4XMBQ8M9Fw/edit#heading=h.upirzig57bbx" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>


<p>Etiq is considered to be a hybrid framework as it offers both offline and online implementation. Etiq has four tiers of usage:</p>


<div class="custom-point-list">
<ol><li><strong>Free and public</strong>: It includes free usage of the library as well as the dashboard. Keep in mind the results and metadata will be stored in your dashboard instance the moment you log in to the platform, but you will receive full benefits.&nbsp;</li><li><strong>Free and limited</strong>: If you want a free but private testing environment for your project and don’t want to share any information, then you can use the platform without logging into the platform. Keep in mind that you will not receive full benefits as would have received when you logged into the platform.&nbsp;&nbsp;</li><li>Subscribe and private: If you want full benefits of Etiq.ai, then you can subscribe to their plan and make use of their tools in your own private environment. Etiq.ai is already available in the AWS market place which starts at around $3.00/hour or from $25,000.00/year.&nbsp;</li><li>Personalized request: If you require functionality beyond what is provided by Etiq.ai, like explainability, robustness, or team share functionality, then you can contact them and get your own personalized test suite.&nbsp;&nbsp;</li></ol>
</div>


<h5>Structure of the framework&nbsp;</h5>



<p>Etiq follows a structure similar to DeepChecks. This structure remains the core of the framework:</p>


<div class="custom-point-list">
<ul><li><strong>Snapshot</strong>: It is a combination of dataset and model in the pre-production testing phase.&nbsp;</li><li><strong>Scan</strong>: It is usually a test that is applied to the snapshot.</li><li><strong>Config</strong>: It is usually a JSON file that contains a set of parameters that will be used by the scan for running tests in the snapshot.</li><li><strong>Custom test</strong>: It allows you to customize your tests by adding and editing various metrics to the config file.&nbsp;</li></ul>
</div>


<p>Etiq offers two types of tests: <strong>Scan</strong> and <strong>Root Cause Analysis</strong> or RCA, the latter is an experimental pipeline. The scan type offers</p>


<div class="custom-point-list">
<ul><li><strong>Accuracy</strong>: In some cases, high accuracy can indicate a problem just as low accuracy can. In such cases, an ‘accuracy’ scan can be helpful. If the accuracy is too high, then you might do a leakage scan, or if it is low, then you can do a drift scan.&nbsp;</li><li><strong>Leakage</strong>: It helps you to find data leakage.&nbsp;</li><li><strong>Drift</strong>: It can help you to find feature drift, target drift, concept drift, and prediction drift.&nbsp;</li><li><strong>Bias</strong>: Bias refers to algorithmic bias that can happen because of automated decision making causing unintended discrimination.&nbsp;</li></ul>
</div>


<h5>Why should you use this?</h5>



<p>Etiq.ai offers a multi-step pipeline, which means you can monitor the test by logging the results of each of the steps in the ML pipeline. This allows you to identify and repair bias within the model. If you are looking for a framework that can do the heavy lifting of your AI pipeline, then Etiq.ai is the one to go.&nbsp;</p>



<p>Some other reasons why you should use Etiq.ai:</p>


<div class="case-study-numbered-list">
    <h2></h2>
    <ul>
                    <li><span>1</span>It is a Python Framework<br />
</li>
                    <li><span>2</span>Dashboard facility for multiple insights and optimization reporting<br />
</li>
                    <li><span>3</span>You can manage multiple projects. </li>
            </ul>
</div>



<p>All the points above are valid for free tier usage.&nbsp;</p>



<p>One key feature of Etiq.ai is that it allows you to be very precise and straightforward in your model building and deploying approaches. It aims to give users the tools that can help them to achieve the desired model. At times, the development process gets drifted away from the original plan mostly because of the lack of tools needed to shape the model. If you want to deploy a model that is aligned with the proposed requirements, then Etiq.ai is the way to go. This is because the framework offers <strong>similar tests at each step throughout your ML pipeline.&nbsp;</strong></p>


<div class="wp-block-image">
<figure class="aligncenter size-full"><img data-attachment-id="71587" data-permalink="https://neptune.ai/5-tools-that-will-help-you-setup-production-ml-model-testing-19" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-19.png?fit=957%2C232&amp;ssl=1" data-orig-size="957,232" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="5-tools-that-will-help-you-setup-production-ML-model-testing-19" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-19.png?fit=300%2C73&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-19.png?fit=957%2C232&amp;ssl=1" decoding="async" width="957" height="232" src="https://i0.wp.com/neptune.ai/wp-content/uploads/5-tools-that-will-help-you-setup-production-ML-model-testing-19.png?resize=957%2C232&#038;ssl=1" alt="Etiq.ai " class="wp-image-71587" data-recalc-dims="1"/><figcaption><em>Steps of the process when to use Etiq.ai | <a href="https://docs.etiq.ai/#why-use-etiq-for-ml-testing" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>


<h5>Key features </h5>


<div class="case-study-numbered-list">
    <h2></h2>
    <ul>
                    <li><span>1</span>A lot of functionalities in the free tier.<br />
</li>
                    <li><span>2</span>Test each of the pipelines for better monitoring<br />
</li>
                    <li><span>3</span>Supports deep learning frameworks like PyTorch and Keras-Tensorflow<br />
</li>
                    <li><span>4</span>You can request a personalized test library. </li>
            </ul>
</div>



<h5>Key drawbacks</h5>


<div class="case-study-numbered-list">
    <h2></h2>
    <ul>
                    <li><span>1</span>At the moment, in production, they only provide functionality for batch processing.<br />
</li>
                    <li><span>2</span>To apply tests to tasks pertaining to segmentation, regression, or recommendation engines, who must get in touch with the team. </li>
            </ul>
</div>



<h2>Conclusion</h2>



<p>The ML testing frameworks that we discussed are directed toward the needs of the users. All of the frameworks have their own pros and cons. But you can definitely get by using any one of these frameworks. ML model testing frameworks play an integral part in defining how the model will perform when deployed to a real-world scenario.&nbsp;</p>



<p>If you are looking for a free and easy-to-use ML testing framework for structured datasets and smaller ML models, then go with DeepChecks. If you are working with DL algorithms, then Etiq.ai is a good option. But if you can spare some money, then you should definitely inquire about Kolena. And lastly, if you are working in a mid to large-size enterprise and looking for ML testing solutions, then hands-down, it has to be Robust Intelligence.&nbsp;</p>



<p>I hope this article provided you with all the preliminary information needed for you to get started with ML testing. Please share this article with everyone who needs it.&nbsp;</p>



<p>Thanks for reading!!!</p>



<h3>Reference</h3>


<div class="custom-point-list">
<ol><li><a href="https://www.robustintelligence.com/" target="_blank" rel="noreferrer noopener nofollow">https://www.robustintelligence.com/</a></li><li><a href="https://aws.amazon.com/marketplace/pp/prodview-23bciknsbkgta" target="_blank" rel="noreferrer noopener nofollow">https://aws.amazon.com/marketplace/pp/prodview-23bciknsbkgta</a></li><li><a href="https://etiq.ai/" target="_blank" rel="noreferrer noopener nofollow">https://etiq.ai/</a></li><li><a href="https://docs.etiq.ai/" target="_blank" rel="noreferrer noopener nofollow">https://docs.etiq.ai/</a></li><li><a href="https://arxiv.org/pdf/2005.04118.pdf" target="_blank" rel="noreferrer noopener nofollow">https://arxiv.org/pdf/2005.04118.pdf</a></li><li><a href="https://medium.com/kolena-ml/best-practices-for-ml-model-testing-224366d3f23c" target="_blank" rel="noreferrer noopener nofollow">https://medium.com/kolena-ml/best-practices-for-ml-model-testing-224366d3f23c</a></li><li><a href="https://docs.kolena.io/" target="_blank" rel="noreferrer noopener nofollow">https://docs.kolena.io/</a></li><li><a href="https://www.kolena.io/" target="_blank" rel="noreferrer noopener nofollow">https://www.kolena.io/</a></li><li><a href="https://github.com/EricSchles/drifter_ml" target="_blank" rel="noreferrer noopener nofollow">https://github.com/EricSchles/drifter_ml</a></li><li><a href="https://arxiv.org/pdf/2203.08491.pdf" target="_blank" rel="noreferrer noopener nofollow">https://arxiv.org/pdf/2203.08491.pdf</a></li><li><a href="https://medium.com/@ptannor/new-open-source-for-validating-and-testing-machine-learning-86bb9c575e71" target="_blank" rel="noreferrer noopener nofollow">https://medium.com/@ptannor/new-open-source-for-validating-and-testing-machine-learning-86bb9c575e71</a></li><li><a href="https://deepchecks.com/" target="_blank" rel="noreferrer noopener nofollow">https://deepchecks.com/ </a></li><li><a href="https://www.xenonstack.com/insights/machine-learning-model-testing" target="_blank" rel="noreferrer noopener nofollow">https://www.xenonstack.com/insights/machine-learning-model-testing</a></li><li><a href="https://www.jeremyjordan.me/testing-ml/" target="_blank" rel="noreferrer noopener nofollow">https://www.jeremyjordan.me/testing-ml/</a></li><li><a href="https://neptune.ai/blog/ml-model-testing-teams-share-how-they-test-models" target="_blank" rel="noreferrer noopener">https://neptune.ai/blog/ml-model-testing-teams-share-how-they-test-models</a></li><li><a href="https://mlops.toys" target="_blank" rel="noreferrer noopener nofollow">https://mlops.toys</a></li></ol>
</div>



<div id="author-box-new-format-block_604218f9077b8" class="article__footer article__author">
  <div class="article__authorImage">
          <img width="193" height="193" src="https://i0.wp.com/neptune.ai/wp-content/uploads/Nilesh-Barla.png?fit=193%2C193&amp;ssl=1" class="article__authorImage-img" alt="Nilesh Barla" decoding="async" data-attachment-id="35510" data-permalink="https://neptune.ai/blog/representation-learning-with-autoencoder/attachment/nilesh-barla" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Nilesh-Barla.png?fit=193%2C193&amp;ssl=1" data-orig-size="193,193" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Nilesh Barla" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Nilesh-Barla.png?fit=193%2C193&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Nilesh-Barla.png?fit=193%2C193&amp;ssl=1" />      </div>

  <div class="article__authorContent">
          <h3 class="article__authorContent-name">Nilesh Barla</h3>
    
          <p class="article__authorContent-text">I am the founder of a recent startup perceptronai.net which aims to provide solutions in medical and material science through our deep learning algorithms. I also read and think a lot. And sometimes I put them in a form of a painting or a piece of music. And when I need to catch a breath I go for a run.</p>
    
          <ul class="article__authorSocial">
        <li class="article__authorSocial-single article__authorSocial-name">Follow me on</li>
                  <li class="article__authorSocial-single"><a href="https://twitter.com/nielspace07" class="article__authorSocial-tw" target="_blank"></a></li>
        
                  <li class="article__authorSocial-single"><a href="https://www.linkedin.com/in/nielspace/?originalSubdomain=in" class="article__authorSocial-lk" target="_blank"></a></li>
        
              </ul>
    
  </div>
</div>


<div class="is-layout-flow wp-block-group"><div class="wp-block-group__inner-container">
<hr class="wp-block-separator"/>



<p class="has-text-color" style="color:#4455a6"><strong>READ NEXT</strong></p>



<h2>ML Model Testing: 4 Teams Share How They Test Their Models</h2>



<p class="has-small-font-size"> 10 mins read | Author Stephen Oladele | Updated March 1st, 2022</p>


<div id="block_5ffc75def9f8e" class="separator separator-10"></div>



<p>Despite the progress of the machine learning industry in developing solutions that help data teams and practitioners operationalize their machine learning models, testing these models to make sure they’ll work as intended remains one of the most challenging aspects of putting them into production.&nbsp;</p>



<p>Most processes used to <strong>test ML models for production usage</strong> are native to traditional software applications, not machine learning applications. When starting a machine learning project, it’s standard for you to take critical note of the business, tech, and datasets requirements. Still, teams often neglect the testing requirements for later until they are either ready to deploy or altogether skip testing before deployment. </p>



<h2 id="how-do-teams-test-machine-learning-models">How do teams test machine learning models?</h2>



<p>With ML testing, you are asking the question: “How do I know if my model works?” Essentially, you want to ensure that your learned model will behave consistently and produce the results you expect from it.&nbsp;</p>



<p>Unlike traditional software applications, it is not straightforward to establish a standard for testing ML applications because the tests do not just depend on the software, they also rely on the business context, problem domain, dataset used, and the model selected.&nbsp;</p>



<p>While most teams are comfortable with using the model evaluation metrics to quantify a model’s performance before deploying it, these metrics are mostly not enough to ensure your models are ready for production. You also need to perform thorough testing of your models to ensure they are robust enough for real-world encounters.</p>



<p><strong>This article will teach you how various teams perform testing for different scenarios.</strong>&nbsp;At the same time, it’s worth noting that this article should not be used as a template (because ML testing is problem-dependent) but rather a guide to what types of test suite you might want to try out for your application based on your use case.</p>


<a class="button continous-post blue-filled" href="/blog/mlops" target="_blank">
    Continue reading -&gt;</a>



<hr class="wp-block-separator"/>
</div></div>
<p>The post <a rel="nofollow" href="https://neptune.ai/blog/tools-ml-model-testing">5 Tools That Will Help You Setup Production ML Model Testing</a> appeared first on <a rel="nofollow" href="https://neptune.ai">neptune.ai</a>.</p>
]]></content:encoded>
					
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">71745</post-id>	</item>
		<item>
		<title>How to Solve the Data Ingestion and Feature Store Component of the MLOps Stack</title>
		<link>https://neptune.ai/blog/data-ingestion-and-feature-store-component-mlops-stack</link>
		
		<dc:creator><![CDATA[Manuel Martin]]></dc:creator>
		<pubDate>Tue, 13 Sep 2022 15:59:23 +0000</pubDate>
				<category><![CDATA[ML Model Development]]></category>
		<category><![CDATA[MLOps]]></category>
		<category><![CDATA[mlops]]></category>
		<guid isPermaLink="false">https://neptune.ai/?p=71407</guid>

					<description><![CDATA[<p>As every practitioner in the Data Science space knows, Data is the primary fuel for Machine Learning. A trustworthy data sourcing and high-quality data collection and processing can empower a vast range of potential ML use cases. But having a well-governed Data Warehouse requires a thorough devotion from every team in the organization to look [&#8230;]</p>
<p>The post <a rel="nofollow" href="https://neptune.ai/blog/data-ingestion-and-feature-store-component-mlops-stack">How to Solve the Data Ingestion and Feature Store Component of the MLOps Stack</a> appeared first on <a rel="nofollow" href="https://neptune.ai">neptune.ai</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<p>As every practitioner in the <em>Data Science</em> space knows, <strong>Data</strong> <strong>is the primary fuel for Machine Learning</strong>. A trustworthy data sourcing and high-quality data collection and processing can empower a vast range of potential ML use cases. But having a well-governed <a href="https://aws.amazon.com/data-warehouse/#:~:text=A%20data%20warehouse%20is%20a,typically%20on%20a%20regular%20cadence." target="_blank" rel="noreferrer noopener nofollow">Data Warehouse</a> requires a thorough devotion from every team in the organization to look after and curate every data point that they produce, ingest, analyze or exploit. <strong>Data quality responsibility spreads across everyone</strong>. It is not only dependent on the Data Engineering team.</p>


<div class="wp-block-image">
<figure class="aligncenter size-full is-resized"><img data-attachment-id="71390" data-permalink="https://neptune.ai/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-mlops-stack-1" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-1.png?fit=891%2C470&amp;ssl=1" data-orig-size="891,470" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-1" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-1.png?fit=300%2C158&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-1.png?fit=891%2C470&amp;ssl=1" decoding="async" src="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-1.png?resize=668%2C353&#038;ssl=1" alt="Data quality characteristics" class="wp-image-71390" width="668" height="353" data-recalc-dims="1" /><figcaption><em>Main properties of Data Quality | <a href="https://www.aqclab.es/index.php/en/data-quality-iso-25012" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>


<p>The most common data architecture nowadays in organizations is <a href="https://en.wikipedia.org/wiki/Lambda_architecture" target="_blank" rel="noreferrer noopener nofollow">Lambda Architecture</a>. It is characterized by having independent batch and streaming pipelines ingesting data into the Data Lake, which consists of a <em>landing</em> or <em>raw</em> stage where <a href="https://www.ibm.com/cloud/learn/elt" target="_blank" rel="noreferrer noopener nofollow">ELT</a><em> </em>processes dump raw data objects, such as events or database record dumps.&nbsp;</p>



<p>This raw data is later ingested and wrangled into more organized Data Lake tables (Parquet files, for example), and then it is enriched to be ingested into the <em>Data Warehouse</em>. The data that gets into the DW is logically organised information for different business domains called <a href="https://www.oracle.com/autonomous-database/what-is-data-mart/" target="_blank" rel="noreferrer noopener nofollow">Data Marts</a>. These data marts are easily queried by Data Analysts and explored by Business Stakeholders. Each data mart could be related to different business units or product domains (<em>Marketing, Subscriptions, Registrations, Product, Users …)</em>.&nbsp;</p>


<div class="wp-block-image">
<figure class="aligncenter size-large is-resized"><img data-attachment-id="71391" data-permalink="https://neptune.ai/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-mlops-stack-2" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-2.png?fit=1999%2C979&amp;ssl=1" data-orig-size="1999,979" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-2.png?fit=300%2C147&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-2.png?fit=1024%2C501&amp;ssl=1" decoding="async" src="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-2.png?resize=840%2C411&#038;ssl=1" alt="Example of a typical Data Architecture" class="wp-image-71391" width="840" height="411" data-recalc-dims="1" /><figcaption><em>Example of a typical Data Architecture in Google Cloud Platform&nbsp;| <a href="https://blog.miraclesoft.com/data-foundation-with-modernized-data-lake-data-warehouse/" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>


<p>There are also other reference architecture patterns such as the <a href="https://hazelcast.com/glossary/kappa-architecture/#:~:text=What%20Is%20the%20Kappa%20Architecture,with%20a%20single%20technology%20stack." target="_blank" rel="noreferrer noopener nofollow">Kappa</a> or Delta, the latter getting a lot of traction with commercial products such as <a href="https://www.databricks.com/" target="_blank" rel="noreferrer noopener nofollow">Databricks</a> and <a href="https://delta.io/" target="_blank" rel="noreferrer noopener nofollow">Delta Lake</a>.&nbsp;</p>



<p>These foundational data architectural patterns have paved the way for analytical workloads. <a href="https://en.wikipedia.org/wiki/Online_analytical_processing" target="_blank" rel="noreferrer noopener nofollow">OLAP</a> databases and processing engines for Big Data, such as <a href="https://spark.apache.org/" target="_blank" rel="noreferrer noopener nofollow">Spark</a> and <a href="https://www.dask.org/" target="_blank" rel="noreferrer noopener nofollow">Dask</a>, among others, have enabled the decoupling of the storage and computing hardware, allowing Data practitioners to interact with massive amounts of data for doing <em>Data Analytics </em>and <em>Data Science</em>.</p>



<p>With the rise of <a href="/blog/mlops" target="_blank" rel="noreferrer noopener">MLOps</a>, DataOps, and the importance of <em>Software Engineering </em>in production <em>Machine Learning, </em>different startups and products have emerged to solve the issue of serving features such as <a href="https://www.tecton.ai/" target="_blank" rel="noreferrer noopener nofollow">Tecton</a>, <a href="https://www.hopsworks.ai/" target="_blank" rel="noreferrer noopener nofollow">HopsWorks</a>, <a href="https://feast.dev/" target="_blank" rel="noreferrer noopener nofollow">Feast</a>, <a href="https://aws.amazon.com/sagemaker/feature-store/" target="_blank" rel="noreferrer noopener nofollow">SageMaker Feature Store</a>, <a href="https://docs.databricks.com/applications/machine-learning/feature-store/index.html" target="_blank" rel="noreferrer noopener nofollow">Databricks Feature Store</a>, <a href="https://cloud.google.com/vertex-ai/docs/featurestore" target="_blank" rel="noreferrer noopener nofollow">Vertex AI Feature Store</a>…<em> </em>(check out <a href="https://www.featurestore.org/" target="_blank" rel="noreferrer noopener nofollow">Featurestore.org</a> to see all the players in this field).</p>



<p>Furthermore, every company doing production data science at a considerable scale, if not using one of the tools named before, has built their in-house feature store (e.g., <a href="https://www.uber.com/blog/michelangelo-machine-learning-platform/" target="_blank" rel="noreferrer noopener nofollow">Uber was of the first to publish their own approach for building an ML platform</a>, followed by Airbnb).</p>



<p>In this article, we will explain some of the concepts and issues that feature stores solve as if it was an in-house platform. This is because we think it is easier to understand the underlying components and the conceptual and technical relationships among them. We won’t dive deep into commercial products. </p>



<p>We will also discuss the tension between build and buy, which is a hot topic among practitioners in the industry today and what’s the best way to approach this decision.</p>



<div id="blog-cta-intext-block_6320a803d38d1" class="blog-cta-intext">
  <h3 class="blog-cta-intext__title">Bookmark for later</h3>
  <div class="blog-cta-intext__content"><p><a href="/blog/model-serving-component-mlops-stack" target="_blank" rel="noopener">How to Solve the Model Serving Component of the MLOps Stack</a></p>
</div>
  </div>


<h2>What is a feature store?</h2>



<p>Last year, some <a href="https://www.datanami.com/2021/01/19/2021-the-year-of-the-feature-store/" target="_blank" rel="noreferrer noopener nofollow">blogs and influential people in the ML world named 2021</a> as the year of the feature store. We will argue in the next sections the reason behind this. But then, what is a feature store?</p>



<p>A short definition given by<a href="https://www.featurestore.org/" target="_blank" rel="noreferrer noopener nofollow"> Featurestore.org</a> is:</p>



<blockquote class="wp-block-quote"><p><em>“A </em><strong><em>data management layer for machine learning</em></strong><em> that allows to share &amp; discover features and create more effective machine learning pipelines.”</em></p></blockquote>



<p>That’s pretty accurate. To briefly expand on some details, feature stores are composed of a set of technological, architectural, conceptual, and semantic components that enable ML practitioners to create, ingest, discover and fetch features for doing offline experiments and developing online production services.</p>



<h3>Components of a feature store</h3>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img data-attachment-id="71392" data-permalink="https://neptune.ai/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-mlops-stack-3" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-3.png?fit=1706%2C1070&amp;ssl=1" data-orig-size="1706,1070" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-3" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-3.png?fit=300%2C188&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-3.png?fit=1024%2C642&amp;ssl=1" decoding="async" width="1024" height="642" src="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-3.png?resize=1024%2C642&#038;ssl=1" alt="Components of a Feature Store" class="wp-image-71392" data-recalc-dims="1"/><figcaption><em>Components of a feature store |<a href="https://www.featureform.com/post/feature-stores-explained-the-three-common-architectures" target="_blank" rel="noreferrer noopener nofollow"> Source</a></em></figcaption></figure></div>


<p>We should start defining what is a feature vector as it’s the core entity that feature stores deal with.</p>


<div class="custom-point-list">
<ul><li><strong>Feature Vector: </strong>This is a data element that contains an entity identifier and a set of properties or characteristics that describe that element at a certain point in time. For example, the entity identifier can be a <strong>user ID</strong> and the properties could contain the following values: (<em>time_since_registration, n_purchases, ltv_value, is_free_trial, average_purchases_per_month, accumulated_purchases, last_purchase_ts etc)</em></li></ul>
</div>


<p>Let’s explain now which are the different storage components that host these feature vectors:</p>


<div class="custom-point-list">
<ul><li><strong>Offline Store: </strong>This is meant to be an analytical database that can ingest, store and serve feature vectors for offline workloads such as data science experiments or batch production jobs. In general, each row contains a feature vector uniquely identified by the entity ID and a given timestamp. This component is usually materialized as S3, Redshift, BigQuery, Hive, etc.</li></ul>
</div>

<div class="custom-point-list">
<ul><li><strong>Online Store: </strong>Also referred to as <em>hot data</em>, this storage layer is meant to serve features for low latency prediction services. This database is now used to fetch features at millisecond speed. Redis, DynamoDB, or Cassandra are the common candidates to play this role. Key-Value databases are the best option as complex queries and join are not often needed at runtime.</li></ul>
</div>

<div class="custom-point-list">
<ul><li><strong>Feature Catalog or Registry: </strong>Ideally, this is presented as a nice UI that enables features and training datasets discoverability.</li></ul>
</div>

<div class="custom-point-list">
<ul><li><strong>Feature Store SDK: </strong>This is a Python library that abstracts access patterns for online and offline stores.</li></ul>
</div>

<div class="custom-point-list">
<ul><li><strong>Metadata Management: </strong>This component is used to track access from different users or pipelines, ingestion processes, schema changes, and this type of information.</li></ul>
</div>

<div class="custom-point-list">
<ul><li><strong>Offline and Online Serving API: </strong>This is a proxy service that sits in between the SDK and the online and feature hardware to facilitate feature access.</li></ul>
</div>


<p>In the following chronological diagram, we can see a summary of the key milestones around feature store since 2017, when Uber released its famous <a href="https://www.uber.com/blog/michelangelo-machine-learning-platform/" target="_blank" rel="noreferrer noopener nofollow">Michelangelo</a>. A couple of years later, after several commercial and OS products launched, we’ve already seen a wide acceptance of the concept of feature store by industry practitioners. Several organizations such as <a href="https://www.featurestore.org/" target="_blank" rel="noreferrer noopener nofollow">featurestore.org</a> and <a href="https://mlops.community/" target="_blank" rel="noreferrer noopener nofollow">mlops.community</a> have emerged in response to this.</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img data-attachment-id="71393" data-permalink="https://neptune.ai/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-mlops-stack-4" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-4.png?fit=1400%2C788&amp;ssl=1" data-orig-size="1400,788" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-4" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-4.png?fit=300%2C169&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-4.png?fit=1024%2C576&amp;ssl=1" decoding="async" width="1024" height="576" src="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-4.png?resize=1024%2C576&#038;ssl=1" alt=" Feature Store Milestones chart" class="wp-image-71393" data-recalc-dims="1"/><figcaption><em>Feature Store Milestones | <a href="https://medium.com/data-for-ai/feature-store-milestones-cca2bafe6e9c" target="_blank" rel="noreferrer noopener nofollow">Source </a></em></figcaption></figure></div>


<p>In relationship with MLOps, feature stores are themselves affected and affect other components of the stack such as the Data Warehouse, Data Lake, the data job schedulers, production databases, etc. as well. We will discuss this relationship in detail later, i.e., where does a feature store sit in the big picture of the MLOps framework?</p>



<p>Now, let’s discuss some of the major issues that ML Engineers face around production feature engineering.</p>



<h2>Hassles around feature store</h2>



<h3>Standardization of features ingestion and fetching</h3>



<p>Before the existence of a proper feature store, each data science team stored and fetched features using very different tools. These kinds of jobs have been treated traditionally as part of <em>Data Engineering</em> pipelines. Therefore, the libraries, SDKs, and tooling around these jobs are the ones used by data engineers. They can be quite diverse depending on the team’s expertise, maturity level, and background.</p>



<p>For example, you could see the following situation in the same organization:</p>


<div class="custom-point-list">
<ul><li><strong>Team A:</strong> The team is not very knowledgeable in data engineering. They use bare pandas and SQL<strong> </strong>scripts with psycopg<strong> </strong>connectors to store offline features in Redshift and boto to store online features in DynamoDb.</li><li><strong>Team B:</strong> The team is mature and autonomous. They built a library for abstracting connections to several data sources using sqlalchemy<strong> </strong>or PySpark<strong> </strong>for big data jobs. They also have custom wrappers for sending data to DynamoDb and other <em>hot </em>databases.</li></ul>
</div>


<p>This is very typical in large organizations where the ML teams are not fully centralized, or ML cross-teams don’t exist.</p>



<p>Teams operating with the same databases over different projects tend to build wrappers around them so that they can abstract the connectors and encapsulate common utilities or domain definitions. This problem is already solved by Team B. But Team A is not so skilled, and they might develop another in-house library to work with their features in a simpler way.&nbsp;</p>



<p>This causes friction among teams because they want to impose their tool across the organization. It also lowers productivity levels across teams because each one is reinventing the wheel in its own manner, coupling developers to projects.</p>



<p>By introducing a Feature Store SDK, both teams could leverage the same interface for interacting with Redshift and DynamoDb, and other data sources too. The learning curve will be steeper for Team A, but they will maintain the same standard for operating them. So overall productivity will be increased. This allows for better feature governance. SDKs usually hide other API calls to log user requests, and version datasets, allowing for rollbacks, etc.&nbsp;</p>



<p>Most commercial feature stores provide specific SDKs for interacting with their central service. For example, in<a href="https://github.com/feast-dev/feast#5-build-a-training-dataset" target="_blank" rel="noreferrer noopener nofollow"> the next snippet</a>, you could see how to build a dataset fetching features from Feast.</p>


<div class="wp-block-image">
<figure class="aligncenter size-full is-resized"><img data-attachment-id="71394" data-permalink="https://neptune.ai/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-mlops-stack-5" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-5.png?fit=873%2C677&amp;ssl=1" data-orig-size="873,677" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-5" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-5.png?fit=300%2C233&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-5.png?fit=873%2C677&amp;ssl=1" decoding="async" src="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-5.png?resize=840%2C651&#038;ssl=1" alt="Building a dataset " class="wp-image-71394" width="840" height="651" data-recalc-dims="1" /><figcaption><em>Build a dataset fetching features from Feast | <a href="https://github.com/feast-dev/feast#5-build-a-training-dataset" target="_blank" rel="noreferrer noopener nofollow">Source </a></em></figcaption></figure></div>


<p>This is not only valuable for standardizing feature store operations but also for abstracting the online and offline stores&#8217; hardware. Data Scientists don’t need to know if the offline store is a BigQuery or Redshift database. This is a great benefit as you could use a different source depending on the use case, data, etc.</p>



<h3>Time-travel data</h3>



<p>If we want to predict whether a user will buy a product or not, we have to build a dataset with features until that specific moment. <strong>We need to be very careful regarding not introducing future data as this can lead to </strong><a href="https://machinelearningmastery.com/data-leakage-machine-learning/" target="_blank" rel="noreferrer noopener nofollow"><strong>Data Leakage</strong></a><strong>.</strong> But how?</p>



<p>If we introduce future data into the training dataset with respect to each observation, the <em>Machine Learning</em> model will learn unreliable patterns. When putting the model into real-time production, it won’t have access to the same features (unless you can travel to the future), and its prediction capabilities will deteriorate.</p>



<p>Coming back to the example of the product purchase prediction, let’s say you want to use specific characteristics about the users, for example, the number of items saved in the cart. The training dataset will contain events about users who saw and bought the product (positive label) and users who saw but didn’t buy the product (negative label). If you want to use the number of items in the cart as a feature, you would need to query specifically for the events that log every item added to the cart within the same session and just before the purchase/seen event.</p>


<div class="wp-block-image">
<figure class="aligncenter size-full"><img data-attachment-id="71395" data-permalink="https://neptune.ai/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-mlops-stack-6" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-6.png?fit=1024%2C280&amp;ssl=1" data-orig-size="1024,280" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-6" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-6.png?fit=300%2C82&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-6.png?fit=1024%2C280&amp;ssl=1" decoding="async" width="1024" height="280" src="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-6.png?resize=1024%2C280&#038;ssl=1" alt="Time Travel in ML" class="wp-image-71395" data-recalc-dims="1"/><figcaption><em>Tecton: Time Travel in ML&nbsp;| <a href="https://www.tecton.ai/blog/time-travel-in-ml/" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>


<p>Hence, when building such a dataset, we need to query specifically for the features that were available <strong>at that point in time</strong> with respect to each event. It’s necessary to have a representation of the world in which that event occurred.</p>



<h4>How to have an accurate picture?</h4>


<div class="custom-point-list">
<ul><li><strong>Log and wait</strong>: You just have to log specific features, such as <em>n_cumulative_items_in_the_cart,</em> and then we’ll know how many items the user had at that point in time. The main drawback is that this feature collection strategy needs time to gather enough data points for the use case. But on the other hand, it is easy to implement.<br></li><li><strong>Backfilling</strong><em>:</em> This technique basically aims to reconstruct the desired features at a given point in time. For example, by looking at logged events, we could add all the items added to the cart before each purchase. However, this might become very complex as we have to select the time window cutoff for every feature. These queries are commonly known as <strong>point-in-time</strong> joins.<br></li><li><strong>Snapshotting<em>:</em></strong> It is based on dumping the state of a production database periodically. This allows having features at any given point in time, with the drawback that the data changes between consecutive snapshots wouldn’t be available.</li></ul>
</div>


<h3>Features availability for production</h3>



<p>Experienced ML engineers tend to think about what features are available at run time (online) when a new ML use case is proposed. Engineering the systems behind enabling features is the most time-consuming piece of the ML architecture in most cases.</p>



<p>Having an up-to-date feature vector ready to be fed to ML models to make a prediction is not an easy task. Lots of components are involved, and special care is required to glue them all together.</p>



<p>Features in production can come from very different sources. They can be fed to the algorithm within the request body parameters, they can be fetched from a specific API, retrieved from a SQL or NoSQL database, from a Kafka topic event, from a Key-Value store, or they can be computed and derived on-the-fly from other data. Each of them implies different levels of complexity and resource capacity.&nbsp;</p>



<h4>What are these sources?</h4>


<div class="custom-point-list">
<ol><li><strong>Request Body Parameters</strong></li></ol>
</div>


<p>This is the simplest way of receiving features for prediction. The responsibility of obtaining these features and passing them to the ML model is delegated to the client or consumer of the inference API Web Service. Nevertheless, this is not the most common way of feeding features. In fact, request parameters tend to contain unique identifiers that are needed to fetch feature vectors from other sources. These are usually user IDs, content IDs, timestamps, search queries, etc.</p>


<div class="custom-point-list">
<ol start="2"><li><strong>Databases</strong></li></ol>
</div>


<p>Depending on the evolvability requirements of the features schemas and latency, features can be live in different databases such as Cassandra, DynamoDb, Redis, PostgreSQL, or any other fast NoSQL or SQL database. Fetching these features from an online service is quite straightforward. You can use any Python library like boto for DynamoDb, pyredis for Redis, psycopg2 for PostgreSQL, mysql-connector-python for MySQL, cassandra-driver for Cassandra, and so on.&nbsp;</p>


<div class="wp-block-image">
<figure class="aligncenter size-full"><img data-attachment-id="71396" data-permalink="https://neptune.ai/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-mlops-stack-7" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-7.png?fit=800%2C470&amp;ssl=1" data-orig-size="800,470" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-7" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-7.png?fit=300%2C176&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-7.png?fit=800%2C470&amp;ssl=1" decoding="async" width="800" height="470" src="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-7.png?resize=800%2C470&#038;ssl=1" alt="Redis database" class="wp-image-71396" data-recalc-dims="1"/><figcaption><em>Redis database | <a href="https://dishagroup.in/jvdd.aspx?iid=150612136-redis+machine+learning&amp;cid=23" target="_blank" rel="noreferrer noopener nofollow">Source </a></em></figcaption></figure></div>


<p>Each row in the database will have a primary key or index that will be available at runtime for each prediction request. The rest of the columns or values will be the features that you can use.</p>



<p>To fill up these tables we can use different approaches depending on the nature of the features to compute:</p>


<div class="custom-point-list">
<ul><li><strong>Batch jobs:</strong> These are compute-intensive, heavy, and “slow”, that’s why they only serve a certain type of features defined by how <em>fresh</em> they need to be. When building different use cases, you realise that not every model needs real-time features. If you’re using the average rating of a product, you don’t need to compute the average every second. Most of the features like this just need a daily computation. If the feature requires higher update frequency than 1 day, you should start thinking about a batch job.</li></ul>
</div>

<div class="wp-block-image">
<figure class="aligncenter size-full"><img data-attachment-id="71397" data-permalink="https://neptune.ai/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-mlops-stack-8" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-8.png?fit=1024%2C341&amp;ssl=1" data-orig-size="1024,341" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-8" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-8.png?fit=300%2C100&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-8.png?fit=1024%2C341&amp;ssl=1" decoding="async" width="1024" height="341" src="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-8.png?resize=1024%2C341&#038;ssl=1" alt=" Batch processing example" class="wp-image-71397" data-recalc-dims="1"/><figcaption><em>An example of a batch processing | <a href="https://datawhatnow.com/batch-processing-mapreduce/" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>


<p>Talking about common tech stacks, old friends come into play for serving different purposes and scales:&nbsp;</p>


<div class="custom-point-list">
<ul><li>Airflow + DBT or Python is a great first start to schedule and run these jobs.&nbsp;</li><li>If more scale is needed in terms of distributed memory, we can start thinking about Kubernetes Clusters to execute Spark or Dask jobs.&nbsp;</li></ul>
</div>


<p>Some alternatives for orchestration tools are Prefect, Dagster, Luigi, or Flyte. Have a look at a comparison of <a href="/blog/best-workflow-and-pipeline-orchestration-tools">Data Science orchestration and workflow tools</a>.</p>


<div class="custom-point-list">
<ul><li><strong>Streaming Ingestion:</strong><a href="https://medium.com/data-for-ai/building-real-time-ml-pipelines-with-a-feature-store-9f90091eeb4"> </a>Features that need streaming or (near) real-time computations are time-sensitive. Common use cases that need real-time features are fraud detection, real-time product recommendation, predictive maintenance, dynamic pricing, voice assistants, chatbots, and more. For such use cases, we would need a very fast data transformation service.</li></ul>
</div>

<div class="wp-block-image">
<figure class="aligncenter size-large"><img data-attachment-id="71398" data-permalink="https://neptune.ai/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-mlops-stack-10" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-10.png?fit=1176%2C535&amp;ssl=1" data-orig-size="1176,535" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-10" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-10.png?fit=300%2C136&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-10.png?fit=1024%2C466&amp;ssl=1" decoding="async" width="1024" height="466" src="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-10.png?resize=1024%2C466&#038;ssl=1" alt="Building ML pipeline with Feature" class="wp-image-71398" data-recalc-dims="1"/><figcaption><em>Building ML pipeline with Feature | <a href="https://medium.com/data-for-ai/building-real-time-ml-pipelines-with-a-feature-store-9f90091eeb4" target="_blank" rel="noreferrer noopener">Source</a></em></figcaption></figure></div>


<p>There are two important dimensions to take into account here – <strong>frequency</strong> and <strong>complexity</strong>. For example, computing the “standard deviation of the current price versus the average monthly price” on an individual transaction is both a real-time and complex aggregation.</p>


<div class="wp-block-image">
<figure class="aligncenter size-full"><img data-attachment-id="71399" data-permalink="https://neptune.ai/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-mlops-stack-11" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-11.png?fit=800%2C392&amp;ssl=1" data-orig-size="800,392" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-11" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-11.png?fit=300%2C147&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-11.png?fit=800%2C392&amp;ssl=1" decoding="async" width="800" height="392" src="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-11.png?resize=800%2C392&#038;ssl=1" alt="Feature Store Streaming Ingestion" class="wp-image-71399" data-recalc-dims="1"/><figcaption><em>Amazon SageMaker Feature Store Streaming Ingestion | <a href="https://aws.amazon.com/es/blogs/aws-spanish/ingesta-de-streaming-con-amazon-sagemaker-feature-store-para-tomar-decisiones-respaldadas-por-ml-casi-en-tiempo-real/" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>


<p>Apart from having a streaming tool in place for collecting events (Kafka), we would also need a high-speed and scalable (to handle any volume of events per second) function-as-a-service (such as AWS Lambda) to read and process those events. More importantly, the transformation service needs to support aggregations, grouping, joins, custom functions, filters, sliding windows to calculate data over a given time period every X minutes or hours, etc.</p>



<h2>Where does the feature store sit in the MLOps architecture?</h2>



<p>The feature store is an inherent part of ML Platforms. As said previously, it has been a part of it since the first ML models were put in production, but it wasn’t until a few years ago when the concept acquired its own identity within the MLOps world.</p>



<p>Features data sources can get tracked with Experiment Tracking tools such as Neptune, MLFlow, or SageMaker Experiments. That is, let’s say you’re training a fraud detection model and you’ve used some shared Features that another team has built. If you logged those features metadata as parameters, then they will be versioned along with your experiment results and code when tracking the experiments.</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img data-attachment-id="71400" data-permalink="https://neptune.ai/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-mlops-stack-12" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-12.png?fit=1628%2C570&amp;ssl=1" data-orig-size="1628,570" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-12" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-12.png?fit=300%2C105&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-12.png?fit=1024%2C359&amp;ssl=1" decoding="async" width="1024" height="359" src="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-12.png?resize=1024%2C359&#038;ssl=1" alt=" Orchestrating Spark ML Pipelines and MLflow for Production" class="wp-image-71400" data-recalc-dims="1"/><figcaption>The Killer Feature Store: Orchestrating Spark ML Pipelines and MLflow for Production&nbsp;| <a href="https://www.slideshare.net/databricks/the-killer-feature-store-orchestrating-spark-ml-pipelines-and-mlflow-for-production" target="_blank" rel="noreferrer noopener nofollow">Source</a></figcaption></figure></div>


<p>Besides, they become a critical piece when the model is in the production stage. There are several components that need to be synchronised and closely monitored when being live. If one fails, predictions could degrade pretty quickly. These components are the features computation &amp; ingestion pipelines and features consumption from the production services. The computation pipelines need to run at a specific frequency so that features’ freshness doesn’t affect the online predictions. E.g.: if a recommendation system needs to know the film you viewed yesterday, the feature pipeline should run before you go into the media streaming service again!</p>



<h2>How to implement a feature store?</h2>



<p>In this section, we will discuss different architectures that can be implemented for different stages and sizes of Data Science teams. In <a href="https://eugeneyan.com/writing/feature-stores/" target="_blank" rel="noreferrer noopener nofollow">this very nice article</a>, you can see how the author uses the <em>Hierarchy of Needs </em>to very explicitly show which are the main pillars you need to solve. He places the <strong><em>Access</em></strong><em> </em>need, which encompasses transparency and lineage, as more foundational than <strong><em>Serving</em></strong>. I don’t completely agree as the features availability in production unlocks higher business value.</p>



<p>The suggestions presented below will be based on AWS services (although they are easily interchangeable with other public cloud services).</p>



<h3>The simplest solution</h3>



<p>This architecture is based on managed services, which require less maintenance overhead and are better suited for small teams that can operate quickly.</p>



<p>My initial setup would be Redshift as an offline store, DynamoDB as an online key value store, Airflow to manage batch feature computation jobs. Also, Pandas as data processing engine for both options. In this architecture, all feature computation pipelines are scheduled in Airflow and would need to ingest data by using Python scripts that fetch data from Redshift or S3, transforms it, and put it into DynamoDB for online services and then in Redshift again for the offline feature storage.</p>


<div class="wp-block-image">
<figure class="aligncenter size-large is-resized"><img data-attachment-id="71401" data-permalink="https://neptune.ai/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-mlops-stack-13" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-13.png?fit=1999%2C980&amp;ssl=1" data-orig-size="1999,980" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-13" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-13.png?fit=300%2C147&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-13.png?fit=1024%2C502&amp;ssl=1" decoding="async" src="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-13.png?resize=850%2C416&#038;ssl=1" alt="The initial setup chart " class="wp-image-71401" width="850" height="416" data-recalc-dims="1" /><figcaption><em>The initial setup | Source: author</em></figcaption></figure></div>


<h3>Medium-size feature store</h3>



<p>If you’re already dealing with big data, near real-time needs for features, and reusability necessities across data science teams, then you are probably looking for more standardization across feature pipelines and some degree of reusability.</p>



<p>In this situation, I would recommend starting using third-party feature store vendors when the data science team size is relatively big (let’s say, more than 8-10 data scientists). First, I would explore Feast as it’s the most used open-source solution out there, and it can work on top of existing infrastructure. You could use Redshift as an offline feature store and DynamoDB or Redis as an online feature store. The latter is faster for online prediction services with lower latency requirements. <a href="https://feast.dev/" target="_blank" rel="noreferrer noopener nofollow">Feast </a>will help to catalogue and serve features through their SDK and web UI (still experimental, though). If you want a fully managed commercial tool, I implore you to try out <a href="https://www.tecton.ai/product/" target="_blank" rel="noreferrer noopener nofollow">Tecton</a>.</p>



<p>Feature computation pipelines can now be developed using plain Python or Spark if there are big data requirements, leveraging <a href="https://rtd.feast.dev/en/master/" target="_blank" rel="noreferrer noopener nofollow">Feast SDK</a> for managing data ingestion.</p>


<div class="wp-block-image">
<figure class="aligncenter size-full"><img data-attachment-id="71402" data-permalink="https://neptune.ai/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-mlops-stack-14" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-14.png?fit=967%2C494&amp;ssl=1" data-orig-size="967,494" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-14" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-14.png?fit=300%2C153&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-14.png?fit=967%2C494&amp;ssl=1" decoding="async" width="967" height="494" src="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-14.png?resize=967%2C494&#038;ssl=1" alt="" class="wp-image-71402" data-recalc-dims="1"/><figcaption><em>Running Feast in production | <a href="https://docs.feast.dev/how-to-guides/running-feast-in-production" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>


<p>It’s also pretty likely that at this size, there are some use cases with real-time features freshness necessities. In this case, we need a streaming service that ingests features directly into the online feature store. We could use Kinesis services and AWS Lambda to write feature vectors into Redis or DynamoDB directly. If window aggregations are needed, then Kinesis Data Analytics, KafkaSQL, or Spark Streaming might be reasonable options.</p>



<h3>Enterprise-level feature store</h3>



<p>At this stage, we assume the company has plenty of data scientists creating different types of models for different business or technical domains. One key principle when setting architectures for development teams of this size is to provide a reliable, scalable, secure, and standardized data platform. Therefore, SLAs, GDPR, Audit, and Access Control Lists are mandatory requirements to put in place. These are always important points to cover at every organization size, but in this case, they play a critical role.&nbsp;</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img data-attachment-id="71403" data-permalink="https://neptune.ai/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-mlops-stack-15" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-15.png?fit=1080%2C754&amp;ssl=1" data-orig-size="1080,754" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-15" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-15.png?fit=300%2C209&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-15.png?fit=1024%2C715&amp;ssl=1" decoding="async" width="1024" height="715" src="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-15.png?resize=1024%2C715&#038;ssl=1" alt="Feature Store" class="wp-image-71403" data-recalc-dims="1"/><figcaption>feature store explained | <a href="https://www.featureform.com/post/feature-stores-explained-the-three-common-architectures" target="_blank" rel="noreferrer noopener nofollow">Source </a></figcaption></figure></div>


<p>Most of the big players in the tech space have built their own feature stores according to their own needs, security principles, existing infrastructure, and managed availability themselves to avoid having a single point of failure if the service is fully managed.&nbsp;</p>



<p>But if this is not the case and you’re running a public cloud-heavy workload, using AWS <a href="https://aws.amazon.com/sagemaker/feature-store/" target="_blank" rel="noreferrer noopener nofollow">SageMaker Feature Store</a> or <a href="https://cloud.google.com/vertex-ai/docs/featurestore" target="_blank" rel="noreferrer noopener nofollow">GCP Vertex AI Feature Store</a> can be good options to start with. Their API is very similar to their open source counterparts, and if you’re already using SageMaker or Vertex, setting up their feature store services should be straightforward.</p>


<div class="wp-block-image">
<figure class="aligncenter size-full"><img data-attachment-id="71404" data-permalink="https://neptune.ai/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-mlops-stack-16" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-16.png?fit=800%2C369&amp;ssl=1" data-orig-size="800,369" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-16" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-16.png?fit=300%2C138&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-16.png?fit=800%2C369&amp;ssl=1" decoding="async" width="800" height="369" src="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-16.png?resize=800%2C369&#038;ssl=1" alt="Amazon SageMaker Feature Store " class="wp-image-71404" data-recalc-dims="1"/><figcaption><em>Amazon SageMaker Feature Store for machine learning | <a href="http://Amazon SageMaker Feature Store for machine learning (ML)" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>


<p><a href="https://docs.databricks.com/applications/machine-learning/feature-store/index.html" target="_blank" rel="noreferrer noopener nofollow">Databricks also offers an embedded Feature Store</a> service, which is also a good option and would be perfectly compatible with a tool like <a href="https://mlflow.org/" target="_blank" rel="noreferrer noopener nofollow">MLFlow</a>.</p>


<div class="wp-block-image">
<figure class="aligncenter size-full"><img data-attachment-id="71405" data-permalink="https://neptune.ai/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-mlops-stack-17" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-17.png?fit=1024%2C732&amp;ssl=1" data-orig-size="1024,732" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-17" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-17.png?fit=300%2C214&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-17.png?fit=1024%2C732&amp;ssl=1" decoding="async" width="1024" height="732" src="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-17.png?resize=1024%2C732&#038;ssl=1" alt="" class="wp-image-71405" data-recalc-dims="1"/><figcaption><em>Databricks Feature Store&nbsp;| <a href="https://www.databricks.com/it/product/feature-store" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>


<h2>The buy versus build question</h2>



<p>The MLOps landscape has been dominated and shaped by big players such as Facebook, Netflix, Uber, Spotify, etc., throughout these years with their very influential staff engineers and blogs. But ML teams should be able to recognize the contexts in which they operate in their own organizations, teams, and business domains. A 200,000 users app doesn’t need the scale, standardization, and rigidity of a 20-million one. That’s why <a href="/blog/mlops-at-reasonable-scale">MLOps at reasonable scale</a> is a hot topic that is sticking around senior practitioners not working at FAANG-like companies.</p>



<div id="blog-cta-intext-block_6320a7c0d38d0" class="blog-cta-intext">
  <h3 class="blog-cta-intext__title">Read also </h3>
  <div class="blog-cta-intext__content"><p><a href="/blog/mlops-reasonable-scale-jacopo-tagliabue" target="_blank" rel="noopener">Setting up MLOps at a Reasonable Scale With Jacopo Tagliabue</a></p>
</div>
  </div>

<div class="wp-block-image">
<figure class="aligncenter size-large"><img data-attachment-id="71406" data-permalink="https://neptune.ai/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-mlops-stack-18" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-18.png?fit=1268%2C722&amp;ssl=1" data-orig-size="1268,722" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-18" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-18.png?fit=300%2C171&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-18.png?fit=1024%2C583&amp;ssl=1" decoding="async" width="1024" height="583" src="https://i0.wp.com/neptune.ai/wp-content/uploads/how-to-solve-the-data-ingestion-and-feature-store-component-of-the-MLOps-stack-18.png?resize=1024%2C583&#038;ssl=1" alt="Graphic explanation of a feature store" class="wp-image-71406" data-recalc-dims="1"/><figcaption><em>Explanation of a feature store | <a href="https://towardsdatascience.com/do-you-need-a-feature-store-35b90c3d8963" target="_blank" rel="noreferrer noopener nofollow">Source </a></em></figcaption></figure></div>


<h3>Who should build a feature store?</h3>



<p>As mentioned at the start of this article, there’s a constant tussle between building a <em>feature store-like</em> platform in-house or buying a commercial or open source product like <em>Feast, Hopsworks,</em> or <em>Tecton</em>. This tension exists primarily because these products can be opinionated to some degree in their architecture and their SDKs. Thus, most of these tools need to have a central service to handle feature serving on top of online stores, which becomes a single point of failure for production ML services.&nbsp;</p>



<p>In addition, some other products are full SaaS, becoming an uncertain critical piece for some teams. Thus, ML Engineers are skeptical to bet and adhere too early to one of these tools in their MLOps journey.&nbsp;</p>



<p>It is very common that ML and Data Engineering teams share the same technology stack in small or medium size companies or startups. For that reason, migrating to a feature store might cause a big headache and expose some hidden costs. In terms of planning, legacy maintenance, operationality, duplicities, etc., it becomes another piece of infrastructure with specific SDKs which are different from the traditional Data Engineering ones.&nbsp;</p>



<h3>Who should buy a feature store?</h3>



<p>To extract the most value from a commercial feature store, your use cases and data science teams&#8217; setup need to be aligned with the core benefits that they provide. Products that are heavily reliant on real-time complex ML use cases such as recommendation systems, dynamic pricing, or fraud detection are the ones that can leverage these tools the most.&nbsp;</p>



<p>A big team of Data Scientists is also a good reason to have a feature store, as it will increase productivity and features reusability. Apart from that, they usually provide a nice UI to discover and explore features. Nonetheless, commercial Feature Store SDKs and APIs provide a set of standards for a more homogeneous way of ingesting and retrieving features. And as a by-product, the data is governed, and reliable metadata is always logged.</p>



<p>In the very wide variety of ML teams domains, the situation described above is not always met, and setting up these new commercial stacks is sometimes just a personal development desire of the engineers to stay up-to-date with respect to new technology.</p>



<p>That’s why there are teams still who haven’t migrated to a full-packaged feature store and, instead, still rely on the existing data engineering stack for running their production feature engineering layer. This is totally valid, in my opinion.&nbsp;</p>



<p>All in all, feature stores just add a convenient shell on top of the existing data engineering stack to provide unified access APIs, a nice UI to discover and govern feature sets, guarantee consistency between online and feature stores, etc. But all these features are not critical for every ML team&#8217;s use case.</p>



<h2>Conclusion</h2>



<p>I hope that this article has provided a broad view of what feature store are. But more importantly, the<strong> </strong>reason they’re necessary and the key components that need to be addressed when building one.&nbsp;&nbsp;</p>



<p>Feature stores are necessary for levelling up the production services in the data science industry. But you need engineers behind them. The ML Engineer role is critical for dealing with feature pipelines as they are just a specific type of data transformation and ingestion process. Hybrid roles like that allow Data Scientists to focus more on the experimentation side and also guarantee high-quality deliverables.</p>



<p>In addition, I paid special attention to explaining the <em>build versus buy</em> dilemma. From my personal experience, this question arises sooner or later within any mature ML team. I have tried to describe the situations in which they are key for achieving velocity and standardisation, but also left some thoughts on why context awareness is necessary regarding implementing this new technology. Experienced and senior roles should take into consideration the stage of the MLOps journey in which they operate.&nbsp;</p>



<p>The feature store (commercial and open source) world is still young, and there is not yet a uniform and accepted way of dealing with all the different use cases and needs. So try all the approaches before settling down with one.</p>



<h3>References</h3>


<div class="custom-point-list">
<ol><li><a href="https://eugeneyan.com/writing/feature-stores/" target="_blank" rel="noreferrer noopener nofollow">Feature Stores &#8211; A Hierarchy of Needs</a><strong>&nbsp;</strong></li><li><a href="https://www.featureform.com/post/feature-stores-explained-the-three-common-architectures" target="_blank" rel="noreferrer noopener nofollow">Feature Stores Explained: The Three Common Architectures | FeatureForm</a><strong>&nbsp;</strong></li><li><a href="https://www.moderndatastack.xyz/category/feature-store" target="_blank" rel="noreferrer noopener nofollow">Feature Store &#8211; Modern Data Stack</a>&nbsp;</li><li><a href="https://www.tecton.ai/blog/time-travel-in-ml/#:~:text=Time-travel" target="_blank" rel="noreferrer noopener nofollow">Back to the Future: Solving the time-travel problem in machine learning | Tecton</a></li><li><a href="https://maxhalford.github.io/blog/dataset-time-travel/" target="_blank" rel="noreferrer noopener nofollow">An overview of dataset time travel • Max Halford</a></li><li><a href="https://www.youtube.com/watch?v=fU9hR3kiOK0" target="_blank" rel="noreferrer noopener nofollow">&#8220;Turning the database inside out with Apache Samza&#8221; by Martin Kleppmann</a></li><li><a href="https://www.wikiwand.com/en/Temporal_database" target="_blank" rel="noreferrer noopener nofollow">Temporal database &#8211; Wikiwand</a></li><li><a href="https://medium.com/data-for-ai/building-real-time-ml-pipelines-with-a-feature-store-9f90091eeb4" target="_blank" rel="noreferrer noopener nofollow">Building Real-Time ML Pipelines with a Feature Store | by Adi Hirschtein</a></li><li><a href="https://docs.feast.dev/how-to-guides/running-feast-in-production" target="_blank" rel="noreferrer noopener nofollow">Running Feast in production</a></li><li><a href="https://www.slideshare.net/databricks/the-killer-feature-store-orchestrating-spark-ml-pipelines-and-mlflow-for-production" target="_blank" rel="noreferrer noopener nofollow">The Killer Feature Store: Orchestrating Spark ML Pipelines and MLflow for Production</a></li><li><a href="https://towardsdatascience.com/do-you-need-a-feature-store-35b90c3d8963" target="_blank" rel="noreferrer noopener nofollow">Do you need a feature store?</a></li></ol>
</div>



<div id="author-box-new-format-block_62b32ad88674d" class="article__footer article__author">
  <div class="article__authorImage">
          <img width="209" height="230" src="https://i0.wp.com/neptune.ai/wp-content/uploads/5-Model-Deployment-Mistakes-That-Can-Really-Cost-You_8.png?fit=209%2C230&amp;ssl=1" class="article__authorImage-img" alt="Manuel Martín" decoding="async" data-attachment-id="67679" data-permalink="https://neptune.ai/5-model-deployment-mistakes-that-can-really-cost-you_8" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-Model-Deployment-Mistakes-That-Can-Really-Cost-You_8.png?fit=980%2C1076&amp;ssl=1" data-orig-size="980,1076" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="5 Model Deployment Mistakes That Can Really Cost You_8" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-Model-Deployment-Mistakes-That-Can-Really-Cost-You_8.png?fit=273%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/5-Model-Deployment-Mistakes-That-Can-Really-Cost-You_8.png?fit=933%2C1024&amp;ssl=1" />      </div>

  <div class="article__authorContent">
          <h3 class="article__authorContent-name">Manuel Martín</h3>
    
          <p class="article__authorContent-text">Senior Machine Learning Engineer at Busuu. I like building ML systems and write about technical stuff.</p>
    
          <ul class="article__authorSocial">
        <li class="article__authorSocial-single article__authorSocial-name">Follow me on</li>
        
                  <li class="article__authorSocial-single"><a href="https://www.linkedin.com/in/manuelmart%C3%ADn11/" class="article__authorSocial-lk" target="_blank"></a></li>
        
              </ul>
    
  </div>
</div>


<div class="is-layout-flow wp-block-group"><div class="wp-block-group__inner-container">
<hr class="wp-block-separator has-css-opacity"/>



<p class="has-text-color" style="color:#4455a6"><strong>READ NEXT</strong></p>



<h2>Real-World MLOps Examples: Model Development in Hypefactors</h2>



<p class="has-small-font-size">6 mins read | Author&nbsp;Stephen Oladele | Updated June 28th, 2022</p>


<div id="block_5ffc75def9f8e" class="separator separator-10"></div>



<p>In this first installment of the series “Real-world MLOps Examples,”&nbsp;<a href="https://www.linkedin.com/in/jules-belveze" target="_blank" rel="noreferrer noopener">Jules Belveze</a>, an MLOps Engineer, will walk you through the model development process at&nbsp;<a href="https://hypefactors.com/" target="_blank" rel="noreferrer noopener">Hypefactors</a>, including the types of models they build, how they design their training pipeline, and other details you may find valuable. Enjoy the chat!</p>



<h3 id="company-profile">Company profile</h3>



<p><a href="https://hypefactors.com/" target="_blank" rel="noreferrer noopener">Hypefactors</a>&nbsp;provides an all-in-one media intelligence solution for managing PR and communications, tracking trust, product launches, and market and financial intelligence. They operate large data pipelines that stream in the world’s media data ongoingly in real-time. AI is used for many automations that were previously performed manually.</p>



<h3 id="guest-introduction">Guest introduction</h3>



<h4>Could you introduce yourself to our readers?</h4>



<p>Hey Stephen, thanks for having me! My name is Jules. I am 26. I was born and raised in Paris, I am currently living in Copenhagen.</p>



<h4>Hey Jules! Thanks for the intro. Walk me through your background and how you got to Hypefactors.</h4>



<p>I hold a Bachelor’s in statistics and probabilities and a Master’s in general engineering from universities in France. On top of that, I also graduated in Data Science with a focus on deep learning from Danish Technical University, Denmark. I’m fascinated by multilingual natural language processing (and therefore specialized in it). I also researched anomaly detection on high-dimensional time series during my graduate studies with Microsoft.&nbsp;</p>



<p>Today, I work for a media intelligence tech company called Hypefactors, where I develop NLP models to help our users gain insights from the media landscape. What currently works for me is having the opportunity to carry out models from prototyping all the way to production. I guess you could call me a nerd, at least that’s how my friend describes me, as I spent most of my free time either coding or listening to disco vinyl.</p>



<h3 id="model-development-at-hypefactors">Model development at Hypefactors</h3>



<h4>Could you elaborate on the types of models you build at Hypefactors?</h4>



<p>Even though we also have computer vision models running in production, we mainly build&nbsp;<a href="https://neptune.ai/blog/category/natural-language-processing" target="_blank" rel="noreferrer noopener">NLP (Natural Language Processing)</a>&nbsp;models for various use cases. We need to cover multiple countries and handle many languages. The multilingual aspect makes developing with “classical machine learning” approaches hard. We craft deep learning models on top of the&nbsp;<a href="https://github.com/huggingface/transformers" target="_blank" rel="noreferrer noopener">transformer library</a>.&nbsp;</p>



<p>We run all sorts of models in production, varying from span extraction or sequence classification to text generation. Those models are designed to serve different use cases, like topic classification, sentiment analysis, or summarisation.</p>


<a class="button continous-post blue-filled" href="/blog/mlops" target="_blank">
    Continue reading -&gt;</a>



<hr class="wp-block-separator has-css-opacity"/>
</div></div>
<p>The post <a rel="nofollow" href="https://neptune.ai/blog/data-ingestion-and-feature-store-component-mlops-stack">How to Solve the Data Ingestion and Feature Store Component of the MLOps Stack</a> appeared first on <a rel="nofollow" href="https://neptune.ai">neptune.ai</a>.</p>
]]></content:encoded>
					
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">71407</post-id>	</item>
		<item>
		<title>Feature Selection Methods and How to Choose Them</title>
		<link>https://neptune.ai/blog/feature-selection-methods</link>
		
		<dc:creator><![CDATA[Michał Oleszak]]></dc:creator>
		<pubDate>Fri, 09 Sep 2022 09:23:07 +0000</pubDate>
				<category><![CDATA[ML Model Development]]></category>
		<category><![CDATA[mlops]]></category>
		<guid isPermaLink="false">https://neptune.ai/?p=71265</guid>

					<description><![CDATA[<p>Have you ever found yourself sitting in front of the screen wondering what kind of features will help your machine learning model learn its task best? I bet you have. Data preparation tends to consume vast amounts of data scientists’ and machine learning engineers’ time and energy, and making the data ready to be fed [&#8230;]</p>
<p>The post <a rel="nofollow" href="https://neptune.ai/blog/feature-selection-methods">Feature Selection Methods and How to Choose Them</a> appeared first on <a rel="nofollow" href="https://neptune.ai">neptune.ai</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<p>Have you ever found yourself sitting in front of the screen wondering what kind of features will help your machine learning model learn its task best? I bet you have. Data preparation tends to consume vast amounts of data scientists’ and machine learning engineers’ time and energy, and making the data ready to be fed to the learning algorithms is no small feat.&nbsp;</p>



<p>One of the crucial steps in the data preparation pipeline is <strong>feature selection</strong>. You might know the popular adage: garbage in, garbage out. What you feed your models with is at least as important as the models themselves, if not more so.</p>



<p>In this article, we will:</p>


<div class="custom-point-list">
<ul><li>look at the place of feature selection among other feature-related tasks in the data preparation pipeline </li><li>and discuss the multiple reasons why it is so crucial for any machine learning project’s success. </li><li>Next, we will go over different approaches to feature selection and discuss some tricks and tips to improve their results. </li><li>Then, we will take a glimpse behind the hood of Boruta, the state-of-the-art feature selection algorithm, to check out a clever way to combine different feature selection methods</li><li>And we&#8217;ll look into how feature selection is leveraged in the industry. </li></ul>
</div>


<p>Let’s dive in!</p>



<h2>What is feature selection, and what is it not?</h2>



<p>Let’s kick off by defining our object of interest.&nbsp;</p>



<p>What is feature selection? In a nutshell, it is the process of selecting the subset of features to be used for training a machine learning model.&nbsp;</p>



<p>This is what feature selection is, but it is equally important to understand what feature selection is not – it is neither feature extraction/feature engineering nor it is dimensionality reduction.</p>



<p>Feature extraction and feature engineering are two terms describing the same process of creating new features from the existing ones based on domain knowledge. This yields more features than were originally there, and it should be performed before feature selection. First, we can do feature extraction to come up with many potentially useful features, and then we can perform feature selection in order to pick the best subset that will indeed improve the model’s performance.</p>



<p><a href="/blog/dimensionality-reduction" target="_blank" rel="noreferrer noopener">Dimensionality reduction</a> is yet another concept. It is somewhat similar to feature selection as both aim at reducing the number of features. However, they differ significantly in how they achieve this goal. While feature selection chooses a subset of original features to keep and discards others, dimensionality reduction techniques create projections of original features onto a fewer-dimensional space, thus creating a completely new set of features. Dimensionality reduction, if desired, should be run after feature selection, but in practice, it is either one or the other.</p>



<p>Now we know what feature selection is and how it corresponds to other feature-related data preparation tasks. But why do we even need it?</p>



<h2>7 reasons why we need feature selection</h2>



<p>A popular claim is that modern machine learning techniques do well without feature selection. After all, a model should be able to learn that particular features are useless, and it should focus on the others, right?&nbsp;</p>



<p>Well, this reasoning makes sense to some extent. Linear models could, in theory, assign a weight of zero to useless features, and tree-based models should learn quickly not to make splits on them. In practice, however, many things can go wrong with training when the inputs are irrelevant or redundant &#8211; more on these two terms later. On top of this, there are many other reasons why simply dumping all the available features into the model might not be a good idea. Let’s look at the seven most prominent ones.</p>



<p><strong>1. Irrelevant and redundant features</strong></p>



<p>Some features might be irrelevant to the problem at hand. This means they have no relation with the target variable and are completely unrelated to the task the model is designed to solve. Discarding irrelevant features will prevent the model from picking up on spurious correlations it might carry, thus fending off overfitting.</p>



<p>Redundant features are a different animal, though. Redundancy implies that two or more features share the same information, and all but one can be safely discarded without information loss. Note that an important feature can also be redundant in the presence of another relevant feature. Redundant features should be dropped, as they might pose many problems during training, such as multicollinearity in linear models.</p>



<p><strong>2. Curse of dimensionality</strong></p>



<p>Feature selection techniques are especially indispensable in scenarios with many features but few training examples. Such cases suffer from what is known as the curse of dimensionality: in a very high-dimensional space, each training example is so far from all the other examples that the model cannot learn any useful patterns. The solution is to decrease the dimensionality of the features space, for instance, via feature selection.</p>



<p><strong>3. Training time</strong></p>



<p>The more features, the more training time. The specifics of this trade-off depend on the particular learning algorithm being used, but in situations where retraining needs to happen in real-time, one might need to limit oneself to a couple of best features.</p>



<p><strong>4. Deployment effort</strong></p>



<p>The more features, the more complex the machine learning system becomes in production. This poses multiple risks, including but not limited to high maintenance effort, <a href="https://towardsdatascience.com/8-hazards-menacing-machine-learning-systems-in-production-5c470baa0163" target="_blank" rel="noreferrer noopener nofollow">entanglement, undeclared consumers, or correction cascades</a>.</p>



<p><strong>5. Interpretability</strong></p>



<p>With too many features, we lose the <a href="/blog/explainability-auditability-ml-definitions-techniques-tools" target="_blank" rel="noreferrer noopener">explainability of the model</a>. While not always the primary modeling goal, interpreting and explaining the model’s results are often important and, in some regulated domains, might even constitute a legal requirement. </p>



<p><strong>6. Occam’s Razor</strong></p>



<p>According to this so-called law of parsimony, simpler models should be preferred over the more complex ones as long as their performance is the same. This also has to do with the machine learning engineer’s nemesis, overfitting. Less complex models are less likely to overfit the data.</p>



<p><strong>7. Data-model compatibility</strong></p>



<p>Finally, there is the issue of data-model compatibility. While, in principle, the approach should be data-first, which means collecting and preparing high-quality data and then choosing a model which works well on this data, real life may have it the other way around.&nbsp;</p>



<p>You might be trying to reproduce a particular research paper, or your boss might have suggested using a particular model. In this model-first approach, you might be forced to select features that are compatible with the model you set out to train. For instance, many models don’t work with missing values in the data. Unless you <a href="https://towardsdatascience.com/handling-missing-data-5be11eddbdd" target="_blank" rel="noreferrer noopener nofollow">know your imputation methods well</a>, you might need to drop the incomplete features.</p>



<h2>Different approaches to feature selection</h2>



<p>All the different approaches to feature selection can be grouped into four families of methods, each coming with its pros and cons. There are unsupervised and supervised methods. The latter can be further divided into the wrapper, filter, and embedded methods. Let’s discuss them one by one.</p>


<div class="wp-block-image">
<figure class="aligncenter size-large is-resized"><img data-attachment-id="71268" data-permalink="https://neptune.ai/feature-selection-methods-1" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/feature-selection-methods-1.png?fit=1999%2C1176&amp;ssl=1" data-orig-size="1999,1176" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="feature-selection-methods-1" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/feature-selection-methods-1.png?fit=300%2C176&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/feature-selection-methods-1.png?fit=1024%2C602&amp;ssl=1" decoding="async" src="https://i0.wp.com/neptune.ai/wp-content/uploads/feature-selection-methods-1.png?resize=767%2C452&#038;ssl=1" alt="Different approaches to feature selection" class="wp-image-71268" width="767" height="452" data-recalc-dims="1" /><figcaption><em>Feature selection methods | Source: author </em></figcaption></figure></div>


<h3>Unsupervised feature selection methods</h3>



<p>Just like unsupervised learning is the type of learning that looks for patterns in unlabeled data, similarly, unsupervised feature selection methods are such methods that do not make use of any labels. In other words, they don’t need access to the target variable of the machine learning model.&nbsp;</p>



<p>How can we claim a feature to be unimportant for the model without analyzing its relation to the model’s target, you might ask. Well, in some cases, this is possible. We might want to discard the features with:</p>


<div class="custom-point-list">
<ul><li>Zero or near-zero variance. Features that are (almost) constant provide little information to learn from and thus are irrelevant.</li><li>Many missing values. While dropping incomplete features <a href="https://towardsdatascience.com/handling-missing-data-5be11eddbdd" target="_blank" rel="noreferrer noopener nofollow">is not the prefer</a>red way to handle missing data, it is often a good start, and if too many entries are missing, it might be the only sensible thing to do since such features are likely inconsequential.</li><li>High multicollinearity; multicollinearity means a strong correlation between different features, which might signal redundancy issues.</li></ul>
</div>


<h4>Unsupervised methods in practice</h4>



<p>Let’s now discuss the practical implementation of unsupervised feature selection methods. Just like most other machine learning tasks, feature selection is served very well by the scikit-learn package, and in particular by its `sklearn.feature_selection` module. However, in some cases, one needs to reach out to other places. Here, as well as for the remainder of the article, let’s denote an array or data frame by `X` with all potential features as columns and observation in rows and the targets vector by `y`.</p>


<div class="custom-point-list">
<ul><li>Th<em>e </em>`sklearn.feature_selection.VarianceThreshold` transformer will by default remove all zero-variance features. We can also pass a threshold as an argument to make it remove features whose variance is lower than the threshold.</li></ul>
</div>


<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);"><span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">from</span> sklearn.feature_selection <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">import</span> VarianceThreshold


sel = VarianceThreshold(threshold=<span class="hljs-number" style="color: teal;">0.05</span>)
X_selection = sel.fit_transform(X)
</pre>


<div class="custom-point-list">
<ul><li>In order to drop the columns with missing values, pandas’ `.dropna(axis=1)` method can be used on the data frame.</li></ul>
</div>


<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);">X_selection = X.dropna(axis=<span class="hljs-number" style="color: teal;">1</span>)</pre>


<div class="custom-point-list">
<ul><li>To remove features with high multicollinearity, we first need to measure it. A popular multicollinearity measure is the Variance Inflation Factor or VIF. It is implemented in the statsmodels package.</li></ul>
</div>


<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);"><span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">from</span> statsmodels.stats.outliers_influence <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">import</span> variance_inflation_factor


vif_scores = [variance_inflation_factor(X.values, feature)<span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">for</span> feature <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">in</span> range(len(X.columns))]
</pre>



<p>By convention, columns with a VIF larger than 10 are considered as suffering from multicollinearity, but another threshold may be chosen if it seems more reasonable.</p>



<h3>Wrapper feature selection methods</h3>



<p>Wrapper methods refer to a family of supervised feature selection methods which uses a model to score different subsets of features to finally select the best one. Each new subset is used to train a model whose performance is then evaluated on a hold-out set. The features subset which yields the best model performance is selected. A major advantage of wrapper methods is the fact that they tend to provide the best-performing feature set for the particular chosen type of model.&nbsp;</p>



<p>At the same time, however, it has a limitation. Wrapper methods are likely to overfit to the model type, and the feature subsets they produce might not generalize should one want to try them with a different model.</p>



<p>Another significant disadvantage of wrapper methods is their large computational needs. They require training a large number of models, which might require some time and computing power.&nbsp;</p>



<p>Popular wrapper methods include:</p>


<div class="custom-point-list">
<ul><li><strong>Backward selection</strong>, in which we start with a full model comprising all available features. In subsequent iterations, we remove one feature at a time, always the one that yields the largest gain in a model performance metric, until we reach the desired number of features.</li><li><strong>Forward selection</strong>, which works in the opposite direction: we start from a null model with zero features and add them greedily one at a time to maximize the model’s performance.</li><li><strong>Recursive Feature Elimination</strong>, or RFE, which is similar in spirit to backward selection. It also starts with a full model and iteratively eliminates the features one by one. The difference is in the way the features to discard are chosen. Instead of relying on a model performance metric from a hold-out set, RFE makes its decision based on feature importance extracted from the model. This could be feature weights in linear models, impurity decrease in tree-based models, or permutation importance (which is applicable to any model type).</li></ul>
</div>


<h4>Wrapper methods in practice</h4>



<p>When it comes to wrapper methods, scikit-learn has got us covered:</p>


<div class="custom-point-list">
<ul><li>Backward and forward feature selection can be implemented with the SequentialFeatureSelector transformer. For instance, in order to use the k-Nearest-Neighbor classifier as the scoring model in forward selection, we could use the following code snippet:</li></ul>
</div>


<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);"><span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">from</span> sklearn.feature_selection <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">import</span> SequentialFeatureSelector

knn = KNeighborsClassifier(n_neighbors=<span class="hljs-number" style="color: teal;">3</span>)
sfs = SequentialFeatureSelector(knn, n_features_to_select=<span class="hljs-number" style="color: teal;">3</span>, direction=”forward”)
sfs.fit(X, y)
X_selection = sfs.transform(X)
</pre>


<div class="custom-point-list">
<ul><li>Recursive Feature Elimination is implemented in a very similar fashion. Here is a snippet implementing RFE based on feature importance from a Support Vector Classifier.</li></ul>
</div>


<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);"><span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">from</span> sklearn.feature_selection <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">import</span> RFE

svc = SVC(kernel=<span class="hljs-string" style="color: rgb(221, 17, 68);">"linear"</span>)
rfe = RFE(svc, n_features_to_select=<span class="hljs-number" style="color: teal;">3</span>)
rfe.fit(X, y)
X_selection = rfe.transform(X)
</pre>



<h3>Filter feature selection methods</h3>



<p>Another member of the supervised family is filter methods. They can be thought of as a simpler and faster alternative to wrappers. In order to evaluate the usefulness of each feature, they simply analyze its statistical relation with the model’s target, using measures such as correlation or mutual information as a proxy for the model performance metric.</p>



<p>Not only filter methods faster than wrappers, but they are also more general since they are model-agnostic; they won’t overfit to any particular algorithm. They are also pretty easy to interpret: a feature is discarded if it has no statistical relationship to the target.</p>



<p>On the other hand, however, filter methods have one major drawback. They look at each feature in isolation, evaluating its relation to the target. This makes them prone to discarding useful features that are weak predictors of the target on their own but add a lot of value to the model when combined with other features.</p>



<h4>Filter methods in practice</h4>



<p>Let’s now take a look at implementing various filter methods. These will need some more glue code to implement. First, we need to compute the desired correlation measure between each feature and the target. Then, we would sort all features according to the results and keep the desired number (top-K or top-30%) of the ones with the strongest correlation. Luckily, scikit-learn provides some utilities to help in this endeavour.</p>


<div class="custom-point-list">
<ul><li>To keep the top 2 features with the strongest Pearson correlation with the target, we can run:</li></ul>
</div>


<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);"><span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">from</span> sklearn.feature_selection <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">import</span> r_regression, SelectKBest

X_selection = SelectKBest(r_regression, k=<span class="hljs-number" style="color: teal;">2</span>).fit_transform(X, y)</pre>


<div class="custom-point-list">
<ul><li>Similarly, to keep the top 30% of features, we would run:</li></ul>
</div>


<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);">	<span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">from</span> sklearn.feature_selection <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">import</span> r_regression, SelectPercentile

	X_selection = SelectPercentile(r_regression, percentile=<span class="hljs-number" style="color: teal;">30</span>).fit_transform(X, y)</pre>



<p>The `SelectKBest` and `SelectPercentile` methods will also work with custom or non-scikit-learn correlation measures, as long as they return a vector of length equal to the number of features, with a number for each feature denoting the strength of its association with the target. Let’s now take a look at how to calculate all the different correlation measures out there (we will discuss what they mean and when to choose which later).</p>


<div class="custom-point-list">
<ul><li>Spearman’s Rho, Kendall Tau, and point-biserial correlation are all available in the scipy package. This is how to get their values for each feature in X.</li></ul>
</div>


<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);"><span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">from</span> scipy <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">import</span> stats

rho_corr = [stats.spearmanr(X[:, f], y).correlation <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">for</span> f <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">in</span> range(X.shape[<span class="hljs-number" style="color: teal;">1</span>])]

tau_corr = [stats.kendalltau(X[:, f], y).correlation <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">for</span> f <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">in</span> range(X.shape[<span class="hljs-number" style="color: teal;">1</span>])]

pbs_corr = [stats.pointbiserialr(X[:, f], y).correlation <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">for</span> f <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">in</span> range(X.shape[<span class="hljs-number" style="color: teal;">1</span>])]
</pre>


<div class="custom-point-list">
<ul><li>Chi-Squared, Mutual Information, and ANOVA F-score are all in scikit-learn. Note that mutual information has a separate implementation, depending on whether the target is nominal or not.</li></ul>
</div>


<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);"><span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">from</span> sklearn.feature_selection <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">import</span> chi2
<span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">from</span> sklearn.feature_selection <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">import</span> mutual_info_regression
<span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">from</span> sklearn.feature_selection <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">import</span> mutual_info_classif
<span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">from</span> sklearn.feature_selection <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">import</span> f_classif

chi2_corr = chi2(X, y)[<span class="hljs-number" style="color: teal;">0</span>]
f_corr = f_classif(X, y)[<span class="hljs-number" style="color: teal;">0</span>]
mi_reg_corr = mutual_info_regression(X, y)
mi_class_corr = mutual_info_classif(X, y)
</pre>


<div class="custom-point-list">
<ul><li>Cramer’s V can be obtained from a recent scipy version (1.7.0 or higher).</li></ul>
</div>


<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);"><span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">from</span> scipy.stats.contingency <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">import</span> association

v_corr = [association(np.hstack([X[:, f].reshape(<span class="hljs-number" style="color: teal;">-1</span>, <span class="hljs-number" style="color: teal;">1</span>), y.reshape(<span class="hljs-number" style="color: teal;">-1</span>, <span class="hljs-number" style="color: teal;">1</span>)]), method=<span class="hljs-string" style="color: rgb(221, 17, 68);">"cramer"</span>) <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">for</span> f <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">in</span> range(X.shape[<span class="hljs-number" style="color: teal;">1</span>])]
</pre>



<h3>Embedded feature selection methods</h3>



<p>The final approach to feature selection we will discuss is to embed it into the learning algorithm itself. The idea is to combine the best of both worlds: speed of the filters, while getting the best subset for the particular model just like from a wrapper.</p>



<h4>Embedded methods in practice</h4>



<p>The flagship example is the LASSO regression. It is basically just regularized linear regression, in which feature weights are shrunk towards zero in the loss function. As a result, many features end up with weights of zero, meaning they are discarded from the model, while the rest with non-zero weights are included.</p>



<p>The problem with embedded methods is that there are not that many algorithms out there with feature selection built-in. Another example next to LASSO comes from computer vision: <a href="https://towardsdatascience.com/autoencoders-from-vanilla-to-variational-6f5bb5537e4a" target="_blank" rel="noreferrer noopener nofollow">auto-encoders</a> with a bottleneck layer force the network to disregard some of the least useful features of the image and focus on the most important ones. Other than that, there aren’t many useful examples.</p>



<h2>Filter feature selection methods: useful tricks &amp; tips</h2>



<p>As we have seen, wrapper methods are slow, computationally heavy, and model-specific, and there are not many embedded methods. As a result, filters are often the go-to family of feature selection methods.&nbsp;</p>



<p>At the same time, they require the most expertise and attention to detail. While embedded methods work out of the box and wrappers are fairly simple to implement (especially when one just calls scikit-learn functions), filters ask for a pinch of statistical sophistication. Let us now turn our attention to filter methods and discuss them in more detail.</p>



<p>Filter methods need to evaluate the statistical relationship between each feature and the target. As simple as it may sound, there’s more to it than meets the eye. There are many statistical methods to measure the relationship between two variables. To know which one to choose in a particular case, we need to think back to our first STATS101 class and brush up on <a href="https://towardsdatascience.com/data-measurement-levels-dfa9a4564176" target="_blank" rel="noreferrer noopener nofollow">data measurement levels</a>.</p>



<h3>Data measurement levels</h3>



<p>In a nutshell, a variable’s measurement level describes the true meaning of the data and the types of mathematical operations that make sense for these data. There are four measurement levels: nominal, ordinal, interval, and ratio.</p>


<div class="wp-block-image">
<figure class="aligncenter size-full is-resized"><img data-attachment-id="71269" data-permalink="https://neptune.ai/feature-selection-methods-2" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/feature-selection-methods-2.png?fit=610%2C198&amp;ssl=1" data-orig-size="610,198" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="feature-selection-methods-2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/feature-selection-methods-2.png?fit=300%2C97&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/feature-selection-methods-2.png?fit=610%2C198&amp;ssl=1" decoding="async" src="https://i0.wp.com/neptune.ai/wp-content/uploads/feature-selection-methods-2.png?resize=693%2C225&#038;ssl=1" alt="Tabel with data measurement levels" class="wp-image-71269" width="693" height="225" data-recalc-dims="1" /><figcaption><em>Data measurement levels | <a href="https://towardsdatascience.com/data-measurement-levels-dfa9a4564176" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>

<div class="custom-point-list">
<ul><li>Nominal features, such as color (“red”, “green” or “blue”) have no ordering between the values; they simply group<em> </em>observations based on them.&nbsp;</li></ul>
</div>

<div class="custom-point-list">
<ul><li>Ordinal features, such as education level (“primary”, “secondary”, “tertiary”) denote order, but not the differences between particular levels (we cannot say that the difference between “primary” and “secondary” is the same as the one between “secondary” and “tertiary”).&nbsp;</li></ul>
</div>

<div class="custom-point-list">
<ul><li>Interval features, such as temperature in degrees Celsius, keep the intervals equal (the difference between 25 and 20 degrees is the same as between 30 and 25).&nbsp;</li></ul>
</div>

<div class="custom-point-list">
<ul><li>Finally, ratio features, such as price in USD, are characterized by a meaningful zero, which allows us to calculate ratios between two data points: we can say that $4 is twice as much as $2.</li></ul>
</div>


<p>In order to choose the right statistical tool to measure the relation between two variables, we need to think about their measurement levels.</p>



<h3>Measuring correlations for various data types</h3>



<p>When the two variables we compare, i.e., the feature and the target, are both either interval or ratio, we are allowed to use the most popular correlation measure out there: the <strong>Pearson correlation</strong>, also known as <strong>Pearson’s r</strong>.&nbsp;</p>



<p>This is great, but Pearson correlation comes with two drawbacks: it assumes both variables are normally distributed, and it only measures the linear correlation between them. When the correlation is non-linear, Pearson’s r won’t detect it, even if it’s really strong.&nbsp;</p>



<p>You might have heard about the <em>Datasaurus</em> dataset compiled by Alberto Cairo. It consists of 13 pairs of variables, each with the same very weak Pearson correlation of -0.06. As it quickly becomes obvious once we plot them, the pairs are actually correlated pretty strongly, albeit in a non-linear way.</p>


<div class="wp-block-image">
<figure class="aligncenter size-full is-resized"><img data-attachment-id="71270" data-permalink="https://neptune.ai/feature-selection-methods-3" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/feature-selection-methods-3.png?fit=597%2C426&amp;ssl=1" data-orig-size="597,426" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="feature-selection-methods-3" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/feature-selection-methods-3.png?fit=300%2C214&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/feature-selection-methods-3.png?fit=597%2C426&amp;ssl=1" decoding="async" src="https://i0.wp.com/neptune.ai/wp-content/uploads/feature-selection-methods-3.png?resize=597%2C426&#038;ssl=1" alt="The Datasaurus dataset" class="wp-image-71270" width="597" height="426" data-recalc-dims="1" /><figcaption><em>The Datasaurus dataset by Alberto Cairo | <a href="https://www.autodesk.com/research/publications/same-stats-different-graphs" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>


<p>When non-linear relations are to be expected, one of the alternatives to Pearson&#8217;s correlation should be taken into account. The two most popular ones are:</p>


<div class="custom-point-list">
<ol><li><strong>Spearman’s rank correlation (Spearman’s Rho),</strong></li></ol>
</div>


<p>Spearman’s rank correlation is an alternative to Pearson correlation for ratio/interval variables. As the name suggests, it only looks at the rank values, i.e. it compares the two variables in terms of the relative positions of particular data points within the variables. It is able to capture non-linear relations, but there are no free lunches: we lose some information due to only considering the rank instead of the exact data points.</p>


<div class="custom-point-list">
<ol start="2"><li><strong>Kendall rank correlation (Kendall Tau).</strong></li></ol>
</div>


<p>Another rank-based correlation measure is the Kendall rank correlation.<strong> </strong>It is similar in spirit to Spearman’s correlation but formulated in a slightly different way (Kendall&#8217;s calculations are based on concordant and discordant pairs of values, as opposed to Spearman’s calculations based on deviations). Kendall is often regarded as more robust to outliers in the data.</p>



<p>If at least one of the compared variables is of ordinal type, Spearman’s or Kendall rank correlation is the way to go. Due to the fact that ordinal data contains only the information on the ranks, they are both a perfect fit, while Pearson’s linear correlation is of little use.</p>



<p>Another scenario is when both variables are nominal. In this case, we can choose from a couple of different correlation measures:</p>


<div class="custom-point-list">
<ul><li><strong>Cramer’s V</strong>, which captures the association between the two variables into a number ranging from zero (no association) to one (one variable completely determined by the other).</li><li><strong>Chi-Squared statistic</strong> commonly used for testing for dependence between two variables. Lack of dependence suggests the particular feature is not useful.</li><li><strong>Mutual information</strong> a measure of mutual dependence between two variables that seeks to quantify the amount of information that one can extract from one variable about the other.</li></ul>
</div>


<p>Which one to choose? There is no one-size-fits-all answer. As usual, each method comes with some pros and cons. Cramer’s V is known to overestimate the association’s strength. Mutual information, being a non-parametric method, requires larger data samples to yield reliable results. Finally, the Chi-Squared does not provide information about the strength of the relationship, but rather only whether it exists or not.</p>



<p>We have discussed scenarios in which the two variables we compare are both interval or ratio, when at least one of them is ordinal, and when we compare two nominal variables. The final possible encounter is to compare a nominal variable with a non-nominal one.</p>



<p>In such cases, the two most widely-used correlation measures are:</p>


<div class="custom-point-list">
<ul><li><strong>ANOVA F-score</strong>, a chi-squared equivalent for the case when one of the variables is continuous while the other is nominal,</li><li><strong>Point-biserial correlation</strong> a correlation measure especially designed to evaluate the relationship between a binary and a continuous variable.</li></ul>
</div>


<p>Once again, there is no silver bullet. The F-score only captures linear relations, while point-biserial correlation makes some strong normality assumption that might not hold in practice, undermining its results.</p>



<p>Having said all that, which method should one choose in a particular case? The table below will hopefully provide some guidance in this matter.</p>


<div id="block_631894b437194" class="separator separator-20"></div>


<div class="medium-table">
        <div class="mt-row heading">
            <div class="mt-col" style="width: 17.5%">
            Variable 1        </div>
            <div class="mt-col" style="width: 17.5%">
            Variable 2        </div>
            <div class="mt-col" style="width: 20%">
            Method        </div>
            <div class="mt-col" style="width: 45%">
            Comments        </div>
        </div>
    
            <div class="mt-row">
                            <div class="mt-col" style="width: 17.5%">
                                                                <table>
<tbody>
<tr>
<td rowspan="3"><span style="font-weight: 400;">Interval / ratio</span></td>
</tr>
</tbody>
</table>
                                    </div>
                            <div class="mt-col" style="width: 17.5%">
                                        <span class="column-name">
                        Variable 2:
                    </span>
                                                                <table>
<tbody>
<tr>
<td rowspan="3"><span style="font-weight: 400;">Interval / ratio</span></td>
</tr>
</tbody>
</table>
                                    </div>
                            <div class="mt-col" style="width: 20%">
                                        <span class="column-name">
                        Method:
                    </span>
                                                                <table>
<tbody>
<tr>
<td><span style="font-weight: 400;">Pearson’s r</span></td>
</tr>
</tbody>
</table>
                                    </div>
                            <div class="mt-col" style="width: 45%">
                                        <span class="column-name">
                        Comments:
                    </span>
                                                                <table>
<tbody>
<tr>
<td><span style="font-weight: 400;">Only captures linear relations, assumes normality</span></td>
</tr>
</tbody>
</table>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 17.5%">
                                                                                                    </div>
                            <div class="mt-col" style="width: 17.5%">
                                        <span class="column-name">
                        Variable 2:
                    </span>
                                                                                                    </div>
                            <div class="mt-col" style="width: 20%">
                                        <span class="column-name">
                        Method:
                    </span>
                                                                <table>
<tbody>
<tr>
<td><span style="font-weight: 400;">Spearman’s Rho</span></td>
</tr>
</tbody>
</table>
                                    </div>
                            <div class="mt-col" style="width: 45%">
                                        <span class="column-name">
                        Comments:
                    </span>
                                                                <table>
<tbody>
<tr>
<td><span style="font-weight: 400;">When nonlinear relations are expected</span></td>
</tr>
</tbody>
</table>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 17.5%">
                                                                                                    </div>
                            <div class="mt-col" style="width: 17.5%">
                                        <span class="column-name">
                        Variable 2:
                    </span>
                                                                                                    </div>
                            <div class="mt-col" style="width: 20%">
                                        <span class="column-name">
                        Method:
                    </span>
                                                                <table>
<tbody>
<tr>
<td><span style="font-weight: 400;">Kendall Tau</span></td>
</tr>
</tbody>
</table>
                                    </div>
                            <div class="mt-col" style="width: 45%">
                                        <span class="column-name">
                        Comments:
                    </span>
                                                                <p><span style="font-weight: 400;">When nonlinear relations are expected</span></p>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 17.5%">
                                                                <table>
<tbody>
<tr>
<td rowspan="2"><span style="font-weight: 400;">Interval / ratio</span></td>
</tr>
</tbody>
</table>
                                    </div>
                            <div class="mt-col" style="width: 17.5%">
                                        <span class="column-name">
                        Variable 2:
                    </span>
                                                                <p><span style="font-weight: 400;">Ordinal</span></p>
                                    </div>
                            <div class="mt-col" style="width: 20%">
                                        <span class="column-name">
                        Method:
                    </span>
                                                                <table>
<tbody>
<tr>
<td><span style="font-weight: 400;">Spearman’s Rho</span></td>
</tr>
</tbody>
</table>
                                    </div>
                            <div class="mt-col" style="width: 45%">
                                        <span class="column-name">
                        Comments:
                    </span>
                                                                <table>
<tbody>
<tr>
<td><span style="font-weight: 400;">Based on ranks only, captures nonlinearities</span></td>
</tr>
</tbody>
</table>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 17.5%">
                                                                                                    </div>
                            <div class="mt-col" style="width: 17.5%">
                                        <span class="column-name">
                        Variable 2:
                    </span>
                                                                                                    </div>
                            <div class="mt-col" style="width: 20%">
                                        <span class="column-name">
                        Method:
                    </span>
                                                                <table>
<tbody>
<tr>
<td><span style="font-weight: 400;">Kendall Tau</span></td>
</tr>
</tbody>
</table>
                                    </div>
                            <div class="mt-col" style="width: 45%">
                                        <span class="column-name">
                        Comments:
                    </span>
                                                                <p><span style="font-weight: 400;">Like Rho, but more robust to outliers</span></p>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 17.5%">
                                                                <p><span style="font-weight: 400;">Nominal </span></p>
                                    </div>
                            <div class="mt-col" style="width: 17.5%">
                                        <span class="column-name">
                        Variable 2:
                    </span>
                                                                <p><span style="font-weight: 400;">Nominal </span></p>
                                    </div>
                            <div class="mt-col" style="width: 20%">
                                        <span class="column-name">
                        Method:
                    </span>
                                                                <table>
<tbody>
<tr>
<td><span style="font-weight: 400;">Cramer’s V</span></td>
</tr>
</tbody>
</table>
                                    </div>
                            <div class="mt-col" style="width: 45%">
                                        <span class="column-name">
                        Comments:
                    </span>
                                                                <table>
<tbody>
<tr>
<td><span style="font-weight: 400;">May overestimate correlation strength</span></td>
</tr>
</tbody>
</table>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 17.5%">
                                                                                                    </div>
                            <div class="mt-col" style="width: 17.5%">
                                        <span class="column-name">
                        Variable 2:
                    </span>
                                                                                                    </div>
                            <div class="mt-col" style="width: 20%">
                                        <span class="column-name">
                        Method:
                    </span>
                                                                <p><span style="font-weight: 400;">Chi-Squared</span></p>
                                    </div>
                            <div class="mt-col" style="width: 45%">
                                        <span class="column-name">
                        Comments:
                    </span>
                                                                <table>
<tbody>
<tr>
<td><span style="font-weight: 400;">No info on correlation’s strength</span></td>
</tr>
</tbody>
</table>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 17.5%">
                                                                                                    </div>
                            <div class="mt-col" style="width: 17.5%">
                                        <span class="column-name">
                        Variable 2:
                    </span>
                                                                                                    </div>
                            <div class="mt-col" style="width: 20%">
                                        <span class="column-name">
                        Method:
                    </span>
                                                                <p><span style="font-weight: 400;">Mutual Information</span></p>
                                    </div>
                            <div class="mt-col" style="width: 45%">
                                        <span class="column-name">
                        Comments:
                    </span>
                                                                <table>
<tbody>
<tr>
<td><span style="font-weight: 400;">Requires many data samples.</span></td>
</tr>
</tbody>
</table>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 17.5%">
                                                                <table>
<tbody>
<tr>
<td rowspan="2"><span style="font-weight: 400;">Nominal</span></td>
</tr>
</tbody>
</table>
                                    </div>
                            <div class="mt-col" style="width: 17.5%">
                                        <span class="column-name">
                        Variable 2:
                    </span>
                                                                <p><span style="font-weight: 400;">Interval / ratio </span><span style="font-weight: 400;">/ ordinal</span></p>
                                    </div>
                            <div class="mt-col" style="width: 20%">
                                        <span class="column-name">
                        Method:
                    </span>
                                                                <table>
<tbody>
<tr>
<td><span style="font-weight: 400;">F-score</span></td>
</tr>
</tbody>
</table>
                                    </div>
                            <div class="mt-col" style="width: 45%">
                                        <span class="column-name">
                        Comments:
                    </span>
                                                                <table>
<tbody>
<tr>
<td><span style="font-weight: 400;">Only captures linear relations</span></td>
</tr>
</tbody>
</table>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 17.5%">
                                                                                                    </div>
                            <div class="mt-col" style="width: 17.5%">
                                        <span class="column-name">
                        Variable 2:
                    </span>
                                                                                                    </div>
                            <div class="mt-col" style="width: 20%">
                                        <span class="column-name">
                        Method:
                    </span>
                                                                <table>
<tbody>
<tr>
<td><span style="font-weight: 400;">Point-biserial</span></td>
</tr>
</tbody>
</table>
                                    </div>
                            <div class="mt-col" style="width: 45%">
                                        <span class="column-name">
                        Comments:
                    </span>
                                                                <table>
<tbody>
<tr>
<td><span style="font-weight: 400;">Makes strong normality assumptions</span></td>
</tr>
</tbody>
</table>
                                    </div>
                    </div>
    </div>


<div id="block_6318949637193" class="separator separator-15"></div>



<p class="has-text-align-center"><em>Comparison of different methods</em></p>



<h2>Take no prisoners: Boruta needs no human input</h2>



<p>When talking about feature selection, we cannot fail to mention Boruta. Back in 2010, when it was <a href="https://www.jstatsoft.org/article/view/v036i11" target="_blank" rel="noreferrer noopener nofollow">first published</a> as an R package, it quickly became famous as a revolutionary feature selection algorithm.</p>



<h3>Why is Boruta a game-changer?</h3>



<p>All the other methods we have discussed so far require a human to make an arbitrary decision. Unsupervised methods need us to set the variance or VIF threshold for feature removal. Wrappers require us to decide on the number of features we want to keep upfront. Filters need us to choose the correlation measure and the number of features to keep as well. Embedded methods have us select regularization strength. Boruta needs none of these.</p>



<p>Boruta is a simple yet statistically elegant algorithm. It uses feature importance measures from a random forest model to select the best subset of features, and it does so via introducing two clever ideas.</p>


<div class="custom-point-list">
<ol><li>First, the importance scores of features are not compared to one another. Rather, the importance of each feature competes against the importance of its randomized version. To achieve this, Boruta randomly permutes each feature to construct its “shadow” version.&nbsp;</li></ol>
</div>


<p class="has-text-align-left">Then, a random forest is trained on the whole feature set, including the new shadow features. The maximum feature importance among the shadow features serves as a threshold. Of the original features, only those whose importance is above this threshold score a point. In other words, only features that are more important than random vectors are awarded points.&nbsp;</p>



<p>This process is repeated iteratively multiple times. Since each time the random permutation is different, the threshold also differs, and so different features might score points. After multiple iterations, each of the original features has some number of points to its name.&nbsp;</p>


<div class="custom-point-list">
<ol start="2"><li>The final step is to decide, based on the number of points each feature scored, whether it should be kept or discarded. Here enters the other of Boruta’s two clever ideas: we can model the scores using a <a href="https://towardsdatascience.com/6-useful-probability-distributions-with-applications-to-data-science-problems-2c0bee7cef28" target="_blank" rel="noreferrer noopener nofollow">binomial distribution</a>.</li></ol>
</div>


<p>Each iteration is assumed to be a separate trial. If the feature scored in a given iteration, it is a vote to keep it; if it did not, it’s a vote to discard it. A priori, we have no idea whatsoever whether a feature is important or not, so the expected percentage of trials in which the feature scores is 50%. Hence, we can model the number of points scored with a binomial distribution with p=0.5. If our feature scores significantly more times than this, it is deemed important and kept. If it scores significantly fewer times, it’s deemed unimportant and discarded. If it scores in around 50% of trials, its status is unresolved, but for the sake of being conservative, we can keep it.</p>



<p>For example, if we let Boruta run for 100 trials, the expected score of each feature would be 50. If it’s closer to zero, we discard it, if it’s closer to 100, we keep it.</p>


<div class="wp-block-image">
<figure class="aligncenter size-large is-resized"><a href="https://i0.wp.com/neptune.ai/wp-content/uploads/feature-selection-methods-4.png?ssl=1"><img data-attachment-id="71271" data-permalink="https://neptune.ai/feature-selection-methods-4" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/feature-selection-methods-4.png?fit=1356%2C1110&amp;ssl=1" data-orig-size="1356,1110" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="feature-selection-methods-4" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/feature-selection-methods-4.png?fit=300%2C246&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/feature-selection-methods-4.png?fit=1024%2C838&amp;ssl=1" decoding="async" src="https://i0.wp.com/neptune.ai/wp-content/uploads/feature-selection-methods-4.png?resize=512%2C419&#038;ssl=1" alt="Graph with example of Boruta" class="wp-image-71271" width="512" height="419" data-recalc-dims="1" /></a><figcaption><em>Boruta example | Source: author&nbsp;</em></figcaption></figure></div>


<p>Boruta has proven very successful in many Kaggle competitions and is always worth trying out. It has also been successfully used for <a href="https://www.mdpi.com/1996-1073/14/10/2779" target="_blank" rel="noreferrer noopener nofollow">predicting energy consumption for building heating</a> or <a href="https://www.researchgate.net/publication/353955153_An_application_of_Machine_learning_with_Boruta_Feature_selection_to_Improve_NO2_pollution_prediction" target="_blank" rel="noreferrer noopener nofollow">predicting air pollution</a>.</p>



<p>There is a very intuitive Python package to implement Boruta, called <a href="https://github.com/scikit-learn-contrib/boruta_py" target="_blank" rel="noreferrer noopener nofollow">BorutaPy</a> (now part of scikit-learn-contrib). The package’s GitHub readme demonstrates how easy it is to run feature selection with Boruta.</p>



<h2>Which feature selection method to choose? Build yourself a voting selector</h2>



<p>We have discussed many different feature selection methods. Each of them has its own strengths and weaknesses, makes its own assumptions, and arrives at its conclusions in a different fashion. Which one to choose? Or do we have to choose? In many cases combining all these different methods together under one roof would make the resulting feature selector stronger than each of its subparts.</p>



<h3>The inspiration</h3>



<p>One way to do it is inspired by ensembled decision trees. In this class of models, which includes random forests and many popular gradients boosting algorithms, one trains multiple different models and lets them vote on the final prediction. In a similar spirit, we can build ourselves a voting selector.</p>



<p>The idea is simple: implement a couple of feature selection methods we have discussed. Your choice could be guided by your time, computational resources, and data measurement levels. Just run as many different methods as you conveniently can afford. Then, for each feature, write down the percentage of selection methods that suggest keeping this feature in the data set. If more than 50% of the methods vote to keep the feature, keep it – otherwise, discard it.</p>



<p>The idea behind this approach is that while some methods might make wrong judgments with regard to some of the features due to their intrinsic biases, the ensemble of methods should get the set of useful features right. Let’s see how to implement it in practice!</p>



<h3>The implementation</h3>



<p>Let’s build a simple voting selector that ensembles three different features selection methods:</p>


<div class="case-study-numbered-list">
    <h2></h2>
    <ul>
                    <li><span>1</span>A filter method based on Pearson correlation.<br />
</li>
                    <li><span>2</span>An unsupervised method based on multicollinearity.<br />
</li>
                    <li><span>3</span>A wrapper, Recursive Feature Elimination. </li>
            </ul>
</div>



<p>Let’s take a look at how such a voting selector might look like.&nbsp;</p>



<p>Making the imports.</p>



<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);"><span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">from</span> itertools <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">import</span> compress

<span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">import</span> pandas <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">as</span> pd
<span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">from</span> sklearn.feature_selection <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">import</span> RFE, r_regression, SelectKBest
<span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">from</span> sklearn.svm <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">import</span> SVR
<span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">from</span> statsmodels.stats.outliers_influence <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">import</span> variance_inflation_factor</pre>



<p>Next, Our VotingSelector class comprises four methods on top of the init constructor. Three of them implement the three feature selection techniques we would like to ensemble:</p>


<div class="case-study-numbered-list">
    <h2></h2>
    <ul>
                    <li><span>1</span> _select_pearson() for Pearson correlation filtering<br />
</li>
                    <li><span>2</span> _select_vif() for Variance Inflation Factor-based unsupervised approach<br />
</li>
                    <li><span>3</span> _select_rbf() for the RBF wrapper</li>
            </ul>
</div>



<p>Each of these methods takes the feature matrix X and the targets y as inputs. The VIF-based method will not use the targets, but we use this argument anyway to keep the interface consistent across all methods so that we can conveniently call them in a loop later. On top of that, each method accepts a keyword arguments dictionary which we will use to pass method-dependent parameters. Having parsed the inputs, each method calls the appropriate sklearn or statsmodels functions which we have discussed before, to return the list of feature names to keep.</p>



<p>The voting magic happens in the select() method. There, we simply iterate over the three selection methods, and for each feature, we record whether it should be kept (1) or discarded (0) according to this method. Finally, we take the mean over these votes. For each feature, if this mean is greater than the voting threshold of 0.5 (which means that at least two out of three methods voted to keep a feature), we keep it.&nbsp;</p>



<p>Here is the code for the entire class.</p>



<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);"><span class="hljs-class"><span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">class</span> <span class="hljs-title" style="color: rgb(68, 85, 136); font-weight: 700;">VotingSelector</span><span class="hljs-params">()</span>:</span>
   <span class="hljs-function"><span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">def</span> <span class="hljs-title" style="color: rgb(153, 0, 0); font-weight: 700;">__init__</span><span class="hljs-params">(self)</span>:</span>
       self.selectors = {
           <span class="hljs-string" style="color: rgb(221, 17, 68);">"pearson"</span>: self._select_pearson,
           <span class="hljs-string" style="color: rgb(221, 17, 68);">"vif"</span>: self._select_vif,
           <span class="hljs-string" style="color: rgb(221, 17, 68);">"rfe"</span>: self._select_rfe,
       }
       self.votes = <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">None</span>

<span class="hljs-meta" style="font-weight: 700; color: rgb(153, 153, 153);">   @staticmethod</span>
   <span class="hljs-function"><span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">def</span> <span class="hljs-title" style="color: rgb(153, 0, 0); font-weight: 700;">_select_pearson</span><span class="hljs-params">(X, y, **kwargs)</span>:</span>
       selector = SelectKBest(r_regression, k=kwargs.get(<span class="hljs-string" style="color: rgb(221, 17, 68);">"n_features_to_select"</span>, <span class="hljs-number" style="color: teal;">5</span>)).fit(X, y)
       <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">return</span> selector.get_feature_names_out()

<span class="hljs-meta" style="font-weight: 700; color: rgb(153, 153, 153);">   @staticmethod</span>
   <span class="hljs-function"><span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">def</span> <span class="hljs-title" style="color: rgb(153, 0, 0); font-weight: 700;">_select_vif</span><span class="hljs-params">(X, y, **kwargs)</span>:</span>
       <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">return</span> [
           X.columns[feature_index]
           <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">for</span> feature_index <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">in</span> range(len(X.columns))
           <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">if</span> variance_inflation_factor(X.values, feature_index) &lt;= kwargs.get(<span class="hljs-string" style="color: rgb(221, 17, 68);">"vif_threshold"</span>, <span class="hljs-number" style="color: teal;">10</span>)
       ]

<span class="hljs-meta" style="font-weight: 700; color: rgb(153, 153, 153);">   @staticmethod</span>
   <span class="hljs-function"><span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">def</span> <span class="hljs-title" style="color: rgb(153, 0, 0); font-weight: 700;">_select_rfe</span><span class="hljs-params">(X, y, **kwargs)</span>:</span>
       svr = SVR(kernel=<span class="hljs-string" style="color: rgb(221, 17, 68);">"linear"</span>)
       rfe = RFE(svr, n_features_to_select=kwargs.get(<span class="hljs-string" style="color: rgb(221, 17, 68);">"n_features_to_select"</span>, <span class="hljs-number" style="color: teal;">5</span>))
       rfe.fit(X, y)
       <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">return</span> rfe.get_feature_names_out()

   <span class="hljs-function"><span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">def</span> <span class="hljs-title" style="color: rgb(153, 0, 0); font-weight: 700;">select</span><span class="hljs-params">(self, X, y, voting_threshold=<span class="hljs-number" style="color: teal;">0.5</span>, **kwargs)</span>:</span>
       votes = []
       <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">for</span> selector_name, selector_method <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">in</span> self.selectors.items():
           features_to_keep = selector_method(X, y, **kwargs)
           votes.append(
               pd.DataFrame([int(feature <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">in</span> features_to_keep) <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">for</span> feature <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">in</span> X.columns]).T
           )
       self.votes = pd.concat(votes)
       self.votes.columns = X.columns
       self.votes.index = self.selectors.keys()
       features_to_keep = list(compress(X.columns, self.votes.mean(axis=<span class="hljs-number" style="color: teal;">0</span>) &gt; voting_threshold))
       <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">return</span> X[features_to_keep]

</pre>



<p>Let’s see it working in practice. We will load the infamous Boston Housing data, which comes built-in within scikit-learn.</p>



<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);"><span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">from</span> sklearn.datasets <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">import</span> load_boston
boston = load_boston()
X = pd.DataFrame(boston[<span class="hljs-string" style="color: rgb(221, 17, 68);">"data"</span>], columns=boston[<span class="hljs-string" style="color: rgb(221, 17, 68);">"feature_names"</span>])
y = boston[<span class="hljs-string" style="color: rgb(221, 17, 68);">"target"</span>]

</pre>



<p>Now, running feature selection is as easy as this:</p>



<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);">vs = VotingSelector()
X_selection = vs.select(X, y)</pre>



<p>As a result, we get the feature matrix with only three features left.</p>



<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);">      ZN  CHAS     RM
<span class="hljs-number" style="color: teal;">0</span>    <span class="hljs-number" style="color: teal;">18.0</span>   <span class="hljs-number" style="color: teal;">0.0</span>  <span class="hljs-number" style="color: teal;">6.575</span>
<span class="hljs-number" style="color: teal;">1</span>     <span class="hljs-number" style="color: teal;">0.0</span>   <span class="hljs-number" style="color: teal;">0.0</span>  <span class="hljs-number" style="color: teal;">6.421</span>
<span class="hljs-number" style="color: teal;">2</span>     <span class="hljs-number" style="color: teal;">0.0</span>   <span class="hljs-number" style="color: teal;">0.0</span>  <span class="hljs-number" style="color: teal;">7.185</span>
<span class="hljs-number" style="color: teal;">3</span>     <span class="hljs-number" style="color: teal;">0.0</span>   <span class="hljs-number" style="color: teal;">0.0</span>  <span class="hljs-number" style="color: teal;">6.998</span>
<span class="hljs-number" style="color: teal;">4</span>     <span class="hljs-number" style="color: teal;">0.0</span>   <span class="hljs-number" style="color: teal;">0.0</span>  <span class="hljs-number" style="color: teal;">7.147</span>
..    ...   ...    ...
<span class="hljs-number" style="color: teal;">501</span>   <span class="hljs-number" style="color: teal;">0.0</span>   <span class="hljs-number" style="color: teal;">0.0</span>  <span class="hljs-number" style="color: teal;">6.593</span>
<span class="hljs-number" style="color: teal;">502</span>   <span class="hljs-number" style="color: teal;">0.0</span>   <span class="hljs-number" style="color: teal;">0.0</span>  <span class="hljs-number" style="color: teal;">6.120</span>
<span class="hljs-number" style="color: teal;">503</span>   <span class="hljs-number" style="color: teal;">0.0</span>   <span class="hljs-number" style="color: teal;">0.0</span>  <span class="hljs-number" style="color: teal;">6.976</span>
<span class="hljs-number" style="color: teal;">504</span>   <span class="hljs-number" style="color: teal;">0.0</span>   <span class="hljs-number" style="color: teal;">0.0</span>  <span class="hljs-number" style="color: teal;">6.794</span>
<span class="hljs-number" style="color: teal;">505</span>   <span class="hljs-number" style="color: teal;">0.0</span>   <span class="hljs-number" style="color: teal;">0.0</span>  <span class="hljs-number" style="color: teal;">6.030</span>
[<span class="hljs-number" style="color: teal;">506</span> rows x <span class="hljs-number" style="color: teal;">3</span> columns]
</pre>



<p>We can also glimpse at how each of our methods has voted by printing <em>vs.votes.</em></p>



<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);">        CRIM  ZN  INDUS  CHAS  NOX  RM  AGE  DIS  RAD  TAX  PTRATIO  B  LSTAT
pearson     <span class="hljs-number" style="color: teal;">0</span>   <span class="hljs-number" style="color: teal;">1</span>      <span class="hljs-number" style="color: teal;">0</span>     <span class="hljs-number" style="color: teal;">1</span>    <span class="hljs-number" style="color: teal;">0</span>   <span class="hljs-number" style="color: teal;">1</span>    <span class="hljs-number" style="color: teal;">0</span>    <span class="hljs-number" style="color: teal;">1</span>    <span class="hljs-number" style="color: teal;">0</span>    <span class="hljs-number" style="color: teal;">0</span>        <span class="hljs-number" style="color: teal;">0</span>  <span class="hljs-number" style="color: teal;">1</span>      <span class="hljs-number" style="color: teal;">0</span>
vif         <span class="hljs-number" style="color: teal;">1</span>   <span class="hljs-number" style="color: teal;">1</span>      <span class="hljs-number" style="color: teal;">0</span>     <span class="hljs-number" style="color: teal;">1</span>    <span class="hljs-number" style="color: teal;">0</span>   <span class="hljs-number" style="color: teal;">0</span>    <span class="hljs-number" style="color: teal;">0</span>    <span class="hljs-number" style="color: teal;">0</span>    <span class="hljs-number" style="color: teal;">0</span>    <span class="hljs-number" style="color: teal;">0</span>        <span class="hljs-number" style="color: teal;">0</span>  <span class="hljs-number" style="color: teal;">0</span>      <span class="hljs-number" style="color: teal;">0</span>
rfe         <span class="hljs-number" style="color: teal;">0</span>   <span class="hljs-number" style="color: teal;">0</span>      <span class="hljs-number" style="color: teal;">0</span>     <span class="hljs-number" style="color: teal;">1</span>    <span class="hljs-number" style="color: teal;">1</span>   <span class="hljs-number" style="color: teal;">1</span>    <span class="hljs-number" style="color: teal;">0</span>    <span class="hljs-number" style="color: teal;">0</span>    <span class="hljs-number" style="color: teal;">0</span>    <span class="hljs-number" style="color: teal;">0</span>        <span class="hljs-number" style="color: teal;">1</span>  <span class="hljs-number" style="color: teal;">0</span>      <span class="hljs-number" style="color: teal;">1</span></pre>



<p>We might not be happy with only 3 out of the initial 13 columns left. Luckily, we can easily make the selection less restrictive by modifying the parameters of the particular methods. This can be done by simply adding appropriate arguments to the call to select, thanks to how we pass kwargs around.</p>



<p>Pearson and RFE methods need a pre-defined number of features to keep. The default has been 5, but we might want to increase it to 8. We can also modify the VIF threshold, that is the value of the Variance Inflation Factor above which we discard a feature due to multicollinearity. By convention, this threshold is set at 10, but increasing it to, say, 15 will result in more features being kept.</p>



<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);">vs = VotingSelector()
X_selection = vs.select(X, y, n_features_to_select=<span class="hljs-number" style="color: teal;">8</span>, vif_threshold=<span class="hljs-number" style="color: teal;">15</span>)</pre>



<p>This way, we have seven features left.</p>



<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);">        CRIM  ZN  INDUS  CHAS  NOX  RM  AGE  DIS  RAD  TAX  PTRATIO  B  LSTAT
pearson     <span class="hljs-number" style="color: teal;">1</span>   <span class="hljs-number" style="color: teal;">1</span>      <span class="hljs-number" style="color: teal;">0</span>     <span class="hljs-number" style="color: teal;">1</span>    <span class="hljs-number" style="color: teal;">0</span>   <span class="hljs-number" style="color: teal;">1</span>    <span class="hljs-number" style="color: teal;">1</span>    <span class="hljs-number" style="color: teal;">1</span>    <span class="hljs-number" style="color: teal;">1</span>    <span class="hljs-number" style="color: teal;">0</span>        <span class="hljs-number" style="color: teal;">0</span>  <span class="hljs-number" style="color: teal;">1</span>      <span class="hljs-number" style="color: teal;">0</span>
vif         <span class="hljs-number" style="color: teal;">1</span>   <span class="hljs-number" style="color: teal;">1</span>      <span class="hljs-number" style="color: teal;">1</span>     <span class="hljs-number" style="color: teal;">1</span>    <span class="hljs-number" style="color: teal;">0</span>   <span class="hljs-number" style="color: teal;">0</span>    <span class="hljs-number" style="color: teal;">0</span>    <span class="hljs-number" style="color: teal;">1</span>    <span class="hljs-number" style="color: teal;">0</span>    <span class="hljs-number" style="color: teal;">0</span>        <span class="hljs-number" style="color: teal;">0</span>  <span class="hljs-number" style="color: teal;">0</span>      <span class="hljs-number" style="color: teal;">1</span>
rfe         <span class="hljs-number" style="color: teal;">1</span>   <span class="hljs-number" style="color: teal;">0</span>      <span class="hljs-number" style="color: teal;">1</span>     <span class="hljs-number" style="color: teal;">1</span>    <span class="hljs-number" style="color: teal;">1</span>   <span class="hljs-number" style="color: teal;">1</span>    <span class="hljs-number" style="color: teal;">0</span>    <span class="hljs-number" style="color: teal;">1</span>    <span class="hljs-number" style="color: teal;">0</span>    <span class="hljs-number" style="color: teal;">0</span>        <span class="hljs-number" style="color: teal;">1</span>  <span class="hljs-number" style="color: teal;">0</span>      <span class="hljs-number" style="color: teal;">1</span></pre>



<p>Our VotingSelector class is a simple but generic template which you can extend to an arbitrary number of feature selection methods. As a possible extension, you could also treat all the arguments passed to select() as hyperparameters of your modeling pipeline and optimize them so as to maximize the performance of the downstream model.</p>



<h2>Feature selection at Big Tech</h2>



<p>Large technology companies such as GAFAM and the likes of it, with their thousands of machine learning models in production, are prime examples of how feature selection is operated in the wild. Let’s see what these tech giants have to say about it!</p>



<h3>Google</h3>



<p><a href="https://martin.zinkevich.org/rules_of_ml/rules_of_ml.pdf" target="_blank" rel="noreferrer noopener nofollow">Rules of ML</a> is a handy compilation of best practices in machine learning from around Google. In it, Google’s engineers point out that the number of parameters the model can learn is roughly</p>



<p>proportional to the amount of data it has access to. Hence, the less data we have, the more features we need to discard. Their rough guidelines (derived from text-based models) are to use a dozen features with 1000 training examples or 100,000 features with 10 million training examples.&nbsp;</p>



<p>Another crucial point in the document concerns model deployment issues, which can also affect feature selection.&nbsp;</p>


<div class="custom-point-list">
<ul><li>First, your set of features to select from might be constrained by what will be available in production at inference time. You may be forced to drop a great feature from training if it isn’t there for the model when it goes live.&nbsp;</li></ul>
</div>

<div class="custom-point-list">
<ul><li>Second, some features might be prone to <a href="https://towardsdatascience.com/dont-let-your-model-s-quality-drift-away-53d2f7899c09" target="_blank" rel="noreferrer noopener nofollow">data drift</a>. While the topic of tackling drift is a complex one, sometimes the best solution might be to remove the problematic feature from the model altogether.</li></ul>
</div>


<h3>Facebook</h3>



<p>A couple of years ago, in 2019, Facebook came up with its own Neural Network suitable Feature Selection algorithm in order to save computational resources while training large-scale models. They further tested this algorithm on their own Facebook News Feed dataset so as to rank relevant items as efficiently as possible while working with a fewer-dimensional input. You can read all about it <a href="https://research.facebook.com/publications/feature-selection-for-facebook-feed-ranking-system-via-a-group-sparsity-regularized-training-algorithm/" target="_blank" rel="noreferrer noopener nofollow">here</a>.</p>



<h2>Parting words</h2>



<p>Thanks for reading till the end! I hope this article convinced you that feature selection is a crucial step in the data preparation pipeline and gave you some guidance as to how to approach it.&nbsp;</p>



<p>Don’t hesitate to hit me up on social media to discuss the topics covered here or any other machine learning topics, for that matter. Happy feature selection!</p>



<h3>References</h3>


<div class="custom-point-list">
<ol><li><a href="https://scikit-learn.org/stable/modules/feature_selection.html" target="_blank" rel="noreferrer noopener nofollow">Scikit-learn documentation on feature selection</a></li><li><a href="https://martin.zinkevich.org/rules_of_ml/rules_of_ml.pdf">B</a><a href="https://github.com/scikit-learn-contrib/boruta_py/blob/master/README.md" target="_blank" rel="noreferrer noopener nofollow">oruta_py’s GitHub README</a></li><li><a href="https://martin.zinkevich.org/rules_of_ml/rules_of_ml.pdf" target="_blank" rel="noreferrer noopener nofollow">Rules of Machine Learning: Best Practices for ML Engineering</a></li></ol>
</div>



<div id="author-box-new-format-block_625956d8f9d5e" class="article__footer article__author">
  <div class="article__authorImage">
          <img width="230" height="202" src="https://i0.wp.com/neptune.ai/wp-content/uploads/Michal_Oleszak.jpeg?fit=230%2C202&amp;ssl=1" class="article__authorImage-img" alt="Michal_Oleszak" decoding="async" data-attachment-id="68367" data-permalink="https://neptune.ai/blog-author-michal-oleszak/attachment/michal_oleszak" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Michal_Oleszak.jpeg?fit=1599%2C1406&amp;ssl=1" data-orig-size="1599,1406" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Michal_Oleszak" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Michal_Oleszak.jpeg?fit=300%2C264&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Michal_Oleszak.jpeg?fit=1024%2C900&amp;ssl=1" />      </div>

  <div class="article__authorContent">
          <h3 class="article__authorContent-name">Michał Oleszak</h3>
    
          <p class="article__authorContent-text">Machine Learning Engineer with a statistics background. Has worn all the hats, having worked for a consultancy, an AI startup, and a software house. A traveler, polyglot, data science blogger and instructor, and lifelong learner. Check out his website to find out more.
</p>
    
          <ul class="article__authorSocial">
        <li class="article__authorSocial-single article__authorSocial-name">Follow me on</li>
                  <li class="article__authorSocial-single"><a href="https://twitter.com/MichalOleszak" class="article__authorSocial-tw" target="_blank"></a></li>
        
                  <li class="article__authorSocial-single"><a href="https://www.linkedin.com/in/michal-oleszak/" class="article__authorSocial-lk" target="_blank"></a></li>
        
                  <li class="article__authorSocial-single"><a href="https://michaloleszak.com/" class="article__authorSocial-www" target="_blank"></a></li>
              </ul>
    
  </div>
</div>


<div class="is-layout-flow wp-block-group"><div class="wp-block-group__inner-container">
<hr class="wp-block-separator has-css-opacity"/>



<p class="has-text-color" style="color:#4455a6"><strong>READ NEXT</strong></p>



<h2>Real-World MLOps Examples: Model Development in Hypefactors</h2>



<p class="has-small-font-size">6 mins read | Author&nbsp;Stephen Oladele | Updated June 28th, 2022</p>


<div id="block_5ffc75def9f8e" class="separator separator-10"></div>



<p>In this first installment of the series “Real-world MLOps Examples,”&nbsp;<a href="https://www.linkedin.com/in/jules-belveze" target="_blank" rel="noreferrer noopener">Jules Belveze</a>, an MLOps Engineer, will walk you through the model development process at&nbsp;<a href="https://hypefactors.com/" target="_blank" rel="noreferrer noopener">Hypefactors</a>, including the types of models they build, how they design their training pipeline, and other details you may find valuable. Enjoy the chat!</p>



<h3 id="company-profile">Company profile</h3>



<p><a href="https://hypefactors.com/" target="_blank" rel="noreferrer noopener">Hypefactors</a>&nbsp;provides an all-in-one media intelligence solution for managing PR and communications, tracking trust, product launches, and market and financial intelligence. They operate large data pipelines that stream in the world’s media data ongoingly in real-time. AI is used for many automations that were previously performed manually.</p>



<h3 id="guest-introduction">Guest introduction</h3>



<h4>Could you introduce yourself to our readers?</h4>



<p>Hey Stephen, thanks for having me! My name is Jules. I am 26. I was born and raised in Paris, I am currently living in Copenhagen.</p>



<h4>Hey Jules! Thanks for the intro. Walk me through your background and how you got to Hypefactors.</h4>



<p>I hold a Bachelor’s in statistics and probabilities and a Master’s in general engineering from universities in France. On top of that, I also graduated in Data Science with a focus on deep learning from Danish Technical University, Denmark. I’m fascinated by multilingual natural language processing (and therefore specialized in it). I also researched anomaly detection on high-dimensional time series during my graduate studies with Microsoft.&nbsp;</p>



<p>Today, I work for a media intelligence tech company called Hypefactors, where I develop NLP models to help our users gain insights from the media landscape. What currently works for me is having the opportunity to carry out models from prototyping all the way to production. I guess you could call me a nerd, at least that’s how my friend describes me, as I spent most of my free time either coding or listening to disco vinyl.</p>



<h3 id="model-development-at-hypefactors">Model development at Hypefactors</h3>



<h4>Could you elaborate on the types of models you build at Hypefactors?</h4>



<p>Even though we also have computer vision models running in production, we mainly build&nbsp;<a href="https://neptune.ai/blog/category/natural-language-processing" target="_blank" rel="noreferrer noopener">NLP (Natural Language Processing)</a>&nbsp;models for various use cases. We need to cover multiple countries and handle many languages. The multilingual aspect makes developing with “classical machine learning” approaches hard. We craft deep learning models on top of the&nbsp;<a href="https://github.com/huggingface/transformers" target="_blank" rel="noreferrer noopener">transformer library</a>.&nbsp;</p>



<p>We run all sorts of models in production, varying from span extraction or sequence classification to text generation. Those models are designed to serve different use cases, like topic classification, sentiment analysis, or summarisation.</p>


<a class="button continous-post blue-filled" href="/blog/mlops" target="_blank">
    Continue reading -&gt;</a>



<hr class="wp-block-separator has-css-opacity"/>
</div></div>
<p>The post <a rel="nofollow" href="https://neptune.ai/blog/feature-selection-methods">Feature Selection Methods and How to Choose Them</a> appeared first on <a rel="nofollow" href="https://neptune.ai">neptune.ai</a>.</p>
]]></content:encoded>
					
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">71265</post-id>	</item>
		<item>
		<title>Exploratory Data Analysis for Tabular Data</title>
		<link>https://neptune.ai/blog/exploratory-data-analysis-for-tabular-data</link>
		
		<dc:creator><![CDATA[Mirza Mujtaba]]></dc:creator>
		<pubDate>Fri, 09 Sep 2022 08:46:01 +0000</pubDate>
				<category><![CDATA[ML Model Development]]></category>
		<category><![CDATA[Tabular Data]]></category>
		<category><![CDATA[tabular data]]></category>
		<guid isPermaLink="false">https://neptune.ai/?p=71225</guid>

					<description><![CDATA[<p>Often on having a look at any dataset, we see a bunch of rows and columns filled with numbers or even with some alphabets, words, or abbreviations. Understanding this data and attempting to gain as many insights as possible is a smart strategy to begin the process of model development. In this article, we will [&#8230;]</p>
<p>The post <a rel="nofollow" href="https://neptune.ai/blog/exploratory-data-analysis-for-tabular-data">Exploratory Data Analysis for Tabular Data</a> appeared first on <a rel="nofollow" href="https://neptune.ai">neptune.ai</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<p>Often on having a look at any dataset, we see a bunch of rows and columns filled with numbers or even with some alphabets, words, or abbreviations. Understanding this data and attempting to gain as many insights as possible is a smart strategy to begin the process of model development. In this article, we will learn about EDA, its types, techniques, underlying assumptions, tools and also, we will do Exploratory Data Analysis on a sample dataset to understand why it’s so important and helpful.</p>



<p>So let’s begin with a brief intro.</p>



<h2>What is Exploratory Data Analysis?</h2>



<p>According to <a href="https://www.itl.nist.gov/div898/handbook/eda/section1/eda11.htm" target="_blank" rel="noreferrer noopener nofollow">NIST</a> (National Institute of Standards and Technology, USA ), EDA is a non-formal process with no definitive rules and techniques; rather, rather it is more of a philosophy or attitude about how data analysis should be conducted. Furthermore, a famous mathematician and statistician, John W. Tukey, in his book “<strong><a href="http://www.ru.ac.bd/wp-content/uploads/sites/25/2019/03/102_05_01_Tukey-Exploratory-Data-Analysis-1977.pdf" target="_blank" rel="noreferrer noopener nofollow">Exploratory Data Analysis</a>”</strong>, describes EDA as a detective’s work. An analyst or a data scientist uses it to establish the assumptions needed for model fitting and hypothesis testing, as well as for handling missing values and transforming variables as necessary.</p>



<p>To simplify further, we can describe EDA as an iterative cycle where you:</p>


<div class="case-study-numbered-list">
    <h2></h2>
    <ul>
                    <li><span>1</span>generate questions about your data.<br />
</li>
                    <li><span>2</span>search for answers by visualizing, transforming, and modeling your data.<br />
</li>
                    <li><span>3</span>use what you learn to refine your questions and/or generate new questions.</li>
            </ul>
</div>



<p>These questions can be:</p>


<div class="custom-point-list">
<ul><li>What is the typical value or central value that best describes the data?</li><li>How spread out is the data from the typical value?</li><li>What is a good distributional fit for the data? </li><li>Does a certain feature affect the target variable?</li><li>What are the statistically most important features/variables?</li><li>What is the best function for relating a target variable to a set of other variables/ features?</li><li>Does the data have any outliers?</li></ul>
</div>


<div id="blog-cta-intext-block_631afd5477be5" class="blog-cta-intext">
  <h3 class="blog-cta-intext__title">May interest you</h3>
  <div class="blog-cta-intext__content"><p><a href="/blog/exploratory-data-analysis-natural-language-processing-tools" target="_blank" rel="noopener">Exploratory Data Analysis for Natural Language Processing: A Complete Guide to Python Tools</a></p>
</div>
  </div>


<h3>Exploratory Data Analysis vs. Classical Data Analysis</h3>



<p>Apart from EDA, there are also other data analysis approaches, Classical Data Analysis being one of the most popular ones. Both Exploratory Data Analysis and Classical Data Analysis start with a problem, followed by collecting the related data that can be used to understand the problem. Both of them end with yielding some inferences about the data. This is where their similarities end, let us see the differences now:</p>


<div class="medium-table">
        <div class="mt-row heading">
            <div class="mt-col" style="width: 20%">
            Parameters        </div>
            <div class="mt-col" style="width: 40%">
            Exploratory Data Analysis        </div>
            <div class="mt-col" style="width: 40%">
            Classical Data Analysis        </div>
        </div>
    
            <div class="mt-row">
                            <div class="mt-col" style="width: 20%">
                                                                <p>Model</p>
                                    </div>
                            <div class="mt-col" style="width: 40%">
                                        <span class="column-name">
                        Exploratory Data Analysis:
                    </span>
                                                                <p>does not impose deterministic or probabilistic models on the data. Instead, it allows the data to suggest admissible models that best suit the data.</p>
                                    </div>
                            <div class="mt-col" style="width: 40%">
                                        <span class="column-name">
                        Classical Data Analysis:
                    </span>
                                                                <p>imposes deterministic and probabilistic models on the data.</p>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 20%">
                                                                <p>Focus</p>
                                    </div>
                            <div class="mt-col" style="width: 40%">
                                        <span class="column-name">
                        Exploratory Data Analysis:
                    </span>
                                                                <p>the structure of the data, outliers, and models suggested by the data.</p>
                                    </div>
                            <div class="mt-col" style="width: 40%">
                                        <span class="column-name">
                        Classical Data Analysis:
                    </span>
                                                                <p>parameters of the model, and generates predicted values from the model.</p>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 20%">
                                                                <p>Techniques</p>
                                    </div>
                            <div class="mt-col" style="width: 40%">
                                        <span class="column-name">
                        Exploratory Data Analysis:
                    </span>
                                                                <p>generally graphical, for example, scatter plots, character plots, box plots, histograms, bi-histograms, probability plots, residual plots, and mean plots.</p>
                                    </div>
                            <div class="mt-col" style="width: 40%">
                                        <span class="column-name">
                        Classical Data Analysis:
                    </span>
                                                                <p>generally quantitative, for example, ANOVA, t-tests, chi-squared tests, and F-tests.</p>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 20%">
                                                                <p>Rigor</p>
                                    </div>
                            <div class="mt-col" style="width: 40%">
                                        <span class="column-name">
                        Exploratory Data Analysis:
                    </span>
                                                                <p>suggestive, insightful and subjective in nature.</p>
                                    </div>
                            <div class="mt-col" style="width: 40%">
                                        <span class="column-name">
                        Classical Data Analysis:
                    </span>
                                                                <p>rigorous, formal, and objective in nature.</p>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 20%">
                                                                <p>Data Treatment</p>
                                    </div>
                            <div class="mt-col" style="width: 40%">
                                        <span class="column-name">
                        Exploratory Data Analysis:
                    </span>
                                                                <p>uses all of the available data, in this sense, there is no corresponding loss of information.</p>
                                    </div>
                            <div class="mt-col" style="width: 40%">
                                        <span class="column-name">
                        Classical Data Analysis:
                    </span>
                                                                <p>condenses data into important characteristics such as location, variation, etc. while filtering some other important factors such as skewness, tail length, autocorrelation, etc., resulting in loss of information.</p>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 20%">
                                                                <p>Assumptions</p>
                                    </div>
                            <div class="mt-col" style="width: 40%">
                                        <span class="column-name">
                        Exploratory Data Analysis:
                    </span>
                                                                <p>makes little or no assumptions as these techniques use all of the data.</p>
                                    </div>
                            <div class="mt-col" style="width: 40%">
                                        <span class="column-name">
                        Classical Data Analysis:
                    </span>
                                                                <p>dependent on underlying assumptions such as normality.</p>
                                    </div>
                    </div>
    </div>


<div id="block_63173e71810c4" class="separator separator-15"></div>



<p class="has-text-align-center"><em>Differences between parameters for Exploratory Data Analysis and Classical Data Analysis</em></p>


<div id="block_631748b3810d2" class="separator separator-10"></div>



<p>It should be noted that in the real world, we might use elements from both of these approaches along with other ones during data analysis. For example, it is really common to use ANOVA and chi-squared tests to understand the relations between the different features of a dataset while doing EDA.</p>



<h3>Univariate analysis vs. multivariate analysis</h3>



<p>Often our dataset contains more than one variable, and in such cases, we can do univariate and multivariate analyses to understand our data better.</p>



<p>The term univariate analysis refers to the analysis of one variable and is basically the simplest form to analyze the data. The purpose of the univariate analysis is to understand the distribution of values for a single variable and not to deal with the relationship among the variables in the entire dataset. Summary statistics and frequency distribution plots such as histograms, bar plots, and kernel density plots are some of the common methods to do univariate analysis.</p>



<p>On the other hand, multivariate analysis can take all the variables in the dataset into consideration which makes it complicated as compared to univariate analysis. The main purpose of such analysis is to find the relationship among the variables to get a better understanding of the overall data. Usually, any phenomenon in the real world is influenced by multiple factors, which makes multivariate analysis much more realistic. Some of the common methods used in multivariate analysis are regression analysis, principal component analysis, clustering, correlation, and graphical plots such as scatter plots.</p>



<h3>Exploratory Data Analysis (EDA) tools</h3>



<p>Some of the most common tools used for Exploratory Data Analysis are:</p>


<div class="custom-point-list">
<ul><li>Excel</li><li>R </li><li>Python</li></ul>
</div>


<h3>Exploratory Data Analysis (EDA) assumptions</h3>



<p>Every measuring procedure includes some underlying assumptions that are presumed to be statistically true. In particular, there are four assumptions that commonly form the basis of all measurement procedures.&nbsp;</p>


<div class="case-study-numbered-list">
    <h2></h2>
    <ul>
                    <li><span>1</span> Data is randomly drawn.<br />
</li>
                    <li><span>2</span> The data belongs to a fixed distribution.<br />
</li>
                    <li><span>3</span> The distribution has a fixed location.<br />
</li>
                    <li><span>4</span> The distribution has a fixed variation.</li>
            </ul>
</div>



<p>In simpler words, we want the data to have some underlying structure that we can discover. Otherwise, it will be a complete waste of time trying to make any sense out of the data, which comes across as random noise.</p>



<p>If these four underlying assumptions are true, we will attain probabilistic predictability, which allows us to make probability claims about both the process&#8217;s past and future. They are referred to as &#8220;statistically in control&#8221; processes. Additionally, if the four assumptions are true, the approach can yield reliable conclusions that are reproducible.</p>



<p>But the interpretation of these assumptions might differ across different problem types. So, here we will describe these assumptions for the simplest problem type, i.e., univariate problems. In the univariate system, the response comprises a deterministic(constant) and a random(error) part, so we can rewrite the above assumptions as:</p>


<div class="case-study-numbered-list">
    <h2></h2>
    <ul>
                    <li><span>1</span>The data points are uncorrelated with one another.<br />
</li>
                    <li><span>2</span>The random component has a fixed distribution.<br />
</li>
                    <li><span>3</span>The deterministic component consists only of a constant.<br />
</li>
                    <li><span>4</span>The random component has a fixed variation.</li>
            </ul>
</div>



<p>The univariate model&#8217;s universality and significance lie in its ability to extrapolate with ease to more general problems when the deterministic component is not only a constant but rather a function of several variables.&nbsp;</p>



<p>In this article, we will also see how to test these assumptions using some simple EDA techniques, viz histogram, lag plot, probability plot, and run sequence plot.</p>



<h2>Exploratory Data Analysis with a sample tabular dataset</h2>



<p>Now before going through the rest of the article, I&#8217;ll take an example of a dataset – “120 years of Olympic history: athletes and results”, which is a dataset containing basic data of Olympic athletes and medal results from Athens 1896 to Rio 2016.</p>



<p>The main variables or attributes in this dataset are:</p>


<div class="custom-point-list">
<ul><li>ID &#8211; Unique number for each athlete;</li><li>Name &#8211; Athlete&#8217;s name;</li><li>Sex &#8211; M or F;</li><li>Age &#8211; Integer;</li><li>Height &#8211; In centimeters;</li><li>Weight &#8211; In kilograms;</li><li>Team &#8211; Team name;</li><li>NOC &#8211; National Olympic Committee 3-letter code;</li><li>Games &#8211; Year and season;</li><li>Year &#8211; Integer;</li><li>Season &#8211; Summer or Winter;</li><li>City &#8211; Host city;</li><li>Sport &#8211; Sport;</li><li>Event &#8211; Event;</li><li>Medal &#8211; Gold, Silver, Bronze, or NA.</li></ul>
</div>


<p>After storing this data in a pandas dataframe, we can see the top 5 rows as follows:</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img data-attachment-id="71227" data-permalink="https://neptune.ai/exploratory-data-analysis-for-tabular-data-1a" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-1a.png?fit=1999%2C656&amp;ssl=1" data-orig-size="1999,656" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="exploratory-data-analysis-for-tabular-data-1a" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-1a.png?fit=300%2C98&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-1a.png?fit=1024%2C336&amp;ssl=1" decoding="async" width="1024" height="336" src="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-1a.png?resize=1024%2C336&#038;ssl=1" alt="Data in pandas dataframe" class="wp-image-71227" data-recalc-dims="1"/><figcaption><em>Sorted data in pandas dataframe</em></figcaption></figure></div>


<p>As mentioned earlier, it is a good practice in EDA to generate questions about the dataset to understand the data. For instance, with regard to this data, I would like to find out answers to the following questions:</p>


<div class="custom-point-list">
<ul><li>Which countries produce more gold-winning athletes?</li><li>Does any of the physical features of an athlete, such as height, give an athlete an edge over others?</li><li>Are there any features that are highly correlated and thus can be dropped?</li><li>Is there any kind of bias in the data?</li></ul>
</div>


<p>Of course, you can have a completely different set of questions about this data, which might be more relevant to your use case for this dataset. In the upcoming sections, along with going over the concepts, we will try to get answers to the aforementioned questions.</p>



<h3>Descriptive statistics</h3>



<p>Descriptive statistics summarizes the data to make it simpler to comprehend and analyze. Remember that one of the purposes of EDA is to understand variable properties like central value, variance, skewness and suggest possible modeling strategies. Descriptive Statistics are divided into two broad categories:</p>



<h4>The measure of central tendency</h4>



<p>They are computed to give a “centre” around which the measurements in the data are distributed. We can use mean, median, or mode to find the central value of the data.</p>



<h5>Mean</h5>



<p>The mean is the most widely used approach for determining the central value. It is calculated by adding all of the data values together and dividing the total by the number of data points.&nbsp;</p>



<h5>Median</h5>



<p>The value at the exact middle of the dataset is defined as the median. Locate the number in the middle of the data after organizing the values in ascending order. In case there are two numbers in the middle, the median is calculated as the mean of them.</p>



<h5>Mode</h5>



<p>The mode is perhaps the most simple way to calculate the central value in a dataset. It is equal to The most frequent number, i.e., the number that occurs the highest number of times in the data.&nbsp;</p>



<p>It is to be noted that the mean is best for symmetric distributions without outliers, while the median is useful for skewed distributions or data with outliers. The mode is the least used of the measures of central tendency and is only used when dealing with nominal data.&nbsp;</p>



<h4>Measure of dispersion</h4>



<p>The measure of dispersion describes “data spread”, or how far away the measurements are from the centre. Some of the common measures are:</p>



<h5>Range</h5>



<p>The range of a particular data set is the difference between its greatest and lowest values. The higher the value of the range, the higher the spread in data.</p>



<h5>Percentiles or Quartiles</h5>



<p>The numbers that split your data into quarters are called quartiles. Typically, they split the data into four sections based on the positions of the numbers on the number line. A data collection is divided into four quartiles:</p>


<div class="custom-point-list">
<ul><li>First quartile: The lowest 25% of numbers.</li><li>Second quartile: The next lowest 25% of numbers (up to the median).</li><li>Third quartile: The second highest 25% of numbers (above the median).</li><li>Fourth quartile: The highest 25% of numbers.</li></ul>
</div>


<p>Based on the above quartiles, we can also define some additional terms here such as:</p>


<div class="custom-point-list">
<ul><li>The 25th Percentile is the value which is the end of the first quartile.</li><li>The 50th Percentile is the value which is the end of the second quartile (or the median)&nbsp;</li><li>The 75th Percentile is the value which is the end of the third quartile.&nbsp;</li><li>IQR, also known as the interquartile range, is a measure of how the data is spread out around the mean.</li></ul>
</div>


<p>We can plot percentiles using a box plot, as we will see later in the article</p>



<h5>Variance</h5>



<p>The variance measures the average degree to which each point differs from the mean. It can be calculated using the following formula:</p>


<div class="wp-block-image">
<figure class="aligncenter size-full"><img data-attachment-id="71228" data-permalink="https://neptune.ai/exploratory-data-analysis-for-tabular-data-1b" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-1b.png?fit=550%2C140&amp;ssl=1" data-orig-size="550,140" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="exploratory-data-analysis-for-tabular-data-1b" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-1b.png?fit=300%2C76&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-1b.png?fit=550%2C140&amp;ssl=1" decoding="async" width="550" height="140" src="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-1b.png?resize=550%2C140&#038;ssl=1" alt="Formula for the varaince " class="wp-image-71228" data-recalc-dims="1"/><figcaption><em>Formula for calculating the variance</em></figcaption></figure></div>


<p>Where x<sub>i </sub>is a data point, and μ is the mean calculated for all data points.</p>



<p>In the example mentioned earlier, the variance for the following data points:&nbsp; 6,8,7,10,8,4,9 is 3.95</p>



<h5>Standard Deviation</h5>



<p>The standard deviation value tells us how much all data points deviate from the mean value, but it is affected by the outliers as it uses the mean for its calculation. It is equal to the square root of the variance.</p>



<h5>Skewness</h5>



<p>A deviation from the symmetrical bell curve, or normal distribution, in a collection of data is referred to as skewness. A skewness value greater than 1 or less than -1 indicates a highly skewed distribution. A value between 0.5 and 1 or -0.5 and -1 is moderately skewed. A value between -0.5 and 0.5 indicates that the distribution is fairly symmetrical. We can use pandas functions skew to find skewness of all numerical variables:</p>


<div class="wp-block-image">
<figure class="aligncenter size-full"><img data-attachment-id="71229" data-permalink="https://neptune.ai/exploratory-data-analysis-for-tabular-data-2" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-2.png?fit=382%2C344&amp;ssl=1" data-orig-size="382,344" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="exploratory-data-analysis-for-tabular-data-2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-2.png?fit=300%2C270&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-2.png?fit=382%2C344&amp;ssl=1" decoding="async" width="382" height="344" src="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-2.png?resize=382%2C344&#038;ssl=1" alt="Pandas functions skew" class="wp-image-71229" data-recalc-dims="1"/><figcaption><em>Finding skewness using the pandas skew function</em></figcaption></figure></div>


<p>We can use a simple pandas method to find most of these statistics such as min, max, mean, percentile values, and standard deviation for all numerical variables in the data:</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img data-attachment-id="71230" data-permalink="https://neptune.ai/exploratory-data-analysis-for-tabular-data-3" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-3.png?fit=1382%2C712&amp;ssl=1" data-orig-size="1382,712" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="exploratory-data-analysis-for-tabular-data-3" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-3.png?fit=300%2C155&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-3.png?fit=1024%2C528&amp;ssl=1" decoding="async" width="1024" height="528" src="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-3.png?resize=1024%2C528&#038;ssl=1" alt="Using a simple pandas method " class="wp-image-71230" data-recalc-dims="1"/><figcaption><em>Using a simple pandas method to find statistics </em></figcaption></figure></div>


<p>Moving onto the techniques used in Exploratory Data Analysis, they can be broadly classified into graphical and non-graphical techniques, with most of them being graphical. Although non-graphical methods are quantitative and objective, they do not provide a complete picture of the data. Therefore, graphical methods, which are more qualitative and involve some subjective analysis, are also necessary.</p>



<h3>Graphical techniques</h3>



<h4>Histogram</h4>



<p>A histogram is a graph that illustrates the distribution of the values of a numeric variable (univariate) having continuous values as a series of bars. Each bar normally spans a range of numeric values known as a bin or class, where the height of the bar shows the frequency of data points within the values present in the respective bin.</p>



<p>Using histograms, we can get an idea about the centre of the data, the spread of the data, the skewness of the data, and the presence of outliers.</p>



<p>For example, we can plot the histogram for the numerical variable such as height in the dataset.</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img data-attachment-id="71231" data-permalink="https://neptune.ai/exploratory-data-analysis-for-tabular-data-4" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-4.png?fit=1358%2C1036&amp;ssl=1" data-orig-size="1358,1036" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="exploratory-data-analysis-for-tabular-data-4" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-4.png?fit=300%2C229&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-4.png?fit=1024%2C781&amp;ssl=1" decoding="async" width="1024" height="781" src="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-4.png?resize=1024%2C781&#038;ssl=1" alt="Example of histogram for the numerical variable" class="wp-image-71231" data-recalc-dims="1"/><figcaption><em>Histogram for the numerical variable</em> &#8211; height</figcaption></figure></div>


<p>From this histogram, we can confirm that the median height of athletes lies around 175 cm, which is also evident from the output of “<em>data.describe</em>” in the last section.</p>



<h4>Normal Probability Plot</h4>



<p>In general, a probability plot is a visual tool for determining if a variable in a dataset has an approximately similar theoretical distribution, such as normal or gamma. This plot generates a probability plot of sample data against the quantiles of a specified theoretical distribution, in this case, a normal distribution.</p>



<p>For example, we can plot the Normal Probability Plot for the numerical variable height in the dataset.</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img data-attachment-id="71232" data-permalink="https://neptune.ai/exploratory-data-analysis-for-tabular-data-5" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-5.png?fit=1700%2C1140&amp;ssl=1" data-orig-size="1700,1140" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="exploratory-data-analysis-for-tabular-data-5" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-5.png?fit=300%2C201&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-5.png?fit=1024%2C687&amp;ssl=1" decoding="async" width="1024" height="687" src="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-5.png?resize=1024%2C687&#038;ssl=1" alt="Example of  Normal Probability Plot" class="wp-image-71232" data-recalc-dims="1"/><figcaption><em> Normal Probability Plot for the numerical variable</em> &#8211; height</figcaption></figure></div>


<p>As we can see, the histogram is a bit skewed, thus there is a slight curve in the normal probability plot. We can perform techniques such as power transform, which will make the probability distribution of this variable more Gaussian or Normal.</p>



<p>Using the Histogram and Probability Plot, we can test for one of the EDA assumptions i.e., fixed distribution of data. For example, If the normal probability plot is linear, the underlying distribution is fixed and normal. Also, as histograms are used to represent the distribution of data, a bell-shaped histogram implies that the underlying distribution is symmetric and perhaps normal.</p>



<h4>Kernel Distribution Estimation or KDE plot</h4>



<p>The<a href="https://jakevdp.github.io/PythonDataScienceHandbook/05.13-kernel-density-estimation.html"> </a><a href="https://seaborn.pydata.org/tutorial/distributions.html#tutorial-kde" target="_blank" rel="noreferrer noopener nofollow">Kernel Distribution Estimation</a> plot depicts the probability density function of the continuous numeric variables and can be considered analogous to a histogram. We can use this plot for univariate as well as multivariate data.&nbsp;</p>



<p>For example, we can plot the KDE Plot for a numerical variable such as height in this dataset. So here we plot KDE for gold medal-winning athletes in basketball and swimming sports.</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img data-attachment-id="71233" data-permalink="https://neptune.ai/exploratory-data-analysis-for-tabular-data-6" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-6.png?fit=1426%2C1046&amp;ssl=1" data-orig-size="1426,1046" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="exploratory-data-analysis-for-tabular-data-6" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-6.png?fit=300%2C220&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-6.png?fit=1024%2C751&amp;ssl=1" decoding="async" width="1024" height="751" src="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-6.png?resize=1024%2C751&#038;ssl=1" alt="Example of KDE Plot" class="wp-image-71233" data-recalc-dims="1"/><figcaption><em>KDE Plot for a numerical variable &#8211; height</em></figcaption></figure></div>


<p>The y-value is an estimate of the probability density for the corresponding value on the x-axis, which is the height variable, so the area under the curve between 175 cm and 180 cm gives the probability of the height of an Olympic athlete being between 175 cm and 180 cm.</p>



<p>We can clearly see in the KDE plots that the probability of winning gold is higher for a basketball athlete if he/she is tall, whereas height is a relatively small factor when it comes to winning gold in swimming.</p>



<h4>Pie chart&nbsp;</h4>



<p>A pie chart is a circular statistical graphic which is used to illustrate the distribution of a categorical variable. The pie is divided into slices, with each slice representing each category in the data. For the above dataset, we can describe the share of gold medals among the top 10 countries using a pie chart as this:</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img data-attachment-id="71234" data-permalink="https://neptune.ai/exploratory-data-analysis-for-tabular-data-7" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-7.png?fit=1128%2C780&amp;ssl=1" data-orig-size="1128,780" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="exploratory-data-analysis-for-tabular-data-7" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-7.png?fit=300%2C207&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-7.png?fit=1024%2C708&amp;ssl=1" decoding="async" width="1024" height="708" src="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-7.png?resize=1024%2C708&#038;ssl=1" alt="Example of pie chart" class="wp-image-71234" data-recalc-dims="1"/><figcaption><em>A pie chart with gold medals among the top 10 countries</em></figcaption></figure></div>


<p>Through this pie chart, we can see that the USA, Russia, and Germany are the leading countries in the Olympics.</p>



<h4>Bar chart</h4>



<p>A bar chart, sometimes known as a bar graph, is a type of chart or graph that displays a categorical variable using rectangular bars with heights proportionate to the values they represent. The bars can be plotted either horizontally or vertically.</p>



<p>For this dataset, we can plot the number of gold medals won by the top 20 countries as follows.</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img data-attachment-id="71235" data-permalink="https://neptune.ai/exploratory-data-analysis-for-tabular-data-8" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-8.png?fit=1999%2C1216&amp;ssl=1" data-orig-size="1999,1216" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="exploratory-data-analysis-for-tabular-data-8" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-8.png?fit=300%2C182&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-8.png?fit=1024%2C623&amp;ssl=1" decoding="async" width="1024" height="623" src="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-8.png?resize=1024%2C623&#038;ssl=1" alt="Example of a bar chart " class="wp-image-71235" data-recalc-dims="1"/><figcaption><em>A bar chart with the number of gold medals won by the top 20 countries</em></figcaption></figure></div>


<p>It is obvious that we will need a pretty big pie chart to display this information. Instead, we can use a bar chart as it looks more visually pleasing and easy to understand.</p>



<h4>Stacked bar chart</h4>



<p>A stacked bar chart is an extension to a simple bar chart where we can represent more than one variable. Each bar is further divided into segments where each segment represents a category. The height of the bar in the stacked bar chart is determined by the combined height of the variables.</p>



<p>We can now show the number of gold, silver, and bronze won by the leading 20 countries as follows:</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img data-attachment-id="71236" data-permalink="https://neptune.ai/exploratory-data-analysis-for-tabular-data-9" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-9.png?fit=1999%2C1233&amp;ssl=1" data-orig-size="1999,1233" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="exploratory-data-analysis-for-tabular-data-9" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-9.png?fit=300%2C185&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-9.png?fit=1024%2C632&amp;ssl=1" decoding="async" width="1024" height="632" src="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-9.png?resize=1024%2C632&#038;ssl=1" alt="Example of stacked bar chat " class="wp-image-71236" data-recalc-dims="1"/><figcaption><em>Stacked bar chart with the number of gold, silver, and bronze won by the leading 20 countries</em></figcaption></figure></div>


<p>So, as we can see in the stacked graph above, the USA is still leading in the number of gold medals as well as the total number of medals won. When we compare Italy and France, although France has more total number of medals in their name, Italy has slightly more gold medalists. Thus, this plot allows us to get more granular information that we can otherwise miss easily.</p>



<h4>Line chart</h4>



<p>A line chart or a curve chart is similar to a bar chart, but instead of bars, it shows information as a collection of data points that are connected by a line in a certain pattern. Line charts have an advantage – it’s easier to see small changes on line graphs than on bar graphs, and the line represents the overall trend very clearly.</p>



<p>As mentioned, the line plot is an excellent choice for describing certain trends, such as an increase in women athletes competing over the last years.</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img data-attachment-id="71237" data-permalink="https://neptune.ai/exploratory-data-analysis-for-tabular-data-10" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-10.png?fit=1310%2C1104&amp;ssl=1" data-orig-size="1310,1104" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="exploratory-data-analysis-for-tabular-data-10" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-10.png?fit=300%2C253&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-10.png?fit=1024%2C863&amp;ssl=1" decoding="async" width="1024" height="863" src="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-10.png?resize=1024%2C863&#038;ssl=1" alt="Example of line chart " class="wp-image-71237" data-recalc-dims="1"/><figcaption><em>Line chart with the number of women participating in the Olympics</em></figcaption></figure></div>


<p>From the above line plot, we can see a sharp rise in the number of women participating in the Olympics after 1980.</p>



<h4>Run Sequence plot</h4>



<p>If we plot a line graph between the values of a variable and a dummy index, we get a run sequence plot. It is important as we can test for the fixed location and fixed variation assumptions made while conducting Exploratory Data Analysis.</p>



<p>If the run sequence plot is flat and non-drifting, the fixed-location assumption holds, whereas If the run sequence plot has a vertical spread which is about the same over the entire plot, then the fixed-variation assumption holds.</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img data-attachment-id="71238" data-permalink="https://neptune.ai/exploratory-data-analysis-for-tabular-data-11" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-11.png?fit=1118%2C754&amp;ssl=1" data-orig-size="1118,754" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="exploratory-data-analysis-for-tabular-data-11" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-11.png?fit=300%2C202&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-11.png?fit=1024%2C691&amp;ssl=1" decoding="async" width="1024" height="691" src="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-11.png?resize=1024%2C691&#038;ssl=1" alt="Example of Run Sequence plot" class="wp-image-71238" data-recalc-dims="1"/><figcaption><em>Run Sequence plot </em></figcaption></figure></div>


<p>So we used this plot to check if the variable height in the dataset has fixed-location and fixed- variation and, as we can see, the graph appears to be non-drifting and flat, with a uniform vertical spread over the entire plot, so both these assumptions hold true for this variable.</p>



<h4>Area plot</h4>



<p>An area chart is similar to a line chart, except that the area between the x-axis and the line is filled in with colour or shading. The use cases of line charts and area plots are almost similar.</p>



<p>For our dataset, we can use an area plot to compare the gold medals won by men and women over the years.</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img data-attachment-id="71239" data-permalink="https://neptune.ai/exploratory-data-analysis-for-tabular-data-12" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-12.png?fit=1999%2C1145&amp;ssl=1" data-orig-size="1999,1145" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="exploratory-data-analysis-for-tabular-data-12" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-12.png?fit=300%2C172&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-12.png?fit=1024%2C587&amp;ssl=1" decoding="async" width="1024" height="587" src="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-12.png?resize=1024%2C587&#038;ssl=1" alt="Example of area plot" class="wp-image-71239" data-recalc-dims="1"/><figcaption><em>Area plot used to compare the gold medals won by men and women over the years</em></figcaption></figure></div>


<p>As a consequence of more female athletes since 1980, we can also see a spike in the number of gold medals won by women. This is an important observation, as based on the data before 1980, we can wrongfully conclude that a male athlete has a higher chance of winning gold as compared to a female athlete. Hence, we can say that there is a bias known as <a href="https://www.kdnuggets.com/2019/08/types-bias-machine-learning.html" target="_blank" rel="noreferrer noopener nofollow">prejudice bias </a>present in this dataset.</p>



<h4>Box plot</h4>



<p>A box plot, also called a box and whisker plot, shows the distribution of data for a continuous variable. It usually displays the five-number summary, i.e., minimum, first quartile, median, third quartile, and maximum for a dataset. A box is drawn from the first quartile to the third quartile, and the median of data is represented by a vertical line drawn through the box. Additionally, a box plot can be used as a visual tool for verifying normality or for identifying possible outliers.&nbsp;</p>



<p>A box plot also contains whiskers which are the lines that extend away from the box. For a more general case, as mentioned above, the boundary of the lower whisker is the minimum value of the data, while the boundary of the upper whisker is its maximum value.</p>



<p>In cases when we also want to find outliers, we use a variation of the box plot where the whiskers extend 1.5 times from the Interquartile Range (IQR) from the box&#8217;s top and bottom. The Interquartile range (IQR) is the distance between the upper(Q3) and lower quartiles(Q1) and is calculated by subtracting Q1 from Q3. The data points that fall outside of the end of the whiskers are referred to as outliers and are represented by dots.</p>



<p>In our dataset, we can plot box plots for our numeric variables such as height, age, and weight.</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img data-attachment-id="71240" data-permalink="https://neptune.ai/exploratory-data-analysis-for-tabular-data-13" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-13.png?fit=1468%2C1272&amp;ssl=1" data-orig-size="1468,1272" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="exploratory-data-analysis-for-tabular-data-13" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-13.png?fit=300%2C260&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-13.png?fit=1024%2C887&amp;ssl=1" decoding="async" width="1024" height="887" src="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-13.png?resize=1024%2C887&#038;ssl=1" alt="Example of box plot" class="wp-image-71240" data-recalc-dims="1"/><figcaption><em>Box plots for the numeric variables &#8211; height, weight, age</em></figcaption></figure></div>


<p>So, from the above box plots, we can get a good idea regarding the distribution of the height, weight, and age variables. We can also see how weight and age features have a lot of outliers, predominantly at the higher en.</p>



<h4>Scatter plot</h4>



<p>In most cases, scatter plots are used to examine correlations between two continuous variables in a dataset. The values of the two variables are represented by the horizontal and vertical axes, and their cartesian coordinates correspond to the value for a single data point.</p>



<p>In our dataset, we can try to find the relation between height and weight variables as follows:</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img data-attachment-id="71241" data-permalink="https://neptune.ai/exploratory-data-analysis-for-tabular-data-14" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-14.png?fit=1872%2C1216&amp;ssl=1" data-orig-size="1872,1216" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="exploratory-data-analysis-for-tabular-data-14" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-14.png?fit=300%2C195&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-14.png?fit=1024%2C665&amp;ssl=1" decoding="async" width="1024" height="665" src="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-14.png?resize=1024%2C665&#038;ssl=1" alt="Example of scatter plot" class="wp-image-71241" data-recalc-dims="1"/><figcaption><em>Scatter plot used to find the relation between height and weight </em></figcaption></figure></div>


<p>To move one step further, we can add one more categorical variable, such as the sex of an athlete, into the comparison as follows:</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img data-attachment-id="71242" data-permalink="https://neptune.ai/exploratory-data-analysis-for-tabular-data-15" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-15.png?fit=1860%2C1200&amp;ssl=1" data-orig-size="1860,1200" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="exploratory-data-analysis-for-tabular-data-15" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-15.png?fit=300%2C194&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-15.png?fit=1024%2C661&amp;ssl=1" decoding="async" width="1024" height="661" src="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-15.png?resize=1024%2C661&#038;ssl=1" alt="Another example of scatter plot" class="wp-image-71242" data-recalc-dims="1"/><figcaption><em>Scatter plot expanded to include the sex of an athlete</em></figcaption></figure></div>


<p>From the scatter plot above, we can conclude that the majority of male athletes have an advantage over female athletes when it comes to height and weight. Also, we cannot miss the fact that as the weight increases, the height of an athlete also increases, which may be an indication of the overall fitness of an athlete.</p>



<h4>Lag plot</h4>



<p>A lag plot is a special kind of scatter plot in which the X-axis and Y-axis both represent the same data points, but there is a difference in index or time units. The difference between these time units is called lag.</p>



<p>Let Y(i) be the value assumed by a variable/feature at index i or time step i (for time series data), then the lag plot contains the following axes:</p>



<p>Vertical axis: Y(i) for all i, starting from 0 to n.</p>



<p>Horizontal axis: Y(i-k) for all i, where k is the lag value and is 1 by default.</p>



<p>The randomness assumption is the most critical but least tested, and we can check for it using a lag plot. If the data is random, the points on the graph will be dispersed both horizontally and vertically quite equally, indicating no pattern. On the other hand, a graph with a form or trend (such as a linear pattern) shows that the data is not purely random.</p>



<p>We can plot the lag plot for the height variable of our dataset as follows:</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img data-attachment-id="71243" data-permalink="https://neptune.ai/exploratory-data-analysis-for-tabular-data-16" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-16.png?fit=1324%2C1054&amp;ssl=1" data-orig-size="1324,1054" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="exploratory-data-analysis-for-tabular-data-16" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-16.png?fit=300%2C239&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-16.png?fit=1024%2C815&amp;ssl=1" decoding="async" width="1024" height="815" src="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-16.png?resize=1024%2C815&#038;ssl=1" alt="Example of a lag plot" class="wp-image-71243" data-recalc-dims="1"/><figcaption><em>Lag plot for a numerical variable &#8211; height</em></figcaption></figure></div>


<p>Here the data seems to be completely random, and there appears to be no pattern present. Hence the data also fulfills the randomness assumption.&nbsp;</p>



<h4>Pair plot</h4>



<p>A pair plot is a data visualization that shows pairwise associations between various variables of a dataset in a grid so that we may more easily see how they relate to one another. The diagonal of the grid can represent a histogram or KDE, as shown in the following example in which we compare the height, weight, and age variables of the dataset.</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img data-attachment-id="71244" data-permalink="https://neptune.ai/exploratory-data-analysis-for-tabular-data-17" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-17.png?fit=1174%2C1288&amp;ssl=1" data-orig-size="1174,1288" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="exploratory-data-analysis-for-tabular-data-17" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-17.png?fit=273%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-17.png?fit=933%2C1024&amp;ssl=1" decoding="async" width="933" height="1024" src="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-17.png?resize=933%2C1024&#038;ssl=1" alt="Example of a pair plot " class="wp-image-71244" data-recalc-dims="1"/><figcaption><em>Pair plot for the dataset </em></figcaption></figure></div>


<p>In this plot, we can try to find if any two features are correlated. As we can see, there appears to be no clear relation between age and height or age and weight. As seen earlier, there seems to be a correlation between weight and height, which is not surprising at all. An interesting thing to check will be if we can drop any of these features without losing much information.</p>



<h4>Heatmap</h4>



<p>A heatmap is a two-dimensional matrix representation of data where each cell is represented by a colour. Usually, during EDA, we use this visualization to plot the correlations among all the numerical variables in the dataset.</p>



<p>Let us try to find such relationships among a few variables of our dataset.</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img data-attachment-id="71245" data-permalink="https://neptune.ai/exploratory-data-analysis-for-tabular-data-18" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-18.png?fit=1518%2C740&amp;ssl=1" data-orig-size="1518,740" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="exploratory-data-analysis-for-tabular-data-18" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-18.png?fit=300%2C146&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-18.png?fit=1024%2C499&amp;ssl=1" decoding="async" width="1024" height="499" src="https://i0.wp.com/neptune.ai/wp-content/uploads/exploratory-data-analysis-for-tabular-data-18.png?resize=1024%2C499&#038;ssl=1" alt="Example of a heatmap" class="wp-image-71245" data-recalc-dims="1"/><figcaption><em>Heatmap for the dataset</em></figcaption></figure></div>


<p>Correlation is a statistical term which measures the degree up to which two variables move in coordination with one another. If the two variables move in the same direction, then those variables are said to have a positive correlation, and vice versa. Also, if the two variables have no relation, then the correlation value is near zero, as is between height and age in our example.</p>



<p>So now I have the answers to my questions, but some of these answers lead to a new set of questions –</p>


<div class="custom-point-list">
<ol><li>We now know that the USA has the most medals in the Olympics, but It will be interesting to know which and why other countries are lagging behind.&nbsp;</li><li>We found out some factors like athlete height can be advantageous when it comes to basketball, so it would make sense to add more tall athletes to the basketball teams.&nbsp;</li><li>We now also know that there is a chance that we can drop either the weight or height feature without losing much information about the data.&nbsp;</li><li>Also, it is clear that the data is biased, and if we use this data to train any model, it may produce a model biased against female athletes.&nbsp;</li></ol>
</div>


<p>To answer subsequent questions, you can do EDA in a more granular and detailed way and find some more interesting things about this data.</p>



<h3>Quantitative techniques</h3>



<p>Even though EDA is mostly centred around graphical techniques, it includes certain quantitative approaches. Most of the quantitative techniques fall into two broad categories:</p>


<div class="case-study-numbered-list">
    <h2></h2>
    <ul>
                    <li><span>1</span>Interval estimation <br />
</li>
                    <li><span>2</span>Hypothesis testing </li>
            </ul>
</div>



<p>In this section, we are going to cover them briefly. I would like to point to this <a href="https://online.stat.psu.edu/stat200/lesson/6/6.6#:~:text=Confidence%20intervals%20and%20hypothesis%20tests,to%20test%20a%20specified%20hypothesis." target="_blank" rel="noreferrer noopener nofollow">resource</a> if you want to read about these techniques in depth.</p>



<h4>Interval estimation</h4>



<p>The concept of interval estimate is used to create a range of values within which a variable is expected to fall. The confidence interval is a good example of this.</p>


<div class="custom-point-list">
<ul><li>The confidence interval represents the statistical significance of the expected distance between the real value and the observed estimate.&nbsp;</li><li>An N% confidence interval for some parameter p, is an interval having a lower bound(LB) and an upper bound (UB) that is expected with probability N% to contain p such that LB&lt;=p&lt;=UB.</li><li>The confidence interval is a way to show what the uncertainty is with a certain statistic.</li></ul>
</div>


<h4>Hypothesis testing&nbsp;</h4>



<p>A statistical hypothesis is a statement that is considered to be true until there is substantial evidence to the contrary. Hypothesis testing is widely used in many disciplines to determine whether a proposition is true or false.</p>



<p>Rejecting a hypothesis implies that it is untrue. Accepting a hypothesis, however, does not imply that it is true; it only means that we lack evidence to believe otherwise. As a result, hypothesis tests are defined in terms of both an acceptable (null) and an unacceptable (non-null) outcome (alternative).</p>



<p>Hypothesis testing is a multi-step process consisting of the following:</p>


<div class="custom-point-list">
<ol><li><strong>Null hypothesis:</strong> This is the statement that is assumed to be true.</li><li><strong>Alternative hypothesis:</strong> This is the statement that will be accepted if the null hypothesis is rejected.</li><li><strong>Test statistic:</strong> The test determines if the observed data fall outside of the null hypothesis&#8217;s expected range of values. The type of data will determine which statistical test is used.</li><li><strong>Significance level:</strong> The significance level is a figure that the researcher specifies in advance as the threshold for statistical significance. It is the highest risk of getting a false positive conclusion that you are ready to tolerate.</li><li><strong>The critical value:</strong> The critical region encompasses those values of the test statistic that lead to a rejection of the null hypothesis</li><li><strong>The decision:</strong> The null hypothesis is accepted or rejected based on the relationship between the test statistic and the critical value.</li></ol>
</div>


<h2>Conclusion</h2>



<p>I hope this article gave you a good idea about some core concepts behind Exploratory Data Analysis. Although there are numerous EDA techniques, especially graphical techniques described in this article, there are a lot more out there and which ones to use depends on the dataset and your personal requirement. As mentioned earlier in this article, EDA is like a detective’s work and is mostly subjective, so you are free to raise as many questions as possible about your data and find their answers using EDA.</p>



<h3>References</h3>


<div class="custom-point-list">
<ol><li><a href="https://www.itl.nist.gov/div898/handbook/eda/eda.htm" target="_blank" rel="noreferrer noopener nofollow">EDA &#8211; Information Technology Laboratory</a></li><li><a href="https://r4ds.had.co.nz/exploratory-data-analysis.html" target="_blank" rel="noreferrer noopener nofollow">R for Data Science</a></li><li><a href="https://www.gs.washington.edu/academics/courses/akey/56008/lecture/lecture2.pdf" target="_blank" rel="noreferrer noopener nofollow">Descriptive Statistics and Exploratory Data Analysis</a></li></ol>
</div>



<div id="author-box-new-format-block_61e6cef6506de" class="article__footer article__author">
  <div class="article__authorImage">
          <img width="200" height="200" src="https://i0.wp.com/neptune.ai/wp-content/uploads/M.Mujtaba.jpeg?fit=200%2C200&amp;ssl=1" class="article__authorImage-img" alt="Mirza Mujtaba" decoding="async" data-attachment-id="60910" data-permalink="https://neptune.ai/m-mujtaba" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/M.Mujtaba.jpeg?fit=200%2C200&amp;ssl=1" data-orig-size="200,200" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="M.Mujtaba" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/M.Mujtaba.jpeg?fit=200%2C200&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/M.Mujtaba.jpeg?fit=200%2C200&amp;ssl=1" />      </div>

  <div class="article__authorContent">
          <h3 class="article__authorContent-name">Mirza Mujtaba</h3>
    
          <p class="article__authorContent-text">Experienced Machine Learning Engineer with a demonstrated history of working in the financial services industry. Skilled in Analytical Skills, PHP, Data Science, Data Analytics, and Data Analysis. Strong engineering professional with a Bachelor of Technology &#8211; BTech focused in Computer Science from University of Kashmir.</p>
    
          <ul class="article__authorSocial">
        <li class="article__authorSocial-single article__authorSocial-name">Follow me on</li>
        
                  <li class="article__authorSocial-single"><a href="https://www.linkedin.com/in/mirza-mujtaba-011aa31a0/" class="article__authorSocial-lk" target="_blank"></a></li>
        
              </ul>
    
  </div>
</div>


<div class="is-layout-flow wp-block-group"><div class="wp-block-group__inner-container">
<hr class="wp-block-separator has-css-opacity"/>



<p class="has-text-color" style="color:#4455a6"><strong>READ NEXT</strong></p>



<h2>Real-World MLOps Examples: Model Development in Hypefactors</h2>



<p class="has-small-font-size">6 mins read | Author&nbsp;Stephen Oladele | Updated June 28th, 2022</p>


<div id="block_5ffc75def9f8e" class="separator separator-10"></div>



<p>In this first installment of the series “Real-world MLOps Examples,”&nbsp;<a href="https://www.linkedin.com/in/jules-belveze" target="_blank" rel="noreferrer noopener">Jules Belveze</a>, an MLOps Engineer, will walk you through the model development process at&nbsp;<a href="https://hypefactors.com/" target="_blank" rel="noreferrer noopener">Hypefactors</a>, including the types of models they build, how they design their training pipeline, and other details you may find valuable. Enjoy the chat!</p>



<h3 id="company-profile">Company profile</h3>



<p><a href="https://hypefactors.com/" target="_blank" rel="noreferrer noopener">Hypefactors</a>&nbsp;provides an all-in-one media intelligence solution for managing PR and communications, tracking trust, product launches, and market and financial intelligence. They operate large data pipelines that stream in the world’s media data ongoingly in real-time. AI is used for many automations that were previously performed manually.</p>



<h3 id="guest-introduction">Guest introduction</h3>



<h4>Could you introduce yourself to our readers?</h4>



<p>Hey Stephen, thanks for having me! My name is Jules. I am 26. I was born and raised in Paris, I am currently living in Copenhagen.</p>



<h4>Hey Jules! Thanks for the intro. Walk me through your background and how you got to Hypefactors.</h4>



<p>I hold a Bachelor’s in statistics and probabilities and a Master’s in general engineering from universities in France. On top of that, I also graduated in Data Science with a focus on deep learning from Danish Technical University, Denmark. I’m fascinated by multilingual natural language processing (and therefore specialized in it). I also researched anomaly detection on high-dimensional time series during my graduate studies with Microsoft.&nbsp;</p>



<p>Today, I work for a media intelligence tech company called Hypefactors, where I develop NLP models to help our users gain insights from the media landscape. What currently works for me is having the opportunity to carry out models from prototyping all the way to production. I guess you could call me a nerd, at least that’s how my friend describes me, as I spent most of my free time either coding or listening to disco vinyl.</p>



<h3 id="model-development-at-hypefactors">Model development at Hypefactors</h3>



<h4>Could you elaborate on the types of models you build at Hypefactors?</h4>



<p>Even though we also have computer vision models running in production, we mainly build&nbsp;<a href="https://neptune.ai/blog/category/natural-language-processing" target="_blank" rel="noreferrer noopener">NLP (Natural Language Processing)</a>&nbsp;models for various use cases. We need to cover multiple countries and handle many languages. The multilingual aspect makes developing with “classical machine learning” approaches hard. We craft deep learning models on top of the&nbsp;<a href="https://github.com/huggingface/transformers" target="_blank" rel="noreferrer noopener">transformer library</a>.&nbsp;</p>



<p>We run all sorts of models in production, varying from span extraction or sequence classification to text generation. Those models are designed to serve different use cases, like topic classification, sentiment analysis, or summarisation.</p>


<a class="button continous-post blue-filled" href="/blog/mlops" target="_blank">
    Continue reading -&gt;</a>



<hr class="wp-block-separator has-css-opacity"/>
</div></div>
<p>The post <a rel="nofollow" href="https://neptune.ai/blog/exploratory-data-analysis-for-tabular-data">Exploratory Data Analysis for Tabular Data</a> appeared first on <a rel="nofollow" href="https://neptune.ai">neptune.ai</a>.</p>
]]></content:encoded>
					
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">71225</post-id>	</item>
		<item>
		<title>Best ML Model Registry Tools</title>
		<link>https://neptune.ai/blog/ml-model-registry-best-tools</link>
		
		<dc:creator><![CDATA[Gourav Bais]]></dc:creator>
		<pubDate>Mon, 05 Sep 2022 08:11:31 +0000</pubDate>
				<category><![CDATA[Machine Learning Tools]]></category>
		<category><![CDATA[mlops]]></category>
		<guid isPermaLink="false">https://neptune.ai/?p=71093</guid>

					<description><![CDATA[<p>A model registry is a central repository that is used to version control Machine Learning (ML) models. It simply tracks the models while they move between training, production, monitoring, and deployment. It stores all the predominant information such as: metadata, lineage, model versions, annotations, and training jobs. As the model registry is shared by multiple [&#8230;]</p>
<p>The post <a rel="nofollow" href="https://neptune.ai/blog/ml-model-registry-best-tools">Best ML Model Registry Tools</a> appeared first on <a rel="nofollow" href="https://neptune.ai">neptune.ai</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<p><strong>A model registry</strong> is a central repository that is used to <a href="/blog/version-control-for-ml-models" target="_blank" rel="noreferrer noopener">version control Machine Learning (ML) models</a>. It simply tracks the models while they move between training, production, monitoring, and deployment. It stores all the predominant information such as:</p>


<div class="custom-point-list">
<ul><li>metadata, </li><li>lineage, </li><li>model versions, </li><li>annotations, </li><li>and training jobs. </li></ul>
</div>


<p>As the model registry is shared by multiple team members working on the same machine learning project, <strong>model governance</strong> is a major advantage that these teams have. This governance data tells them:</p>


<div class="custom-point-list">
<ul><li>which dataset was used for training, </li><li>who trained and published a model, </li><li>what’s the predictive performance of the model, </li><li>and finally, when the model was deployed to production.</li></ul>
</div>


<div id="blog-cta-intext-block_8e300d741040b2077cf4de75d857355c" class="blog-cta-intext">
  <h3 class="blog-cta-intext__title">Read also </h3>
  <div class="blog-cta-intext__content"><p><a href="/blog/tools-for-ml-model-governance-provenance-lineage" target="_blank" rel="noopener">Best Tools for ML Model Governance, Provenance, and Lineage</a></p>
</div>
  </div>


<p>Usually, while working in a team, different team members tend to try out different things, and only a few of them are finalized and pushed to the version control tool they use. The model registry helps them solve this issue as each team member can try their own versions of models, and they will <strong>have a record of all the things they have experimented with throughout the project journey</strong>.</p>



<p>This article will discuss the model registry tools and evaluation criteria for such tools. You will also see a comparison of different model registry tools, such as: </p>


<div class="custom-point-list">
<ol><li>Neptune.ai, </li><li>MLflow, </li><li>AWS Sagemaker, </li><li>Verta.ai, </li><li>and Comet. </li></ol>
</div>


<p>So let’s get started!</p>


<div class="table-of-contents">
        <div class="table-elements">
                                    <div class="table-element">
                    <a href="#model-registry-tools">
                        <span>Jump right to the tools list -></span>
                    </a>
                </div>
                        </div>
</div>


<h2>Evaluation criteria for choosing model registry tools&nbsp;</h2>



<p>The model registry is an important part of <a href="/blog/category/machine-learning-tools" target="_blank" rel="noreferrer noopener">MLOps platforms/tools</a>. There are plenty of tools available in the market that can fulfill your ML workflow needs. Here is an illustration that classifies these tools on the basis of their specialization.</p>


<div class="wp-block-image">
<figure class="aligncenter size-full"><img data-attachment-id="71095" data-permalink="https://neptune.ai/best-model-registry-tools-1" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/best-model-registry-tools-1.png?fit=934%2C644&amp;ssl=1" data-orig-size="934,644" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="best-model-registry-tools-1" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/best-model-registry-tools-1.png?fit=300%2C207&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/best-model-registry-tools-1.png?fit=934%2C644&amp;ssl=1" decoding="async" width="934" height="644" src="https://i0.wp.com/neptune.ai/wp-content/uploads/best-model-registry-tools-1.png?resize=934%2C644&#038;ssl=1" alt="Various model registry tools " class="wp-image-71095" data-recalc-dims="1"/><figcaption><em>Classification of model registry tools | <a href="https://www.thoughtworks.com/content/dam/thoughtworks/documents/whitepaper/tw_whitepaper_guide_to_evaluating_mlops_platforms_2021.pdf" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>


<p>The products on the bottom right are focused on <a href="/blog/best-8-machine-learning-model-deployment-tools" target="_blank" rel="noreferrer noopener">deployment</a> and <a href="/blog/ml-model-monitoring-best-tools" target="_blank" rel="noreferrer noopener">monitoring</a>; those on the bottom-left focus on training and <a href="/blog/best-ml-experiment-tracking-tools" target="_blank" rel="noreferrer noopener">tracking</a>. Those at the very top aim to cover every aspect of the ML lifecycle, while those in the middle-top do most or all of the spectrum with leaning one way or another.</p>



<p>To visualize it even more precisely, let’s have a look at another image:</p>


<div class="wp-block-image">
<figure class="aligncenter size-full"><img data-attachment-id="71096" data-permalink="https://neptune.ai/best-model-registry-tools-2" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/best-model-registry-tools-2.png?fit=872%2C558&amp;ssl=1" data-orig-size="872,558" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="best-model-registry-tools-2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/best-model-registry-tools-2.png?fit=300%2C192&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/best-model-registry-tools-2.png?fit=872%2C558&amp;ssl=1" decoding="async" width="872" height="558" src="https://i0.wp.com/neptune.ai/wp-content/uploads/best-model-registry-tools-2.png?resize=872%2C558&#038;ssl=1" alt="More precise classification of model registry tools " class="wp-image-71096" data-recalc-dims="1"/><figcaption><em>More precise</em> <em>classification of model registry tools | <a href="https://www.thoughtworks.com/content/dam/thoughtworks/documents/whitepaper/tw_whitepaper_guide_to_evaluating_mlops_platforms_2021.pdf" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>


<p>From the above image, it can be inferred that tools like <a href="https://www.kubeflow.org/" target="_blank" rel="noreferrer noopener nofollow">Kubeflow</a> and other cloud providers are the most balanced and cover every stage of an ML pipeline development equally. Specialized tools like <a href="/" target="_blank" rel="noreferrer noopener">Neptune </a>and <a href="https://polyaxon.com/" target="_blank" rel="noreferrer noopener nofollow">Polyaxon </a>are closest to their axis, i.e., majorly focused on model training.&nbsp;</p>



<p><em>NOTE: Aforementioned evaluation criteria for these tools is subjective to the features these tools had at that point in time (November 2021). Many of these tools have moved much beyond their area of specialization in the past year, so take this discussion with a pinch of salt.</em></p>



<p>However, there are some evergreen factors that are integral to determining a registry tool’s effectiveness. From my own experience, some of them are:</p>



<h3>Installation and integration</h3>



<p>Choosing the right model registry tool is often influenced by how it would be installed and what kind of integrations it would offer. Usually, organizations choose the tools based on their development environment. For example:</p>


<div class="custom-point-list">
<ul><li>if the organization is using <a href="https://aws.amazon.com/" target="_blank" rel="noreferrer noopener nofollow">AWS</a> for whole development and deployment, in that case, Sagemaker would make a lot of sense as there would be no compatibility issues. </li><li>But if the organization is not using AWS, then tools like Neptune or <a href="https://mlflow.org/" target="_blank" rel="noreferrer noopener nofollow">MLFlow</a> can be used for a model registry.&nbsp;</li><li>On the other hand, tools that are typically viewed as end-to-end, like Sagemaker, are more and more open to the concept of interoperability and the fact that users can complement them with other tools. </li></ul>
</div>


<p>Integrations can be a major worry for firms that are dedicated to their current choices in terms of their technological stack. If an organization is using some continuous integration tool, they might prefer the model registry tool that easily blends in.&nbsp;</p>



<h3>Ease of automation</h3>



<p>Another requirement of a model registry tool is how easily the development team can make use of that tool. </p>


<div class="custom-point-list">
<ul><li>Some tools require you to code all the things needed to store the model versions,</li><li>While some tools require very less coding, and you just need to drag and drop different components to use them. </li><li>There are also some tools fully based on the concept of AutoML and do not require you to write any code for storing your model versions.&nbsp;</li></ul>
</div>


<p>Auto-ML tools have less flexibility for customizations while Low-Code tools provide both custom and automation options finally, Code-First tools only provide a writing code facility. You can choose a tool based on your requirement.</p>



<h3>Updated model overview and model stages tracking&nbsp;</h3>



<p>The entire purpose of a model registry tool is to provide an easy overview of all the versions of models that the development team has tried. While selecting the tool, you must remember that the tool must provide the model overview of each version at every stage. Tracking models extend beyond development; it is done for maintenance and enhancement in staging and production as well. The machine learning model lifetime including:</p>


<div class="custom-point-list">
<ul><li>training, </li><li>staging, </li><li>and production, </li></ul>
</div>


<p>must be tracked by the model registration tool.</p>



<h3>Competence in managing the model dependencies</h3>



<p>The model registry tool must have compatibility with all the dependencies the ML model needs. You should check the dependencies competence for the Machine Learning libraries, Python version, and data. If you are working on some use case that requires a special ML library and the registry tool does not support it, that tool would not make much sense for you.</p>



<h3>Providing the flexibility of team collaboration</h3>



<p>You may evaluate whether you and your team can collaborate on the registered model or not. If the model registry enables you to work with your team on the same ML model, then you can choose that tool.</p>



<p>Thus, you can follow the evaluation criteria to select the best model registry tool according to your requirements.</p>



<h2>Comparison of model registry tools</h2>



<p>Every model registry tool has different features and performs various unique operations. Here&#8217;s how they compare:</p>


<div class="medium-table">
        <div class="mt-row heading">
            <div class="mt-col" style="width: 20%">
            Functionality         </div>
            <div class="mt-col" style="width: 16%">
            Neptune.ai        </div>
            <div class="mt-col" style="width: 16%">
            Amazon SageMaker        </div>
            <div class="mt-col" style="width: 16%">
            MLFlow        </div>
            <div class="mt-col" style="width: 16%">
            Comet         </div>
            <div class="mt-col" style="width: 16%">
            Verta.AI        </div>
        </div>
    
            <div class="mt-row">
                            <div class="mt-col" style="width: 20%">
                                                                <p>Dataset versioning</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        Neptune.ai:
                    </span>
                                                                <p>Yes</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        Amazon SageMaker:
                    </span>
                                                                <p>No</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        MLFlow:
                    </span>
                                                                <p>No</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        Comet :
                    </span>
                                                                <p>No</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        Verta.AI:
                    </span>
                                                                <p>Yes</p>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 20%">
                                                                <p>Versioning model files</p>
<p></p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        Neptune.ai:
                    </span>
                                                                <p>Yes</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        Amazon SageMaker:
                    </span>
                                                                <p>Yes</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        MLFlow:
                    </span>
                                                                <p>Yes</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        Comet :
                    </span>
                                                                <p>Limited</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        Verta.AI:
                    </span>
                                                                <p>Yes</p>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 20%">
                                                                <p>Versioning model explanations&nbsp;</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        Neptune.ai:
                    </span>
                                                                <p>Limited</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        Amazon SageMaker:
                    </span>
                                                                <p>Yes</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        MLFlow:
                    </span>
                                                                <p>Yes</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        Comet :
                    </span>
                                                                <p>Limited</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        Verta.AI:
                    </span>
                                                                <p>Yes</p>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 20%">
                                                                <p>Model lineage</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        Neptune.ai:
                    </span>
                                                                <p>No</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        Amazon SageMaker:
                    </span>
                                                                <p>Limited</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        MLFlow:
                    </span>
                                                                <p>No</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        Comet :
                    </span>
                                                                <p>Limited</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        Verta.AI:
                    </span>
                                                                <p>No</p>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 20%">
                                                                <p>Main stage transition tags</p>
<p></p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        Neptune.ai:
                    </span>
                                                                <p>Yes</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        Amazon SageMaker:
                    </span>
                                                                <p>No</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        MLFlow:
                    </span>
                                                                <p>Yes</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        Comet :
                    </span>
                                                                <p>Yes</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        Verta.AI:
                    </span>
                                                                <p>Yes</p>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 20%">
                                                                <p>Model compare</p>
<p></p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        Neptune.ai:
                    </span>
                                                                <p>Limited</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        Amazon SageMaker:
                    </span>
                                                                <p>No</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        MLFlow:
                    </span>
                                                                <p>No</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        Comet :
                    </span>
                                                                <p>No</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        Verta.AI:
                    </span>
                                                                <p>No</p>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 20%">
                                                                <p>Model searching&nbsp;</p>
<p></p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        Neptune.ai:
                    </span>
                                                                <p>No</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        Amazon SageMaker:
                    </span>
                                                                <p>Limited</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        MLFlow:
                    </span>
                                                                <p>Limited</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        Comet :
                    </span>
                                                                <p>Limited</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        Verta.AI:
                    </span>
                                                                <p>No</p>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 20%">
                                                                <p>Model packaging</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        Neptune.ai:
                    </span>
                                                                <p>No</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        Amazon SageMaker:
                    </span>
                                                                <p>Limited</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        MLFlow:
                    </span>
                                                                <p>Yes</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        Comet :
                    </span>
                                                                <p>No</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        Verta.AI:
                    </span>
                                                                <p>Yes</p>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 20%">
                                                                <p>Pricing</p>
<p>&nbsp;</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        Neptune.ai:
                    </span>
                                                                <p>Free for individuals and researchers, paid for teams</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        Amazon SageMaker:
                    </span>
                                                                <p>Usage based pricing</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        MLFlow:
                    </span>
                                                                <p>Free</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        Comet :
                    </span>
                                                                <p>Free for individuals and researchers, paid for teams</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        Verta.AI:
                    </span>
                                                                <p>Open-source and paid versions available</p>
                                    </div>
                    </div>
    </div>


<div id="block_be07f737a3ce65f74b59cce0dd95e8d9" class="separator separator-15"></div>



<h2>Model registry tools</h2>



<p>Here are a number of model registry tools that are used across the industry:</p>



<h3>1. <a href="/product/model-registry" target="_blank" rel="noreferrer noopener">Neptune.ai</a></h3>



<p>Neptune is a metadata store for experiment tracking and model registry. So registering models is one of the two key functionalities of this tool. </p>



<p>In general, Neptune allows you to<strong> log, compare, display, query, and organize all metadata</strong> related to ML experiments and models. It only takes a few lines of code to integrate it with your code, the API is flexible, and the UI is user-friendly but also prepared for the high volume of logged metadata. </p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><a href="https://i0.wp.com/neptune.ai/wp-content/uploads/best-model-registry-tools-3.png?ssl=1"><img data-attachment-id="71097" data-permalink="https://neptune.ai/best-model-registry-tools-3" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/best-model-registry-tools-3.png?fit=1999%2C1142&amp;ssl=1" data-orig-size="1999,1142" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="best-model-registry-tools-3" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/best-model-registry-tools-3.png?fit=300%2C171&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/best-model-registry-tools-3.png?fit=1024%2C585&amp;ssl=1" decoding="async" width="1024" height="585" src="https://i0.wp.com/neptune.ai/wp-content/uploads/best-model-registry-tools-3.png?resize=1024%2C585&#038;ssl=1" alt="Neptune dashboard " class="wp-image-71097" data-recalc-dims="1"/></a><figcaption><em>Neptune dashboard showing a list of registered model versions | <a href="https://app.neptune.ai/common/showcase-model-registry/m/SHOW2-MOD21/versions" target="_blank" rel="noreferrer noopener">Source</a></em></figcaption></figure></div>


<p>&nbsp;Some of the features of Neptune’s model registry include:</p>


<div class="custom-point-list">
<ul><li>It lets you <a href="https://docs.neptune.ai/how-to-guides/model-registry/creating-model-versions" target="_blank" rel="noreferrer noopener">register models and model versions</a>, along with the metadata associated with these versions. It can version model code, images, datasets, Git info, and notebooks.</li><li>It allows you to filter and sort the versioned data easily.</li><li>It lets you <a href="https://docs.neptune.ai/how-to-guides/model-registry/managing-model-stages" target="_blank" rel="noreferrer noopener">manage model stage transitions </a>using four available stages.</li><li>You can then <a href="https://docs.neptune.ai/how-to-guides/model-registry/querying-and-downloading-models-and-metadata" target="_blank" rel="noreferrer noopener">query and download any stored model files</a> and metadata.</li><li>Additionally, it records all your metadata for machine learning model development with version control in one place.</li><li>And it h<a href="https://docs.neptune.ai/you-should-know/collaboration-in-neptune" target="_blank" rel="noreferrer noopener">elps your team to collaborate</a> on model building and experiments by providing persistent links and share buttons for its central ML metadata store and the table for all runs so far.</li><li>It supports different connection modes such as asynchronous (default),&nbsp;synchronous, offline, read-only, and debug modes for the versioned metadata tracking.&nbsp;&nbsp;&nbsp;</li></ul>
</div>


<h3>2. <a href="https://mlflow.org/" target="_blank" rel="noreferrer noopener nofollow">MLflow</a></h3>



<p>An open-source platform that you can use for managing the ML model lifecycle. MLFlow enables you to track the MLOps life cycle with the help of its APIs. It provides model versioning, model lineage, annotations, and transitions from development to deployment functionalities.</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><a href="https://i0.wp.com/neptune.ai/wp-content/uploads/best-model-registry-tools-4.png?ssl=1"><img data-attachment-id="71098" data-permalink="https://neptune.ai/best-model-registry-tools-4" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/best-model-registry-tools-4.png?fit=1600%2C894&amp;ssl=1" data-orig-size="1600,894" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="best-model-registry-tools-4" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/best-model-registry-tools-4.png?fit=300%2C168&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/best-model-registry-tools-4.png?fit=1024%2C572&amp;ssl=1" decoding="async" width="1024" height="572" src="https://i0.wp.com/neptune.ai/wp-content/uploads/best-model-registry-tools-4.png?resize=1024%2C572&#038;ssl=1" alt="MLFlow dashboard " class="wp-image-71098" data-recalc-dims="1"/></a><figcaption><em>MLFlow dashboard | <a href="https://www.databricks.com/product/mlflow-model-registry" target="_blank" rel="noreferrer noopener nofollow">Source</a>&nbsp;</em></figcaption></figure></div>


<p>Some features of MLflow model registry are as follows:</p>


<div class="custom-point-list">
<ul><li>It provides chronological model lineage, i.e., ​​which MLflow experiment and run produced the model at a given time.</li><li>It provides different predefined model stages as Archived, Staging, and Production but allocates one model stage at a time for different model versions.</li><li>MLflow allows you to annotate the top-level models and version them individually using markdown.</li><li>It offers webhooks so that you can automatically trigger actions based on registry events.</li><li>There is also a provision for email notifications of model events.</li></ul>
</div>


<div id="blog-cta-intext-block_cc53fd661a9545434d66dcf2822a7616" class="blog-cta-intext">
  <h3 class="blog-cta-intext__title">Learn more</h3>
  <div class="blog-cta-intext__content"><p>Check detailed <a href="/vs/mlflow">comparison between Neptune.ai and MLflow</a>.</p>
</div>
  </div>


<h3>3. <a href="https://aws.amazon.com/sagemaker/" target="_blank" rel="noreferrer noopener nofollow">Amazon SageMaker</a></h3>



<p>Developers use Amazon SageMaker for complete control of the ML development lifecycle. You can catalogue production models, associate metadata, and manage versions and approval status of models with the SageMaker registry.&nbsp;</p>



<p>First, you create a version of a model and specify its respective group. Besides, you could use an inference pipeline to register the model with variables and container specifications. Then you may create new model versions using AWS Python SDK. Moreover, you can also deploy the model out of the model registry using AWS. You can deploy the trained Machine Learning model with real-time interference and low latency to SageMaker endpoints. This deployed model can be monitored using the Amazon SageMaker Model Monitor feature.&nbsp;</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><a href="https://i0.wp.com/neptune.ai/wp-content/uploads/best-model-registry-tools-5.png?ssl=1"><img data-attachment-id="71099" data-permalink="https://neptune.ai/best-model-registry-tools-5" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/best-model-registry-tools-5.png?fit=1400%2C608&amp;ssl=1" data-orig-size="1400,608" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="best-model-registry-tools-5" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/best-model-registry-tools-5.png?fit=300%2C130&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/best-model-registry-tools-5.png?fit=1024%2C445&amp;ssl=1" decoding="async" width="1024" height="445" src="https://i0.wp.com/neptune.ai/wp-content/uploads/best-model-registry-tools-5.png?resize=1024%2C445&#038;ssl=1" alt="Amazon SageMaker dashboard" class="wp-image-71099" data-recalc-dims="1"/></a><figcaption><em>Amazon SageMaker dashboard | <a href="https://towardsdatascience.com/track-manage-discover-and-reuse-ai-models-better-using-amazon-sagemaker-model-registry-a238ec73351c" target="_blank" rel="noreferrer noopener nofollow">Source</a>&nbsp;</em></figcaption></figure></div>


<p>Some features of the Amazon Sagemaker model registry are as follows:</p>


<div class="custom-point-list">
<ul><li>You can create a model group to solve a specific ML problem. It allows you to view all of the model versions that are associated with a model group.&nbsp;</li><li>Using AWS Python SDK or Amazon Sagemaker Studio, you can view details of a specific version of a model.</li><li>You can also associate metadata, such as training metrics, with a model and version it as a whole.</li><li>You can approve or reject a model version within the model registry, if approved, the CI/CD deployment can be carried out easily from there.</li></ul>
</div>


<h3>4. <a href="https://www.comet.com/site/" target="_blank" rel="noreferrer noopener nofollow">Comet</a></h3>



<p>Developers can use the Comet platform to manage machine learning experiments. This system allows you to version, register, and deploy the model using its Python SDK Experiment.&nbsp;&nbsp;</p>



<p>Comet keeps track of model versions and the experiment history of the model. You can check the detailed information of all model versions. Besides, you can maintain ML workflow more efficiently using model reproduction and optimization.&nbsp;&nbsp;</p>


<div class="wp-block-image">
<figure class="aligncenter size-large is-resized"><a href="https://i0.wp.com/neptune.ai/wp-content/uploads/best-model-registry-tools-6.png?ssl=1"><img data-attachment-id="71100" data-permalink="https://neptune.ai/best-model-registry-tools-6" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/best-model-registry-tools-6.png?fit=1046%2C694&amp;ssl=1" data-orig-size="1046,694" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="best-model-registry-tools-6" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/best-model-registry-tools-6.png?fit=300%2C199&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/best-model-registry-tools-6.png?fit=1024%2C679&amp;ssl=1" decoding="async" src="https://i0.wp.com/neptune.ai/wp-content/uploads/best-model-registry-tools-6.png?resize=840%2C557&#038;ssl=1" alt="Comet dashboard" class="wp-image-71100" width="840" height="557" data-recalc-dims="1" /></a><figcaption><em>Comet dashboard | <a href="https://www.comet.com/site/" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>


<p>The feature-rich Comet has various functionalities for running and tracking ML model experiments, including:</p>


<div class="custom-point-list">
<ul><li>Comet allows you to easily check the history of evaluation/testing runs.</li><li>You can easily compare different experiments using the Comet model registry.&nbsp;</li><li>It allows you to access the code, dependencies, hyperparameters, and metrics within a single UI.&nbsp;</li><li>It has in-built reporting and visualization features to communicate with team members and stakeholders.</li><li>It lets you configure webhooks and integrate the Comet model registry with your CI/CD pipeline.</li></ul>
</div>


<div id="blog-cta-intext-block_790d9408235a8adbd6b9220d3bca5df4" class="blog-cta-intext">
  <h3 class="blog-cta-intext__title">May be useful </h3>
  <div class="blog-cta-intext__content"><p>Check detailed <a href="/vs/comet" target="_blank" rel="noopener">comparison between Neptune.ai and Comet</a>.</p>
</div>
  </div>


<h3>5. <a href="https://www.verta.ai/" target="_blank" rel="noreferrer noopener nofollow">Verta.ai</a></h3>



<p>You can use the Verta AI tool for the management and operations of the model in one unified space. It provides an interactive UI where you can register the ML models and publish the metadata, artefacts, and documents. Then, to manage the end-to-end experiment, you may connect the model to the experiment tracker. Version control solutions for ML projects are also offered by Verta AI.</p>



<p>Additionally, it enables you to keep track of changes made to data, code, environments, and model configuration. With the audit log&#8217;s accessibility, you may also examine the model&#8217;s dependability and compatibility at any time. You can also create a unique approval sequence that is appropriate for your project and incorporate it with the selected ticketing system.</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><a href="https://i0.wp.com/neptune.ai/wp-content/uploads/best-model-registry-tools-7.png?ssl=1"><img data-attachment-id="71101" data-permalink="https://neptune.ai/best-model-registry-tools-7" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/best-model-registry-tools-7.png?fit=1778%2C1068&amp;ssl=1" data-orig-size="1778,1068" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="best-model-registry-tools-7" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/best-model-registry-tools-7.png?fit=300%2C180&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/best-model-registry-tools-7.png?fit=1024%2C615&amp;ssl=1" decoding="async" width="1024" height="615" src="https://i0.wp.com/neptune.ai/wp-content/uploads/best-model-registry-tools-7.png?resize=1024%2C615&#038;ssl=1" alt="Verta AI dashboard" class="wp-image-71101" data-recalc-dims="1"/></a><figcaption><em>Verta AI dashboard | <a href="https://blog.verta.ai/introducing-verta-model-registry">Source</a></em></figcaption></figure></div>


<p>Some of the main features of Verta AI’s model registry are:</p>


<div class="custom-point-list">
<ul><li>It enables end-to-end information tracking such as Model ID, description, tags, documentation, model versions, release stage, artifacts, model metadata, and more, which helps in selecting the best model.&nbsp;</li><li>It works on container tools like Kubernetes and <a href="https://www.docker.com/" target="_blank" rel="noreferrer noopener nofollow">Docker </a>and is integrable with <a href="https://www.gitops.tech/" target="_blank" rel="noreferrer noopener nofollow">GitOps </a>and <a href="https://www.jenkins.io/" target="_blank" rel="noreferrer noopener nofollow">Jenkins</a>, which helps in automatically tracking model versions.</li><li>It provides access to detailed audit logs for compliance.&nbsp;</li><li>It has an environment like Git that makes it intuitive.</li><li>You can set up granular access control for<strong> </strong>editors, reviewers, and collaborators.</li></ul>
</div>


<h2>Summary</h2>



<p>After reading this article, I hope you now know what model registry tools are and the different criteria that one must look for while selecting a model registry tool. To offer a practical perspective, we also discussed some of the popular model registry tools and compared them with each other in several aspects. Now, let&#8217;s wrap the article with a few key takeaways:</p>


<div class="custom-point-list">
<ul><li>Model registry performs model versioning and publishes them into production.</li><li>Before selecting a model registry tool, you must evaluate each model according to your requirement.</li><li>Model registry evaluation criteria can range from the capability to monitor and manage the different ML model stages and versions to its ease of use and pricing.</li><li>You may refer to the highlighted features of different model registry tools to get a better idea of that tool’s compatibility with your use case.</li></ul>
</div>


<p>With these points in mind, I hope your model registry tool search will be much easier.</p>



<h3>References</h3>


<div class="custom-point-list">
<ol><li><a href="https://www.phdata.io/blog/what-is-a-model-registry/" target="_blank" rel="noreferrer noopener nofollow">https://www.phdata.io/blog/what-is-a-model-registry/</a></li><li><a href="https://neptune.ai/blog/best-alternatives-to-mlflow-model-registry" target="_blank" rel="noreferrer noopener">https://neptune.ai/blog/best-alternatives-to-mlflow-model-registry</a></li><li><a href="https://www.datarevenue.com/en-blog/why-is-a-model-registry-valuable" target="_blank" rel="noreferrer noopener nofollow">https://www.datarevenue.com/en-blog/why-is-a-model-registry-valuable</a></li></ol>
</div>



<div id="author-box-new-format-block_62d007aebea48" class="article__footer article__author">
  <div class="article__authorImage">
          <img width="230" height="230" src="https://i0.wp.com/neptune.ai/wp-content/uploads/Gourav-Bais.jpeg?fit=230%2C230&amp;ssl=1" class="article__authorImage-img" alt="Gourav Bais" decoding="async" data-attachment-id="69158" data-permalink="https://neptune.ai/gourav-bais" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Gourav-Bais.jpeg?fit=800%2C800&amp;ssl=1" data-orig-size="800,800" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Gourav Bais" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Gourav-Bais.jpeg?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Gourav-Bais.jpeg?fit=800%2C800&amp;ssl=1" />      </div>

  <div class="article__authorContent">
          <h3 class="article__authorContent-name">Gourav Bais</h3>
    
          <p class="article__authorContent-text">Applied ML Engineer skilled in Computer Vision/Deep Learning Pipeline Development, creating machine learning models, retraining systems and transforming data science prototypes to production-grade solutions. Consistently optimises and improves real-time systems by evaluating strategies and testing on real world scenarios.</p>
    
          <ul class="article__authorSocial">
        <li class="article__authorSocial-single article__authorSocial-name">Follow me on</li>
        
                  <li class="article__authorSocial-single"><a href="linkedin.com/in/gourav-singh-bais" class="article__authorSocial-lk" target="_blank"></a></li>
        
              </ul>
    
  </div>
</div>


<div class="is-layout-flow wp-block-group"><div class="wp-block-group__inner-container">
<hr class="wp-block-separator"/>



<p class="has-text-color" style="color:#4455a6"><strong>READ NEXT</strong></p>



<h2>Continuum Industries Case Study: How to Track, Monitor &amp; Visualize CI/CD Pipelines </h2>



<p class="has-small-font-size"> 7 mins read | Updated August 9th, 2021 </p>


<div id="block_5ffc75def9f8e" class="separator separator-10"></div>



<p><a href="https://www.continuum.industries/" target="_blank" rel="noreferrer noopener nofollow">Continuum Industries</a> is a company in the infrastructure industry that wants to automate and optimize the design of linear infrastructure assets like water pipelines, overhead transmission lines, subsea power lines, or telecommunication cables.&nbsp;&nbsp;</p>



<p>Its core product Optioneer lets customers input the engineering design assumptions and the geospatial data and <strong>uses evolutionary optimization algorithms to find possible solutions to connect point A to B given the constraints.&nbsp;</strong></p>


<div id="block_610943f455774" class="separator separator-15"></div>



<figure class="wp-block-video"><video controls src="https://neptune.ai/wp-content/uploads/Continuum-Industries-video.mp4"></video></figure>


<div id="block_617106e0168b3" class="separator separator-15"></div>



<p>As Chief Scientist Andreas Malekos, who works on the Optioneer AI-powered engine, explains:</p>


<div class="case-study-quote">
    <p>“Building something like a power line is a huge project, so you have to get the design right before you start. The more reasonable designs you see, the better decision you can make. Optioneer can get you design assets in minutes at a fraction of the cost of traditional design methods.”</p>
    <div class="meta">
        <div class="thumb">
            <img width="150" height="150" src="https://i0.wp.com/neptune.ai/wp-content/uploads/Andreas-Malekos.jpeg?resize=150%2C150&amp;ssl=1" class="attachment-thumbnail size-thumbnail" alt="Andreas Malekos" decoding="async" data-attachment-id="49927" data-permalink="https://neptune.ai/customers/continuum-industries/attachment/andreas-malekos" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Andreas-Malekos.jpeg?fit=427%2C427&amp;ssl=1" data-orig-size="427,427" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;X-T10&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1538408840&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;35&quot;,&quot;iso&quot;:&quot;320&quot;,&quot;shutter_speed&quot;:&quot;0.008&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Andreas Malekos" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Andreas-Malekos.jpeg?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Andreas-Malekos.jpeg?fit=427%2C427&amp;ssl=1" />        </div>
        <div class="content">
            <p class="name">Andreas Malekos</p>
            <p class="company">Chief Scientist @Continuum Industries</p>
        </div>
    </div>

</div>



<p>But creating and operating the Optioneer engine is more challenging than it seems:</p>


<div class="custom-point-list">
<ul><li>The objective function does not represent reality</li><li>There are a lot of assumptions that civil engineers don’t know in advance</li><li>Different customers feed it completely different problems, and the algorithm needs to be robust enough to handle those</li></ul>
</div>


<p>Instead of building the perfect solution, it’s better to present them with a list of interesting design options so that they can make informed decisions.</p>



<p>The engine team leverages a diverse skillset from mechanical engineering, electrical engineering, computational physics, applied mathematics, and software engineering to pull this off.</p>



<h2>Problem</h2>



<p>A side effect of building a successful software product, whether it uses AI or not, is that people rely on it working. And when people rely on your optimization engine with million-dollar infrastructure design decisions, you need to have a robust quality assurance (QA) in place.</p>



<p>As Andreas pointed out, they have to be able to say that the solutions they return to the users are:</p>


<div class="custom-point-list">
<ul><li><strong>Good</strong>, meaning that it is a result that a civil engineer can look at and agree with</li><li><strong>Correct</strong>, meaning that all the different engineering quantities that are calculated and returned to the end-user are as accurate as possible</li></ul>
</div>


<p>On top of that, the team is constantly working on improving the optimization engine. But to do that, you have to make sure that the changes:</p>


<div class="custom-point-list">
<ul><li>Don’t break the algorithm in some way or another</li><li>They actually improve the results not just on one infrastructure problem but across the board</li></ul>
</div>


<p>Basically, you need to <strong>set up a proper validation and testing,</strong> but the nature of the problem the team is trying to solve presents additional challenges:</p>


<div class="custom-point-list">
<ul><li>You cannot automatically tell whether an algorithm output is correct or not. <strong>It is not like in ML where you have labeled data</strong> to compute accuracy or recall on your evaluation set.&nbsp;</li><li>You <strong>need a set of example problems that is representative</strong> of the kind of problem that the algorithm will be asked to solve in production. Furthermore, these problems need to be versioned so that repeatability is as easily achievable as possible.</li></ul>
</div>

<a class="button continous-post blue-filled" href="/blog/mlops" target="_blank">
    Continue reading -&gt;</a>



<hr class="wp-block-separator"/>
</div></div>
<p>The post <a rel="nofollow" href="https://neptune.ai/blog/ml-model-registry-best-tools">Best ML Model Registry Tools</a> appeared first on <a rel="nofollow" href="https://neptune.ai">neptune.ai</a>.</p>
]]></content:encoded>
					
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">71093</post-id>	</item>
		<item>
		<title>Building ML Pipeline: 6 Problems &#038; Solutions [From a Data Scientist&#8217;s Experience]</title>
		<link>https://neptune.ai/blog/building-ml-pipeline-problems-solutions</link>
		
		<dc:creator><![CDATA[Thomas Epelbaum]]></dc:creator>
		<pubDate>Fri, 02 Sep 2022 20:00:55 +0000</pubDate>
				<category><![CDATA[MLOps]]></category>
		<category><![CDATA[mlops]]></category>
		<guid isPermaLink="false">https://neptune.ai/?p=65705</guid>

					<description><![CDATA[<p>Long gone is the time where ML jobs start and end with a jupyter notebook.&#160;&#160; Since all companies want to deploy their models into production, having an efficient and rigorous MLOps pipeline to do so is a real challenge that ML engineers have to face nowadays.&#160; But creating such a pipeline is not an easy [&#8230;]</p>
<p>The post <a rel="nofollow" href="https://neptune.ai/blog/building-ml-pipeline-problems-solutions">Building ML Pipeline: 6 Problems &#038; Solutions [From a Data Scientist&#8217;s Experience]</a> appeared first on <a rel="nofollow" href="https://neptune.ai">neptune.ai</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<p>Long gone is the time where ML jobs start and end with a jupyter notebook.&nbsp;&nbsp;</p>



<p>Since all companies want to deploy their models into production, having an efficient and rigorous MLOps pipeline to do so is a real challenge that ML engineers have to face nowadays.&nbsp;</p>



<p>But creating such a pipeline is not an easy task, given how new the MLOps tools are. Indeed, the field itself is no more than a couple of years old for the vast majority of medium-sized companies. Thus creating such a pipeline can only be accomplished through trial and error, and the mastering of numerous tools/libraries is needed.</p>



<p>In this article, I will introduce you to</p>


<div class="custom-point-list">
<ul><li>common pitfalls I have seen in the previous companies I have been working at,&nbsp;</li><li>and how I managed to solve them.</li></ul>
</div>


<p>This is by no means the end of the story, though, and I am sure that the MLOps field will be at a way more mature level two years from now. But by showing you the challenges I faced, I hope you will learn something in the process. I sure did!</p>



<p>So here we go!</p>



<p><strong>A short note on the author</strong></p>



<p>Before proceeding, it may be enlightening for you to have a little background on me.</p>



<p>I am a French engineer who did a master&#8217;s and a Ph.D. in particle physics before leaving the research ecosystem to join the industry one, as I wanted to have a more direct impact on society. At the time (2015), I only developed codes for myself and maybe 1-2 co-authors, and you can therefore guess my production-compatible coding abilities (in case you did not: there were none :)).&nbsp;</p>



<p>But since then, I have contributed to different codebases in different languages (C# and Python mostly), and even if I am not a developer by formation, I have seen more than once what works and what does not :).</p>



<p>In order to not destroy all of my credibility before even starting the journey, let me hasten to add that I do have a non-zero knowledge of deep learning (this <a href="https://arxiv.org/abs/1709.01412" target="_blank" rel="noreferrer noopener nofollow">white book</a> made available to the community on <a href="https://github.com/tomepel/Technical_Book_DL" target="_blank" rel="noreferrer noopener nofollow">github</a> in 2017 can hopefully attest to this fact :)).</p>



<h2>Building MLOps pipelines: the most common problems I encountered</h2>



<p>Here are the 6 most common pitfalls I have encountered during my ML activity in the past 6 years.</p>


<div id="block_63123477d1bd2" class="separator separator-10"></div>


<div class="wp-block-image">
<figure class="aligncenter size-large"><a href="https://i0.wp.com/neptune.ai/wp-content/uploads/Building-mlops-pipeline-problems.jpg?ssl=1"><img data-attachment-id="71149" data-permalink="https://neptune.ai/building-mlops-pipeline-lessons-learned/attachment/building-mlops-pipeline-problems" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Building-mlops-pipeline-problems.jpg?fit=1024%2C1331&amp;ssl=1" data-orig-size="1024,1331" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Building-mlops-pipeline-problems" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Building-mlops-pipeline-problems.jpg?fit=231%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Building-mlops-pipeline-problems.jpg?fit=788%2C1024&amp;ssl=1" decoding="async" width="788" height="1024" src="https://i0.wp.com/neptune.ai/wp-content/uploads/Building-mlops-pipeline-problems.jpg?resize=788%2C1024&#038;ssl=1" alt="" class="wp-image-71149" data-recalc-dims="1"/></a></figure></div>


<p>I’ll dig into each of one them throughout the article, first presenting the problem and then offering a possible solution.&nbsp;</p>



<h3>Problem 1:&nbsp;POC &#8211; style code</h3>



<p>More often than not, I encountered code bases developed in a Proof Of Concept (POC) style.</p>



<p>For instance, to release a model into production,&nbsp; one may have to chain 5 to 10 <a href="https://github.com/pallets/click" target="_blank" rel="noreferrer noopener nofollow">click</a> commands (or even worse, argparse!)&nbsp; in order to be able to:</p>


<div class="custom-point-list">
<ul><li>preprocess data</li><li>featurize data</li><li>train an ML model</li><li>export the ML model into production</li><li>produce a CSV report on the model performance</li></ul>
</div>


<p>In addition, it is very common to need to edit the code between two commands for the full process to work.&nbsp;</p>



<p>This is normal in startups, they want to build innovative products, and they want to build them fast. But in my experience, leaving a code base at the POC level is a long-term recipe for disaster.&nbsp;</p>



<p>Indeed, adding new features in this manner becomes more and more costly as maintenance costs become higher and higher. Another factor worth considering is that in companies with even regular turnover, each leave with this kind of code base has a real impact on the structure speed.</p>



<h3>Problem 2: No high-level separation of concerns</h3>



<p>The separation of concerns in ML code bases is often missing at a high level. What this means is that more often than not, so-called ML code is also doing feature transformations like operations that have nothing to do with ML – think physical document ingestion, conversion of administrative data, etc.</p>



<p>In addition, the dependencies between these modules are often not well thought out. Look at fantasy diagram created by a small wrapper coded by me (I aim to release it on PyPI one day :)) and based on the excellent <a href="https://github.com/thebjorn/pydeps" target="_blank" rel="noreferrer noopener nofollow">pydeps</a> that gives a code base dependencies at the regroupment of module levels (this is closer to real life situations that you might think :):</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><a href="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-dependencies.png?ssl=1"><img data-attachment-id="65722" data-permalink="https://neptune.ai/attachment/mlops-pipeline-dependencies" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-dependencies.png?fit=1600%2C938&amp;ssl=1" data-orig-size="1600,938" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="MLOps-pipeline-dependencies" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-dependencies.png?fit=300%2C176&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-dependencies.png?fit=1024%2C600&amp;ssl=1" decoding="async" width="1024" height="600" src="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-dependencies.png?resize=1024%2C600&#038;ssl=1" alt="MLOps pipeline dependencies" class="wp-image-65722" data-recalc-dims="1"/></a></figure></div>


<p>To me, the most worrisome aspect of this diagram is the number of cyclic dependencies present between what seems to be low-level packages and high-level ones.</p>



<p>Another thing that I personally interpret as a not well-thought-out architecture is a large utils folder, and it is very common to see utils folders with dozen of modules in ML codebases.</p>



<h3>Problem 3: No low-level separation of concerns</h3>



<p>The separation of concerns in the code is unfortunately often missing at a low level as well. When this happens, you end up with 2000+ line classes handling almost everything: Featurization, preprocessing, building the model graph, training, predicting, exporting… You name it, those master classes have your bases covered (only coffee is missing, and sometimes you never know… :)). But as you know, this is not what the S of the <a href="https://en.wikipedia.org/wiki/SOLID" target="_blank" rel="noreferrer noopener nofollow">SOLID</a> would recommend.&nbsp;</p>



<h3>Problem 4: No configuration Data Model</h3>



<p>A data model for handling ML configuration is often missing. For instance, this is what a fantasy model hyperparameter declaration could look like (again, closer to real-life situations than you might think).&nbsp;</p>


<div class="wp-block-image">
<figure class="aligncenter size-full is-resized"><img data-attachment-id="65727" data-permalink="https://neptune.ai/attachment/mlops-pipeline-hyperparameters-2" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-hyperparameters-2.png?fit=375%2C87&amp;ssl=1" data-orig-size="375,87" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="MLOps-pipeline-hyperparameters-2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-hyperparameters-2.png?fit=300%2C70&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-hyperparameters-2.png?fit=375%2C87&amp;ssl=1" decoding="async" src="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-hyperparameters-2.png?resize=375%2C87&#038;ssl=1" alt="MLOps pipeline hyperparameters" class="wp-image-65727" width="375" height="87" data-recalc-dims="1" /><figcaption><em>350+ lines dictionaries :’(</em></figcaption></figure></div>


<p>Even more problematic (but comprehensible), this allowed for dynamic modification of the model configuration (fantasy snippet inspired from numerous real-life situations):</p>


<div class="wp-block-image">
<figure class="aligncenter size-full"><a href="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-model-configuration-1.png?ssl=1"><img data-attachment-id="69781" data-permalink="https://neptune.ai/attachment/mlops-pipeline-model-configuration-1" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-model-configuration-1.png?fit=342%2C311&amp;ssl=1" data-orig-size="342,311" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="MLOps-pipeline-model-configuration-1" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-model-configuration-1.png?fit=300%2C273&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-model-configuration-1.png?fit=342%2C311&amp;ssl=1" decoding="async" width="342" height="311" src="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-model-configuration-1.png?resize=342%2C311&#038;ssl=1" alt="MLOps pipeline model configuration" class="wp-image-69781" data-recalc-dims="1"/></a></figure></div>


<p>As one can see in the fantasy code snippet above, the `params` attribute is modified in place. When this happens at several places in the code (and trust me, it does when you start going down that road), you end up with a code that is a real nightmare to debug, as what you put into configurations is not necessarily what arrives in the subsequent ML pipeline steps.</p>



<h3>Problem 5: Handling legacy models&nbsp;</h3>



<p>Since the process of training a ML model often involves manual efforts (see problem 1) it can take really long to do so. It is also prone to some errors (when a human is in the loop errors are also :)). In that case, you end up with (fantasy code snippet) stuff like this:</p>


<div class="wp-block-image">
<figure class="aligncenter size-full"><a href="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-legacy-models.png?ssl=1"><img data-attachment-id="65729" data-permalink="https://neptune.ai/attachment/mlops-pipeline-legacy-models" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-legacy-models.png?fit=749%2C181&amp;ssl=1" data-orig-size="749,181" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="MLOps-pipeline-legacy-models" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-legacy-models.png?fit=300%2C72&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-legacy-models.png?fit=749%2C181&amp;ssl=1" decoding="async" width="749" height="181" src="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-legacy-models.png?resize=749%2C181&#038;ssl=1" alt="MLOps pipeline legacy models" class="wp-image-65729" data-recalc-dims="1"/></a></figure></div>


<p><em>Hint: look at the docstring date <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f642.png" alt="🙂" class="wp-smiley" style="height: 1em; max-height: 1em;" /></em></p>



<h3>Problem 6: Code quality: type hinting, documentation, complexity, dead code&nbsp;</h3>



<p>As the above fantasy code snippets can attest, type hinting is rarely present when it is needed the most. I can guess that <em>n_model_to_keep</em> is an int, but would be hard-pressed naming the types of <em>graph_configuration</em> in the code snippet of problem 5 .&nbsp;</p>



<p>In addition, ML code bases I encountered often had a limited amount of docstring, and modern concepts for code quality like cyclomatic/cognitive complexity or working memory (see <a href="https://sourcery.ai/blog/working-memory/" target="_blank" rel="noreferrer noopener nofollow">this</a> post to learn more about it) are not respected.</p>


<div class="wp-block-image">
<figure class="aligncenter size-full"><a href="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-code-quality.png?ssl=1"><img data-attachment-id="65730" data-permalink="https://neptune.ai/attachment/mlops-pipeline-code-quality" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-code-quality.png?fit=945%2C234&amp;ssl=1" data-orig-size="945,234" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="MLOps-pipeline-code-quality" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-code-quality.png?fit=300%2C74&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-code-quality.png?fit=945%2C234&amp;ssl=1" decoding="async" width="945" height="234" src="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-code-quality.png?resize=945%2C234&#038;ssl=1" alt="MLOps pipeline code quality" class="wp-image-65730" data-recalc-dims="1"/></a><figcaption><em>Fantasy code snippet. even the </em><a href="https://github.com/marcoemrich/Refactoring-Katas/blob/master/GildedRose/python/gilded_rose.py" target="_blank" rel="noreferrer noopener nofollow"><em>famous python refactoring kata</em></a><em> is beaten!&nbsp;</em></figcaption></figure></div>


<p>Finally, unknown to all, a lot of dead code is often present in the solution. In this case, you might scratch your head during several days when adding a new feature before realizing that the code you do not manage to make it work with this new feature is not even called (again, true story)!</p>



<h2>Building MLOps pipelines: how I solved these problems</h2>



<p>Let&#8217;s now look at solutions I found (of course with the help of my collaborators along the years) to the 6 pressing problems discussed above and give you an overview of where I would be if I had to develop a new MLOPS pipeline now.</p>



<h3>Solution 1: from POC to prod</h3>



<p>Thanks to <a href="https://typer.tiangolo.com/" target="_blank" rel="noreferrer noopener nofollow">Typer</a>, a lot of click/argpase boilerplate code can be suppressed from command lines.&nbsp;</p>



<p>I am a big fan of a couple of mantras:</p>


<div class="custom-point-list">
<ol><li>The best code is the one you don’t need to write (<a href="https://www.folklore.org/StoryView.py?story=Negative_2000_Lines_Of_Code.txt" target="_blank" rel="noreferrer noopener nofollow">funny</a> folklore on this).&nbsp;</li><li>When an observation starts to be used as a metric (in this case, the number of lines written to attest all the work done), it stops being a good observation.&nbsp;</li></ol>
</div>


<p>Here is, in my opinion, a good high-level command signature to launch an end-to-end ML model training:&nbsp;</p>


<div class="wp-block-image">
<figure class="aligncenter size-full"><a href="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-hyperparameter-optimization.png?ssl=1"><img data-attachment-id="65731" data-permalink="https://neptune.ai/attachment/mlops-pipeline-hyperparameter-optimization" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-hyperparameter-optimization.png?fit=809%2C238&amp;ssl=1" data-orig-size="809,238" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="MLOps-pipeline-hyperparameter-optimization" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-hyperparameter-optimization.png?fit=300%2C88&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-hyperparameter-optimization.png?fit=809%2C238&amp;ssl=1" decoding="async" width="809" height="238" src="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-hyperparameter-optimization.png?resize=809%2C238&#038;ssl=1" alt="MLOps pipeline hyperparameter optimization" class="wp-image-65731" data-recalc-dims="1"/></a></figure></div>


<p>TL DR: use Typer for all your command line tools.</p>



<h3>Solution 2: Handling high-level separation of concerns – from ML monolith to ML microservices</h3>



<p>This is a big one that took me a long time to improve on. As I guess most of my readers are today, I am on the side of the microservice in the microservice/monolith battle (though I know that microservices are not a miracle that solve all development issues with a finger snap). With docker and docker-compose used to encompass the different services, you can improve on the functionalities of your architecture incrementally and in isolation with the rest of the already implemented features. Unfortunately, ML docker architecture often looks like this:</p>


<div class="wp-block-image">
<figure class="aligncenter size-full"><img data-attachment-id="65732" data-permalink="https://neptune.ai/attachment/mlops-pipeline-ml-container" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-ML-container.png?fit=164%2C77&amp;ssl=1" data-orig-size="164,77" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="MLOps-pipeline-ML-container" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-ML-container.png?fit=164%2C77&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-ML-container.png?fit=164%2C77&amp;ssl=1" decoding="async" width="164" height="77" src="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-ML-container.png?resize=164%2C77&#038;ssl=1" alt="MLOps pipeline ML container" class="wp-image-65732" data-recalc-dims="1"/><figcaption><em>A typical docker ML container architecture</em></figcaption></figure></div>


<p>Now I would advocate for something more like this (with the data processing parts also acknowledged):</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><a href="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-ML-container-2.png?ssl=1"><img data-attachment-id="65733" data-permalink="https://neptune.ai/attachment/mlops-pipeline-ml-container-2" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-ML-container-2.png?fit=1353%2C485&amp;ssl=1" data-orig-size="1353,485" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="MLOps-pipeline-ML-container-2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-ML-container-2.png?fit=300%2C108&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-ML-container-2.png?fit=1024%2C367&amp;ssl=1" decoding="async" width="1024" height="367" src="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-ML-container-2.png?resize=1024%2C367&#038;ssl=1" alt="MLOps pipeline ML container" class="wp-image-65733" data-recalc-dims="1"/></a></figure></div>


<p>The data ingestion and storing functionalities that are not ML related are now&nbsp; delegated to a dedicated feature-store container. It stores the data it ingests into a <a href="https://hub.docker.com/_/mongo" target="_blank" rel="noreferrer noopener nofollow">MongoDB</a> (I am used to work with non structured documents, but of course if you are also/only dealing with structured data use a <a href="https://hub.docker.com/_/postgres" target="_blank" rel="noreferrer noopener nofollow">Postgresql</a> container) container, after having processed the documents it is fed with via calls to a <a href="https://gotenberg.dev/" target="_blank" rel="noreferrer noopener nofollow">gotenberg</a> container (a very useful off the shelf container to handle documents).</p>



<p>The ML is here split into three parts:</p>


<div class="custom-point-list">
<ul><li><strong>A Computer Vision part: document-recognition container,</strong> applying computer vision techniques to documents Think the usual suspects: open-cv, Pillow… . I have experience doing the labeling with the help of a <a href="https://github.com/Slava/label-tool" target="_blank" rel="noreferrer noopener nofollow">label-tool</a> container, but there are a lot of alternatives out there.</li><li><strong>An NLP part: NLP</strong>, with a container applying NLP techniques to the texts extracted from the documents. Think the usual suspects: nltk, Spacy,&nbsp; DL/BERT… I have experience doing the labeling with the help of a <a href="https://github.com/doccano/doccano" target="_blank" rel="noreferrer noopener nofollow">doccano</a> container, and in my opinion there are no better alternatives out there :).</li><li><strong>A core DL part: a&nbsp; pytorch_dl container</strong>. I migrated from TensorFlow to PyTorch in all my DL activities, as interacting with TensorFlow was a source of frustration for me. Some of the problems I faced:<ul><li>It was slow and prone to error in my developments,&nbsp;</li><li>Lack of support on the official github (some issues have been sitting there for years!),&nbsp;</li><li>Difficulty to debug (even if the eager mode of tensorflow2 has mitigated this point to some extent).&nbsp;</li></ul></li></ul>
</div>


<p>You must have heard that codebases and functionalities should only be changed incrementally. In my experience, this is true and good advice 95% percent of the time. But 5% of the time things are so entangled and the danger of silently breaking by doing incremental changes is so high (low test coverage, I am looking at you) that I recommend rewriting everything from scratch in a new package, ensuring that the new package has the same features as the old one and thereafter, unplugging the faulty code in one stroke to plug in the new one.&nbsp;&nbsp;</p>



<p>I have handled TensorFlow to PyTorch migrations in my previous experiences as one of these occasions.</p>



<p>To implement PyTorch networks, I recommend using <a href="https://www.pytorchlightning.ai/" target="_blank" rel="noreferrer noopener nofollow">Pytorch Lightning</a> which is a very concise and easy-to-use high-level library around PyTorch. To gauge the difference, the lines of code in my old TensorFlow codebases are in the order of thousands, whereas with Pytorch Lightning you can accomplish more with ten times less code. I usually handle in these different modules the DL concepts:</p>



<p>&nbsp;</p>


<div class="wp-block-image">
<figure class="aligncenter size-full"><img data-attachment-id="65734" data-permalink="https://neptune.ai/attachment/mlops-pipeline-pytorch-lightning" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-Pytorch-lightning.png?fit=142%2C157&amp;ssl=1" data-orig-size="142,157" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="MLOps-pipeline-Pytorch-lightning" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-Pytorch-lightning.png?fit=142%2C157&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-Pytorch-lightning.png?fit=142%2C157&amp;ssl=1" decoding="async" width="142" height="157" src="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-Pytorch-lightning.png?resize=142%2C157&#038;ssl=1" alt="MLOps pipeline Pytorch lightning" class="wp-image-65734" data-recalc-dims="1"/><figcaption><em>The PyTorch-dependent code</em></figcaption></figure></div>


<p>Thanks to PyTorch Lightning, each module is less than 50 lines long (except for network :)).&nbsp;</p>


<div class="wp-block-image">
<figure class="aligncenter size-full"><a href="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-Pytorch-lightning-2.png?ssl=1"><img data-attachment-id="65735" data-permalink="https://neptune.ai/attachment/mlops-pipeline-pytorch-lightning-2" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-Pytorch-lightning-2.png?fit=823%2C645&amp;ssl=1" data-orig-size="823,645" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="MLOps-pipeline-Pytorch-lightning-2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-Pytorch-lightning-2.png?fit=300%2C235&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-Pytorch-lightning-2.png?fit=823%2C645&amp;ssl=1" decoding="async" width="823" height="645" src="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-Pytorch-lightning-2.png?resize=823%2C645&#038;ssl=1" alt="MLOps pipeline Pytorch lightning" class="wp-image-65735" data-recalc-dims="1"/></a></figure></div>


<p>The Trainer is a marvel, and you can use the experiment logger of your choice in a finger snap. I started my journey with the good old TensorBoard logger, coming from the TensorFlow ecosystem. But as you can see on the above screen, I recently started to use one of its alternatives: yes, you guessed it, <a href="/" target="_blank" rel="noreferrer noopener">neptune.ai</a>, and I am loving it so far. With <a href="https://docs.neptune.ai/getting-started/how-to-add-neptune-to-your-code" target="_blank" rel="noreferrer noopener">as little code as the one you see in the code snippet above,</a> you end up with all your models stored in a very user-friendly manner on the Neptune dashboard.</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><a href="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-neptune-dashboard.png?ssl=1"><img data-attachment-id="65738" data-permalink="https://neptune.ai/attachment/mlops-pipeline-neptune-dashboard" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-neptune-dashboard.png?fit=1316%2C838&amp;ssl=1" data-orig-size="1316,838" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="MLOps-pipeline-neptune-dashboard" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-neptune-dashboard.png?fit=300%2C191&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-neptune-dashboard.png?fit=1024%2C652&amp;ssl=1" decoding="async" width="1024" height="652" src="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-neptune-dashboard.png?resize=1024%2C652&#038;ssl=1" alt="MLOps pipeline neptune dashboard" class="wp-image-65738" data-recalc-dims="1"/></a><figcaption><em>Metrics and losses tracked in the Neptune UI</em></figcaption></figure></div>


<p>For hyperparameter optimization, I switched from <a href="http://hyperopt.github.io/hyperopt/" target="_blank" rel="noreferrer noopener nofollow">Hyperopt</a> to <a href="https://optuna.org/" target="_blank" rel="noreferrer noopener nofollow">Optuna</a> over the years, following this in-depth <a href="/blog/optuna-vs-hyperopt">blog post</a>. Reasons for this switch were numerous. Among others:</p>


<div class="custom-point-list">
<ul><li>Poor Hyperopt documentation</li><li>Ease of integration with PyTorch Lightning for optuna</li><li>Visualization of the hyperparameter search</li></ul>
</div>


<p>Tips that will save you a LOT of time: to allow graceful model restart after the pytorch_dl container crashes for whatever reason (server reboot, server low on resources, etc.), I replay the whole <a href="https://optuna.readthedocs.io/en/stable/reference/generated/optuna.samplers.TPESampler.html" target="_blank" rel="noreferrer noopener nofollow">TPEsamplings</a> of the finished runs with the same random seed, and start the unfinished trial from the last saved checkpoint. This allows me not to waste hours on an unfinished run each time something unexpected happens on a server.&nbsp;</p>



<p>For my R&amp;D experiments I use <a href="https://doc.ubuntu-fr.org/screen" target="_blank" rel="noreferrer noopener nofollow">screen</a> and more and more <a href="https://doc.ubuntu-fr.org/tmux" target="_blank" rel="noreferrer noopener nofollow">tmux</a> (a <a href="https://books.google.fr/books/about/Tmux_2.html?id=ugsMvgAACAAJ&amp;redir_esc=y" target="_blank" rel="noreferrer noopener nofollow">good ref</a> on tmux) scripts to launch hyperparameter optimization runs.&nbsp;</p>



<p>Hyperparameter comparison is very easy thanks to<a href="https://plotly.com/python/parallel-coordinates-plot/" target="_blank" rel="noreferrer noopener nofollow"> plotly parallel coordinate</a> plot.</p>



<p>Finally, I use a custom reporter container to compile a tex template into a beamer pdf. Think jinja2 like <a href="https://en.wikipedia.org/wiki/LaTeX" target="_blank" rel="noreferrer noopener nofollow">tex</a> template that you fill with PNGs and CSVs specific to each run to produce a PDF that is the perfect conversation starter with the businesses/clients when they come to understand Machine Learning Model performance (main confusions, label repartition, performance, etc.).</p>



<p>These architecture patterns drastically simplify coding new functionalities. If you are familiar with <a href="https://en.wikipedia.org/wiki/Accelerate_(book)" target="_blank" rel="noreferrer noopener nofollow">Accelerate</a>, then you know it is no lie that having a good codebase can reduce the time taken to implement a new feature by a factor of 10 to 50, and I can attest to it :).</p>



<p>Should you need to add a message broker to your microservice architecture, I can recommend <a href="https://www.rabbitmq.com/" target="_blank" rel="noreferrer noopener nofollow">rabbit MQ</a> as it is a breeze to plug within a python code thanks to the pika library. But here I have nothing to say on the alternatives (except readings: <a href="https://www-inf.telecom-sudparis.eu/COURS/CILS-IAAIO/Articles/debs_kafka_versus_rabbitmq.pdf" target="_blank" rel="noreferrer noopener nofollow">kafka</a>, redis…) as I have never worked with them so far :).</p>



<h3>Solution 3: Handling low-level separation of concerns – good code architecture</h3>



<p>Having a clear separation of concerns between containers allows to have a very clean container-level architecture. Look at this fantasy (but the one I advocate! :)) dependency graph for a pytorch_dl container:</p>


<div class="wp-block-image">
<figure class="aligncenter size-full"><a href="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-dependencies-2.png?ssl=1"><img data-attachment-id="65746" data-permalink="https://neptune.ai/attachment/mlops-pipeline-dependencies-2" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-dependencies-2.png?fit=702%2C477&amp;ssl=1" data-orig-size="702,477" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="MLOps-pipeline-dependencies-2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-dependencies-2.png?fit=300%2C204&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-dependencies-2.png?fit=702%2C477&amp;ssl=1" decoding="async" width="702" height="477" src="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-dependencies-2.png?resize=702%2C477&#038;ssl=1" alt="MLOps pipeline dependencies" class="wp-image-65746" data-recalc-dims="1"/></a></figure></div>


<p>and the chronology of the different module actions:</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><a href="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-chronology-of-actions.png?ssl=1"><img data-attachment-id="65747" data-permalink="https://neptune.ai/attachment/mlops-pipeline-chronology-of-actions" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-chronology-of-actions.png?fit=1438%2C320&amp;ssl=1" data-orig-size="1438,320" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="MLOps-pipeline-chronology-of-actions" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-chronology-of-actions.png?fit=300%2C67&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-chronology-of-actions.png?fit=1024%2C228&amp;ssl=1" decoding="async" width="1024" height="228" src="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-chronology-of-actions.png?resize=1024%2C228&#038;ssl=1" alt="MLOps pipeline chronology of actions" class="wp-image-65747" data-recalc-dims="1"/></a></figure></div>


<p>High level view of the different regroupment of modules I advocate for:</p>


<div class="custom-point-list">
<ul><li>Adapters transform a raw CSV to a CSV dedicated to a particular prediction task.</li><li>Filterers remove rows of the passed CSV if they fail to pass given filtering criteria (too rare label, etc). For both filterers and adapters, I often have generic classes implementing all the adapting and filtering logic and inheriting classes overriding the specific adapting/filtering logic of each given filter/adapter (<a href="https://www.youtube.com/watch?v=xvb5hGLoK0A" target="_blank" rel="noreferrer noopener nofollow">Resource on ABC/protocols)</a>.</li><li>Featurizers are always based on sklearn and essentially convert a CSV into a dictionary of feature names (string) to NumPy arrays. Here I wrap the usual suspects (<a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html" target="_blank" rel="noreferrer noopener nofollow">TfidfVectorizer</a>, <a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html" target="_blank" rel="noreferrer noopener nofollow">StandardScaler</a>) into my own classes, essentially because (for a reason unknown to me), sklearn does not offer memoization for its featurizers. I do not want to use <a href="https://pypi.org/project/pickle5/" target="_blank" rel="noreferrer noopener nofollow">pickle</a> as it is not a <a href="https://medium.com/ochrona/python-pickle-is-notoriously-insecure-d6651f1974c9" target="_blank" rel="noreferrer noopener nofollow">security-compliant</a> library and does not offer any protection against <a href="https://github.com/scikit-learn/scikit-learn/issues/16033#issuecomment-571656393" target="_blank" rel="noreferrer noopener nofollow">sklearn version changes</a>. I thus always use a homemade improvement on <a href="https://thiagomarzagao.com/2015/12/08/saving-TfidfVectorizer-without-pickles/" target="_blank" rel="noreferrer noopener nofollow">t</a>his.</li><li>PyTorch contains the Dataset, Dataloader, and Trainer logic.</li><li>Model reports produce the pdf beamer reports already talked about above</li><li>Taggers regroup deterministic techniques to predict (think expert rules) on rare data, for instance. In my experience, the performance of&nbsp; DL models can be improved with human knowledge, and you should always consider the possibility of doing so if feasible.</li><li>MLConfiguration contains the ML data model: enums and classes that do not contain any processing methods. Think Hyperparameter class, PredictionType Enum, etc. Side note: use Enums over strings at all places where it makes sense (closed list of things)&nbsp;</li><li>The pipeline plugs together all the elementary bricks.</li><li>Routes contain the <a href="https://fastapi.tiangolo.com/" target="_blank" rel="noreferrer noopener nofollow">FastAPI</a> routes that allow other containers to ask for predictions on new data. Indeed I left <a href="https://flask.palletsprojects.com/en/2.1.x/" target="_blank" rel="noreferrer noopener nofollow">Flask</a> aside for the same reasons that I left-click aside for Typer – less boilerplate, ease of use and maintainability, and even more functionalities. <a href="https://github.com/tiangolo">Tiangolo</a> is a god :).&nbsp; I glanced at <a href="https://pytorch.org/serve/" target="_blank" rel="noreferrer noopener nofollow">TorchS</a>erve to serve models, but given the project sizes I have been working on in my career, I did not yet feel necessary to commit to it. Plus TorchServe is (as of July 2022) still in its infancy.&nbsp;</li></ul>
</div>


<p>I now always enforce regroupment of modules dependencies of my different codebases with a custom <a href="https://pre-commit.com/" target="_blank" rel="noreferrer noopener nofollow">pre-commit</a> hook. This means that each time someone tries to add new code that adds a new depency, a discussion is triggered between collaborators to evaluate the relevance of this new dependency. For instance, I see no reason as of today to create a dependency on model reports from pytorch given the architecture I presented. And would always vote against ml_configuration depending on anything.</p>



<h3>Solution 4: Simple configuration Data Model thanks to Pydantic</h3>



<p>To avoid config in code as an untyped giant dictionary, I enforce the use of <a href="https://pydantic-docs.helpmanual.io/" target="_blank" rel="noreferrer noopener nofollow">Pydantic</a> for all configuration/Data model classes. I even got inspiration from the best Disney movies <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f642.png" alt="🙂" class="wp-smiley" style="height: 1em; max-height: 1em;" /> (see code snippet)</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><a href="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-configuration.png?ssl=1"><img data-attachment-id="65754" data-permalink="https://neptune.ai/attachment/mlops-pipeline-configuration" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-configuration.png?fit=1197%2C592&amp;ssl=1" data-orig-size="1197,592" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="MLOps-pipeline-configuration" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-configuration.png?fit=300%2C148&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-configuration.png?fit=1024%2C506&amp;ssl=1" decoding="async" width="1024" height="506" src="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-pipeline-configuration.png?resize=1024%2C506&#038;ssl=1" alt="MLOps pipeline configuration" class="wp-image-65754" data-recalc-dims="1"/></a></figure></div>


<p>This enforces a configuration defined in one and only one place, hopefully in a JSON file outside the code, and thanks to Pydantic one-liners to serialize and deserialize the configuration. I kept an eye on <a href="https://hydra.cc/docs/intro/" target="_blank" rel="noreferrer noopener nofollow">Hydra</a>, but as explained <a href="https://www.youtube.com/watch?v=tEsPyYnzt8s&amp;t=1s" target="_blank" rel="noreferrer noopener nofollow">here</a> (very good channel) for instance, the framework may be too young and will presumably be more mature and more natural in a few months/years.&nbsp;</p>



<p>In order to update the frozen configuration with the optuna trial, I usually just define a dictionary of mute actions (a mute action value for each hyperparameter key present in the optuna trial).</p>



<h3>Solution 5: Handling legacy models with frequent automatic retrains</h3>



<p>Since the entry point to train a model is a unique Typer command (if you followed solutions 1 to 4 :)), it is easy to <a href="https://doc.ubuntu-fr.org/cron" target="_blank" rel="noreferrer noopener nofollow">cron</a> it periodically and automatically re-train models. Thanks to the reports and the metrics it contains, you then have two levels to decide whether to put the new model in production or not.</p>


<div class="custom-point-list">
<ul><li><strong>Automatic, high-level:</strong> if the macro performance of the new model is better than the old one, put the new model in production.</li><li><strong>Manual, fine-grained:</strong> an expert can compare the two models in detail and conclude that even if a certain model is somewhat worse than another in terms of overall performance, it could be better if its predictions make more sense when it&#8217;s wrong. For instance&nbsp; (here comes a completely fake vision example to clearly illustrate the point on ImageNet), the second conflates tigers with lions when it’s wrong whereas the first model predicts bees.</li></ul>
</div>


<p>What do I mean by exporting a model into production? In the framework depicted above, it is essentially just copying a model folder from one location to another. Then one of the high-level configuration classes can load all of this in one, in order to do new predictions via FastApi and (in fine) PyTorch. From my experience, PyTorch eases this procedure. With TensorFlow, I had to manually tweak the model checkpoints when I moved models from one folder to another.</p>



<h3>Solution 6: Improving code quality, a constant battle with a little help from my tools</h3>



<p>On code quality and affiliated, I have several battle horses:</p>


<div class="custom-point-list">
<ul><li>As already mentioned, all the data model classes I implement are based on <a href="https://pydantic-docs.helpmanual.io/" target="_blank" rel="noreferrer noopener nofollow">Pydantic</a> (another python god: <a href="https://github.com/samuelcolvin" target="_blank" rel="noreferrer noopener nofollow">Samuel Covin</a>).&nbsp;</li><li>I docstring every method (but try to ban comments inside methods, which are, in my opinion, the sign of an urgent need to apply the good old extract method <a href="https://martinfowler.com/books/refactoring.html" target="_blank" rel="noreferrer noopener nofollow">refactoring</a> pattern :)). The<a href="https://google.github.io/styleguide/pyguide.html" target="_blank" rel="noreferrer noopener nofollow"> Google style guide</a> is a must-read (even if you do not adhere to all its aspects, know why you do not :)).</li><li>I use <a href="https://sourcery.ai/" target="_blank" rel="noreferrer noopener nofollow">sourcery</a> to automatically hunt down bad designs and apply suggested refactoring patterns (you can find the current list <a href="https://docs.sourcery.ai/refactorings/" target="_blank" rel="noreferrer noopener nofollow">here</a>, and they add new ones on a regular basis). This tool is such a time saver – bad code does not survive long and your colleagues do not have to read it nor point it out during a painful code review. In fact the only extensions that I advocate every one to use on pycharm are sourcery and <a href="https://www.tabnine.com/" target="_blank" rel="noreferrer noopener nofollow">tabnine</a></li><li>Among other pre-commit hooks (remember the homemade one on the high-level dependencies I already talked about) I use <a href="https://github.com/pre-commit/mirrors-autopep8" target="_blank" rel="noreferrer noopener nofollow">autopep8</a>, <a href="https://github.com/pre-commit/pre-commit-hooks" target="_blank" rel="noreferrer noopener nofollow">flake</a>, and <a href="https://github.com/pre-commit/mirrors-mypy" target="_blank" rel="noreferrer noopener nofollow">mypy</a>.</li><li>I&nbsp; use <a href="https://pypi.org/project/pylint/" target="_blank" rel="noreferrer noopener nofollow">pylint</a> to lint my code bases and aim for a 9-9.5 target. This is completely arbitrary, but as Richard Thaler said – “I’m sure there’s an evolutionary explanation for this, if you give them [men] a target, they will aim.”</li><li>I use <a href="https://docs.python.org/3/library/unittest.html" target="_blank" rel="noreferrer noopener nofollow">unittest</a> (this is the one I have experience with and I did not feel the need to switch to pytest. Even if it does mean some boilerplate I am more tolerant on the test side, as long as the tests exist!). For the same reason as the one mentioned in the last point, I aim for 95% coverage.</li><li>I adopt the <a href="https://github.com/scikit-learn/scikit-learn/blob/main/sklearn/covariance/__init__.py" target="_blank" rel="noreferrer noopener nofollow">sklearn pattern</a> for imports, meaning everything that is imported outside the folder regroupment of modules where the __init__.py stands must be listed in this very __init__.py. Every class/method listed here is the interface of the “package” and must be tested (unitary and/or functional).&nbsp;</li><li>I often tried to implement cross-platform deterministic tests (read <a href="https://pytorch.org/docs/stable/notes/randomness.html" target="_blank" rel="noreferrer noopener nofollow">this</a> and <a href="https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html#reproducibility" target="_blank" rel="noreferrer noopener nofollow">this</a>) but failed (though I did succeed on a fixed platform). Since GitLab runners are changing from time to time this often leads to a lot of pain. I settle on having a performance “high enough” in&nbsp; end-to-end test.</li><li>To avoid code duplication across several containers, I advocate for a low-level homemade library that you then install in each of your containers (via a command line in their respective Dockerfiles).&nbsp;</li><li>Concerning <a href="https://en.wikipedia.org/wiki/Continuous_integration" target="_blank" rel="noreferrer noopener nofollow">CI</a>, build your docker images in their respective GitLab pipelines.</li><li>Try not to mount code in production (but do so locally to ease development. A very good <a href="https://pythonspeed.com/" target="_blank" rel="noreferrer noopener nofollow">reference</a> blog on docker+python).</li><li>I do not ship the tests in production, nor the librairies needed to run the tests (you should thus aim for two requirement files, one requirement-dev.txt not used in prod).</li><li>I often have a custom python dev docker-compose file to ease my life (and the onboarding of new members) which is different from the production one.&nbsp;</li><li>I advocate to (extensively) use the wiki part of your GitLab repos :), as the oral tradition was good at some stage of human history but is definitely not for IT companies :).&nbsp;</li><li>I try to minimize the number of volumes mounted on my containers, the best number being 0 but for some data sources (like model checkpoint) it can be complicated.</li><li>Handling dead code&nbsp; has a simple solution: <a href="https://pypi.org/project/vulture/" target="_blank" rel="noreferrer noopener nofollow">Vulture</a>. Run it, inspect (closely, as they are some false positives) its output, unplug dead code, rinse and repeat.</li></ul>
</div>


<h2>Conclusion</h2>



<p>All too often, you see self congratulating articles hiding what real life really is in the ML field. I hope that you leave this post knowing this is not one of these articles. This is the honest journey I went on in the past six years developing MLOPS pipelines, and I can be all the more proud when I look back at where I was when I started coding in 2006 (a one line method of more&nbsp; than 400 characters in a C code :)).&nbsp;</p>



<p>In my experience, some switching decisions are easy to make and implement (flask to FastAPI), some are easy to make but not so easy to implement (like Hyperopt to Optuna) and some are hard to make as well as hard to implement (like TensorFlow to PyTorch), but all are worth the effort in the end to avoid the 6 pitfalls I presented.&nbsp;</p>



<p>This mindset will hopefully allow you to transition from a POC-like ML environment&nbsp; to an<a href="https://en.wikipedia.org/wiki/Accelerate_(book)" target="_blank" rel="noreferrer noopener nofollow"> Accelerate</a> compliant one where implementing new features can take less than an hour, and adding them to the code base takes less than another hour.&nbsp;</p>



<p>At a personal level, I learned an awful lot and I am deeply indebted to my previous employers and my&nbsp;previous colleagues for that!</p>




<div id="author-box-new-format-block_62751d9d7a06a" class="article__footer article__author">
  <div class="article__authorImage">
          <img width="230" height="230" src="https://i0.wp.com/neptune.ai/wp-content/uploads/Thomas-Epelbaum.jpg?fit=230%2C230&amp;ssl=1" class="article__authorImage-img" alt="Thomas Epelbaum" decoding="async" data-attachment-id="65761" data-permalink="https://neptune.ai/attachment/thomas-epelbaum" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Thomas-Epelbaum.jpg?fit=323%2C323&amp;ssl=1" data-orig-size="323,323" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Thomas Epelbaum" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Thomas-Epelbaum.jpg?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Thomas-Epelbaum.jpg?fit=323%2C323&amp;ssl=1" />      </div>

  <div class="article__authorContent">
          <h3 class="article__authorContent-name">Thomas Epelbaum</h3>
    
          <p class="article__authorContent-text">Senior Python Dev and ML at EcoAct. Heavy Euro style board game enthusiast. Always happy to read a new philosophy/sociology/economy/biology book.</p>
    
          <ul class="article__authorSocial">
        <li class="article__authorSocial-single article__authorSocial-name">Follow me on</li>
        
                  <li class="article__authorSocial-single"><a href="https://www.linkedin.com/in/thomas-epelbaum-64b09625/" class="article__authorSocial-lk" target="_blank"></a></li>
        
                  <li class="article__authorSocial-single"><a href="http://www.normalesup.org/~epelbaum/" class="article__authorSocial-www" target="_blank"></a></li>
              </ul>
    
  </div>
</div>


<div class="is-layout-flow wp-block-group"><div class="wp-block-group__inner-container">
<hr class="wp-block-separator"/>



<p class="has-text-color" style="color:#4455a6"><strong>READ NEXT</strong></p>



<h2>MLOps at GreenSteam: Shipping Machine Learning [Case Study]</h2>



<p class="has-small-font-size">7 mins read | Tymoteusz Wołodźko | Posted March 31, 2021</p>


<div id="block_5ffc75def9f8e" class="separator separator-10"></div>



<div class="is-layout-flex wp-container-11 wp-block-columns are-vertically-aligned-center">
<div class="is-layout-flow wp-block-column is-vertically-aligned-center" style="flex-basis:66.66%">
<p><a href="https://www.greensteam.com/" target="_blank" rel="noreferrer noopener nofollow">GreenSteam</a> is a company that provides software solutions for the marine industry that help reduce fuel usage. Excess fuel usage is both costly and bad for the environment, and vessel operators are obliged to get more green by the International Marine Organization and reduce the CO2 emissions by 50 percent by 2050.</p>
</div>



<div class="is-layout-flow wp-block-column is-vertically-aligned-center" style="flex-basis:33.33%">
<div class="wp-block-image"><figure class="aligncenter size-large"><img data-attachment-id="42633" data-permalink="https://neptune.ai/blog/mlops-at-greensteam-shipping-machine-learning-case-study/attachment/greensteam-logo" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/GreenSteam-logo.png?fit=665%2C157&amp;ssl=1" data-orig-size="665,157" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="GreenSteam-logo" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/GreenSteam-logo.png?fit=300%2C71&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/GreenSteam-logo.png?fit=665%2C157&amp;ssl=1" decoding="async" width="665" height="157" src="https://i0.wp.com/neptune.ai/wp-content/uploads/GreenSteam-logo.png?resize=665%2C157&#038;ssl=1" alt="Greensteam logo" class="wp-image-42633" data-recalc-dims="1"/></figure></div>
</div>
</div>



<p>Even though we are not a big company (50 people including business, devs, domain experts, researchers, and data scientists), we have already built several machine learning products over the last 13 years that help some <a href="https://blog.greensteam.com/crucial-tools-for-shipping-companies-looking-to-thrive-post-2020" target="_blank" rel="noreferrer noopener nofollow">major shipping companies make informed performance optimization decisions</a>.</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img data-attachment-id="42643" data-permalink="https://neptune.ai/blog/mlops-at-greensteam-shipping-machine-learning-case-study/attachment/mlops-shipping-4" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-shipping-4.jpg?fit=960%2C539&amp;ssl=1" data-orig-size="960,539" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="MLOps shipping 4" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-shipping-4.jpg?fit=300%2C168&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-shipping-4.jpg?fit=960%2C539&amp;ssl=1" decoding="async" src="https://i0.wp.com/neptune.ai/wp-content/uploads/MLOps-shipping-4.jpg?resize=720%2C404&#038;ssl=1" alt="MLOps shipping" class="wp-image-42643" width="720" height="404" data-recalc-dims="1" /></figure></div>



<p>In this blog post, I want to share our journey to building the MLOps stack. Specifically, how we:</p>


<div class="custom-point-list">
<ul><li>dealt with <strong>code dependencies</strong></li><li>approached <strong>testing ML models </strong>&nbsp;</li><li>built <strong>automated training and evaluation pipelines&nbsp;</strong></li><li><strong>deployed and served our models</strong></li><li>managed to keep <strong>human-in-the-loop in MLOps</strong></li></ul>
</div>

<a class="button continous-post blue-filled" href="/blog/mlops" target="_blank">
    Continue reading -&gt;</a>



<hr class="wp-block-separator"/>
</div></div>
<p>The post <a rel="nofollow" href="https://neptune.ai/blog/building-ml-pipeline-problems-solutions">Building ML Pipeline: 6 Problems &#038; Solutions [From a Data Scientist&#8217;s Experience]</a> appeared first on <a rel="nofollow" href="https://neptune.ai">neptune.ai</a>.</p>
]]></content:encoded>
					
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">65705</post-id>	</item>
		<item>
		<title>Recommender Systems: Lessons From Building and Deployment</title>
		<link>https://neptune.ai/blog/recommender-systems-lessons-from-building-and-deployment</link>
		
		<dc:creator><![CDATA[Dhruvil Karani]]></dc:creator>
		<pubDate>Thu, 25 Aug 2022 16:15:27 +0000</pubDate>
				<category><![CDATA[ML Model Development]]></category>
		<category><![CDATA[MLOps]]></category>
		<category><![CDATA[mlops]]></category>
		<guid isPermaLink="false">https://neptune.ai/?p=70885</guid>

					<description><![CDATA[<p>If you look at recommender systems papers, a large number of them come from the industry instead of academia. This is because RecSys is actually a practical problem. RecSys for e-commerce could be considerably different than RecSys for social media, as the business objectives differ. In addition, every novel idea needs to be tested in [&#8230;]</p>
<p>The post <a rel="nofollow" href="https://neptune.ai/blog/recommender-systems-lessons-from-building-and-deployment">Recommender Systems: Lessons From Building and Deployment</a> appeared first on <a rel="nofollow" href="https://neptune.ai">neptune.ai</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<p>If you look at recommender systems papers, a large number of them come from the industry instead of academia. This is because RecSys is actually a practical problem. RecSys for e-commerce could be considerably different than RecSys for social media, as the business objectives differ. In addition, every novel idea needs to be tested in the real world to gain credibility. As a result, learning the practicalities of RecSys is as essential as learning about novel architectures. </p>


<div class="wp-block-image">
<figure class="aligncenter size-full is-resized"><img data-attachment-id="71023" data-permalink="https://neptune.ai/lessons-from-building-and-deploying-recommender-systems/attachment/structure-of-a-recommender-system" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Structure-of-a-recommender-system.png?fit=850%2C477&amp;ssl=1" data-orig-size="850,477" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Structure-of-a-recommender-system" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Structure-of-a-recommender-system.png?fit=300%2C168&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Structure-of-a-recommender-system.png?fit=850%2C477&amp;ssl=1" decoding="async" src="https://i0.wp.com/neptune.ai/wp-content/uploads/Structure-of-a-recommender-system.png?resize=840%2C471&#038;ssl=1" alt="Structure of a recommender system" class="wp-image-71023" width="840" height="471" data-recalc-dims="1" /><figcaption><em>Structure of a recommender system | <a href="https://www.researchgate.net/figure/Structure-of-a-recommender-system_fig2_220827211" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>


<p>This article discusses practical considerations while building a recommender system. Specifically, we are going to talk about my learnings regarding recommender systems in the following areas:</p>


<div class="custom-point-list">
<ul><li>Dataset creation</li><li>Objective-design</li><li>Model training</li><li>Model evaluation<ul><li>Offline evaluation</li><li>Detecting and mitigating bias</li></ul></li><li>Checklist for checking model correctness</li><li>RecSys architecture</li><li>Online MLOps</li><li>A/B testing</li></ul>
</div>


<p><em>Note: All views in the article are the author’s own and do not represent the author’s current or past employers.</em></p>



<h2>Recommender systems: dataset creation</h2>



<p>This step for RecSys is not as straightforward as text or image classification. For example, consider that we are creating a RecSys, which predicts clicks for an e-commerce website. We might train our model on all the data if we have a small number of users and items.&nbsp;</p>



<p>However, if we are working at an Amazon or Walmart scale, we have millions of daily active users and items in the catalog. Training a simple collaborative filtering model on the entire historical interactions will cost us a lot – Reading the data (in TBs if not PBs) from the data warehouse, spinning up a high-capacity VM (that will run for weeks). <strong>We must question if it is worth the cost and what is the correct way of going about this.</strong></p>



<p>If we have a billion users in your database and a few million daily active users, then we must only train for these active users since the inactive users have fewer chances of showing up. One can select this subset of users by putting a threshold on activity in the last N days, like select users who clicked on &gt;=10 items in the last 10 days. If a few users we have not included in training show up, we can fall back to a custom logic, like a content-based or popularity-based retrieval. Since RecSys models are trained periodically, this subset of users will keep changing. Once we select this subset of users, we can train our model on interactions with these users.</p>



<p><strong>The next question is, how much data is enough?</strong> If we have five years of data, we don’t need all of it. Yes, a model benefits from more data. But in RecSys, the main idea is to best capture a user’s interest, which changes over time. So it makes more sense to have fresh training data. In addition, a simple collaborative filtering model cannot capture too much complexity. One can verify this by plotting a metric vs. number of training steps, which will most likely show diminishing gains.</p>



<p>Next,<strong> detecting duplicates in your dataset is helpful</strong>, like the same video/item posted two times with different Ids. Besides, <a href="/blog/category/natural-language-processing" target="_blank" rel="noreferrer noopener">NLP</a> and <a href="/blog/category/computer-vision" target="_blank" rel="noreferrer noopener">CV </a>models can help remove the dataset&#8217;s NSFW, harmful, and illegal content.</p>



<p>Following these steps can reduce the dataset size considerably. This will help us save costs with minimal loss of quality.</p>



<h2>Recommender systems: designing optimal objective</h2>



<p>The ultimate goal of RecSys is to give people what they want. Although this is a broad and rather philosophical question, we must narrow it down to a specific signal for which the model must optimize – predicting clicks, likes, shares, etc. <strong>When we train a model to predict clicks and use it to serve recommendations, our underlying assumption is that if you click on an item, it is relevant to you. More often than not, it is not completely true.&nbsp;</strong></p>



<p>To understand this better, let’s use a different example. Say you are building a RecSys for YouTube, which predicts whether a user will click a particular video. This model is used to serve recommendations based on the click probability. However, this model resulted in lesser user time spent on the platform. <strong>The reason is that clicks are not equivalent to relevance</strong>. Most clickbait videos have a high click rate, but viewers stop watching them after a few seconds. A model that is 100% accurate would serve a high number of videos that are clicked but not watched.</p>



<p>Learning from the above, you decide to train a model that predicts if the user will watch at least 75% of the video. So the training examples will include (user, video, label) triplets, where label=1 if &gt;=75% of the video is watched else 0. This is better than the click model because now we consider that the user has done more than just click a video. However, even this has a major problem.</p>



<p>Consider two videos, A and B. A is an entertaining 20 seconds long video, and B is a tutorial video of 60 minutes. To watch 75%, you need to watch 15 seconds of A and 45 seconds of B.</p>



<p>Naturally, A will have a higher positive rate of this label than B. However, watching 15 seconds of A could mean that the user did not like A (as 15 seconds is too less of a time to decide if you prefer the content), and watching 30 minutes (50%) of B most likely means that B is relevant to the user. <strong>Even a highly accurate model would end up serving a disproportionately large number of shorter duration videos, which is not optimal.</strong></p>



<p>The point is that one signal rarely defines complete relevance. Each signal has its own bias. <strong>It is a good practice to train multiple models on multiple signals, combine their individual scores (weighted addition, for example), and create the final score.</strong></p>



<h2>Recommender systems: model training</h2>



<p>Large NLP or Vision models have billions of parameters distributed among linear, convolution, recurrent, or attention layers. Each of these parameters is involved in the computation of the output. However, in recommendation models, model sizes are much larger than most NLP or CV models.&nbsp;</p>



<p>Consider matrix factorization, where the model learns a user and an item embedding (in the case of <a href="https://developers.google.com/machine-learning/recommendation/collaborative/basics" target="_blank" rel="noreferrer noopener nofollow">collaborative filtering</a>). If the embedding dimension is 100, you have 100 million users and 10 million items. The total number of embeddings is 110 million. Each embedding has 100 learnable parameters. Hence the model has 110*100 million or ~11 billion parameters. However, to compute scores for a user, you need to access just one of the 100 million user embeddings at a time. This particular user embedding is used along with all the item embeddings to score all the items. Hence, recommendation models are memory intensive but compute light.</p>



<p>This is a different challenge because now you can’t and don’t need to load the entire embedding table on a GPU/TPU for a batch of data. However, writing such models on traditional frameworks like <a href="https://www.tensorflow.org/" target="_blank" rel="noreferrer noopener nofollow">TensorFlow </a>or <a href="https://pytorch.org/" target="_blank" rel="noreferrer noopener nofollow">PyTorch</a> is hard because their default behaviour is to load the entire model on GPU/TPUs. Fortunately, many frameworks have built functionality for this very purpose.</p>



<p>Tensorflow has built a framework called <a href="https://www.tensorflow.org/recommenders" target="_blank" rel="noreferrer noopener nofollow"><strong>tensorflow_recommenders</strong></a><strong> </strong>with a special embedding table called <a href="https://www.tensorflow.org/recommenders/api_docs/python/tfrs/layers/embedding/TPUEmbedding">TPUEmbedding</a>. Besides, it has implemented versions of many common tasks in RecSys like <a href="https://www.tensorflow.org/recommenders/api_docs/python/tfrs/tasks/Retrieval" target="_blank" rel="noreferrer noopener nofollow">retrieval</a> and <a href="https://www.tensorflow.org/recommenders/api_docs/python/tfrs/tasks/Ranking" target="_blank" rel="noreferrer noopener nofollow">ranking</a> and popular architectures like <a href="https://www.tensorflow.org/recommenders/api_docs/python/tfrs/layers/dcn" target="_blank" rel="noreferrer noopener nofollow">DCN</a>.&nbsp;</p>



<p>Recently, PyTorch announced <a href="https://pytorch.org/torchrec/" target="_blank" rel="noreferrer noopener nofollow"><strong>torchrec</strong></a>. According to the team: </p>



<p><em>“TorchRec is a PyTorch domain library built to provide common sparsity &amp; parallelism primitives needed for large-scale recommender systems (RecSys). It allows authors to train models with large embedding tables sharded across many GPUs.” </em></p>



<p>NVIDIA also has <a href="https://developer.nvidia.com/nvidia-merlin" target="_blank" rel="noreferrer noopener nofollow"><strong>Merlin</strong></a>, which automates common processes in RecSys for faster production-grade systems. It supports Tensorflow and PyTorch and is built on top of cuDF (GPU equivalent of Pandas), RAPIDS (GPU-based analytics and data manipulation library), and Triton (high-performance inference server).</p>



<h2>Recommender systems: model evaluation</h2>



<h3>Offline evaluation</h3>



<p>Typical classification task optimizes for metrics like accuracy, precision, recall, or F1-score. Evaluating RecSys using these metrics is deceptive. In RecSys, we are not interested in objective probabilities. We are more interested in ranking. For example, if predicted scores for videos A and B are 0.9 and 0.8, we will show video A first and then B while serving. Even if the probabilities for A and B were 0.5, 0.4, or 0.3,0.2, the outcome is still the same. It’s the ordering that matters, not the absolute numbers. Hence, metrics like ROC-AUC, PR-AUC, NDCG, recall@K, and precision@K are better suited.&nbsp;</p>



<p>However, even then, this evaluation is can fall short. Recommender systems are notorious for compounding bias towards certain topics, demographics, or popularity. A recommender system trains on logs generated by itself. If popular content is promoted more by the system, then the incremental logs generated will have more triplets for this popular content. <strong>The next version of the model, trained on these new logs, will see a skewed distribution and will learn that recommending popular items is a safe choice. This is called popularity bias.&nbsp;</strong></p>



<p>It is advisable to compute metrics on different levels &#8211; user attributes like age, gender, location, etc. This helps us understand if the model is performing better for a particular set of users and not performing well for the rest. Tools like <a href="https://github.com/jacopotagliabue/reclist" target="_blank" rel="noreferrer noopener nofollow">reclist</a> provide an easy interface to deep-dive into your recommender model.</p>



<p>Another useful tool could be <a href="/experiment-tracking" target="_blank" rel="noreferrer noopener">Neptune</a>, as it provides simple logging APIs for a much more organized, collaborative, and comprehensive analysis. One can <a href="https://docs.neptune.ai/you-should-know/displaying-metadata#creating-dashboards" target="_blank" rel="noreferrer noopener">create custom dashboards</a> to visualize the logs through interactive visualizations. As discussed above, we are interested in metrics at multiple cuts based on attributes like demographic and location. We can plot ROC/PR AUC, loss curves, and log ranking metrics here and easily compare and determine if the model is really robust or not.</p>



<div id="blog-cta-intext-block_63079ae6b8f14" class="blog-cta-intext">
  <h3 class="blog-cta-intext__title">Learn more</h3>
  <div class="blog-cta-intext__content"><p>Check what <a href="https://docs.neptune.ai/you-should-know/what-can-you-log-and-display" target="_blank" rel="noopener">metadata you can log and display in Neptune</a>.</p>
</div>
  </div>

<div class="wp-block-image">
<figure class="aligncenter size-full"><img data-attachment-id="70888" data-permalink="https://neptune.ai/lessons-from-building-recommender-system-1" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/lessons-from-building-recommender-system-1.png?fit=768%2C413&amp;ssl=1" data-orig-size="768,413" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="lessons-from-building-recommender-system-1" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/lessons-from-building-recommender-system-1.png?fit=300%2C161&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/lessons-from-building-recommender-system-1.png?fit=768%2C413&amp;ssl=1" decoding="async" width="768" height="413" src="https://i0.wp.com/neptune.ai/wp-content/uploads/lessons-from-building-recommender-system-1.png?resize=768%2C413&#038;ssl=1" alt="Example dashboard in Neptune with  visualize logs through interactive visualizations" class="wp-image-70888" data-recalc-dims="1"/><figcaption><em>Example dashboard in Neptune | <a href="/experiment-tracking">Source</a></em></figcaption></figure></div>


<h3>Detecting and mitigating bias</h3>



<p>As explained earlier, biases like popularity bias can easily propagate through the system if not taken care of. But how do we measure bias before mitigating it?</p>


<div class="wp-block-image">
<figure class="aligncenter size-full is-resized"><img data-attachment-id="70889" data-permalink="https://neptune.ai/lessons-from-building-recommender-system-2" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/lessons-from-building-recommender-system-2.png?fit=334%2C151&amp;ssl=1" data-orig-size="334,151" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="lessons-from-building-recommender-system-2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/lessons-from-building-recommender-system-2.png?fit=300%2C136&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/lessons-from-building-recommender-system-2.png?fit=334%2C151&amp;ssl=1" decoding="async" src="https://i0.wp.com/neptune.ai/wp-content/uploads/lessons-from-building-recommender-system-2.png?resize=474%2C214&#038;ssl=1" alt="Mitigating bias" class="wp-image-70889" width="474" height="214" data-recalc-dims="1" /><figcaption><em>A loop of detecting and mitigating bias| <a href="https://people.engr.tamu.edu/caverlee/pubs/Ziwei_KDD_2021.pdf" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>


<p>One easy way to measure popularity bias is to check how many unique items make 10%, 20%, 50%, .. 100% of recommendations. In an ideal case, the number of items should increase with % of recommendations. However, for a biased model, the number of items will saturate after a certain % (usually on the lower end). This is because the model relies on only a certain subset of recommendable items to make predictions.&nbsp;</p>



<p>But this approach does not take the user’s preference into account. For example, if a user U1 interacts with three items A, B, and C; and likes items A and B but not C. Similarly, user U2 interacts with A, B, and C; and likes only A. We know that A is a popular item while B and C are not.</p>


<div class="medium-table">
        <div class="mt-row heading">
            <div class="mt-col" style="width: 10%">
                    </div>
            <div class="mt-col" style="width: 30%">
            A (popular)        </div>
            <div class="mt-col" style="width: 30%">
            B (not-popular)        </div>
            <div class="mt-col" style="width: 30%">
            C (not-popular)        </div>
        </div>
    
            <div class="mt-row">
                            <div class="mt-col" style="width: 10%">
                                                                <p>U1</p>
                                    </div>
                            <div class="mt-col" style="width: 30%">
                                        <span class="column-name">
                        A (popular):
                    </span>
                                                                <p>1</p>
                                    </div>
                            <div class="mt-col" style="width: 30%">
                                        <span class="column-name">
                        B (not-popular):
                    </span>
                                                                <p>1</p>
                                    </div>
                            <div class="mt-col" style="width: 30%">
                                        <span class="column-name">
                        C (not-popular):
                    </span>
                                                                0                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 10%">
                                                                <p>U2</p>
                                    </div>
                            <div class="mt-col" style="width: 30%">
                                        <span class="column-name">
                        A (popular):
                    </span>
                                                                <p>1</p>
                                    </div>
                            <div class="mt-col" style="width: 30%">
                                        <span class="column-name">
                        B (not-popular):
                    </span>
                                                                0                                    </div>
                            <div class="mt-col" style="width: 30%">
                                        <span class="column-name">
                        C (not-popular):
                    </span>
                                                                0                                    </div>
                    </div>
    </div>


<div id="block_63073c43681ca" class="separator separator-10"></div>



<p class="has-text-align-center"><em>Example of a simple biased model</em></p>



<p>For U1, if the model scores higher for A than B, then it may be biased. Because the user response to both of them is positive. Even if the model consistently favours the more popular item, we have a biased model. However, for U2, it makes sense to rank the popular item higher because U2 does not like the other two non-popular items. <strong>Although the examples we have used are very simplistic, there are measures like statistical parity that help you measure this.</strong></p>



<p>There are a few simple ways to mitigate bias. <strong>One way is to introduce negative samples.</strong> Consider an e-commerce platform where users interact with a few items out of hundreds shown. We only know what items the user interacted with (positive examples). However, we have no idea about what happened to the other items. To balance this dataset, we introduce negative samples by randomly sampling an item for a user and assigning it a negative label (=0). The assumption is that a user will not like an item picked randomly. Since this assumption is most likely true, adding negative samples actually adds missing information to the dataset.</p>



<div id="blog-cta-intext-block_630798d2b8f12" class="blog-cta-intext">
  <h3 class="blog-cta-intext__title">May interest you</h3>
  <div class="blog-cta-intext__content"><p><img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f4cc.png" alt="📌" class="wp-smiley" style="height: 1em; max-height: 1em;" /> <a href="/blog/recommender-systems-metrics" target="_blank" rel="noopener">Recommender Systems: Machine Learning Metrics and Business Metrics</a></p>
</div>
  </div>


<h2>Checklist for testing correctness of a recommender system model</h2>



<p>Like any piece of software, one should ensure the correctness of the models by writing unit tests. Unfortunately, writing ML code unit tests is uncommon and tricky. However, for RecSys, let’s focus on a simple CF (collaborative filtering) model. As we know, the model is essentially the set of user embeddings and item embeddings. You can test this model for the following:</p>


<div class="custom-point-list">
<ol><li><strong>Correct Scoring </strong>&#8211; The scoring operation consuming a user and item embedding should produce a score between 0 and 1.</li><li><strong>Correct versioning </strong>&#8211; Since the embeddings are retrained periodically, it is important to version them correctly so that the scores are consistent.</li><li><strong>Correct features </strong>&#8211; Some models, like two-tower models, use features like user activity in the last X hours. One needs to make sure that the feature pipeline that the model consumes does not produce leaky features.</li><li><strong>Correct training dataset </strong>&#8211; The dataset should not have duplicate user-item pairs, the labels should be correct, and the train-test-split should be random.</li></ol>
</div>


<div id="blog-cta-intext-block_630798a2b8f11" class="blog-cta-intext">
  <h3 class="blog-cta-intext__title">Read also </h3>
  <div class="blog-cta-intext__content"><p><img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f4cc.png" alt="📌" class="wp-smiley" style="height: 1em; max-height: 1em;" /> <a href="/blog/how-to-test-recommender-system" target="_blank" rel="noopener">How to Test a Recommender System</a></p>
<p><img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f4cc.png" alt="📌" class="wp-smiley" style="height: 1em; max-height: 1em;" /> <a href="https://github.com/jacopotagliabue/reclist" target="_blank" rel="noopener">RecList &#8211; Behavioral &#8220;black-box&#8221; testing for recommender systems</a></p>
</div>
  </div>


<h2>RecSys architecture</h2>



<p>Recommender systems have to pick the best set for a user from a set of millions of items. However, this has to be done within strict latency requirements. As a result, the more complex model we train, the more time it takes to process one request. Hence, RecSys follows a multi-stage architecture. Think of it as a funnel that starts with a million items and ends with a handful of recommendations.</p>



<p><strong>The idea is to use a simple, lightweight model at the top of this funnel, like a simple collaborative filtering model.</strong> This model should be able to pick a few thousand most relevant items, maybe not with the best ranking i.e., the relevant items should be present in this set of thousands of items, and it is okay if they are not at the top. Hence, this model optimizes recall and speed. This model is also called a candidate generator. Even in a simple collaborative filtering model, ensure the embedding dimensions are not too large. Using 100s of dimensions might give you a slight increment in the recall but affect your latencies.</p>



<p><strong>Then, these thousands of items are sent to another model called light ranker. As the name suggests, the task of this model is to find the best ranking.</strong> The model is trained for high precision and is more complex than the candidate generator (for example, two-tower models). It also uses more features based on user activity, item metadata, and more. The outcome of this model is a ranked list top hundreds of items.</p>



<p><strong>Finally, these hundreds of items are sent to heavy ranker. </strong>This ranker has a similar objective to the light ranker, except that it is heavier than the light ranker and uses even more features. Since it operates on hundreds of items only, the latencies involved with such complex architectures are manageable.&nbsp;</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img data-attachment-id="70890" data-permalink="https://neptune.ai/lessons-from-building-recommender-system-3" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/lessons-from-building-recommender-system-3.png?fit=1999%2C1068&amp;ssl=1" data-orig-size="1999,1068" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="lessons-from-building-recommender-system-3" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/lessons-from-building-recommender-system-3.png?fit=300%2C160&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/lessons-from-building-recommender-system-3.png?fit=1024%2C547&amp;ssl=1" decoding="async" width="1024" height="547" src="https://i0.wp.com/neptune.ai/wp-content/uploads/lessons-from-building-recommender-system-3.png?resize=1024%2C547&#038;ssl=1" alt="RecSys architecture" class="wp-image-70890" data-recalc-dims="1"/><figcaption><em>Recommender systems architecture | <a href="https://milvus.io/blog/2021-11-26-accelerating-candidate-generation-in-recommender-systems-using-milvus-paired-with-paddlepaddle.md" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>


<h2>Online MLOps for recommender systems</h2>



<p>One good thing about recommendation models vs. a classification or regression model is that we get real-time feedback or “labels”. Hence, we can set up a comprehensive ML Ops pipeline to closely monitor your model performance.</p>



<p>There are many metrics we can monitor.</p>


<div class="case-study-numbered-list">
    <h2></h2>
    <ul>
                    <li><span>1</span>Time spent on the platform<br />
</li>
                    <li><span>2</span>Engagement</li>
                    <li><span>3</span>Clicks</li>
                    <li><span>4</span>Purchases<br />
</li>
                    <li><span>5</span>User churn</li>
            </ul>
</div>



<p>Model performance on metrics like engagement is easy to measure in offline experiments. However, you can’t measure something like churn in an offline experiment. It is common to find such discrepancies in real-world RecSys. <strong>Usually, we analyze what online metrics that are measurable offline (like time spent, engagement, clicks) have a positive correlation with churn. This reduces the problem of improving a set of predictable metrics in offline experiments.</strong></p>



<p><strong>Besides model quality and performance, we should monitor things like average, 95th percentile,</strong> and 99th percentile latencies, CPU, non-200 status code rates,<strong> and memory usage.</strong> Not so surprising, but improving these metrics also improves the time spent and reduces churn. Tools like <a href="https://grafana.com/" target="_blank" rel="noreferrer noopener nofollow">Grafana</a> help set up comprehensive observability dashboards.</p>



<p>Retraining pipelines can also break down because of problems not related to bugs in code, like not enough pods available in your Kubernetes clusters or not enough GPU resources available. <strong>If you are using DAGs on Airflow, it has the option to set up a failure alert on Slack.</strong> Alternatively, tune the number of retries and timeout parameters so that the chances of automatic recovery improve.</p>



<h2>Recommender systems: A/B testing</h2>



<p>Improving recommender systems is a continuous process. However, this improvement should not worsen the user experience. If your team comes up with a novel model that shows amazing gains in offline evaluation, it is not obvious to roll out the model for all the users. This is where A/B testing comes into play.</p>



<p>Any new target model must be evaluated against the control (existing production) model. In an A/B test, you would randomly select a small percentage of users and serve them using the target model, while the rest receive recommendations from the control model as before. After a few days/weeks, look at which model performed better and quantify it using hypothesis testing. If the test concludes that the new model gives gains over the control, you roll out the new model for all users.</p>



<p><strong>However, it is a good practice to roll out the new model to only 98-99% of users and let the rest 1-2% be served by the control model.</strong> This 1-2% of users is called the holdout set. <strong>The idea here is to see if, at some point, the new model starts degrading, is it due to some change that impacts all models, or if something is wrong with this new model alone?</strong> In RecSys, a target model, when served to a small set of users, is still trained on logs majorly generated by the control model. However, it is possible that when the new model becomes the control, it starts learning from the logs majorly generated by itself and degrades.</p>



<h2>Conclusion</h2>



<p>RecSys has many moving parts, and each of these parts is a knob that can be tuned to make the system better. Personally, this is what makes RecSys really interesting to me. I hope the article was able to provide new directions of thinking. Each of these topics has a varying amount of literature for you to explore. I have linked some references below. Make sure to check them out!</p>



<h3>References </h3>



<p>[1] <a href="https://arxiv.org/abs/2202.05387" target="_blank" rel="noreferrer noopener nofollow">TwHIN: Embedding the Twitter Heterogeneous Information Network for Personalized Recommendation</a></p>



<p>[2] <a href="https://dl.acm.org/doi/pdf/10.1145/3437963.3441820" target="_blank" rel="noreferrer noopener nofollow">Popularity-Opportunity Bias in Collaborative Filtering</a></p>



<p>[3] <a href="https://arxiv.org/pdf/2105.09293.pdf" target="_blank" rel="noreferrer noopener nofollow">Lessons Learned Addressing Dataset Bias in Model-Based Candidate Generation at Twitter</a></p>




<div id="author-box-new-format-block_60421833aff63" class="article__footer article__author">
  <div class="article__authorImage">
          <img width="193" height="193" src="https://i0.wp.com/neptune.ai/wp-content/uploads/Dhruvil-Karani.png?fit=193%2C193&amp;ssl=1" class="article__authorImage-img" alt="Dhruvil Karani" decoding="async" data-attachment-id="35458" data-permalink="https://neptune.ai/blog/how-to-structure-and-manage-nlp-projects-templates/attachment/dhruvil-karani" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Dhruvil-Karani.png?fit=193%2C193&amp;ssl=1" data-orig-size="193,193" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Dhruvil Karani" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Dhruvil-Karani.png?fit=193%2C193&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Dhruvil-Karani.png?fit=193%2C193&amp;ssl=1" />      </div>

  <div class="article__authorContent">
          <h3 class="article__authorContent-name">Dhruvil Karani</h3>
    
          <p class="article__authorContent-text"><strong>Data Scientist at i3systems India</strong><br>A Data Scientist who loves math and programming equally. His previous experiences allowed him to work on large scale NLP problems like chatbots and document understanding. He believes that educating the masses about technology and its impact is as important as developing new ones.</p>
    
          <ul class="article__authorSocial">
        <li class="article__authorSocial-single article__authorSocial-name">Follow me on</li>
                  <li class="article__authorSocial-single"><a href="https://twitter.com/dhruvil_karani" class="article__authorSocial-tw" target="_blank"></a></li>
        
                  <li class="article__authorSocial-single"><a href="https://www.linkedin.com/in/dhruvil-karani/" class="article__authorSocial-lk" target="_blank"></a></li>
        
                  <li class="article__authorSocial-single"><a href="https://thenlp.space/" class="article__authorSocial-www" target="_blank"></a></li>
              </ul>
    
  </div>
</div>


<div class="is-layout-flow wp-block-group"><div class="wp-block-group__inner-container">
<hr class="wp-block-separator has-css-opacity"/>



<p class="has-text-color" style="color:#4455a6"><strong>READ NEXT</strong></p>



<h2>Real-World MLOps Examples: Model Development in Hypefactors</h2>



<p class="has-small-font-size">6 mins read | Author&nbsp;Stephen Oladele | Updated June 28th, 2022</p>


<div id="block_5ffc75def9f8e" class="separator separator-10"></div>



<p>In this first installment of the series “Real-world MLOps Examples,”&nbsp;<a href="https://www.linkedin.com/in/jules-belveze" target="_blank" rel="noreferrer noopener">Jules Belveze</a>, an MLOps Engineer, will walk you through the model development process at&nbsp;<a href="https://hypefactors.com/" target="_blank" rel="noreferrer noopener">Hypefactors</a>, including the types of models they build, how they design their training pipeline, and other details you may find valuable. Enjoy the chat!</p>



<h3 id="company-profile">Company profile</h3>



<p><a href="https://hypefactors.com/" target="_blank" rel="noreferrer noopener">Hypefactors</a>&nbsp;provides an all-in-one media intelligence solution for managing PR and communications, tracking trust, product launches, and market and financial intelligence. They operate large data pipelines that stream in the world’s media data ongoingly in real-time. AI is used for many automations that were previously performed manually.</p>



<h3 id="guest-introduction">Guest introduction</h3>



<h4>Could you introduce yourself to our readers?</h4>



<p>Hey Stephen, thanks for having me! My name is Jules. I am 26. I was born and raised in Paris, I am currently living in Copenhagen.</p>



<h4>Hey Jules! Thanks for the intro. Walk me through your background and how you got to Hypefactors.</h4>



<p>I hold a Bachelor’s in statistics and probabilities and a Master’s in general engineering from universities in France. On top of that, I also graduated in Data Science with a focus on deep learning from Danish Technical University, Denmark. I’m fascinated by multilingual natural language processing (and therefore specialized in it). I also researched anomaly detection on high-dimensional time series during my graduate studies with Microsoft.&nbsp;</p>



<p>Today, I work for a media intelligence tech company called Hypefactors, where I develop NLP models to help our users gain insights from the media landscape. What currently works for me is having the opportunity to carry out models from prototyping all the way to production. I guess you could call me a nerd, at least that’s how my friend describes me, as I spent most of my free time either coding or listening to disco vinyl.</p>



<h3 id="model-development-at-hypefactors">Model development at Hypefactors</h3>



<h4>Could you elaborate on the types of models you build at Hypefactors?</h4>



<p>Even though we also have computer vision models running in production, we mainly build&nbsp;<a href="https://neptune.ai/blog/category/natural-language-processing" target="_blank" rel="noreferrer noopener">NLP (Natural Language Processing)</a>&nbsp;models for various use cases. We need to cover multiple countries and handle many languages. The multilingual aspect makes developing with “classical machine learning” approaches hard. We craft deep learning models on top of the&nbsp;<a href="https://github.com/huggingface/transformers" target="_blank" rel="noreferrer noopener">transformer library</a>.&nbsp;</p>



<p>We run all sorts of models in production, varying from span extraction or sequence classification to text generation. Those models are designed to serve different use cases, like topic classification, sentiment analysis, or summarisation.</p>


<a class="button continous-post blue-filled" href="/blog/mlops" target="_blank">
    Continue reading -&gt;</a>



<hr class="wp-block-separator has-css-opacity"/>
</div></div>
<p>The post <a rel="nofollow" href="https://neptune.ai/blog/recommender-systems-lessons-from-building-and-deployment">Recommender Systems: Lessons From Building and Deployment</a> appeared first on <a rel="nofollow" href="https://neptune.ai">neptune.ai</a>.</p>
]]></content:encoded>
					
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">70885</post-id>	</item>
	</channel>
</rss>
