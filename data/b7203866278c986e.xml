<?xml version='1.0' encoding='UTF-8'?><?xml-stylesheet href="http://www.blogger.com/styles/atom.css" type="text/css"?><feed xmlns='http://www.w3.org/2005/Atom' xmlns:openSearch='http://a9.com/-/spec/opensearchrss/1.0/' xmlns:blogger='http://schemas.google.com/blogger/2008' xmlns:georss='http://www.georss.org/georss' xmlns:gd="http://schemas.google.com/g/2005" xmlns:thr='http://purl.org/syndication/thread/1.0'><id>tag:blogger.com,1999:blog-10560800</id><updated>2022-11-05T08:08:28.365-07:00</updated><title type='text'>Machine Learning, etc</title><subtitle type='html'></subtitle><link rel='http://schemas.google.com/g/2005#feed' type='application/atom+xml' href='http://yaroslavvb.blogspot.com/feeds/posts/default'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default'/><link rel='alternate' type='text/html' href='http://yaroslavvb.blogspot.com/'/><link rel='hub' href='http://pubsubhubbub.appspot.com/'/><link rel='next' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default?start-index=26&amp;max-results=25'/><author><name>Yaroslav Bulatov</name><uri>http://www.blogger.com/profile/06139256691290554110</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='24' height='32' src='http://3.bp.blogspot.com/_bx6Dx71KhWU/TGIERDKa7JI/AAAAAAAAABs/FMguoAgVdRA/S220/me.gif'/></author><generator version='7.00' uri='http://www.blogger.com'>Blogger</generator><openSearch:totalResults>121</openSearch:totalResults><openSearch:startIndex>1</openSearch:startIndex><openSearch:itemsPerPage>25</openSearch:itemsPerPage><entry><id>tag:blogger.com,1999:blog-10560800.post-7506333235700702670</id><published>2017-11-19T19:51:00.001-08:00</published><updated>2017-11-19T19:51:25.675-08:00</updated><title type='text'>Backprop and systolic arrays</title><summary type="text">https://medium.com/@yaroslavvb/backprop-and-systolic-arrays-24e925d2050</summary><link rel='replies' type='application/atom+xml' href='http://yaroslavvb.blogspot.com/feeds/7506333235700702670/comments/default' title='Post Comments'/><link rel='replies' type='text/html' href='http://www.blogger.com/comment.g?blogID=10560800&amp;postID=7506333235700702670' title='525 Comments'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/7506333235700702670'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/7506333235700702670'/><link rel='alternate' type='text/html' href='http://yaroslavvb.blogspot.com/2017/11/backprop-and-systolic-arrays.html' title='Backprop and systolic arrays'/><author><name>Yaroslav Bulatov</name><uri>http://www.blogger.com/profile/06139256691290554110</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='24' height='32' src='http://3.bp.blogspot.com/_bx6Dx71KhWU/TGIERDKa7JI/AAAAAAAAABs/FMguoAgVdRA/S220/me.gif'/></author><thr:total>525</thr:total></entry><entry><id>tag:blogger.com,1999:blog-10560800.post-547044245035456587</id><published>2017-10-30T22:19:00.002-07:00</published><updated>2017-10-30T22:19:35.642-07:00</updated><title type='text'>TensorFlow meets PyTorch with new Eager mode</title><summary type="text">medium post</summary><link rel='replies' type='application/atom+xml' href='http://yaroslavvb.blogspot.com/feeds/547044245035456587/comments/default' title='Post Comments'/><link rel='replies' type='text/html' href='http://www.blogger.com/comment.g?blogID=10560800&amp;postID=547044245035456587' title='177 Comments'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/547044245035456587'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/547044245035456587'/><link rel='alternate' type='text/html' href='http://yaroslavvb.blogspot.com/2017/10/tensorflow-meets-pytorch-with-new-eager.html' title='TensorFlow meets PyTorch with new Eager mode'/><author><name>Yaroslav Bulatov</name><uri>http://www.blogger.com/profile/06139256691290554110</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='24' height='32' src='http://3.bp.blogspot.com/_bx6Dx71KhWU/TGIERDKa7JI/AAAAAAAAABs/FMguoAgVdRA/S220/me.gif'/></author><thr:total>177</thr:total></entry><entry><id>tag:blogger.com,1999:blog-10560800.post-5553983325212368022</id><published>2017-10-22T16:03:00.001-07:00</published><updated>2017-10-22T16:03:38.230-07:00</updated><title type='text'> Optimizing deeper networks with KFAC in PyTorch.</title><summary type="text">Medium post.

(I&#39;m getting too much comment spam on Blogger, so I&#39;ll probably use medium/something else from now on, and just link here)</summary><link rel='replies' type='application/atom+xml' href='http://yaroslavvb.blogspot.com/feeds/5553983325212368022/comments/default' title='Post Comments'/><link rel='replies' type='text/html' href='http://www.blogger.com/comment.g?blogID=10560800&amp;postID=5553983325212368022' title='224 Comments'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/5553983325212368022'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/5553983325212368022'/><link rel='alternate' type='text/html' href='http://yaroslavvb.blogspot.com/2017/10/optimizing-deeper-networks-with-kfac-in.html' title=' Optimizing deeper networks with KFAC in PyTorch.'/><author><name>Yaroslav Bulatov</name><uri>http://www.blogger.com/profile/06139256691290554110</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='24' height='32' src='http://3.bp.blogspot.com/_bx6Dx71KhWU/TGIERDKa7JI/AAAAAAAAABs/FMguoAgVdRA/S220/me.gif'/></author><thr:total>224</thr:total></entry><entry><id>tag:blogger.com,1999:blog-10560800.post-2510000814735912906</id><published>2016-05-18T10:23:00.000-07:00</published><updated>2016-05-18T10:23:04.629-07:00</updated><title type='text'>Queues in TensorFlow</title><summary type="text">I did an introduction to Queues talk at TensorFlow meetup in SF yesterday.



Here are the slides and the notebook: https://github.com/yaroslavvb/stuff/tree/master/queues_talk</summary><link rel='replies' type='application/atom+xml' href='http://yaroslavvb.blogspot.com/feeds/2510000814735912906/comments/default' title='Post Comments'/><link rel='replies' type='text/html' href='http://www.blogger.com/comment.g?blogID=10560800&amp;postID=2510000814735912906' title='601 Comments'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/2510000814735912906'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/2510000814735912906'/><link rel='alternate' type='text/html' href='http://yaroslavvb.blogspot.com/2016/05/queues-in-tensorflow.html' title='Queues in TensorFlow'/><author><name>Yaroslav Bulatov</name><uri>http://www.blogger.com/profile/06139256691290554110</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='24' height='32' src='http://3.bp.blogspot.com/_bx6Dx71KhWU/TGIERDKa7JI/AAAAAAAAABs/FMguoAgVdRA/S220/me.gif'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://3.bp.blogspot.com/-WmRGKSxZ16o/VzykhXWXWtI/AAAAAAAEZLg/P4cNqkFKP9E5Zk2Gv-TMIMobjIFvhpsOwCK4B/s72-c/Screen%2BShot%2B2016-05-18%2Bat%2B10.20.30%2BAM.png" height="72" width="72"/><thr:total>601</thr:total></entry><entry><id>tag:blogger.com,1999:blog-10560800.post-1815251316830832590</id><published>2015-05-12T16:36:00.001-07:00</published><updated>2015-05-12T16:36:27.558-07:00</updated><title type='text'>ICLR 2015</title><summary type="text">Some ICLR posters that caught my eye:




[larger image]
Very simple to implement idea that gives impressive results. They force two groups of units to be uncorrelated by penalizing their cross covariance. When the first group is also forced to model classes, the second group automatically models the &quot;style&quot;. The problem if separating out &quot;style&quot; has been studied for a while, see  Tenenbaum&#39;s &quot;</summary><link rel='replies' type='application/atom+xml' href='http://yaroslavvb.blogspot.com/feeds/1815251316830832590/comments/default' title='Post Comments'/><link rel='replies' type='text/html' href='http://www.blogger.com/comment.g?blogID=10560800&amp;postID=1815251316830832590' title='946 Comments'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/1815251316830832590'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/1815251316830832590'/><link rel='alternate' type='text/html' href='http://yaroslavvb.blogspot.com/2015/05/iclr-2015_12.html' title='ICLR 2015'/><author><name>Yaroslav Bulatov</name><uri>http://www.blogger.com/profile/06139256691290554110</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='24' height='32' src='http://3.bp.blogspot.com/_bx6Dx71KhWU/TGIERDKa7JI/AAAAAAAAABs/FMguoAgVdRA/S220/me.gif'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://2.bp.blogspot.com/-ENyqNcUsysA/VVJ6UPaLGzI/AAAAAAAALww/B4-o1ovZ19s/s72-c/1.jpg" height="72" width="72"/><thr:total>946</thr:total></entry><entry><id>tag:blogger.com,1999:blog-10560800.post-7029508944358036453</id><published>2014-03-05T12:11:00.001-08:00</published><updated>2014-03-05T14:02:01.571-08:00</updated><title type='text'>Stochastic Gradient Methods 2014</title><summary type="text">Last week I attended Stochastic Gradient Methods workshop held at UCLA&#39;s IPAM . Surprisingly, there&#39;s still quite a bit of activity and unsolved questions around what is essentially, minimizing a quadratic function.

In 2009 Strohmer and Vershinin rediscovered an algorithm used for solving linear systems of equations from 1970 -- Kaczmarz method, and showed that this algorithm is a form of </summary><link rel='replies' type='application/atom+xml' href='http://yaroslavvb.blogspot.com/feeds/7029508944358036453/comments/default' title='Post Comments'/><link rel='replies' type='text/html' href='http://www.blogger.com/comment.g?blogID=10560800&amp;postID=7029508944358036453' title='207 Comments'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/7029508944358036453'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/7029508944358036453'/><link rel='alternate' type='text/html' href='http://yaroslavvb.blogspot.com/2014/03/stochastic-gradient-methods-2014.html' title='Stochastic Gradient Methods 2014'/><author><name>Yaroslav Bulatov</name><uri>http://www.blogger.com/profile/06139256691290554110</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='24' height='32' src='http://3.bp.blogspot.com/_bx6Dx71KhWU/TGIERDKa7JI/AAAAAAAAABs/FMguoAgVdRA/S220/me.gif'/></author><thr:total>207</thr:total></entry><entry><id>tag:blogger.com,1999:blog-10560800.post-2577362389303014412</id><published>2013-12-06T02:11:00.002-08:00</published><updated>2014-03-02T08:54:05.791-08:00</updated><title type='text'>Deep Learning Internship at Google, Summer 2014</title><summary type="text">We have a couple of internship openings for someone to train deep neural nets find extract interesting things in StreetView imagery. The ideal person would come and push the envelope of what&#39;s possible with large amount of training data (billions of labeled image examples for some tasks), and large amount of computation power data (essentially unlimited when you parallelize).

If you are </summary><link rel='replies' type='application/atom+xml' href='http://yaroslavvb.blogspot.com/feeds/2577362389303014412/comments/default' title='Post Comments'/><link rel='replies' type='text/html' href='http://www.blogger.com/comment.g?blogID=10560800&amp;postID=2577362389303014412' title='74 Comments'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/2577362389303014412'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/2577362389303014412'/><link rel='alternate' type='text/html' href='http://yaroslavvb.blogspot.com/2013/12/deep-learning-internship-at-google.html' title='Deep Learning Internship at Google, Summer 2014'/><author><name>Yaroslav Bulatov</name><uri>http://www.blogger.com/profile/06139256691290554110</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='24' height='32' src='http://3.bp.blogspot.com/_bx6Dx71KhWU/TGIERDKa7JI/AAAAAAAAABs/FMguoAgVdRA/S220/me.gif'/></author><thr:total>74</thr:total></entry><entry><id>tag:blogger.com,1999:blog-10560800.post-1430768426325198816</id><published>2012-10-30T14:35:00.002-07:00</published><updated>2012-10-30T14:35:47.615-07:00</updated><title type='text'>Summer Intern opening</title><summary type="text">We are looking for a summer intern to apply Deep Learning techniques to the problem of reading text in the wild. More details here</summary><link rel='replies' type='application/atom+xml' href='http://yaroslavvb.blogspot.com/feeds/1430768426325198816/comments/default' title='Post Comments'/><link rel='replies' type='text/html' href='http://www.blogger.com/comment.g?blogID=10560800&amp;postID=1430768426325198816' title='42 Comments'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/1430768426325198816'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/1430768426325198816'/><link rel='alternate' type='text/html' href='http://yaroslavvb.blogspot.com/2012/10/summer-intern-opening.html' title='Summer Intern opening'/><author><name>Yaroslav Bulatov</name><uri>http://www.blogger.com/profile/06139256691290554110</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='24' height='32' src='http://3.bp.blogspot.com/_bx6Dx71KhWU/TGIERDKa7JI/AAAAAAAAABs/FMguoAgVdRA/S220/me.gif'/></author><thr:total>42</thr:total></entry><entry><id>tag:blogger.com,1999:blog-10560800.post-3802708886693327086</id><published>2012-05-01T20:53:00.000-07:00</published><updated>2012-05-01T20:54:07.027-07:00</updated><title type='text'>The Average Font</title><summary type="text">I came across this post post where the author created a font by averaging together all fonts on his machine. I thought it would be cool to do the same for all fonts on the internet -- here&#39;s the average of about 375k distinct fonts




It&#39;s interesting that shapes are clearly seen even though fonts on the web are quite noisy, here&#39;s a random sample of things that make up the A above

</summary><link rel='replies' type='application/atom+xml' href='http://yaroslavvb.blogspot.com/feeds/3802708886693327086/comments/default' title='Post Comments'/><link rel='replies' type='text/html' href='http://www.blogger.com/comment.g?blogID=10560800&amp;postID=3802708886693327086' title='40 Comments'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/3802708886693327086'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/3802708886693327086'/><link rel='alternate' type='text/html' href='http://yaroslavvb.blogspot.com/2012/05/average-font.html' title='The Average Font'/><author><name>Yaroslav Bulatov</name><uri>http://www.blogger.com/profile/06139256691290554110</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='24' height='32' src='http://3.bp.blogspot.com/_bx6Dx71KhWU/TGIERDKa7JI/AAAAAAAAABs/FMguoAgVdRA/S220/me.gif'/></author><thr:total>40</thr:total></entry><entry><id>tag:blogger.com,1999:blog-10560800.post-6304110592998816522</id><published>2011-11-21T22:23:00.001-08:00</published><updated>2011-11-21T22:29:29.146-08:00</updated><title type='text'>Interesting papers coming up at NIPS&#39;11</title><summary type="text">There&#39;s a number of accepted papers whose camera-ready versions have been posted already. Here are the ones I found interesting. I&#39;ll give further update on these after the conference.


Efficient Inference in Fully Connected CRFs with Gaussian Edge Potentials, P. Krähenbühl, V. Koltun

Fast and Accurate k-means For Large Datasets, M. Shindler, A. Wong, A. Meyerson

Hashing Algorithms for </summary><link rel='replies' type='application/atom+xml' href='http://yaroslavvb.blogspot.com/feeds/6304110592998816522/comments/default' title='Post Comments'/><link rel='replies' type='text/html' href='http://www.blogger.com/comment.g?blogID=10560800&amp;postID=6304110592998816522' title='56 Comments'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/6304110592998816522'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/6304110592998816522'/><link rel='alternate' type='text/html' href='http://yaroslavvb.blogspot.com/2011/11/interesting-papers-coming-up-at-nips11.html' title='Interesting papers coming up at NIPS&#39;11'/><author><name>Yaroslav Bulatov</name><uri>http://www.blogger.com/profile/06139256691290554110</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='24' height='32' src='http://3.bp.blogspot.com/_bx6Dx71KhWU/TGIERDKa7JI/AAAAAAAAABs/FMguoAgVdRA/S220/me.gif'/></author><thr:total>56</thr:total></entry><entry><id>tag:blogger.com,1999:blog-10560800.post-8870314489439247400</id><published>2011-11-13T22:39:00.001-08:00</published><updated>2011-11-14T11:03:31.680-08:00</updated><title type='text'>Shapecatcher</title><summary type="text">




Here&#39;s a cool tool I stumbled across reading John Cook&#39;s blog -- Shape Catcher looks up Unicode value from a drawing of a character.



Apparently it uses Shape Context features.



This motivated me to put together another dataset, unlike notMNIST this focuses on the tail end of Unicode, this is 370k bitmaps representing 29k Unicode values, grouped by Unicode 
Unicode 370k</summary><link rel='replies' type='application/atom+xml' href='http://yaroslavvb.blogspot.com/feeds/8870314489439247400/comments/default' title='Post Comments'/><link rel='replies' type='text/html' href='http://www.blogger.com/comment.g?blogID=10560800&amp;postID=8870314489439247400' title='37 Comments'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/8870314489439247400'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/8870314489439247400'/><link rel='alternate' type='text/html' href='http://yaroslavvb.blogspot.com/2011/11/shapecatcher.html' title='Shapecatcher'/><author><name>Yaroslav Bulatov</name><uri>http://www.blogger.com/profile/06139256691290554110</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='24' height='32' src='http://3.bp.blogspot.com/_bx6Dx71KhWU/TGIERDKa7JI/AAAAAAAAABs/FMguoAgVdRA/S220/me.gif'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://2.bp.blogspot.com/-MniB2Rzb_AQ/TsFWvfMRBjI/AAAAAAAAAHw/peJiiYMmJ_Q/s72-c/Screen%2Bshot%2B2011-11-14%2Bat%2B9.57.34%2BAM.png" height="72" width="72"/><thr:total>37</thr:total></entry><entry><id>tag:blogger.com,1999:blog-10560800.post-1603248061403845397</id><published>2011-11-09T13:17:00.000-08:00</published><updated>2011-11-13T17:55:06.918-08:00</updated><title type='text'>Google1000 dataset</title><summary type="text">


This is a dataset of scans of 1000 public domain books that was released to the public at ICDAR 2007.
At the time there was no public serving infrastructure, so few people actually got the 120GB dataset.
It has since been hosted on Google Cloud Storage and made available for public download


http://commondatastorage.googleapis.com/books/icdar2007/README.txt
http://</summary><link rel='replies' type='application/atom+xml' href='http://yaroslavvb.blogspot.com/feeds/1603248061403845397/comments/default' title='Post Comments'/><link rel='replies' type='text/html' href='http://www.blogger.com/comment.g?blogID=10560800&amp;postID=1603248061403845397' title='34 Comments'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/1603248061403845397'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/1603248061403845397'/><link rel='alternate' type='text/html' href='http://yaroslavvb.blogspot.com/2011/11/google1000-dataset_09.html' title='Google1000 dataset'/><author><name>Yaroslav Bulatov</name><uri>http://www.blogger.com/profile/06139256691290554110</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='24' height='32' src='http://3.bp.blogspot.com/_bx6Dx71KhWU/TGIERDKa7JI/AAAAAAAAABs/FMguoAgVdRA/S220/me.gif'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://3.bp.blogspot.com/-jsG6AcxcgUo/TrrsCqNcNMI/AAAAAAAAAHk/4vV16HB6zvM/s72-c/Screen%2Bshot%2B2011-11-09%2Bat%2B1.08.27%2BPM.png" height="72" width="72"/><thr:total>34</thr:total></entry><entry><id>tag:blogger.com,1999:blog-10560800.post-7865189674426685465</id><published>2011-11-06T23:01:00.000-08:00</published><updated>2011-11-06T23:03:05.519-08:00</updated><title type='text'>b-matching as improvement of kNN</title><summary type="text">Below is an illustration of b-matching from  (Huang,Jebara AISTATS 2007)  paper. You start with a weighted graph and the goal is to connect each v to k u&#39;s to minimize total edge cost. If v&#39;s represent labelled datapoints, u&#39;s unlabeled and weights correspond to distances, this works as a robust version of kNN classifier (k=2 in the picture) because it prevents any datapoint from exhibiting too </summary><link rel='replies' type='application/atom+xml' href='http://yaroslavvb.blogspot.com/feeds/7865189674426685465/comments/default' title='Post Comments'/><link rel='replies' type='text/html' href='http://www.blogger.com/comment.g?blogID=10560800&amp;postID=7865189674426685465' title='52 Comments'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/7865189674426685465'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/7865189674426685465'/><link rel='alternate' type='text/html' href='http://yaroslavvb.blogspot.com/2011/11/b-matching-as-improvement-of-knn.html' title='b-matching as improvement of kNN'/><author><name>Yaroslav Bulatov</name><uri>http://www.blogger.com/profile/06139256691290554110</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='24' height='32' src='http://3.bp.blogspot.com/_bx6Dx71KhWU/TGIERDKa7JI/AAAAAAAAABs/FMguoAgVdRA/S220/me.gif'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://1.bp.blogspot.com/--MumbdCcsq0/Trd_w4E4dYI/AAAAAAAAAHY/I8HGh5nTP0I/s72-c/Screen%2Bshot%2B2011-11-06%2Bat%2B10.44.23%2BPM.png" height="72" width="72"/><thr:total>52</thr:total></entry><entry><id>tag:blogger.com,1999:blog-10560800.post-1913671509611268521</id><published>2011-10-25T21:07:00.000-07:00</published><updated>2011-10-26T11:43:54.839-07:00</updated><title type='text'>Google Internship in Vision/ML</title><summary type="text">My group has intern openings for winter and summer. Winter may be too late (but if you really want winter, ping me and I&#39;ll find out feasibility). We use OCR for Google Books, frames from YouTube videos, spam images, unreadable PDFs encountered by the crawler, images from Google&#39;s StreetView cameras, Android and few other areas. Recognizing individual character candidates is a key step in OCR </summary><link rel='replies' type='application/atom+xml' href='http://yaroslavvb.blogspot.com/feeds/1913671509611268521/comments/default' title='Post Comments'/><link rel='replies' type='text/html' href='http://www.blogger.com/comment.g?blogID=10560800&amp;postID=1913671509611268521' title='523 Comments'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/1913671509611268521'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/1913671509611268521'/><link rel='alternate' type='text/html' href='http://yaroslavvb.blogspot.com/2011/10/google-internship-in-visionml.html' title='Google Internship in Vision/ML'/><author><name>Yaroslav Bulatov</name><uri>http://www.blogger.com/profile/06139256691290554110</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='24' height='32' src='http://3.bp.blogspot.com/_bx6Dx71KhWU/TGIERDKa7JI/AAAAAAAAABs/FMguoAgVdRA/S220/me.gif'/></author><thr:total>523</thr:total></entry><entry><id>tag:blogger.com,1999:blog-10560800.post-5971713134997549505</id><published>2011-09-24T12:25:00.000-07:00</published><updated>2011-09-24T19:03:39.826-07:00</updated><title type='text'>Don&#39;t test for exact equality of floating point numbers</title><summary type="text">
A discussion came up on Guido von Rossum&#39;s Google Plus post. It comes down to the fact that 2.1 is not exactly represented as a floating point number. Internally it&#39;s 2.0999999999999996, and this causes unexpected behavior.

These kinds of issues often come up. The confusion is caused by treating floating point numbers as exact numbers, and expecting calculations with them to produce results </summary><link rel='replies' type='application/atom+xml' href='http://yaroslavvb.blogspot.com/feeds/5971713134997549505/comments/default' title='Post Comments'/><link rel='replies' type='text/html' href='http://www.blogger.com/comment.g?blogID=10560800&amp;postID=5971713134997549505' title='66 Comments'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/5971713134997549505'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/5971713134997549505'/><link rel='alternate' type='text/html' href='http://yaroslavvb.blogspot.com/2011/09/dont-use-exact-equality-with-floating.html' title='Don&#39;t test for exact equality of floating point numbers'/><author><name>Yaroslav Bulatov</name><uri>http://www.blogger.com/profile/06139256691290554110</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='24' height='32' src='http://3.bp.blogspot.com/_bx6Dx71KhWU/TGIERDKa7JI/AAAAAAAAABs/FMguoAgVdRA/S220/me.gif'/></author><thr:total>66</thr:total></entry><entry><id>tag:blogger.com,1999:blog-10560800.post-6380637522936189490</id><published>2011-09-08T22:45:00.000-07:00</published><updated>2011-09-08T23:05:49.461-07:00</updated><title type='text'>notMNIST dataset</title><summary type="text">I&#39;ve taken some publicly available fonts and extracted glyphs from them to make a dataset similar to MNIST. There are 10 classes, with letters A-J taken from different fonts.

Here are some examples of letter &quot;A&quot;


Judging by the examples, one would expect this to be a  harder task than MNIST. This seems to be the case -- logistic regression on top of stacked auto-encoder with fine-tuning gets </summary><link rel='replies' type='application/atom+xml' href='http://yaroslavvb.blogspot.com/feeds/6380637522936189490/comments/default' title='Post Comments'/><link rel='replies' type='text/html' href='http://www.blogger.com/comment.g?blogID=10560800&amp;postID=6380637522936189490' title='1044 Comments'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/6380637522936189490'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/6380637522936189490'/><link rel='alternate' type='text/html' href='http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html' title='notMNIST dataset'/><author><name>Yaroslav Bulatov</name><uri>http://www.blogger.com/profile/06139256691290554110</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='24' height='32' src='http://3.bp.blogspot.com/_bx6Dx71KhWU/TGIERDKa7JI/AAAAAAAAABs/FMguoAgVdRA/S220/me.gif'/></author><thr:total>1044</thr:total></entry><entry><id>tag:blogger.com,1999:blog-10560800.post-6270374438911760263</id><published>2011-08-16T19:54:00.000-07:00</published><updated>2011-08-17T00:24:58.342-07:00</updated><title type='text'>Making self-contained Unix programs with CDE</title><summary type="text">In the old days you could statically link your program and run it on another Unix station without worrying about dependencies. Unfortunately static linking no longer works, so you need to make sure that your target platform has the right libraries.For instance, in order to get Matlab compiled code running on a server, you have to copy over libraries and set environment variables as specified </summary><link rel='replies' type='application/atom+xml' href='http://yaroslavvb.blogspot.com/feeds/6270374438911760263/comments/default' title='Post Comments'/><link rel='replies' type='text/html' href='http://www.blogger.com/comment.g?blogID=10560800&amp;postID=6270374438911760263' title='33 Comments'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/6270374438911760263'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/6270374438911760263'/><link rel='alternate' type='text/html' href='http://yaroslavvb.blogspot.com/2011/08/making-self-contained-unix-programs.html' title='Making self-contained Unix programs with CDE'/><author><name>Yaroslav Bulatov</name><uri>http://www.blogger.com/profile/06139256691290554110</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='24' height='32' src='http://3.bp.blogspot.com/_bx6Dx71KhWU/TGIERDKa7JI/AAAAAAAAABs/FMguoAgVdRA/S220/me.gif'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://2.bp.blogspot.com/-j5RnwrbXISQ/TkteSz0daUI/AAAAAAAAAG0/vHT4HnD_8KI/s72-c/INIT.GIF" height="72" width="72"/><thr:total>33</thr:total></entry><entry><id>tag:blogger.com,1999:blog-10560800.post-8438166030503417500</id><published>2011-07-13T01:52:00.000-07:00</published><updated>2011-07-14T20:01:31.138-07:00</updated><title type='text'>Google+ ML people</title><summary type="text">Google+ seems to have a fair number of Machine Learning people, I was able to track down 50 people I&#39;ve met at conferences by starting at Andrew McCallum&#39;s circles. If you add me on Google Circles I&#39;ll assume you came from this blog and add you to my &quot;Machine Learning&quot; circle</summary><link rel='replies' type='application/atom+xml' href='http://yaroslavvb.blogspot.com/feeds/8438166030503417500/comments/default' title='Post Comments'/><link rel='replies' type='text/html' href='http://www.blogger.com/comment.g?blogID=10560800&amp;postID=8438166030503417500' title='38 Comments'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/8438166030503417500'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/8438166030503417500'/><link rel='alternate' type='text/html' href='http://yaroslavvb.blogspot.com/2011/07/google-ml-people.html' title='Google+ ML people'/><author><name>Yaroslav Bulatov</name><uri>http://www.blogger.com/profile/06139256691290554110</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='24' height='32' src='http://3.bp.blogspot.com/_bx6Dx71KhWU/TGIERDKa7JI/AAAAAAAAABs/FMguoAgVdRA/S220/me.gif'/></author><thr:total>38</thr:total></entry><entry><id>tag:blogger.com,1999:blog-10560800.post-7633989648266744620</id><published>2011-06-25T22:33:00.001-07:00</published><updated>2011-07-14T20:16:58.126-07:00</updated><title type='text'>Embracing non-determinism</title><summary type="text">Computers are supposed to be deterministic. This is often the case for single processor machines. However, as you scale up, guaranteeing determinism becomes increasingly expensive.Even on single processor machines you are facing non-determinism on semi-regular basis. Here are some examples Bugs + poor OS memory control that allows programs to read uninitialized memory. A recent example for me was</summary><link rel='replies' type='application/atom+xml' href='http://yaroslavvb.blogspot.com/feeds/7633989648266744620/comments/default' title='Post Comments'/><link rel='replies' type='text/html' href='http://www.blogger.com/comment.g?blogID=10560800&amp;postID=7633989648266744620' title='27 Comments'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/7633989648266744620'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/7633989648266744620'/><link rel='alternate' type='text/html' href='http://yaroslavvb.blogspot.com/2011/06/embracing-non-determinism.html' title='Embracing non-determinism'/><author><name>Yaroslav Bulatov</name><uri>http://www.blogger.com/profile/06139256691290554110</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='24' height='32' src='http://3.bp.blogspot.com/_bx6Dx71KhWU/TGIERDKa7JI/AAAAAAAAABs/FMguoAgVdRA/S220/me.gif'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://3.bp.blogspot.com/-6TXc1Vy2D0Q/TgbJ6M6KzKI/AAAAAAAAACs/zuuPsw6xkEA/s72-c/burning-hard-drive.jpg" height="72" width="72"/><thr:total>27</thr:total></entry><entry><id>tag:blogger.com,1999:blog-10560800.post-4934083198091321883</id><published>2011-06-22T10:10:00.000-07:00</published><updated>2011-06-22T11:04:20.411-07:00</updated><title type='text'>Machine Learning opportunities at Google</title><summary type="text">Google is hiring and there are lots of opportunities to do Machine Learning-related work here. Kevin Murphy is applying Bayesian methods to video recommendation, Andrew Ng is working on a neural network that can run on millions of cores, and that&#39;s just the tip of the iceberg that I&#39;ve discovered working here for last 3 months.There is machine learning work in both &quot;researcher&quot; and &quot;engineer&quot; </summary><link rel='replies' type='application/atom+xml' href='http://yaroslavvb.blogspot.com/feeds/4934083198091321883/comments/default' title='Post Comments'/><link rel='replies' type='text/html' href='http://www.blogger.com/comment.g?blogID=10560800&amp;postID=4934083198091321883' title='79 Comments'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/4934083198091321883'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/4934083198091321883'/><link rel='alternate' type='text/html' href='http://yaroslavvb.blogspot.com/2011/06/machine-learning-opportunities-at.html' title='Machine Learning opportunities at Google'/><author><name>Yaroslav Bulatov</name><uri>http://www.blogger.com/profile/06139256691290554110</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='24' height='32' src='http://3.bp.blogspot.com/_bx6Dx71KhWU/TGIERDKa7JI/AAAAAAAAABs/FMguoAgVdRA/S220/me.gif'/></author><thr:total>79</thr:total></entry><entry><id>tag:blogger.com,1999:blog-10560800.post-3390642347975977336</id><published>2011-04-30T13:47:00.000-07:00</published><updated>2011-05-01T10:30:22.434-07:00</updated><title type='text'>Neural Networks making a come-back?</title><summary type="text">Five years ago I ran some queries on Google Scholar to see trends on the number of papers that mention particular phrase. The number of hits for each year was divided by the number of hits for &quot;machine learning&quot;. Back then it looked like NN&#39;s started gaining in popularity with invention of back-propagation in 1980&#39;s, peaked in 1993 and went downhill from there.Since then, there&#39;s been several </summary><link rel='replies' type='application/atom+xml' href='http://yaroslavvb.blogspot.com/feeds/3390642347975977336/comments/default' title='Post Comments'/><link rel='replies' type='text/html' href='http://www.blogger.com/comment.g?blogID=10560800&amp;postID=3390642347975977336' title='249 Comments'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/3390642347975977336'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/3390642347975977336'/><link rel='alternate' type='text/html' href='http://yaroslavvb.blogspot.com/2011/04/neural-networks-making-come-back.html' title='Neural Networks making a come-back?'/><author><name>Yaroslav Bulatov</name><uri>http://www.blogger.com/profile/06139256691290554110</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='24' height='32' src='http://3.bp.blogspot.com/_bx6Dx71KhWU/TGIERDKa7JI/AAAAAAAAABs/FMguoAgVdRA/S220/me.gif'/></author><thr:total>249</thr:total></entry><entry><id>tag:blogger.com,1999:blog-10560800.post-6060120941658754484</id><published>2011-04-29T22:28:00.001-07:00</published><updated>2011-04-29T22:56:53.789-07:00</updated><title type='text'>Another ML blog</title><summary type="text">I just noticed that Justin Domke has a blog -- He&#39;s one of the strongest researchers in the field of graphical models. I first came across his dissertation when looking for a way to improve loopy-Belief Propagation based training. His thesis gives one such idea -- instead of maximizing the fit of an intractable model, and using BP as intermediate step, maximize the fit of BP marginals directly. </summary><link rel='replies' type='application/atom+xml' href='http://yaroslavvb.blogspot.com/feeds/6060120941658754484/comments/default' title='Post Comments'/><link rel='replies' type='text/html' href='http://www.blogger.com/comment.g?blogID=10560800&amp;postID=6060120941658754484' title='53 Comments'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/6060120941658754484'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/6060120941658754484'/><link rel='alternate' type='text/html' href='http://yaroslavvb.blogspot.com/2011/04/another-ml-blog.html' title='Another ML blog'/><author><name>Yaroslav Bulatov</name><uri>http://www.blogger.com/profile/06139256691290554110</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='24' height='32' src='http://3.bp.blogspot.com/_bx6Dx71KhWU/TGIERDKa7JI/AAAAAAAAABs/FMguoAgVdRA/S220/me.gif'/></author><thr:total>53</thr:total></entry><entry><id>tag:blogger.com,1999:blog-10560800.post-1041951345399867160</id><published>2011-03-13T21:13:00.000-07:00</published><updated>2011-03-13T22:00:04.334-07:00</updated><title type='text'>Going to Google</title><summary type="text">I&#39;ve accepted an offer from Google and will be joining  their Tesseract team next week.I first got interested in OCR when I faced a project at my previous job involving OCR of outdoor scenes and found it to be a very complex task, yet highly rewarding because it&#39;s easy to make incremental progress and see your learners working.Current state-of-the-art OCR tools are not at human level of reading, </summary><link rel='replies' type='application/atom+xml' href='http://yaroslavvb.blogspot.com/feeds/1041951345399867160/comments/default' title='Post Comments'/><link rel='replies' type='text/html' href='http://www.blogger.com/comment.g?blogID=10560800&amp;postID=1041951345399867160' title='51 Comments'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/1041951345399867160'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/1041951345399867160'/><link rel='alternate' type='text/html' href='http://yaroslavvb.blogspot.com/2011/03/going-to-google.html' title='Going to Google'/><author><name>Yaroslav Bulatov</name><uri>http://www.blogger.com/profile/06139256691290554110</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='24' height='32' src='http://3.bp.blogspot.com/_bx6Dx71KhWU/TGIERDKa7JI/AAAAAAAAABs/FMguoAgVdRA/S220/me.gif'/></author><thr:total>51</thr:total></entry><entry><id>tag:blogger.com,1999:blog-10560800.post-574649679618068310</id><published>2011-03-05T03:52:00.000-08:00</published><updated>2011-03-05T04:35:22.222-08:00</updated><title type='text'>Linear Programming for Maximum Independent Set</title><summary type="text">Maximum independent set, or &quot;maximum stable&quot; set is one of classical NP-complete problems described in Richard Karp&#39;s 1972 paper &quot;Reducibility Among Combinatorial Problems&quot;. Other NP-complete problems often have a simple reduction to it, for instance, p.3 of Tony Jebara&#39;s &quot;MAP Estimation, Message Passing, and Perfect Graphs&quot; shows how MAP inference in an arbitrary MRF reduces to Maximum Weight </summary><link rel='replies' type='application/atom+xml' href='http://yaroslavvb.blogspot.com/feeds/574649679618068310/comments/default' title='Post Comments'/><link rel='replies' type='text/html' href='http://www.blogger.com/comment.g?blogID=10560800&amp;postID=574649679618068310' title='252 Comments'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/574649679618068310'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/574649679618068310'/><link rel='alternate' type='text/html' href='http://yaroslavvb.blogspot.com/2011/03/linear-programming-for-maximum.html' title='Linear Programming for Maximum Independent Set'/><author><name>Yaroslav Bulatov</name><uri>http://www.blogger.com/profile/06139256691290554110</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='24' height='32' src='http://3.bp.blogspot.com/_bx6Dx71KhWU/TGIERDKa7JI/AAAAAAAAABs/FMguoAgVdRA/S220/me.gif'/></author><thr:total>252</thr:total></entry><entry><id>tag:blogger.com,1999:blog-10560800.post-1477497617535178174</id><published>2011-03-03T16:38:00.000-08:00</published><updated>2011-03-13T22:13:33.862-07:00</updated><title type='text'>Perils of floating point arithmetic</title><summary type="text">A recent discussion on stackoverflow brought up the issue of results of floating point arithmetic being non-reproducibleA reader asked what one could do to guarantee that result of floating point computation is always the same, and Daniel Lichtblau, a veteran developer at the kernel group of WRI replied that &quot;it is impossible with current hardware and software&quot;One problem is that IEEE 754 </summary><link rel='replies' type='application/atom+xml' href='http://yaroslavvb.blogspot.com/feeds/1477497617535178174/comments/default' title='Post Comments'/><link rel='replies' type='text/html' href='http://www.blogger.com/comment.g?blogID=10560800&amp;postID=1477497617535178174' title='190 Comments'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/1477497617535178174'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/10560800/posts/default/1477497617535178174'/><link rel='alternate' type='text/html' href='http://yaroslavvb.blogspot.com/2011/03/perils-of-floating-point-arithmetic.html' title='Perils of floating point arithmetic'/><author><name>Yaroslav Bulatov</name><uri>http://www.blogger.com/profile/06139256691290554110</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='24' height='32' src='http://3.bp.blogspot.com/_bx6Dx71KhWU/TGIERDKa7JI/AAAAAAAAABs/FMguoAgVdRA/S220/me.gif'/></author><thr:total>190</thr:total></entry></feed>