<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	
	xmlns:georss="http://www.georss.org/georss"
	xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#"
	>

<channel>
	<title>Kavita Ganesan, PhD </title>
	<atom:link href="https://kavita-ganesan.com/feed/" rel="self" type="application/rss+xml" />
	<link>https://kavita-ganesan.com/</link>
	<description></description>
	<lastBuildDate>Thu, 27 Oct 2022 01:49:55 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.1</generator>

<image>
	<url>https://kavita-ganesan.com/wp-content/uploads/cropped-KavitaOutdoor1-V2-1-edited-1-scaled-1-32x32.jpeg</url>
	<title>Kavita Ganesan, PhD </title>
	<link>https://kavita-ganesan.com/</link>
	<width>32</width>
	<height>32</height>
</image> 
<site xmlns="com-wordpress:feed-additions:1">137950579</site>	<item>
		<title>What are Precision &#038; Recall in Machine Learning?</title>
		<link>https://kavita-ganesan.com/precision-and-recall-machine-learning/</link>
					<comments>https://kavita-ganesan.com/precision-and-recall-machine-learning/#respond</comments>
		
		<dc:creator><![CDATA[Kavita Ganesan]]></dc:creator>
		<pubDate>Thu, 27 Oct 2022 01:42:48 +0000</pubDate>
				<category><![CDATA[AI Foundation]]></category>
		<category><![CDATA[precision]]></category>
		<category><![CDATA[recall]]></category>
		<guid isPermaLink="false">https://kavita-ganesan.com/?p=8367</guid>

					<description><![CDATA[Precision and recall are commonly used terms to assess machine learning  model performance. Learn what precision and recall are from a business perspective.]]></description>
										<content:encoded><![CDATA[
<p>Precision and recall are commonly used metrics to measure the performance of machine learning models or AI solutions in general. It helps understand how well models are making predictions.</p>



<p>Let&#8217;s use an email SPAM prediction example. Say you have a model that looks at an email and decides whether it&#8217;s SPAM or NOT SPAM.  To see how well it&#8217;s doing, you want to compare it with human-generated labels, which we will call the <em>actual labels</em>. </p>



<p>To demonstrate this, the table below shows you some actual labels and the machine (model) predicted labels.  Now we&#8217;ll assume that the <strong><em>spam</em></strong> prediction is positive, and the not spam prediction is negative.</p>



<figure class="wp-block-table aligncenter is-style-regular"><table class="has-background has-fixed-layout" style="background:linear-gradient(135deg,rgb(238,238,238) 26%,rgb(158,197,226) 100%)"><thead><tr><th><strong>Email ID</strong></th><th><strong>Actual Label</strong></th><th><strong>Machine Predicted Label</strong></th></tr></thead><tbody><tr><td><strong>Email 1</strong></td><td>Spam (positive)</td><td>Spam (positive &amp; correct)</td></tr><tr><td><strong>Email 2</strong></td><td>Spam (positive)</td><td>Not Spam (negative &amp; incorrect)</td></tr><tr><td><strong>Email 3</strong></td><td>Not Spam (negative)</td><td>Spam   (positive &amp; incorrect) </td></tr><tr><td><strong>Email 4</strong></td><td>Spam (positive)</td><td>Not Spam (negative &amp; incorrect) </td></tr></tbody></table><figcaption><em>Email spam predictions with corresponding true predictions.</em></figcaption></figure>



<h2>What is Precision in ML?</h2>



<p>Given this, intuitively, <strong>precision </strong>measures the proportion of correct positive predictions. </p>



<figure class="wp-block-image aligncenter size-large"><img decoding="async" src="http://www.opinosis-analytics.com/wp-content/uploads/2021/08/precision-and-recall-machine-learning-1024x309.png" alt="" class="wp-image-13868"/><figcaption>How precision is computed</figcaption></figure>



<p>As you can see from the table above, out of the 2 <strong>spam</strong> (positive) machine predictions, only 1 is correct. So the precision is 0.5 or 50%.</p>



<h2>What is Recall in ML?</h2>



<p><strong>Recall </strong>measures the proportion of actual positive labels correctly identified by the model. </p>



<figure class="wp-block-image aligncenter size-large"><img decoding="async" src="http://www.opinosis-analytics.com/wp-content/uploads/2021/08/recall-computing-in-machine-learning-1024x316.png" alt="recall computing in machine learning" class="wp-image-13870"/><figcaption>How recall is computed
</figcaption></figure>



<p>From the table above, notice that we have 3 actual labels that are positive, and out of that only one is correctly captured by the model. So the recall is 0.33 or 33%. </p>



<p>All in all, in the SPAM prediction example, precision is 50% and recall is 33%. </p>



<h2>What Message Do Precision and Recall Convey?</h2>



<p>What precision measures at a high level is <em>correctness</em>. What recall measures at a high level is <em>coverage</em>. For example, if precision is 98% it means that when the model says the prediction is positive, the prediction is likely accurate. A model can be overly conservative and only make limited positive predictions, resulting in high precision. In other words, it fails to make sufficient positive predictions. This is why you also need to consider recall—to ensure you&#8217;re capturing sufficient actual positives.  </p>



<p>When it comes to recall, a high recall means that the model can capture most of the positive predictions. But if a model says everything is positive regardless of underlying reasoning, the recall will be artificially high and close to perfect. That&#8217;s why you need to balance between precision and recall. You want accurate predictions, but at the same time not at the cost of missing out on too many positive predictions (false negative predictions). Ideally, you want sufficiently high precision and recall. </p>



<h2>Summary</h2>



<p>In summary,  <strong>precision </strong>measures the proportion of correct positive predictions, and <strong>recall</strong> measures the coverage of actual positive labels.  For a model to be considered &#8220;good&#8221; both precision and recall must be at acceptable levels. In the end, what&#8217;s acceptable depends on the application. </p>



<p></p>



<h2>Recommended Reading:</h2>



<ul><li><a href="https://kavita-ganesan.com/how-to-compute-precision-and-recall-for-a-multi-class-classification-problem/">How to compute precision and recall</a> </li></ul>



<div class="inherit-container-width is-layout-constrained wp-block-group"><div class="wp-block-group__inner-container">
<div class="is-layout-flex wp-container-2 wp-block-columns">
<div class="is-layout-flow wp-block-column is-vertically-aligned-center" style="flex-basis:100%"></div>
</div>
</div></div>
]]></content:encoded>
					
					<wfw:commentRss>https://kavita-ganesan.com/precision-and-recall-machine-learning/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">8367</post-id>	</item>
		<item>
		<title>The Business Case For AI: A Review by Customer Contact Week Conference &#038; Magazine</title>
		<link>https://kavita-ganesan.com/the-business-case-for-ai-review-customer-contact-week/</link>
					<comments>https://kavita-ganesan.com/the-business-case-for-ai-review-customer-contact-week/#respond</comments>
		
		<dc:creator><![CDATA[Kavita Ganesan]]></dc:creator>
		<pubDate>Wed, 26 Oct 2022 17:21:15 +0000</pubDate>
				<category><![CDATA[The Business Case For AI]]></category>
		<guid isPermaLink="false">https://kavita-ganesan.com/?p=8319</guid>

					<description><![CDATA[The Business Case for AI is perfect for AI-fanatics and AI-skeptics alike. From defining AI and its various forms, to explaining exactly how companies should approach AI to see the results they want, Kavita Ganesan’s no-fluff book helps make the AI conversation a whole lot easier.]]></description>
										<content:encoded><![CDATA[
<p>“Stop using AI.”</p>



<p>This is how Dr. Kavita Ganesan, an AI expert since 2005, begins her book The Business Case for AI. In a refreshingly direct tone, Ganesan goes on to deliver the news that, yes, you probably need to rethink your use of AI and, no, it does not need to be this difficult or this expensive. </p>



<p>While AI is a necessary tool for businesses to remain competitive, many find themselves worried about the investment, and the consequences– what if I’m using AI to solve the wrong problems? Could it really take away my job or my employees’ jobs?</p>



<p>Ganesan is a sharp but assuring voice in a field full of questions like these. “These worries are real,” she states before going on to describe exactly what you need to do to assuage them.  Throughout the book, Ganesan tells you where you can apply AI, how you can prepare your organization for it, how to invest in the right AI opportunities, and how to measure the success of your AI initiatives, almost making it sound easy. </p>



<p>The book does not go into technical language or AI-specific jargon that a CS professional might not be familiar with. Ganesan makes AI, a topic that many feel is unapproachable and a bit overwhelming, something that even<em><strong> the least tech-savvy person can grasp</strong></em>.</p>



<p>Ganesan makes <strong>AI sound not only less intimidating but ultimately worthwhile for CS teams in any sector.</strong> She explains that there is an irresistible pull for customers when an experience is personalized, and the most successful companies in the world have utilized the hyper-personalization that only AI can provide. </p>



<p>The Business Case for AI is<strong> perfect for AI-fanatics and AI-skeptics alike.</strong> From defining AI and its various forms, to explaining exactly how companies should approach AI to see the results they want, Kavita Ganesan’s no-fluff book helps make the AI conversation a whole lot easier.</p>



<blockquote class="wp-block-quote"><p>The Business Case for AI is<strong> perfect for AI-fanatics and AI-skeptics alike.</strong> From defining AI and its various forms, to explaining exactly how companies should approach AI to see the results they want, Kavita Ganesan’s no-fluff book helps make the AI conversation a whole lot easier.</p><cite>CCW Conference &amp; Magazine</cite></blockquote>



<p></p>



<p><strong>Original source: </strong><a href="https://www.customercontactweekdigital.com/ccwomen/whitepapers/four-books-authored-by-women-in-customer-experience">CCW Digital</a></p>



<p></p>



<p></p>



<h2 class="has-text-align-center"></h2>



<div class="is-layout-flex wp-container-6 wp-block-columns">
<div class="is-layout-constrained wp-block-column" style="padding-top:0px;padding-right:0px;padding-bottom:0px;padding-left:0px">
<div class="wp-block-stackable-image stk-block-image has-text-align-center stk-block stk-34201b4" data-block-id="34201b4"><style>.stk-34201b4 .stk-img-wrapper img{object-fit:fill !important}.stk-34201b4 .stk-img-wrapper img{border-radius:14px !important}</style><figure class="stk-img-wrapper stk-image--shape-stretch"><img decoding="async" loading="lazy" class="stk-img wp-image-7315" src="https://kavita-ganesan.com/wp-content/uploads/040-tx-e1648764756565.png" width="3260" height="2480" alt="AI strategy book" srcset="https://kavita-ganesan.com/wp-content/uploads/040-tx-e1648764756565.png 3260w, https://kavita-ganesan.com/wp-content/uploads/040-tx-e1648764756565-300x228.png 300w, https://kavita-ganesan.com/wp-content/uploads/040-tx-e1648764756565-1024x779.png 1024w, https://kavita-ganesan.com/wp-content/uploads/040-tx-e1648764756565-150x114.png 150w, https://kavita-ganesan.com/wp-content/uploads/040-tx-e1648764756565-768x584.png 768w, https://kavita-ganesan.com/wp-content/uploads/040-tx-e1648764756565-1536x1168.png 1536w, https://kavita-ganesan.com/wp-content/uploads/040-tx-e1648764756565-2048x1558.png 2048w" sizes="(max-width: 3260px) 100vw, 3260px" /></figure></div>
</div>



<div class="is-layout-constrained wp-block-column" style="flex-basis:60%">
<div class="wp-block-stackable-heading stk-block-heading stk-block stk-dbf0db7" id="strong-get-your-copy-today-strong" data-block-id="dbf0db7"><h2 class="stk-block-heading__text"><strong>Get Your Copy Today</strong>!</h2></div>



<div class="wp-block-stackable-text stk-block-text stk-block stk-f1e3335" data-block-id="f1e3335"><p class="stk-block-text__text"><em>Whether you want to jumpstart your AI strategy, manage your AI initiatives for better outcomes, or simply find inspiration for your own AI and machine learning applications,&nbsp;The Business Case for AI&nbsp;is your blueprint for AI success.</em></p></div>
</div>
</div>



<div class="is-content-justification-center is-layout-flex wp-container-7 wp-block-buttons">
<div class="wp-block-button"><a class="wp-block-button__link" href="http://amazon.aibusinesscasebook.com">BUY ON AMAZON</a></div>
</div>



<div class="wp-block-stackable-feature alignfull stk-block-feature stk-block stk-27ec623 is-style-horizontal" data-block-id="27ec623"><style>.stk-27ec623-container{display:flex !important}.stk-27ec623-container{align-items:flex-start !important}</style><div class="stk-content-align stk-27ec623-column alignwide stk-container stk-27ec623-container stk--no-background stk--no-padding"><div class="stk-inner-blocks stk-block-content stk-row">
<div class="wp-block-stackable-column stk-block-column stk-block-column--v2 stk-column stk-block stk-accbde2" data-block-id="accbde2"><style>.stk-accbde2{align-self:center !important}.stk-accbde2-container{display:flex !important}.stk-accbde2-inner-blocks{justify-content:flex-start !important}.stk-accbde2-container{flex-direction:column !important}</style><div class="stk-column-wrapper stk-block-column__content stk-container stk-accbde2-container stk--no-background stk--no-padding"><div class="stk-block-content stk-inner-blocks stk-accbde2-inner-blocks"></div></div></div>
</div></div></div>



<p></p>



<div class="wp-block-stackable-image-box stk-block-image-box stk-hover-parent stk-block stk-a3551ad is-style-default" data-block-id="a3551ad"><div class="stk-block-content stk-inner-blocks has-text-align-center stk-row stk-block-image-box__content">
<div class="wp-block-stackable-column stk-block-column stk-block-column--v2 stk-column stk-block stk-6cafb71" data-block-id="6cafb71"><style>.stk-6cafb71{display:flex !important}.stk-6cafb71{align-items:center !important}</style><div class="stk-column-wrapper stk-block-column__content stk-container stk-6cafb71-container stk--no-background stk--no-padding"><div class="stk-block-content stk-inner-blocks stk-6cafb71-inner-blocks">
<div class="wp-block-stackable-subtitle stk-block-subtitle stk-block stk-8888f21" data-block-id="8888f21"><style>.stk-8888f21{margin-bottom:8px !important}.stk-8888f21{opacity:0 !important}:where(.stk-hover-parent:hover,.stk-hover-parent.stk--is-hovered) .stk-8888f21{opacity:1 !important}.stk-8888f21 .stk-block-subtitle__text{color:#FFFFFF !important}</style><p class="stk-block-subtitle__text stk-subtitle has-text-color has-white-color">Subtitle for This Block</p></div>
</div></div></div>
</div></div>
]]></content:encoded>
					
					<wfw:commentRss>https://kavita-ganesan.com/the-business-case-for-ai-review-customer-contact-week/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">8319</post-id>	</item>
		<item>
		<title>What went wrong with Tay, the Twitter bot that turned racist?</title>
		<link>https://kavita-ganesan.com/tay-twitter-bot/</link>
					<comments>https://kavita-ganesan.com/tay-twitter-bot/#respond</comments>
		
		<dc:creator><![CDATA[Kavita Ganesan]]></dc:creator>
		<pubDate>Fri, 21 Oct 2022 16:09:00 +0000</pubDate>
				<category><![CDATA[AI Fails]]></category>
		<category><![CDATA[Business AI]]></category>
		<guid isPermaLink="false">https://kavita-ganesan.com/?p=8285</guid>

					<description><![CDATA[Why Tay the Twitter bot from 2016 failed and what we can learn from it. How can we generalize this to ML development best practices?]]></description>
										<content:encoded><![CDATA[
<p>Of late, we’ve been hearing about <strong>Twitter bots</strong> in the news due to the whole saga of <a href="https://techcrunch.com/2022/10/04/elon-intends-buy-twitter/">Elon Musk buying Twitter</a>. One of the reasons the deal took so long to pan out was Musk’s concerns about the number of <strong><em>spam</em></strong> bots running rampant on the platform. While Musk <a href="https://www.wsj.com/podcasts/the-journal/elon-musk-doesnt-want-to-buy-twitter-anymore/72ac2322-bb3e-4d41-8237-16e8e115d3d5">believes that bots make up more than 20%</a> of accounts on Twitter, Twitter states that the number of bots on its platform is marginal.</p>



<p>So, what’s this <em>Twitter bot </em>thing?</p>



<p>A Twitter bot is essentially a Twitter account controlled by software automation rather than an actual human. It is programmed to behave like regular Twitter accounts, liking Tweets, retweeting, and engaging with other accounts.&nbsp;</p>



<p>Twitter bots can be helpful for specific use cases, such as sending out critical alerts and announcements. On the flip side, they can also be used for nefarious purposes, such as starting a disinformation campaign. These bots can also turn nefarious when “programmed” incorrectly.&nbsp;&nbsp;</p>



<p>This is what happened with Tay, an AI Twitter bot from 2016.&nbsp;&nbsp;&nbsp;</p>



<p>Tay was an experiment at the intersection of ML, NLP, and social networks. She had the capacity to Tweet her “thoughts” and engage with her growing number of followers. While other chatbots in the past, such as <a href="https://web.njit.edu/~ronkowit/eliza.html">Eliza</a>, conducted conversations using narrow scripts, Tay was designed to learn more about language over time from its environment, allowing her to have conversations about any topic.&nbsp;</p>



<p>In the beginning, Tay engaged harmlessly with her followers with benign Tweets. However, after a few hours, Tay started tweeting highly <em>offensive</em> things, and as a result, she was shut down just sixteen hours after her launch.</p>



<p>You may wonder how can such an “error” happen so publicly. Wasn’t this bot tested? Weren’t the researchers aware that this bot was an evil, racist bot before releasing it?&nbsp;</p>



<p>These are valid questions. To get into the crux of what went wrong, let’s study some of the problems in detail and try to learn from them. This will help us all see how to handle similar challenges when deploying AI in our organizations.&nbsp;</p>



<h2>Data</h2>



<p>Data is often a big reason why AI models fail. In the case of Tay, shortly after her release,&nbsp; Twitter trolls started engaging the bot with racist, misogynistic, and anti-Semitic language. And because Tay had the capacity to learn as she went, it meant that she internalized some of the language taught by the trolls. Tay just repeated some of this language. Tay uttered bad language because she was fed bad data.</p>



<p><strong>Take note: </strong>Poor-quality, prejudiced, or downright bad training data can significantly impact how machine learning models behave. You train ML models with nonrepresentative data, and they will churn out biased predictions. If you starve models of data or feed models incomplete data, they will make random predictions instead of meaningful ones. Questionable learning/training data = questionable output.&nbsp;</p>



<blockquote class="wp-block-quote has-text-align-left is-style-plain" style="font-style:normal;font-weight:500"><p></p><p>Questionable training data = questionable ML model output&nbsp;</p><p></p></blockquote>



<figure class="wp-block-image aligncenter size-full"><a href="https://arstechnica.com/"><img decoding="async" loading="lazy" width="628" height="308" src="https://kavita-ganesan.com/wp-content/uploads/image-13.png" alt="" class="wp-image-8304" srcset="https://kavita-ganesan.com/wp-content/uploads/image-13.png 628w, https://kavita-ganesan.com/wp-content/uploads/image-13-300x147.png 300w, https://kavita-ganesan.com/wp-content/uploads/image-13-150x74.png 150w" sizes="(max-width: 628px) 100vw, 628px" /></a><figcaption>Example of Tay&#8217;s Tweet (source: <a href="https://arstechnica.com/">https://arstechnica.com/</a>)</figcaption></figure>



<p></p>



<figure class="wp-block-image aligncenter size-full is-resized"><img decoding="async" loading="lazy" src="https://kavita-ganesan.com/wp-content/uploads/image-14.png" alt="Tay twitter bot" class="wp-image-8306" width="576" height="271" srcset="https://kavita-ganesan.com/wp-content/uploads/image-14.png 748w, https://kavita-ganesan.com/wp-content/uploads/image-14-300x141.png 300w, https://kavita-ganesan.com/wp-content/uploads/image-14-150x71.png 150w" sizes="(max-width: 576px) 100vw, 576px" /><figcaption>Example of Tay&#8217;s Tweet (source: <a href="https://twitter.com/geraldmellor/status/712880710328139776?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E712880710328139776%7Ctwgr%5E19f193e907faca963bca95676c139db39fd3cce6%7Ctwcon%5Es1_&amp;ref_url=https%3A%2F%2Farstechnica.com%2Finformation-technology%2F2016%2F03%2Fmicrosoft-terminates-its-tay-ai-chatbot-after-she-turns-into-a-nazi%2F">Twitter.com</a>)</figcaption></figure>



<h2>Design&nbsp;</h2>



<p>While we don’t often relate model or solution design to erratic model behaviors, it’s often more common than you think. By design, Tay continuously learned from external input (i.e., the environment). Among all the benign Tweets that Tay consumed from her environment were also <em>abrasive</em> Tweets. The more abrasive Tweets Tay saw, the more she learned that those were typical types of responses to Tweet.&nbsp;</p>



<p>This is true of any ML model. The dominant patterns influence the predictions of the ML models. Fortunately,&nbsp; it’s not necessary for ML models to learn continuously from their environment. ML models can learn from controlled data. So, Tay’s design itself was risky.&nbsp;</p>



<p><strong>Take note:</strong> The design of your ML models impacts how it behaves in reality. So, when designing ML systems, developers and business stakeholders should consider the different ways in which the system can fail, operate suboptimally, be breached, and adjust the design accordingly. In the end, you need a fail-safe plan.&nbsp;</p>



<p>In the case of Tay,&nbsp; such thinking early on would’ve made clear that not all Tweet engagements would be benign. There could be bad actors tweeting and engaging in a highly offensive manner, not far-fetched at all from reality. The realization that the bot could be consuming bad data may have stopped the team from using data from other Twitter accounts. They may also have considered consuming data from approved Twitter accounts.&nbsp;</p>



<blockquote class="wp-block-quote"><p>The design of your ML models impacts how it behaves in reality. </p></blockquote>



<h2>Testing</h2>



<p>One of the key steps in the machine learning development lifecycle is <em>testing</em>—not just during development, but testing right before full deployment. I call this <em>post-development testing</em> (PDT).&nbsp;</p>



<figure class="wp-block-image size-large"><img decoding="async" loading="lazy" width="1024" height="606" src="https://kavita-ganesan.com/wp-content/uploads/post-development-testing-1024x606.png" alt="post-development-testing" class="wp-image-5831" srcset="https://kavita-ganesan.com/wp-content/uploads/post-development-testing-1024x606.png 1024w, https://kavita-ganesan.com/wp-content/uploads/post-development-testing-300x178.png 300w, https://kavita-ganesan.com/wp-content/uploads/post-development-testing-150x89.png 150w, https://kavita-ganesan.com/wp-content/uploads/post-development-testing-768x455.png 768w, https://kavita-ganesan.com/wp-content/uploads/post-development-testing-1536x910.png 1536w, https://kavita-ganesan.com/wp-content/uploads/post-development-testing.png 1756w" sizes="(max-width: 1024px) 100vw, 1024px" /></figure>



<p class="has-text-align-center"><strong>The ML Development Life Cycle</strong></p>



<p></p>



<p>In the case of Tay, It’s unclear how much PDT went on before releasing the bot, but obviously, it wasn’t enough! Had Tay been subjected to different types of tweet engagements during PDT, the dangers of releasing Tay would’ve become obvious.</p>



<p><strong>Take note: </strong>In practice, PDT is often overlooked due to a rush to release a new feature or product. It’s often assumed that if a model works well during development, it will naturally perform well in practice. Sadly, that’s not always the case.&nbsp;So, take note that PDT is critical when it comes to AI deployment.</p>



<p></p>



<p>During PDT, you can stress test your AI solution to find points of failure. In the case of Tay, subjecting it to different types of Twitter users (e.g., trolls, benign users, and passive aggressives) could’ve surfaced risky behaviors of the bot.&nbsp; PDT can also help evaluate your solution’s impact on relevant business metrics. For example, suppose your business metric measures speed improvement in completing a particular task. PDT can give you early insights into such metrics.&nbsp;</p>



<blockquote class="wp-block-quote"><p>During PDT, you can stress test your AI solution to find points of failure. PDT can also help evaluate your solution’s impact on relevant business metrics. </p></blockquote>



<h2>Monitoring</h2>



<p>Another critical component in the ML development lifecycle is monitoring after deployment. With Tay, monitoring the bot&#8217;s behavior eventually led to it being shut down within 24 hours of its release (side note: negative press also had a hand in it). If the bot hadn’t been monitored long after its release, this could’ve led to a whole lot more negative press and many more groups being offended.&nbsp;</p>



<p><strong>Take note: </strong>While model monitoring is often done as an afterthought, it should be prioritized before its release to end users. The initial weeks after a model’s release is the most crucial, as unpredictable behaviors not seen during testing could emerge.&nbsp;</p>



<blockquote class="wp-block-quote"><p>The initial weeks after a model’s release is the most crucial, as unpredictable behaviors not seen during testing could emerge.&nbsp;</p></blockquote>



<p></p>



<h2>Summary</h2>



<p>While what went wrong with Tay may be surprising and intriguing to many, from a machine learning best practices perspective, Tay’s behavior could’ve been predicted. Tay’s environment wasn’t always positive, and she was designed to learn from that environment which led to a perfect recipe for a dangerous experiment.&nbsp;</p>



<p>So decisions around data, model design, testing, and monitoring are critical to every AI initiative. And this is not just the responsibility of the developers but also the business stakeholders. The more thought we put into each element, the fewer the surprises and the higher the chances of a successful initiative.&nbsp;</p>



<p></p>



<p>That’s all for now!</p>



<p></p>



<div class="inherit-container-width is-layout-constrained wp-block-group has-ast-global-color-4-background-color has-background" style="border-style:dotted;border-width:1px;padding-top:10px;padding-right:10px;padding-bottom:10px;padding-left:10px"><div class="wp-block-group__inner-container">
<h2>Keep Learning From Me:</h2>



<ul><li><strong>Join my&nbsp;<a href="https://kavita-ganesan.com/blog">AI Integrated newsletter</a>,&nbsp;</strong>which clears the AI confusion and teaches you how to successfully integrate AI to achieve profitability and growth in your business.</li><li><strong>Read&nbsp;&nbsp;<a href="http://amazon.aibusinesscasebook.com/?utm_source=newsletter&amp;utm_medium=email&amp;utm_campaign=why_starting_without_ai_improves_outcomes_even_if_ai_is_your_goal&amp;utm_term=2022-08-19" target="_blank" rel="noreferrer noopener">The Business Case for AI</a></strong>&nbsp;to learn applications, strategies, and best practices to be successful with AI (select companies using the book: government agencies, automakers like Mercedes Benz, beverage makers, and e-commerce companies such as Flipkart).</li></ul>
</div></div>



<p></p>
]]></content:encoded>
					
					<wfw:commentRss>https://kavita-ganesan.com/tay-twitter-bot/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">8285</post-id>	</item>
		<item>
		<title>3 Strategic Mistakes Leaders Can Easily Avoid When Thinking About AI Integration</title>
		<link>https://kavita-ganesan.com/ai-leadership-mistakes/</link>
					<comments>https://kavita-ganesan.com/ai-leadership-mistakes/#respond</comments>
		
		<dc:creator><![CDATA[Kavita Ganesan]]></dc:creator>
		<pubDate>Fri, 09 Sep 2022 17:17:45 +0000</pubDate>
				<category><![CDATA[AI Strategy]]></category>
		<category><![CDATA[Business AI]]></category>
		<category><![CDATA[ai for leaders]]></category>
		<category><![CDATA[ai in business]]></category>
		<category><![CDATA[ai mistakes]]></category>
		<category><![CDATA[ai strategy]]></category>
		<guid isPermaLink="false">https://kavita-ganesan.com/?p=8204</guid>

					<description><![CDATA[Rushing through AI integration can result in unintended failures. Learn 3 AI integration mistakes leaders can easily avoid to limit confusion, reduce waste, and truly reap the benefits from AI.   ]]></description>
										<content:encoded><![CDATA[
<p>Several years ago, a product manager at a tech company had a <strong>data collection problem</strong>: to scrape software security vulnerability data from multiple web sources, consolidate the vulnerabilities and store them in a database.<br><br>As this was an automation problem relating to data, the product manager (PM) immediately concluded that this was a <strong><em><a href="https://kavita-ganesan.com/common-ai-problem-types-cheat-sheet/">machine learning problem</a></em></strong>. The PM then “hired” the company’s data science team to build ML models to solve the problem.&nbsp;</p>



<p>The data science team agreed to the <a href="https://kavita-ganesan.com/machine-learning-training-data-generation/">data collection task</a> without making any promises on “models.” They realized that their attempts to educate the PM that this <strong><em>was a simple script</em></strong> (not a sophisticated ML model) would be a losing battle as there was a big internal push to use AI, and the PM was sold on the idea.</p>



<p>Several weeks passed, and when the time came to “deploy” the models, there wasn’t a model to be deployed. Just a software script that would continually read specific webpages, heuristically scrape security vulnerability entries and populate them into a database.&nbsp;</p>



<p>Although the PM was eventually informed that no ML models were used or necessary, the scraping software was sold to the entire company as a machine learning powered security solution.&nbsp;</p>



<p>This is not uncommon.&nbsp;</p>



<p>Such <strong>confusion </strong>around AI and where it’s best employed happens more often than we think. In the case of this tech firm, the confusion didn’t do much damage as it was a small project, and the only thing wasted was the data science team’s precious time for that few weeks.&nbsp;&nbsp;</p>



<p>In many other situations, the damage from such miscategorization, poor understanding of AI, and the use of wrong resources can be <strong>extremely costly</strong>.</p>



<p>Imagine if the data collection problem above was <strong>forced to use machine learning</strong>, although unnecessary. Maintaining an ML solution costs much more than a simple software script. Plus, if the project had gone on for an entire year, the data scientists would have been paid to solve a problem that a single contracted software engineer could&#8217;ve solved. More importantly, these data scientists could’ve been working on high-impact AI initiatives.&nbsp;</p>



<p><br>Based on this story, let’s narrow down three strategic mistakes leaders can easily avoid to prevent confusion, reduce waste, and ensure that you’re genuinely reaping the<em> benefits from AI.</em></p>



<p></p>



<h2>3 Mistakes Leaders Can Avoid When Thinking About AI Integration</h2>



<figure class="wp-block-image aligncenter size-large"><img decoding="async" loading="lazy" width="1024" height="753" src="https://kavita-ganesan.com/wp-content/uploads/ai-leadership-mistakes-to-avoid-1024x753.png" alt="ai leadership mistakes to avoid" class="wp-image-8240" srcset="https://kavita-ganesan.com/wp-content/uploads/ai-leadership-mistakes-to-avoid-1024x753.png 1024w, https://kavita-ganesan.com/wp-content/uploads/ai-leadership-mistakes-to-avoid-300x221.png 300w, https://kavita-ganesan.com/wp-content/uploads/ai-leadership-mistakes-to-avoid-150x110.png 150w, https://kavita-ganesan.com/wp-content/uploads/ai-leadership-mistakes-to-avoid-768x565.png 768w, https://kavita-ganesan.com/wp-content/uploads/ai-leadership-mistakes-to-avoid-1536x1130.png 1536w, https://kavita-ganesan.com/wp-content/uploads/ai-leadership-mistakes-to-avoid.png 1794w" sizes="(max-width: 1024px) 100vw, 1024px" /></figure>



<p class="has-text-align-center">Summary of AI leadership mistakes to avoid</p>



<h3><strong>#1: Expecting “Others” to Understand AI</strong></h3>



<p>In 2018, industry research firm Gartner made a bold prediction—that 85% of AI projects will “not deliver.” This is a shocking prediction, given how important AI has become in recent years.&nbsp;</p>



<p>One reason for this prediction is confusion among leaders on what AI is and what it can do.</p>



<p>It&#8217;s a given that your technical teams need to understand AI. However, executives, technology leaders, and product managers looking to make AI an integral part of their business should also be well-versed with the technology.&nbsp;</p>



<p>We’re not talking about getting into AI model development. Still, you need to know AI at the <em>right level </em>to be comfortable exploring the possibility of using AI to solve business problems.&nbsp;</p>



<p>Further, this AI knowledge can be handy in several ways.</p>



<ul><li><strong>Closing AI adoption gaps: </strong>Once you understand AI, you’ll start seeing the building blocks for preparing your organization for its adoption. You’ll start noticing gaps in your company infrastructure, cultural readiness, and talent pool, allowing you to develop strategies to lay the necessary foundation.</li><li><strong>Vendor selection and hiring: </strong>The AI knowledge will also help you when talking to AI vendors and job candidates, where you’ll be able to ask the right questions, separate the good from the bad, and make sound purchase and hiring decisions.</li><li><strong>Maximize investments:</strong> A breadth of AI understanding will also help you use the proper thought process and frameworks in evaluating which problems would benefit the most from AI, helping you solve the rest of the problems with alternative approaches. With this, you’re increasing the odds of seeing meaningful results from AI.</li></ul>



<p></p>



<h5 class="has-ast-global-color-4-background-color has-background"><strong><span style="color: #ad2033;" class="stk-highlight">Take Action:</span></strong> If you’re a leader new to AI, <strong>start by building a foundation</strong> around understanding AI use cases, what it is, and what makes AI initiatives different from traditional software engineering. Understanding the <strong>misconceptions of the field</strong> and how to <strong>spot opportunities</strong> will also significantly help identify high-impact use cases. <br><br>You can get some of this information by reading <a href="https://www.google.com/search?q=ai+business+books">relevant books</a> as well as industry reports from big consulting firms. Attending AI leadership seminars and presentations can also be helpful. Podcasts? I wouldn’t recommend podcasts to build your foundation. The scattered nature of podcasts can be confusing and should be supplemental knowledge once you have a general foundation.</h5>



<h2>&nbsp;</h2>



<h3><strong>#2: Expecting a Quick Financial Return from AI&nbsp;</strong></h3>



<p>Yes, AI has the promise of cost savings and boosting revenues. Although you may observe an immediate financial impact for some problems, in most cases, you may never see a noticeable financial impact from AI, just from a single initiative.&nbsp;</p>



<p>It may take multiple related initiatives coming together to change your financial trajectory, or it&#8217;s something you’ll observe over the long haul.&nbsp;</p>



<p>So, when it comes to the ROI of AI, you need to focus on the benefits of employing AI (in the short term and long term). Ask these questions:</p>



<ul><li>What <strong>immediate pain point</strong> would the AI solution ease for your organization?</li><li>What <strong>benefits </strong>would you see by addressing the pain point?</li><li>What’s the<strong> added advantage</strong> of an AI solution over a simpler one, such as a manual approach?</li></ul>



<p>Answering such questions will clarify why AI is necessary and guide you in tracking the right business metrics</p>



<p></p>



<h5 class="has-ast-global-color-4-background-color has-background"><span style="color: #ad2033;" class="stk-highlight"><strong>Take Action:</strong> </span>When you’re looking to track the success of AI, <strong>always start with metrics that tie into its direct impact </strong>first. Once this is well underway and delivering results, track metrics that relate to the longer-term implications, which can take months or even years to observe.&nbsp;</h5>



<p></p>



<h3><strong>#3: Leaving AI Completely in the Hands of Data Scientists</strong></h3>



<p>In the rush to adopt AI, companies often start by hiring a team of data scientists. This happens long before leaders understand AI or have an AI strategy.</p>



<p>These data scientists are then let loose on the data to discover potential AI opportunities. While several identified projects may be meaningful, many are better suited for publishing a research paper—not so much for creating value for the business.<br></p>



<p>This is not entirely the fault of the data scientists. Data scientists newly brought in to solve AI problems for the company will have a limited view of the company’s business challenges.&nbsp;</p>



<p>Exploring the data tells them nothing about the process and workflow inefficiencies in the company. Further, your company may not be collecting data for problems that would most benefit from AI. Instead of twiddling thumbs, these data scientists are left with no choice but to tackle “made-up” problems with relevant data.<br></p>



<p>On the contrary, business unit leaders, executives, and domain experts deal with the organization&#8217;s daily challenges—whether it’s customer complaints, a media coverage issue, or friction in your business processes.&nbsp;</p>



<p>These employees should be equally capable of spotting opportunities for automation and workflow augmentation with AI. They should feel empowered to bring relevant business problems for data scientists to solve.&nbsp;</p>



<p>For companies to succeed with AI, there must be a deep collaboration between business leaders, domain experts, and their technical counterparts.</p>



<p></p>



<h5 class="has-ast-global-color-4-background-color has-background"><strong><span style="color: #ad2033;" class="stk-highlight">Take Action:</span></strong> When you witness <strong>process inefficiencies, repetitive manual tasks, and lagging accuracy</strong> of existing software systems, start taking note. Have your team track current baseline performance numbers and determine if the problem relates to solving a complex decision-making task. Such problems are often great candidates for AI. Involve your technical experts to help study the problem further and determine if AI is a good fit and, if not, recommend alternate approaches.&nbsp;&nbsp;</h5>



<p></p>



<h2>How Will You Accelerate Your AI Adoption?</h2>



<p>While many leaders believe that the success of AI adoption is in the excellence of their technical teams, in reality, it starts at the top.&nbsp;</p>



<p>Executives and functional leaders deal with the everyday challenges that the organization faces. With a good AI understanding, they’re better positioned to <strong>recognize problems </strong>that AI will solve and consequently <strong>fund impactful initiatives.</strong> This, coupled with the <strong>right expectations and success metrics</strong>, will translate to better outcomes for the organization.</p>



<p></p>



<p></p>



<p></p>



<div class="inherit-container-width is-layout-constrained wp-block-group has-ast-global-color-4-background-color has-background" style="border-style:dotted;border-width:1px;padding-top:10px;padding-right:10px;padding-bottom:10px;padding-left:10px"><div class="wp-block-group__inner-container">
<h2>Keep Learning From Me:</h2>



<ul><li><strong>Join my&nbsp;<a href="https://kavita-ganesan.com/blog">AI Integrated newsletter</a>,&nbsp;</strong>which clears the AI confusion and teaches you how to successfully integrate AI to achieve profitability and growth in your business.</li><li><strong>Read&nbsp;&nbsp;<a href="http://amazon.aibusinesscasebook.com/?utm_source=newsletter&amp;utm_medium=email&amp;utm_campaign=why_starting_without_ai_improves_outcomes_even_if_ai_is_your_goal&amp;utm_term=2022-08-19" target="_blank" rel="noreferrer noopener">The Business Case for AI</a></strong>&nbsp;to learn applications, strategies, and best practices to be successful with AI (select companies using the book: government agencies, automakers like Mercedes Benz, beverage makers, and e-commerce companies such as Flipkart).</li></ul>
</div></div>



<p></p>



<div class="inherit-container-width is-layout-constrained wp-block-group has-ast-global-color-2-color has-ast-global-color-4-background-color has-text-color has-background has-medium-font-size" style="border-style:solid"><div class="wp-block-group__inner-container">
<div class="inherit-container-width is-layout-constrained wp-block-group has-ast-global-color-5-background-color has-background"><div class="wp-block-group__inner-container">
<h2 style="font-style:normal;font-weight:500">Recommended Reading</h2>



<ul class="has-medium-font-size"><li><a href="https://kavita-ganesan.com/how-to-improve-ai-outcomes-in-business/">Even if AI is your goal, why start without it to improve AI success</a></li><li><a href="https://kavita-ganesan.com/common-ai-problem-types-cheat-sheet/">15 Common AI Problem Types</a></li></ul>
</div></div>
</div></div>
]]></content:encoded>
					
					<wfw:commentRss>https://kavita-ganesan.com/ai-leadership-mistakes/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">8204</post-id>	</item>
		<item>
		<title>How Sentiment Analysis Keeps Your Brand in Check (and How to Get Started)</title>
		<link>https://kavita-ganesan.com/sentiment-analysis-business-applications/</link>
					<comments>https://kavita-ganesan.com/sentiment-analysis-business-applications/#respond</comments>
		
		<dc:creator><![CDATA[Kavita Ganesan]]></dc:creator>
		<pubDate>Thu, 25 Aug 2022 16:16:47 +0000</pubDate>
				<category><![CDATA[AI Use Cases]]></category>
		<category><![CDATA[Business AI]]></category>
		<category><![CDATA[NLP Applications]]></category>
		<category><![CDATA[nlp]]></category>
		<category><![CDATA[sentiment analysis]]></category>
		<guid isPermaLink="false">https://kavita-ganesan.com/?p=8104</guid>

					<description><![CDATA[We’ve all heard of sentiment analysis, but what exactly is it and what can it do for your brand, your business, and how can you get started with it?]]></description>
										<content:encoded><![CDATA[
<p><em>We’ve all heard of sentiment analysis, but what exactly is it and what can it do for your brand, your business, and how can you get started with it?</em></p>



<p></p>


				<div class="wp-block-uagb-table-of-contents uagb-toc__align-left uagb-toc__columns-1  uagb-block-df53d82c    "
					data-scroll= "1"
					data-offset= "30"
				>
				<div class="uagb-toc__wrap">
						<div class="uagb-toc__title">
							Table Of Contents						</div>
																<div class="uagb-toc__list-wrap">
						<ol class="uagb-toc__list"><li class="uagb-toc__list"><a href="#what-is-sentiment-analysis">What is Sentiment Analysis?</a><li class="uagb-toc__list"><a href="#why-is-sentiment-analysis-important-in-business">Why is Sentiment Analysis Important in Business?</a><li class="uagb-toc__list"><a href="#how-are-businesses-using-sentiment-analysis-real-world-examples">How are Businesses Using Sentiment Analysis? (Real-World Examples)</a><li class="uagb-toc__list"><a href="#how-to-get-started-with-sentiment-analysis">How to Get Started with Sentiment Analysis</a><li class="uagb-toc__list"><a href="#keep-learning-from-me">Keep Learning From Me:</a><li class="uagb-toc__list"><a href="#recommeded-reading">Recommeded Reading</a></ol>					</div>
									</div>
				</div>
			


<p></p>



<h2>What is Sentiment Analysis?</h2>



<p>Sentiment analysis relates to analyzing content such as social media comments, customer feedback, employee feedback, and even facial expressions in images to render sentiment orientation.&nbsp;These sentiments can be as <em>broad </em>as just saying that the specific content is from a <strong>“detractor”</strong> or <strong>“promoter,”</strong> or it can be as detailed as listing out all the <strong>emotions</strong> within the content.</p>



<p></p>



<p class="has-text-align-center"><img decoding="async" loading="lazy" src="https://lh3.googleusercontent.com/ZJTsL89jkMZcNcqFzqlFEzTAVS4xymQVo-Fca_N6X5NZERsMJW3MRcwKeFtQAuyxvQFyL33Wd_Fh_1jqPsa7bcw5d2dXeu1HYBH64NzpkeU21BGZp6NahgjbryDcSKUXt4yxJZH0ntTtX_k8yqerOcs" width="624" height="371"></p>



<p class="has-text-align-center">Predicting fine-grained sentiment in images</p>



<figure class="wp-block-image aligncenter"><img decoding="async" src="https://lh4.googleusercontent.com/y1MhZlKK3AwBAHNeP5MX6w07aETHFoYaz-eoagqm6AX8pOaKuHFpe3GFFi8lQyJpfcHeTj2L1_X1AHmVsjImCGtzUQ8Ysyh460eqzAMDleT-wnaf0-dnPdT4JEiQ_UQzSgKGBgwkjYC4MeNs8Q3SR5E" alt="sentiment analysis business application examples"/><figcaption>Predicting sentiment in text data</figcaption></figure>



<p class="has-text-align-center"></p>



<h2>Why is Sentiment Analysis Important in Business?</h2>



<p>While, on the surface, sentiment analysis can seem like a fancy class project, in actuality, it has many uses in business. Let’s look at some sentiment analysis examples applied to business problems.</p>



<ol><li>You can <strong>aggregate customer sentiments from free-form feedback data </strong>and determine if your customers are primarily promoters or detractors. You can then take corrective measures to gradually <em>rebuild trust with the detractors</em> and turn them into promoters.</li><li>You can <strong>keep your online platform clean and free from bullies </strong>by detecting hateful and inappropriate comments.</li><li>You can determine <strong>which employees are demotivated </strong>or about to quit based on their outlook from recent feedback, peer reviews, and manager feedback and provide a constructive path ahead for employees to succeed at the company.</li></ol>



<p>Overall, as you can see from these sentiment analysis examples, sentiment analysis is a versatile tool that can help you better understand employees and customers, keep platforms safe, provide customers with a better shopping and product selection experience, and learn from competitor brands. </p>



<p>More importantly, when you combine <em>sentiment analysis</em> with other AI-driven technologies such as <em>text summarization,</em> you can get deeper, more powerful insights.&nbsp;</p>



<h2>How are Businesses Using Sentiment Analysis? (Real-World Examples)</h2>



<p>Now that we know what sentiment analysis can help accomplish, let’s see how three companies are using sentiment analysis for a specific business purpose.&nbsp;</p>



<h3>GAIL</h3>



<p>Great Wolf Lodge (GWL), a chain of resorts and indoor water parks, has expanded its broad digital strategy by using <a href="https://www.cio.com/article/3435118/introducing-gail-great-wolf-lodges-ai-for-pinpointing-guest-sentiment.html">AI to classify customer comments based on sentiment</a>. They developed what they call the <em>Great Wolf Lodge’s Artificial Intelligence Lexicographer (GAIL)</em>.</p>



<p>GWL capitalizes on the concept of net promoter score (NPS) to gauge the experience of individual customers. </p>



<p></p>



<p>Instead of using an NPS score to determine customer satisfaction, GAIL determines if customers are <em>net promoter</em>s, <em>detractor</em>s, or <em>neutral parties </em>based on the free-text responses posted in monthly customer surveys. This is analogous to predicting if the customer sentiment is <em>positive</em>, <em>negative</em>, or <em>neutral</em>. GAIL essentially “reads” the comments and generates an opinion.</p>



<figure class="wp-block-image aligncenter size-full"><img decoding="async" loading="lazy" width="850" height="447" src="https://kavita-ganesan.com/wp-content/uploads/image-12.png" alt="sentiment analysis business application examples" class="wp-image-8110" srcset="https://kavita-ganesan.com/wp-content/uploads/image-12.png 850w, https://kavita-ganesan.com/wp-content/uploads/image-12-300x158.png 300w, https://kavita-ganesan.com/wp-content/uploads/image-12-150x79.png 150w, https://kavita-ganesan.com/wp-content/uploads/image-12-768x404.png 768w" sizes="(max-width: 850px) 100vw, 850px" /><figcaption>Detractors, promoters, and how the NPS score is computed</figcaption></figure>



<p>Through this effort, the company hopes to understand its guests better and improve the customer experience. For example, by analyzing comments by detractors, Great Wolf Lodge would know areas in their service that need improvement.&nbsp;</p>



<p>Analyzing this unstructured data manually would take far too long for humans. However, GAIL can <em>parse this data in seconds </em>and determine whether the author is a net promoter, detractor, or neutral party.</p>



<h3>Meta</h3>



<p>Meta—with nearly 1.7 billion daily active users—naturally has content posted on the platform that violates its rules. Among this negative content is <a href="https://www.wired.com/story/facebook-ai-hate-speech-improves-unclear/"><strong>hate speech</strong></a><strong>. </strong>Defining and detecting hate speech is one of the biggest political and technical challenges for Meta and similar platforms. Detecting hate speech is a type of sentiment analysis problem focused on content with overall negative implications.&nbsp;</p>



<p>Humans review the AI-flagged posts in the same way as posts reported by users. In fact, the platform removed 9.6 million pieces of content flagged as hate speech in the first quarter of 2020 alone. While the sentiment models alone may not be sufficient to control hate speech on the platform, the tool does capture a massive number of spam posts, significantly reducing the amount of manual work by humans.</p>



<p class="has-text-align-center"><img decoding="async" loading="lazy" width="624" height="475" src="https://lh6.googleusercontent.com/IOgGQI_H1HU69ZQOM6cIUxe0w4HGkla3hremcoHR-gt9xwog8TmcE0LdpCZwlGRyidpmJcnPWQ4B9FsY8CAm9TTvIb7ic0wqOtzVDob_VOEE-nLrPKIAKZGxZ13ZQBYd9US4J5eJzpzYZbPrDyk0CEo" alt="text categorization example"></p>



<p class="has-text-align-center">The volume of AI-based hate speech removal on Facebook. Source: <a href="https://www.wired.com/story/facebook-ai-hate-speech-improves-unclear/">Wired</a></p>



<p>Detecting which content contains hate speech is a complicated problem. AI algorithms must understand the subtle meanings in text and nuances in expressions, analyze the cultural context, and then determine whether it’s offensive without incorrectly penalizing harmless content.</p>



<p class="has-text-align-center"><img decoding="async" loading="lazy" alt="text classification example" src="https://lh3.googleusercontent.com/zcnfSCER59kFxzJVZUGRiTaEJW2R8cHOzuTNvYnJFqKQ7vXiWAt1gRSIuwy94i_xX54C3ZFHb0iKWRKczGcebMlsyqqf6c_CEQYbFVdC5zdthtCYAO2U4tZnGY6wzgIqw65lbN-4iN7a7giCTqhK-Ds" width="411" height="193"><br>Example hate speech. Source: <a href="https://arxiv.org/pdf/1804.04257.pdf">arxiv.org</a></p>



<h3>Ocean Spray</h3>



<p>When the morning juice market weakened, Ocean Spray, an agricultural cooperative of cranberry and grapefruit growers, sought a new strategy to improve sales. Ocean Spray first needed to understand consumer sentiment and behaviors around cranberry juice better so that they could innovate.</p>



<p>Typically such innovation is done with the help of small focus groups of 10-15 people. However, Ocean Spray decided to leverage AI-driven analysis of thousands of online conversations, such as user reviews and tweets around cranberry juice, to really<em> listen at scale.&nbsp;</em></p>



<p>Plus, instead of just classifying content like what Meta does, Ocean Spray leveraged <em>themes</em> and <em>opinion summaries</em> to understand consumer sentiment around specific topics. Through this analysis, Ocean Spray understood how consumers were using cranberry juice in real life, giving them ideas on how best to innovate and fill gaps in the marketplace.&nbsp;</p>



<p>The research surfaced unexpected customer behaviors. For example, they found that women enjoyed cranberry juice as a substitute drink without the alcohol in place of cocktails. Such insights helped them launch<a href="https://news.oceanspray.com/2017-03-2017-Sip-Back-and-Unwind-With-a-Mocktail-Moment"> two new beverage lines</a>, boosting revenues and helping them get out of an over-saturated segment of the market.</p>



<figure class="wp-block-image aligncenter size-large is-resized"><img decoding="async" loading="lazy" src="https://kavita-ganesan.com/wp-content/uploads/sentiment-analysis-1024x1017.png" alt="" class="wp-image-8112" width="773" height="768" srcset="https://kavita-ganesan.com/wp-content/uploads/sentiment-analysis-1024x1017.png 1024w, https://kavita-ganesan.com/wp-content/uploads/sentiment-analysis-300x298.png 300w, https://kavita-ganesan.com/wp-content/uploads/sentiment-analysis-150x150.png 150w, https://kavita-ganesan.com/wp-content/uploads/sentiment-analysis-768x763.png 768w, https://kavita-ganesan.com/wp-content/uploads/sentiment-analysis.png 1224w" sizes="(max-width: 773px) 100vw, 773px" /><figcaption>A new beverage line by Ocean Spray in direct response to understanding consumer behaviors around cranberry juice. Source: <a href="https://news.oceanspray.com/2017-03-2017-Sip-Back-and-Unwind-With-a-Mocktail-Moment">oceanspray.com</a></figcaption></figure>



<p></p>



<h2>How to Get Started with Sentiment Analysis</h2>



<p>As you’ve seen in this article, sentiment analysis has many nuances—you can detect sentiments in a sentence, paragraphs of text, and even from facial expressions in images. Further, you have various ways to leverage sentiment information—from using it for new product innovation to improving the customer experience.&nbsp;</p>



<p></p>



<p>To get started with sentiment analysis, you first need to understand your business <strong>application</strong>. Consider these questions:</p>



<ul><li>What would you like to know about your brand, customers, or employees? </li><li>How granular should the information be? </li><li>Do you just need sentiment information, or textual themes and summaries?</li><li><span style="background-color: var(--ast-global-color-5); font-size: 1rem;">Are you planning to integrate the solution into your dashboards or perform an independent analysis?</span></li></ul>



<p></p>



<p>Let&#8217;s take an example. Say you need to understand the general sentiment in your company’s <em>support conversations</em>. You want to learn the ongoing “tone” and “mood” of your customers. Further, you want to visualize this within your dashboards. In such a case, you&#8217;d need to employ an <em><strong>emotion classifier</strong></em> to generate predictions on <em>relevant conversations</em>. You can then leverage those sentiments in your dashboards for downstream analysis.  </p>



<figure class="wp-block-image aligncenter size-full"><a href="https://arxiv.org/pdf/1812.01207v1.pdf"><img decoding="async" loading="lazy" width="698" height="612" src="https://kavita-ganesan.com/wp-content/uploads/sentiment-analysis-emotion-classification.png" alt="" class="wp-image-8121" srcset="https://kavita-ganesan.com/wp-content/uploads/sentiment-analysis-emotion-classification.png 698w, https://kavita-ganesan.com/wp-content/uploads/sentiment-analysis-emotion-classification-300x263.png 300w, https://kavita-ganesan.com/wp-content/uploads/sentiment-analysis-emotion-classification-150x132.png 150w" sizes="(max-width: 698px) 100vw, 698px" /></a><figcaption>Plutchik’s Wheel of Emotions. The boxed emotions are commonly used for developing emotion classifiers. Source: arxiv.org</figcaption></figure>



<p></p>



<p>Depending on your sentiment analysis problem, in some cases, you’d have to custom build the classifiers. But for others, you can leverage off-the-shelf tools such as <a href="https://medium.com/google-cloud/sentiment-analysis-using-google-cloud-machine-learning-552be9b9c39b">Google’s Natural Language API</a> or the <a href="https://perspectiveapi.com/">Perspective API</a>.</p>



<p></p>



<p>Often, for a multi-faceted analysis, you’d have to combine <strong>off-the-shelf tools with custom pipelines and analysis </strong>to help you answer all questions for optimal decision-making. This is what one of my clients did. They combined insights from an independent off-the-shelf text analytics tool such as <strong>Netbase</strong> (extremely pricey, by the way) with custom-built pipelines for a complete market research analysis.</p>



<p></p>



<p>There are endless possibilities in how you can employ these sentiment analysis tools. But remember to let the application guide the solutions that you’ll employ.</p>



<p></p>



<p>Now, over to you. What sentiment analysis applications come to mind after reading this article? What tools will you use for your analysis? </p>



<p></p>



<h2>Keep Learning From Me:</h2>



<ul><li><strong>Join my <a href="/blog">AI Integrated newsletter</a>,&nbsp;</strong>which clears the AI confusion and teaches you how to successfully integrate AI to achieve profitability and growth in your business.</li><li><strong>Read&nbsp;&nbsp;<a href="http://amazon.aibusinesscasebook.com/?utm_source=newsletter&amp;utm_medium=email&amp;utm_campaign=why_starting_without_ai_improves_outcomes_even_if_ai_is_your_goal&amp;utm_term=2022-08-19" target="_blank" rel="noreferrer noopener">The Business Case for AI</a></strong>&nbsp;to learn applications, strategies, and best practices to be successful with AI (select companies using the book:  government agencies, automakers like Mercedes Benz, beverage makers, and e-commerce companies such as Flipkart).</li></ul>



<p></p>



<h2>Recommeded Reading</h2>



<ul><li><a href="https://kavita-ganesan.com/natural-language-processing-applications/">7 NLP Applications in Business</a></li><li><a href="https://kavita-ganesan.com/common-ai-problem-types-cheat-sheet/">List of Common AI Problem Types  in Business</a></li></ul>



<p></p>



<p></p>



<p>&nbsp;</p>
]]></content:encoded>
					
					<wfw:commentRss>https://kavita-ganesan.com/sentiment-analysis-business-applications/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">8104</post-id>	</item>
		<item>
		<title>Even if AI is Your Goal, Why Starting Without AI Improves Outcomes</title>
		<link>https://kavita-ganesan.com/how-to-improve-ai-outcomes-in-business/</link>
					<comments>https://kavita-ganesan.com/how-to-improve-ai-outcomes-in-business/#respond</comments>
		
		<dc:creator><![CDATA[Kavita Ganesan]]></dc:creator>
		<pubDate>Fri, 12 Aug 2022 01:24:00 +0000</pubDate>
				<category><![CDATA[AI Strategy]]></category>
		<category><![CDATA[Business AI]]></category>
		<guid isPermaLink="false">https://kavita-ganesan.com/?p=8000</guid>

					<description><![CDATA[In this article, you’ll learn why it’s sometimes wiser to start without AI, even if your goal is to integrate AI into products, services, and workflows. You'll also learn tips for handlings AI non-readiness issues. ]]></description>
										<content:encoded><![CDATA[
<p>When it comes to software automation, many teams turn to&nbsp;AI&nbsp;as their potential answer.</p>



<p>AI&nbsp;in the form of machine learning or NLP may be an excellent solution to a problem. But did you know that the best way to&nbsp;start&nbsp;AI&nbsp;initiatives is to&nbsp;start&nbsp;with&nbsp;no&nbsp;AI&nbsp;at all?</p>



<p>This may seem counterintuitive, but there’s a simple reason for it.</p>



<p>It’s because<em>&nbsp;you may&nbsp;not&nbsp;be ready for&nbsp;AI&nbsp;as a solution</em>. There could be several missing elements that’ll prevent you from seeing success with&nbsp;AI&nbsp;if pursued prematurely.</p>



<p>When it comes to&nbsp;AI, it’s&nbsp;not&nbsp;far-fetched to say that several critical stars need to align to get results from initiatives from a usability perspective.</p>



<p>Let’s look at the reasons why it may be wiser to hold off on&nbsp;AI&nbsp;than to&nbsp;start&nbsp;with it and hit roadblocks and, later, tips for how you can eliminate those roadblocks.</p>



<h2>Why it’s Wiser to Hold Off on AI</h2>



<h3>1: You don’t yet understand the problem you’re solving</h3>



<p>Typically, when you’re trying to solve an existing problem with&nbsp;AI, the input, and the desired output are often well understood. You may be looking to&nbsp;AI&nbsp;to improve the accuracy of the existing solution or the speed of completing tasks.</p>



<p>But from my experience, a large number of problems that engineering teams and entrepreneurs are solving today are&nbsp;<em>new problems.</em>&nbsp;The problems are weakly defined, and you may&nbsp;not&nbsp;fully understand what your expected output is, let alone what you’re input into the system would be.</p>



<p>Take the problem of sentiment prediction. Do you know if you’re looking to predict broad overall sentiments (e.g., positive or negative) or more granular ones like 10% anger and 90% sadness on some given text? Are you looking to feed in paragraphs of text or just a single sentence or short snippets?</p>



<p>Yes, this is a design problem. And the right design comes from a good understanding of the problem.&nbsp;Without&nbsp;it, you’ll be battling many design dilemmas. Such design issues, along with the complexity of developing the&nbsp;AI&nbsp;systems, may require you to constantly revamp models to address design changes, introducing confusion and reducing your chances of success with&nbsp;AI.</p>



<h3>2: You may&nbsp;not&nbsp;have the necessary data</h3>



<p>As I repeatedly talk about in my&nbsp;<a href="https://kavita-ganesan.com/the-business-case-for-ai/#.YuQTgnbMJPY" target="_blank" rel="noreferrer noopener">book</a>,&nbsp;AI&nbsp;systems demand data. It’s&nbsp;not&nbsp;just data for training models but also data to better understand the problem you’re solving and the expected output from the system.</p>



<p>Often, when you have a brand new problem, this data is non-existent. Even for old problems that are being manually solved, the data may&nbsp;not&nbsp;exist or may be available in a non-accessible format. This is exactly what happened with a healthcare client. They were performing a billing annotation task for over eight years, but when came time to automate the process, the data just wasn’t there.</p>



<p>Without&nbsp;the right type of data, you won’t really know what problem you’re solving, let alone train a model.</p>



<h3>3: Your users may be skeptical of automation</h3>



<p>Let’s face it. People are suspicious of&nbsp;AI, especially those who don’t know what it is and the current state of its capabilities. The moment you talk about automation within employee workflows, some will get uncomfortable and anxious and&nbsp;start&nbsp;to worry about being replaced by the “AI&nbsp;race.”</p>



<p>People are also used to their preferred way of doing things. They worry about how their current “efficient” workflow will be affected by the integration of&nbsp;AI. Some think this new&nbsp;AI&nbsp;thing is just a gimmick. This is the exact problem I faced with the healthcare client I mentioned earlier. While the CEO was very enthusiastic about integrating&nbsp;AI&nbsp;in one specific workflow in their business, the employees were&nbsp;not&nbsp;enthusiastic and made that clear.</p>



<p>The problem with resistance to using&nbsp;AI&nbsp;is that people may&nbsp;not&nbsp;perceive the solution to be a long-term one. Further, subject matter experts who are suspicious of the automation idea may&nbsp;not&nbsp;be willing to help co-develop a working&nbsp;AI&nbsp;solution, as was the case with my healthcare client. Additional education, training, and buy-in were required to get them to see why automation would make their lives easier.&nbsp;Without&nbsp;customer buy-in,&nbsp;no&nbsp;matter how impressive the&nbsp;AI&nbsp;solution, its existence will be short-lived.</p>



<h4>So, what to give?</h4>



<p>Forcing an&nbsp;AI&nbsp;solution on people will&nbsp;not&nbsp;work…in the long term.</p>



<p>Starting&nbsp;an&nbsp;AI&nbsp;initiative&nbsp;without&nbsp;data will ensure you hit a dead end.</p>



<p>An ill-defined problem will require that you redesign your&nbsp;AI&nbsp;tool over and over again, and this can be expensive.</p>



<p>What can you do?</p>



<h2>3 Tips for Handling&nbsp;AI&nbsp;Non-Readiness</h2>



<p>Even if you’re&nbsp;not&nbsp;ready for&nbsp;AI&nbsp;today, here are three things you can do to eventually see significant benefits from&nbsp;AI&nbsp;for the problems you’ve been struggling with.</p>



<h3>1:&nbsp;Start&nbsp;with a manual or semi-automatic approach</h3>



<p>If your users are receptive to&nbsp;AI, but you don’t have the data to support the initiative, or you don’t quite understand what problem you’re solving, consider&nbsp;starting&nbsp;with a manual approach.</p>



<p>This means you put together a small team (e.g., virtual assistants for non-domain-specific problems) and have them manually execute the tasks while also storing the data from the manual execution.</p>



<p>Alternatively, if the workload is extremely high, you can consider automating the task with a less-than-ideal software automation to bring in some level of control to the task.</p>



<p>For example, if your virtual assistant is expected to analyze thousands of images to spot a stop sign. But you know that images with specific color distribution will&nbsp;not&nbsp;have a stop sign with 99% certainty. You can develop a simple software script to weed out such images from review, reducing the workload of your virtual assistants. There are many such possibilities to integrate simple software automation before introducing&nbsp;AI.</p>



<h4>Why does this work?</h4>



<ul><li>You can easily change the design of your solution until you’re comfortable.</li><li>You can keep changing the type of data you’re collecting</li><li>You can generate high-quality data for machine learning down the road</li><li>You can establish baseline metrics, which you can later compare with an&nbsp;AI-powered solution</li></ul>



<h3>2: Collect data efficiently</h3>



<p>If your only problem is the lack of data to develop your&nbsp;AI&nbsp;solution, there are ways to do this efficiently&nbsp;without&nbsp;completely spawning out a full data strategy.</p>



<p>I will&nbsp;not&nbsp;get into this in-depth in this article, as you can read my article where I talk about strategies for&nbsp;<a href="https://www.opinosis-analytics.com/blog/machine-learning-training-data/" target="_blank" rel="noreferrer noopener">generating data for your machine learning projects</a>.</p>



<h3>3: Remove adoption fears</h3>



<p>If your problem is well understood and you have the necessary data, but users want nothing to do with an automated solution, there’s much work to do on the cultural side of things.</p>



<p>You’d need to think about how to get buy-in from users, who may be your employees, customers, or even vendors.</p>



<p>The way to approach this is first to ask them what they think about automating specific tasks. If you sense resistance, you’d want to understand their worries and fear. This will give you a sense of what your emphasis would be when you’re trying to “sell” them a solution.</p>



<p>If the worry is&nbsp;<a href="https://kavita-ganesan.com/will-ai-kill-your-job/" target="_blank" rel="noreferrer noopener"><em>fear of job loss</em></a>, you can show employees how the nature of their work will change or be simplified with the integration of&nbsp;AI.</p>



<p>If the fear is potential rigidity in workflows, you can educate users about how you’re&nbsp;not&nbsp;just developing a solution in the dark but rather co-developing one with them (the users) to ensure that they’re happy with it and it’s truly solving a pain point.</p>



<h4>Why does this work?</h4>



<ul><li>By actively removing fears and seeking feedback, you’re fostering collaboration.</li><li>The more collaboration between potential consumers of&nbsp;AI, business stakeholders, designers, and developers, the better the solution and the higher the chances of&nbsp;AI&nbsp;adoption.</li></ul>



<h2>Last Word</h2>



<p>As you’ve seen in this article, although your business problem may be a good candidate for&nbsp;AI, you may&nbsp;not&nbsp;be ready to&nbsp;start&nbsp;with&nbsp;AI.</p>



<p>There’s a high likelihood that you lack the data for the initiative, may&nbsp;not&nbsp;understand the problem well, and your users may&nbsp;not&nbsp;be ready for an automated solution. The workaround to this is&nbsp;not&nbsp;to&nbsp;start&nbsp;with&nbsp;AI—but to&nbsp;start&nbsp;without&nbsp;it. Solve the foundational issues using simple but effective approaches.</p>



<p>That’s all for now.</p>



<p></p>



<h2>To Keep Learning From Me:</h2>



<ul><li><strong>Join my&nbsp;<a href="https://kavita-ganesan.com/blog">AI Integrated newsletter</a>,&nbsp;</strong>which clears the AI confusion and teaches you how to successfully integrate AI to achieve profitability and growth in your business.</li><li><strong>Read&nbsp;&nbsp;<a href="http://amazon.aibusinesscasebook.com/?utm_source=newsletter&amp;utm_medium=email&amp;utm_campaign=why_starting_without_ai_improves_outcomes_even_if_ai_is_your_goal&amp;utm_term=2022-08-19" target="_blank" rel="noreferrer noopener">The Business Case for AI</a></strong>&nbsp;to learn applications, strategies, and best practices to be successful with AI (get 3 free chapters <a href="https://kavita-ganesan.com/the-business-case-for-ai/">here</a>).</li><li><strong><a href="/contact-me">Send me a message</a> </strong>for a more customized roadmap and AI strategy for your business</li></ul>



<h2>Recommened Articles</h2>



<ul><li><a href="https://kavita-ganesan.com/will-ai-kill-your-job/">Will AI Really Kill Your Job?</a></li><li><a href="https://kavita-ganesan.com/machine-learning-training-data-generation/">5 Strategies for Generating Data for AI</a></li></ul>



<p></p>
]]></content:encoded>
					
					<wfw:commentRss>https://kavita-ganesan.com/how-to-improve-ai-outcomes-in-business/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">8000</post-id>	</item>
		<item>
		<title>15 Common AI Problem Types</title>
		<link>https://kavita-ganesan.com/common-ai-problem-types-cheat-sheet/</link>
					<comments>https://kavita-ganesan.com/common-ai-problem-types-cheat-sheet/#respond</comments>
		
		<dc:creator><![CDATA[Kavita Ganesan]]></dc:creator>
		<pubDate>Fri, 29 Jul 2022 01:48:00 +0000</pubDate>
				<category><![CDATA[Business AI]]></category>
		<guid isPermaLink="false">https://kavita-ganesan.com/?p=6982</guid>

					<description><![CDATA[One of the problems business leaders face in communicating with their technical counterparts is trying to describe their AI problem. To simplify some of the communication, here are some common AI problem types.]]></description>
										<content:encoded><![CDATA[
<p>One of the problems business leaders face in communicating with their technical counterparts is trying to describe their AI problem. To simplify some of the communication, here are some common AI problem types.</p>



<p>Try to map AI opportunities at hand to these common problem types. Note that the problem types often overlap—but that’s ok. The key is to identify problem types that most closely match the task at hand when communicating with your AI and data science experts.</p>


				<div class="wp-block-uagb-table-of-contents uagb-toc__align-left uagb-toc__columns-2  uagb-block-ee02ff97    "
					data-scroll= "1"
					data-offset= "30"
				>
				<div class="uagb-toc__wrap">
						<div class="uagb-toc__title">
							Table Of Contents						</div>
																<div class="uagb-toc__list-wrap">
						<ol class="uagb-toc__list"><li class="uagb-toc__list"><a href="#common-ai-problem-types">Common AI Problem Types</a><ul class="uagb-toc__list"><li class="uagb-toc__list"><a href="#1-classification">1. Classification</a><li class="uagb-toc__list"><a href="#2-regression">2. Regression</a><li class="uagb-toc__list"><a href="#3-recommendation">3. Recommendation</a><li class="uagb-toc__list"><a href="#4-search-relevance">4. Search Relevance</a><li class="uagb-toc__list"><a href="#5-information-extraction-ie">5. Information Extraction (IE)</a><li class="uagb-toc__list"><a href="#6-text-summarization">6. Text Summarization</a><li class="uagb-toc__list"><a href="#7-clustering">7. Clustering</a><li class="uagb-toc__list"><a href="#9-virtual-ai-assistant">9. Virtual AI Assistant</a><li class="uagb-toc__list"><a href="#10-sentiment-analysis">10. Sentiment Analysis</a><li class="uagb-toc__list"><a href="#11-object-detection">11. Object Detection</a><li class="uagb-toc__list"><a href="#12-document-segmentation-problem">12. Document Segmentation Problem</a><li class="uagb-toc__list"><a href="#13-keyword-extraction">13. Keyword Extraction</a><li class="uagb-toc__list"><a href="#14-speech-recognition">14. Speech Recognition</a><li class="uagb-toc__list"><a href="#15-machine-translation">15. Machine Translation</a><li class="uagb-toc__list"><a href="#summary-of-ai-problem-types">Summary of AI Problem Types</a><li class="uagb-toc__list"><a href="#other-articles-you-may-be-interested-in">Other Articles You May Be Interested In:</a></li></ul></ol>					</div>
									</div>
				</div>
			


<p></p>



<h2 id="0-common-ai-problem-types">Common AI Problem Types</h2>



<h3 id="1-1-classification-"><strong>1. Classification </strong></h3>



<p>A <strong>classification</strong> problem is about assigning one or more categories to a document, product, person, or image—essentially anything. Examples include:</p>



<ul><li>Categorizing incoming support tickets by relevant topics</li><li><a href="https://www.opinosis-analytics.com/blog/ai-in-manufacturing-examples" data-type="post" data-id="14192">Classifying images of silicon wafers </a>as containing defects or no defects</li></ul>



<div class="wp-block-image">
<figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" class="wp-image-10572" src="https://www.opinosis-analytics.com/wp-content/uploads/2020/07/big_data_strategy_ticket_routing-1024x717.png" alt="Big data strategy" width="536" height="375">
<figcaption>Example of support ticket classification</figcaption>
</figure>
</div>



<h3 id="2-2-regression-"><strong>2. Regression</strong></h3>



<p>A <strong>regression problem</strong> is about estimating <em>numerical</em> values given some input. For example, trying to predict the number of months before a machine needs service given the conditions of the current machine, or predicting how specific drug dosage affects blood pressure.&nbsp;</p>



<div class="wp-block-image">
<figure class="aligncenter size-full"><img decoding="async" loading="lazy" class="wp-image-14923" src="https://www.opinosis-analytics.com/wp-content/uploads/2021/12/machine-learning-regression.png" alt="" width="500" height="337">
<p>&nbsp;</p>
<figcaption>Predicting a person’s weight given their height—a regression problem. Source: <a href="https://online.stat.psu.edu/stat500/book/export/html/478" target="_blank" rel="noreferrer noopener">stat.psu.edu</a></figcaption>
</figure>
</div>



<h3 id="3-3-recommendation-"><strong>3. Recommendation</strong></h3>



<p>A <strong>r</strong><strong style="font-size: 1rem;">ecommendation problem </strong><span style="font-size: 1rem;">is about providing personalized content or products to a group of people.&nbsp;</span>Examples include:</p>



<ul><li>Product recommendation</li><li>Recommendations on who to follow</li><li>Recommendations on jobs to apply for</li><li>Recommendations on articles to read</li></ul>



<div class="wp-block-image">
<figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" class="wp-image-14926" src="https://www.opinosis-analytics.com/wp-content/uploads/2021/12/topics-to-follow-—-recommendations-1024x655.png" alt="" width="700" height="448">
<p>&nbsp;</p>
<figcaption>Recommendations of topics to follow on Twitter. Source: twitter.com</figcaption>
</figure>
</div>



<h3 id="4-4-search-relevance-"><strong>4. Search Relevance</strong></h3>



<p>A <strong>search relevance</strong> problem is about <span style="font-size: 1rem;">improving the rankings of search results shown to users.</span> Often search relevance improvement starts with the analysis of search logs to diagnose problems using hard data. Search improvement may or may not require heavy use of machine learning.</p>



<h3 id="5-5-information-extraction-ie"><strong>5. Information Extraction</strong> (IE)</h3>



<p>An<strong> information extraction</strong> problem is about extracting specific information from large volumes of text data. One of the goals of information extraction is to fill templates using data extracted from raw text. Examples include:</p>



<ul><li>Extracting patient symptoms from large volumes of clinical notes</li><li>Extracting pertinent information from large volumes of legal case files</li><li>Pre-populating a candidate application form / database by extracting pertinent information from resumes</li></ul>



<h3 id="6-6-text-summarization-"><strong>6. Text Summarization</strong></h3>



<p><strong>Text summarization </strong>is about creating an accurate synopsis of a longer document or a set of documents.&nbsp;</p>



<div class="wp-block-image">
<figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" class="wp-image-14941" src="https://www.opinosis-analytics.com/wp-content/uploads/2021/12/review-summarization-1024x609.png" alt="" width="599" height="356">
<p>&nbsp;</p>
<figcaption>An example of review summarization</figcaption>
</figure>
</div>



<h3 id="7-7-clustering-"><strong>7. Clustering</strong></h3>



<p><strong>Clustering</strong>&nbsp;is about grouping people, content, documents, topics and etc&nbsp;based on some logical structure—for example, grouping customers by their purchase behavior.&nbsp;</p>



<p>More generally,&nbsp;clustering divides data points into a number of fixed (or dynamic)&nbsp;groups such that the data points in one group are more similar to each other&nbsp;than data points in other groups.&nbsp;</p>



<h3 id="8-9-virtual-ai-assistant-"><strong>9. Virtual AI Assistant</strong></h3>



<p><strong>Virtual AI Assistant </strong>is used for having short conversations with humans to complete simple tasks. Examples include:</p>



<ul><li>Providing answers to common customer questions without human involvement</li><li>Using text messages to check bank balances or to get a refund</li></ul>



<p>Alexa and Siri are examples of virtual AI assistants.</p>



<h3 id="9-10-sentiment-analysis-"><strong>10. Sentiment Analysis</strong></h3>



<p><strong style="font-size: 1rem;"><a href="https://kavita-ganesan.com/sentiment-analysis-business-applications/#.Y0C-Z-zMJhE">Sentiment Analysis</a> </strong><span style="font-size: 1rem;">is about discovering emotions in text data such as user reviews, social media comments, and surveys. For example, automatically detecting customer sentiment in social media channels after a new product release.</span> Sentiment analysis can even be applied to images for understanding emotions from&nbsp;facial expressions.</p>



<h3 id="10-11-object-detection-"><strong>11. Object Detection</strong></h3>



<p><strong style="font-size: 1rem;">Object detection problem </strong><span style="font-size: 1rem;">is about discovering specific objects such as humans, buildings, or cars in digital images and videos.</span></p>



<div class="wp-block-image">
<figure class="aligncenter size-large"><img decoding="async" loading="lazy" class="wp-image-14917" src="https://www.opinosis-analytics.com/wp-content/uploads/2021/12/object-detection-1024x538.jpeg" alt="" width="1024" height="538">
<p>&nbsp;</p>
<figcaption>Example of object detection—automatically detecting people, traffic lights, personal accessories, and vehicles given an image. Source: <a href="https://infotech.report/guest-articles/real-time-object-detection-in-video-with-intro-to-yolo-v3" target="_blank" rel="noreferrer noopener">infotech.report</a></figcaption>
</figure>
</div>



<h3 id="11-12-document-segmentation-problem-"><strong>12. Document Segmentation Problem</strong></h3>



<p><strong>Document segmentation</strong> is about trying to subdivide documents into meaningful parts. For example, segmenting unstructured clinical texts to extract their past medical history and family history.&nbsp;</p>



<div class="wp-block-image">
<figure class="aligncenter size-large"><img decoding="async" loading="lazy" class="wp-image-14915" src="https://www.opinosis-analytics.com/wp-content/uploads/2021/12/document-segmentation-1024x677.png" alt="" width="1024" height="677">
<p>&nbsp;</p>
<figcaption>Example segmentation of a clinical record</figcaption>
</figure>
</div>



<h3 id="12-13-keyword-extraction-"><strong>13. Keyword Extraction</strong></h3>



<p><strong>Keyword extraction</strong> <span style="font-size: 1rem;">is about identifying terms that best describe the subject of a document—for example, extracting keywords from large volumes of legal documents to understand the themes of discussion.</span></p>



<p>While there are many keyword extraction tools readily available (including open-source tools), you’d need to ensure that these work on your data. Often, keyword extraction tools are best customized or custom-developed.</p>



<h3 id="13-14-speech-recognition-"><strong>14. Speech Recognition</strong></h3>



<p>Speech recognition, also known as speech-to-text (STT) or automatic speech recognition (ASR), is about having a computer program understand and transform spoken language into a written format (or text).</p>



<p>Speech recognition is often used to complete downstream tasks. For example, speech recognition is used behind the scenes to surface relevant search results when you use Google voice search. Specifically, your speech is translated into a human-readable format, and that generated text is used to surface relevant search results.</p>



<p>Many vendors offer speech recognition solutions, and therefore, speech recognition systems rarely need to be developed from scratch. Of course, these systems will benefit from customization for the target data.</p>



<h3 id="14-15-machine-translation-"><strong>15. Machine Translation</strong></h3>



<p><a href="https://www.opinosis-analytics.com/blog/nlp-applications/#3-machine-translation">Machine translation</a> is the automatic software translation of text from one language to another. For example, translating English sentences into German with reasonable accuracy.&nbsp;Machine translation programs rarely need to be developed from scratch but may benefit from customization.</p>



<p>Machine translation is used for many purposes, including:</p>



<ul><li>Localizing website text for a particular country</li><li>Customer support conversations across countries</li><li>Understanding documents written in a different language</li><li>&nbsp;</li></ul>



<h3 id="15-summary-of-ai-problem-types">Summary of AI Problem Types</h3>



<p>In this short guide, we discussed 15 common AI problems types—that often overlap. For example, you can apply a classification approach for sentiment analysis. However, the key is to identify the problem type that best fits the task at hand. It doesn’t have to be 100% accurate—it’s just semantics. You can continually refine these definitions with the help of your AI experts.</p>



<p></p>



<p></p>



<div class="inherit-container-width is-layout-constrained wp-block-group has-ast-global-color-4-background-color has-background" style="border-style:dotted;border-width:1px;padding-top:10px;padding-right:10px;padding-bottom:10px;padding-left:10px"><div class="wp-block-group__inner-container">
<h2>Keep Learning From Me:</h2>



<ul><li><strong>Join my&nbsp;<a href="https://kavita-ganesan.com/blog">AI Integrated newsletter</a>,&nbsp;</strong>which clears the AI confusion and teaches you how to successfully integrate AI to achieve profitability and growth in your business.</li><li><strong>Read&nbsp;&nbsp;<a href="http://amazon.aibusinesscasebook.com/?utm_source=newsletter&amp;utm_medium=email&amp;utm_campaign=why_starting_without_ai_improves_outcomes_even_if_ai_is_your_goal&amp;utm_term=2022-08-19" target="_blank" rel="noreferrer noopener">The Business Case for AI</a></strong>&nbsp;to learn applications, strategies, and best practices to be successful with AI (select companies using the book: government agencies, automakers like Mercedes Benz, beverage makers, and e-commerce companies such as Flipkart).</li></ul>
</div></div>



<p></p>



<h3>Other Articles You May Be Interested In:</h3>



<ul><li><a href="https://kavita-ganesan.com/tay-twitter-bot/#.Y1nTYOzMJhE">What Happened to Tay the Twitter Bot that Turned Racist?</a></li><li><a href="https://kavita-ganesan.com/ai-leadership-mistakes/">3 Mistakes Leaders Should Avoid When Integrating AI</a></li></ul>
]]></content:encoded>
					
					<wfw:commentRss>https://kavita-ganesan.com/common-ai-problem-types-cheat-sheet/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">6982</post-id>	</item>
		<item>
		<title>4 Business AI Predictions for 2022-2023</title>
		<link>https://kavita-ganesan.com/ai-predictions/</link>
					<comments>https://kavita-ganesan.com/ai-predictions/#respond</comments>
		
		<dc:creator><![CDATA[Kavita Ganesan]]></dc:creator>
		<pubDate>Tue, 28 Jun 2022 23:59:21 +0000</pubDate>
				<category><![CDATA[AI Strategy]]></category>
		<category><![CDATA[Business AI]]></category>
		<guid isPermaLink="false">https://kavita-ganesan.com/?p=7159</guid>

					<description><![CDATA[Having worked with numerous clients, big and small in the integration of AI, here are 4 Business AI predictions in 2022 and beyond.]]></description>
										<content:encoded><![CDATA[
<p>AI as a field, especially in the context of real-world applications, has been progressing at a rapid pace. This has been further accelerated by the onset of the COVID-19 pandemic. In fact, AI was found to be the<a href="https://www.tvtechnology.com/news/artificial-intelligence-was-the-most-discussed-technology-of-2021"> most discussed technology</a> in 2021. Having worked with numerous clients, big and small, in the integration of AI, here are 4 Business AI predictions in 2022 and beyond.</p>



<h2><strong>#1 Many more “deployed” models</strong></h2>



<p>In the recent past, businesses have had trouble operationalizing models and have not seen the value in many of their AI initiatives. In fact, <a href="https://www.gartner.com/en/newsroom/press-releases/2020-10-19-gartner-identifies-the-top-strategic-technology-trends-for-2021">Gartner’s research </a>shows that <em>only</em> 53% of AI initiatives make it from prototype to production.</p>



<p>However, with the recent growth in the number of ML deployment platforms, low-code and no-code AI development services, and AI vendors providing out-of-the-box AI solutions, such as speech recognition, sentiment analysis, and ticket routing, we will start witnessing many more real-world applications of AI.</p>



<h2><strong>#2 The rise of problem-focused practitioners</strong></h2>



<p>While the focus of AI as a field has been strongly techniques-focused, business practitioners are slowly beginning to realize that the latest and greatest techniques <em>may not necessarily work</em> from a practical standpoint for many use cases. There is a fundamental difference between techniques that are still in “research mode” versus those that have been tried and tested.</p>



<p>Even though in the past, data scientists have taken pride in using the most sophisticated techniques to demonstrate expertise, data scientists are becoming more <em>problem-focused.</em> They’re adopting simpler techniques that will have a higher chance of success for real-world use cases. This change in thinking will improve the outcomes of many AI initiatives.</p>



<h2><strong>#3 </strong><strong><em>Accountable AI</em></strong><strong> will gain steam</strong></h2>



<p>With all the Facebook drama and regulations around AI still being limited and “in the talks”, more and more businesses are becoming aware of the problems with algorithms. Unless algorithms are used responsibly with downstream and long-term impact in mind, it’s clear that they can do significant damage. To that end, I’m seeing many data scientists and leaders talk about the ethics and implications of algorithms.</p>



<p>I believe that informal conversations around AI ethics are just the beginning. Some of these discussions will turn into action where businesses will start having their <em>own committees</em> to vet AI systems rigorously. Some will even study potential societal impact before the release of specific technologies—regardless of regulations. Regulations will only add another layer of oversight, especially for companies that have yet to take AI ethics and accountability seriously.</p>



<h2><strong>#4 </strong><strong><em>Underserved </em></strong><strong>industries will start adopting AI</strong></h2>



<p>AI has largely been a winning tool for large tech companies. But the stress caused by the COVID-19 pandemic, such as the shrinking labor force participation, workers not wanting to work on the front lines, social distancing requirements and others have forced many companies that used to rely heavily on the availability of workers to <em>rethink </em>their business models.</p>



<p>From allowing employees to work remotely, to automating away jobs that no human worker wants to do, are all options on the table for serious consideration. As part of this, AI will be a critical player in changing businesses forever.&nbsp; Hospitals, manufacturers, and restaurant chains will all be at the crossroads of technology transformations.</p>



<h1><strong>Summary</strong></h1>



<p>While AI within business applications was a new concept several years ago, as you can see from these predictions that it’s becoming more mainstream and achievable. The growth of AI deployment and development platforms, mindset changes, and stress caused by the COVID-19 pandemic will all be true catalysts in making AI a reality for businesses.</p>



<p>The post <a href="https://www.opinosis-analytics.com/blog/2022-2023-business-ai-predictions" rel="nofollow">4 Business AI Predictions for 2022-2023</a> appeared first on <a href="https://www.opinosis-analytics.com" rel="nofollow">Opinosis Analytics</a>.</p>



<p><a href="https://www.opinosis-analytics.com/blog/2022-2023-business-ai-predictions" target="_blank" rel="noopener">4 Business AI Predictions for 2022-2023</a></p>
]]></content:encoded>
					
					<wfw:commentRss>https://kavita-ganesan.com/ai-predictions/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">7159</post-id>	</item>
		<item>
		<title>What is AI? And what does it mean for me and the world?</title>
		<link>https://kavita-ganesan.com/what-is-ai-and-what-does-it-mean-for-me-and-the-world/</link>
					<comments>https://kavita-ganesan.com/what-is-ai-and-what-does-it-mean-for-me-and-the-world/#respond</comments>
		
		<dc:creator><![CDATA[Kavita Ganesan]]></dc:creator>
		<pubDate>Tue, 24 May 2022 14:20:43 +0000</pubDate>
				<category><![CDATA[Podcast Interview]]></category>
		<guid isPermaLink="false">https://kavita-ganesan.com/?p=7453</guid>

					<description><![CDATA[What is AI? And what does it mean for me and the world? A Podcast Interview: Kavita Ganesan &#038; David Gee. ]]></description>
										<content:encoded><![CDATA[
<p><em>Listen to my interview with the  <strong><a href="https://www.audible.com/pd/Insatiably-Curious-Podcast-Podcast/B08JJN4W7Z">Insatiably Curious Podcast</a> </strong>host, David Gee.</em> <em>Transcript of the podcast is as below.</em></p>



<p>00:07</p>



<p>Welcome to the <strong>Insatiably Curious Podcast</strong>, where we invite lifelong learners to join us on a personal and professional journey. Now here to inform, entertain and enlighten, while always keeping it interesting from our nation&#8217;s capital. It&#8217;s your host, David Gee.</p>



<p><strong>David Gee&nbsp; </strong>00:26</p>



<p>Joining us today so glad to have her, Kavita Ganesan&#8230; She is the author of <strong><em>&#8220;The Business Case for AI: A Leader&#8217;s Guide to AI Strategies, Best Practices &amp; Real-World Applications.&#8221;</em></strong> Welcome to the show, Kavita.</p>



<p><strong>Kavita Ganesan&nbsp; </strong>00:40</p>



<p>Yes, thank you for having me, David.</p>



<p><strong>David Gee&nbsp; </strong>00:41</p>



<p>So one of the things when we have broad complicated topics, and I certainly think this qualifies&#8230; I like to kind of set the landscape or the ground rules a little bit to make sure we&#8217;re talking about the same thing or that we even know, in some cases, what we are talking about it.</p>



<p>So we&#8217;re talking about Artificial Intelligence, AI, how it informs the kinds of decisions we can make it work. But why don&#8217;t you give us the layman&#8217;s definition of what it is we&#8217;re talking about, and maybe second to that the difference between how you might use it in your computer science lab in an academic or research setting and how I might use it at my office or IBM or something like that.</p>



<p><strong>Kavita Ganesan&nbsp; </strong>01:33</p>



<p>Yes, so AI is all about trying to mimic human decision making, within a computer. And using software programs. And the way AI systems today work is by learning from data. So let&#8217;s take a credit card. Let&#8217;s say you&#8217;re trying to detect fraudulent transactions, credit card transactions. So the way that AI systems today learn is by looking at 1000s of different examples of what makes a transaction fraudulent, or non-fraudulent. And then it mines the patterns [phonetic 02:09] from that. And then the next time it sees a new transaction, it then decides, hey, this seems suspicious. So it might be fraudulent. So that&#8217;s how systems today learn. But historically, they have been very rules based. And in the future, it may not even be data dependent anymore.</p>



<p>So right now it&#8217;s highly data dependent. And from a business perspective, AI systems are very good in improving efficiency of workflows. So let&#8217;s say, right now, your customer service agent is manually routing tickets to the appropriate teams to get things resolved. So if you put an AI system there, it can do that very efficiently, 24 hours a day, and maybe even more accurately than your human agent.</p>



<p>But from a research perspective, in a research lab, that&#8217;s not how we look at things, we are not looking at what benefits that can be to a business. So we are thinking about how can we get better? How can technique-2 become better than technique-1. So we are always looking at incremental improvements, either through better data or better techniques. So we&#8217;re always trying to beat the state of the art. So it&#8217;s kind of different, what happens in the research world versus what&#8217;s happening in the business world. And the business we have to be completely focused on the applications of it, how it&#8217;s going to help us.</p>



<p><strong>David Gee&nbsp; </strong>03:40</p>



<p>There&#8217;s probably not a day that goes by that I don&#8217;t come across AI and in Washington Post, New York Times, Wall Street Journal, you know, whatever your source of news is. It&#8217;s certainly on the minds of business leaders today, is it currently in the state that we use it today as it is a kind of the purview of large corporations, IBM&#8217;s and Googles and in Tesla&#8217;s, or are you seeing the use of AI filtered down to more medium sized businesses or even in some cases, small businesses?</p>



<p><strong>Kavita Ganesan&nbsp; </strong>04:24</p>



<p>So there are two groups that I see, that have really embraced AI, and that&#8217;s the large corporations. And that&#8217;s specifically on the tech sector, not in other industries, and startups&#8230;. This AI startup are very good using AI and they&#8217;re very efficient because they&#8217;re small, they&#8217;re nimble, they know how to adopt new technologies and just run with it. And then the large corporations on the tech side, they are already very AI driven. Their infrastructure is set up for AI. So these two groups are running fast with AI but I think that&#8217;s the group in between the midsize businesses, they are thinking about AI, but they just don&#8217;t know how to get started. Because there&#8217;s so much of confusion in the media, like what&#8217;s happening in research gets overstated as the current capabilities.</p>



<p><strong>David Gee&nbsp; </strong>05:16</p>



<p>In your book, you talk about some of the myths, conceptions and the myths around AI that we should all be aware of&#8230; Why don&#8217;t you specifically outline a couple of them or predominant ones?</p>



<p><strong>Kavita Ganesan&nbsp; </strong>05:30</p>



<p>Yes, sure. So the first myth that people think is that they need to use the latest and greatest technique that the media is talking about. But really, the latest and greatest techniques are very still in the r&amp;d phase. And they may not fit in within your infrastructure, you may have an old infrastructure that can maybe take in basic computer algorithms, not something sophisticated that needs GPUs, and TPUs. And you have to keep in mind that AI has been there since the 1940s. So the techniques are already very old, it&#8217;s only become popular now because of the computation power that we have. So using any one of those techniques that can benefit your business, is a good technique. So not to worry about what&#8217;s being discussed in the media.</p>



<p><strong>David Gee&nbsp; </strong>06:20</p>



<p>I don&#8217;t necessarily want to make this a history lesson, but you just told me something I absolutely was not aware of. And that is 7 decades give or take of AI. So without supercomputers and the computational power that we have today, how was AI used in the 1940s, the 1950s, I&#8217;m fascinated by that.</p>



<p><strong>Kavita Ganesan&nbsp; </strong>06:44</p>



<p>Yes, so back in the days, it was like heavily rules base, you have to encode human knowledge in the form of specific rules. And they also had started neural networks research long ago, but that research stopped because insufficient computation power. And then he picked up again, I think, around 2011, when big data became a thing, then we had lots of faster computation power, and then it just accelerated from that. And neural networks now has become deep learning. And that&#8217;s a big field of study now.</p>



<p><strong>David Gee&nbsp; </strong>07:19</p>



<p>You talk again, in your book about the 5 basic pillars of AI preparation and AI landscape, why don&#8217;t you go into a little bit of those, if you would, please.</p>



<p><strong>Kavita Ganesan&nbsp; </strong>07:32</p>



<p>Yes, so given how AI systems today learn, like they heavily dependent on data. So if you&#8217;re not already collecting data, or if your processes are still paper based, then data infrastructure is a big pillar in your AI preparation. And you don&#8217;t have to start off fancy, you just have to make sure that you&#8217;re doing the basics to start with, like, if you&#8217;re using paper processes, why not shift to Excel. If you&#8217;re not collecting data, think about where, which are the areas that AI could benefit, and start collecting data in those areas. So that&#8217;s one huge pillar, the data infrastructure pillar, then there is the cultural pillar. That&#8217;s like addressing some of the fears around AI, because a good percentage of Americans are fearful of AI, and&nbsp; a research has actually shown that [unintelligible 08:36] that in my book. So you want to put this fears to rest so that companies can actually start looking into the benefits of AI, as opposed to fearing AI. Then there&#8217;s also understanding what&#8217;s development around AI? Like, that&#8217;s also a cultural element. It&#8217;s very experimental. It&#8217;s very iterative. So you need to establish those cultural elements. So those are the two big pillars:</p>



<ol type="1"><li>Data</li></ol>



<p>and</p>



<ul><li>Culture.</li></ul>



<p><strong>David Gee&nbsp; </strong>09:09</p>



<p>Follow up on that fear angle, oftentimes just kind of the way that humans are wired, we fear the unknown, whatever that is. Is this what&#8217;s it at play here? Is it simply that most people don&#8217;t know enough about AI to feel comfortable with it? Or is it something kind of spookier where they envision giant super computers and robots and everybody or things like that, you know, kind of taking over the world with information and you know, brains mimicking my brain and so on. And so, you know, what, what is it that that, you know, I know you&#8217;re not a psychologist, but in your take, what is it that people fear about the subject of AI?</p>



<p><strong>Kavita Ganesan&nbsp; </strong>10:00</p>



<p>So, there are some celebrities out there that are spreading this type of information that it will take of our jobs and later humanity, it can be used for bad things. And some of it is true, like AI can be used unethically. But taking over humans, that&#8217;s untrue. Because AI systems today don&#8217;t have the common sense reasoning as humans do, they can&#8217;t read body language, they don&#8217;t natively understand emotions, they can&#8217;t read between the lines, and just connect the dots like humans can. But on very specific tasks, AI systems can be very effective, and can even surpass human accuracy.</p>



<p>So the misunderstanding is that these AI systems can become conscious like humans, and then start making decisions that can overpower humans, I&#8217;ve seen that is a real fear, really. And that actually even came up and I was trying to hire one of my narrators for my book. And she said, Hey, I was afraid to audition for this book, because there&#8217;s so much fear about AI in our community. So, it&#8217;s widespread.</p>



<p><strong>David Gee&nbsp; </strong>11:14</p>



<p>Interesting. Yeah, I can think of a couple of Hollywood movies where the machines are plotting&#8230; Ex Machina is actually one of the [unintelligible 11:23] a machine plots to take over the mind and world of the founder or the inventor of the machine. So yeah, Hollywood has definitely taken that theme. And I&#8217;m sure some media outlets as well. You talk about back to the book, you talk about what you call vanity AI, you know, anything that&#8217;s kind of in the zeitgeist or that becomes a kind of a thing will be social media or anything else. There are companies that will just kind of glom on to that not in a real authentic sense, but just to say, hey, yes, guess what, yes, we do AI too&#8230; You talk about vanity AI?</p>



<p><strong>Kavita Ganesan&nbsp; </strong>12:11</p>



<p>Yes, Vanity AI happens a lot. And a lot within large corporations, especially, because there&#8217;s a rush to adopt AI. And as that trickles down the ladder, people think that they just need to use AI, and the way companies start using AI today is just by looking at data, seeing what data is available, and then coming up with problems based on data. But the problem with that approach is that it tells you nothing about the inefficiencies within the company, like what problem really, is it solving? What pain point is it addressing? So because of that the AI projects don&#8217;t necessarily solve real business challenges. And then executives don&#8217;t see the value from it. And then they start distrusting AI as a whole, that it&#8217;s useless. It&#8217;s just hype. But really, there&#8217;s not enough planning around it for what problems are we applying AI.</p>



<p><strong>David Gee&nbsp; </strong>13:12</p>



<p>So, I&#8217;m in the content creation, marketing messaging business, and I use data all the time to inform my content, whether it be page views, or how long people engage with content, you know, downloads, you know, all those kinds of things. We have lots of ways to measure the way that people interact with our marketing with our messaging, is there do you draw a distinct line between what I would call data driven decision making and AI? Am I using AI a little bit when I make those content decisions? Or is it just something completely different?</p>



<p><strong>Kavita Ganesan&nbsp; </strong>13:57</p>



<p>Yes, that&#8217;s a great question. So AI can serve two grand purposes.</p>



<ol type="1"><li>One is to improve efficiency within businesses.</li></ol>



<ul><li>And one is to help make better decisions.</li></ul>



<p>And if you look at our data, we have a lot of structured data, things that fit neatly in an Excel spreadsheet. And then we have lots of unstructured data, like all the Twitter comments, all the documents within your company, your customer support conversations, all of that is completely unstructured. So when you&#8217;re trying to extract data-driven insights, you can&#8217;t just use your structured data, which I refer to as simple data analytics, but to make deeper decisions, like what are your customers complaining about? What&#8217;s your top wish list? You need that unstructured data and you can&#8217;t really aggregate unstructured data like you do structured data, you need some form of AI on that, and specifically, a branch of AI called natural language processing that tries to make sense of all that text data, and then extract key elements that you can later make sense of and inform decisions like, what are my customers&#8217; top points, wishlist and so on. So there&#8217;s a lot of opportunity there.</p>



<p><strong>David Gee&nbsp; </strong>15:16</p>



<p>Well, certainly that&#8230; I mean, regardless of how you achieve, it was certainly from a customer service perspective, a marketing perspective, the more we know about our audience, our prospects, our consumers, the better we&#8217;re going to be and the bigger competitive advantage we have, right? And it&#8217;s not just,</p>



<p><strong>Kavita Ganesan&nbsp; </strong>15:38</p>



<p>Yes, that&#8217;s right.</p>



<p><strong>David Gee&nbsp; </strong>15:38</p>



<p>Yes. So when you first came to University of Southern California to get a master&#8217;s in computer science, were you hearing about AI from your first day in school was AI, a big thing in the halls of computer science classes a long&#8230; a while ago.</p>



<p><strong>Kavita Ganesan&nbsp; </strong>16:00</p>



<p>So USC is a special breed, they were so much into AI, even when I joined. So, that&#8217;s how I got exposed to this whole field. I took one natural language processing class and the professor. And I was hooked. I liked it. So then I went on to doing my PhD in the field, and then became a data scientist. But within USC, AI was a big thing. Within academic institutions, AI has been a big thing since I guess long ago.</p>



<p><strong>David Gee&nbsp; </strong>16:32</p>



<p>And you&#8217;ve been at the consulting game for 15 years, give or take and working with Fortune 500 companies, as well as some smaller organizations, when you first you know&#8230; When you got your freshly minted degrees and kind of went out in the business world, were people conversing about AI? Did you have to do a lot of educating. Tell me about the landscape when you first started.</p>



<p><strong>Kavita Ganesan&nbsp; </strong>17:00</p>



<p>So when I first started, AI was not known in the industry. So I had to become a software engineer, because there was no prospect for AI right after I graduated with my master&#8217;s. So I did my PhD thinking that I&#8217;ll go into a research lab to maybe use some AI. But around 2013 is where data science started to really become a thing. So then I jumped on to the whole data science field where I could apply AI. So it&#8217;s only around 2013, 2011, where AI became a thing in the industry.</p>



<p><strong>David Gee&nbsp; </strong>17:46</p>



<p>We spent a little bit of time today talking about both the past and the future, as you look into to the future and to your crystal ball. What do you think is and conversely, is not appropriate to expect from Ai?</p>



<p><strong>Kavita Ganesan&nbsp; </strong>18:04</p>



<p>I think what we can expect is as the understanding around AI improves, I think all the midsize businesses are going to start using AI the right way. And also the non tech companies are going to start embracing AI and start seeing value from it. But in the next few years, don&#8217;t expect a conscious bot to be walking around. That&#8217;s not going to happen in the next few years. And maybe not even this whole decade. So these are the two things that are going to happen. Business are going to pick up on AI a lot more. And research is going to improve around trying to mimic like human reasoning within an AI system, but not to the point of it becoming conscious, really.</p>



<p><strong>David Gee&nbsp; </strong>18:51</p>



<p>So you do see it filtering down into the mainstream and into smaller companies, though, is that correct?</p>



<p><strong>Kavita Ganesan&nbsp; </strong>18:57</p>



<p>Definitely. Yes.</p>



<p><strong>David Gee&nbsp; </strong>18:59</p>



<p>Anything that you&#8217;re concerned about as a data scientist, as a software engineer, as someone who&#8217;s spent so much time around AI? Is there a potential? I mean, we don&#8217;t know, you know, the capacity for human beings sometimes. But is there something that you&#8217;re even as knowledgeable as you are that you&#8217;re a little fearful of?</p>



<p><strong>Kavita Ganesan&nbsp; </strong>19:22</p>



<p>So my biggest fear is one bias in data. So that can propagate through AI systems because AI systems, learn from data and bias has been shown to be very prevalent, like in facial recognition systems. So in fact, some of the big tech companies stop using facial recognition systems for law enforcement, I think?</p>



<p><strong>David Gee&nbsp; </strong>19:47</p>



<p>Right.</p>



<p><strong>Kavita Ganesan&nbsp; </strong>19:48</p>



<p>Yes. So that&#8217;s one big problem, the bias in data and the second problem is how people are using AI like we saw with Deep fakes. The recent news about Deep fakes on how people can make you say things that you didn&#8217;t really say. And then make that to be reality. So the applications of AI really needs to be regulated. Otherwise, it&#8217;s going to be used in unethical ways.</p>



<p><strong>David Gee&nbsp; </strong>20:15</p>



<p>Wow. Yes. I mean, talking about big tech and regulation. I live in Washington, DC. And that&#8217;s obviously, you know&#8211; the pages of The Washington Post all the time about how we regulate these companies and social media and that could be a whole another conversation. So thank you so much for joining us. I&#8217;ve really enjoyed it.</p>



<p><strong>Kavita Ganesan&nbsp; </strong>20:36</p>



<p>Yeah, thank you for having me, David.</p>



<p><strong>David Gee&nbsp; </strong>20:38</p>



<p>Kavita Ganesan, author of <strong><em>&#8220;<a href="https://www.amazon.com/Business-Case-Strategies-Real-World-Applications-ebook/dp/B09TRS55K8?crid=1UX93S9MHCFXF&amp;keywords=the+business+case+for+ai&amp;qid=1649883890&amp;sprefix=the+business+case+for+ai,aps,136&amp;sr=8-1&amp;linkCode=sl1&amp;tag=kavganbook-20&amp;linkId=ce9c7b637e704bd00a06f421c7a17016&amp;language=en_US&amp;ref_=as_li_ss_tl">The Business Case for AI: A Leader&#8217;s Guide to AI Strategies, Best Practices &amp; Real-World Applications.</a>&#8221; </em></strong>Thanks again to her and thanks to you for joining us as well. I&#8217;m David Gee. We&#8217;ll see you next time. So long, everyone.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://kavita-ganesan.com/what-is-ai-and-what-does-it-mean-for-me-and-the-world/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">7453</post-id>	</item>
		<item>
		<title>Will AI Kill Your Job?</title>
		<link>https://kavita-ganesan.com/will-ai-kill-your-job/</link>
					<comments>https://kavita-ganesan.com/will-ai-kill-your-job/#respond</comments>
		
		<dc:creator><![CDATA[Kavita Ganesan]]></dc:creator>
		<pubDate>Fri, 04 Feb 2022 18:27:08 +0000</pubDate>
				<category><![CDATA[AI Mindset]]></category>
		<category><![CDATA[Business AI]]></category>
		<guid isPermaLink="false">https://kavita-ganesan.com/?p=6806</guid>

					<description><![CDATA[Will AI *really* steal our jobs? This article performs some reality checks on this topic. You may find some of the thought process counterintuitive to what the media makes you believe.]]></description>
										<content:encoded><![CDATA[
<p><em><strong>Oh, what will happen to our jobs when my company starts using AI?</strong></em></p>



<p>This is such a popular question that comes up when I give talks—even to a pseudo technical audience.</p>



<p>Not surprisingly, this question will land sarcastic smiles on the faces of some data scientists and AI experts; you may even catch some eyes rolling.&nbsp;</p>



<p><em>But it’s a valid question.&nbsp;</em></p>



<p>Don’t forget, we had a US political candidate run for the presidency on the theme that <a href="https://www.nytimes.com/2019/11/14/opinion/andrew-yang-jobs.html" target="_blank" rel="noopener">automation is robbing people of good jobs</a> and we should thus be compensated for the crisis. Popular figures take it to extreme levels and even state that <a href="https://www.independent.co.uk/life-style/gadgets-and-tech/news/elon-musk-artificial-intelligence-ai-singularity-a9640196.html" target="_blank" rel="noopener">AI will take over the human race</a> very soon.</p>



<p>With all this noise around automation and AI, of course, this will send shivers down people’s spines; A technology they don’t quite understand is trying to <em>pull the rug from under their feet</em>. Worse still, this technology has the potential of destroying them, according to some.</p>



<p>The fear is real.</p>



<p>According to a<a href="https://governanceai.github.io/US-Public-Opinion-Report-Jan-2019/public-opinion-on-ai-governance.html." target="_blank" rel="noopener"> survey</a> conducted by Oxford University’s Center for the Governance of AI, Americans fear a future where AI becomes too intelligent. &nbsp;When people were asked what kind of impact machine intelligence would have on humanity, 34 percent thought it would be negative, with 12 percent leaning towards <em>human extinction</em>!&nbsp;</p>



<p>This begs the question of, <em>Will, AI *really* replace our jobs and later us?</em>&nbsp;</p>



<p>The answer is complicated. There are several parts to this story.</p>



<h1 id="why-ai-will-steal-some-of-our-jobs">Why AI <em>will</em> steal some of our jobs</h1>



<p>To recap, the goal of AI is to mimic human intelligence and decision-making within a computer, leveraging computer algorithms.&nbsp;Given the computing power, learning algorithms, and data we have today, there are many repetitive tasks done by humans that can be offloaded to AI.&nbsp;At least, AI can assist humans in completing those tasks.</p>



<p>For example, AI systems can be taught to handle simple customer support requests, detect defects on manufactured products, and even investigate the possibility of a fraud event.&nbsp;Once these AI systems are trained, they can perform these tasks more efficiently, quicker, and sometimes even with higher accuracy.&nbsp;So, of course, specific jobs, especially those decision-making jobs that are also labor-intensive, can be “replaced”.&nbsp;But not in the way you think.</p>



<p>Remember that when AI systems fail or make mistakes, you still need humans to rectify the issues.&nbsp;You also need humans in the loop to provide quality assurance–essentially, become the supervisor of these AI systems.&nbsp;Further, as AI systems today rely heavily on data to learn how to perform tasks, you still need humans in the loop to generate high-quality data.&nbsp;More importantly, there’ll be functions around the “stolen” job that no AI is capable of doing single-handedly, such as reporting progress, finding areas of improvement,&nbsp;managing team members, etc.</p>



<p>So eventually, while tasks that used to take a whole team may now be augmented with AI, the roles within your team can change.&nbsp;The humans may become acting supervisors, AI trainers, and quality assurance managers.</p>



<p>In the end, teams could shrink.&nbsp;But teams may also stay the same for years, while their roles change.&nbsp;In some cases, teams may grow bigger due to the demand for other related roles.&nbsp;Nevertheless, humans play a critical part in AI-augmented workflows.</p>



<h1 id="why-ai-will-not-replace-us-humans">Why AI <em>will not</em> replace us humans</h1>



<p>AI systems are task-oriented machines. If you train these machines to perform a series of tasks, they very well will. For example, if you teach a machine learning algorithm to detect breast cancer by asking it to read thousands of mammogram images, it could very well do it like a radiologist. At the same time, the same AI system will not be able to detect any other types of cancer, unlike a radiologist who could detect other related cancers.</p>



<p>We must come to terms that AI systems today lack commonsense reasoning, the ability to effectively build upon knowledge, read between the lines, and use logic as humans do. While humans are born with such innate abilities, AI systems today rely heavily on <em>patterns</em> in data.</p>



<p>Even the famed ​​ GPT-3, the massive language prediction model that seems to do everything, including completing computer source code, answering questions, predicting sentiment, writing articles, etc, gets stumped when you play with its “commonsense abilities”. When you trick it with illogical questions, it produces illogical answers. That’s because it’s trained to learn <em>obvious</em> patterns from huge volumes of data, not conceptualized knowledge, which is more abstract.</p>



<p>For example, if you ask GPT-3, “How many eyes does your foot have?”, it will answer, “Your <strong>foot</strong> has <strong>two</strong> <strong>eyes</strong>” (<a href="https://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html" target="_blank" rel="noopener">see examples here</a>). On the contrary, a two-year-old will quickly tell you that feet don’t have eyes!</p>



<div class="wp-block-image">
<figure class="aligncenter size-large"><a href="https://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html" target="_blank" rel="noopener"><img decoding="async" loading="lazy" class="wp-image-15597" src="https://www.opinosis-analytics.com/wp-content/uploads/2022/01/question-and-answer-with-GPT-3-1024x437.png" alt="" width="1024" height="437"></a>
<figcaption><strong>Question and answers with GPT-3</strong> (Source: <a href="https://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html" target="_blank" rel="noopener">lacker.io</a>)</figcaption>
</figure>
</div>



<p>My point here is that while AI systems can perform complex tasks, at present, they’re very much task-oriented machines. AI is a long way from performing humanlike reasoning in a general sense. If one of the more sophisticated AI systems can’t tell you that feet don’t have eyes, do you really think AI robots can plan a complete takeover of the human race? General humanlike reasoning technology just isn’t there yet due to its complexity and it may be so for several decades to come.&nbsp;Nonetheless, this does not diminish the fact that task-oriented AI systems can already enhance human lives in so many ways.</p>



<h1 id="we-need-ai-and-automation-more-than-ever">We <em>need</em> AI and automation more than ever</h1>



<p>As we’ve all seen with the COVID-19 pandemic, a 100% human workforce is risky and may no longer be suitable for the world we live in today. Workers resigned in great numbers to either care for their homeschooling kids, fear of the virus itself, or at the realization that many of the jobs were not worth the risk. This has resulted in a <em>shrinking</em> labor force participation which has already been happening over the last several decades due to the aging population and other factors.</p>



<div width="100%" align="center"><iframe loading="lazy" align="center" src="https://d3fy651gv2fhd3.cloudfront.net/embed/?s=unitedstalabforparra&amp;v=202201071504V20200908&amp;d1=19970202&amp;type=type=column&amp;h=300&amp;w=600" height="300" width="600" frameborder="0" scrolling="no"></iframe><br>source: <a href="https://tradingeconomics.com/united-states/labor-force-participation-rate">tradingeconomics.com</a></div>



<p class="has-text-align-center"><strong>US Labor force participation over the years</strong></p>



<p>This means that there will be many unfilled jobs. It could also mean that many businesses won’t survive without alternatives. If enough people aren’t willing to work in roles that were fully filled just a decade ago, companies need to compensate.</p>



<p>Automation will become necessary.</p>



<p>We’re already&nbsp;seeing&nbsp;much of this play out in pharmacies and grocery stores throughout the United States, where self-checkout machines, heavily software powered,&nbsp;have become more of a norm after the COVID-19 pandemic.&nbsp;It’s just the beginning. As more and more businesses embrace the digital world and with fewer people wanting to work in roles that earlier generations were comfortable working in,&nbsp;there’ll be a lot more need for software-powered automation.&nbsp;Whether companies use AI, RPA, or simple software automation, all of that is&nbsp;context-dependent.</p>



<h2 id="final-word">Final Word</h2>



<p>So, in summary, to answer the question of whether jobs will be lost because of AI, the answer is—maybe. But what’s more certain is that the nature of certain jobs will <em>gradually</em> change. Instead of doing everything manually, we’ll slowly be assisted by AI-powered tools. We may also become the quality assurance managers and data generators for AI-powered systems. And as for the question of AI takeover? Well, that’s probably not even a question for this decade—not until we get a hopeful glimpse into the study of AI as it relates to <a href="https://www.quantamagazine.org/common-sense-comes-to-computers-20200430/" target="_blank" rel="noopener">commonsense reasoning</a>.</p>



<h1 id="references">References:</h1>



<ul><li><em>US Bureau of Labor Statistics Latest Numbers. Accessed January 28, 2022. <a href="https://www.bls.gov/" target="_blank" rel="noopener">https://www.bls.gov/</a>.</em></li><li><em>Pavlus, John. 2020. “Common Sense Comes Closer to Computers.” Quanta Magazine. <a href="https://www.quantamagazine.org/common-sense-comes-to-computers-20200430/." target="_blank" rel="noopener">https://www.quantamagazine.org/common-sense-comes-to-computers-20200430/.</a></em></li><li><em>“Elon Musk claims AI will overtake humans ‘in less than five years.’” 2020. The Independent. <a href="https://www.independent.co.uk/life-style/gadgets-and-tech/news/elon-musk-artificial-intelligence-ai-singularity-a9640196.html" target="_blank" rel="noopener">https://www.independent.co.uk/life-style/gadgets-and-tech/news/elon-musk-artificial-intelligence-ai-singularity-a9640196.html</a>.</em></li><li><em>3 Public opinion on AI governance | Artificial Intelligence: American Attitudes and Trends. Accessed January 28, 2022. <a href="https://governanceai.github.io/US-Public-Opinion-Report-Jan-2019/public-opinion-on-ai-governance.html" target="_blank" rel="noopener">https://governanceai.github.io/US-Public-Opinion-Report-Jan-2019/public-opinion-on-ai-governance.html</a>.</em></li><li><em>Lacker, Kevin. 2020. “Giving GPT-3 a Turing Test.” Kevin Lacker’s blog. <a href="https://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html" target="_blank" rel="noopener">https://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html</a>.</em></li></ul>



<p><em>The original post can be found here: <a href="https://www.opinosis-analytics.com/blog/ai-job-loss/" target="_blank" rel="noopener">Will AI Kill Your Job?</a></em></p>
]]></content:encoded>
					
					<wfw:commentRss>https://kavita-ganesan.com/will-ai-kill-your-job/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">6806</post-id>	</item>
		<item>
		<title>A Gentle Introduction to Deep Neural Networks with Python</title>
		<link>https://kavita-ganesan.com/neural-network-intro/</link>
					<comments>https://kavita-ganesan.com/neural-network-intro/#respond</comments>
		
		<dc:creator><![CDATA[Kavita Ganesan]]></dc:creator>
		<pubDate>Thu, 27 Jan 2022 21:44:08 +0000</pubDate>
				<category><![CDATA[AI Implementation]]></category>
		<guid isPermaLink="false">https://kavita-ganesan.com/?p=6748</guid>

					<description><![CDATA[This article examines the parts that make up neural networks and deep neural networks, as well as the fundamental different types of models (e.g. regression), their constituent parts (and how they contribute to model accuracy), and which tasks they are designed to learn.]]></description>
										<content:encoded><![CDATA[
<p><em>This is a guest post from Andrew Ferlitsch, author of <a href="https://www.manning.com/books/deep-learning-patterns-and-practices">Deep Learning Patterns and Practices</a>. &nbsp;It provides an introduction to deep neural networks in Python. Andrew is an expert on computer vision, deep learning, and operationalizing ML in production at Google Cloud AI Developer Relations.</em></p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" src="https://kavita-ganesan.com/wp-content/uploads/Ferlitsch-DL-HI-817x1024.png" alt="" class="wp-image-6795" width="174" height="218" srcset="https://kavita-ganesan.com/wp-content/uploads/Ferlitsch-DL-HI-817x1024.png 817w, https://kavita-ganesan.com/wp-content/uploads/Ferlitsch-DL-HI-239x300.png 239w, https://kavita-ganesan.com/wp-content/uploads/Ferlitsch-DL-HI-120x150.png 120w, https://kavita-ganesan.com/wp-content/uploads/Ferlitsch-DL-HI-768x963.png 768w, https://kavita-ganesan.com/wp-content/uploads/Ferlitsch-DL-HI-1225x1536.png 1225w, https://kavita-ganesan.com/wp-content/uploads/Ferlitsch-DL-HI-1633x2048.png 1633w" sizes="(max-width: 174px) 100vw, 174px" /></figure></div>



<p class="has-black-color has-text-color has-background" style="background-color:#eeeeee">This article examines the parts that make up neural networks and deep neural networks, as well as the fundamental different types of models (e.g. regression), their constituent parts (and how they contribute to model accuracy), and which tasks they are designed to learn. This article is meant for machine learning engineers who are familiar with Python and deep learning and want to get a thorough intro to the parts and functions of deep neural networks and related models.</p>


				<div class="wp-block-uagb-table-of-contents uagb-toc__align-left uagb-toc__columns-1  uagb-block-fc090491    "
					data-scroll= "1"
					data-offset= "30"
				>
				<div class="uagb-toc__wrap">
						<div class="uagb-toc__title">
							Table Of Contents						</div>
																<div class="uagb-toc__list-wrap">
						<ol class="uagb-toc__list"><li class="uagb-toc__list"><a href="#introduction-to-neural-networks-in-python">Introduction to Neural Networks in Python</a><li class="uagb-toc__list"><a href="#neural-network-basics">Neural Network Basics</a><ul class="uagb-toc__list"><li class="uagb-toc__list"><a href="#input-layer">Input Layer</a></li></ul></li><li class="uagb-toc__list"><a href="#deep-neural-networks-dnn">Deep Neural Networks (DNN)</a><ul class="uagb-toc__list"><li class="uagb-toc__list"><a href="#feed-forward-networks">Feed Forward networks</a><li class="uagb-toc__list"><a href="#sequential-api-method">Sequential API Method</a><li class="uagb-toc__list"><a href="#functional-api-method">Functional API Method</a><li class="uagb-toc__list"><a href="#input-shape-vs-input-layer">Input Shape vs Input Layer</a><li class="uagb-toc__list"><a href="#dense-layer">Dense Layer</a><li class="uagb-toc__list"><a href="#activation-functions">Activation Functions</a><li class="uagb-toc__list"><a href="#shorthand-syntax">Shorthand Syntax</a></li></ul></li></ul></ol>					</div>
									</div>
				</div>
			


<p></p>



<h2><strong>Introduction to Neural Networks in Python</strong></h2>



<p>We will start this article with some basics on neural networks. First, we will cover the input layer to a neural network, then how this is connected to an output layer, and then how hidden layers are added in-between to become what is called a deep neural network. From there, we cover how the layers are made of nodes, how these nodes learn, and how layers are connected to each other to form fully connected neural networks.</p>



<p>We will also cover the fundamental different types of models. That is, there are different model types, such as regression and classification, which learn different types of tasks. Depending on the task you want to learn, determines the model type you will design a model for.</p>



<p>We will also cover the fundamentals of weights, biases, activations and optimizers, and how they contribute to the accuracy of the model.</p>



<h2><strong>Neural Network Basics</strong></h2>



<p>We will start with some basics on neural networks. First, we will cover the input layer to a neural network, then how this is connected to an output layer, and then how hidden layers are added in-between to become what is called a deep neural network. From there, we cover how the layers are made of nodes, what nodes do, and how layers are connected to each other to form fully connected neural networks.</p>



<h3><strong>Input Layer</strong></h3>



<p>The input layer to a neural network takes numbers! All the input data is converted to numbers. Everything is a number. The text becomes numbers, speech becomes numbers, pictures become numbers, and things that are already numbers are just numbers.</p>



<p>Neural networks take numbers either as vectors, matrices, or tensors. These are simply names for the number of dimensions in an array. A&nbsp;vector&nbsp;is a one-dimensional array, such as a list of numbers. A&nbsp;matrix&nbsp;is a two- dimensional array, like the pixels in a black and white image. And a&nbsp;tensor&nbsp;is any array of three or more dimensions. For example, a three dimensional array is a stack of matrices where each matrix is the same dimension. That&#8217;s it.</p>



<div class="wp-block-image"><figure class="aligncenter size-full is-resized"><img decoding="async" loading="lazy" src="https://kavita-ganesan.com/wp-content/uploads/CH02_F01_Ferlitsch.png" alt="A Gentle Introduction to Deep Neural Networks with Python" class="wp-image-6794" width="437" height="472" srcset="https://kavita-ganesan.com/wp-content/uploads/CH02_F01_Ferlitsch.png 1746w, https://kavita-ganesan.com/wp-content/uploads/CH02_F01_Ferlitsch-278x300.png 278w, https://kavita-ganesan.com/wp-content/uploads/CH02_F01_Ferlitsch-947x1024.png 947w, https://kavita-ganesan.com/wp-content/uploads/CH02_F01_Ferlitsch-139x150.png 139w, https://kavita-ganesan.com/wp-content/uploads/CH02_F01_Ferlitsch-768x830.png 768w, https://kavita-ganesan.com/wp-content/uploads/CH02_F01_Ferlitsch-1421x1536.png 1421w" sizes="(max-width: 437px) 100vw, 437px" /></figure></div>



<p class="has-text-align-center"><strong>Fig. 1 Comparison of array shapes and corresponding names in deep learning.</strong></p>



<p>Speaking of numbers, you might have heard terms like normalization or standardization. In standardization the numbers are converted to be centered around a mean of zero, with one standard deviation on each side of the mean. If you’re saying, &#8216;I don&#8217;t do statistics&#8217; right about now, I know how you feel. But don&#8217;t worry. Packages like&nbsp;scikit-learn&nbsp;and&nbsp;numpy&nbsp;have library calls that do this for you. Standardization is basically a button to push, and it doesn’t even need a lever, so there are no parameters to set.</p>



<p>Speaking of packages, you&#8217;re going to be using a lot of&nbsp;numpy. What is numpy and why is it so popular? Given the interpretive nature of Python, the language handles large arrays poorly. Like really big, super big arrays of numbers &#8211; thousands, tens of thousands, millions of numbers. Think of Carl Sagan&#8217;s infamous quote on the size of the Universe – “billions and billions of stars.” That&#8217;s a tensor!</p>



<p>One day a C programmer got the idea to write, in low-level C, a high performance implementation for handling super big arrays, and then added an external Python wrapper. Numpy was born. Today&nbsp;numpy&nbsp;is a class with lots of useful methods and properties, like the property shape which tells you the shape (or dimensions) of the array, and the where() method which allows you to do SQL-like queries on your super big array.</p>



<p>All Python machine learning frameworks, including TensorFlow and PyTorch, will take as input on the input layer a&nbsp;numpy&nbsp;multidimensional array. And speaking of C, or Java, or C+, &#8230;, the input layer in a neural network is just like the parameters passed to a function in a programming language. That&#8217;s it.</p>



<p>Let&#8217;s get started by installing Python packages you will need. I assume you have&nbsp;<a href="https://www.python.org/downloads/">Python installed</a>&nbsp;(version 3.X). Whether you directly installed it, or it got installed as part of a larger package, like&nbsp;<a href="https://www.anaconda.com/what-is-anaconda/">Anaconda</a>, you got with it a nifty command-like tool called pip. This tool is used to install any Python package you will ever need again, from a single command invocation. You use pip install and then the name of the package. It goes to the global repository PyPi of Python packages and downloads and installs the package for you. It&#8217;s quite easy.</p>



<p>We want to start off by downloading and installing the&nbsp;Tensorflow&nbsp;framework, and the&nbsp;numpy&nbsp;package. Guess what their names are in the registry, tensorflow and numpy &#8211; thankfully very obvious. Let&#8217;s do it together. Go to the command line and issue the following:</p>



<pre class="wp-block-code"><code lang="python" class="language-python">cmd&gt; pip install tensorflow
cmd&gt; pip install numpy</code></pre>



<p>With Tensorflow 2.0, Keras is built-in and the recommended model API, referred to now as&nbsp;TF.Keras.</p>



<p>TF.Keras&nbsp;is based on object oriented programming with a collection of classes and associated methods and properties. Let&#8217;s start simply. Say we have a dataset of housing data. Each row has fourteen columns of data. One column has the sale price of a home. We are going to call that the &#8220;label&#8221;. The other thirteen columns have information about the house, such as the square footage and property tax. It&#8217;s all numbers. We are going to call those the &#8220;features&#8221;. What we want to do is &#8220;learn&#8221; to predict (or estimate) the &#8220;label&#8221; from the &#8220;features&#8221;. Now before we had all this compute power and these awesome machine learning frameworks, data analysts did this stuff by hand or by using formulas in an Excel spreadsheet with some amount of data and lots and lots of linear algebra.We, however, will use Keras and TensorFlow.</p>



<p>We will start by first importing the&nbsp;Keras&nbsp;module from&nbsp;TensorFlow, and then instantiate an Input class object. For this class object, we define the shape or dimensions of the input. In our example, the input is a one-dimensional array (a vector) of 13 elements, one for each feature.</p>



<pre class="wp-block-code"><code lang="python" class="language-python">from tensorflow.keras import Input
Input(shape=(13,))</code></pre>



<p>When you run the above two lines in a notebook, you will see the output:</p>



<pre class="wp-block-preformatted">&lt;<strong>tf.Tensor</strong> 'input_1:0' shape=(?, 13) dtype=float32&gt;</pre>



<p>This is showing you what Input(shape=(13,)) evaluates to. It produces a tensor object by the name &#8216;input_1:0&#8217;. This name will be useful later in assisting you in debugging your models. The &#8216;?&#8217; in shape shows that the input object takes an unbounded number of entries (your examples or rows) of 13 elements each. That is, at run-time it will bind the number of one-dimensional vectors of 13 elements to the actual number of examples (rows) you pass in, referred to as the (mini) batch size. The &#8216;dtype&#8217; shows the default data type of the elements, which in this case is a 32-bit float (single precision).</p>



<p class="has-background" style="background-color:#eeeeee">Take 40% off <a href="https://www.manning.com/books/deep-learning-patterns-and-practices"><em>Deep Learning Patterns and Practices</em></a> by entering <strong>fccferlitsch</strong> into the discount code box at checkout at <a href="https://www.manning.com/">manning.com</a>.</p>



<h2><strong>Deep Neural Networks (DNN)</strong></h2>



<p>DeepMind, Deep Learning, Deep, Deep, Deep. Oh my, what&#8217;s all this? Deep in this context just means that the neural network has one or more layers between the input layer and the output layer. Visualize a directed graph in layers of depth. The root nodes are the input layer and the terminal nodes are the output layer. The layers in between are known as the hidden or deep layers. So a four-layer DNN architecture would look like this:</p>



<pre class="wp-block-preformatted">input layer
hidden layer
hidden layer
output layer</pre>



<p>To get started, we’ll assume every neural network node in every layer, except the output layer, is the same type of neural network node. And that every node on each layer is connected to every other node on the next layer. This is known as a fully connected neural network (FCNN), as depicted in figure 2. For example, if the input layer has three nodes and the next (hidden) layer has four nodes, then each node on the first layer is connected to all four nodes on the next layer for a total of 12 (3&#215;4) connections.</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" src="https://kavita-ganesan.com/wp-content/uploads/CH02_F02_Ferlitsch-1024x706.png" alt="A Gentle Introduction to Deep Neural Networks with Python" class="wp-image-6793" width="512" height="353" srcset="https://kavita-ganesan.com/wp-content/uploads/CH02_F02_Ferlitsch-1024x706.png 1024w, https://kavita-ganesan.com/wp-content/uploads/CH02_F02_Ferlitsch-300x207.png 300w, https://kavita-ganesan.com/wp-content/uploads/CH02_F02_Ferlitsch-150x103.png 150w, https://kavita-ganesan.com/wp-content/uploads/CH02_F02_Ferlitsch-768x529.png 768w, https://kavita-ganesan.com/wp-content/uploads/CH02_F02_Ferlitsch.png 1336w" sizes="(max-width: 512px) 100vw, 512px" /></figure></div>



<p class="has-text-align-center"><strong>Fig. 2 Deep neural networks have one or more hidden layers between the input and output layers. This is a fully-connected network, so the nodes at each level are all connected to each other.</strong></p>



<h3><strong>Feed Forward networks</strong></h3>



<p>The DNN and Convolutional Neural Network (CNN), are known as feed forward neural networks. Feed forward means that data moves through the network sequentially, in one direction, from input to output layer). This is analogous to a function in procedural programming. The inputs are passed as parameters in the input layer, the function performs a sequenced set of actions based on the inputs (in the hidden layers) and outputs a result (the output layer).</p>



<p>When coding a forward feed network in&nbsp;TF.Keras,&nbsp;you will see two distinctive styles in blogs and other tutorials. I will briefly touch on both so when you see a code snippet in one style you can translate it to the other.</p>



<h3><strong>Sequential API Method</strong></h3>



<p>The&nbsp;Sequential API&nbsp;method is easier to read and follow for beginners, but the trade-off is that it is less flexible. Essentially, you create an empty forward feed neural network with the&nbsp;Sequential&nbsp;class object, and then &#8220;add&#8221; one layer at a time, until the output layer. In the examples below, the ellipses represent pseudo code.</p>



<pre class="wp-block-code"><code lang="python" class="language-python">from tensorflow.keras import Sequential
model = Sequential()
model.add( ...the first layer... )
model.add( ...the next layer... )
model.add( ...the output layer... )
</code></pre>



<p class="has-background" style="background-color:#eeeeee"><strong>A Create an empty model.</strong><br><strong>B Placeholders for adding layers in sequential order.</strong></p>



<p>Alternatively, the layers can be specified in sequential order as a list passed as a parameter when instantiating the&nbsp;Sequential&nbsp;class object.</p>



<pre class="wp-block-code"><code lang="python" class="language-python">model = Sequential([ ...the first layer...,
                     ...the next layer...,
                     ...the output layer...
                   ])</code></pre>



<p>So, you might ask, when would one use the add() method versus specifying as a list in the instantiation of the Sequential object. Well, both methods generate the same model and behavior, so it’s a matter of personal preference. For myself, I tend to use the more verbose add() method in instructional and demonstration material for clarity. But, if I am writing code for production, I will use the sparser list method, where I can visualize and edit the code more easily.</p>



<h3><strong>Functional API Method</strong></h3>



<p>The&nbsp;Functional API&nbsp;method is more advanced, allowing you to construct models that are non-sequential in flow &#8211;such as branches, skip links, and multiple inputs and outputs. You build the layers separately and then &#8220;tie&#8221; them together. This latter step gives you the freedom to connect layers in creative ways. Essentially, for a forward feed neural network, you create the layers, bind them to another layer(s), and then pull all the layers together in a final instantiation of a&nbsp;Model&nbsp;class object.</p>



<pre class="wp-block-code"><code lang="python" class="language-python">input = layers.(...the first layer...)
hidden = layers.(...the next layer...)( ...the layer to bind to... )
output = layers.(...the output layer...)( /the layer to bind to... )
model = Model(input, output)</code></pre>



<p></p>



<h3><strong>Input Shape vs Input Layer</strong></h3>



<p>The input shape and input layer can be confusing at first. They are not the same thing. More specifically, the number of nodes in the input layer does not need to match the shape of the input vector. That&#8217;s because every element in the input vector will be passed to every node in the input layer, as depicted in figure 2a.</p>



<div class="wp-block-image"><figure class="aligncenter size-full is-resized"><img decoding="async" loading="lazy" src="https://kavita-ganesan.com/wp-content/uploads/CH02_F03_Ferlitsch.png" alt="A Gentle Introduction to Deep Neural Networks with Python" class="wp-image-6792" width="390" height="372" srcset="https://kavita-ganesan.com/wp-content/uploads/CH02_F03_Ferlitsch.png 780w, https://kavita-ganesan.com/wp-content/uploads/CH02_F03_Ferlitsch-300x286.png 300w, https://kavita-ganesan.com/wp-content/uploads/CH02_F03_Ferlitsch-150x143.png 150w, https://kavita-ganesan.com/wp-content/uploads/CH02_F03_Ferlitsch-768x732.png 768w" sizes="(max-width: 390px) 100vw, 390px" /></figure></div>



<p class="has-text-align-center"><strong>Fig. 2a Shows the difference between the input (shape) and input layer and how every element in the input is connected to every node in the input layer.</strong></p>



<p>For example, if our input layer is ten nodes, and we use our earlier example of a thirteen-element input vector, we will have 130 connections (10 x 13) between the input vector and the input layer.</p>



<p>Each one of these connections between an element in the input vector and a node in the input layer will have a weight and each node in the input layer has a bias. Think of each connection between the input vector and input layer, as well as connections between layers, as sending a signal forward in how strongly it believes the input value will contribute to what the model predictions. We need to have a measurement of the strength of this signal, and that is what the weight does. It is a coefficient that is multiplied against the input value for the input layer, and previous value for subsequent layers. Now each one of these connections is like a vector on an x-y plane. Ideally, we would want each of these vectors to cross the y-axis at the same central point, e.g., 0 origin. But they don’t. To make the vectors relative to each other, the bias is the offset of each vector from the central point on the y-axis.</p>



<p>The weights and biases are what the neural network will &#8220;learn&#8221; during training. The weights and biases are also referred to as parameters. That is, these values stay with the model after it is trained. This operation will otherwise be invisible to you.</p>



<h3><strong>Dense Layer</strong></h3>



<p>In&nbsp;TF.Keras, layers in a fully connected neural network (FCNN) are called&nbsp;Dense&nbsp;layers. A&nbsp;Dense&nbsp;layer is defined as having an &#8220;n&#8221; number of nodes, and is fully connected to the previous layer. Let&#8217;s continue and define in&nbsp;TF.Keras&nbsp;a three layer neural network, using the&nbsp;Sequential API&nbsp;method, for our example. Our input layer will be ten nodes, and take as input a thirteen element vector (i.e., the thirteen features), which will be connected to a second (hidden) layer of ten nodes, which will then be connected to a third (output) layer of one node. Our output layer only needs to be one node, since it will be outputting a single real value (e.g. &#8211; the predicted price of the house). This is an example where we are going to use a neural network as a regressor. That means, the neural network will output a single real number.</p>



<pre class="wp-block-preformatted">input layer&nbsp; = 10 nodes
hidden layer = 10 nodes
output layer = 1 node</pre>



<p>For input and hidden layers, we can pick any number of nodes. The more nodes we have, the better the neural network can learn, but more nodes means more complexity and more time in training and predicting.</p>



<p>In the following code example, we have three&nbsp;add()&nbsp;calls to the class object&nbsp;Dense(). The&nbsp;add()&nbsp;method &#8220;adds&#8221; the layers in the same sequential order we specified them in. The first (positional) parameter is the number of nodes, ten in the first and second layer and one in the third layer. Notice how in the first&nbsp;Dense()&nbsp;layer we added the (keyword) parameter&nbsp;input_shape. This is where we will define the input vector and connect it to the first (input) layer in a single instantiation of&nbsp;Dense().</p>



<pre class="wp-block-code"><code lang="python" class="language-python">from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
model = Sequential()
# Add the first (input) layer (10 nodes) with input shape 13 element vector (1D).
model.add(Dense(10, input_shape=(13,)))
# Add the second (hidden) layer of 10 nodes.
model.add(Dense(10))
# Add the third (output) layer of 1 node.
model.add(Dense(1))</code></pre>



<p>Alternatively, we can define the sequential sequence of the layers as a list parameter when instantiating the&nbsp;Sequential&nbsp;class object.</p>



<pre class="wp-block-code"><code lang="python" class="language-python">from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
model = Sequential([
                   # Add the first (input) layer (10 nodes)
                   Dense(10, input_shape=(13,)),
                   # Add the second (hidden) layer of 10 nodes.
                   Dense(10),
                   # Add the third (output) layer of 1 node.
                   Dense(1)
                   ])
</code></pre>



<p>Let&#8217;s now do the same but use the&nbsp;Functional API&nbsp;method. We start by creating an input vector by instantiating an&nbsp;Input&nbsp;class object. The (positional) parameter to the&nbsp;Input()&nbsp;object is the shape of the input, which can be a vector, matrix or tensor. In our example, we have a vector that is thirteen elements long. So our shape is (13,). I am sure you noticed the trailing comma. That&#8217;s to overcome a quirk in Python. Without the comma, a (13) is evaluated as an expression. That is, the integer value 13 is surrounded by a parenthesis. Adding a comma will tell the interpreter this is a tuple (an ordered set of values).</p>



<p>Next, we create the input layer by instantiating a&nbsp;Dense&nbsp;class object. The positional parameter to the&nbsp;Dense()&nbsp;object is the number of nodes; which in our example is ten. Note the peculiar syntax that follows with a&nbsp;(inputs). The&nbsp;Dense()&nbsp;object is a callable. That is, the object returned by instantiating the&nbsp;Dense()&nbsp;object can be callable as a function. So we call it as a function, and in this case, the function takes as a (positional) parameter the input vector (or layer output) to connect it to; hence we pass it&nbsp;inputs&nbsp;so the input vector is bound to the ten node input layer.</p>



<p>Next, we create the hidden layer by instantiating another&nbsp;Dense()&nbsp;object with ten nodes, and using it as a callable, we (fully) connect it to the input layer.</p>



<p>Then we create the output layer by instantiating another&nbsp;Dense()&nbsp;object with one node, and using it as a callable, we (fully) connect it to the hidden layer.</p>



<p>Finally, we put it altogether by instantiating a&nbsp;Model&nbsp;class object, passing it the (positional) parameters for the input vector and output layer. Remember, all the other layers in-between are already connected so we don&#8217;t need to specify them when instantiating the&nbsp;Model()&nbsp;object.</p>



<pre class="wp-block-code"><code lang="python" class="language-python">from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Dense
 
inputs = Input((13,))
input = Dense(10)(inputs)
hidden = Dense(10)(input)
output = Dense(1)(hidden)
model = Model(inputs, output)
</code></pre>



<h3><strong>Activation Functions</strong></h3>



<p>When training or predicting (inference), each node in a layer will output a value to the nodes in the next layer. We don&#8217;t always want to pass the value &#8216;as-is&#8217;, but instead sometimes we want to change the value in some manner. This process is called an activation function. Think of a function that returns some result, like&nbsp;return result. In the case of an activation function, instead of returning&nbsp;result, we would return the result of passing the result value to another (activation) function, like&nbsp;return A(result), where A() is the activation function. Conceptually, you can think of this as:</p>



<pre class="wp-block-code"><code lang="python" class="language-python">def layer(params):
    """ inside are the nodes """
    result = some_calculations
    return A(result)
 
def A(result):
    """ modifies the result """
    return some_modified_value_of_result
</code></pre>



<p>Activation functions assist neural networks in learning faster and better. By default, when no activation function is specified, the values from one layer are passed as-is (unchanged) to the next layer. The most basic activation function is a step function. If the value is greater than 0, then a 1 is outputted; otherwise a zero. The step function hasn&#8217;t been used in a long, long time.</p>



<p>Let’s pause for a moment and discuss the purpose of an activation function. You likely have heard the phrase non-linearity. What is this? To me, more importantly, is what it is not?</p>



<p>In traditional statistics, we worked in low dimensional space where there was a strong linear correlation between the input space and output space. This correlation could be computed as a polynomial transformation of the input that, when transformed, had a linear correlation to the output. The most fundamental example is the slope of a line, which is represented as y = mx + b. In this case, x and y are coordinates of the line, and we want to fit the value of m, the slope, and b, where the line intercepts the y access.</p>



<p>In deep learning, we work in high dimensional space where there is substantial non-linearity between the input space and output space. What is non-linearity? It means that an input is not (near) uniformly related to an output based on a polynomial transformation of the input. For example, let’s say one’s property tax is a fixed percentage rate (r) of the house value. In this case, the property tax can be represented by a function that multiplies the rate by the house value &#8212; thus having a linear (i.e., straight line) relationship between value (input) and property tax (output).</p>



<pre class="wp-block-preformatted">tax = F(<strong>value</strong>) = r * <strong>value</strong></pre>



<p>Let’s look at the logarithmic scale for measuring earthquakes, where an increase of one, means the power released is ten times greater. For example, an earthquake of 4 is 10 times stronger than a 3. By applying a logarithmic transform to the input power we have a linear relationship between power and scale.</p>



<pre class="wp-block-preformatted">scale&nbsp; = F(power) = log(power)</pre>



<p>In a non-linear relationship, sequences within the input have different linear relationships to the output, and in deep learning we want to learn both the separation points as well as the linear functions for each input sequence. For example, consider age vs. income to demonstrate a non-linear relationship. In general, toddlers have no income, grade-school children have an allowance, early-teens earn an allowance + money for chores, later teens earn money from jobs, and then when they go to college their income drops to zero! After college, their income gradually increases until retirement, when it becomes fixed. We could model this nonlinearity as sequences across age and learn a linear function for each sequence, such as depicted below.</p>



<pre class="wp-block-preformatted">income = F1(age) = 0    for age [0..5]
income = F2(age) = c1    for age[6..9]
income = F3(age) = c1 + (w1 * age)  for age[10..15]
income = F4(age) = (w2 * age) for age[16..18]
income = F5(age) = 0 for age[19..22]
income = F6(age) = (w3 * age) for age[23..64]
income = F7(age) = c2 for age [65+]
</pre>



<p>Activation functions assist in finding the non-linear separations and corresponding clustering of nodes within input sequences which then learn the (near) linear relationship to the output.</p>



<p>There are three activation functions you will use most of the time: the rectified linear unit (ReLU); sigmoid; softmax. We will start with the ReLU, since it is the one that is most used in all but the output layer of a model. The sigmoid and softmax activation we will then cover when we look at how different model types affect the design of the output layer.</p>



<p>The rectified linear unit, as depicted in figure 3, passes values greater than zero as-is (unchanged); otherwise zero (no signal).</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" src="https://kavita-ganesan.com/wp-content/uploads/CH02_F04_Ferlitsch-1024x847.png" alt="A Gentle Introduction to Deep Neural Networks with Python" class="wp-image-6791" width="512" height="424" srcset="https://kavita-ganesan.com/wp-content/uploads/CH02_F04_Ferlitsch-1024x847.png 1024w, https://kavita-ganesan.com/wp-content/uploads/CH02_F04_Ferlitsch-300x248.png 300w, https://kavita-ganesan.com/wp-content/uploads/CH02_F04_Ferlitsch-150x124.png 150w, https://kavita-ganesan.com/wp-content/uploads/CH02_F04_Ferlitsch-768x635.png 768w, https://kavita-ganesan.com/wp-content/uploads/CH02_F04_Ferlitsch-1536x1271.png 1536w, https://kavita-ganesan.com/wp-content/uploads/CH02_F04_Ferlitsch-2048x1694.png 2048w" sizes="(max-width: 512px) 100vw, 512px" /><figcaption><strong>Fig. 3 The function for a rectified linear unit clips all negative values to zero. In essence, any negative value is the same as no signal ~ zero.</strong></figcaption></figure></div>



<p class="has-text-align-center"></p>



<p>The rectified linear unit is generally used between layers. While early researchers used different activation functions, such as a hyperbolic tangent, between layers, researchers found that the ReLU produced the best result in training a model. In our example, we will add a rectified linear unit between each layer.</p>



<pre class="wp-block-code"><code lang="python" class="language-python"> 
model = Sequential()
# Add the first (input) layer (10 nodes) with input shape 13 element vector (1D).
model.add(Dense(10, input_shape=(13,)))
# Pass the output from the input layer through a rectified linear unit activation  # function.
model.add(ReLU())
# Add the second (hidden) layer (10 nodes).
model.add(Dense(10))
# Pass the output from the input layer through a rectified linear unit activation  # function.
model.add(ReLU())
# Add the third (output) layer of 1 node.
model.add(Dense(1))</code></pre>



<p>Let&#8217;s take a look inside our model object and see if we constructed what we think we did. You can do this using the summary() method. It will show in sequential order a summary of each layer.</p>



<pre class="wp-block-code"><code lang="python" class="language-python">model.summary()</code></pre>



<pre class="wp-block-preformatted">Layer (type)                 Output Shape              Param #   
=================================================================
dense_56 (Dense)             (None, 10)                140       
_________________________________________________________________
re_lu_18 (ReLU)              (None, 10)                0         
_________________________________________________________________
dense_57 (Dense)             (None, 10)                110       
_________________________________________________________________
re_lu_19 (ReLU)              (None, 10)                0         
_________________________________________________________________
dense_58 (Dense)             (None, 1)                 11        
=================================================================
Total params: 261
Trainable params: 261
Non-trainable params: 0
_________________________________________________________________
</pre>



<p>For this code example, you see the summary starts with a&nbsp;Dense&nbsp;layer of ten nodes (input layer), followed by a&nbsp;ReLU&nbsp;activation function, followed by a second&nbsp;Dense&nbsp;layer (hidden) of ten nodes, followed by a&nbsp;ReLU&nbsp;activation function, and finally followed by a&nbsp;Dense&nbsp;layer (output) of one node. So, yes, we got what we expected.</p>



<p>Next, let&#8217;s look at the parameter field in the summary. See how, for the input layer, it shows 140 parameters. How is that calculated? We have 13 inputs and 10 nodes, so 13 x 10 is 130. Where does 140 come from? Each connection between the inputs and each node has a weight, which adds up to 130. But each node has an additional bias. That&#8217;s ten nodes, so 130 + 10 = 140. As I’ve said, it&#8217;s the weights and biases that the neural network will &#8220;learn&#8221; during training. A bias is a learned offset, conceptually equivalent to the y-intercept (b) in the slope of a line, which is where the line intercepts the y-axis:</p>



<pre class="wp-block-preformatted">y = b + mx</pre>



<p>At the next (hidden) layer you see 110 params. That&#8217;s ten outputs from the input layer connected to each of the ten nodes from the hidden layer (10&#215;10) plus the ten biases for the nodes in the hidden layers, for a total of 110 parameters to &#8220;learn&#8221;.</p>



<h3><strong>Shorthand Syntax</strong></h3>



<p>TF.Keras provides a shorthand syntax when specifying layers. You don&#8217;t actually need to separately specify activation functions between layers, as we did above. Instead, you can specify the activation function as a (keyword) parameter when instantiating a Dense() layer.</p>



<p>You might ask, why not then simply always use the shorthand syntax? As you will see later in the book, where in today’s model architecture the activation function is preceded by another intermediate layer &#8212; batch normalization, or precedes the layer altogether &#8212; pre-activation batch normalization.</p>



<p>The code example below does exactly the same as the code above.</p>



<pre class="wp-block-code"><code lang="python" class="language-python">from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
 
model = Sequential()
# Add the first (input) layer (10 nodes) with input shape 13 element vector (1D).
model.add(Dense(10, input_shape=(13,), activation='relu'))
# Add the second (hidden) layer (10 nodes).
model.add(Dense(10, activation='relu'))
# Add the third (output) layer of 1 node.
model.add(Dense(1))#A The activation function is specified as a keyword parameter in the layer.</code></pre>



<p>Let&#8217;s call the&nbsp;summary()&nbsp;method on this model.</p>



<pre class="wp-block-code"><code class="">model.summary()</code></pre>



<pre class="wp-block-preformatted">Layer (type)                 Output Shape              Param #   
=================================================================
dense_56 (Dense)             (None, 10)                140       
_________________________________________________________________
re_lu_18 (ReLU)              (None, 10)                0         
_________________________________________________________________
dense_57 (Dense)             (None, 10)                110       
_________________________________________________________________
re_lu_19 (ReLU)              (None, 10)                0         
_________________________________________________________________
dense_58 (Dense)             (None, 1)                 11        
=================================================================

Total params: 261
Trainable params: 261
Non-trainable params: 0
</pre>



<p>Hum, you don&#8217;t see the activations between the layers as you did in the earlier example. Why not? It&#8217;s a quirk in how the summary() method displays output. They are still there.</p>



<p><strong>Improving accuracy with optimizer</strong></p>



<p>Once you&#8217;ve completed building the forward feed portion of your neural network, as we have for our simple example, we now need to add a few things for training the model. This is done with the&nbsp;compile()&nbsp;method. This step adds the backward propagation during training. Let’s define and explore this concept.</p>



<p>Each time we send data (or a batch of data) forward through the neural network, the neural network calculates the errors in the predicted results (known as the loss) from the actual values (called labels) and uses that information to incrementally adjust the weights and biases of the nodes. This, for a model, is the process of learning.</p>



<p>The calculation of the error, as I’ve said, is called a loss. It can be calculated in many different ways. Since we designed our example neural network to be a regresser (meaning that the output, house price, is a real value), we want to use a loss function that is best suited for a regresser. Generally, for this type of neural network, we use the Mean Square Error method of calculating a loss. In Keras, the&nbsp;compile()&nbsp;method takes a (keyword) parameter&nbsp;loss&nbsp;where we can specify how we want to calculate the loss. We are going to pass it the value&nbsp;‘mse’&nbsp;for Mean Square Error.</p>



<p>The next step in the process is the optimizer that occurs during backward propagation. The optimizer is based on gradient descent; where different variations of the gradient descent algorithm can be selected. These terms can be hard to understand at first. Essentially, each time we pass data through the neural network we use the calculated loss to decide how much to change the weights and biases in the layers by. The goal is to gradually get closer and closer to the correct values for the weights and biases to accurately predict or estimate the &#8220;label&#8221; for each example. This process of progressively getting closer and closer to the accurate values is called convergence. The job of the optimizer is to calculate the updates to the weights to progressively get closer to the accurate values to reach convergence.</p>



<p>As the loss gradually decreases we are converging and once the loss plateaus out, we have convergence, and the result is the accuracy of the neural network. Before using gradient descent, the methods used by early AI researchers could take years on a supercomputer to find convergence on a non-trivial problem. After the discovery of using the gradient descent algorithm, this time reduced to days, hours and even just minutes on ordinary compute power. Let&#8217;s skip the math and just say that gradient descent is the data scientist&#8217;s pixie dust that makes convergence possible.</p>



<p>For our regressor neural network, we will use the&nbsp;<code>rmsprop</code>&nbsp;method (root mean square property).</p>



<pre class="wp-block-code"><code class="">model.compile(loss='mse', optimizer='rmsprop')</code></pre>



<p>Now we have completed building your first &#8216;trainable&#8217; neural network.</p>



<p>That’s all for now. If you want to learn more about the book, check it out on Manning’s liveBook platform <a href="https://livebook.manning.com/book/deep-learning-patterns-and-practices?origin=product-look-inside">here</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://kavita-ganesan.com/neural-network-intro/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">6748</post-id>	</item>
		<item>
		<title>AI in Manufacturing: 4 Real-World Examples</title>
		<link>https://kavita-ganesan.com/ai-in-manufacturing-examples/</link>
					<comments>https://kavita-ganesan.com/ai-in-manufacturing-examples/#respond</comments>
		
		<dc:creator><![CDATA[Kavita Ganesan]]></dc:creator>
		<pubDate>Fri, 08 Oct 2021 20:30:09 +0000</pubDate>
				<category><![CDATA[AI Strategy]]></category>
		<category><![CDATA[AI Use Cases]]></category>
		<category><![CDATA[Business AI]]></category>
		<category><![CDATA[text summarization]]></category>
		<guid isPermaLink="false">https://kavita-ganesan.com/?p=6175</guid>

					<description><![CDATA[Explore 4 real-world AI in manufacturing examples. From defect detection to predictive maintenance in beverage manufacturing, silicone wafer production and automotive production.]]></description>
										<content:encoded><![CDATA[<p>Human error causes <a href="https://www.businesswire.com/news/home/20171106006370/en/Human-Error-Common-Unplanned-Downtime-Manufacturing-Sector">23% of unplanned downtime</a> in manufacturing. As you may know, unplanned downtime in manufacturing is a major cause of <a href="https://www2.deloitte.com/content/dam/Deloitte/us/Documents/process-and-operations/us-cons-predictive-maintenance.pdf">lost revenues</a>.</p>
<p>Can AI help reduce human errors in manufacturing? The quick answer is yes!</p>
<p>AI can help mimic human decision-making on specific tasks. For example, on analyzing the image of a traffic stop, AI systems can be trained to detect the presence of objects such as a person, a stop sign, or a road bump. Given an image, they can also be trained to find minuscule abnormalities—ones that even humans can miss.</p>
<p>But, unlike humans, AI systems don’t get bored, tired and can work at optimal levels 24/7 hours of the day, reducing the likelihood of errors, improving workflow productivity, and spotting the minuscule details that can be missed by humans.</p>
<p>With the vast amount of data generated during manufacturing processes, more and more business leaders across the globe are harnessing the power of AI to eliminate manual tasks and errors in production. Here is a glimpse of how AI is being used in manufacturing today with four real-world AI in manufacturing examples.</p>
<h2>4 Real-World Uses Cases of AI in Manufacturing</h2>
<h3>#1: Streamlining Quality Control in Beverage Production</h3>
<p>Suntory PepsiCo, a beverage production company operates five factories in Vietnam. The soda factories struggled to scan printed manufacturing and expiration date code labels accurately. That’s because sometimes, the code was attached before the surface was completely dry, resulting in smudges. Such mistakes led to production delays and expensive stoppages.</p>
<div class="wp-block-image">
<figure class="aligncenter size-full is-resized"><img decoding="async" loading="lazy" class="wp-image-14195" src="https://www.opinosis-analytics.com/wp-content/uploads/2021/09/matrox-imaging_production-line-scan-mfd-exp-codes_cr.jpeg" alt="AI in manufacturing example" width="665" height="375"><figcaption>Scanning for code labels in one of Suntory’s factories. Source: <a href="https://www.matrox.com/en/imaging/media/case-studies/suntory-pepsico-bottles-perfection-improving-identification-capabilities">matrox.com</a></figcaption></figure>
</div>
<p>To avoid such problems, Suntory PepsiCo asked its integrator Pacific Hi-Tech, and the Matrox Imaging <a href="https://www.insight.tech/content/how-machine-vision-puts-the-focus-on-quality-control#main-content">“Machine Vision” solution</a> was born.</p>
<p>The AI-powered solution, integrated with cameras, reads code label images and instantly determines if they are attached to the product, that the codes are correct, and if the label is unreadable, smudged, obscured, or absent entirely. If a label is missing or illegible, an ejector removes the <em>offending</em> product without stopping the assembly line. By swiftly reading poorly positioned code labels and removing the products from the assembly line, the Machine Vision System has helped Suntory PepsiCo streamline its quality control process.</p>
<div class="wp-block-image">
<figure class="aligncenter size-large"><img decoding="async" src="https://www.matrox.com/sites/default/files/suntory-pepsico-varieties-packaging-mfd-exp-code-single.png" alt=""><figcaption>Examples of attached code labels that pass on a single production line. Notice that all code here labels are readable. Source: <a href="https://www.matrox.com/en/imaging/media/case-studies/suntory-pepsico-bottles-perfection-improving-identification-capabilities">matrox.com</a></figcaption></figure>
</div>
<p>In this scenario, it would be much slower for a human to examine each product and determine if code labels are correctly attached, readable and then determine the next course of action. Machines in combination with AI can do this work many times faster and with fewer errors.</p>
<h3>#2: BMW Uses AI To Keep Production In Overdrive</h3>
<p>BMWs are known to be sleek and fast automobiles, and now thanks to AI, they have the production capabilities to match their design. <a href="https://iot-automotive.news/bmw-group-artificial-intelligence/">BMW Group</a> utilizes AI in manufacturing solutions to perform monotonous tasks that used to require human intervention, including quality control, logistics coordination, and virtual layout planning.</p>
<p>Specifically, AI-based applications can replace camera portals with automated image recognition systems, view images of auto production, and compare them to a database of hundreds of other photos. With automated image recognition, <em>production deviations</em> are detected in real-time and corrected before they pose a more significant problem. For example, at a BMW manufacturing plant in Germany, AI is used to determine if the correct model designation is attached to a vehicle. By seeing hundreds upon hundreds of images of model designation, the AI has learned to recognize permitted combinations with non-permitted ones.</p>
<div class="wp-block-jetpack-tiled-gallery aligncenter is-style-columns">
<div class="tiled-gallery__gallery">
<div class="tiled-gallery__row">
<div class="tiled-gallery__col" style="flex-basis: 54.84134%;">
<figure class="tiled-gallery__item"><img decoding="async" src="https://i2.wp.com/www.opinosis-analytics.com/wp-content/uploads/2021/09/ai-learns-from-hundreds-of-model-designation-examples-1024x432.png?ssl=1" alt="" data-height="1038" data-id="14251" data-link="https://www.opinosis-analytics.com/?attachment_id=14251" data-url="https://www.opinosis-analytics.com/wp-content/uploads/2021/09/ai-learns-from-hundreds-of-model-designation-examples-1024x432.png" data-width="2460" data-amp-layout="responsive"></figure>
</div>
<div class="tiled-gallery__col" style="flex-basis: 45.15866%;">
<figure class="tiled-gallery__item"><img decoding="async" src="https://i1.wp.com/www.opinosis-analytics.com/wp-content/uploads/2021/09/Model-Designation-Recognition-AI-in-Manufacturing-1024x525.png?ssl=1" alt="" data-height="1274" data-id="14250" data-link="https://www.opinosis-analytics.com/?attachment_id=14250" data-url="https://www.opinosis-analytics.com/wp-content/uploads/2021/09/Model-Designation-Recognition-AI-in-Manufacturing-1024x525.png" data-width="2484" data-amp-layout="responsive"></figure>
</div>
</div>
</div>
</div>
<p class="has-text-align-center"><em>An AI tool learns permitted model designations upon seeing hundreds of model designation images (left). The AI tool can then detect if the model designation on a new car is correct given what it already knows (right). Source: <a href="https://www.youtube.com/watch?v=Fo6pWIi-Ixo">https://www.youtube.com/watch?v=Fo6pWIi-Ixo</a></em></p>
<p>The AI imaging system not only detects defects during manufacturing but can also see pseudo-defects. For example, BMW uses flat sheet metal parts for the car body. Dust particles or oil residues found on the metal can be labeled as cracks with old quality control systems when they are, in fact, benign issues. With the new AI application, pseudo-defects no longer pose a problem. With so many uses of AI in BMW’s manufacturing line, they’re able to maintain their quality standards while freeing employees from repetitive and error-prone tasks.</p>
<h3>#3: ExtractAI Gets To The Root Cause Of Microchip Defects</h3>
<p><a href="https://news.samsung.com/global/eight-major-steps-to-semiconductor-fabrication-part-1-creating-the-wafer">Silicon wafers</a> are a type of semiconductor used in the production of microchips that go into the electronic gadgets we use daily such as cell phones, computers, televisions, and more.</p>
<div class="wp-block-image">
<figure class="aligncenter size-full"><img decoding="async" loading="lazy" class="wp-image-14261" src="https://www.opinosis-analytics.com/wp-content/uploads/2021/09/ai_in_manufacturing_silicone_wafer_example.jpeg" alt="using AI in silicone wafer manufacturing" width="600" height="400"><figcaption>Example of Silicon Wafer</figcaption></figure>
</div>
<p>These chips can be as small as 10 nanometers, and thus, detecting errors in production requires special tools like electron microscopes, which are accurate but slow. Though an optical scan can find millions of problem areas on silicon wafers, examining further with an electron microscope takes multiple days only to find a small percentage of defects that will cause chip malfunction.&nbsp;In manufacturing terms, these are called “killer” defects.</p>
<div class="wp-block-image">
<figure class="aligncenter size-full"><img decoding="async" loading="lazy" class="wp-image-14263" src="https://www.opinosis-analytics.com/wp-content/uploads/2021/09/electron-microscope.jpeg" alt="Example of electron microscope in action" width="480" height="270"><figcaption>An electron microscope in action</figcaption></figure>
</div>
<p>ExtractAI, a new AI-based microchip detection technology from Applied Materials uses AI to spot the killer defects in microchips. <a href="https://www.reuters.com/article/us-applied-tech/new-applied-materials-tools-use-ai-to-catch-mistakes-on-chips-idUSKBN2B81JO">ExtractAI</a> uses a new optical scanner to scan silicon wafers for problem areas, and then an electron microscope zooms in for a closer look.</p>
<p>High-end optical scanners generate millions of noisy signals. In the midst of those noisy signals also exists defects and sifting out actual defects from the noise is an ongoing problem. The good news is that Applied Material’s AI can differentiate <em>killer </em>defects from noise. The ExtractAI technology is also incredibly efficient; it only needs to check about 0.001% of the samples to characterize all of the potential defects. This equates to about an hour of examination versus the days it takes with the old method.</p>
<h3>#4: Predictive Maintenance Energized</h3>
<p>A leading European energy company wanted to take its manufacturing process from reactive to proactive with predictive maintenance. The reliability of systems in the plant is critical for many reasons, from being able to manage maintenance costs to better managing safety and environmental concerns.</p>
<p>Driven by these needs, the energy firm implemented its Digital Predictive Maintenance Center, according to a case study by <a href="https://www.aspentech.com/en/resources/case-studies/energy-company-drives-innovation-in-predictive-maintenance-via-digital-transformation-program">AspenTech</a>. The Digital Predictive Maintenance Center organizes data so reliability engineers can rapidly assess and correct reliability issues proactively. The center gives staff at the plant an early warning of when an asset failure will occur, how it will happen, and what to do about it. After deploying the solution on over 50 significant assets in a refinery powered by wind farms, the energy company avoided between<strong> €4M </strong>and<strong> €5M </strong>in total losses due to maintenance costs and lost production opportunities in the refinery.</p>
<h2>Final Word</h2>
<p>As we’ve seen in the examples in this article, there are many innovative uses ofAI in manufacturing—all of which can solve critical business challenges. Manufacturing facilities worldwide, such as Suntory PepsiCo, BMW, and Applied Materials use AI to reduce the workload on tedious tasks such as defect detection that were once performed by employees manually. This has the greater benefit of reducing costs, limiting human errors, and freeing humans from repetitive and monotonous work.</p>
<p>But we’ve barely scratched the surface.</p>
<p>Most of the examples you’ve seen so far relate to making manufacturing lines more efficient. However, within manufacturing itself, there is a significant potential for using AI in other tasks outside production lines. For example, helping managers get to the root cause of defects. This requires a step-by-step investigation into the problems that resulted in the defect. With the help of AI, you can connect incidents, automatically surface causes, and assist managers in quickly getting to the root causes. This will allow them to focus on addressing problems rather than sifting through documentation.</p>
<p>As the AI in manufacturing examples above prove, AI is no longer an abstract sci-fi dream but an effective business tool with a bright future in manufacturing.</p>
<p>The post <a href="https://www.opinosis-analytics.com/blog/ai-in-manufacturing-examples" rel="nofollow">AI in Manufacturing: 4 Real-World Examples</a> appeared first on <a href="https://www.opinosis-analytics.com" rel="nofollow">Opinosis Analytics</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://kavita-ganesan.com/ai-in-manufacturing-examples/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">6175</post-id>	</item>
		<item>
		<title>How To Generate Quality Training Data For Your Machine Learning Projects</title>
		<link>https://kavita-ganesan.com/machine-learning-training-data-generation/</link>
					<comments>https://kavita-ganesan.com/machine-learning-training-data-generation/#respond</comments>
		
		<dc:creator><![CDATA[Kavita Ganesan]]></dc:creator>
		<pubDate>Sun, 01 Aug 2021 21:42:41 +0000</pubDate>
				<category><![CDATA[AI Project Management]]></category>
		<category><![CDATA[AI Strategy]]></category>
		<category><![CDATA[Business AI]]></category>
		<guid isPermaLink="false">https://kavita-ganesan.com/?p=6039</guid>

					<description><![CDATA[Learn 5 strategies for generating high-quality machine learning training data. Warning: some of these approaches have been tried and tested. ]]></description>
										<content:encoded><![CDATA[
<p>Have you run into issues acquiring the <em>right</em> type of data for your machine learning (ML) projects?</p>



<p>You’re not alone. Many teams do. And data is one of the key sticking points in starting AI initiatives at companies. In fact, according to IBM’s CEO, Arvind Krishna, <a href="https://www.wsj.com/articles/data-challenges-are-halting-ai-projects-ibm-executive-says-11559035800">data-related challenges </a>are the top reason <a href="https://www.wsj.com/articles/data-challenges-are-halting-ai-projects-ibm-executive-says-11559035800">IBM clients</a> have halted or canceled AI projects.&nbsp;</p>



<p>Often what happens in practice is that the relevant ML training data is either not collected, or collected but the data lacks the required <strong>labels </strong>for training a model. It could also be that the existing <strong>volume </strong>of data is insufficient for ML model development.&nbsp;</p>



<p>As I’ve discussed in one of my previous<a href="https://www.opinosis-analytics.com/blog/big-data-strategy/"> data</a> articles, such issues result in delays, project cancellation, biased predictions, and an overall lack of trust in AI initiatives. Bottom line: having the right data, in the right volume is critical for any ML project.&nbsp;</p>



<p>But, what if your company does not have a solid <a href="https://kavita-ganesan.com/big-data-strategy/">big data strategy</a>, or you’re just getting started with data collection? How can you safely start machine learning projects for your automation tasks?</p>



<p>In this article, we’ll explore four strategies for obtaining high-quality machine learning training data for your projects, even if you’re new to AI or your data strategy is still in the works.&nbsp;&nbsp;For convenience, use the table of contents below to explore the strategies of interest to you.</p>



<div id="ub_table-of-contents-46a9a976-f5cb-4008-801f-5e596997174c" class="ub_table-of-contents" data-showtext="show" data-hidetext="hide" data-scrolltype="auto" data-initiallyhideonmobile="false" data-initiallyshow="true">
<div class="ub_table-of-contents-header">&nbsp;</div>
</div>


				<div class="wp-block-uagb-table-of-contents uagb-toc__align-left uagb-toc__columns-1  uagb-block-fcbe2c73    "
					data-scroll= "1"
					data-offset= "30"
				>
				<div class="uagb-toc__wrap">
						<div class="uagb-toc__title">
							Table Of Contents						</div>
																<div class="uagb-toc__list-wrap">
						<ol class="uagb-toc__list"><li class="uagb-toc__list"><a href="#5-strategies-for-generating-machine-learning-training-data">5 Strategies for Generating Machine Learning Training Data</a><ul class="uagb-toc__list"><li class="uagb-toc__list"><a href="#1-start-manually-with-domain-experts">#1: Start Manually with Domain Experts</a><li class="uagb-toc__list"><a href="#2-start-manually-with-customers">#2: Start Manually with Customers</a><li class="uagb-toc__list"><a href="#3-pair-humans-with-software-rules-ie-semi-automatic">#3: Pair Humans With Software Rules (i.e., Semi-Automatic)</a><li class="uagb-toc__list"><a href="#4-crowdsource-internally">#4: Crowdsource Internally</a><li class="uagb-toc__list"><a href="#5-crowdsource-externally">#5: Crowdsource Externally</a></li></ul></li><li class="uagb-toc__list"><a href="#comparison-of-all-training-data-generation-strategies">Comparison of ALL Training Data Generation Strategies</a><li class="uagb-toc__list"><a href="#final-word">Final Word</a></li></ul></ol>					</div>
									</div>
				</div>
			


<hr class="wp-block-separator has-css-opacity"/>



<div style="height:42px" aria-hidden="true" class="wp-block-spacer"></div>



<h2 id="0-5-strategies-for-generating-machine-learning-training-data">5 Strategies for Generating Machine Learning Training Data</h2>



<h3 id="1-1-start-manually-with-domain-experts">#1: Start Manually with Domain Experts</h3>



<p>If you have zero data for an automation problem or your data is limited, you can put together a team of <strong>experts</strong> who’ll manually complete tasks, while at the same time start generating high-quality data.</p>



<div class="wp-block-image">
<figure class="aligncenter size-large"><img decoding="async" loading="lazy" class="wp-image-13639" src="https://www.opinosis-analytics.com/wp-content/uploads/2021/07/How-ai-training-data-collection-works-using-a-team-of-experts-1024x509.png" alt="data collection using a team of domain experts" width="1024" height="509">
<figcaption>How data collection works using a team of experts</figcaption>
</figure>
</div>



<p>Say you’re looking to develop an AI tool that detects fraudulent website logins. If you’ve never tracked fraudulent login attempts, you’ll have limited to no data to train a model. But you can start the process manually with a team of security experts to start generating high-quality data. This data can later be used to train a machine to detect fraud just like its human counterpart. All the data from the manual process can be tracked, collected, and stored for model training.</p>



<h4 id="2-when-is-a-manual-strategy-with-domain-experts-suitable-"><strong>When is a manual strategy with domain experts suitable?</strong></h4>



<p>As a manual approach can be slow, it’s especially suitable for problems that require deep domain expertise and when people’s health and safety are at stake. For example, in a tumor detection task, you can’t just train models on image data produced by a layperson or even a general practitioner. You need data from experienced radiologists as it requires deep domain expertise to detect and label tumors correctly. Otherwise, there’s a higher risk of problematic predictions, putting people’s health at risk.</p>



<h4 id="3-pros-and-cons-of-a-manual-approach-with-domain-experts-"><strong>Pros and cons of a manual approach with domain experts:</strong></h4>



<p>There is no better data than a manually generated and vetted one. Manually generated data, especially data produced by subject matter experts (SMEs), is usually accurate. Plus, there is an added advantage that doing a task manually, to begin with gives you insights into the idiosyncrasies of the task, which can help teams better handle edge cases as automation is introduced.</p>



<p>But the downside of this is, of course—volume. If you have a small team working on the tasks manually, it can take months to generate sufficient data.</p>



<h3 id="4-2-start-manually-with-customers">#2: Start Manually with Customers</h3>



<p>When you’re trying to develop AI-driven productivity enhancements tools for customers, who better to tell you what’s expected than customers themselves? Instead of starting with automation right off the bat, why not augment existing software such that customers can complete the task manually first.&nbsp;</p>



<p>I once worked with a company that wanted to introduce a machine learning model to detect duplicate discussion threads on their software platform. But since the relevant data was non-existent, we first went manual. We introduced a mechanism to allow users to manually specify if a discussion thread was a duplicate of another. In this case, the customers were the “domain experts,” and they decided which threads were duplicates. All the customer-generated data was later leveraged to build an AI-driven duplicate detection solution. You can use a similar approach for many other automation tasks, such as automatically tagging documents with topics and tagging objects in images. With this approach, you are leveraging the power of volume and the expertise of your very own customers.&nbsp;</p>



<h4 id="5-when-is-a-manual-strategy-with-customers-suitable-"><strong>When is a manual strategy with customers suitable?</strong></h4>



<p>A manual strategy with customers makes the most sense when you have a large customer base, and the task benefits the customer. For example, the duplicate detection task we discussed earlier, helped customers explore related discussion threads. So, they were willing to complete the task manually. If completing a task doesn’t benefit the customer, you could still generate data, but the volume could be much lower.&nbsp;</p>



<h4 id="6-pros-and-cons-of-a-manual-strategy-with-customers-"><strong>Pros and cons of a manual strategy with customers:</strong></h4>



<p>When you have motivated customers willing to complete the manual tasks, this strategy ensures that you’re getting volume and a variety in your data in a relatively short time. I’ve personally found that providing sufficient variety in data helps build robust models. On the flip side, this approach may end up generating poor quality data if customers “game” the system for their benefit. Additionally, if customers couldn’t care less about the task, the volume of data could end up being sparse.&nbsp;</p>



<h3 id="7-3-pair-humans-with-software-rules-ie-semi-automatic">#3: Pair Humans With Software Rules (i.e., Semi-Automatic)</h3>



<p>Another approach to collecting good quality training data is to pair rules encoded in software with humans in the loop. Essentially, you encode rules a human would use to perform a task as a set of software rules. At the same time, you still have a few humans in the loop to act as a quality control layer. If the corrected and vetted data is stored, you can use it for model training in months to come.</p>



<div class="wp-block-image">
<figure class="aligncenter size-large"><img decoding="async" loading="lazy" class="wp-image-13669" src="https://www.opinosis-analytics.com/wp-content/uploads/2021/07/How-machine-learning-training-data-generation-works-with-the-use-of-simple-software-automation-and-humans-in-the-loop.-1024x567.png" alt="AI training data collection with humans in the loop and simple software automation" width="1024" height="567">
<p>&nbsp;</p>
<figcaption>How machine learning training data generation works with the use of simple software automation and humans in the loop.</figcaption>
</figure>
</div>



<p>If we reimagine this approach for the fraudulent login example, the software will flag all suspicious login attempts. Then a human goes in and fixes problematic classification.&nbsp; Or, in the case of the duplicate thread detection problem, the software may suggest potential duplicates to customers. But in the end, customers decide if two discussion threads are, in fact, duplicates. This reduces the amount of manual work that customers or domain experts would have to put in—hastening data generation.&nbsp;</p>



<h4 id="8-when-is-a-semi-automatic-approach-suitable">When is a semi-automatic approach suitable?</h4>



<p>A semi-automatic approach is suitable for problems that can be encoded fairly quickly using software rules. For example, you could potentially express conditions that lead to fraudulent website logins using a set of rules. Of course, these rules may not be 100 or even 90 percent accurate. But it can be good enough to get started, allowing the humans-in-the-loop to be the final decision-makers.</p>



<h4 id="9-pros-and-cons-of-a-semi-automatic-approach-"><strong>Pros and cons of a semi-automatic approach:</strong></h4>



<p>The benefit of using a semi-automatic approach is an<strong> improvement in speed</strong> over a manual method. That’s because you can drastically reduce manual work for a human decision-maker with a rules-based software in the mix. This in turn speeds up task completion and the potential to generate a higher volume of data in a shorter time.&nbsp;</p>



<p>The downside of this approach is that it may be hard to form a reliable set of rules for certain problems. Plus, it can take additional time and monetary investments to develop the rules-based software automation.</p>



<h3 id="10-4-crowdsource-internally">#4: Crowdsource Internally</h3>



<p>Crowdsourcing internally means asking a group of people you know and trust (e.g., within the company or your friend’s circle) to complete a certain labeling task.</p>



<div class="wp-block-image">
<figure class="aligncenter size-large"><img decoding="async" loading="lazy" class="wp-image-13626" src="https://www.opinosis-analytics.com/wp-content/uploads/2021/07/internal-crowdsourcing-to-generate-machine-learning-training-data-1024x554.png" alt="internal crowdsourcing to generate ML training data" width="1024" height="554">
<p>&nbsp;</p>
<figcaption>How internal crowdsourcing works to generate data for machine learning</figcaption>
</figure>
</div>



<p>Say you’re looking to build a sentiment classification tool; You could ask colleagues to label phrases such as “prompt customer service” and “flawed design” as containing a positive or negative sentiment, specifically to generate labeled data to develop the ML tool. This is different from a manual or semi-automatic approach as you’re taking the task out of its natural context and presenting it to different people to generate labels.&nbsp;</p>



<p>Internal crowdsourcing requires some extra setup work to acquire labels. I’ve personally used online platforms such as <a href="https://www.lighttag.io/">LightTag</a> to collect labels from SMEs, but there are many others out there.</p>



<div class="wp-block-image">
<figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" class="wp-image-13642" src="https://www.opinosis-analytics.com/wp-content/uploads/2021/07/name-labeling-task--1024x610.png" alt="Labeling with lighttag to generate data for training ML models" width="797" height="474">
<p>&nbsp;</p>
<figcaption>Example Labeling of people and places with LightTag</figcaption>
</figure>
</div>



<p>The trick is to find a tool that fits the task. Some companies end up building their own systems to collect labels as the off-the-shelf tools are either not flexible enough for their needs or they’re concerned about data privacy.&nbsp;</p>



<h4 id="11-when-is-crowdsourcing-internally-suitable">When is crowdsourcing internally suitable?</h4>



<p>Data generation tasks that can be easily taken out of context or don’t require domain expertise make great internal crowdsourcing candidates. For example, these can be tasks that only require “common sense” or knowledge of a particular language. People in your trusted circle are unlikely to be spammers and are inclined to complete tasks properly to support your cause. Internal crowdsourcing can also work with complex tasks—but you must use the right SMEs. I’ve personally had several successes with crowdsourcing using a team of SMEs within the healthcare domain. You can do the same.&nbsp;</p>



<h4 id="12-pros-and-cons-of-internal-crowdsourcing-"><strong>Pros and cons of internal crowdsourcing:</strong></h4>



<p>The benefit of crowdsourcing internally is that you can generate a good volume of high-quality labeled data for many problems. But you need to be extra careful with tasks that require domain expertise. For example, if you’re asking a group of radiologists from different hospitals to study a set of digital images and label tumor location, you may need labels from different SMEs for a single task to ensure accuracy. This can slow things down, but at least you’re sure you’re generating quality data. Also, there may not be an appropriate off-the-shelf tool to help you obtain the necessary labels, and you may have to build the tool first. Not to forget, you’d also need to train your labelers to complete tasks adequately.&nbsp;&nbsp;</p>



<h3 id="13-5-crowdsource-externally">#5: Crowdsource Externally</h3>



<p>Crowdsourcing externally is about paying <em>unknown</em> human workers to generate the necessary data for your ML projects. These workers could very well be in different countries.</p>



<div class="wp-block-image">
<figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" class="wp-image-13631" src="https://www.opinosis-analytics.com/wp-content/uploads/2021/07/How-external-crowdsourcing-works-to-generate-training-data-for-ML-1024x770.png" alt="How external crowdsourcing works to generate training data for ML" width="790" height="593">
<p>&nbsp;</p>
<figcaption>How external crowdsourcing works to generate training data for ML</figcaption>
</figure>
</div>



<p><a href="https://www.mturk.com/">Amazon Mechanical Turk</a>, for example, is an online platform that allows you to outsource labeling tasks to workers around the world, to generate data for machine learning projects quickly. There are also data labeling companies that hire workers specifically to <a href="https://www.sama.com/">generate data</a> for AI projects.&nbsp;</p>



<p>Crowdsourcing externally is a speedy way of generating large volumes of data. For example, I’ve received sentiment annotations for several thousand sentences from Mechanical Turk in a matter of minutes. But as with anything this easy, there’s always a catch. The labeling may not always be accurate. This means that you need to vet the quality of workers, or pay higher costs per labeling task to get more “trustworthy” workers on your task. You may also need multiple workers to complete the same task to ensure that the labels are accurate.&nbsp;</p>



<h4 id="14-when-is-crowdsourcing-externally-suitable">When is crowdsourcing externally suitable?</h4>



<p>External crowdsourcing is very effective for simple labeling tasks that don’t require special domain knowledge and can be taken out of their natural context. For example:</p>



<ul><li>Tagging people and objects within images</li><li>Casting a sentiment opinion on pieces of text</li><li>Tagging people, places, and products in text</li></ul>



<h4 id="15-pros-and-cons-of-a-external-crowdsourcing-"><strong>Pros and cons of a external crowdsourcing:</strong></h4>



<p>Crowdsourcing externally is the fastest way to generate huge amounts of data in a short period of time. But this comes with several downsides. First, the quality of labels may not be as accurate as you’d like it to be. So, this approach should be reserved for tasks that can tolerate some “noise” in the predictions. You’d also need to think about how to account for spam labels by workers randomly completing tasks, and also how best to improve the accuracy of labels produced by your unknown workers.&nbsp;</p>



<div class="wp-block-image">
<figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" class="wp-image-13612" src="https://www.opinosis-analytics.com/wp-content/uploads/2021/07/generating-machine-learning-training-data-manual-vs.-crowdsourced-1024x576.png" alt="generating synthetic data for machine learning using crowdsourcing approaches" width="961" height="541">
<p>&nbsp;</p>
<figcaption>Key differences between a manual or semi-automatic approach and a crowdsourcing approach in generating data for machine learning</figcaption>
</figure>
</div>



<h2 id="16-comparison-of-all-training-data-generation-strategies">Comparison of ALL Training Data Generation Strategies</h2>



<p>Here’s a quick comparison of the different machine learning training data generation strategies discussed in this article. I hope this guides you towards the best approach for your machine learning projects.</p>



<div class="wp-block-image">
<figure class="aligncenter size-large"><img decoding="async" loading="lazy" class="wp-image-13616" src="https://www.opinosis-analytics.com/wp-content/uploads/2021/07/how-to-generate-machine-learning-training-data-comparison-1024x1024.png" alt="how to generate synthetic training data for machine learning training comparison" width="1024" height="1024">
<p>&nbsp;</p>
<figcaption>Comparison of the different strategies for generating ML training data</figcaption>
</figure>
</div>



<h2 id="17-final-word">Final Word</h2>



<p>We’ve seen that there are many ways to get started with AI initiatives without an elaborate <a href="https://kavita-ganesan.com/big-data-strategy/">data strategy.</a> If you’re looking to automate a new problem with AI,&nbsp; but you don’t have the data, you can generate it by starting with a manual process. Alternatively, you can augment your manual process with a semi-automatic approach to increase data generation speed.</p>



<p>Further, if a task can be taken out of its natural context and you don’t need deep domain expertise, you can think about crowdsourcing internally within a trusted circle or externally, with unknown human workers. But external crowdsourcing requires extra care to counter quality issues such as spam and unreliable labels.</p>



<p>So which approach should you consider? This is entirely task-dependent. If you’re dealing with tasks where <strong>accuracy</strong> is of utmost importance, a manual or semi-automatic strategy and internal crowdsourcing with SMEs can work well. If you need labeled data for a task that anyone can easily complete, you could consider internal or external crowdsourcing. If you’re having data struggles for your ML projects, would you consider any of these approaches? Leave a comment below to share your thoughts!</p>



<div class="inherit-container-width is-layout-constrained wp-block-group has-ast-global-color-4-background-color has-background" style="border-style:dotted;border-width:1px;padding-top:10px;padding-right:10px;padding-bottom:10px;padding-left:10px"><div class="wp-block-group__inner-container">
<h2>Keep Learning From Me:</h2>



<ul><li><strong>Join my&nbsp;<a href="https://kavita-ganesan.com/blog">AI Integrated newsletter</a>,&nbsp;</strong>which clears the AI confusion and teaches you how to successfully integrate AI to achieve profitability and growth in your business.</li><li><strong>Read&nbsp;&nbsp;<a href="http://amazon.aibusinesscasebook.com/?utm_source=newsletter&amp;utm_medium=email&amp;utm_campaign=why_starting_without_ai_improves_outcomes_even_if_ai_is_your_goal&amp;utm_term=2022-08-19" target="_blank" rel="noreferrer noopener">The Business Case for AI</a></strong>&nbsp;to learn applications, strategies, and best practices to be successful with AI (select companies using the book: government agencies, automakers like Mercedes Benz, beverage makers, and e-commerce companies such as Flipkart).</li></ul>
</div></div>



<p></p>



<p></p>
]]></content:encoded>
					
					<wfw:commentRss>https://kavita-ganesan.com/machine-learning-training-data-generation/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">6039</post-id>	</item>
		<item>
		<title>FastText vs. Word2vec: A Quick Comparison</title>
		<link>https://kavita-ganesan.com/fasttext-vs-word2vec/</link>
					<comments>https://kavita-ganesan.com/fasttext-vs-word2vec/#respond</comments>
		
		<dc:creator><![CDATA[Kavita Ganesan]]></dc:creator>
		<pubDate>Thu, 08 Jul 2021 20:54:29 +0000</pubDate>
				<category><![CDATA[AI Implementation]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[Neural Embeddings]]></category>
		<guid isPermaLink="false">https://kavita-ganesan.com/?p=5990</guid>

					<description><![CDATA[One of the questions that often comes up is what&#8217;s the difference between fastText&#160;and Word2Vec? Aren&#8217;t they both the same? Yes and no. They are conceptually the same, but there is a minor difference—fastText&#160;operates at a character level but Word2Vec operates at a word level. Why this difference? Before we dive into fastText&#160;, let&#8217;s quickly &#8230;<p class="read-more"> <a class="" href="https://kavita-ganesan.com/fasttext-vs-word2vec/"> <span class="screen-reader-text">FastText vs. Word2vec: A Quick Comparison</span> Read More »</a></p>]]></description>
										<content:encoded><![CDATA[
<p>One of the questions that often comes up is what&#8217;s the difference between fastText&nbsp;and Word2Vec? Aren&#8217;t they both the same?</p>



<p>Yes and no. They are conceptually the same, but there is a minor difference—fastText&nbsp;operates at a <em>character </em>level but Word2Vec operates at a <em>word </em>level. Why this difference?</p>



<p>Before we dive into fastText&nbsp;, let&#8217;s quickly recap what Word2Vec is. With Word2Vec, we train a neural network with a single hidden layer to predict a&nbsp;<strong>target word</strong>&nbsp;based on its&nbsp;<strong>context</strong>&nbsp;(<strong>neighboring words</strong>). The assumption is that&nbsp;<em>the meaning of a word can be inferred by the company it keeps</em>. Under the hood, when it comes to training you could use two different neural architectures to achieve this—<a href="https://kavita-ganesan.com/comparison-between-cbow-skipgram-subword/"><em>CBOW</em> and <em>SkipGram</em></a>.</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" src="https://kavita-ganesan.com/wp-content/uploads/skipgram-vs-cbow-continuous-bag-of-words-word2vec-word-representation-1024x538.png" alt="Difference between skipgram and cbow - word2vec" class="wp-image-4613" width="785" height="412" srcset="https://kavita-ganesan.com/wp-content/uploads/skipgram-vs-cbow-continuous-bag-of-words-word2vec-word-representation-1024x538.png 1024w, https://kavita-ganesan.com/wp-content/uploads/skipgram-vs-cbow-continuous-bag-of-words-word2vec-word-representation-300x158.png 300w, https://kavita-ganesan.com/wp-content/uploads/skipgram-vs-cbow-continuous-bag-of-words-word2vec-word-representation-150x79.png 150w, https://kavita-ganesan.com/wp-content/uploads/skipgram-vs-cbow-continuous-bag-of-words-word2vec-word-representation-768x403.png 768w, https://kavita-ganesan.com/wp-content/uploads/skipgram-vs-cbow-continuous-bag-of-words-word2vec-word-representation-1536x806.png 1536w, https://kavita-ganesan.com/wp-content/uploads/skipgram-vs-cbow-continuous-bag-of-words-word2vec-word-representation-2048x1075.png 2048w" sizes="(max-width: 785px) 100vw, 785px" /><figcaption>CBOW vs. SkipGram</figcaption></figure></div>



<p>And as you know, after the training phase using either architecture, you can use the learned vectors in creative ways. For example, for recommendations, synonyms extraction, and more. The <strong>SkipGram </strong>architecture from Word2Vec was taken one level deeper, to operate at a character n-gram level—essentially using a bag of character n-grams. This is fastText.</p>



<p></p>



<h2>What is a character n-gram?</h2>



<p>A character n-gram is a set of co-occurring characters within a given window. It&#8217;s very similar to word <a href="https://kavita-ganesan.com/what-are-n-grams/">n-grams</a>, only that the window size is at the character level. And a <em>bag </em>of character n-grams in the fastText case means a word is represented by a sum of its character n-grams. If <code>n=</code>2, and your word is <em><strong><code>this</code> </strong></em>your resulting n-grams would be:</p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: plain; title: ; notranslate">
&lt;t
th
hi
is
s&gt;
this

</pre></div>


<p>The last item is a special sequence. Here&#8217;s a visual example of how the neighboring word <em>this </em>is represented in learning to predict the word <em>visual</em> based on the sentence &#8220;<strong>this</strong> is a <strong>visual</strong> example&#8221; (remember: the meaning of a word, is inferred by the company it keeps).</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" src="https://kavita-ganesan.com/wp-content/uploads/SkipGram-with-subword-information-character-n-gram-size2.-Also-known-as-FastText-1024x794.png" alt="Word2Vec vs. fastText" class="wp-image-4696" width="710" height="551" srcset="https://kavita-ganesan.com/wp-content/uploads/SkipGram-with-subword-information-character-n-gram-size2.-Also-known-as-FastText-1024x794.png 1024w, https://kavita-ganesan.com/wp-content/uploads/SkipGram-with-subword-information-character-n-gram-size2.-Also-known-as-FastText-300x233.png 300w, https://kavita-ganesan.com/wp-content/uploads/SkipGram-with-subword-information-character-n-gram-size2.-Also-known-as-FastText-150x116.png 150w, https://kavita-ganesan.com/wp-content/uploads/SkipGram-with-subword-information-character-n-gram-size2.-Also-known-as-FastText-768x596.png 768w, https://kavita-ganesan.com/wp-content/uploads/SkipGram-with-subword-information-character-n-gram-size2.-Also-known-as-FastText.png 1436w" sizes="(max-width: 710px) 100vw, 710px" /><figcaption>Skip-Gram with character n-gram information (character n-gram size=2). </figcaption></figure></div>



<p>The intuition behind fastText&nbsp;is that by using a bag of character n-grams, you can learn representations for&nbsp;morphologically rich languages. </p>



<p>For example, in languages such as German, certain phrases are expressed as a single word. The phrase <em>table tennis,</em> for instance, is written in as Tischtennis. In plain vanilla Word2Vec, you&#8217;ll learn the representation of <code>tennis</code> and <code>tischtennis</code> separately. This makes it harder to infer that <code>tennis</code> and <code>tischtennis</code> are in fact related. </p>



<p>However, by learning the character n-gram representation of these words,&nbsp;<code>tennis</code>&nbsp;and&nbsp;<code>tischtennis</code>&nbsp;will now share overlapping n-grams, making them closer in vector space. And thus, would make it easier to surface related concepts. </p>



<p>Another use of character n-gram representation is to infer the meaning of unseen words. For example, if you are looking for the similarity of&nbsp;<code>courageous</code> and your corpora does not carry this word, you can still infer its meaning from its subwords such as&nbsp;<code>courage</code>.</p>



<h2>Some Interesting Tidbits</h2>



<ul><li>From the original <a href="https://arxiv.org/abs/1607.04606">fastText paper, </a>the authors found that the use of character n-grams was more useful in morphologically rich languages such as Arabic, German and Russian than for English (evaluated using rank correlation with human judgment). I can attest to this as I did try subword information for English similarity and the results were not as good as using CBOW.  (See my <a href="https://kavita-ganesan.com/comparison-between-cbow-skipgram-subword/">CBOW vs. SkipGram</a> article)</li><li>The authors found that using n-grams with <code><em>n>=3</em></code> and <code><em>n&lt;=6</em></code> worked best. But the The optimal n-gram size really depends on the task and language and should be tuned appropriately. </li><li>For analogy tasks, subword information significantly improved syntactic analogy tasks but did not help with semantic (meaning) analogy tasks. </li></ul>



<h2>Summing up fastText vs. Word2Vec</h2>



<p>In summary, conceptually Word2Vec and fastText have the same goal: to learn vector representations of words. But unlike Word2Vec, which under the hood uses words to predict words, fastText operates at a more granular level with character n-grams. Where words are represented by the sum of the character n-gram vectors.</p>



<p>Is fastText better than Word2Vec? In my opinion, no. It does better on some tasks and maybe in non-English languages. But for tasks in English, I&#8217;ve found Word2Vec to be just as good or better. </p>



<h2>Learn More About Word Embeddings: </h2>



<ul class="has-background" style="background-color:#fff9f9"><li><a href="https://kavita-ganesan.com/comparison-between-cbow-skipgram-subword/">Comparison between CBOW, SkipGram and SkipGramSI</a></li><li><a href="https://kavita-ganesan.com/gensim-word2vec-tutorial-starter-code/">Gensim Word2Vec Tutorial: An End-to-End Example</a></li><li><a href="https://kavita-ganesan.com/easily-access-pre-trained-word-embeddings-with-gensim/">Easily Access Pre-trained Word Embeddings with Gensim</a></li></ul>
]]></content:encoded>
					
					<wfw:commentRss>https://kavita-ganesan.com/fasttext-vs-word2vec/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">5990</post-id>	</item>
		<item>
		<title>3 Painful Mistakes Leaders Can Avoid When Buying AI Solutions</title>
		<link>https://kavita-ganesan.com/buying-ai-solutions/</link>
					<comments>https://kavita-ganesan.com/buying-ai-solutions/#respond</comments>
		
		<dc:creator><![CDATA[Kavita Ganesan]]></dc:creator>
		<pubDate>Fri, 04 Jun 2021 18:53:21 +0000</pubDate>
				<category><![CDATA[AI Strategy]]></category>
		<category><![CDATA[Business AI]]></category>
		<category><![CDATA[undefined]]></category>
		<guid isPermaLink="false">https://kavita-ganesan.com/?p=5925</guid>

					<description><![CDATA[Buying AI solutions requires the right strategy. In this article, we explore 3 mistakes to avoid when buying AI. ]]></description>
										<content:encoded><![CDATA[<p><a href="https://sloanreview.mit.edu/projects/reshaping-business-with-artificial-intelligence/#:~:text=Almost%2085%25%20believe%20AI%20will,or%20sustain%20a%20competitive%20advantage.&amp;text=Our%20research%20reveals%20large%20gaps,is%20their%20approach%20to%20data.">85% of global executives believe that AI can become their competitive advantage</a>. So, the rush to AI adoption is understandable. Unfortunately, implementing AI from scratch takes time, and success comes with <em>experience </em>in building and deploying solutions.</p>
<p>To speed things up, “buying” instead of building from scratch seems like a sensible way to get started; You don’t have to hire a team of data scientists, spend on additional infrastructure, or have support staff on call to troubleshoot model problems. Plus, off-the-shelf solutions are often rigorously tested.</p>
<p>But buying AI solutions is tricky. If you don’t pursue it strategically, you could be buying your way into trouble. Here are three mistakes I see companies make (which you should avoid) when considering third-party AI solutions.</p>
<div class="wp-block-spacer" style="height: 38px;" aria-hidden="true"></div>
<h2>1: Not testing vendor performance</h2>
<p>Performance, what performance, you may be thinking? This is the accuracy or error rate that vendors publish to sell their AI solutions. For example, a vendor may claim a 3%<em> word error rate</em> in automatic speech recognition. Often, you’ll find that vendors tout shiny performance numbers. By itself, this is not a problem, it gives you an idea of how <em>usable</em> the solution is. The problem really starts when you take these numbers at face value.</p>
<p>The data that vendors use to test their solution, can look very different from your company data. Let’s take a sentiment classifier (sentiment classifiers predict sentiment polarity such as positive/negative on some given text). Say a third-party API boasts 98% accuracy on a user reviews dataset, but your plan is not to use it on user reviews. You want to use it for forum comments. Do you think that the 98% accuracy will still hold? It’s unlikely.</p>
<p class="has-background" style="background-color: #eeeeee;"><strong>Action Tip: </strong>To avoid buying into a solution that works on paper, but not on your data, test, test, test—on your own data before making a purchase decision. Use additional metrics that make sense for the problem, and do a side-by-side performance comparison of different vendor solutions on YOUR data.</p>
<div class="wp-block-spacer" style="height: 38px;" aria-hidden="true"></div>
<h2>2: Not thinking about long-term costs and risks</h2>
<p>One significant advantage of buying a solution vs. custom development is cost. It’s often cheaper to buy an off-the-shelf solution than to custom build, especially in-house. It’s also more convenient as you don’t have to put together a team for development. But is this truly more cost-effective?</p>
<p>If you skipped the testing step above, your AI solution could be error-prone even without you knowing it. And with that comes the risks. Are you losing customers because of bad predictions? Are customers constantly complaining due to problems introduced by your AI solution? This not only costs customers, but also your reputation.</p>
<p>Also, the pricing of third-party solutions can change with time, and some solutions need specialized infrastructure, which can be hard to maintain. Navigating through such issues would require additional investments. While you thought you got a good deal, costs may be quietly adding up.</p>
<p class="has-background" style="background-color: #eeeeee;"><strong>Action Tip:</strong> Think through the potential risks of the third-party AI solution in consideration and have a fallback plan. The costs and performance of the AI solution may be justified today. But long-term costs due to lower than desired accuracy, additional infrastructure requirements, and pricing changes may require that you switch paths. Having a plan B can help you act swiftly.</p>
<div class="wp-block-spacer" style="height: 38px;" aria-hidden="true"></div>
<h2>3: Not considering business systems compatibility</h2>
<p>When evaluating third-party AI solutions, many companies go with solutions that use the latest techniques or with the highest published accuracy. But this may not always be the right move for your organization. Third-party AI solutions come in all shapes and forms. Some are available as a cloud service. Some require code integration with your existing software systems.</p>
<div class="wp-block-image is-style-default">
<figure class="aligncenter size-large"><img decoding="async" loading="lazy" class="wp-image-13265" src="https://i1.wp.com/www.opinosis-analytics.com/wp-content/uploads/2021/06/buying-ai_incompatible-systems.jpeg?resize=600%2C263&amp;ssl=1" alt="buying ai_incompatible systems" width="600" height="263" data-recalc-dims="1"><figcaption>Incompatible software systems can create a mess</figcaption></figure>
</div>
<p>Without compatibility between the consumer application and the AI solution, you’d have to jump through many hoops to get the consumer application and the AI solution talking. If you find that integration is impossible or just too expensive <em>after </em>you’ve purchased the solution, it’s too late. You risk wasting the subscription or license altogether.</p>
<p class="has-background" style="background-color: #eeeeee;"><strong>Action Tip: </strong>When testing different vendor solutions, try to attempt light integration with a handful of shortlisted solutions. This will help guide your purchase decision to solutions that not just perform well but are also easy to integrate.</p>
<div class="wp-block-image">
<figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" class="wp-image-13252" src="https://i0.wp.com/www.opinosis-analytics.com/wp-content/uploads/2021/06/buying-ai-solutions-3-mistakes-companies-should-avoid-1.png?w=1000&amp;ssl=1" alt="buying ai solutions --3 mistakes companies should avoid" width="-42" height="-32" data-recalc-dims="1"><figcaption>The Best Third-Party AI Solutions Have 3 Core Properties</figcaption></figure>
</div>
<div class="wp-block-spacer" style="height: 38px;" aria-hidden="true"></div>
<h2>Final Word About Buying AI Solutions</h2>
<p>Buying off-the-shelf AI solutions can be a convenient option to hit the ground running with AI. But doing it strategically is essential. High vendor published accuracy doesn’t automatically mean high accuracy on your company data. Or a cheap off-the-shelf AI solution does not mean it’s truly more cost-effective. This is why it’s best to dig deeper as you’re shortlisting solutions.</p>
<p>Use the action tips from above as a starting point to guide your purchase decisions. Establishing performance benchmarks, investigating integration compatibility, and analyzing costs and risks are all within your control. Plus, the groundwork that you lay today, will serve you in the long term, such as when you’re looking to revert to an in-house solution or want to consider other third-party options.</p>
<p>The post <a href="https://www.opinosis-analytics.com/blog/buying-ai-solutions/#.YLp2UqhKhPY" rel="nofollow">3 Painful Mistakes Leaders Can Avoid When Buying AI Solutions</a> appeared first on <a href="https://www.opinosis-analytics.com" rel="nofollow">Opinosis Analytics</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://kavita-ganesan.com/buying-ai-solutions/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">5925</post-id>	</item>
	</channel>
</rss>
